# Comparing `tmp/lightgbm-3.3.5.tar.gz` & `tmp/lightgbm-4.0.0.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "dist/lightgbm-3.3.5.tar", last modified: Tue Jan 24 02:09:01 2023, max compression
+gzip compressed data, was "lightgbm-4.0.0.tar", last modified: Wed Nov  9 12:37:21 2022, max compression
```

## Comparing `lightgbm-3.3.5.tar` & `lightgbm-4.0.0.tar`

### file list

```diff
@@ -1,815 +1,777 @@
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1083 2023-01-24 02:09:01.000000 lightgbm-3.3.5/LICENSE
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2369 2023-01-24 02:04:40.000000 lightgbm-3.3.5/MANIFEST.in
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    14927 2023-01-24 02:09:01.000000 lightgbm-3.3.5/PKG-INFO
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    13974 2023-01-24 02:04:40.000000 lightgbm-3.3.5/README.rst
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/_IS_SOURCE_PACKAGE.txt
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    18994 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/CMakeLists.txt
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/cmake/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4743 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/cmake/IntegratedOpenCL.cmake
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/compute/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4326 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/CMakeLists.txt
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/compute/cmake/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      247 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/cmake/BoostComputeConfig.cmake.in
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     5611 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/cmake/FindBolt.cmake
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     7381 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/cmake/FindEigen.cmake
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    12956 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/cmake/FindTBB.cmake
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/compute/cmake/opencl/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3311 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/cmake/opencl/FindOpenCL.cmake
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/compute/include/
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6375 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/accumulate.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4416 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/adjacent_difference.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     5313 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/adjacent_find.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1427 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/all_of.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1544 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/any_of.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1480 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/binary_search.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    31483 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/copy.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2574 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/copy_if.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1940 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/copy_n.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2103 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/count.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2388 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/count_if.hpp
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6267 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/balanced_path.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4626 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/binary_find.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2188 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/compact.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     7382 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/copy_on_device.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6731 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/copy_to_device.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6658 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/copy_to_host.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2605 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/count_if_with_ballot.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2648 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/count_if_with_reduce.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4241 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/count_if_with_threads.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2441 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/find_extrema.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     5333 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/find_extrema_on_cpu.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4251 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/find_extrema_with_atomics.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    18672 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/find_extrema_with_reduce.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     8509 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/find_if_with_atomics.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4839 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/inplace_reduce.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6030 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/insertion_sort.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3874 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/merge_path.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    14654 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/merge_sort_on_cpu.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    22093 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/merge_sort_on_gpu.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     7339 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/merge_with_merge_path.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    15502 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/radix_sort.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1880 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/random_fill.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     5243 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/reduce_by_key.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    23735 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/reduce_by_key_with_scan.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3949 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/reduce_on_cpu.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    10391 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/reduce_on_gpu.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1545 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/scan.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     7056 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/scan_on_cpu.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    11320 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/scan_on_gpu.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2579 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/search_all.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1990 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/serial_accumulate.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2243 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/serial_count_if.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3151 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/serial_find_extrema.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3504 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/serial_merge.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2145 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/serial_reduce.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4240 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/serial_reduce_by_key.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3184 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/serial_scan.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2209 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/equal.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1636 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/equal_range.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4042 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/exclusive_scan.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    10030 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/fill.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1367 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/fill_n.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2004 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/find.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4772 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/find_end.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1504 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/find_if.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1652 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/find_if_not.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2131 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/for_each.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1423 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/for_each_n.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2796 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/gather.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1903 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/generate.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1277 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/generate_n.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     5615 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/includes.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3402 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/inclusive_scan.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3849 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/inner_product.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2047 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/inplace_merge.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1735 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/iota.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1785 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/is_partitioned.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2744 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/is_permutation.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2436 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/is_sorted.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4950 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/lexicographical_compare.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1573 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/lower_bound.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2781 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/max_element.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     5037 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/merge.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2780 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/min_element.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2668 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/minmax_element.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3409 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/mismatch.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     5703 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/next_permutation.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1426 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/none_of.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2868 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/nth_element.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1676 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/partial_sum.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1523 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/partition.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2592 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/partition_copy.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1858 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/partition_point.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     5695 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/prev_permutation.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3010 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/random_shuffle.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    11454 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/reduce.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     5933 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/reduce_by_key.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2002 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/remove.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1850 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/remove_if.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2588 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/replace.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2230 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/replace_copy.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2438 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/reverse.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2678 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/reverse_copy.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1813 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/rotate.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1529 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/rotate_copy.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3435 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/scatter.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4730 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/scatter_if.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2967 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/search.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4428 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/search_n.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6941 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/set_difference.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6646 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/set_intersection.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     7533 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/set_symmetric_difference.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     7384 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/set_union.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6569 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/sort.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6156 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/sort_by_key.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2737 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/stable_partition.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3809 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/stable_sort.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6071 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/stable_sort_by_key.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1870 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/swap_ranges.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3252 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/transform.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4737 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/transform_if.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3683 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/transform_reduce.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2565 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/unique.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6429 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/unique_copy.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1561 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/upper_bound.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4399 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm.hpp
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/allocator/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2990 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/allocator/buffer_allocator.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1392 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/allocator/pinned_allocator.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      748 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/allocator.hpp
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/async/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3982 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/async/future.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1652 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/async/wait.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1862 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/async/wait_guard.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      703 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/async.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6783 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/buffer.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1625 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/cl.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      664 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/cl_ext.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    10111 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/closure.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    62500 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/command_queue.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2359 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/config.hpp
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/container/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     7670 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/container/array.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     7854 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/container/basic_string.hpp
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/container/detail/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1507 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/container/detail/scalar.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6852 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/container/dynamic_bitset.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    10795 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/container/flat_map.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     8359 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/container/flat_set.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6910 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/container/mapped_view.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1587 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/container/stack.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      801 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/container/string.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    16704 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/container/valarray.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    23941 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/container/vector.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1021 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/container.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6594 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/context.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1141 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/core.hpp
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      851 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/assert_cl_success.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4062 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/buffer_value.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3130 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/cl_versions.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     5394 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/device_ptr.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     5196 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/diagnostic.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1641 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/duration.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     8316 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/get_object_info.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      936 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/getenv.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1437 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/global_static.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      960 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/is_buffer_iterator.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3720 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/is_contiguous_iterator.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1662 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/iterator_plus_distance.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1414 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/iterator_range_size.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1158 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/iterator_traits.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1444 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/literal.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3467 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/lru_cache.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    32043 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/meta_kernel.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2270 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/mpl_vector_to_tuple.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2073 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/nvidia_compute_capability.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     7191 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/parameter_cache.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2100 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/path.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2588 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/print_range.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2542 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/read_write_single_value.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1545 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/sha1.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1836 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/variadic_macros.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1491 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/vendor.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1242 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/work_size.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    21203 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/device.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    10280 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/event.hpp
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/exception/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2575 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/exception/context_error.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1321 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/exception/no_device_found.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6707 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/exception/opencl_error.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1707 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/exception/program_build_failure.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2200 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/exception/unsupported_extension_error.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      858 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/exception.hpp
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/experimental/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1468 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/experimental/clamp_range.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1449 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/experimental/malloc.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1989 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/experimental/sort_by_transform.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1336 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/experimental/tabulate.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    12138 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/function.hpp
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1200 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional/as.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2949 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional/atomic.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     7230 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional/bind.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1117 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional/common.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1230 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional/convert.hpp
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional/detail/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1256 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional/detail/macros.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1435 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional/detail/nvidia_ballot.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1226 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional/detail/nvidia_popcount.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4206 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional/detail/unpack.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2097 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional/field.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1447 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional/geometry.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1883 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional/get.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2573 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional/hash.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1553 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional/identity.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1176 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional/integer.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4723 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional/logical.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4281 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional/math.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3073 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional/operator.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1802 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional/popcount.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1983 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional/relational.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1343 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional.hpp
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/image/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     5655 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/image/image1d.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     7776 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/image/image2d.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     8050 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/image/image3d.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3990 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/image/image_format.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4640 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/image/image_object.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6113 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/image/image_sampler.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      894 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/image.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      549 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/image2d.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      549 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/image3d.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      559 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/image_format.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      561 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/image_sampler.hpp
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/eigen/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2666 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/eigen/core.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      617 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/eigen.hpp
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/opencv/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4745 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/opencv/core.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1059 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/opencv/highgui.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1382 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/opencv/ocl.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      673 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/opencv.hpp
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/opengl/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3751 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/opengl/acquire.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      723 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/opengl/cl_gl.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      743 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/opengl/cl_gl_ext.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4565 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/opengl/context.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      659 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/opengl/gl.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2828 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/opengl/opengl_buffer.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3638 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/opengl/opengl_renderbuffer.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3942 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/opengl/opengl_texture.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      941 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/opengl.hpp
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/qt/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2173 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/qt/qimage.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      692 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/qt/qpoint.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      699 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/qt/qpointf.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      724 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/qt/qtcore.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      625 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/qt/qtgui.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1382 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/qt/qvector.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      653 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/qt.hpp
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/vtk/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2054 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/vtk/bounds.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2677 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/vtk/data_array.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1293 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/vtk/matrix4x4.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1841 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/vtk/points.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      762 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/vtk.hpp
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/iterator/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     8270 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/iterator/buffer_iterator.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     5576 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/iterator/constant_buffer_iterator.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4244 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/iterator/constant_iterator.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4602 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/iterator/counting_iterator.hpp
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/iterator/detail/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1674 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/iterator/detail/get_base_iterator_buffer.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     5888 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/iterator/detail/swizzle_iterator.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3908 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/iterator/discard_iterator.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4983 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/iterator/function_input_iterator.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6313 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/iterator/permutation_iterator.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     9596 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/iterator/strided_iterator.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     7752 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/iterator/transform_iterator.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    10435 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/iterator/zip_iterator.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1140 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/iterator.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    17580 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/kernel.hpp
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/lambda/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    10915 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/lambda/context.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    25023 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/lambda/functional.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4225 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/lambda/get.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2232 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/lambda/make_pair.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4914 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/lambda/make_tuple.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      788 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/lambda/placeholder.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2496 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/lambda/placeholders.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4119 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/lambda/result_of.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      862 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/lambda.hpp
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/memory/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2252 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/memory/local_buffer.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4446 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/memory/svm_ptr.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      717 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/memory.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6994 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/memory_object.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4008 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/pipe.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     7420 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/platform.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    25342 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/program.hpp
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/random/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2968 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/random/bernoulli_distribution.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      801 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/random/default_random_engine.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     5397 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/random/discrete_distribution.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     7498 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/random/linear_congruential_engine.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     8288 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/random/mersenne_twister_engine.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4642 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/random/normal_distribution.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    13937 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/random/threefry_engine.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3598 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/random/uniform_int_distribution.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3474 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/random/uniform_real_distribution.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1148 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/random.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      551 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/source.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1969 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/svm.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     9388 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/system.hpp
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/type_traits/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2198 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/type_traits/common_type.hpp
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/type_traits/detail/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      959 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/type_traits/detail/capture_traits.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1351 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/type_traits/is_device_iterator.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2558 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/type_traits/is_fundamental.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1105 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/type_traits/is_vector_type.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2344 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/type_traits/make_vector_type.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1312 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/type_traits/result_of.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2366 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/type_traits/scalar_type.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1133 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/type_traits/type_definition.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3709 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/type_traits/type_name.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2193 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/type_traits/vector_size.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1106 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/type_traits.hpp
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/types/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      557 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/types/builtin.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4906 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/types/complex.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     5978 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/types/fundamental.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3177 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/types/pair.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1740 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/types/size_t.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     5713 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/types/struct.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     8803 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/types/tuple.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      870 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/types.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2414 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/user_event.hpp
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/utility/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2186 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/utility/dim.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3876 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/utility/extents.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2786 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/utility/invoke.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     5493 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/utility/program_cache.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1327 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/utility/source.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     5739 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/utility/wait_list.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      823 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/utility.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      665 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/version.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      557 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/wait_list.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1523 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute.hpp
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/compute/meta/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      268 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/compute/meta/libraries.json
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/eigen/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    25536 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/CMakeLists.txt
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1206 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/Cholesky
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    12156 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/Core
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      122 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/Dense
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1822 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/Eigenvalues
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1948 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/Geometry
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      874 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/Householder
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      939 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/Jacobi
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1433 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/LU
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1317 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/QR
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1629 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/SVD
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Cholesky/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    24837 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Cholesky/LDLT.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    18683 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Cholesky/LLT.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3974 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Cholesky/LLT_LAPACKE.h
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    19214 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/ArithmeticSequence.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    16713 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Array.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     8217 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/ArrayBase.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6775 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/ArrayWrapper.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2738 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Assign.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    40319 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/AssignEvaluator.h
--rwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    12488 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Assign_MKL.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    13910 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/BandMatrix.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    18400 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Block.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4409 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/BooleanRedux.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     5981 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/CommaInitializer.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6990 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/ConditionEstimator.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    63980 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/CoreEvaluators.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4745 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/CoreIterators.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     7942 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/CwiseBinaryOp.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    33010 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/CwiseNullaryOp.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     8256 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/CwiseTernaryOp.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3877 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/CwiseUnaryOp.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     5345 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/CwiseUnaryView.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    29919 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/DenseBase.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    24220 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/DenseCoeffsBase.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    22741 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/DenseStorage.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     9705 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Diagonal.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    14670 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/DiagonalMatrix.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      988 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/DiagonalProduct.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    11651 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Dot.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     5751 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/EigenBase.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4769 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/ForceAlignedAccess.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     5759 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Fuzzy.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    21847 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/GeneralProduct.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    29185 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/GenericPacketMath.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    11398 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/GlobalFunctions.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     8238 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/IO.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     9620 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/IndexedView.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3449 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Inverse.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     7227 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Map.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    11212 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/MapBase.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    55321 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/MathFunctions.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3628 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/MathFunctionsImpl.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    24280 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Matrix.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    23856 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/MatrixBase.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2458 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/NestByValue.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3620 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/NoAlias.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    10401 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/NumTraits.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     9197 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/PartialReduxEvaluator.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    20748 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/PermutationMatrix.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    48524 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/PlainObjectBase.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     7333 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Product.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    53277 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/ProductEvaluators.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6397 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Random.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    18669 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Redux.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    13060 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Ref.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     5631 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Replicate.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    17000 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Reshaped.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4218 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/ReturnByValue.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     7457 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Reverse.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6020 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Select.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    14873 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/SelfAdjointView.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1697 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/SelfCwiseBinaryOp.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6797 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Solve.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     9226 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/SolveTriangular.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6170 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/SolverBase.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     8901 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/StableNorm.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    21445 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/StlIterators.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3865 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Stride.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2765 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Swap.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    17546 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Transpose.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    13091 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Transpositions.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    38109 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/TriangularMatrix.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3488 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/VectorBlock.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    35117 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/VectorwiseOp.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     9304 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Visitor.h
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/AVX/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    16853 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/AVX/Complex.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6353 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/AVX/MathFunctions.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    56120 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/AVX/PacketMath.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2564 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/AVX/TypeCasting.h
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/AVX512/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    17855 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/AVX512/Complex.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    18075 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/AVX512/MathFunctions.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    78861 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/AVX512/PacketMath.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1613 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/AVX512/TypeCasting.h
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/AltiVec/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    16101 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/AltiVec/Complex.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2323 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/AltiVec/MathFunctions.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    12086 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/AltiVec/MatrixProduct.h
--rwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    90580 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/AltiVec/PacketMath.h
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/CUDA/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4244 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/CUDA/Complex.h
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/Default/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    25735 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/Default/BFloat16.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1989 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/Default/ConjHelper.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    24292 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/Default/GenericPacketMathFunctions.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2186 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/Default/GenericPacketMathFunctionsFwd.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    27588 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/Default/Half.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1746 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/Default/Settings.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3746 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/Default/TypeCasting.h
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/GPU/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2695 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/GPU/MathFunctions.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    57305 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/GPU/PacketMath.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2256 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/GPU/TypeCasting.h
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/HIP/
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/HIP/hcc/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      691 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/HIP/hcc/math_constants.h
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/MSA/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    19831 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/MSA/Complex.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    16159 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/MSA/MathFunctions.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    33711 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/MSA/PacketMath.h
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/NEON/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    25103 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/NEON/Complex.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2278 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/NEON/MathFunctions.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)   162585 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/NEON/PacketMath.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    51022 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/NEON/TypeCasting.h
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/SSE/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    18707 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/SSE/Complex.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6285 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/SSE/MathFunctions.h
--rwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    57000 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/SSE/PacketMath.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3399 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/SSE/TypeCasting.h
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/SYCL/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     7262 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/SYCL/InteropHeaders.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    11866 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/SYCL/MathFunctions.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    27786 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/SYCL/PacketMath.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    21856 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/SYCL/SyclMemoryModel.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2626 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/SYCL/TypeCasting.h
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/ZVector/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    19037 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/ZVector/Complex.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     8230 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/ZVector/MathFunctions.h
--rwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    36303 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/ZVector/PacketMath.h
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/functors/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6686 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/functors/AssignmentFunctors.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    26043 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/functors/BinaryFunctors.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     8280 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/functors/NullaryFunctors.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4400 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/functors/StlFunctors.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      607 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/functors/TernaryFunctors.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    37942 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/functors/UnaryFunctors.h
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/products/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)   114705 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/products/GeneralBlockPanelKernel.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    20112 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/products/GeneralMatrixMatrix.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    15948 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/products/GeneralMatrixMatrixTriangular.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6936 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/products/GeneralMatrixMatrixTriangular_BLAS.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     5106 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/products/GeneralMatrixMatrix_BLAS.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    21724 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/products/GeneralMatrixVector.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6368 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/products/GeneralMatrixVector_BLAS.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     5583 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/products/Parallelizer.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    21354 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/products/SelfadjointMatrixMatrix.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    11570 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/products/SelfadjointMatrixMatrix_BLAS.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     9958 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/products/SelfadjointMatrixVector.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     5209 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/products/SelfadjointMatrixVector_BLAS.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6164 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/products/SelfadjointProduct.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4104 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/products/SelfadjointRank2Update.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    20987 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/products/TriangularMatrixMatrix.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    13867 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/products/TriangularMatrixMatrix_BLAS.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    14722 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/products/TriangularMatrixVector.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    10571 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/products/TriangularMatrixVector_BLAS.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    14612 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/products/TriangularSolverMatrix.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6707 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/products/TriangularSolverMatrix_BLAS.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     5882 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/products/TriangularSolverVector.h
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/util/
--rwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    21637 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/util/BlasUtil.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    18926 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/util/ConfigureVectorization.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    21496 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/util/Constants.h
--rwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4784 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/util/DisableStupidWarnings.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    15487 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/util/ForwardDeclarations.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6525 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/util/IndexedViewHelper.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    10895 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/util/IntegralConstant.h
--rwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4268 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/util/MKL_support.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    46890 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/util/Macros.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    45640 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/util/Memory.h
--rwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    25627 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/util/Meta.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)       85 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/util/NonMPL2.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1024 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/util/ReenableStupidWarnings.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1432 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/util/ReshapedHelper.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    10643 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/util/StaticAssert.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    11987 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/util/SymbolicIndex.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    35825 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/util/XprHelper.h
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Eigenvalues/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    12559 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Eigenvalues/ComplexEigenSolver.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    17274 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Eigenvalues/ComplexSchur.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4178 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Eigenvalues/ComplexSchur_LAPACKE.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    22970 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Eigenvalues/EigenSolver.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    17176 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Eigenvalues/GeneralizedEigenSolver.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     9716 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Eigenvalues/GeneralizedSelfAdjointEigenSolver.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    14339 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Eigenvalues/HessenbergDecomposition.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     5575 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Eigenvalues/MatrixBaseEigenvalues.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    23640 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Eigenvalues/RealQZ.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    21078 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Eigenvalues/RealSchur.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3650 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Eigenvalues/RealSchur_LAPACKE.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    33949 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4104 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Eigenvalues/SelfAdjointEigenSolver_LAPACKE.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    22538 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Eigenvalues/Tridiagonalization.h
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Geometry/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    14840 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Geometry/AlignedBox.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     8423 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Geometry/AngleAxis.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3639 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Geometry/EulerAngles.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    20539 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Geometry/Homogeneous.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    11962 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Geometry/Hyperplane.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     8955 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Geometry/OrthoMethods.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     9817 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Geometry/ParametrizedLine.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    34410 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Geometry/Quaternion.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6877 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Geometry/Rotation2D.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     8063 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Geometry/RotationBase.h
--rwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6717 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Geometry/Scaling.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    61604 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Geometry/Transform.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     7664 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Geometry/Translation.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6190 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Geometry/Umeyama.h
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Geometry/arch/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     5823 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Geometry/arch/Geometry_SSE.h
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Householder/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4784 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Householder/BlockHouseholder.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     5365 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Householder/Householder.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    23569 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Householder/HouseholderSequence.h
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Jacobi/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    16373 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Jacobi/Jacobi.h
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/LU/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3439 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/LU/Determinant.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    32313 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/LU/FullPivLU.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    15102 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/LU/InverseImpl.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    21856 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/LU/PartialPivLU.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3555 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/LU/PartialPivLU_LAPACKE.h
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/LU/arch/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    13662 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/LU/arch/Inverse_SSE.h
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/QR/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    25498 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/QR/ColPivHouseholderQR.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4662 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/QR/ColPivHouseholderQR_LAPACKE.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    23429 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/QR/CompleteOrthogonalDecomposition.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    26768 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/QR/FullPivHouseholderQR.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    14641 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/QR/HouseholderQR.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2993 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/QR/HouseholderQR_LAPACKE.h
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/SVD/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    53680 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/SVD/BDCSVD.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    32993 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/SVD/JacobiSVD.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     5099 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/SVD/JacobiSVD_LAPACKE.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    14266 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/SVD/SVDBase.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    15957 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/SVD/UpperBidiagonalization.h
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/misc/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2913 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/misc/Image.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2742 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/misc/Kernel.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1748 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/misc/RealSvd2x2.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    30560 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/misc/blas.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     7834 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/misc/lapack.h
--rwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)  1058369 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/misc/lapacke.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      474 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/misc/lapacke_mangling.h
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/plugins/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    14060 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/plugins/ArrayCwiseBinaryOps.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    20084 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/plugins/ArrayCwiseUnaryOps.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    59005 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/plugins/BlockMethods.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4828 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/plugins/CommonCwiseBinaryOps.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     7211 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/plugins/CommonCwiseUnaryOps.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    12283 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/plugins/IndexedViewMethods.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6375 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/plugins/MatrixCwiseBinaryOps.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2937 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/plugins/MatrixCwiseUnaryOps.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6915 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/plugins/ReshapedMethods.h
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/fast_double_parser/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2591 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/fast_double_parser/CMakeLists.txt
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    11343 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/fast_double_parser/LICENSE
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1367 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/fast_double_parser/LICENSE.BSL
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/fast_double_parser/include/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    49482 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/fast_double_parser/include/fast_double_parser.h
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/fmt/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    13051 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/fmt/CMakeLists.txt
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1408 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/fmt/LICENSE.rst
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/fmt/include/
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/external_libs/fmt/include/fmt/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    35802 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/fmt/include/fmt/chrono.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    23649 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/fmt/include/fmt/color.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    24071 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/fmt/include/fmt/compile.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    71298 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/fmt/include/fmt/core.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)   109835 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/fmt/include/fmt/format-inl.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)   132881 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/fmt/include/fmt/format.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2319 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/fmt/include/fmt/locale.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    13680 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/fmt/include/fmt/os.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     5905 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/fmt/include/fmt/ostream.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)       75 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/fmt/include/fmt/posix.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    23257 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/fmt/include/fmt/printf.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    12546 2023-01-24 02:04:52.000000 lightgbm-3.3.5/compile/external_libs/fmt/include/fmt/ranges.h
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/include/
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/include/LightGBM/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2350 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/include/LightGBM/application.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    16960 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/include/LightGBM/bin.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    10931 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/include/LightGBM/boosting.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    69471 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/include/LightGBM/c_api.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    65410 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/include/LightGBM/config.h
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/include/LightGBM/cuda/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      692 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/include/LightGBM/cuda/cuda_utils.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2457 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/include/LightGBM/cuda/vector_cudahost.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    24905 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/include/LightGBM/dataset.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3668 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/include/LightGBM/dataset_loader.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      623 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/include/LightGBM/export.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    19446 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/include/LightGBM/feature_group.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2760 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/include/LightGBM/meta.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3974 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/include/LightGBM/metric.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    11959 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/include/LightGBM/network.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2979 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/include/LightGBM/objective_function.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1276 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/include/LightGBM/prediction_early_stop.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     7985 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/include/LightGBM/train_share_states.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    26222 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/include/LightGBM/tree.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3762 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/include/LightGBM/tree_learner.h
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/include/LightGBM/utils/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4946 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/include/LightGBM/utils/array_args.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     8431 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/include/LightGBM/utils/chunked_array.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    33184 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/include/LightGBM/utils/common.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     5171 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/include/LightGBM/utils/common_legacy_solaris.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2655 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/include/LightGBM/utils/file_io.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     9006 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/include/LightGBM/utils/json11.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4472 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/include/LightGBM/utils/log.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2865 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/include/LightGBM/utils/openmp_wrapper.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2099 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/include/LightGBM/utils/pipeline_reader.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2912 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/include/LightGBM/utils/random.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    11331 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/include/LightGBM/utils/text_reader.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6595 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/include/LightGBM/utils/threading.h
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/include/LightGBM/utils/yamc/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6249 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/include/LightGBM/utils/yamc/alternate_shared_mutex.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4343 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/include/LightGBM/utils/yamc/yamc_rwlock_sched.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     5050 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/include/LightGBM/utils/yamc/yamc_shared_lock.hpp
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/src/
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/src/application/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    10512 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/application/application.cpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    12176 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/application/predictor.hpp
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/src/boosting/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2229 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/boosting/boosting.cpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     7393 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/boosting/dart.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    32155 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/boosting/gbdt.cpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    19076 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/boosting/gbdt.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    24034 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/boosting/gbdt_model_text.cpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3749 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/boosting/gbdt_prediction.cpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6764 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/boosting/goss.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2552 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/boosting/prediction_early_stop.cpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     7963 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/boosting/rf.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4987 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/boosting/score_updater.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    99280 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/c_api.cpp
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/src/io/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    28914 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/io/bin.cpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    16347 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/io/config.cpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    25875 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/io/config_auto.cpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    56853 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/io/dataset.cpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    61290 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/io/dataset_loader.cpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    18411 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/io/dense_bin.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     5436 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/io/file_io.cpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    22412 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/io/json11.cpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    19593 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/io/metadata.cpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     8485 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/io/multi_val_dense_bin.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    12230 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/io/multi_val_sparse_bin.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     8012 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/io/parser.cpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3628 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/io/parser.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    23091 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/io/sparse_bin.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    16475 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/io/train_share_states.cpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    42925 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/io/tree.cpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      912 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/main.cpp
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/src/metric/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    11418 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/metric/binary_metric.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     5511 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/metric/dcg_calculator.cpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     5516 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/metric/map_metric.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2553 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/metric/metric.cpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    13197 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/metric/multiclass_metric.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6040 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/metric/rank_metric.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     9576 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/metric/regression_metric.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    13050 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/metric/xentropy_metric.hpp
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/src/network/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3479 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/network/ifaddrs_patch.cpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      910 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/network/ifaddrs_patch.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6229 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/network/linker_topo.cpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     9003 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/network/linkers.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1840 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/network/linkers_mpi.cpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     7665 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/network/linkers_socket.cpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    13775 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/network/network.cpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     8986 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/network/socket_wrapper.hpp
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/src/objective/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     7532 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/objective/binary_objective.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     8915 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/objective/multiclass_objective.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3866 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/objective/objective_function.cpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    13096 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/objective/rank_objective.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    27371 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/objective/regression_objective.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     9764 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/objective/xentropy_objective.hpp
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/src/treelearner/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     7799 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/treelearner/col_sampler.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     6107 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/treelearner/cost_effective_gradient_boosting.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     7687 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/treelearner/cuda_kernel_launcher.cu
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2592 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/treelearner/cuda_kernel_launcher.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    40282 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/treelearner/cuda_tree_learner.cpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    11073 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/treelearner/cuda_tree_learner.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    12901 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/treelearner/data_parallel_tree_learner.cpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     5661 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/treelearner/data_partition.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    51068 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/treelearner/feature_histogram.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     3551 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/treelearner/feature_parallel_tree_learner.cpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    53236 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/treelearner/gpu_tree_learner.cpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    11501 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/treelearner/gpu_tree_learner.h
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/src/treelearner/kernels/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    36852 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/treelearner/kernels/histogram_16_64_256.cu
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     5394 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/treelearner/kernels/histogram_16_64_256.hu
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     5157 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/treelearner/leaf_splits.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    14634 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/treelearner/linear_tree_learner.cpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4709 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/treelearner/linear_tree_learner.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    47829 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/treelearner/monotone_constraints.hpp
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/src/treelearner/ocl/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    42125 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/treelearner/ocl/histogram16.cl
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    33354 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/treelearner/ocl/histogram256.cl
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    34081 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/treelearner/ocl/histogram64.cl
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     8452 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/treelearner/parallel_tree_learner.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    35277 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/treelearner/serial_tree_learner.cpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     9272 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/treelearner/serial_tree_learner.h
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     9215 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/treelearner/split_info.hpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     2281 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/treelearner/tree_learner.cpp
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    24408 2023-01-24 02:04:40.000000 lightgbm-3.3.5/compile/src/treelearner/voting_parallel_tree_learner.cpp
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/windows/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1653 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/windows/LightGBM.sln
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    18674 2023-01-24 02:09:01.000000 lightgbm-3.3.5/compile/windows/LightGBM.vcxproj
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/lightgbm/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        6 2023-01-24 02:09:01.000000 lightgbm-3.3.5/lightgbm/VERSION.txt
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1390 2023-01-24 02:04:40.000000 lightgbm-3.3.5/lightgbm/__init__.py
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)   166034 2023-01-24 02:04:40.000000 lightgbm-3.3.5/lightgbm/basic.py
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    11220 2023-01-24 02:04:40.000000 lightgbm-3.3.5/lightgbm/callback.py
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     4558 2023-01-24 02:04:40.000000 lightgbm-3.3.5/lightgbm/compat.py
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    65064 2023-01-24 02:04:40.000000 lightgbm-3.3.5/lightgbm/dask.py
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    32995 2023-01-24 02:04:40.000000 lightgbm-3.3.5/lightgbm/engine.py
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)     1449 2023-01-24 02:04:40.000000 lightgbm-3.3.5/lightgbm/libpath.py
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    27302 2023-01-24 02:04:40.000000 lightgbm-3.3.5/lightgbm/plotting.py
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    52983 2023-01-24 02:04:40.000000 lightgbm-3.3.5/lightgbm/sklearn.py
-drwxr-xr-x   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        0 2023-01-24 02:09:01.000000 lightgbm-3.3.5/lightgbm.egg-info/
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    14927 2023-01-24 02:09:01.000000 lightgbm-3.3.5/lightgbm.egg-info/PKG-INFO
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    45724 2023-01-24 02:09:01.000000 lightgbm-3.3.5/lightgbm.egg-info/SOURCES.txt
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        1 2023-01-24 02:09:01.000000 lightgbm-3.3.5/lightgbm.egg-info/dependency_links.txt
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        1 2023-01-24 02:09:01.000000 lightgbm-3.3.5/lightgbm.egg-info/not-zip-safe
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)      121 2023-01-24 02:09:01.000000 lightgbm-3.3.5/lightgbm.egg-info/requires.txt
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)        9 2023-01-24 02:09:01.000000 lightgbm-3.3.5/lightgbm.egg-info/top_level.txt
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)       38 2023-01-24 02:09:01.000000 lightgbm-3.3.5/setup.cfg
--rw-r--r--   0 AzDevOps_azpcontainer  (1001) AzDevOps_azpcontainer  (1002)    15513 2023-01-24 02:04:40.000000 lightgbm-3.3.5/setup.py
+-rw-r--r--   0        0        0    21759 2022-11-09 12:37:21.000000 lightgbm-4.0.0/CMakeLists.txt
+-rw-r--r--   0        0        0     1083 2022-11-09 12:37:21.000000 lightgbm-4.0.0/LICENSE
+-rw-r--r--   0        0        0    16467 2022-11-09 12:37:21.000000 lightgbm-4.0.0/README.rst
+-rw-r--r--   0        0        0     5897 2022-11-09 12:37:21.000000 lightgbm-4.0.0/cmake/IntegratedOpenCL.cmake
+-rw-r--r--   0        0        0     1644 2022-11-09 12:37:21.000000 lightgbm-4.0.0/cmake/Sanitizer.cmake
+-rw-r--r--   0        0        0     6811 2022-11-09 12:37:21.000000 lightgbm-4.0.0/cmake/modules/FindLibR.cmake
+-rw-r--r--   0        0        0     6375 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/accumulate.hpp
+-rw-r--r--   0        0        0     4416 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/adjacent_difference.hpp
+-rw-r--r--   0        0        0     5313 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/adjacent_find.hpp
+-rw-r--r--   0        0        0     1427 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/all_of.hpp
+-rw-r--r--   0        0        0     1544 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/any_of.hpp
+-rw-r--r--   0        0        0     1480 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/binary_search.hpp
+-rw-r--r--   0        0        0    31483 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/copy.hpp
+-rw-r--r--   0        0        0     2574 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/copy_if.hpp
+-rw-r--r--   0        0        0     1940 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/copy_n.hpp
+-rw-r--r--   0        0        0     2103 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/count.hpp
+-rw-r--r--   0        0        0     2388 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/count_if.hpp
+-rw-r--r--   0        0        0     6267 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/balanced_path.hpp
+-rw-r--r--   0        0        0     4626 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/binary_find.hpp
+-rw-r--r--   0        0        0     2188 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/compact.hpp
+-rw-r--r--   0        0        0     7382 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/copy_on_device.hpp
+-rw-r--r--   0        0        0     6731 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/copy_to_device.hpp
+-rw-r--r--   0        0        0     6658 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/copy_to_host.hpp
+-rw-r--r--   0        0        0     2605 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/count_if_with_ballot.hpp
+-rw-r--r--   0        0        0     2648 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/count_if_with_reduce.hpp
+-rw-r--r--   0        0        0     4241 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/count_if_with_threads.hpp
+-rw-r--r--   0        0        0     2441 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/find_extrema.hpp
+-rw-r--r--   0        0        0     5333 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/find_extrema_on_cpu.hpp
+-rw-r--r--   0        0        0     4251 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/find_extrema_with_atomics.hpp
+-rw-r--r--   0        0        0    18672 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/find_extrema_with_reduce.hpp
+-rw-r--r--   0        0        0     8509 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/find_if_with_atomics.hpp
+-rw-r--r--   0        0        0     4839 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/inplace_reduce.hpp
+-rw-r--r--   0        0        0     6030 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/insertion_sort.hpp
+-rw-r--r--   0        0        0     3874 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/merge_path.hpp
+-rw-r--r--   0        0        0    14654 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/merge_sort_on_cpu.hpp
+-rw-r--r--   0        0        0    22093 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/merge_sort_on_gpu.hpp
+-rw-r--r--   0        0        0     7339 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/merge_with_merge_path.hpp
+-rw-r--r--   0        0        0    15502 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/radix_sort.hpp
+-rw-r--r--   0        0        0     1880 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/random_fill.hpp
+-rw-r--r--   0        0        0     5243 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/reduce_by_key.hpp
+-rw-r--r--   0        0        0    23735 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/reduce_by_key_with_scan.hpp
+-rw-r--r--   0        0        0     3949 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/reduce_on_cpu.hpp
+-rw-r--r--   0        0        0    10391 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/reduce_on_gpu.hpp
+-rw-r--r--   0        0        0     1545 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/scan.hpp
+-rw-r--r--   0        0        0     7056 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/scan_on_cpu.hpp
+-rw-r--r--   0        0        0    11320 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/scan_on_gpu.hpp
+-rw-r--r--   0        0        0     2579 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/search_all.hpp
+-rw-r--r--   0        0        0     1990 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/serial_accumulate.hpp
+-rw-r--r--   0        0        0     2243 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/serial_count_if.hpp
+-rw-r--r--   0        0        0     3151 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/serial_find_extrema.hpp
+-rw-r--r--   0        0        0     3504 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/serial_merge.hpp
+-rw-r--r--   0        0        0     2145 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/serial_reduce.hpp
+-rw-r--r--   0        0        0     4240 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/serial_reduce_by_key.hpp
+-rw-r--r--   0        0        0     3184 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/serial_scan.hpp
+-rw-r--r--   0        0        0     2209 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/equal.hpp
+-rw-r--r--   0        0        0     1636 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/equal_range.hpp
+-rw-r--r--   0        0        0     4042 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/exclusive_scan.hpp
+-rw-r--r--   0        0        0    10030 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/fill.hpp
+-rw-r--r--   0        0        0     1367 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/fill_n.hpp
+-rw-r--r--   0        0        0     2004 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/find.hpp
+-rw-r--r--   0        0        0     4772 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/find_end.hpp
+-rw-r--r--   0        0        0     1504 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/find_if.hpp
+-rw-r--r--   0        0        0     1652 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/find_if_not.hpp
+-rw-r--r--   0        0        0     2131 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/for_each.hpp
+-rw-r--r--   0        0        0     1423 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/for_each_n.hpp
+-rw-r--r--   0        0        0     2796 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/gather.hpp
+-rw-r--r--   0        0        0     1903 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/generate.hpp
+-rw-r--r--   0        0        0     1277 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/generate_n.hpp
+-rw-r--r--   0        0        0     5615 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/includes.hpp
+-rw-r--r--   0        0        0     3402 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/inclusive_scan.hpp
+-rw-r--r--   0        0        0     3849 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/inner_product.hpp
+-rw-r--r--   0        0        0     2047 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/inplace_merge.hpp
+-rw-r--r--   0        0        0     1735 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/iota.hpp
+-rw-r--r--   0        0        0     1785 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/is_partitioned.hpp
+-rw-r--r--   0        0        0     2744 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/is_permutation.hpp
+-rw-r--r--   0        0        0     2436 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/is_sorted.hpp
+-rw-r--r--   0        0        0     4950 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/lexicographical_compare.hpp
+-rw-r--r--   0        0        0     1573 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/lower_bound.hpp
+-rw-r--r--   0        0        0     2781 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/max_element.hpp
+-rw-r--r--   0        0        0     5037 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/merge.hpp
+-rw-r--r--   0        0        0     2780 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/min_element.hpp
+-rw-r--r--   0        0        0     2668 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/minmax_element.hpp
+-rw-r--r--   0        0        0     3409 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/mismatch.hpp
+-rw-r--r--   0        0        0     5703 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/next_permutation.hpp
+-rw-r--r--   0        0        0     1426 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/none_of.hpp
+-rw-r--r--   0        0        0     2868 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/nth_element.hpp
+-rw-r--r--   0        0        0     1676 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/partial_sum.hpp
+-rw-r--r--   0        0        0     1523 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/partition.hpp
+-rw-r--r--   0        0        0     2592 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/partition_copy.hpp
+-rw-r--r--   0        0        0     1858 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/partition_point.hpp
+-rw-r--r--   0        0        0     5695 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/prev_permutation.hpp
+-rw-r--r--   0        0        0     3010 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/random_shuffle.hpp
+-rw-r--r--   0        0        0    11454 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/reduce.hpp
+-rw-r--r--   0        0        0     5933 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/reduce_by_key.hpp
+-rw-r--r--   0        0        0     2002 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/remove.hpp
+-rw-r--r--   0        0        0     1850 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/remove_if.hpp
+-rw-r--r--   0        0        0     2588 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/replace.hpp
+-rw-r--r--   0        0        0     2230 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/replace_copy.hpp
+-rw-r--r--   0        0        0     2438 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/reverse.hpp
+-rw-r--r--   0        0        0     2678 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/reverse_copy.hpp
+-rw-r--r--   0        0        0     1813 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/rotate.hpp
+-rw-r--r--   0        0        0     1529 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/rotate_copy.hpp
+-rw-r--r--   0        0        0     3435 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/scatter.hpp
+-rw-r--r--   0        0        0     4730 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/scatter_if.hpp
+-rw-r--r--   0        0        0     2967 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/search.hpp
+-rw-r--r--   0        0        0     4428 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/search_n.hpp
+-rw-r--r--   0        0        0     6941 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/set_difference.hpp
+-rw-r--r--   0        0        0     6646 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/set_intersection.hpp
+-rw-r--r--   0        0        0     7533 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/set_symmetric_difference.hpp
+-rw-r--r--   0        0        0     7384 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/set_union.hpp
+-rw-r--r--   0        0        0     6569 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/sort.hpp
+-rw-r--r--   0        0        0     6156 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/sort_by_key.hpp
+-rw-r--r--   0        0        0     2737 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/stable_partition.hpp
+-rw-r--r--   0        0        0     3809 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/stable_sort.hpp
+-rw-r--r--   0        0        0     6071 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/stable_sort_by_key.hpp
+-rw-r--r--   0        0        0     1870 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/swap_ranges.hpp
+-rw-r--r--   0        0        0     3252 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/transform.hpp
+-rw-r--r--   0        0        0     4737 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/transform_if.hpp
+-rw-r--r--   0        0        0     3683 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/transform_reduce.hpp
+-rw-r--r--   0        0        0     2565 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/unique.hpp
+-rw-r--r--   0        0        0     6429 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/unique_copy.hpp
+-rw-r--r--   0        0        0     1561 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/upper_bound.hpp
+-rw-r--r--   0        0        0     4399 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm.hpp
+-rw-r--r--   0        0        0     2990 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/allocator/buffer_allocator.hpp
+-rw-r--r--   0        0        0     1392 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/allocator/pinned_allocator.hpp
+-rw-r--r--   0        0        0      748 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/allocator.hpp
+-rw-r--r--   0        0        0     3982 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/async/future.hpp
+-rw-r--r--   0        0        0     1652 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/async/wait.hpp
+-rw-r--r--   0        0        0     1862 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/async/wait_guard.hpp
+-rw-r--r--   0        0        0      703 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/async.hpp
+-rw-r--r--   0        0        0     6783 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/buffer.hpp
+-rw-r--r--   0        0        0     1625 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/cl.hpp
+-rw-r--r--   0        0        0      664 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/cl_ext.hpp
+-rw-r--r--   0        0        0    10111 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/closure.hpp
+-rw-r--r--   0        0        0    62500 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/command_queue.hpp
+-rw-r--r--   0        0        0     2359 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/config.hpp
+-rw-r--r--   0        0        0     7670 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/container/array.hpp
+-rw-r--r--   0        0        0     7854 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/container/basic_string.hpp
+-rw-r--r--   0        0        0     1507 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/container/detail/scalar.hpp
+-rw-r--r--   0        0        0     6852 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/container/dynamic_bitset.hpp
+-rw-r--r--   0        0        0    10795 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/container/flat_map.hpp
+-rw-r--r--   0        0        0     8359 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/container/flat_set.hpp
+-rw-r--r--   0        0        0     6910 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/container/mapped_view.hpp
+-rw-r--r--   0        0        0     1587 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/container/stack.hpp
+-rw-r--r--   0        0        0      801 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/container/string.hpp
+-rw-r--r--   0        0        0    16704 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/container/valarray.hpp
+-rw-r--r--   0        0        0    23941 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/container/vector.hpp
+-rw-r--r--   0        0        0     1021 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/container.hpp
+-rw-r--r--   0        0        0     6594 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/context.hpp
+-rw-r--r--   0        0        0     1141 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/core.hpp
+-rw-r--r--   0        0        0      851 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/assert_cl_success.hpp
+-rw-r--r--   0        0        0     4062 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/buffer_value.hpp
+-rw-r--r--   0        0        0     3130 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/cl_versions.hpp
+-rw-r--r--   0        0        0     5394 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/device_ptr.hpp
+-rw-r--r--   0        0        0     5196 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/diagnostic.hpp
+-rw-r--r--   0        0        0     1641 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/duration.hpp
+-rw-r--r--   0        0        0     8316 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/get_object_info.hpp
+-rw-r--r--   0        0        0      936 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/getenv.hpp
+-rw-r--r--   0        0        0     1437 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/global_static.hpp
+-rw-r--r--   0        0        0      960 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/is_buffer_iterator.hpp
+-rw-r--r--   0        0        0     3720 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/is_contiguous_iterator.hpp
+-rw-r--r--   0        0        0     1662 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/iterator_plus_distance.hpp
+-rw-r--r--   0        0        0     1414 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/iterator_range_size.hpp
+-rw-r--r--   0        0        0     1158 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/iterator_traits.hpp
+-rw-r--r--   0        0        0     1444 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/literal.hpp
+-rw-r--r--   0        0        0     3467 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/lru_cache.hpp
+-rw-r--r--   0        0        0    32043 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/meta_kernel.hpp
+-rw-r--r--   0        0        0     2270 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/mpl_vector_to_tuple.hpp
+-rw-r--r--   0        0        0     2073 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/nvidia_compute_capability.hpp
+-rw-r--r--   0        0        0     7191 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/parameter_cache.hpp
+-rw-r--r--   0        0        0     2100 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/path.hpp
+-rw-r--r--   0        0        0     2588 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/print_range.hpp
+-rw-r--r--   0        0        0     2542 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/read_write_single_value.hpp
+-rw-r--r--   0        0        0     1545 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/sha1.hpp
+-rw-r--r--   0        0        0     1836 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/variadic_macros.hpp
+-rw-r--r--   0        0        0     1491 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/vendor.hpp
+-rw-r--r--   0        0        0     1242 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/work_size.hpp
+-rw-r--r--   0        0        0    21203 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/device.hpp
+-rw-r--r--   0        0        0    10280 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/event.hpp
+-rw-r--r--   0        0        0     2575 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/exception/context_error.hpp
+-rw-r--r--   0        0        0     1321 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/exception/no_device_found.hpp
+-rw-r--r--   0        0        0     6707 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/exception/opencl_error.hpp
+-rw-r--r--   0        0        0     1707 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/exception/program_build_failure.hpp
+-rw-r--r--   0        0        0     2200 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/exception/unsupported_extension_error.hpp
+-rw-r--r--   0        0        0      858 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/exception.hpp
+-rw-r--r--   0        0        0     1468 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/experimental/clamp_range.hpp
+-rw-r--r--   0        0        0     1449 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/experimental/malloc.hpp
+-rw-r--r--   0        0        0     1989 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/experimental/sort_by_transform.hpp
+-rw-r--r--   0        0        0     1336 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/experimental/tabulate.hpp
+-rw-r--r--   0        0        0    12138 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/function.hpp
+-rw-r--r--   0        0        0     1200 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/functional/as.hpp
+-rw-r--r--   0        0        0     2949 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/functional/atomic.hpp
+-rw-r--r--   0        0        0     7230 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/functional/bind.hpp
+-rw-r--r--   0        0        0     1117 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/functional/common.hpp
+-rw-r--r--   0        0        0     1230 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/functional/convert.hpp
+-rw-r--r--   0        0        0     1256 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/functional/detail/macros.hpp
+-rw-r--r--   0        0        0     1435 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/functional/detail/nvidia_ballot.hpp
+-rw-r--r--   0        0        0     1226 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/functional/detail/nvidia_popcount.hpp
+-rw-r--r--   0        0        0     4206 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/functional/detail/unpack.hpp
+-rw-r--r--   0        0        0     2097 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/functional/field.hpp
+-rw-r--r--   0        0        0     1447 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/functional/geometry.hpp
+-rw-r--r--   0        0        0     1883 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/functional/get.hpp
+-rw-r--r--   0        0        0     2573 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/functional/hash.hpp
+-rw-r--r--   0        0        0     1553 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/functional/identity.hpp
+-rw-r--r--   0        0        0     1176 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/functional/integer.hpp
+-rw-r--r--   0        0        0     4723 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/functional/logical.hpp
+-rw-r--r--   0        0        0     4281 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/functional/math.hpp
+-rw-r--r--   0        0        0     3073 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/functional/operator.hpp
+-rw-r--r--   0        0        0     1802 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/functional/popcount.hpp
+-rw-r--r--   0        0        0     1983 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/functional/relational.hpp
+-rw-r--r--   0        0        0     1343 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/functional.hpp
+-rw-r--r--   0        0        0     5655 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/image/image1d.hpp
+-rw-r--r--   0        0        0     7776 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/image/image2d.hpp
+-rw-r--r--   0        0        0     8050 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/image/image3d.hpp
+-rw-r--r--   0        0        0     3990 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/image/image_format.hpp
+-rw-r--r--   0        0        0     4640 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/image/image_object.hpp
+-rw-r--r--   0        0        0     6113 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/image/image_sampler.hpp
+-rw-r--r--   0        0        0      894 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/image.hpp
+-rw-r--r--   0        0        0      549 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/image2d.hpp
+-rw-r--r--   0        0        0      549 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/image3d.hpp
+-rw-r--r--   0        0        0      559 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/image_format.hpp
+-rw-r--r--   0        0        0      561 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/image_sampler.hpp
+-rw-r--r--   0        0        0     2666 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/eigen/core.hpp
+-rw-r--r--   0        0        0      617 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/eigen.hpp
+-rw-r--r--   0        0        0     4745 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/opencv/core.hpp
+-rw-r--r--   0        0        0     1059 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/opencv/highgui.hpp
+-rw-r--r--   0        0        0     1382 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/opencv/ocl.hpp
+-rw-r--r--   0        0        0      673 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/opencv.hpp
+-rw-r--r--   0        0        0     3751 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/opengl/acquire.hpp
+-rw-r--r--   0        0        0      723 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/opengl/cl_gl.hpp
+-rw-r--r--   0        0        0      743 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/opengl/cl_gl_ext.hpp
+-rw-r--r--   0        0        0     4565 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/opengl/context.hpp
+-rw-r--r--   0        0        0      659 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/opengl/gl.hpp
+-rw-r--r--   0        0        0     2828 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/opengl/opengl_buffer.hpp
+-rw-r--r--   0        0        0     3638 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/opengl/opengl_renderbuffer.hpp
+-rw-r--r--   0        0        0     3942 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/opengl/opengl_texture.hpp
+-rw-r--r--   0        0        0      941 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/opengl.hpp
+-rw-r--r--   0        0        0     2173 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/qt/qimage.hpp
+-rw-r--r--   0        0        0      692 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/qt/qpoint.hpp
+-rw-r--r--   0        0        0      699 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/qt/qpointf.hpp
+-rw-r--r--   0        0        0      724 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/qt/qtcore.hpp
+-rw-r--r--   0        0        0      625 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/qt/qtgui.hpp
+-rw-r--r--   0        0        0     1382 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/qt/qvector.hpp
+-rw-r--r--   0        0        0      653 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/qt.hpp
+-rw-r--r--   0        0        0     2054 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/vtk/bounds.hpp
+-rw-r--r--   0        0        0     2677 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/vtk/data_array.hpp
+-rw-r--r--   0        0        0     1293 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/vtk/matrix4x4.hpp
+-rw-r--r--   0        0        0     1841 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/vtk/points.hpp
+-rw-r--r--   0        0        0      762 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/vtk.hpp
+-rw-r--r--   0        0        0     8270 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/iterator/buffer_iterator.hpp
+-rw-r--r--   0        0        0     5576 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/iterator/constant_buffer_iterator.hpp
+-rw-r--r--   0        0        0     4244 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/iterator/constant_iterator.hpp
+-rw-r--r--   0        0        0     4602 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/iterator/counting_iterator.hpp
+-rw-r--r--   0        0        0     1674 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/iterator/detail/get_base_iterator_buffer.hpp
+-rw-r--r--   0        0        0     5888 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/iterator/detail/swizzle_iterator.hpp
+-rw-r--r--   0        0        0     3908 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/iterator/discard_iterator.hpp
+-rw-r--r--   0        0        0     4983 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/iterator/function_input_iterator.hpp
+-rw-r--r--   0        0        0     6313 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/iterator/permutation_iterator.hpp
+-rw-r--r--   0        0        0     9596 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/iterator/strided_iterator.hpp
+-rw-r--r--   0        0        0     7752 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/iterator/transform_iterator.hpp
+-rw-r--r--   0        0        0    10435 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/iterator/zip_iterator.hpp
+-rw-r--r--   0        0        0     1140 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/iterator.hpp
+-rw-r--r--   0        0        0    17580 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/kernel.hpp
+-rw-r--r--   0        0        0    10915 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/lambda/context.hpp
+-rw-r--r--   0        0        0    25023 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/lambda/functional.hpp
+-rw-r--r--   0        0        0     4225 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/lambda/get.hpp
+-rw-r--r--   0        0        0     2232 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/lambda/make_pair.hpp
+-rw-r--r--   0        0        0     4914 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/lambda/make_tuple.hpp
+-rw-r--r--   0        0        0      788 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/lambda/placeholder.hpp
+-rw-r--r--   0        0        0     2496 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/lambda/placeholders.hpp
+-rw-r--r--   0        0        0     4119 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/lambda/result_of.hpp
+-rw-r--r--   0        0        0      862 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/lambda.hpp
+-rw-r--r--   0        0        0     2252 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/memory/local_buffer.hpp
+-rw-r--r--   0        0        0     4446 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/memory/svm_ptr.hpp
+-rw-r--r--   0        0        0      717 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/memory.hpp
+-rw-r--r--   0        0        0     6994 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/memory_object.hpp
+-rw-r--r--   0        0        0     4008 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/pipe.hpp
+-rw-r--r--   0        0        0     7420 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/platform.hpp
+-rw-r--r--   0        0        0    25342 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/program.hpp
+-rw-r--r--   0        0        0     2968 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/random/bernoulli_distribution.hpp
+-rw-r--r--   0        0        0      801 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/random/default_random_engine.hpp
+-rw-r--r--   0        0        0     5397 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/random/discrete_distribution.hpp
+-rw-r--r--   0        0        0     7498 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/random/linear_congruential_engine.hpp
+-rw-r--r--   0        0        0     8288 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/random/mersenne_twister_engine.hpp
+-rw-r--r--   0        0        0     4642 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/random/normal_distribution.hpp
+-rw-r--r--   0        0        0    13937 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/random/threefry_engine.hpp
+-rw-r--r--   0        0        0     3598 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/random/uniform_int_distribution.hpp
+-rw-r--r--   0        0        0     3474 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/random/uniform_real_distribution.hpp
+-rw-r--r--   0        0        0     1148 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/random.hpp
+-rw-r--r--   0        0        0      551 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/source.hpp
+-rw-r--r--   0        0        0     1969 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/svm.hpp
+-rw-r--r--   0        0        0     9388 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/system.hpp
+-rw-r--r--   0        0        0     2198 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/type_traits/common_type.hpp
+-rw-r--r--   0        0        0      959 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/type_traits/detail/capture_traits.hpp
+-rw-r--r--   0        0        0     1351 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/type_traits/is_device_iterator.hpp
+-rw-r--r--   0        0        0     2558 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/type_traits/is_fundamental.hpp
+-rw-r--r--   0        0        0     1105 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/type_traits/is_vector_type.hpp
+-rw-r--r--   0        0        0     2344 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/type_traits/make_vector_type.hpp
+-rw-r--r--   0        0        0     1312 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/type_traits/result_of.hpp
+-rw-r--r--   0        0        0     2366 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/type_traits/scalar_type.hpp
+-rw-r--r--   0        0        0     1133 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/type_traits/type_definition.hpp
+-rw-r--r--   0        0        0     3709 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/type_traits/type_name.hpp
+-rw-r--r--   0        0        0     2193 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/type_traits/vector_size.hpp
+-rw-r--r--   0        0        0     1106 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/type_traits.hpp
+-rw-r--r--   0        0        0      557 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/types/builtin.hpp
+-rw-r--r--   0        0        0     4906 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/types/complex.hpp
+-rw-r--r--   0        0        0     5978 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/types/fundamental.hpp
+-rw-r--r--   0        0        0     3177 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/types/pair.hpp
+-rw-r--r--   0        0        0     1740 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/types/size_t.hpp
+-rw-r--r--   0        0        0     5713 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/types/struct.hpp
+-rw-r--r--   0        0        0     8803 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/types/tuple.hpp
+-rw-r--r--   0        0        0      870 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/types.hpp
+-rw-r--r--   0        0        0     2414 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/user_event.hpp
+-rw-r--r--   0        0        0     2186 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/utility/dim.hpp
+-rw-r--r--   0        0        0     3876 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/utility/extents.hpp
+-rw-r--r--   0        0        0     2786 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/utility/invoke.hpp
+-rw-r--r--   0        0        0     5493 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/utility/program_cache.hpp
+-rw-r--r--   0        0        0     1327 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/utility/source.hpp
+-rw-r--r--   0        0        0     5739 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/utility/wait_list.hpp
+-rw-r--r--   0        0        0      823 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/utility.hpp
+-rw-r--r--   0        0        0      665 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/version.hpp
+-rw-r--r--   0        0        0      557 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute/wait_list.hpp
+-rw-r--r--   0        0        0     1523 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/compute/include/boost/compute.hpp
+-rw-r--r--   0        0        0    24767 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/CMakeLists.txt
+-rw-r--r--   0        0        0     1161 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/Cholesky
+-rw-r--r--   0        0        0    12799 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/Core
+-rw-r--r--   0        0        0      122 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/Dense
+-rw-r--r--   0        0        0     1777 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/Eigenvalues
+-rw-r--r--   0        0        0     1940 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/Geometry
+-rw-r--r--   0        0        0      829 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/Householder
+-rw-r--r--   0        0        0      894 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/Jacobi
+-rw-r--r--   0        0        0     1268 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/LU
+-rw-r--r--   0        0        0     1272 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/QR
+-rw-r--r--   0        0        0     1584 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/SVD
+-rw-r--r--   0        0        0    24934 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Cholesky/LDLT.h
+-rw-r--r--   0        0        0    18760 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Cholesky/LLT.h
+-rw-r--r--   0        0        0     3974 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Cholesky/LLT_LAPACKE.h
+-rw-r--r--   0        0        0    19214 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/ArithmeticSequence.h
+-rw-r--r--   0        0        0    16782 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Array.h
+-rw-r--r--   0        0        0     8217 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/ArrayBase.h
+-rw-r--r--   0        0        0     7018 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/ArrayWrapper.h
+-rw-r--r--   0        0        0     2738 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Assign.h
+-rw-r--r--   0        0        0    41673 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/AssignEvaluator.h
+-rwxr-xr-x   0        0        0    12488 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Assign_MKL.h
+-rw-r--r--   0        0        0    14075 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/BandMatrix.h
+-rw-r--r--   0        0        0    18648 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Block.h
+-rw-r--r--   0        0        0     4429 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/BooleanRedux.h
+-rw-r--r--   0        0        0     5981 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/CommaInitializer.h
+-rw-r--r--   0        0        0     6990 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/ConditionEstimator.h
+-rw-r--r--   0        0        0    63841 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/CoreEvaluators.h
+-rw-r--r--   0        0        0     4745 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/CoreIterators.h
+-rw-r--r--   0        0        0     7909 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/CwiseBinaryOp.h
+-rw-r--r--   0        0        0    36282 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/CwiseNullaryOp.h
+-rw-r--r--   0        0        0     8256 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/CwiseTernaryOp.h
+-rw-r--r--   0        0        0     3937 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/CwiseUnaryOp.h
+-rw-r--r--   0        0        0     5551 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/CwiseUnaryView.h
+-rw-r--r--   0        0        0    31529 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/DenseBase.h
+-rw-r--r--   0        0        0    24484 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/DenseCoeffsBase.h
+-rw-r--r--   0        0        0    25360 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/DenseStorage.h
+-rw-r--r--   0        0        0     9870 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Diagonal.h
+-rw-r--r--   0        0        0    14670 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/DiagonalMatrix.h
+-rw-r--r--   0        0        0      988 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/DiagonalProduct.h
+-rw-r--r--   0        0        0    11654 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Dot.h
+-rw-r--r--   0        0        0     5841 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/EigenBase.h
+-rw-r--r--   0        0        0     4909 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/ForceAlignedAccess.h
+-rw-r--r--   0        0        0     5759 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Fuzzy.h
+-rw-r--r--   0        0        0    21679 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/GeneralProduct.h
+-rw-r--r--   0        0        0    38812 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/GenericPacketMath.h
+-rw-r--r--   0        0        0    11543 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/GlobalFunctions.h
+-rw-r--r--   0        0        0     8238 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/IO.h
+-rw-r--r--   0        0        0     9620 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/IndexedView.h
+-rw-r--r--   0        0        0     3503 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Inverse.h
+-rw-r--r--   0        0        0     7256 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Map.h
+-rw-r--r--   0        0        0    11281 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/MapBase.h
+-rw-r--r--   0        0        0    60784 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/MathFunctions.h
+-rw-r--r--   0        0        0     7156 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/MathFunctionsImpl.h
+-rw-r--r--   0        0        0    24343 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Matrix.h
+-rw-r--r--   0        0        0    23856 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/MatrixBase.h
+-rw-r--r--   0        0        0     2520 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/NestByValue.h
+-rw-r--r--   0        0        0     3620 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/NoAlias.h
+-rw-r--r--   0        0        0    12884 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/NumTraits.h
+-rw-r--r--   0        0        0     9207 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/PartialReduxEvaluator.h
+-rw-r--r--   0        0        0    20748 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/PermutationMatrix.h
+-rw-r--r--   0        0        0    49193 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/PlainObjectBase.h
+-rw-r--r--   0        0        0     7336 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Product.h
+-rw-r--r--   0        0        0    53832 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/ProductEvaluators.h
+-rw-r--r--   0        0        0     7756 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Random.h
+-rw-r--r--   0        0        0    19195 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Redux.h
+-rw-r--r--   0        0        0    17821 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Ref.h
+-rw-r--r--   0        0        0     5656 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Replicate.h
+-rw-r--r--   0        0        0    17033 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Reshaped.h
+-rw-r--r--   0        0        0     4284 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/ReturnByValue.h
+-rw-r--r--   0        0        0     7522 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Reverse.h
+-rw-r--r--   0        0        0     6143 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Select.h
+-rw-r--r--   0        0        0    14999 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/SelfAdjointView.h
+-rw-r--r--   0        0        0     1697 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/SelfCwiseBinaryOp.h
+-rw-r--r--   0        0        0     6837 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Solve.h
+-rw-r--r--   0        0        0     9368 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/SolveTriangular.h
+-rw-r--r--   0        0        0     6170 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/SolverBase.h
+-rw-r--r--   0        0        0     8700 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/StableNorm.h
+-rw-r--r--   0        0        0    21641 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/StlIterators.h
+-rw-r--r--   0        0        0     4212 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Stride.h
+-rw-r--r--   0        0        0     2765 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Swap.h
+-rw-r--r--   0        0        0    17606 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Transpose.h
+-rw-r--r--   0        0        0    13567 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Transpositions.h
+-rw-r--r--   0        0        0    38277 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/TriangularMatrix.h
+-rw-r--r--   0        0        0     3488 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/VectorBlock.h
+-rw-r--r--   0        0        0    35168 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/VectorwiseOp.h
+-rw-r--r--   0        0        0    11997 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Visitor.h
+-rw-r--r--   0        0        0    15223 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/AVX/Complex.h
+-rw-r--r--   0        0        0     8102 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/AVX/MathFunctions.h
+-rw-r--r--   0        0        0    64608 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/AVX/PacketMath.h
+-rw-r--r--   0        0        0     2564 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/AVX/TypeCasting.h
+-rw-r--r--   0        0        0    17160 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/AVX512/Complex.h
+-rw-r--r--   0        0        0    13344 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/AVX512/MathFunctions.h
+-rw-r--r--   0        0        0    87891 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/AVX512/PacketMath.h
+-rw-r--r--   0        0        0     2134 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/AVX512/TypeCasting.h
+-rw-r--r--   0        0        0    16540 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/AltiVec/Complex.h
+-rw-r--r--   0        0        0     2323 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/AltiVec/MathFunctions.h
+-rw-r--r--   0        0        0   119355 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/AltiVec/MatrixProduct.h
+-rw-r--r--   0        0        0     9490 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/AltiVec/MatrixProductCommon.h
+-rw-r--r--   0        0        0    24820 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/AltiVec/MatrixProductMMA.h
+-rwxr-xr-x   0        0        0   102394 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/AltiVec/PacketMath.h
+-rw-r--r--   0        0        0    17317 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/CUDA/Complex.h
+-rw-r--r--   0        0        0    26903 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/Default/BFloat16.h
+-rw-r--r--   0        0        0     5251 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/Default/ConjHelper.h
+-rw-r--r--   0        0        0    67696 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/Default/GenericPacketMathFunctions.h
+-rw-r--r--   0        0        0     3770 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/Default/GenericPacketMathFunctionsFwd.h
+-rw-r--r--   0        0        0    35534 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/Default/Half.h
+-rw-r--r--   0        0        0     1746 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/Default/Settings.h
+-rw-r--r--   0        0        0     3746 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/Default/TypeCasting.h
+-rw-r--r--   0        0        0     2695 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/GPU/MathFunctions.h
+-rw-r--r--   0        0        0    57047 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/GPU/PacketMath.h
+-rw-r--r--   0        0        0     2256 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/GPU/TypeCasting.h
+-rw-r--r--   0        0        0      691 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/HIP/hcc/math_constants.h
+-rw-r--r--   0        0        0    17541 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/MSA/Complex.h
+-rw-r--r--   0        0        0    16159 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/MSA/MathFunctions.h
+-rw-r--r--   0        0        0    33615 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/MSA/PacketMath.h
+-rw-r--r--   0        0        0    22503 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/NEON/Complex.h
+-rw-r--r--   0        0        0     6815 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/NEON/GeneralBlockPanelKernel.h
+-rw-r--r--   0        0        0     3083 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/NEON/MathFunctions.h
+-rw-r--r--   0        0        0   189525 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/NEON/PacketMath.h
+-rw-r--r--   0        0        0    51286 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/NEON/TypeCasting.h
+-rw-r--r--   0        0        0    14251 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/SSE/Complex.h
+-rw-r--r--   0        0        0     6765 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/SSE/MathFunctions.h
+-rwxr-xr-x   0        0        0    64465 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/SSE/PacketMath.h
+-rw-r--r--   0        0        0     3650 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/SSE/TypeCasting.h
+-rw-r--r--   0        0        0     1194 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/SVE/MathFunctions.h
+-rw-r--r--   0        0        0    21200 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/SVE/PacketMath.h
+-rw-r--r--   0        0        0     1351 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/SVE/TypeCasting.h
+-rw-r--r--   0        0        0     7428 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/SYCL/InteropHeaders.h
+-rw-r--r--   0        0        0    12539 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/SYCL/MathFunctions.h
+-rw-r--r--   0        0        0    27786 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/SYCL/PacketMath.h
+-rw-r--r--   0        0        0    21856 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/SYCL/SyclMemoryModel.h
+-rw-r--r--   0        0        0     2626 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/SYCL/TypeCasting.h
+-rw-r--r--   0        0        0    16728 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/ZVector/Complex.h
+-rw-r--r--   0        0        0     8024 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/ZVector/MathFunctions.h
+-rwxr-xr-x   0        0        0    36894 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/ZVector/PacketMath.h
+-rw-r--r--   0        0        0     6686 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/functors/AssignmentFunctors.h
+-rw-r--r--   0        0        0    20921 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/functors/BinaryFunctors.h
+-rw-r--r--   0        0        0     8334 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/functors/NullaryFunctors.h
+-rw-r--r--   0        0        0     4998 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/functors/StlFunctors.h
+-rw-r--r--   0        0        0      607 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/functors/TernaryFunctors.h
+-rw-r--r--   0        0        0    40146 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/functors/UnaryFunctors.h
+-rw-r--r--   0        0        0   108448 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/products/GeneralBlockPanelKernel.h
+-rw-r--r--   0        0        0    20104 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/products/GeneralMatrixMatrix.h
+-rw-r--r--   0        0        0    15948 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/products/GeneralMatrixMatrixTriangular.h
+-rw-r--r--   0        0        0     6936 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/products/GeneralMatrixMatrixTriangular_BLAS.h
+-rw-r--r--   0        0        0     5106 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/products/GeneralMatrixMatrix_BLAS.h
+-rw-r--r--   0        0        0    21724 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/products/GeneralMatrixVector.h
+-rw-r--r--   0        0        0     6368 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/products/GeneralMatrixVector_BLAS.h
+-rw-r--r--   0        0        0     5582 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/products/Parallelizer.h
+-rw-r--r--   0        0        0    21354 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/products/SelfadjointMatrixMatrix.h
+-rw-r--r--   0        0        0    11570 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/products/SelfadjointMatrixMatrix_BLAS.h
+-rw-r--r--   0        0        0     9958 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/products/SelfadjointMatrixVector.h
+-rw-r--r--   0        0        0     5209 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/products/SelfadjointMatrixVector_BLAS.h
+-rw-r--r--   0        0        0     6164 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/products/SelfadjointProduct.h
+-rw-r--r--   0        0        0     4126 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/products/SelfadjointRank2Update.h
+-rw-r--r--   0        0        0    20987 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/products/TriangularMatrixMatrix.h
+-rw-r--r--   0        0        0    13867 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/products/TriangularMatrixMatrix_BLAS.h
+-rw-r--r--   0        0        0    14722 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/products/TriangularMatrixVector.h
+-rw-r--r--   0        0        0    10571 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/products/TriangularMatrixVector_BLAS.h
+-rw-r--r--   0        0        0    14678 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/products/TriangularSolverMatrix.h
+-rw-r--r--   0        0        0     6707 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/products/TriangularSolverMatrix_BLAS.h
+-rw-r--r--   0        0        0     5882 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/products/TriangularSolverVector.h
+-rwxr-xr-x   0        0        0    23156 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/util/BlasUtil.h
+-rw-r--r--   0        0        0    19876 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/util/ConfigureVectorization.h
+-rw-r--r--   0        0        0    21931 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/util/Constants.h
+-rwxr-xr-x   0        0        0     4892 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/util/DisableStupidWarnings.h
+-rw-r--r--   0        0        0    15555 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/util/ForwardDeclarations.h
+-rw-r--r--   0        0        0     6696 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/util/IndexedViewHelper.h
+-rw-r--r--   0        0        0    10949 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/util/IntegralConstant.h
+-rwxr-xr-x   0        0        0     4268 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/util/MKL_support.h
+-rw-r--r--   0        0        0    52909 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/util/Macros.h
+-rw-r--r--   0        0        0    46661 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/util/Memory.h
+-rwxr-xr-x   0        0        0    29336 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/util/Meta.h
+-rw-r--r--   0        0        0       85 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/util/NonMPL2.h
+-rw-r--r--   0        0        0     1024 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/util/ReenableStupidWarnings.h
+-rw-r--r--   0        0        0     1432 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/util/ReshapedHelper.h
+-rw-r--r--   0        0        0    10676 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/util/StaticAssert.h
+-rw-r--r--   0        0        0    12003 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/util/SymbolicIndex.h
+-rw-r--r--   0        0        0    35762 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/util/XprHelper.h
+-rw-r--r--   0        0        0    12559 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Eigenvalues/ComplexEigenSolver.h
+-rw-r--r--   0        0        0    17274 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Eigenvalues/ComplexSchur.h
+-rw-r--r--   0        0        0     4178 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Eigenvalues/ComplexSchur_LAPACKE.h
+-rw-r--r--   0        0        0    22970 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Eigenvalues/EigenSolver.h
+-rw-r--r--   0        0        0    17176 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Eigenvalues/GeneralizedEigenSolver.h
+-rw-r--r--   0        0        0     9716 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Eigenvalues/GeneralizedSelfAdjointEigenSolver.h
+-rw-r--r--   0        0        0    14349 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Eigenvalues/HessenbergDecomposition.h
+-rw-r--r--   0        0        0     5575 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Eigenvalues/MatrixBaseEigenvalues.h
+-rw-r--r--   0        0        0    23640 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Eigenvalues/RealQZ.h
+-rw-r--r--   0        0        0    21078 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Eigenvalues/RealSchur.h
+-rw-r--r--   0        0        0     3650 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Eigenvalues/RealSchur_LAPACKE.h
+-rw-r--r--   0        0        0    35182 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h
+-rw-r--r--   0        0        0     4104 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Eigenvalues/SelfAdjointEigenSolver_LAPACKE.h
+-rw-r--r--   0        0        0    22764 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Eigenvalues/Tridiagonalization.h
+-rw-r--r--   0        0        0    18939 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Geometry/AlignedBox.h
+-rw-r--r--   0        0        0     8403 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Geometry/AngleAxis.h
+-rw-r--r--   0        0        0     3624 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Geometry/EulerAngles.h
+-rw-r--r--   0        0        0    20726 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Geometry/Homogeneous.h
+-rw-r--r--   0        0        0    11962 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Geometry/Hyperplane.h
+-rw-r--r--   0        0        0     8955 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Geometry/OrthoMethods.h
+-rw-r--r--   0        0        0     9812 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Geometry/ParametrizedLine.h
+-rw-r--r--   0        0        0    34367 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Geometry/Quaternion.h
+-rw-r--r--   0        0        0     6862 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Geometry/Rotation2D.h
+-rw-r--r--   0        0        0     8063 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Geometry/RotationBase.h
+-rw-r--r--   0        0        0     6724 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Geometry/Scaling.h
+-rw-r--r--   0        0        0    61930 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Geometry/Transform.h
+-rw-r--r--   0        0        0     7664 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Geometry/Translation.h
+-rw-r--r--   0        0        0     6190 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Geometry/Umeyama.h
+-rw-r--r--   0        0        0     5945 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Geometry/arch/Geometry_SIMD.h
+-rw-r--r--   0        0        0     4784 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Householder/BlockHouseholder.h
+-rw-r--r--   0        0        0     5365 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Householder/Householder.h
+-rw-r--r--   0        0        0    23611 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Householder/HouseholderSequence.h
+-rw-r--r--   0        0        0    16383 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/Jacobi/Jacobi.h
+-rw-r--r--   0        0        0     3439 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/LU/Determinant.h
+-rw-r--r--   0        0        0    32383 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/LU/FullPivLU.h
+-rw-r--r--   0        0        0    15727 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/LU/InverseImpl.h
+-rw-r--r--   0        0        0    22069 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/LU/PartialPivLU.h
+-rw-r--r--   0        0        0     3555 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/LU/PartialPivLU_LAPACKE.h
+-rw-r--r--   0        0        0    13693 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/LU/arch/InverseSize4.h
+-rw-r--r--   0        0        0    25498 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/QR/ColPivHouseholderQR.h
+-rw-r--r--   0        0        0     4662 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/QR/ColPivHouseholderQR_LAPACKE.h
+-rw-r--r--   0        0        0    23429 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/QR/CompleteOrthogonalDecomposition.h
+-rw-r--r--   0        0        0    26768 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/QR/FullPivHouseholderQR.h
+-rw-r--r--   0        0        0    14641 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/QR/HouseholderQR.h
+-rw-r--r--   0        0        0     2993 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/QR/HouseholderQR_LAPACKE.h
+-rw-r--r--   0        0        0    54214 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/SVD/BDCSVD.h
+-rw-r--r--   0        0        0    32988 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/SVD/JacobiSVD.h
+-rw-r--r--   0        0        0     5099 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/SVD/JacobiSVD_LAPACKE.h
+-rw-r--r--   0        0        0    14743 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/SVD/SVDBase.h
+-rw-r--r--   0        0        0    15957 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/SVD/UpperBidiagonalization.h
+-rw-r--r--   0        0        0     2913 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/misc/Image.h
+-rw-r--r--   0        0        0     2742 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/misc/Kernel.h
+-rw-r--r--   0        0        0     1748 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/misc/RealSvd2x2.h
+-rw-r--r--   0        0        0    30560 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/misc/blas.h
+-rw-r--r--   0        0        0     7834 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/misc/lapack.h
+-rwxr-xr-x   0        0        0  1058369 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/misc/lapacke.h
+-rw-r--r--   0        0        0      474 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/misc/lapacke_mangling.h
+-rw-r--r--   0        0        0    14060 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/plugins/ArrayCwiseBinaryOps.h
+-rw-r--r--   0        0        0    21431 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/plugins/ArrayCwiseUnaryOps.h
+-rw-r--r--   0        0        0    59020 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/plugins/BlockMethods.h
+-rw-r--r--   0        0        0     4828 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/plugins/CommonCwiseBinaryOps.h
+-rw-r--r--   0        0        0     6089 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/plugins/CommonCwiseUnaryOps.h
+-rw-r--r--   0        0        0    12283 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/plugins/IndexedViewMethods.h
+-rw-r--r--   0        0        0     6387 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/plugins/MatrixCwiseBinaryOps.h
+-rw-r--r--   0        0        0     3350 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/plugins/MatrixCwiseUnaryOps.h
+-rw-r--r--   0        0        0     6915 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/eigen/Eigen/src/plugins/ReshapedMethods.h
+-rw-r--r--   0        0        0     2591 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/fast_double_parser/CMakeLists.txt
+-rw-r--r--   0        0        0    11343 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/fast_double_parser/LICENSE
+-rw-r--r--   0        0        0     1367 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/fast_double_parser/LICENSE.BSL
+-rw-r--r--   0        0        0    49482 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/fast_double_parser/include/fast_double_parser.h
+-rw-r--r--   0        0        0     2591 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/fmt/CMakeLists.txt
+-rw-r--r--   0        0        0     1408 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/fmt/LICENSE.rst
+-rw-r--r--   0        0        0     7518 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/fmt/include/fmt/args.h
+-rw-r--r--   0        0        0    67575 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/fmt/include/fmt/chrono.h
+-rw-r--r--   0        0        0    24610 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/fmt/include/fmt/color.h
+-rw-r--r--   0        0        0    21753 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/fmt/include/fmt/compile.h
+-rw-r--r--   0        0        0   107187 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/fmt/include/fmt/core.h
+-rw-r--r--   0        0        0   104940 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/fmt/include/fmt/format-inl.h
+-rw-r--r--   0        0        0   113399 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/fmt/include/fmt/format.h
+-rw-r--r--   0        0        0      100 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/fmt/include/fmt/locale.h
+-rw-r--r--   0        0        0    15566 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/fmt/include/fmt/os.h
+-rw-r--r--   0        0        0     4378 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/fmt/include/fmt/ostream.h
+-rw-r--r--   0        0        0    20707 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/fmt/include/fmt/printf.h
+-rw-r--r--   0        0        0    29679 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/fmt/include/fmt/ranges.h
+-rw-r--r--   0        0        0     9241 2022-11-09 12:37:21.000000 lightgbm-4.0.0/external_libs/fmt/include/fmt/xchar.h
+-rw-r--r--   0        0        0     2350 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/application.h
+-rw-r--r--   0        0        0    24653 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/bin.h
+-rw-r--r--   0        0        0    11034 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/boosting.h
+-rw-r--r--   0        0        0    80340 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/c_api.h
+-rw-r--r--   0        0        0    69254 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/config.h
+-rw-r--r--   0        0        0    25617 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/cuda/cuda_algorithms.hpp
+-rw-r--r--   0        0        0     5452 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/cuda/cuda_column_data.hpp
+-rw-r--r--   0        0        0     1571 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/cuda/cuda_metadata.hpp
+-rw-r--r--   0        0        0     1004 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/cuda/cuda_metric.hpp
+-rw-r--r--   0        0        0     2954 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/cuda/cuda_objective_function.hpp
+-rw-r--r--   0        0        0     1805 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/cuda/cuda_random.hpp
+-rw-r--r--   0        0        0     6792 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/cuda/cuda_row_data.hpp
+-rw-r--r--   0        0        0     2720 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/cuda/cuda_split_info.hpp
+-rw-r--r--   0        0        0     5397 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/cuda/cuda_tree.hpp
+-rw-r--r--   0        0        0     6107 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/cuda/cuda_utils.h
+-rw-r--r--   0        0        0     2457 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/cuda/vector_cudahost.h
+-rw-r--r--   0        0        0    35436 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/dataset.h
+-rw-r--r--   0        0        0     4754 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/dataset_loader.h
+-rw-r--r--   0        0        0      623 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/export.h
+-rw-r--r--   0        0        0    22758 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/feature_group.h
+-rw-r--r--   0        0        0     2829 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/meta.h
+-rw-r--r--   0        0        0     4084 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/metric.h
+-rw-r--r--   0        0        0    11959 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/network.h
+-rw-r--r--   0        0        0     3645 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/objective_function.h
+-rw-r--r--   0        0        0     1276 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/prediction_early_stop.h
+-rw-r--r--   0        0        0     2741 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/sample_strategy.h
+-rw-r--r--   0        0        0    14424 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/train_share_states.h
+-rw-r--r--   0        0        0    26490 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/tree.h
+-rw-r--r--   0        0        0     4043 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/tree_learner.h
+-rw-r--r--   0        0        0     4946 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/utils/array_args.h
+-rw-r--r--   0        0        0     1780 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/utils/binary_writer.h
+-rw-r--r--   0        0        0     1352 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/utils/byte_buffer.h
+-rw-r--r--   0        0        0     8431 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/utils/chunked_array.hpp
+-rw-r--r--   0        0        0    33736 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/utils/common.h
+-rw-r--r--   0        0        0     1950 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/utils/file_io.h
+-rw-r--r--   0        0        0     9042 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/utils/json11.h
+-rw-r--r--   0        0        0     4472 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/utils/log.h
+-rw-r--r--   0        0        0     3168 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/utils/openmp_wrapper.h
+-rw-r--r--   0        0        0     2099 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/utils/pipeline_reader.h
+-rw-r--r--   0        0        0     2912 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/utils/random.h
+-rw-r--r--   0        0        0    11653 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/utils/text_reader.h
+-rw-r--r--   0        0        0     6595 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/utils/threading.h
+-rw-r--r--   0        0        0     6249 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/utils/yamc/alternate_shared_mutex.hpp
+-rw-r--r--   0        0        0     4343 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/utils/yamc/yamc_rwlock_sched.hpp
+-rw-r--r--   0        0        0     5050 2022-11-09 12:37:21.000000 lightgbm-4.0.0/include/LightGBM/utils/yamc/yamc_shared_lock.hpp
+-rw-r--r--   0        0        0        6 2022-11-09 12:37:21.000000 lightgbm-4.0.0/lightgbm/VERSION.txt
+-rw-r--r--   0        0        0     1352 2022-11-09 12:37:21.000000 lightgbm-4.0.0/lightgbm/__init__.py
+-rw-r--r--   0        0        0   187217 2022-11-09 12:37:21.000000 lightgbm-4.0.0/lightgbm/basic.py
+-rw-r--r--   0        0        0    17491 2022-11-09 12:37:21.000000 lightgbm-4.0.0/lightgbm/callback.py
+-rw-r--r--   0        0        0     6190 2022-11-09 12:37:21.000000 lightgbm-4.0.0/lightgbm/compat.py
+-rw-r--r--   0        0        0    67569 2022-11-09 12:37:21.000000 lightgbm-4.0.0/lightgbm/dask.py
+-rw-r--r--   0        0        0    34497 2022-11-09 12:37:21.000000 lightgbm-4.0.0/lightgbm/engine.py
+-rw-r--r--   0        0        0     1132 2022-11-09 12:37:21.000000 lightgbm-4.0.0/lightgbm/libpath.py
+-rw-r--r--   0        0        0    32450 2022-11-09 12:37:21.000000 lightgbm-4.0.0/lightgbm/plotting.py
+-rw-r--r--   0        0        0        0 2022-11-09 12:37:21.000000 lightgbm-4.0.0/lightgbm/py.typed
+-rw-r--r--   0        0        0    61909 2022-11-09 12:37:21.000000 lightgbm-4.0.0/lightgbm/sklearn.py
+-rw-r--r--   0        0        0     2914 2022-11-09 12:37:21.000000 lightgbm-4.0.0/pyproject.toml
+-rw-r--r--   0        0        0      314 2022-11-09 12:37:21.000000 lightgbm-4.0.0/setup.cfg
+-rw-r--r--   0        0        0    10628 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/application/application.cpp
+-rw-r--r--   0        0        0    12394 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/application/predictor.hpp
+-rw-r--r--   0        0        0     7957 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/boosting/bagging.hpp
+-rw-r--r--   0        0        0     2209 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/boosting/boosting.cpp
+-rw-r--r--   0        0        0     4069 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/boosting/cuda/cuda_score_updater.cpp
+-rw-r--r--   0        0        0     1479 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/boosting/cuda/cuda_score_updater.cu
+-rw-r--r--   0        0        0     1740 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/boosting/cuda/cuda_score_updater.hpp
+-rw-r--r--   0        0        0     7393 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/boosting/dart.hpp
+-rw-r--r--   0        0        0    34702 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/boosting/gbdt.cpp
+-rw-r--r--   0        0        0    21496 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/boosting/gbdt.h
+-rw-r--r--   0        0        0    24758 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/boosting/gbdt_model_text.cpp
+-rw-r--r--   0        0        0     3749 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/boosting/gbdt_prediction.cpp
+-rw-r--r--   0        0        0     6545 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/boosting/goss.hpp
+-rw-r--r--   0        0        0     2552 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/boosting/prediction_early_stop.cpp
+-rw-r--r--   0        0        0     8753 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/boosting/rf.hpp
+-rw-r--r--   0        0        0      741 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/boosting/sample_strategy.cpp
+-rw-r--r--   0        0        0     5045 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/boosting/score_updater.hpp
+-rw-r--r--   0        0        0   108586 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/c_api.cpp
+-rw-r--r--   0        0        0    25873 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/cuda/cuda_algorithms.cu
+-rw-r--r--   0        0        0      809 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/cuda/cuda_utils.cpp
+-rw-r--r--   0        0        0    39311 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/io/bin.cpp
+-rw-r--r--   0        0        0    19382 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/io/config.cpp
+-rw-r--r--   0        0        0    37762 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/io/config_auto.cpp
+-rw-r--r--   0        0        0    16111 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/io/cuda/cuda_column_data.cpp
+-rw-r--r--   0        0        0     2673 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/io/cuda/cuda_column_data.cu
+-rw-r--r--   0        0        0     3794 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/io/cuda/cuda_metadata.cpp
+-rw-r--r--   0        0        0    22863 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/io/cuda/cuda_row_data.cpp
+-rw-r--r--   0        0        0    16368 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/io/cuda/cuda_tree.cpp
+-rw-r--r--   0        0        0    17477 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/io/cuda/cuda_tree.cu
+-rw-r--r--   0        0        0    75094 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/io/dataset.cpp
+-rw-r--r--   0        0        0    69232 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/io/dataset_loader.cpp
+-rw-r--r--   0        0        0    25327 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/io/dense_bin.hpp
+-rw-r--r--   0        0        0     5430 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/io/file_io.cpp
+-rw-r--r--   0        0        0    22466 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/io/json11.cpp
+-rw-r--r--   0        0        0    25391 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/io/metadata.cpp
+-rw-r--r--   0        0        0    14711 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/io/multi_val_dense_bin.hpp
+-rw-r--r--   0        0        0    18570 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/io/multi_val_sparse_bin.hpp
+-rw-r--r--   0        0        0    10450 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/io/parser.cpp
+-rw-r--r--   0        0        0     3628 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/io/parser.hpp
+-rw-r--r--   0        0        0    31919 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/io/sparse_bin.hpp
+-rw-r--r--   0        0        0    22558 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/io/train_share_states.cpp
+-rw-r--r--   0        0        0    42526 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/io/tree.cpp
+-rw-r--r--   0        0        0      912 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/main.cpp
+-rw-r--r--   0        0        0    11420 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/metric/binary_metric.hpp
+-rw-r--r--   0        0        0     1196 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/metric/cuda/cuda_binary_metric.cpp
+-rw-r--r--   0        0        0     1626 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/metric/cuda/cuda_binary_metric.hpp
+-rw-r--r--   0        0        0     2790 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/metric/cuda/cuda_pointwise_metric.cpp
+-rw-r--r--   0        0        0     4921 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/metric/cuda/cuda_pointwise_metric.cu
+-rw-r--r--   0        0        0     1313 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/metric/cuda/cuda_pointwise_metric.hpp
+-rw-r--r--   0        0        0     2673 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/metric/cuda/cuda_regression_metric.cpp
+-rw-r--r--   0        0        0     6320 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/metric/cuda/cuda_regression_metric.hpp
+-rw-r--r--   0        0        0     5511 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/metric/dcg_calculator.cpp
+-rw-r--r--   0        0        0     5516 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/metric/map_metric.hpp
+-rw-r--r--   0        0        0     6293 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/metric/metric.cpp
+-rw-r--r--   0        0        0    13197 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/metric/multiclass_metric.hpp
+-rw-r--r--   0        0        0     6040 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/metric/rank_metric.hpp
+-rw-r--r--   0        0        0     9578 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/metric/regression_metric.hpp
+-rw-r--r--   0        0        0    13050 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/metric/xentropy_metric.hpp
+-rw-r--r--   0        0        0     6271 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/network/linker_topo.cpp
+-rw-r--r--   0        0        0     9003 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/network/linkers.h
+-rw-r--r--   0        0        0     1840 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/network/linkers_mpi.cpp
+-rw-r--r--   0        0        0     7666 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/network/linkers_socket.cpp
+-rw-r--r--   0        0        0    13775 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/network/network.cpp
+-rw-r--r--   0        0        0     8818 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/network/socket_wrapper.hpp
+-rw-r--r--   0        0        0     7533 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/objective/binary_objective.hpp
+-rw-r--r--   0        0        0     2447 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/objective/cuda/cuda_binary_objective.cpp
+-rw-r--r--   0        0        0     9248 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/objective/cuda/cuda_binary_objective.cu
+-rw-r--r--   0        0        0     1773 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/objective/cuda/cuda_binary_objective.hpp
+-rw-r--r--   0        0        0     2157 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/objective/cuda/cuda_multiclass_objective.cpp
+-rw-r--r--   0        0        0     4572 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/objective/cuda/cuda_multiclass_objective.cu
+-rw-r--r--   0        0        0     2328 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/objective/cuda/cuda_multiclass_objective.hpp
+-rw-r--r--   0        0        0     2430 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/objective/cuda/cuda_rank_objective.cpp
+-rw-r--r--   0        0        0    34265 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/objective/cuda/cuda_rank_objective.cu
+-rw-r--r--   0        0        0     4041 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/objective/cuda/cuda_rank_objective.hpp
+-rw-r--r--   0        0        0     4412 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/objective/cuda/cuda_regression_objective.cpp
+-rw-r--r--   0        0        0    24300 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/objective/cuda/cuda_regression_objective.cu
+-rw-r--r--   0        0        0     5711 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/objective/cuda/cuda_regression_objective.hpp
+-rw-r--r--   0        0        0     8917 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/objective/multiclass_objective.hpp
+-rw-r--r--   0        0        0     6671 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/objective/objective_function.cpp
+-rw-r--r--   0        0        0    13100 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/objective/rank_objective.hpp
+-rw-r--r--   0        0        0    27714 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/objective/regression_objective.hpp
+-rw-r--r--   0        0        0     9806 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/objective/xentropy_objective.hpp
+-rw-r--r--   0        0        0     7799 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/treelearner/col_sampler.hpp
+-rw-r--r--   0        0        0     6443 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/treelearner/cost_effective_gradient_boosting.hpp
+-rw-r--r--   0        0        0    18992 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/treelearner/cuda/cuda_best_split_finder.cpp
+-rw-r--r--   0        0        0    82872 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/treelearner/cuda/cuda_best_split_finder.cu
+-rw-r--r--   0        0        0     7026 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/treelearner/cuda/cuda_best_split_finder.hpp
+-rw-r--r--   0        0        0    17372 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/treelearner/cuda/cuda_data_partition.cpp
+-rw-r--r--   0        0        0    52024 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/treelearner/cuda/cuda_data_partition.cu
+-rw-r--r--   0        0        0    13487 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/treelearner/cuda/cuda_data_partition.hpp
+-rw-r--r--   0        0        0     9426 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/treelearner/cuda/cuda_histogram_constructor.cpp
+-rw-r--r--   0        0        0    23645 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/treelearner/cuda/cuda_histogram_constructor.cu
+-rw-r--r--   0        0        0     5947 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/treelearner/cuda/cuda_histogram_constructor.hpp
+-rw-r--r--   0        0        0     3168 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/treelearner/cuda/cuda_leaf_splits.cpp
+-rw-r--r--   0        0        0     5361 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/treelearner/cuda/cuda_leaf_splits.cu
+-rw-r--r--   0        0        0     5372 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/treelearner/cuda/cuda_leaf_splits.hpp
+-rw-r--r--   0        0        0    25512 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/treelearner/cuda/cuda_single_gpu_tree_learner.cpp
+-rw-r--r--   0        0        0    12282 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/treelearner/cuda/cuda_single_gpu_tree_learner.cu
+-rw-r--r--   0        0        0     5606 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/treelearner/cuda/cuda_single_gpu_tree_learner.hpp
+-rw-r--r--   0        0        0    24028 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/treelearner/data_parallel_tree_learner.cpp
+-rw-r--r--   0        0        0     5661 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/treelearner/data_partition.hpp
+-rw-r--r--   0        0        0    80130 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/treelearner/feature_histogram.hpp
+-rw-r--r--   0        0        0     3491 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/treelearner/feature_parallel_tree_learner.cpp
+-rw-r--r--   0        0        0    54389 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/treelearner/gpu_tree_learner.cpp
+-rw-r--r--   0        0        0    11519 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/treelearner/gpu_tree_learner.h
+-rw-r--r--   0        0        0    12461 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/treelearner/gradient_discretizer.cpp
+-rw-r--r--   0        0        0     3807 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/treelearner/gradient_discretizer.hpp
+-rw-r--r--   0        0        0    36852 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/treelearner/kernels/histogram_16_64_256.cu
+-rw-r--r--   0        0        0     5394 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/treelearner/kernels/histogram_16_64_256.hu
+-rw-r--r--   0        0        0     9515 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/treelearner/leaf_splits.hpp
+-rw-r--r--   0        0        0    14658 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/treelearner/linear_tree_learner.cpp
+-rw-r--r--   0        0        0     4713 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/treelearner/linear_tree_learner.h
+-rw-r--r--   0        0        0    47828 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/treelearner/monotone_constraints.hpp
+-rw-r--r--   0        0        0    42125 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/treelearner/ocl/histogram16.cl
+-rw-r--r--   0        0        0    33354 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/treelearner/ocl/histogram256.cl
+-rw-r--r--   0        0        0    34081 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/treelearner/ocl/histogram64.cl
+-rw-r--r--   0        0        0     9454 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/treelearner/parallel_tree_learner.h
+-rw-r--r--   0        0        0    45902 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/treelearner/serial_tree_learner.cpp
+-rw-r--r--   0        0        0     9711 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/treelearner/serial_tree_learner.h
+-rw-r--r--   0        0        0    10049 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/treelearner/split_info.hpp
+-rw-r--r--   0        0        0     2228 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/treelearner/tree_learner.cpp
+-rw-r--r--   0        0        0    24349 2022-11-09 12:37:21.000000 lightgbm-4.0.0/src/treelearner/voting_parallel_tree_learner.cpp
+-rw-r--r--   0        0        0      785 2022-11-09 12:37:21.000000 lightgbm-4.0.0/swig/ChunkedArray_API_extensions.i
+-rw-r--r--   0        0        0     4101 2022-11-09 12:37:21.000000 lightgbm-4.0.0/swig/StringArray.hpp
+-rw-r--r--   0        0        0     3163 2022-11-09 12:37:21.000000 lightgbm-4.0.0/swig/StringArray.i
+-rw-r--r--   0        0        0     5748 2022-11-09 12:37:21.000000 lightgbm-4.0.0/swig/StringArray_API_extensions.i
+-rw-r--r--   0        0        0    12437 2022-11-09 12:37:21.000000 lightgbm-4.0.0/swig/lightgbmlib.i
+-rw-r--r--   0        0        0     4070 2022-11-09 12:37:21.000000 lightgbm-4.0.0/swig/pointer_manipulation.i
+-rw-r--r--   0        0        0     1653 2022-11-09 12:37:21.000000 lightgbm-4.0.0/windows/LightGBM.sln
+-rw-r--r--   0        0        0    19129 2022-11-09 12:37:21.000000 lightgbm-4.0.0/windows/LightGBM.vcxproj
+-rw-r--r--   0        0        0    13437 2022-11-09 12:37:21.000000 lightgbm-4.0.0/windows/LightGBM.vcxproj.filters
+-rw-r--r--   0        0        0    19310 2022-11-09 12:37:21.000000 lightgbm-4.0.0/PKG-INFO
```

### filetype from file(1)

```diff
@@ -1 +1 @@
-POSIX tar archive (GNU)
+POSIX tar archive
```

### Comparing `lightgbm-3.3.5/LICENSE` & `lightgbm-4.0.0/LICENSE`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/PKG-INFO` & `lightgbm-4.0.0/README.rst`

 * *Files 9% similar despite different names*

```diff
@@ -1,32 +1,7 @@
-Metadata-Version: 2.1
-Name: lightgbm
-Version: 3.3.5
-Summary: LightGBM Python Package
-Home-page: https://github.com/microsoft/LightGBM
-Maintainer: Yu Shi
-Maintainer-email: yushi2@microsoft.com
-License: The MIT License (Microsoft)
-Platform: UNKNOWN
-Classifier: Development Status :: 5 - Production/Stable
-Classifier: Intended Audience :: Science/Research
-Classifier: License :: OSI Approved :: MIT License
-Classifier: Natural Language :: English
-Classifier: Operating System :: MacOS
-Classifier: Operating System :: Microsoft :: Windows
-Classifier: Operating System :: POSIX
-Classifier: Operating System :: Unix
-Classifier: Programming Language :: Python :: 3
-Classifier: Programming Language :: Python :: 3.6
-Classifier: Programming Language :: Python :: 3.7
-Classifier: Programming Language :: Python :: 3.8
-Classifier: Programming Language :: Python :: 3.9
-Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
-Provides-Extra: dask
-
 LightGBM Python-package
 =======================
 
 |License| |Python Versions| |PyPI Version| |Downloads| |API Docs|
 
 Installation
 ------------
@@ -41,158 +16,208 @@
 Install from `PyPI <https://pypi.org/project/lightgbm>`_
 ''''''''''''''''''''''''''''''''''''''''''''''''''''''''
 
 .. code:: sh
 
     pip install lightgbm
 
-You may need to install `wheel <https://pythonwheels.com>`_ via ``pip install wheel`` first.
-
-Compiled library that is included in the wheel file supports both **GPU** and **CPU** versions out of the box. This feature is experimental and available only for **Windows** currently. To use **GPU** version you only need to install OpenCL Runtime libraries. For NVIDIA and AMD GPU they are included in the ordinary drivers for your graphics card, so no action is required. If you would like your AMD or Intel CPU to act like a GPU (for testing and debugging) you can install `AMD APP SDK <https://github.com/microsoft/LightGBM/releases/download/v2.0.12/AMD-APP-SDKInstaller-v3.0.130.135-GA-windows-F-x64.exe>`_.
+Compiled library that is included in the wheel file supports both **GPU** and **CPU** versions out of the box. This feature is experimental and available only for **Windows** and **Linux** currently. To use **GPU** version you only need to install OpenCL Runtime libraries. For NVIDIA and AMD GPU they are included in the ordinary drivers for your graphics card, so no action is required. If you would like your AMD or Intel CPU to act like a GPU (for testing and debugging) you can install `AMD APP SDK <https://github.com/microsoft/LightGBM/releases/download/v2.0.12/AMD-APP-SDKInstaller-v3.0.130.135-GA-windows-F-x64.exe>`_ on **Windows** and `PoCL <http://portablecl.org>`_ on **Linux**. Many modern Linux distributions provide packages for PoCL, look for ``pocl-opencl-icd`` on Debian-based distributions and ``pocl`` on RedHat-based distributions.
 
 For **Windows** users, `VC runtime <https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads>`_ is needed if **Visual Studio** (2015 or newer) is not installed.
 
-For **Linux** users, **glibc** >= 2.14 is required. Also, in some rare cases, when you hit ``OSError: libgomp.so.1: cannot open shared object file: No such file or directory`` error during importing LightGBM, you need to install OpenMP runtime library separately (use your package manager and search for ``lib[g|i]omp`` for doing this).
+For **Linux** users, **glibc** >= 2.14 is required for LightGBM ``<=3.3.3`` and **glibc** >= 2.28 is required for newer versions. Also, in some rare cases, when you hit ``OSError: libgomp.so.1: cannot open shared object file: No such file or directory`` error during importing LightGBM, you need to install OpenMP runtime library separately (use your package manager and search for ``lib[g|i]omp`` for doing this).
 
 For **macOS** (we provide wheels for 3 newest macOS versions) users:
 
-- Starting from version 2.2.1, the library file in distribution wheels is built by the **Apple Clang** (Xcode_8.3.3 for versions 2.2.1 - 2.3.1, and Xcode_9.4.1 from version 2.3.2) compiler. This means that you don't need to install the **gcc** compiler anymore. Instead of that you need to install the **OpenMP** library, which is required for running LightGBM on the system with the **Apple Clang** compiler. You can install the **OpenMP** library by the following command: ``brew install libomp``.
+- Starting from version 2.2.1, the library file in distribution wheels is built by the **Apple Clang** (Xcode_8.3.3 for versions 2.2.1 - 2.3.1, Xcode_9.4.1 for versions 2.3.2 - 3.3.2 and Xcode_11.7 from version 4.0.0) compiler. This means that you don't need to install the **gcc** compiler anymore. Instead of that you need to install the **OpenMP** library, which is required for running LightGBM on the system with the **Apple Clang** compiler. You can install the **OpenMP** library by the following command: ``brew install libomp``.
 
 - For version smaller than 2.2.1 and not smaller than 2.1.2, **gcc-8** with **OpenMP** support must be installed first. Refer to `Installation Guide <https://github.com/microsoft/LightGBM/blob/master/docs/Installation-Guide.rst#gcc>`__ for installation of **gcc-8** with **OpenMP** support.
 
 - For version smaller than 2.1.2, **gcc-7** with **OpenMP** is required.
 
+Use LightGBM with Dask
+**********************
+
+.. warning::
+
+    Dask-package is only tested on Linux.
+
+To install all dependencies needed to use ``lightgbm.dask``, append ``[dask]``.
+
+.. code:: sh
+
+    pip install 'lightgbm[dask]'
+
+Use LightGBM with pandas
+************************
+
+To install all dependencies needed to use ``pandas`` in LightGBM, append ``[pandas]``.
+
+.. code:: sh
+
+    pip install 'lightgbm[pandas]'
+
+Use LightGBM with scikit-learn
+******************************
+
+To install all dependencies needed to use ``scikit-learn`` in LightGBM, append ``[scikit-learn]``.
+
+.. code:: sh
+
+    pip install 'lightgbm[scikit-learn]'
+
 Build from Sources
 ******************
 
 .. code:: sh
 
-    pip install --no-binary :all: lightgbm
+    pip install --no-binary lightgbm lightgbm
 
 For **Linux** and **macOS** users, installation from sources requires installed `CMake`_.
 
-For **Linux** users, **glibc** >= 2.14 is required. Also, in some rare cases you may need to install OpenMP runtime library separately (use your package manager and search for ``lib[g|i]omp`` for doing this).
+For **Linux** users, **glibc** >= 2.28 is required. Also, in some rare cases you may need to install OpenMP runtime library separately (use your package manager and search for ``lib[g|i]omp`` for doing this).
 
 For **macOS** users, you can perform installation either with **Apple Clang** or **gcc**.
 
 - In case you prefer **Apple Clang**, you should install **OpenMP** (details for installation can be found in `Installation Guide <https://github.com/microsoft/LightGBM/blob/master/docs/Installation-Guide.rst#apple-clang>`__) first and **CMake** version 3.16 or higher is required.
 
 - In case you prefer **gcc**, you need to install it (details for installation can be found in `Installation Guide <https://github.com/microsoft/LightGBM/blob/master/docs/Installation-Guide.rst#gcc>`__) and specify compilers by running ``export CXX=g++-7 CC=gcc-7`` (replace "7" with version of **gcc** installed on your machine) first.
 
 For **Windows** users, **Visual Studio** (or `VS Build Tools <https://visualstudio.microsoft.com/downloads/>`_) is needed. If you get any errors during installation, you may need to install `CMake`_ (version 3.8 or higher).
 
 Build Threadless Version
 ~~~~~~~~~~~~~~~~~~~~~~~~
 
 .. code:: sh
 
-    pip install lightgbm --install-option=--nomp
+    pip install lightgbm --config-settings=cmake.define.USE_OPENMP=OFF
 
 All requirements, except the **OpenMP** requirement, from `Build from Sources section <#build-from-sources>`__ apply for this installation option as well.
 
 It is **strongly not recommended** to use this version of LightGBM!
 
 Build MPI Version
 ~~~~~~~~~~~~~~~~~
 
 .. code:: sh
 
-    pip install lightgbm --install-option=--mpi
+    pip install lightgbm --config-settings=cmake.define.USE_MPI=ON
 
 All requirements from `Build from Sources section <#build-from-sources>`__ apply for this installation option as well.
 
 For **Windows** users, compilation with **MinGW-w64** is not supported and `CMake`_ (version 3.8 or higher) is strongly required.
 
 **MPI** libraries are needed: details for installation can be found in `Installation Guide <https://github.com/microsoft/LightGBM/blob/master/docs/Installation-Guide.rst#build-mpi-version>`__.
 
 Build GPU Version
 ~~~~~~~~~~~~~~~~~
 
 .. code:: sh
 
-    pip install lightgbm --install-option=--gpu
+    pip install lightgbm --config-settings=cmake.define.USE_GPU=ON
 
 All requirements from `Build from Sources section <#build-from-sources>`__ apply for this installation option as well.
 
 For **Windows** users, `CMake`_ (version 3.8 or higher) is strongly required.
 
 **Boost** and **OpenCL** are needed: details for installation can be found in `Installation Guide <https://github.com/microsoft/LightGBM/blob/master/docs/Installation-Guide.rst#build-gpu-version>`__. Almost always you also need to pass ``OpenCL_INCLUDE_DIR``, ``OpenCL_LIBRARY`` options for **Linux** and ``BOOST_ROOT``, ``BOOST_LIBRARYDIR`` options for **Windows** to **CMake** via ``pip`` options, like
 
 .. code:: sh
 
-    pip install lightgbm --install-option=--gpu --install-option="--opencl-include-dir=/usr/local/cuda/include/" --install-option="--opencl-library=/usr/local/cuda/lib64/libOpenCL.so"
+    pip install lightgbm \
+      --config-settings=cmake.define.USE_GPU=ON \
+      --config-settings=cmake.define.OpenCL_INCLUDE_DIR="/usr/local/cuda/include/" \
+      --config-settings=cmake.define.OpenCL_LIBRARY="/usr/local/cuda/lib64/libOpenCL.so"
 
-All available options:
+All available options that can be passed via ``cmake.define.{option}``.
 
-- boost-root
+- Boost_ROOT
 
-- boost-dir
+- Boost_DIR
 
-- boost-include-dir
+- Boost_INCLUDE_DIR
 
-- boost-librarydir
+- BOOST_LIBRARYDIR
 
-- opencl-include-dir
+- OpenCL_INCLUDE_DIR
 
-- opencl-library
+- OpenCL_LIBRARY
 
 For more details see `FindBoost <https://cmake.org/cmake/help/latest/module/FindBoost.html>`__ and `FindOpenCL <https://cmake.org/cmake/help/latest/module/FindOpenCL.html>`__.
 
 Build CUDA Version
 ~~~~~~~~~~~~~~~~~~
 
 .. code:: sh
 
-    pip install lightgbm --install-option=--cuda
+    pip install lightgbm --config-settings=cmake.define.USE_CUDA=ON
 
 All requirements from `Build from Sources section <#build-from-sources>`__ apply for this installation option as well, and `CMake`_ (version 3.16 or higher) is strongly required.
 
-**CUDA** library (version 9.0 or higher) is needed: details for installation can be found in `Installation Guide <https://github.com/microsoft/LightGBM/blob/master/docs/Installation-Guide.rst#build-cuda-version-experimental>`__.
+**CUDA** library (version 10.0 or higher) is needed: details for installation can be found in `Installation Guide <https://github.com/microsoft/LightGBM/blob/master/docs/Installation-Guide.rst#build-cuda-version-experimental>`__.
+
+To use the CUDA version within Python, pass ``{"device": "cuda"}`` respectively in parameters.
 
 Build HDFS Version
 ~~~~~~~~~~~~~~~~~~
 
 .. code:: sh
 
-    pip install lightgbm --install-option=--hdfs
+    pip install lightgbm --config-settings=cmake.define.USE_HDFS=ON
 
 All requirements from `Build from Sources section <#build-from-sources>`__ apply for this installation option as well.
 
 **HDFS** library is needed: details for installation can be found in `Installation Guide <https://github.com/microsoft/LightGBM/blob/master/docs/Installation-Guide.rst#build-hdfs-version>`__.
 
 Note that the installation process of HDFS version was tested only on **Linux**.
 
 Build with MinGW-w64 on Windows
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 .. code:: sh
 
-    pip install lightgbm --install-option=--mingw
+    # in sh.exe, git bash, or other Unix-like shell
+    export CMAKE_GENERATOR='MinGW Makefiles'
+    pip install lightgbm --config-settings=cmake.define.CMAKE_SH=CMAKE_SH-NOTFOUND
 
 `CMake`_ and `MinGW-w64 <https://www.mingw-w64.org/>`_ should be installed first.
 
 It is recommended to use **Visual Studio** for its better multithreading efficiency in **Windows** for many-core systems
 (see `Question 4 <https://github.com/microsoft/LightGBM/blob/master/docs/FAQ.rst#4-i-am-using-windows-should-i-use-visual-studio-or-mingw-for-compiling-lightgbm>`__ and `Question 8 <https://github.com/microsoft/LightGBM/blob/master/docs/FAQ.rst#8-cpu-usage-is-low-like-10-in-windows-when-using-lightgbm-on-very-large-datasets-with-many-core-systems>`__).
 
 Build 32-bit Version with 32-bit Python
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 .. code:: sh
 
-    pip install lightgbm --install-option=--bit32
+    # in sh.exe, git bash, or other Unix-like shell
+    export CMAKE_GENERATOR='Visual Studio 17 2022'
+    export CMAKE_GENERATOR_PLATFORM='Win32'
+    pip install --no-binary lightgbm lightgbm
 
 By default, installation in environment with 32-bit Python is prohibited. However, you can remove this prohibition on your own risk by passing ``bit32`` option.
 
 It is **strongly not recommended** to use this version of LightGBM!
 
+Build with Time Costs Output
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+.. code:: sh
+
+    pip install lightgbm --config-settings=cmake.define.USE_TIMETAG=ON
+
+Use this option to make LightGBM output time costs for different internal routines, to investigate and benchmark its performance.
+
 Install from `conda-forge channel <https://anaconda.org/conda-forge/lightgbm>`_
 '''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
 
 If you use ``conda`` to manage Python dependencies, you can install LightGBM using ``conda install``.
 
+We strongly recommend installation from the ``conda-forge`` channel and not from the ``default`` one due to many reasons. The main ones are less time delay for new releases, greater number of supported architectures and better handling of dependency conflicts, especially workaround for OpenMP is crucial for LightGBM. More details can be found in `this comment <https://github.com/microsoft/LightGBM/issues/4948#issuecomment-1013766397>`_.
+
 **Note**: The `lightgbm conda-forge feedstock <https://github.com/conda-forge/lightgbm-feedstock>`_ is not maintained by LightGBM maintainers.
 
 .. code:: sh
 
     conda install -c conda-forge lightgbm
 
 Install from GitHub
@@ -201,55 +226,56 @@
 All requirements from `Build from Sources section <#build-from-sources>`__ apply for this installation option as well.
 
 For **Windows** users, if you get any errors during installation and there is the warning ``WARNING:LightGBM:Compilation with MSBuild from existing solution file failed.`` in the log, you should install `CMake`_ (version 3.8 or higher).
 
 .. code:: sh
 
     git clone --recursive https://github.com/microsoft/LightGBM.git
-    cd LightGBM/python-package
     # export CXX=g++-7 CC=gcc-7  # macOS users, if you decided to compile with gcc, don't forget to specify compilers (replace "7" with version of gcc installed on your machine)
-    python setup.py install
+    sh ./build-python.sh install
 
 Note: ``sudo`` (or administrator rights in **Windows**) may be needed to perform the command.
 
-Run ``python setup.py install --nomp`` to disable **OpenMP** support. All requirements from `Build Threadless Version section <#build-threadless-version>`__ apply for this installation option as well.
+Run ``sh ./build-python.sh install --nomp`` to disable **OpenMP** support. All requirements from `Build Threadless Version section <#build-threadless-version>`__ apply for this installation option as well.
+
+Run ``sh ./build-python.sh install --mpi`` to enable **MPI** support. All requirements from `Build MPI Version section <#build-mpi-version>`__ apply for this installation option as well.
 
-Run ``python setup.py install --mpi`` to enable **MPI** support. All requirements from `Build MPI Version section <#build-mpi-version>`__ apply for this installation option as well.
+Run ``sh ./build-python.sh install --mingw``, if you want to use **MinGW-w64** on **Windows** instead of **Visual Studio**. All requirements from `Build with MinGW-w64 on Windows section <#build-with-mingw-w64-on-windows>`__ apply for this installation option as well.
 
-Run ``python setup.py install --mingw``, if you want to use **MinGW-w64** on **Windows** instead of **Visual Studio**. All requirements from `Build with MinGW-w64 on Windows section <#build-with-mingw-w64-on-windows>`__ apply for this installation option as well.
+Run ``sh ./build-python.sh install --gpu`` to enable GPU support. All requirements from `Build GPU Version section <#build-gpu-version>`__ apply for this installation option as well. To pass additional options to **CMake** use the following syntax: ``sh ./build-python.sh install --gpu --opencl-include-dir="/usr/local/cuda/include/"``, see `Build GPU Version section <#build-gpu-version>`__ for the complete list of them.
 
-Run ``python setup.py install --gpu`` to enable GPU support. All requirements from `Build GPU Version section <#build-gpu-version>`__ apply for this installation option as well. To pass additional options to **CMake** use the following syntax: ``python setup.py install --gpu --opencl-include-dir=/usr/local/cuda/include/``, see `Build GPU Version section <#build-gpu-version>`__ for the complete list of them.
+Run ``sh ./build-python.sh install --cuda`` to enable CUDA support. All requirements from `Build CUDA Version section <#build-cuda-version>`__ apply for this installation option as well.
 
-Run ``python setup.py install --cuda`` to enable CUDA support. All requirements from `Build CUDA Version section <#build-cuda-version>`__ apply for this installation option as well.
+Run ``sh ./build-python.sh install --hdfs`` to enable HDFS support. All requirements from `Build HDFS Version section <#build-hdfs-version>`__ apply for this installation option as well.
 
-Run ``python setup.py install --hdfs`` to enable HDFS support. All requirements from `Build HDFS Version section <#build-hdfs-version>`__ apply for this installation option as well.
+Run ``sh ./build-python.sh install --bit32``, if you want to use 32-bit version. All requirements from `Build 32-bit Version with 32-bit Python section <#build-32-bit-version-with-32-bit-python>`__ apply for this installation option as well.
 
-Run ``python setup.py install --bit32``, if you want to use 32-bit version. All requirements from `Build 32-bit Version with 32-bit Python section <#build-32-bit-version-with-32-bit-python>`__ apply for this installation option as well.
+Run ``sh ./build-python.sh install --time-costs``, if you want to output time costs for different internal routines. All requirements from `Build with Time Costs Output section <#build-with-time-costs-output>`__ apply for this installation option as well.
 
-If you get any errors during installation or due to any other reasons, you may want to build dynamic library from sources by any method you prefer (see `Installation Guide <https://github.com/microsoft/LightGBM/blob/master/docs/Installation-Guide.rst>`__) and then just run ``python setup.py install --precompile``.
+If you get any errors during installation or due to any other reasons, you may want to build dynamic library from sources by any method you prefer (see `Installation Guide <https://github.com/microsoft/LightGBM/blob/master/docs/Installation-Guide.rst>`__) and then just run ``sh ./build-python.sh install --precompile``.
 
 Build Wheel File
 ****************
 
-You can use ``python setup.py bdist_wheel`` instead of ``python setup.py install`` to build wheel file and use it for installation later. This might be useful for systems with restricted or completely without network access.
+You can use ``sh ./build-python.sh install bdist_wheel`` instead of ``sh ./build-python.sh install`` to build wheel file and use it for installation later. This might be useful for systems with restricted or completely without network access.
 
-Install Dask-package
-''''''''''''''''''''
+Build With MSBuild
+******************
 
-.. warning::
+To use ``MSBuild`` (Windows-only), first build ``lib_lightgbm.dll`` by running the following from the root of the repo.
 
-    Dask-package is only tested on Linux.
+.. code:: sh
 
-To install all additional dependencies required for Dask-package, you can append ``[dask]`` to LightGBM package name:
+  MSBuild.exe windows/LightGBM.sln /p:Configuration=DLL /p:Platform=x64 /p:PlatformToolset=v143
 
-.. code:: sh
+Then install the Python package using that library.
 
-    pip install lightgbm[dask]
+.. code:: sh
 
-Or replace ``python setup.py install`` with ``pip install -e .[dask]`` if you are installing the package from source files.
+  sh ./build-python.sh install --precompile
 
 Troubleshooting
 ---------------
 
 In case you are facing any errors during the installation process, you can examine ``$HOME/LightGBM_compilation.log`` file, in which all operations are logged, to get more details about occurred problem. Also, please attach this file to the issue on GitHub to help faster indicate the cause of the error.
 
 Refer to `FAQ <https://github.com/microsoft/LightGBM/tree/master/docs/FAQ.rst>`_.
@@ -258,24 +284,28 @@
 --------
 
 Refer to the walk through examples in `Python guide folder <https://github.com/microsoft/LightGBM/tree/master/examples/python-guide>`_.
 
 Development Guide
 -----------------
 
-The code style of Python-package follows `PEP 8 <https://www.python.org/dev/peps/pep-0008/>`_. If you would like to make a contribution and not familiar with PEP 8, please check the PEP 8 style guide first. Otherwise, the check won't pass. Only E501 (line too long) and W503 (line break occurred before a binary operator) can be ignored.
+The code style of Python-package follows `PEP 8 <https://www.python.org/dev/peps/pep-0008/>`_.
+
+The package's documentation strings (docstrings) are written in the `numpydoc style <https://numpydoc.readthedocs.io/en/latest/format.html>`_.
 
-Documentation strings (docstrings) are written in the NumPy style.
+To check that a contribution to the package matches its style expectations, run the following from the root of the repo.
+
+.. code:: sh
+
+    sh .ci/lint-python.sh
 
 .. |License| image:: https://img.shields.io/github/license/microsoft/lightgbm.svg
    :target: https://github.com/microsoft/LightGBM/blob/master/LICENSE
 .. |Python Versions| image:: https://img.shields.io/pypi/pyversions/lightgbm.svg?logo=python&logoColor=white
    :target: https://pypi.org/project/lightgbm
 .. |PyPI Version| image:: https://img.shields.io/pypi/v/lightgbm.svg?logo=pypi&logoColor=white
    :target: https://pypi.org/project/lightgbm
 .. |Downloads| image:: https://pepy.tech/badge/lightgbm
    :target: https://pepy.tech/project/lightgbm
 .. |API Docs| image:: https://readthedocs.org/projects/lightgbm/badge/?version=latest
    :target: https://lightgbm.readthedocs.io/en/latest/Python-API.html
 .. _CMake: https://cmake.org/
-
-
```

### Comparing `lightgbm-3.3.5/README.rst` & `lightgbm-4.0.0/PKG-INFO`

 * *Files 22% similar despite different names*

```diff
@@ -1,7 +1,65 @@
+Metadata-Version: 2.1
+Name: lightgbm
+Version: 4.0.0
+Summary: LightGBM Python Package
+Home-page: https://github.com/microsoft/LightGBM
+Maintainer-Email: Yu Shi <yushi@microsoft.com>
+License: The MIT License (MIT)
+        
+        Copyright (c) Microsoft Corporation
+        
+        Permission is hereby granted, free of charge, to any person obtaining a copy
+        of this software and associated documentation files (the "Software"), to deal
+        in the Software without restriction, including without limitation the rights
+        to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+        copies of the Software, and to permit persons to whom the Software is
+        furnished to do so, subject to the following conditions:
+        
+        The above copyright notice and this permission notice shall be included in all
+        copies or substantial portions of the Software.
+        
+        THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+        IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+        FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+        AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+        LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+        OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+        SOFTWARE.
+Classifier: Development Status :: 5 - Production/Stable
+Classifier: Intended Audience :: Science/Research
+Classifier: License :: OSI Approved :: MIT License
+Classifier: Natural Language :: English
+Classifier: Operating System :: MacOS
+Classifier: Operating System :: Microsoft :: Windows
+Classifier: Operating System :: POSIX
+Classifier: Operating System :: Unix
+Classifier: Programming Language :: Python :: 3
+Classifier: Programming Language :: Python :: 3.7
+Classifier: Programming Language :: Python :: 3.8
+Classifier: Programming Language :: Python :: 3.9
+Classifier: Programming Language :: Python :: 3.10
+Classifier: Programming Language :: Python :: 3.11
+Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
+Project-URL: Homepage, https://github.com/microsoft/LightGBM
+Project-URL: Documentation, https://lightgbm.readthedocs.io/en/latest/
+Project-URL: Repository, https://github.com/microsoft/LightGBM.git
+Project-URL: Changelog, https://github.com/microsoft/LightGBM/releases
+Requires-Python: >=3.6
+Requires-Dist: numpy
+Requires-Dist: scipy
+Requires-Dist: dask[array,dataframe,distributed]>=2.0.0; extra == "dask"
+Requires-Dist: pandas>=0.24.0; extra == "dask"
+Requires-Dist: pandas>=0.24.0; extra == "pandas"
+Requires-Dist: scikit-learn!=0.22.0; extra == "scikit-learn"
+Provides-Extra: dask
+Provides-Extra: pandas
+Provides-Extra: scikit-learn
+Description-Content-Type: text/x-rst
+
 LightGBM Python-package
 =======================
 
 |License| |Python Versions| |PyPI Version| |Downloads| |API Docs|
 
 Installation
 ------------
@@ -16,158 +74,208 @@
 Install from `PyPI <https://pypi.org/project/lightgbm>`_
 ''''''''''''''''''''''''''''''''''''''''''''''''''''''''
 
 .. code:: sh
 
     pip install lightgbm
 
-You may need to install `wheel <https://pythonwheels.com>`_ via ``pip install wheel`` first.
-
-Compiled library that is included in the wheel file supports both **GPU** and **CPU** versions out of the box. This feature is experimental and available only for **Windows** currently. To use **GPU** version you only need to install OpenCL Runtime libraries. For NVIDIA and AMD GPU they are included in the ordinary drivers for your graphics card, so no action is required. If you would like your AMD or Intel CPU to act like a GPU (for testing and debugging) you can install `AMD APP SDK <https://github.com/microsoft/LightGBM/releases/download/v2.0.12/AMD-APP-SDKInstaller-v3.0.130.135-GA-windows-F-x64.exe>`_.
+Compiled library that is included in the wheel file supports both **GPU** and **CPU** versions out of the box. This feature is experimental and available only for **Windows** and **Linux** currently. To use **GPU** version you only need to install OpenCL Runtime libraries. For NVIDIA and AMD GPU they are included in the ordinary drivers for your graphics card, so no action is required. If you would like your AMD or Intel CPU to act like a GPU (for testing and debugging) you can install `AMD APP SDK <https://github.com/microsoft/LightGBM/releases/download/v2.0.12/AMD-APP-SDKInstaller-v3.0.130.135-GA-windows-F-x64.exe>`_ on **Windows** and `PoCL <http://portablecl.org>`_ on **Linux**. Many modern Linux distributions provide packages for PoCL, look for ``pocl-opencl-icd`` on Debian-based distributions and ``pocl`` on RedHat-based distributions.
 
 For **Windows** users, `VC runtime <https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads>`_ is needed if **Visual Studio** (2015 or newer) is not installed.
 
-For **Linux** users, **glibc** >= 2.14 is required. Also, in some rare cases, when you hit ``OSError: libgomp.so.1: cannot open shared object file: No such file or directory`` error during importing LightGBM, you need to install OpenMP runtime library separately (use your package manager and search for ``lib[g|i]omp`` for doing this).
+For **Linux** users, **glibc** >= 2.14 is required for LightGBM ``<=3.3.3`` and **glibc** >= 2.28 is required for newer versions. Also, in some rare cases, when you hit ``OSError: libgomp.so.1: cannot open shared object file: No such file or directory`` error during importing LightGBM, you need to install OpenMP runtime library separately (use your package manager and search for ``lib[g|i]omp`` for doing this).
 
 For **macOS** (we provide wheels for 3 newest macOS versions) users:
 
-- Starting from version 2.2.1, the library file in distribution wheels is built by the **Apple Clang** (Xcode_8.3.3 for versions 2.2.1 - 2.3.1, and Xcode_9.4.1 from version 2.3.2) compiler. This means that you don't need to install the **gcc** compiler anymore. Instead of that you need to install the **OpenMP** library, which is required for running LightGBM on the system with the **Apple Clang** compiler. You can install the **OpenMP** library by the following command: ``brew install libomp``.
+- Starting from version 2.2.1, the library file in distribution wheels is built by the **Apple Clang** (Xcode_8.3.3 for versions 2.2.1 - 2.3.1, Xcode_9.4.1 for versions 2.3.2 - 3.3.2 and Xcode_11.7 from version 4.0.0) compiler. This means that you don't need to install the **gcc** compiler anymore. Instead of that you need to install the **OpenMP** library, which is required for running LightGBM on the system with the **Apple Clang** compiler. You can install the **OpenMP** library by the following command: ``brew install libomp``.
 
 - For version smaller than 2.2.1 and not smaller than 2.1.2, **gcc-8** with **OpenMP** support must be installed first. Refer to `Installation Guide <https://github.com/microsoft/LightGBM/blob/master/docs/Installation-Guide.rst#gcc>`__ for installation of **gcc-8** with **OpenMP** support.
 
 - For version smaller than 2.1.2, **gcc-7** with **OpenMP** is required.
 
+Use LightGBM with Dask
+**********************
+
+.. warning::
+
+    Dask-package is only tested on Linux.
+
+To install all dependencies needed to use ``lightgbm.dask``, append ``[dask]``.
+
+.. code:: sh
+
+    pip install 'lightgbm[dask]'
+
+Use LightGBM with pandas
+************************
+
+To install all dependencies needed to use ``pandas`` in LightGBM, append ``[pandas]``.
+
+.. code:: sh
+
+    pip install 'lightgbm[pandas]'
+
+Use LightGBM with scikit-learn
+******************************
+
+To install all dependencies needed to use ``scikit-learn`` in LightGBM, append ``[scikit-learn]``.
+
+.. code:: sh
+
+    pip install 'lightgbm[scikit-learn]'
+
 Build from Sources
 ******************
 
 .. code:: sh
 
-    pip install --no-binary :all: lightgbm
+    pip install --no-binary lightgbm lightgbm
 
 For **Linux** and **macOS** users, installation from sources requires installed `CMake`_.
 
-For **Linux** users, **glibc** >= 2.14 is required. Also, in some rare cases you may need to install OpenMP runtime library separately (use your package manager and search for ``lib[g|i]omp`` for doing this).
+For **Linux** users, **glibc** >= 2.28 is required. Also, in some rare cases you may need to install OpenMP runtime library separately (use your package manager and search for ``lib[g|i]omp`` for doing this).
 
 For **macOS** users, you can perform installation either with **Apple Clang** or **gcc**.
 
 - In case you prefer **Apple Clang**, you should install **OpenMP** (details for installation can be found in `Installation Guide <https://github.com/microsoft/LightGBM/blob/master/docs/Installation-Guide.rst#apple-clang>`__) first and **CMake** version 3.16 or higher is required.
 
 - In case you prefer **gcc**, you need to install it (details for installation can be found in `Installation Guide <https://github.com/microsoft/LightGBM/blob/master/docs/Installation-Guide.rst#gcc>`__) and specify compilers by running ``export CXX=g++-7 CC=gcc-7`` (replace "7" with version of **gcc** installed on your machine) first.
 
 For **Windows** users, **Visual Studio** (or `VS Build Tools <https://visualstudio.microsoft.com/downloads/>`_) is needed. If you get any errors during installation, you may need to install `CMake`_ (version 3.8 or higher).
 
 Build Threadless Version
 ~~~~~~~~~~~~~~~~~~~~~~~~
 
 .. code:: sh
 
-    pip install lightgbm --install-option=--nomp
+    pip install lightgbm --config-settings=cmake.define.USE_OPENMP=OFF
 
 All requirements, except the **OpenMP** requirement, from `Build from Sources section <#build-from-sources>`__ apply for this installation option as well.
 
 It is **strongly not recommended** to use this version of LightGBM!
 
 Build MPI Version
 ~~~~~~~~~~~~~~~~~
 
 .. code:: sh
 
-    pip install lightgbm --install-option=--mpi
+    pip install lightgbm --config-settings=cmake.define.USE_MPI=ON
 
 All requirements from `Build from Sources section <#build-from-sources>`__ apply for this installation option as well.
 
 For **Windows** users, compilation with **MinGW-w64** is not supported and `CMake`_ (version 3.8 or higher) is strongly required.
 
 **MPI** libraries are needed: details for installation can be found in `Installation Guide <https://github.com/microsoft/LightGBM/blob/master/docs/Installation-Guide.rst#build-mpi-version>`__.
 
 Build GPU Version
 ~~~~~~~~~~~~~~~~~
 
 .. code:: sh
 
-    pip install lightgbm --install-option=--gpu
+    pip install lightgbm --config-settings=cmake.define.USE_GPU=ON
 
 All requirements from `Build from Sources section <#build-from-sources>`__ apply for this installation option as well.
 
 For **Windows** users, `CMake`_ (version 3.8 or higher) is strongly required.
 
 **Boost** and **OpenCL** are needed: details for installation can be found in `Installation Guide <https://github.com/microsoft/LightGBM/blob/master/docs/Installation-Guide.rst#build-gpu-version>`__. Almost always you also need to pass ``OpenCL_INCLUDE_DIR``, ``OpenCL_LIBRARY`` options for **Linux** and ``BOOST_ROOT``, ``BOOST_LIBRARYDIR`` options for **Windows** to **CMake** via ``pip`` options, like
 
 .. code:: sh
 
-    pip install lightgbm --install-option=--gpu --install-option="--opencl-include-dir=/usr/local/cuda/include/" --install-option="--opencl-library=/usr/local/cuda/lib64/libOpenCL.so"
+    pip install lightgbm \
+      --config-settings=cmake.define.USE_GPU=ON \
+      --config-settings=cmake.define.OpenCL_INCLUDE_DIR="/usr/local/cuda/include/" \
+      --config-settings=cmake.define.OpenCL_LIBRARY="/usr/local/cuda/lib64/libOpenCL.so"
 
-All available options:
+All available options that can be passed via ``cmake.define.{option}``.
 
-- boost-root
+- Boost_ROOT
 
-- boost-dir
+- Boost_DIR
 
-- boost-include-dir
+- Boost_INCLUDE_DIR
 
-- boost-librarydir
+- BOOST_LIBRARYDIR
 
-- opencl-include-dir
+- OpenCL_INCLUDE_DIR
 
-- opencl-library
+- OpenCL_LIBRARY
 
 For more details see `FindBoost <https://cmake.org/cmake/help/latest/module/FindBoost.html>`__ and `FindOpenCL <https://cmake.org/cmake/help/latest/module/FindOpenCL.html>`__.
 
 Build CUDA Version
 ~~~~~~~~~~~~~~~~~~
 
 .. code:: sh
 
-    pip install lightgbm --install-option=--cuda
+    pip install lightgbm --config-settings=cmake.define.USE_CUDA=ON
 
 All requirements from `Build from Sources section <#build-from-sources>`__ apply for this installation option as well, and `CMake`_ (version 3.16 or higher) is strongly required.
 
-**CUDA** library (version 9.0 or higher) is needed: details for installation can be found in `Installation Guide <https://github.com/microsoft/LightGBM/blob/master/docs/Installation-Guide.rst#build-cuda-version-experimental>`__.
+**CUDA** library (version 10.0 or higher) is needed: details for installation can be found in `Installation Guide <https://github.com/microsoft/LightGBM/blob/master/docs/Installation-Guide.rst#build-cuda-version-experimental>`__.
+
+To use the CUDA version within Python, pass ``{"device": "cuda"}`` respectively in parameters.
 
 Build HDFS Version
 ~~~~~~~~~~~~~~~~~~
 
 .. code:: sh
 
-    pip install lightgbm --install-option=--hdfs
+    pip install lightgbm --config-settings=cmake.define.USE_HDFS=ON
 
 All requirements from `Build from Sources section <#build-from-sources>`__ apply for this installation option as well.
 
 **HDFS** library is needed: details for installation can be found in `Installation Guide <https://github.com/microsoft/LightGBM/blob/master/docs/Installation-Guide.rst#build-hdfs-version>`__.
 
 Note that the installation process of HDFS version was tested only on **Linux**.
 
 Build with MinGW-w64 on Windows
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 .. code:: sh
 
-    pip install lightgbm --install-option=--mingw
+    # in sh.exe, git bash, or other Unix-like shell
+    export CMAKE_GENERATOR='MinGW Makefiles'
+    pip install lightgbm --config-settings=cmake.define.CMAKE_SH=CMAKE_SH-NOTFOUND
 
 `CMake`_ and `MinGW-w64 <https://www.mingw-w64.org/>`_ should be installed first.
 
 It is recommended to use **Visual Studio** for its better multithreading efficiency in **Windows** for many-core systems
 (see `Question 4 <https://github.com/microsoft/LightGBM/blob/master/docs/FAQ.rst#4-i-am-using-windows-should-i-use-visual-studio-or-mingw-for-compiling-lightgbm>`__ and `Question 8 <https://github.com/microsoft/LightGBM/blob/master/docs/FAQ.rst#8-cpu-usage-is-low-like-10-in-windows-when-using-lightgbm-on-very-large-datasets-with-many-core-systems>`__).
 
 Build 32-bit Version with 32-bit Python
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
 .. code:: sh
 
-    pip install lightgbm --install-option=--bit32
+    # in sh.exe, git bash, or other Unix-like shell
+    export CMAKE_GENERATOR='Visual Studio 17 2022'
+    export CMAKE_GENERATOR_PLATFORM='Win32'
+    pip install --no-binary lightgbm lightgbm
 
 By default, installation in environment with 32-bit Python is prohibited. However, you can remove this prohibition on your own risk by passing ``bit32`` option.
 
 It is **strongly not recommended** to use this version of LightGBM!
 
+Build with Time Costs Output
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+.. code:: sh
+
+    pip install lightgbm --config-settings=cmake.define.USE_TIMETAG=ON
+
+Use this option to make LightGBM output time costs for different internal routines, to investigate and benchmark its performance.
+
 Install from `conda-forge channel <https://anaconda.org/conda-forge/lightgbm>`_
 '''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
 
 If you use ``conda`` to manage Python dependencies, you can install LightGBM using ``conda install``.
 
+We strongly recommend installation from the ``conda-forge`` channel and not from the ``default`` one due to many reasons. The main ones are less time delay for new releases, greater number of supported architectures and better handling of dependency conflicts, especially workaround for OpenMP is crucial for LightGBM. More details can be found in `this comment <https://github.com/microsoft/LightGBM/issues/4948#issuecomment-1013766397>`_.
+
 **Note**: The `lightgbm conda-forge feedstock <https://github.com/conda-forge/lightgbm-feedstock>`_ is not maintained by LightGBM maintainers.
 
 .. code:: sh
 
     conda install -c conda-forge lightgbm
 
 Install from GitHub
@@ -176,55 +284,56 @@
 All requirements from `Build from Sources section <#build-from-sources>`__ apply for this installation option as well.
 
 For **Windows** users, if you get any errors during installation and there is the warning ``WARNING:LightGBM:Compilation with MSBuild from existing solution file failed.`` in the log, you should install `CMake`_ (version 3.8 or higher).
 
 .. code:: sh
 
     git clone --recursive https://github.com/microsoft/LightGBM.git
-    cd LightGBM/python-package
     # export CXX=g++-7 CC=gcc-7  # macOS users, if you decided to compile with gcc, don't forget to specify compilers (replace "7" with version of gcc installed on your machine)
-    python setup.py install
+    sh ./build-python.sh install
 
 Note: ``sudo`` (or administrator rights in **Windows**) may be needed to perform the command.
 
-Run ``python setup.py install --nomp`` to disable **OpenMP** support. All requirements from `Build Threadless Version section <#build-threadless-version>`__ apply for this installation option as well.
+Run ``sh ./build-python.sh install --nomp`` to disable **OpenMP** support. All requirements from `Build Threadless Version section <#build-threadless-version>`__ apply for this installation option as well.
 
-Run ``python setup.py install --mpi`` to enable **MPI** support. All requirements from `Build MPI Version section <#build-mpi-version>`__ apply for this installation option as well.
+Run ``sh ./build-python.sh install --mpi`` to enable **MPI** support. All requirements from `Build MPI Version section <#build-mpi-version>`__ apply for this installation option as well.
 
-Run ``python setup.py install --mingw``, if you want to use **MinGW-w64** on **Windows** instead of **Visual Studio**. All requirements from `Build with MinGW-w64 on Windows section <#build-with-mingw-w64-on-windows>`__ apply for this installation option as well.
+Run ``sh ./build-python.sh install --mingw``, if you want to use **MinGW-w64** on **Windows** instead of **Visual Studio**. All requirements from `Build with MinGW-w64 on Windows section <#build-with-mingw-w64-on-windows>`__ apply for this installation option as well.
 
-Run ``python setup.py install --gpu`` to enable GPU support. All requirements from `Build GPU Version section <#build-gpu-version>`__ apply for this installation option as well. To pass additional options to **CMake** use the following syntax: ``python setup.py install --gpu --opencl-include-dir=/usr/local/cuda/include/``, see `Build GPU Version section <#build-gpu-version>`__ for the complete list of them.
+Run ``sh ./build-python.sh install --gpu`` to enable GPU support. All requirements from `Build GPU Version section <#build-gpu-version>`__ apply for this installation option as well. To pass additional options to **CMake** use the following syntax: ``sh ./build-python.sh install --gpu --opencl-include-dir="/usr/local/cuda/include/"``, see `Build GPU Version section <#build-gpu-version>`__ for the complete list of them.
 
-Run ``python setup.py install --cuda`` to enable CUDA support. All requirements from `Build CUDA Version section <#build-cuda-version>`__ apply for this installation option as well.
+Run ``sh ./build-python.sh install --cuda`` to enable CUDA support. All requirements from `Build CUDA Version section <#build-cuda-version>`__ apply for this installation option as well.
 
-Run ``python setup.py install --hdfs`` to enable HDFS support. All requirements from `Build HDFS Version section <#build-hdfs-version>`__ apply for this installation option as well.
+Run ``sh ./build-python.sh install --hdfs`` to enable HDFS support. All requirements from `Build HDFS Version section <#build-hdfs-version>`__ apply for this installation option as well.
 
-Run ``python setup.py install --bit32``, if you want to use 32-bit version. All requirements from `Build 32-bit Version with 32-bit Python section <#build-32-bit-version-with-32-bit-python>`__ apply for this installation option as well.
+Run ``sh ./build-python.sh install --bit32``, if you want to use 32-bit version. All requirements from `Build 32-bit Version with 32-bit Python section <#build-32-bit-version-with-32-bit-python>`__ apply for this installation option as well.
 
-If you get any errors during installation or due to any other reasons, you may want to build dynamic library from sources by any method you prefer (see `Installation Guide <https://github.com/microsoft/LightGBM/blob/master/docs/Installation-Guide.rst>`__) and then just run ``python setup.py install --precompile``.
+Run ``sh ./build-python.sh install --time-costs``, if you want to output time costs for different internal routines. All requirements from `Build with Time Costs Output section <#build-with-time-costs-output>`__ apply for this installation option as well.
+
+If you get any errors during installation or due to any other reasons, you may want to build dynamic library from sources by any method you prefer (see `Installation Guide <https://github.com/microsoft/LightGBM/blob/master/docs/Installation-Guide.rst>`__) and then just run ``sh ./build-python.sh install --precompile``.
 
 Build Wheel File
 ****************
 
-You can use ``python setup.py bdist_wheel`` instead of ``python setup.py install`` to build wheel file and use it for installation later. This might be useful for systems with restricted or completely without network access.
+You can use ``sh ./build-python.sh install bdist_wheel`` instead of ``sh ./build-python.sh install`` to build wheel file and use it for installation later. This might be useful for systems with restricted or completely without network access.
 
-Install Dask-package
-''''''''''''''''''''
+Build With MSBuild
+******************
 
-.. warning::
+To use ``MSBuild`` (Windows-only), first build ``lib_lightgbm.dll`` by running the following from the root of the repo.
 
-    Dask-package is only tested on Linux.
+.. code:: sh
 
-To install all additional dependencies required for Dask-package, you can append ``[dask]`` to LightGBM package name:
+  MSBuild.exe windows/LightGBM.sln /p:Configuration=DLL /p:Platform=x64 /p:PlatformToolset=v143
 
-.. code:: sh
+Then install the Python package using that library.
 
-    pip install lightgbm[dask]
+.. code:: sh
 
-Or replace ``python setup.py install`` with ``pip install -e .[dask]`` if you are installing the package from source files.
+  sh ./build-python.sh install --precompile
 
 Troubleshooting
 ---------------
 
 In case you are facing any errors during the installation process, you can examine ``$HOME/LightGBM_compilation.log`` file, in which all operations are logged, to get more details about occurred problem. Also, please attach this file to the issue on GitHub to help faster indicate the cause of the error.
 
 Refer to `FAQ <https://github.com/microsoft/LightGBM/tree/master/docs/FAQ.rst>`_.
@@ -233,17 +342,23 @@
 --------
 
 Refer to the walk through examples in `Python guide folder <https://github.com/microsoft/LightGBM/tree/master/examples/python-guide>`_.
 
 Development Guide
 -----------------
 
-The code style of Python-package follows `PEP 8 <https://www.python.org/dev/peps/pep-0008/>`_. If you would like to make a contribution and not familiar with PEP 8, please check the PEP 8 style guide first. Otherwise, the check won't pass. Only E501 (line too long) and W503 (line break occurred before a binary operator) can be ignored.
+The code style of Python-package follows `PEP 8 <https://www.python.org/dev/peps/pep-0008/>`_.
+
+The package's documentation strings (docstrings) are written in the `numpydoc style <https://numpydoc.readthedocs.io/en/latest/format.html>`_.
+
+To check that a contribution to the package matches its style expectations, run the following from the root of the repo.
+
+.. code:: sh
 
-Documentation strings (docstrings) are written in the NumPy style.
+    sh .ci/lint-python.sh
 
 .. |License| image:: https://img.shields.io/github/license/microsoft/lightgbm.svg
    :target: https://github.com/microsoft/LightGBM/blob/master/LICENSE
 .. |Python Versions| image:: https://img.shields.io/pypi/pyversions/lightgbm.svg?logo=python&logoColor=white
    :target: https://pypi.org/project/lightgbm
 .. |PyPI Version| image:: https://img.shields.io/pypi/v/lightgbm.svg?logo=pypi&logoColor=white
    :target: https://pypi.org/project/lightgbm
```

### Comparing `lightgbm-3.3.5/compile/CMakeLists.txt` & `lightgbm-4.0.0/CMakeLists.txt`

 * *Files 22% similar despite different names*

```diff
@@ -1,57 +1,75 @@
-OPTION(USE_MPI "Enable MPI-based distributed learning" OFF)
-OPTION(USE_OPENMP "Enable OpenMP" ON)
-OPTION(USE_GPU "Enable GPU-accelerated training" OFF)
-OPTION(USE_SWIG "Enable SWIG to generate Java API" OFF)
-OPTION(USE_HDFS "Enable HDFS support (EXPERIMENTAL)" OFF)
-OPTION(USE_TIMETAG "Set to ON to output time costs" OFF)
-OPTION(USE_CUDA "Enable CUDA-accelerated training (EXPERIMENTAL)" OFF)
-OPTION(USE_DEBUG "Set to ON for Debug mode" OFF)
-OPTION(USE_SANITIZER "Use santizer flags" OFF)
-SET(ENABLED_SANITIZERS "address" "leak" "undefined" CACHE STRING
-  "Semicolon separated list of sanitizer names. E.g 'address;leak'. Supported sanitizers are
-address, leak, undefined and thread.")
-OPTION(BUILD_CPP_TEST "Build C++ tests with Google Test" OFF)
-OPTION(BUILD_STATIC_LIB "Build static library" OFF)
-OPTION(__BUILD_FOR_R "Set to ON if building lib_lightgbm for use with the R package" OFF)
-OPTION(__INTEGRATE_OPENCL "Set to ON if building LightGBM with the OpenCL ICD Loader and its dependencies included" OFF)
+option(USE_MPI "Enable MPI-based distributed learning" OFF)
+option(USE_OPENMP "Enable OpenMP" ON)
+option(USE_GPU "Enable GPU-accelerated training" OFF)
+option(USE_SWIG "Enable SWIG to generate Java API" OFF)
+option(USE_HDFS "Enable HDFS support (EXPERIMENTAL)" OFF)
+option(USE_TIMETAG "Set to ON to output time costs" OFF)
+option(USE_CUDA "Enable CUDA-accelerated training " OFF)
+option(USE_DEBUG "Set to ON for Debug mode" OFF)
+option(USE_SANITIZER "Use santizer flags" OFF)
+set(
+  ENABLED_SANITIZERS
+  "address" "leak" "undefined"
+  CACHE
+  STRING
+  "Semicolon separated list of sanitizer names, e.g., 'address;leak'. \
+Supported sanitizers are address, leak, undefined and thread."
+)
+option(BUILD_CLI "Build the 'lightbgm' command-line interface in addition to lib_lightgbm" ON)
+option(BUILD_CPP_TEST "Build C++ tests with Google Test" OFF)
+option(BUILD_STATIC_LIB "Build static library" OFF)
+option(INSTALL_HEADERS "Install headers to CMAKE_INSTALL_PREFIX (e.g. '/usr/local/include')" ON)
+option(__BUILD_FOR_PYTHON "Set to ON if building lib_lightgbm for use with the Python package" OFF)
+option(__BUILD_FOR_R "Set to ON if building lib_lightgbm for use with the R package" OFF)
+option(__INTEGRATE_OPENCL "Set to ON if building LightGBM with the OpenCL ICD Loader and its dependencies included" OFF)
 
 if(APPLE)
-  OPTION(APPLE_OUTPUT_DYLIB "Output dylib shared library" OFF)
-endif(APPLE)
+  option(APPLE_OUTPUT_DYLIB "Output dylib shared library" OFF)
+endif()
 
 if(__INTEGRATE_OPENCL)
   cmake_minimum_required(VERSION 3.11)
+elseif(USE_SWIG)
+  cmake_minimum_required(VERSION 3.8)
 elseif(USE_GPU OR APPLE)
   cmake_minimum_required(VERSION 3.2)
 elseif(USE_CUDA)
   cmake_minimum_required(VERSION 3.16)
 else()
   cmake_minimum_required(VERSION 3.0)
 endif()
 
-PROJECT(lightgbm LANGUAGES C CXX)
+project(lightgbm LANGUAGES C CXX)
 
 list(APPEND CMAKE_MODULE_PATH "${PROJECT_SOURCE_DIR}/cmake/modules")
 
 #-- Sanitizer
 if(USE_SANITIZER)
   if(MSVC)
     message(FATAL_ERROR "Sanitizers are not supported with MSVC.")
-  endif(MSVC)
+  endif()
   include(cmake/Sanitizer.cmake)
   enable_sanitizers("${ENABLED_SANITIZERS}")
-endif(USE_SANITIZER)
+endif()
 
 if(__INTEGRATE_OPENCL)
   set(__INTEGRATE_OPENCL ON CACHE BOOL "" FORCE)
   set(USE_GPU OFF CACHE BOOL "" FORCE)
   message(STATUS "Building library with integrated OpenCL components")
 endif()
 
+if(__BUILD_FOR_PYTHON OR __BUILD_FOR_R)
+    # the Python and R package don't require the CLI
+    set(BUILD_CLI OFF)
+    # installing the R and Python package shouldn't place LightGBM's headers
+    # outside of where the package is installed
+    set(INSTALL_HEADERS OFF)
+endif()
+
 if(CMAKE_CXX_COMPILER_ID STREQUAL "GNU")
   if(CMAKE_CXX_COMPILER_VERSION VERSION_LESS "4.8.2")
     message(FATAL_ERROR "Insufficient gcc version")
   endif()
 elseif(CMAKE_CXX_COMPILER_ID STREQUAL "Clang")
   if(CMAKE_CXX_COMPILER_VERSION VERSION_LESS "3.8")
     message(FATAL_ERROR "Insufficient Clang version")
@@ -59,15 +77,18 @@
 elseif(CMAKE_CXX_COMPILER_ID STREQUAL "AppleClang")
   if(CMAKE_CXX_COMPILER_VERSION VERSION_LESS "8.1.0")
     message(FATAL_ERROR "Insufficient AppleClang version")
   endif()
   cmake_minimum_required(VERSION 3.16)
 elseif(MSVC)
   if(MSVC_VERSION LESS 1900)
-    message(FATAL_ERROR "The compiler ${CMAKE_CXX_COMPILER} doesn't support required C++11 features. Please use a newer MSVC.")
+    message(
+      FATAL_ERROR
+      "The compiler ${CMAKE_CXX_COMPILER} doesn't support required C++11 features. Please use a newer MSVC."
+    )
   endif()
   cmake_minimum_required(VERSION 3.8)
 endif()
 
 if(USE_SWIG)
   find_package(SWIG REQUIRED)
   find_package(Java REQUIRED)
@@ -80,60 +101,61 @@
   set(SWIG_MODULE_JAVA_LANGUAGE "JAVA")
   set(SWIG_MODULE_JAVA_SWIG_LANGUAGE_FLAG "java")
   set(CMAKE_SWIG_OUTDIR "${CMAKE_CURRENT_BINARY_DIR}/java")
   include_directories(Java_INCLUDE_DIRS)
   include_directories(JNI_INCLUDE_DIRS)
   include_directories($ENV{JAVA_HOME}/include)
   if(WIN32)
-      FILE(MAKE_DIRECTORY "${CMAKE_CURRENT_BINARY_DIR}/com/microsoft/ml/lightgbm/windows/x86_64")
+      file(MAKE_DIRECTORY "${CMAKE_CURRENT_BINARY_DIR}/com/microsoft/ml/lightgbm/windows/x86_64")
       include_directories($ENV{JAVA_HOME}/include/win32)
   elseif(APPLE)
-      FILE(MAKE_DIRECTORY "${CMAKE_CURRENT_BINARY_DIR}/com/microsoft/ml/lightgbm/osx/x86_64")
+      file(MAKE_DIRECTORY "${CMAKE_CURRENT_BINARY_DIR}/com/microsoft/ml/lightgbm/osx/x86_64")
       include_directories($ENV{JAVA_HOME}/include/darwin)
   else()
-      FILE(MAKE_DIRECTORY "${CMAKE_CURRENT_BINARY_DIR}/com/microsoft/ml/lightgbm/linux/x86_64")
+      file(MAKE_DIRECTORY "${CMAKE_CURRENT_BINARY_DIR}/com/microsoft/ml/lightgbm/linux/x86_64")
       include_directories($ENV{JAVA_HOME}/include/linux)
   endif()
-endif(USE_SWIG)
+endif()
 
-SET(EIGEN_DIR "${PROJECT_SOURCE_DIR}/external_libs/eigen")
+set(EIGEN_DIR "${PROJECT_SOURCE_DIR}/external_libs/eigen")
 include_directories(${EIGEN_DIR})
 
 # See https://gitlab.com/libeigen/eigen/-/blob/master/COPYING.README
-ADD_DEFINITIONS(-DEIGEN_MPL2_ONLY)
+add_definitions(-DEIGEN_MPL2_ONLY)
+add_definitions(-DEIGEN_DONT_PARALLELIZE)
 
 if(__BUILD_FOR_R)
     find_package(LibR REQUIRED)
     message(STATUS "LIBR_EXECUTABLE: ${LIBR_EXECUTABLE}")
     message(STATUS "LIBR_INCLUDE_DIRS: ${LIBR_INCLUDE_DIRS}")
     message(STATUS "LIBR_CORE_LIBRARY: ${LIBR_CORE_LIBRARY}")
     include_directories(${LIBR_INCLUDE_DIRS})
-    ADD_DEFINITIONS(-DLGB_R_BUILD)
-endif(__BUILD_FOR_R)
+    add_definitions(-DLGB_R_BUILD)
+endif()
 
 if(USE_TIMETAG)
-    ADD_DEFINITIONS(-DTIMETAG)
-endif(USE_TIMETAG)
+    add_definitions(-DTIMETAG)
+endif()
 
 if(USE_DEBUG)
-    ADD_DEFINITIONS(-DDEBUG)
-endif(USE_DEBUG)
+    add_definitions(-DDEBUG)
+endif()
 
 if(USE_MPI)
     find_package(MPI REQUIRED)
-    ADD_DEFINITIONS(-DUSE_MPI)
+    add_definitions(-DUSE_MPI)
 else()
-    ADD_DEFINITIONS(-DUSE_SOCKET)
-endif(USE_MPI)
+    add_definitions(-DUSE_SOCKET)
+endif()
 
 if(USE_CUDA)
-    SET(CMAKE_CUDA_HOST_COMPILER "${CMAKE_CXX_COMPILER}")
+    set(CMAKE_CUDA_HOST_COMPILER "${CMAKE_CXX_COMPILER}")
     enable_language(CUDA)
-    SET(USE_OPENMP ON CACHE BOOL "CUDA requires OpenMP" FORCE)
-endif(USE_CUDA)
+    set(USE_OPENMP ON CACHE BOOL "CUDA requires OpenMP" FORCE)
+endif()
 
 if(USE_OPENMP)
     if(APPLE)
         find_package(OpenMP)
         if(NOT OpenMP_FOUND)
             # libomp 15.0+ from brew is keg-only, so have to search in other locations.
             # See https://github.com/Homebrew/homebrew-core/issues/112107#issuecomment-1278042927.
@@ -150,174 +172,182 @@
     else()
         find_package(OpenMP REQUIRED)
     endif()
     set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} ${OpenMP_CXX_FLAGS}")
 endif()
 
 if(USE_GPU)
-    SET(BOOST_COMPUTE_HEADER_DIR ${PROJECT_SOURCE_DIR}/external_libs/compute/include)
+    set(BOOST_COMPUTE_HEADER_DIR ${PROJECT_SOURCE_DIR}/external_libs/compute/include)
     include_directories(${BOOST_COMPUTE_HEADER_DIR})
     find_package(OpenCL REQUIRED)
     include_directories(${OpenCL_INCLUDE_DIRS})
-    MESSAGE(STATUS "OpenCL include directory: " ${OpenCL_INCLUDE_DIRS})
+    message(STATUS "OpenCL include directory: " ${OpenCL_INCLUDE_DIRS})
     if(WIN32)
         set(Boost_USE_STATIC_LIBS ON)
     endif()
     find_package(Boost 1.56.0 COMPONENTS filesystem system REQUIRED)
     if(WIN32)
         # disable autolinking in boost
         add_definitions(-DBOOST_ALL_NO_LIB)
     endif()
     include_directories(${Boost_INCLUDE_DIRS})
-    ADD_DEFINITIONS(-DUSE_GPU)
-endif(USE_GPU)
+    add_definitions(-DUSE_GPU)
+endif()
 
 if(__INTEGRATE_OPENCL)
-    if(WIN32)
-        include(cmake/IntegratedOpenCL.cmake)
-        ADD_DEFINITIONS(-DUSE_GPU)
+    if(APPLE)
+        message(FATAL_ERROR "Integrated OpenCL build is not available on macOS")
     else()
-        message(FATAL_ERROR "Integrated OpenCL build is available only for Windows")
-    endif(WIN32)
-endif(__INTEGRATE_OPENCL)
+        include(cmake/IntegratedOpenCL.cmake)
+        add_definitions(-DUSE_GPU)
+    endif()
+endif()
 
 if(USE_CUDA)
-    find_package(CUDA 9.0 REQUIRED)
+    find_package(CUDA 10.0 REQUIRED)
     include_directories(${CUDA_INCLUDE_DIRS})
-    LIST(APPEND CMAKE_CUDA_FLAGS -Xcompiler=${OpenMP_CXX_FLAGS} -Xcompiler=-fPIC -Xcompiler=-Wall)
+    set(CMAKE_CUDA_FLAGS "${CMAKE_CUDA_FLAGS} -Xcompiler=${OpenMP_CXX_FLAGS} -Xcompiler=-fPIC -Xcompiler=-Wall")
 
     set(CUDA_ARCHS "6.0" "6.1" "6.2" "7.0")
     if(CUDA_VERSION VERSION_GREATER_EQUAL "10.0")
         list(APPEND CUDA_ARCHS "7.5")
     endif()
     if(CUDA_VERSION VERSION_GREATER_EQUAL "11.0")
         list(APPEND CUDA_ARCHS "8.0")
     endif()
     if(CUDA_VERSION VERSION_GREATER_EQUAL "11.1")
         list(APPEND CUDA_ARCHS "8.6")
     endif()
     list(POP_BACK CUDA_ARCHS CUDA_LAST_SUPPORTED_ARCH)
     list(APPEND CUDA_ARCHS "${CUDA_LAST_SUPPORTED_ARCH}+PTX")
-    CUDA_SELECT_NVCC_ARCH_FLAGS(CUDA_ARCH_FLAGS ${CUDA_ARCHS})
+    cuda_select_nvcc_arch_flags(CUDA_ARCH_FLAGS ${CUDA_ARCHS})
+    string(REPLACE ";" " " CUDA_ARCH_FLAGS "${CUDA_ARCH_FLAGS}")
 
-    LIST(APPEND CMAKE_CUDA_FLAGS ${CUDA_ARCH_FLAGS})
+    set(CMAKE_CUDA_FLAGS "${CMAKE_CUDA_FLAGS} ${CUDA_ARCH_FLAGS}")
     if(USE_DEBUG)
-      SET(CMAKE_CUDA_FLAGS "${CMAKE_CUDA_FLAGS} -g")
+      set(CMAKE_CUDA_FLAGS "${CMAKE_CUDA_FLAGS} -g")
     else()
-      SET(CMAKE_CUDA_FLAGS "${CMAKE_CUDA_FLAGS} -O3 -lineinfo")
+      set(CMAKE_CUDA_FLAGS "${CMAKE_CUDA_FLAGS} -O3 -lineinfo")
     endif()
-    string(REPLACE ";" " " CMAKE_CUDA_FLAGS "${CMAKE_CUDA_FLAGS}")
     message(STATUS "CMAKE_CUDA_FLAGS: ${CMAKE_CUDA_FLAGS}")
 
-    ADD_DEFINITIONS(-DUSE_CUDA)
+    add_definitions(-DUSE_CUDA)
+
     if(NOT DEFINED CMAKE_CUDA_STANDARD)
       set(CMAKE_CUDA_STANDARD 11)
       set(CMAKE_CUDA_STANDARD_REQUIRED ON)
     endif()
 
-    set(BASE_DEFINES
-     -DPOWER_FEATURE_WORKGROUPS=12
-     -DUSE_CONSTANT_BUF=0
+    set(
+      BASE_DEFINES
+      -DPOWER_FEATURE_WORKGROUPS=12
+      -DUSE_CONSTANT_BUF=0
     )
-    set(ALLFEATS_DEFINES
-     ${BASE_DEFINES}
-     -DENABLE_ALL_FEATURES
+    set(
+      ALLFEATS_DEFINES
+      ${BASE_DEFINES}
+      -DENABLE_ALL_FEATURES
     )
-    set(FULLDATA_DEFINES
-     ${ALLFEATS_DEFINES}
-     -DIGNORE_INDICES
+    set(
+      FULLDATA_DEFINES
+      ${ALLFEATS_DEFINES}
+      -DIGNORE_INDICES
     )
 
     message(STATUS "ALLFEATS_DEFINES: ${ALLFEATS_DEFINES}")
     message(STATUS "FULLDATA_DEFINES: ${FULLDATA_DEFINES}")
 
     function(add_histogram hsize hname hadd hconst hdir)
       add_library(histo${hsize}${hname} OBJECT src/treelearner/kernels/histogram${hsize}.cu)
       set_target_properties(histo${hsize}${hname} PROPERTIES CUDA_SEPARABLE_COMPILATION ON)
       set_target_properties(histo${hsize}${hname} PROPERTIES CUDA_ARCHITECTURES OFF)
       if(hadd)
         list(APPEND histograms histo${hsize}${hname})
         set(histograms ${histograms} PARENT_SCOPE)
       endif()
       target_compile_definitions(
-        histo${hsize}${hname} PRIVATE
+        histo${hsize}${hname}
+        PRIVATE
         -DCONST_HESSIAN=${hconst}
         ${hdir}
       )
     endfunction()
 
     foreach(hsize _16_64_256)
       add_histogram("${hsize}" "_sp_const" "True" "1" "${BASE_DEFINES}")
       add_histogram("${hsize}" "_sp" "True" "0" "${BASE_DEFINES}")
       add_histogram("${hsize}" "-allfeats_sp_const" "False" "1" "${ALLFEATS_DEFINES}")
       add_histogram("${hsize}" "-allfeats_sp" "False" "0" "${ALLFEATS_DEFINES}")
       add_histogram("${hsize}" "-fulldata_sp_const" "True" "1" "${FULLDATA_DEFINES}")
       add_histogram("${hsize}" "-fulldata_sp" "True" "0" "${FULLDATA_DEFINES}")
     endforeach()
-endif(USE_CUDA)
+endif()
 
 if(USE_HDFS)
     find_package(JNI REQUIRED)
     find_path(HDFS_INCLUDE_DIR hdfs.h REQUIRED)
     find_library(HDFS_LIB NAMES hdfs REQUIRED)
     include_directories(${HDFS_INCLUDE_DIR})
-    ADD_DEFINITIONS(-DUSE_HDFS)
-    SET(HDFS_CXX_LIBRARIES ${HDFS_LIB} ${JAVA_JVM_LIBRARY})
-endif(USE_HDFS)
+    add_definitions(-DUSE_HDFS)
+    set(HDFS_CXX_LIBRARIES ${HDFS_LIB} ${JAVA_JVM_LIBRARY})
+endif()
 
 include(CheckCXXSourceCompiles)
 check_cxx_source_compiles("
 #include <xmmintrin.h>
 int main() {
   int a = 0;
   _mm_prefetch(&a, _MM_HINT_NTA);
   return 0;
 }
 " MM_PREFETCH)
 
 if(${MM_PREFETCH})
   message(STATUS "Using _mm_prefetch")
-  ADD_DEFINITIONS(-DMM_PREFETCH)
+  add_definitions(-DMM_PREFETCH)
 endif()
 
 include(CheckCXXSourceCompiles)
 check_cxx_source_compiles("
 #include <mm_malloc.h>
 int main() {
   char *a = (char*)_mm_malloc(8, 16);
   _mm_free(a);
   return 0;
 }
 " MM_MALLOC)
 
 if(${MM_MALLOC})
   message(STATUS "Using _mm_malloc")
-  ADD_DEFINITIONS(-DMM_MALLOC)
+  add_definitions(-DMM_MALLOC)
 endif()
 
 if(UNIX OR MINGW OR CYGWIN)
-    SET(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -std=c++11 -pthread -Wextra -Wall -Wno-ignored-attributes -Wno-unknown-pragmas -Wno-return-type")
-    if(USE_DEBUG)
-        SET(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -g -O0")
-    else()
-        SET(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -O3")
-    endif()
-    if(USE_SWIG)
-        SET(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -fno-strict-aliasing")
-    endif()
-    if(NOT USE_OPENMP)
-        SET(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -Wno-unknown-pragmas -Wno-unused-private-field")
-    endif()
-    if(__BUILD_FOR_R AND CMAKE_CXX_COMPILER_ID STREQUAL "GNU")
-        SET(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -Wno-cast-function-type")
-    endif()
+  set(
+    CMAKE_CXX_FLAGS
+    "${CMAKE_CXX_FLAGS} -std=c++11 -pthread -Wextra -Wall -Wno-ignored-attributes -Wno-unknown-pragmas -Wno-return-type"
+  )
+  if(USE_DEBUG)
+      set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -g -O0")
+  else()
+      set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -O3")
+  endif()
+  if(USE_SWIG)
+      set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -fno-strict-aliasing")
+  endif()
+  if(NOT USE_OPENMP)
+      set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -Wno-unknown-pragmas -Wno-unused-private-field")
+  endif()
+  if(__BUILD_FOR_R AND CMAKE_CXX_COMPILER_ID STREQUAL "GNU")
+      set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -Wno-cast-function-type")
+  endif()
 endif()
 
 if(WIN32 AND MINGW)
-    SET(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -static-libstdc++")
+    set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -static-libstdc++")
 endif()
 
 # Check if inet_pton is already available, to avoid conflicts with the implementation in LightGBM.
 # As of 2022, MinGW started including a definition of inet_pton.
 if(WIN32)
   include(CheckSymbolExists)
   list(APPEND CMAKE_REQUIRED_LIBRARIES "ws2_32")
@@ -325,189 +355,255 @@
   if(WIN_INET_PTON_FOUND)
     add_definitions(-DWIN_HAS_INET_PTON)
   endif()
   list(REMOVE_ITEM CMAKE_REQUIRED_LIBRARIES "ws2_32")
 endif()
 
 if(MSVC)
-    SET(variables
+    set(
+      variables
         CMAKE_C_FLAGS_DEBUG
         CMAKE_C_FLAGS_MINSIZEREL
         CMAKE_C_FLAGS_RELEASE
         CMAKE_C_FLAGS_RELWITHDEBINFO
         CMAKE_CXX_FLAGS_DEBUG
         CMAKE_CXX_FLAGS_MINSIZEREL
         CMAKE_CXX_FLAGS_RELEASE
         CMAKE_CXX_FLAGS_RELWITHDEBINFO
     )
-    SET(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} /W4 /MP")
+    set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} /W4 /MP")
     if(USE_DEBUG)
-        SET(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} /Od")
+        set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} /Od")
     else()
-        SET(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} /O2 /Ob2 /Oi /Ot /Oy")
+        set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} /O2 /Ob2 /Oi /Ot /Oy")
     endif()
 else()
+    if(NOT BUILD_STATIC_LIB)
+      set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -fPIC")
+    endif()
     if(NOT USE_DEBUG)
-      SET(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -fPIC -funroll-loops")
+      set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -funroll-loops")
     endif()
-endif(MSVC)
+endif()
 
-SET(LightGBM_HEADER_DIR ${PROJECT_SOURCE_DIR}/include)
+set(LightGBM_HEADER_DIR ${PROJECT_SOURCE_DIR}/include)
 
-SET(EXECUTABLE_OUTPUT_PATH ${PROJECT_SOURCE_DIR})
-SET(LIBRARY_OUTPUT_PATH ${PROJECT_SOURCE_DIR})
+set(EXECUTABLE_OUTPUT_PATH ${PROJECT_SOURCE_DIR})
+set(LIBRARY_OUTPUT_PATH ${PROJECT_SOURCE_DIR})
 
 include_directories(${LightGBM_HEADER_DIR})
 
 if(APPLE)
   if(APPLE_OUTPUT_DYLIB)
-    SET(CMAKE_SHARED_LIBRARY_SUFFIX ".dylib")
+    set(CMAKE_SHARED_LIBRARY_SUFFIX ".dylib")
   else()
-    SET(CMAKE_SHARED_LIBRARY_SUFFIX ".so")
+    set(CMAKE_SHARED_LIBRARY_SUFFIX ".so")
   endif()
-endif(APPLE)
+endif()
 
 if(USE_MPI)
   include_directories(${MPI_CXX_INCLUDE_PATH})
-endif(USE_MPI)
+endif()
 
-file(GLOB SOURCES
-    src/boosting/*.cpp
-    src/io/*.cpp
-    src/metric/*.cpp
-    src/objective/*.cpp
-    src/network/*.cpp
-    src/treelearner/*.cpp
+file(
+    GLOB
+    SOURCES
+      src/boosting/*.cpp
+      src/io/*.cpp
+      src/metric/*.cpp
+      src/objective/*.cpp
+      src/network/*.cpp
+      src/treelearner/*.cpp
 if(USE_CUDA)
-    src/treelearner/*.cu
-endif(USE_CUDA)
+      src/treelearner/*.cu
+      src/boosting/cuda/*.cpp
+      src/boosting/cuda/*.cu
+      src/metric/cuda/*.cpp
+      src/metric/cuda/*.cu
+      src/objective/cuda/*.cpp
+      src/objective/cuda/*.cu
+      src/treelearner/cuda/*.cpp
+      src/treelearner/cuda/*.cu
+      src/io/cuda/*.cu
+      src/io/cuda/*.cpp
+      src/cuda/*.cpp
+      src/cuda/*.cu
+endif()
 )
 
-add_executable(lightgbm src/main.cpp src/application/application.cpp ${SOURCES})
-list(APPEND SOURCES "src/c_api.cpp")
+add_library(lightgbm_objs OBJECT ${SOURCES})
+
+if(BUILD_CLI)
+    add_executable(lightgbm src/main.cpp src/application/application.cpp)
+    target_link_libraries(lightgbm PRIVATE lightgbm_objs)
+endif()
 
+set(API_SOURCES "src/c_api.cpp")
 # Only build the R part of the library if building for
 # use with the R package
 if(__BUILD_FOR_R)
-  list(APPEND SOURCES "src/lightgbm_R.cpp")
-endif(__BUILD_FOR_R)
+  list(APPEND API_SOURCES "src/lightgbm_R.cpp")
+endif()
+
+add_library(lightgbm_capi_objs OBJECT ${API_SOURCES})
 
 if(BUILD_STATIC_LIB)
-  add_library(_lightgbm STATIC ${SOURCES})
+  add_library(_lightgbm STATIC)
 else()
-  add_library(_lightgbm SHARED ${SOURCES})
-endif(BUILD_STATIC_LIB)
+  add_library(_lightgbm SHARED)
+endif()
+# LightGBM headers include openmp, cuda, R etc. headers,
+# thus PUBLIC is required for building _lightgbm_swig target.
+target_link_libraries(_lightgbm PUBLIC lightgbm_capi_objs lightgbm_objs)
 
 if(MSVC)
   set_target_properties(_lightgbm PROPERTIES OUTPUT_NAME "lib_lightgbm")
-endif(MSVC)
+endif()
 
 if(USE_SWIG)
   set_property(SOURCE swig/lightgbmlib.i PROPERTY CPLUSPLUS ON)
-  LIST(APPEND swig_options -package com.microsoft.ml.lightgbm)
+  list(APPEND swig_options -package com.microsoft.ml.lightgbm)
   set_property(SOURCE swig/lightgbmlib.i PROPERTY SWIG_FLAGS "${swig_options}")
-  swig_add_module(_lightgbm_swig java swig/lightgbmlib.i)
+  swig_add_library(_lightgbm_swig LANGUAGE java SOURCES swig/lightgbmlib.i)
   swig_link_libraries(_lightgbm_swig _lightgbm)
   # needed to ensure Linux build does not have lib prefix specified twice, e.g. liblib_lightgbm_swig
   set_target_properties(_lightgbm_swig PROPERTIES PREFIX "")
   # needed in some versions of CMake for VS and MinGW builds to ensure output dll has lib prefix
   set_target_properties(_lightgbm_swig PROPERTIES OUTPUT_NAME "lib_lightgbm_swig")
   if(WIN32)
     if(MINGW OR CYGWIN)
-        add_custom_command(TARGET _lightgbm_swig POST_BUILD
+        add_custom_command(
+            TARGET _lightgbm_swig
+            POST_BUILD
             COMMAND "${Java_JAVAC_EXECUTABLE}" -d . java/*.java
-            COMMAND "${CMAKE_COMMAND}" -E copy_if_different "${PROJECT_SOURCE_DIR}/lib_lightgbm.dll" com/microsoft/ml/lightgbm/windows/x86_64
-            COMMAND "${CMAKE_COMMAND}" -E copy_if_different "${PROJECT_SOURCE_DIR}/lib_lightgbm_swig.dll" com/microsoft/ml/lightgbm/windows/x86_64
-            COMMAND "${Java_JAR_EXECUTABLE}" -cf lightgbmlib.jar com)
+            COMMAND
+              "${CMAKE_COMMAND}"
+              -E
+              copy_if_different
+              "${PROJECT_SOURCE_DIR}/lib_lightgbm.dll"
+              com/microsoft/ml/lightgbm/windows/x86_64
+            COMMAND
+              "${CMAKE_COMMAND}"
+              -E
+              copy_if_different
+              "${PROJECT_SOURCE_DIR}/lib_lightgbm_swig.dll"
+              com/microsoft/ml/lightgbm/windows/x86_64
+            COMMAND "${Java_JAR_EXECUTABLE}" -cf lightgbmlib.jar com
+        )
     else()
-        add_custom_command(TARGET _lightgbm_swig POST_BUILD
+        add_custom_command(
+            TARGET _lightgbm_swig
+            POST_BUILD
             COMMAND "${Java_JAVAC_EXECUTABLE}" -d . java/*.java
             COMMAND cp "${PROJECT_SOURCE_DIR}/Release/*.dll" com/microsoft/ml/lightgbm/windows/x86_64
-            COMMAND "${Java_JAR_EXECUTABLE}" -cf lightgbmlib.jar com)
+            COMMAND "${Java_JAR_EXECUTABLE}" -cf lightgbmlib.jar com
+        )
     endif()
   elseif(APPLE)
-    add_custom_command(TARGET _lightgbm_swig POST_BUILD
-            COMMAND "${Java_JAVAC_EXECUTABLE}" -d . java/*.java
-            COMMAND cp "${PROJECT_SOURCE_DIR}/*.dylib" com/microsoft/ml/lightgbm/osx/x86_64
-            COMMAND cp "${PROJECT_SOURCE_DIR}/lib_lightgbm_swig.jnilib" com/microsoft/ml/lightgbm/osx/x86_64/lib_lightgbm_swig.dylib
-            COMMAND "${Java_JAR_EXECUTABLE}" -cf lightgbmlib.jar com)
+    add_custom_command(
+        TARGET _lightgbm_swig
+        POST_BUILD
+        COMMAND "${Java_JAVAC_EXECUTABLE}" -d . java/*.java
+        COMMAND cp "${PROJECT_SOURCE_DIR}/*.dylib" com/microsoft/ml/lightgbm/osx/x86_64
+        COMMAND
+          cp
+          "${PROJECT_SOURCE_DIR}/lib_lightgbm_swig.jnilib"
+          com/microsoft/ml/lightgbm/osx/x86_64/lib_lightgbm_swig.dylib
+        COMMAND "${Java_JAR_EXECUTABLE}" -cf lightgbmlib.jar com
+    )
   else()
-    add_custom_command(TARGET _lightgbm_swig POST_BUILD
-      COMMAND "${Java_JAVAC_EXECUTABLE}" -d . java/*.java
-      COMMAND cp "${PROJECT_SOURCE_DIR}/*.so" com/microsoft/ml/lightgbm/linux/x86_64
-      COMMAND "${Java_JAR_EXECUTABLE}" -cf lightgbmlib.jar com)
+    add_custom_command(
+        TARGET _lightgbm_swig
+        POST_BUILD
+        COMMAND "${Java_JAVAC_EXECUTABLE}" -d . java/*.java
+        COMMAND cp "${PROJECT_SOURCE_DIR}/*.so" com/microsoft/ml/lightgbm/linux/x86_64
+        COMMAND "${Java_JAR_EXECUTABLE}" -cf lightgbmlib.jar com
+    )
   endif()
-endif(USE_SWIG)
+endif()
 
 if(USE_MPI)
-  TARGET_LINK_LIBRARIES(lightgbm ${MPI_CXX_LIBRARIES})
-  TARGET_LINK_LIBRARIES(_lightgbm ${MPI_CXX_LIBRARIES})
-endif(USE_MPI)
+  target_link_libraries(lightgbm_objs PUBLIC ${MPI_CXX_LIBRARIES})
+endif()
 
 if(USE_OPENMP)
-    if(CMAKE_CXX_COMPILER_ID STREQUAL "AppleClang")
-        TARGET_LINK_LIBRARIES(lightgbm OpenMP::OpenMP_CXX)
-        TARGET_LINK_LIBRARIES(_lightgbm OpenMP::OpenMP_CXX)
-    endif()
-endif(USE_OPENMP)
+  if(CMAKE_CXX_COMPILER_ID STREQUAL "AppleClang")
+    target_link_libraries(lightgbm_objs PUBLIC OpenMP::OpenMP_CXX)
+    # c_api headers also includes OpenMP headers, thus compiling
+    # lightgbm_capi_objs needs include directory for OpenMP.
+    # Specifying OpenMP in target_link_libraries will get include directory
+    # requirements for compilation.
+    # This uses CMake's Transitive Usage Requirements. Refer to CMake doc:
+    # https://cmake.org/cmake/help/v3.16/manual/cmake-buildsystem.7.html#transitive-usage-requirements
+    target_link_libraries(lightgbm_capi_objs PUBLIC OpenMP::OpenMP_CXX)
+  endif()
+endif()
 
 if(USE_GPU)
-  TARGET_LINK_LIBRARIES(lightgbm ${OpenCL_LIBRARY} ${Boost_LIBRARIES})
-  TARGET_LINK_LIBRARIES(_lightgbm ${OpenCL_LIBRARY} ${Boost_LIBRARIES})
-endif(USE_GPU)
+  target_link_libraries(lightgbm_objs PUBLIC ${OpenCL_LIBRARY} ${Boost_LIBRARIES})
+endif()
 
 if(__INTEGRATE_OPENCL)
   # targets OpenCL and Boost are added in IntegratedOpenCL.cmake
-  add_dependencies(lightgbm OpenCL Boost)
-  add_dependencies(_lightgbm OpenCL Boost)
+  add_dependencies(lightgbm_objs OpenCL Boost)
   # variables INTEGRATED_OPENCL_* are set in IntegratedOpenCL.cmake
-  target_include_directories(lightgbm PRIVATE ${INTEGRATED_OPENCL_INCLUDES})
-  target_include_directories(_lightgbm PRIVATE ${INTEGRATED_OPENCL_INCLUDES})
-  target_compile_definitions(lightgbm PRIVATE ${INTEGRATED_OPENCL_DEFINITIONS})
-  target_compile_definitions(_lightgbm PRIVATE ${INTEGRATED_OPENCL_DEFINITIONS})
-  target_link_libraries(lightgbm PRIVATE ${INTEGRATED_OPENCL_LIBRARIES})
-  target_link_libraries(_lightgbm PRIVATE ${INTEGRATED_OPENCL_LIBRARIES})
+  target_include_directories(lightgbm_objs PRIVATE ${INTEGRATED_OPENCL_INCLUDES})
+  target_compile_definitions(lightgbm_objs PRIVATE ${INTEGRATED_OPENCL_DEFINITIONS})
+  target_link_libraries(lightgbm_objs PUBLIC ${INTEGRATED_OPENCL_LIBRARIES} ${CMAKE_DL_LIBS})
 endif()
 
 if(USE_CUDA)
-  set_target_properties(lightgbm PROPERTIES CUDA_RESOLVE_DEVICE_SYMBOLS ON)
-  set_target_properties(lightgbm PROPERTIES CUDA_ARCHITECTURES OFF)
-  TARGET_LINK_LIBRARIES(
-    lightgbm
-    ${histograms}
-  )
-  set_target_properties(_lightgbm PROPERTIES CUDA_RESOLVE_DEVICE_SYMBOLS ON)
+  # Disable cmake warning about policy CMP0104. Refer to issue #3754 and PR #4268.
+  # Custom target properties does not propagate, thus we need to specify for
+  # each target that contains or depends on cuda source.
+  set_target_properties(lightgbm_objs PROPERTIES CUDA_ARCHITECTURES OFF)
   set_target_properties(_lightgbm PROPERTIES CUDA_ARCHITECTURES OFF)
-  TARGET_LINK_LIBRARIES(
-    _lightgbm
-    ${histograms}
-  )
-endif(USE_CUDA)
+  if(BUILD_CLI)
+    set_target_properties(lightgbm PROPERTIES CUDA_ARCHITECTURES OFF)
+  endif()
+
+  set_target_properties(lightgbm_objs PROPERTIES CUDA_SEPARABLE_COMPILATION ON)
+
+  # Device linking is not supported for object libraries.
+  # Thus we have to specify them on final targets.
+  if(BUILD_CLI)
+    set_target_properties(lightgbm PROPERTIES CUDA_RESOLVE_DEVICE_SYMBOLS ON)
+  endif()
+  set_target_properties(_lightgbm PROPERTIES CUDA_RESOLVE_DEVICE_SYMBOLS ON)
+
+  # histograms are list of object libraries. Linking object library to other
+  # object libraries only gets usage requirements, the linked objects won't be
+  # used. Thus we have to call target_link_libraries on final targets here.
+  if(BUILD_CLI)
+    target_link_libraries(lightgbm PRIVATE ${histograms})
+  endif()
+  target_link_libraries(_lightgbm PRIVATE ${histograms})
+endif()
 
 if(USE_HDFS)
-  TARGET_LINK_LIBRARIES(lightgbm ${HDFS_CXX_LIBRARIES})
-  TARGET_LINK_LIBRARIES(_lightgbm ${HDFS_CXX_LIBRARIES})
-endif(USE_HDFS)
+  target_link_libraries(lightgbm_objs PUBLIC ${HDFS_CXX_LIBRARIES})
+endif()
 
 if(WIN32)
     if(MINGW OR CYGWIN)
-      TARGET_LINK_LIBRARIES(lightgbm Ws2_32)
-      TARGET_LINK_LIBRARIES(_lightgbm Ws2_32)
-      TARGET_LINK_LIBRARIES(lightgbm IPHLPAPI)
-      TARGET_LINK_LIBRARIES(_lightgbm IPHLPAPI)
-    endif(MINGW OR CYGWIN)
-endif(WIN32)
+      target_link_libraries(lightgbm_objs PUBLIC ws2_32 iphlpapi)
+    endif()
+endif()
 
 if(__BUILD_FOR_R)
+  # utils/log.h and capi uses R headers, thus both object libraries need to link
+  # with R lib.
   if(MSVC)
-    TARGET_LINK_LIBRARIES(_lightgbm ${LIBR_MSVC_CORE_LIBRARY})
+    set(R_LIB ${LIBR_MSVC_CORE_LIBRARY})
   else()
-    TARGET_LINK_LIBRARIES(_lightgbm ${LIBR_CORE_LIBRARY})
-  endif(MSVC)
-endif(__BUILD_FOR_R)
+    set(R_LIB ${LIBR_CORE_LIBRARY})
+  endif()
+  target_link_libraries(lightgbm_objs PUBLIC ${R_LIB})
+  target_link_libraries(lightgbm_capi_objs PUBLIC ${R_LIB})
+endif()
 
 #-- Google C++ tests
 if(BUILD_CPP_TEST)
   find_package(GTest CONFIG)
   if(NOT GTEST_FOUND)
     message(STATUS "Did not find Google Test in the system root. Fetching Google Test now...")
     include(FetchContent)
@@ -515,32 +611,51 @@
       googletest
       GIT_REPOSITORY https://github.com/google/googletest.git
       GIT_TAG        release-1.11.0
     )
     FetchContent_MakeAvailable(googletest)
     add_library(GTest::GTest ALIAS gtest)
   endif()
+
+  set(LightGBM_TEST_HEADER_DIR ${PROJECT_SOURCE_DIR}/tests/cpp_tests)
+  include_directories(${LightGBM_TEST_HEADER_DIR})
+
   file(GLOB CPP_TEST_SOURCES tests/cpp_tests/*.cpp)
   if(MSVC)
     set(
       CompilerFlags
         CMAKE_CXX_FLAGS
         CMAKE_CXX_FLAGS_DEBUG
         CMAKE_CXX_FLAGS_RELEASE
         CMAKE_C_FLAGS
         CMAKE_C_FLAGS_DEBUG
         CMAKE_C_FLAGS_RELEASE
     )
     foreach(CompilerFlag ${CompilerFlags})
       string(REPLACE "/MD" "/MT" ${CompilerFlag} "${${CompilerFlag}}")
     endforeach()
-  endif(MSVC)
-  add_executable(testlightgbm ${CPP_TEST_SOURCES} ${SOURCES})
-  target_link_libraries(testlightgbm PRIVATE GTest::GTest)
+  endif()
+  add_executable(testlightgbm ${CPP_TEST_SOURCES})
+  target_link_libraries(testlightgbm PRIVATE lightgbm_objs lightgbm_capi_objs GTest::GTest)
+endif()
+
+if(BUILD_CLI)
+    install(
+      TARGETS lightgbm
+      RUNTIME DESTINATION ${CMAKE_INSTALL_PREFIX}/bin
+    )
 endif()
 
-install(TARGETS lightgbm _lightgbm
-        RUNTIME DESTINATION ${CMAKE_INSTALL_PREFIX}/bin
-        LIBRARY DESTINATION ${CMAKE_INSTALL_PREFIX}/lib
-        ARCHIVE DESTINATION ${CMAKE_INSTALL_PREFIX}/lib)
+if(__BUILD_FOR_PYTHON)
+    set(CMAKE_INSTALL_PREFIX "lightgbm")
+endif()
 
-install(DIRECTORY ${LightGBM_HEADER_DIR}/LightGBM DESTINATION ${CMAKE_INSTALL_PREFIX}/include)
+install(
+  TARGETS _lightgbm
+  RUNTIME DESTINATION ${CMAKE_INSTALL_PREFIX}/bin
+  LIBRARY DESTINATION ${CMAKE_INSTALL_PREFIX}/lib
+  ARCHIVE DESTINATION ${CMAKE_INSTALL_PREFIX}/lib
+)
+
+if(INSTALL_HEADERS)
+    install(DIRECTORY ${LightGBM_HEADER_DIR}/LightGBM DESTINATION ${CMAKE_INSTALL_PREFIX}/include)
+endif()
```

### Comparing `lightgbm-3.3.5/compile/cmake/IntegratedOpenCL.cmake` & `lightgbm-4.0.0/cmake/IntegratedOpenCL.cmake`

 * *Files 25% similar despite different names*

```diff
@@ -22,64 +22,172 @@
 set(OPENCL_ICD_LOADER_HEADERS_DIR ${opencl-headers_SOURCE_DIR} CACHE PATH "") # for OpenCL ICD Loader
 set(OpenCL_INCLUDE_DIR ${opencl-headers_SOURCE_DIR} CACHE PATH "") # for Boost::Compute
 
 FetchContent_Declare(OpenCL-ICD-Loader GIT_REPOSITORY ${OPENCL_LOADER_REPOSITORY} GIT_TAG ${OPENCL_LOADER_TAG})
 FetchContent_GetProperties(OpenCL-ICD-Loader)
 if(NOT OpenCL-ICD-Loader_POPULATED)
   FetchContent_Populate(OpenCL-ICD-Loader)
-  set(USE_DYNAMIC_VCXX_RUNTIME ON)
+  if(WIN32)
+    set(USE_DYNAMIC_VCXX_RUNTIME ON)
+  endif()
   add_subdirectory(${opencl-icd-loader_SOURCE_DIR} ${opencl-icd-loader_BINARY_DIR} EXCLUDE_FROM_ALL)
   message(STATUS "Populated OpenCL ICD Loader")
 endif()
 list(APPEND INTEGRATED_OPENCL_INCLUDES ${OPENCL_ICD_LOADER_HEADERS_DIR})
-list(APPEND INTEGRATED_OPENCL_LIBRARIES ${opencl-icd-loader_BINARY_DIR}/Release/OpenCL.lib cfgmgr32.lib runtimeobject.lib)
 list(APPEND INTEGRATED_OPENCL_DEFINITIONS CL_TARGET_OPENCL_VERSION=120)
+if(WIN32)
+  list(
+    APPEND
+    INTEGRATED_OPENCL_LIBRARIES
+      ${opencl-icd-loader_BINARY_DIR}/Release/OpenCL.lib
+      cfgmgr32.lib
+      runtimeobject.lib
+  )
+else()
+  list(
+    APPEND
+    INTEGRATED_OPENCL_LIBRARIES
+      ${opencl-icd-loader_BINARY_DIR}/libOpenCL.a
+  )
+  set_property(TARGET OpenCL PROPERTY POSITION_INDEPENDENT_CODE ON)
+endif()
 
 # Build Independent Boost libraries
 include(ExternalProject)
 include(ProcessorCount)
 ProcessorCount(J)
 set(BOOST_BASE "${PROJECT_BINARY_DIR}/Boost")
-set(BOOST_BOOTSTRAP "${BOOST_BASE}/source/bootstrap.bat")
-set(BOOST_BUILD "${BOOST_BASE}/source/b2.exe")
-set(BOOST_FLAGS "")
-list(APPEND BOOST_SUBMODULES "libs/algorithm" "libs/align" "libs/any" "libs/array" "libs/assert" "libs/bind" "libs/chrono" "libs/compute" "libs/concept_check" "libs/config" "libs/container" "libs/container_hash" "libs/core" "libs/detail" "libs/filesystem" "libs/foreach" "libs/format" "libs/function" "libs/function_types" "libs/fusion" "libs/headers" "libs/integer" "libs/io" "libs/iterator" "libs/lexical_cast" "libs/math" "libs/move" "libs/mpl" "libs/multi_index" "libs/numeric/conversion" "libs/optional" "libs/predef" "libs/preprocessor" "libs/property_tree" "libs/range" "libs/ratio" "libs/serialization" "libs/smart_ptr" "libs/static_assert" "libs/system" "libs/throw_exception" "libs/tuple" "libs/typeof" "libs/type_index" "libs/type_traits" "libs/utility" "libs/uuid" "libs/winapi" "tools/boost_install" "tools/build")
-ExternalProject_Add(Boost
+set(BOOST_INCLUDE "${BOOST_BASE}/source" CACHE PATH "")
+set(BOOST_LIBRARY "${BOOST_BASE}/source/stage/lib" CACHE PATH "")
+if(WIN32)
+  if(MSVC)
+    if(${MSVC_VERSION} GREATER 1929)
+      message(FATAL_ERROR "Unrecognized MSVC version number: ${MSVC_VERSION}")
+    elseif(${MSVC_VERSION} GREATER 1919)
+      set(MSVC_TOOLCHAIN_ID "142")
+    elseif(${MSVC_VERSION} GREATER 1909)
+      set(MSVC_TOOLCHAIN_ID "141")
+    elseif(${MSVC_VERSION} GREATER 1899)
+      set(MSVC_TOOLCHAIN_ID "140")
+    else()
+      message(FATAL_ERROR "Unrecognized MSVC version number: ${MSVC_VERSION}")
+    endif()
+    list(
+      APPEND
+        BOOST_BUILD_BYPRODUCTS
+          ${BOOST_LIBRARY}/libboost_filesystem-vc${MSVC_TOOLCHAIN_ID}-mt-x64-${BOOST_VERSION_UNDERSCORE}.lib
+          ${BOOST_LIBRARY}/libboost_system-vc${MSVC_TOOLCHAIN_ID}-mt-x64-${BOOST_VERSION_UNDERSCORE}.lib
+          ${BOOST_LIBRARY}/libboost_chrono-vc${MSVC_TOOLCHAIN_ID}-mt-x64-${BOOST_VERSION_UNDERSCORE}.lib
+    )
+  else()
+    message(FATAL_ERROR "Integrated OpenCL build is not yet available for MinGW")
+  endif()
+  set(BOOST_BOOTSTRAP "${BOOST_BASE}/source/bootstrap.bat")
+  set(BOOST_BUILD "${BOOST_BASE}/source/b2.exe")
+  set(BOOST_FLAGS "")
+else()
+  set(BOOST_BOOTSTRAP "${BOOST_BASE}/source/bootstrap.sh")
+  set(BOOST_BUILD "${BOOST_BASE}/source/b2")
+  set(BOOST_FLAGS "-fPIC")
+  list(
+    APPEND
+    BOOST_BUILD_BYPRODUCTS
+      ${BOOST_LIBRARY}/libboost_filesystem.a
+      ${BOOST_LIBRARY}/libboost_system.a
+      ${BOOST_LIBRARY}/libboost_chrono.a
+  )
+endif()
+list(
+  APPEND
+  BOOST_SUBMODULES
+    "libs/algorithm"
+    "libs/align"
+    "libs/any"
+    "libs/array"
+    "libs/assert"
+    "libs/bind"
+    "libs/chrono"
+    "libs/compute"
+    "libs/concept_check"
+    "libs/config"
+    "libs/container"
+    "libs/container_hash"
+    "libs/core"
+    "libs/detail"
+    "libs/filesystem"
+    "libs/foreach"
+    "libs/format"
+    "libs/function"
+    "libs/function_types"
+    "libs/fusion"
+    "libs/headers"
+    "libs/integer"
+    "libs/io"
+    "libs/iterator"
+    "libs/lexical_cast"
+    "libs/math"
+    "libs/move"
+    "libs/mpl"
+    "libs/multi_index"
+    "libs/numeric/conversion"
+    "libs/optional"
+    "libs/predef"
+    "libs/preprocessor"
+    "libs/property_tree"
+    "libs/range"
+    "libs/ratio"
+    "libs/serialization"
+    "libs/smart_ptr"
+    "libs/static_assert"
+    "libs/system"
+    "libs/throw_exception"
+    "libs/tuple"
+    "libs/typeof"
+    "libs/type_index"
+    "libs/type_traits"
+    "libs/utility"
+    "libs/uuid"
+    "libs/winapi"
+    "tools/boost_install"
+    "tools/build"
+)
+ExternalProject_Add(
+  Boost
   TMP_DIR "${BOOST_BASE}/tmp"
   STAMP_DIR "${BOOST_BASE}/stamp"
   DOWNLOAD_DIR "${BOOST_BASE}/download"
   SOURCE_DIR "${BOOST_BASE}/source"
   BINARY_DIR "${BOOST_BASE}/source"
   INSTALL_DIR "${BOOST_BASE}/install"
   GIT_REPOSITORY ${BOOST_REPOSITORY}
   GIT_TAG ${BOOST_TAG}
   GIT_SUBMODULES ${BOOST_SUBMODULES}
   GIT_SHALLOW ON
   UPDATE_COMMAND ""
   PATCH_COMMAND ""
   CONFIGURE_COMMAND ${BOOST_BOOTSTRAP}
-  BUILD_COMMAND ${BOOST_BUILD} -sBOOST_ROOT=${BOOST_BASE}/source -a -q -j ${J} --with-headers --with-chrono --with-filesystem --with-system link=static runtime-link=shared variant=release threading=multi cxxflags="${BOOST_FLAGS}"
+  BUILD_COMMAND
+    ${BOOST_BUILD}
+    -sBOOST_ROOT=${BOOST_BASE}/source
+    -a
+    -q
+    -j ${J}
+    --with-headers
+    --with-chrono
+    --with-filesystem
+    --with-system
+    link=static
+    runtime-link=shared
+    variant=release
+    threading=multi
+    cxxflags="${BOOST_FLAGS}"
   INSTALL_COMMAND ""
+  # BUILD_BYPRODUCTS is necessary to support 'Ninja' builds.
+  # ref:
+  #  - https://cmake.org/cmake/help/latest/module/ExternalProject.html
+  #  - https://stackoverflow.com/a/65803911/3986677
+  BUILD_BYPRODUCTS ${BOOST_BUILD_BYPRODUCTS}
 )
-set(BOOST_INCLUDE "${BOOST_BASE}/source" CACHE PATH "")
-set(BOOST_LIBRARY "${BOOST_BASE}/source/stage/lib" CACHE PATH "")
 list(APPEND INTEGRATED_OPENCL_INCLUDES ${BOOST_INCLUDE})
-if(MSVC)
-  if(${MSVC_VERSION} GREATER 1929)
-    message(FATAL_ERROR "Unrecognized MSVC version number: ${MSVC_VERSION}")
-  elseif(${MSVC_VERSION} GREATER 1919)
-    set(MSVC_TOOLCHAIN_ID "142")
-  elseif(${MSVC_VERSION} GREATER 1909)
-    set(MSVC_TOOLCHAIN_ID "141")
-  elseif(${MSVC_VERSION} GREATER 1899)
-    set(MSVC_TOOLCHAIN_ID "140")
-  else()
-    message(FATAL_ERROR "Unrecognized MSVC version number: ${MSVC_VERSION}")
-  endif()
-  list(APPEND INTEGRATED_OPENCL_LIBRARIES ${BOOST_LIBRARY}/libboost_filesystem-vc${MSVC_TOOLCHAIN_ID}-mt-x64-${BOOST_VERSION_UNDERSCORE}.lib)
-  list(APPEND INTEGRATED_OPENCL_LIBRARIES ${BOOST_LIBRARY}/libboost_system-vc${MSVC_TOOLCHAIN_ID}-mt-x64-${BOOST_VERSION_UNDERSCORE}.lib)
-  list(APPEND INTEGRATED_OPENCL_LIBRARIES ${BOOST_LIBRARY}/libboost_chrono-vc${MSVC_TOOLCHAIN_ID}-mt-x64-${BOOST_VERSION_UNDERSCORE}.lib)
-else()
-  message(FATAL_ERROR "Integrated OpenCL build is not yet available for MinGW")
-endif()
+list(APPEND INTEGRATED_OPENCL_LIBRARIES ${BOOST_BUILD_BYPRODUCTS})
 
 set(BUILD_SHARED_LIBS ON CACHE BOOL "" FORCE)
```

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/accumulate.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/accumulate.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/adjacent_difference.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/adjacent_difference.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/adjacent_find.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/adjacent_find.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/all_of.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/all_of.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/any_of.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/any_of.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/binary_search.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/binary_search.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/copy.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/copy.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/copy_if.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/copy_if.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/copy_n.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/copy_n.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/count.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/count.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/count_if.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/count_if.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/balanced_path.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/balanced_path.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/binary_find.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/binary_find.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/compact.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/compact.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/copy_on_device.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/copy_on_device.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/copy_to_device.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/copy_to_device.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/copy_to_host.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/copy_to_host.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/count_if_with_ballot.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/count_if_with_ballot.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/count_if_with_reduce.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/count_if_with_reduce.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/count_if_with_threads.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/count_if_with_threads.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/find_extrema.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/find_extrema.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/find_extrema_on_cpu.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/find_extrema_on_cpu.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/find_extrema_with_atomics.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/find_extrema_with_atomics.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/find_extrema_with_reduce.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/find_extrema_with_reduce.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/find_if_with_atomics.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/find_if_with_atomics.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/inplace_reduce.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/inplace_reduce.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/insertion_sort.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/insertion_sort.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/merge_path.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/merge_path.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/merge_sort_on_cpu.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/merge_sort_on_cpu.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/merge_sort_on_gpu.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/merge_sort_on_gpu.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/merge_with_merge_path.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/merge_with_merge_path.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/radix_sort.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/radix_sort.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/random_fill.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/random_fill.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/reduce_by_key.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/reduce_by_key.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/reduce_by_key_with_scan.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/reduce_by_key_with_scan.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/reduce_on_cpu.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/reduce_on_cpu.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/reduce_on_gpu.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/reduce_on_gpu.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/scan.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/scan.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/scan_on_cpu.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/scan_on_cpu.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/scan_on_gpu.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/scan_on_gpu.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/search_all.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/search_all.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/serial_accumulate.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/serial_accumulate.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/serial_count_if.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/serial_count_if.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/serial_find_extrema.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/serial_find_extrema.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/serial_merge.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/serial_merge.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/serial_reduce.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/serial_reduce.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/serial_reduce_by_key.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/serial_reduce_by_key.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/detail/serial_scan.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/detail/serial_scan.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/equal.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/equal.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/equal_range.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/equal_range.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/exclusive_scan.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/exclusive_scan.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/fill.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/fill.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/fill_n.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/fill_n.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/find.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/find.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/find_end.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/find_end.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/find_if.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/find_if.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/find_if_not.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/find_if_not.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/for_each.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/for_each.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/for_each_n.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/for_each_n.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/gather.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/gather.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/generate.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/generate.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/generate_n.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/generate_n.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/includes.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/includes.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/inclusive_scan.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/inclusive_scan.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/inner_product.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/inner_product.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/inplace_merge.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/inplace_merge.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/iota.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/iota.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/is_partitioned.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/is_partitioned.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/is_permutation.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/is_permutation.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/is_sorted.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/is_sorted.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/lexicographical_compare.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/lexicographical_compare.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/lower_bound.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/lower_bound.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/max_element.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/max_element.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/merge.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/merge.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/min_element.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/min_element.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/minmax_element.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/minmax_element.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/mismatch.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/mismatch.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/next_permutation.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/next_permutation.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/none_of.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/none_of.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/nth_element.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/nth_element.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/partial_sum.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/partial_sum.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/partition.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/partition.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/partition_copy.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/partition_copy.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/partition_point.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/partition_point.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/prev_permutation.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/prev_permutation.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/random_shuffle.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/random_shuffle.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/reduce.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/reduce.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/reduce_by_key.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/reduce_by_key.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/remove.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/remove.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/remove_if.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/remove_if.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/replace.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/replace.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/replace_copy.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/replace_copy.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/reverse.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/reverse.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/reverse_copy.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/reverse_copy.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/rotate.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/rotate.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/rotate_copy.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/rotate_copy.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/scatter.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/scatter.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/scatter_if.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/scatter_if.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/search.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/search.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/search_n.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/search_n.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/set_difference.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/set_difference.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/set_intersection.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/set_intersection.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/set_symmetric_difference.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/set_symmetric_difference.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/set_union.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/set_union.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/sort.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/sort.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/sort_by_key.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/sort_by_key.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/stable_partition.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/stable_partition.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/stable_sort.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/stable_sort.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/stable_sort_by_key.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/stable_sort_by_key.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/swap_ranges.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/swap_ranges.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/transform.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/transform.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/transform_if.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/transform_if.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/transform_reduce.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/transform_reduce.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/unique.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/unique.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/unique_copy.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/unique_copy.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm/upper_bound.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm/upper_bound.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/algorithm.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/algorithm.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/allocator/buffer_allocator.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/allocator/buffer_allocator.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/allocator/pinned_allocator.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/allocator/pinned_allocator.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/allocator.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/allocator.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/async/future.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/async/future.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/async/wait.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/async/wait.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/async/wait_guard.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/async/wait_guard.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/async.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/async.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/buffer.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/buffer.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/cl.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/cl.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/cl_ext.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/cl_ext.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/closure.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/closure.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/command_queue.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/command_queue.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/config.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/config.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/container/array.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/container/array.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/container/basic_string.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/container/basic_string.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/container/detail/scalar.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/container/detail/scalar.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/container/dynamic_bitset.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/container/dynamic_bitset.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/container/flat_map.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/container/flat_map.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/container/flat_set.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/container/flat_set.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/container/mapped_view.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/container/mapped_view.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/container/stack.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/container/stack.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/container/string.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/container/string.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/container/valarray.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/container/valarray.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/container/vector.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/container/vector.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/container.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/container.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/context.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/context.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/core.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/core.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/assert_cl_success.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/assert_cl_success.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/buffer_value.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/buffer_value.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/cl_versions.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/cl_versions.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/device_ptr.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/device_ptr.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/diagnostic.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/diagnostic.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/duration.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/duration.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/get_object_info.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/get_object_info.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/getenv.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/getenv.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/global_static.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/global_static.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/is_buffer_iterator.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/is_buffer_iterator.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/is_contiguous_iterator.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/is_contiguous_iterator.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/iterator_plus_distance.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/iterator_plus_distance.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/iterator_range_size.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/iterator_range_size.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/iterator_traits.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/iterator_traits.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/literal.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/literal.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/lru_cache.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/lru_cache.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/meta_kernel.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/meta_kernel.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/mpl_vector_to_tuple.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/mpl_vector_to_tuple.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/nvidia_compute_capability.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/nvidia_compute_capability.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/parameter_cache.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/parameter_cache.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/path.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/path.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/print_range.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/print_range.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/read_write_single_value.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/read_write_single_value.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/sha1.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/sha1.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/variadic_macros.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/variadic_macros.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/vendor.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/vendor.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/detail/work_size.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/detail/work_size.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/device.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/device.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/event.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/event.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/exception/context_error.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/exception/context_error.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/exception/no_device_found.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/exception/no_device_found.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/exception/opencl_error.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/exception/opencl_error.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/exception/program_build_failure.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/exception/program_build_failure.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/exception/unsupported_extension_error.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/exception/unsupported_extension_error.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/exception.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/exception.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/experimental/clamp_range.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/experimental/clamp_range.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/experimental/malloc.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/experimental/malloc.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/experimental/sort_by_transform.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/experimental/sort_by_transform.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/experimental/tabulate.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/experimental/tabulate.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/function.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/function.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional/as.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/functional/as.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional/atomic.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/functional/atomic.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional/bind.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/functional/bind.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional/common.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/functional/common.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional/convert.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/functional/convert.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional/detail/macros.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/functional/detail/macros.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional/detail/nvidia_ballot.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/functional/detail/nvidia_ballot.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional/detail/nvidia_popcount.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/functional/detail/nvidia_popcount.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional/detail/unpack.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/functional/detail/unpack.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional/field.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/functional/field.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional/geometry.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/functional/geometry.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional/get.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/functional/get.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional/hash.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/functional/hash.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional/identity.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/functional/identity.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional/integer.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/functional/integer.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional/logical.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/functional/logical.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional/math.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/functional/math.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional/operator.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/functional/operator.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional/popcount.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/functional/popcount.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional/relational.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/functional/relational.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/functional.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/functional.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/image/image1d.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/image/image1d.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/image/image2d.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/image/image2d.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/image/image3d.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/image/image3d.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/image/image_format.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/image/image_format.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/image/image_object.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/image/image_object.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/image/image_sampler.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/image/image_sampler.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/image.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/image.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/image2d.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/image2d.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/image3d.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/image3d.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/image_format.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/image_format.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/image_sampler.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/image_sampler.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/eigen/core.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/eigen/core.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/eigen.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/eigen.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/opencv/core.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/opencv/core.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/opencv/highgui.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/opencv/highgui.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/opencv/ocl.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/opencv/ocl.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/opencv.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/opencv.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/opengl/acquire.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/opengl/acquire.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/opengl/cl_gl.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/opengl/cl_gl.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/opengl/cl_gl_ext.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/opengl/cl_gl_ext.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/opengl/context.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/opengl/context.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/opengl/gl.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/opengl/gl.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/opengl/opengl_buffer.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/opengl/opengl_buffer.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/opengl/opengl_renderbuffer.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/opengl/opengl_renderbuffer.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/opengl/opengl_texture.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/opengl/opengl_texture.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/opengl.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/opengl.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/qt/qimage.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/qt/qimage.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/qt/qpoint.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/qt/qpoint.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/qt/qpointf.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/qt/qpointf.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/qt/qtcore.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/qt/qtcore.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/qt/qtgui.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/qt/qtgui.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/qt/qvector.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/qt/qvector.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/qt.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/qt.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/vtk/bounds.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/vtk/bounds.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/vtk/data_array.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/vtk/data_array.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/vtk/matrix4x4.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/vtk/matrix4x4.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/vtk/points.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/vtk/points.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/interop/vtk.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/interop/vtk.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/iterator/buffer_iterator.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/iterator/buffer_iterator.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/iterator/constant_buffer_iterator.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/iterator/constant_buffer_iterator.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/iterator/constant_iterator.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/iterator/constant_iterator.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/iterator/counting_iterator.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/iterator/counting_iterator.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/iterator/detail/get_base_iterator_buffer.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/iterator/detail/get_base_iterator_buffer.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/iterator/detail/swizzle_iterator.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/iterator/detail/swizzle_iterator.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/iterator/discard_iterator.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/iterator/discard_iterator.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/iterator/function_input_iterator.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/iterator/function_input_iterator.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/iterator/permutation_iterator.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/iterator/permutation_iterator.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/iterator/strided_iterator.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/iterator/strided_iterator.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/iterator/transform_iterator.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/iterator/transform_iterator.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/iterator/zip_iterator.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/iterator/zip_iterator.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/iterator.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/iterator.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/kernel.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/kernel.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/lambda/context.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/lambda/context.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/lambda/functional.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/lambda/functional.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/lambda/get.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/lambda/get.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/lambda/make_pair.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/lambda/make_pair.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/lambda/make_tuple.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/lambda/make_tuple.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/lambda/placeholder.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/lambda/placeholder.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/lambda/placeholders.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/lambda/placeholders.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/lambda/result_of.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/lambda/result_of.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/lambda.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/lambda.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/memory/local_buffer.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/memory/local_buffer.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/memory/svm_ptr.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/memory/svm_ptr.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/memory.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/memory.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/memory_object.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/memory_object.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/pipe.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/pipe.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/platform.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/platform.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/program.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/program.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/random/bernoulli_distribution.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/random/bernoulli_distribution.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/random/default_random_engine.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/random/default_random_engine.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/random/discrete_distribution.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/random/discrete_distribution.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/random/linear_congruential_engine.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/random/linear_congruential_engine.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/random/mersenne_twister_engine.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/random/mersenne_twister_engine.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/random/normal_distribution.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/random/normal_distribution.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/random/threefry_engine.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/random/threefry_engine.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/random/uniform_int_distribution.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/random/uniform_int_distribution.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/random/uniform_real_distribution.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/random/uniform_real_distribution.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/random.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/random.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/source.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/source.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/svm.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/svm.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/system.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/system.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/type_traits/common_type.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/type_traits/common_type.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/type_traits/detail/capture_traits.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/type_traits/detail/capture_traits.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/type_traits/is_device_iterator.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/type_traits/is_device_iterator.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/type_traits/is_fundamental.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/type_traits/is_fundamental.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/type_traits/is_vector_type.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/type_traits/is_vector_type.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/type_traits/make_vector_type.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/type_traits/make_vector_type.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/type_traits/result_of.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/type_traits/result_of.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/type_traits/scalar_type.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/type_traits/scalar_type.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/type_traits/type_definition.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/type_traits/type_definition.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/type_traits/type_name.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/type_traits/type_name.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/type_traits/vector_size.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/type_traits/vector_size.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/type_traits.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/type_traits.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/types/builtin.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/types/builtin.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/types/complex.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/types/complex.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/types/fundamental.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/types/fundamental.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/types/pair.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/types/pair.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/types/size_t.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/types/size_t.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/types/struct.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/types/struct.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/types/tuple.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/types/tuple.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/types.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/types.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/user_event.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/user_event.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/utility/dim.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/utility/dim.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/utility/extents.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/utility/extents.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/utility/invoke.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/utility/invoke.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/utility/program_cache.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/utility/program_cache.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/utility/source.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/utility/source.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/utility/wait_list.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/utility/wait_list.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/utility.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/utility.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/version.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/version.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute/wait_list.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute/wait_list.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/compute/include/boost/compute.hpp` & `lightgbm-4.0.0/external_libs/compute/include/boost/compute.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/CMakeLists.txt` & `lightgbm-4.0.0/external_libs/eigen/CMakeLists.txt`

 * *Files 5% similar despite different names*

```diff
@@ -1,11 +1,12 @@
-project(Eigen3)
-
+# cmake_minimum_require must be the first command of the file
 cmake_minimum_required(VERSION 3.5.0)
 
+project(Eigen3)
+
 # guard against in-source builds
 
 if(${CMAKE_SOURCE_DIR} STREQUAL ${CMAKE_BINARY_DIR})
   message(FATAL_ERROR "In-source builds not allowed. Please make a new directory (called a build directory) and run CMake from there. You may need to remove CMakeCache.txt. ")
 endif()
 
 
@@ -52,14 +53,15 @@
   set(EIGEN_VERSION "${EIGEN_VERSION_NUMBER} (git rev ${EIGEN_GIT_REVNUM})")
 else()
   set(EIGEN_VERSION "${EIGEN_VERSION_NUMBER}")
 endif()
 
 include(CheckCXXCompilerFlag)
 include(GNUInstallDirs)
+include(CMakeDependentOption)
 
 set(CMAKE_MODULE_PATH ${PROJECT_SOURCE_DIR}/cmake)
 
 
 option(EIGEN_TEST_CXX11 "Enable testing with C++11 and C++11 features (e.g. Tensor module)." OFF)
 
 
@@ -82,14 +84,17 @@
   endif()
 else()
   #set(CMAKE_CXX_STANDARD 03)
   #set(CMAKE_CXX_EXTENSIONS OFF)
   ei_add_cxx_compiler_flag("-std=c++03")
 endif()
 
+# Determine if we should build shared libraries on this platform.
+get_cmake_property(EIGEN_BUILD_SHARED_LIBS TARGET_SUPPORTS_SHARED_LIBS)
+
 #############################################################################
 # find how to link to the standard libraries                                #
 #############################################################################
 
 find_package(StandardMathLibrary)
 
 
@@ -418,30 +423,36 @@
 # Backward compatibility support for EIGEN_INCLUDE_INSTALL_DIR
 if(EIGEN_INCLUDE_INSTALL_DIR)
   message(WARNING "EIGEN_INCLUDE_INSTALL_DIR is deprecated. Use INCLUDE_INSTALL_DIR instead.")
 endif()
 
 if(EIGEN_INCLUDE_INSTALL_DIR AND NOT INCLUDE_INSTALL_DIR)
   set(INCLUDE_INSTALL_DIR ${EIGEN_INCLUDE_INSTALL_DIR}
-      CACHE PATH "The directory relative to CMAKE_PREFIX_PATH where Eigen header files are installed")
+      CACHE PATH "The directory relative to CMAKE_INSTALL_PREFIX where Eigen header files are installed")
 else()
   set(INCLUDE_INSTALL_DIR
       "${CMAKE_INSTALL_INCLUDEDIR}/eigen3"
-      CACHE PATH "The directory relative to CMAKE_PREFIX_PATH where Eigen header files are installed"
+      CACHE PATH "The directory relative to CMAKE_INSTALL_PREFIX where Eigen header files are installed"
       )
 endif()
 set(CMAKEPACKAGE_INSTALL_DIR
     "${CMAKE_INSTALL_DATADIR}/eigen3/cmake"
-    CACHE PATH "The directory relative to CMAKE_PREFIX_PATH where Eigen3Config.cmake is installed"
+    CACHE PATH "The directory relative to CMAKE_INSTALL_PREFIX where Eigen3Config.cmake is installed"
     )
 set(PKGCONFIG_INSTALL_DIR
     "${CMAKE_INSTALL_DATADIR}/pkgconfig"
-    CACHE PATH "The directory relative to CMAKE_PREFIX_PATH where eigen3.pc is installed"
+    CACHE PATH "The directory relative to CMAKE_INSTALL_PREFIX where eigen3.pc is installed"
     )
 
+foreach(var INCLUDE_INSTALL_DIR CMAKEPACKAGE_INSTALL_DIR PKGCONFIG_INSTALL_DIR)
+  # If an absolute path is specified, make it relative to "{CMAKE_INSTALL_PREFIX}".
+  if(IS_ABSOLUTE "${${var}}")
+    file(RELATIVE_PATH "${var}" "${CMAKE_INSTALL_PREFIX}" "${${var}}")
+  endif()
+endforeach()
 
 # similar to set_target_properties but append the property instead of overwriting it
 macro(ei_add_target_property target prop value)
 
   get_target_property(previous ${target} ${prop})
   # if the property wasn't previously set, ${previous} is now "previous-NOTFOUND" which cmake allows catching with plain if()
   if(NOT previous)
@@ -460,15 +471,20 @@
     install(FILES ${CMAKE_CURRENT_BINARY_DIR}/eigen3.pc
         DESTINATION ${PKGCONFIG_INSTALL_DIR}
         )
 endif()
 
 install(DIRECTORY Eigen DESTINATION ${INCLUDE_INSTALL_DIR} COMPONENT Devel)
 
-add_subdirectory(doc EXCLUDE_FROM_ALL)
+
+option(EIGEN_BUILD_DOC "Enable creation of Eigen documentation" ON)
+if(EIGEN_BUILD_DOC)
+  add_subdirectory(doc EXCLUDE_FROM_ALL)
+endif()
+
 
 option(BUILD_TESTING "Enable creation of Eigen tests." ON)
 if(BUILD_TESTING)
   include(EigenConfigureTesting)
 
   if(EIGEN_LEAVE_TEST_IN_ALL_TARGET)
     add_subdirectory(test) # can't do EXCLUDE_FROM_ALL here, breaks CTest
@@ -488,14 +504,15 @@
 endif()
 
 # add SYCL
 option(EIGEN_TEST_SYCL "Add Sycl support." OFF)
 option(EIGEN_SYCL_TRISYCL "Use the triSYCL Sycl implementation (ComputeCPP by default)." OFF)
 if(EIGEN_TEST_SYCL)
   set (CMAKE_MODULE_PATH "${CMAKE_ROOT}/Modules" "cmake/Modules/" "${CMAKE_MODULE_PATH}")
+  find_package(Threads REQUIRED)
   if(EIGEN_SYCL_TRISYCL)
     message(STATUS "Using triSYCL")
     include(FindTriSYCL)
   else()
     message(STATUS "Using ComputeCPP SYCL")
     include(FindComputeCpp)
     set(COMPUTECPP_DRIVER_DEFAULT_VALUE OFF)
@@ -575,92 +592,62 @@
 set ( EIGEN_VERSION_MAJOR  ${EIGEN_WORLD_VERSION} )
 set ( EIGEN_VERSION_MINOR  ${EIGEN_MAJOR_VERSION} )
 set ( EIGEN_VERSION_PATCH  ${EIGEN_MINOR_VERSION} )
 set ( EIGEN_DEFINITIONS "")
 set ( EIGEN_INCLUDE_DIR "${CMAKE_INSTALL_PREFIX}/${INCLUDE_INSTALL_DIR}" )
 set ( EIGEN_ROOT_DIR ${CMAKE_INSTALL_PREFIX} )
 
-# Interface libraries require at least CMake 3.0
-if (NOT CMAKE_VERSION VERSION_LESS 3.0)
-  include (CMakePackageConfigHelpers)
-
-  # Imported target support
-  add_library (eigen INTERFACE)
-  add_library (Eigen3::Eigen ALIAS eigen)
-  target_compile_definitions (eigen INTERFACE ${EIGEN_DEFINITIONS})
-  target_include_directories (eigen INTERFACE
-    $<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}>
-    $<INSTALL_INTERFACE:${INCLUDE_INSTALL_DIR}>
-  )
+include (CMakePackageConfigHelpers)
 
-  # Export as title case Eigen
-  set_target_properties (eigen PROPERTIES EXPORT_NAME Eigen)
+# Imported target support
+add_library (eigen INTERFACE)
+add_library (Eigen3::Eigen ALIAS eigen)
+target_compile_definitions (eigen INTERFACE ${EIGEN_DEFINITIONS})
+target_include_directories (eigen INTERFACE
+  $<BUILD_INTERFACE:${CMAKE_CURRENT_SOURCE_DIR}>
+  $<INSTALL_INTERFACE:${INCLUDE_INSTALL_DIR}>
+)
+
+# Export as title case Eigen
+set_target_properties (eigen PROPERTIES EXPORT_NAME Eigen)
+
+install (TARGETS eigen EXPORT Eigen3Targets)
+
+configure_package_config_file (
+  ${CMAKE_CURRENT_SOURCE_DIR}/cmake/Eigen3Config.cmake.in
+  ${CMAKE_CURRENT_BINARY_DIR}/Eigen3Config.cmake
+  PATH_VARS EIGEN_INCLUDE_DIR EIGEN_ROOT_DIR
+  INSTALL_DESTINATION ${CMAKEPACKAGE_INSTALL_DIR}
+  NO_CHECK_REQUIRED_COMPONENTS_MACRO # Eigen does not provide components
+)
+# Remove CMAKE_SIZEOF_VOID_P from Eigen3ConfigVersion.cmake since Eigen does
+# not depend on architecture specific settings or libraries. More
+# specifically, an Eigen3Config.cmake generated from a 64 bit target can be
+# used for 32 bit targets as well (and vice versa).
+set (_Eigen3_CMAKE_SIZEOF_VOID_P ${CMAKE_SIZEOF_VOID_P})
+unset (CMAKE_SIZEOF_VOID_P)
+write_basic_package_version_file (Eigen3ConfigVersion.cmake
+                                  VERSION ${EIGEN_VERSION_NUMBER}
+                                  COMPATIBILITY SameMajorVersion)
+set (CMAKE_SIZEOF_VOID_P ${_Eigen3_CMAKE_SIZEOF_VOID_P})
+
+# The Eigen target will be located in the Eigen3 namespace. Other CMake
+# targets can refer to it using Eigen3::Eigen.
+export (TARGETS eigen NAMESPACE Eigen3:: FILE Eigen3Targets.cmake)
+# Export Eigen3 package to CMake registry such that it can be easily found by
+# CMake even if it has not been installed to a standard directory.
+export (PACKAGE Eigen3)
 
-  install (TARGETS eigen EXPORT Eigen3Targets)
-
-  configure_package_config_file (
-    ${CMAKE_CURRENT_SOURCE_DIR}/cmake/Eigen3Config.cmake.in
-    ${CMAKE_CURRENT_BINARY_DIR}/Eigen3Config.cmake
-    PATH_VARS EIGEN_INCLUDE_DIR EIGEN_ROOT_DIR
-    INSTALL_DESTINATION ${CMAKEPACKAGE_INSTALL_DIR}
-    NO_CHECK_REQUIRED_COMPONENTS_MACRO # Eigen does not provide components
-  )
-  # Remove CMAKE_SIZEOF_VOID_P from Eigen3ConfigVersion.cmake since Eigen does
-  # not depend on architecture specific settings or libraries. More
-  # specifically, an Eigen3Config.cmake generated from a 64 bit target can be
-  # used for 32 bit targets as well (and vice versa).
-  set (_Eigen3_CMAKE_SIZEOF_VOID_P ${CMAKE_SIZEOF_VOID_P})
-  unset (CMAKE_SIZEOF_VOID_P)
-  write_basic_package_version_file (Eigen3ConfigVersion.cmake
-                                    VERSION ${EIGEN_VERSION_NUMBER}
-                                    COMPATIBILITY SameMajorVersion)
-  set (CMAKE_SIZEOF_VOID_P ${_Eigen3_CMAKE_SIZEOF_VOID_P})
-
-  # The Eigen target will be located in the Eigen3 namespace. Other CMake
-  # targets can refer to it using Eigen3::Eigen.
-  export (TARGETS eigen NAMESPACE Eigen3:: FILE Eigen3Targets.cmake)
-  # Export Eigen3 package to CMake registry such that it can be easily found by
-  # CMake even if it has not been installed to a standard directory.
-  export (PACKAGE Eigen3)
-
-  install (EXPORT Eigen3Targets NAMESPACE Eigen3:: DESTINATION ${CMAKEPACKAGE_INSTALL_DIR})
-
-else ()
-  # Fallback to legacy Eigen3Config.cmake without the imported target
-
-  # If CMakePackageConfigHelpers module is available (CMake >= 2.8.8)
-  # create a relocatable Config file, otherwise leave the hardcoded paths
-  include(CMakePackageConfigHelpers OPTIONAL RESULT_VARIABLE CPCH_PATH)
-
-  if(CPCH_PATH)
-    configure_package_config_file (
-      ${CMAKE_CURRENT_SOURCE_DIR}/cmake/Eigen3ConfigLegacy.cmake.in
-      ${CMAKE_CURRENT_BINARY_DIR}/Eigen3Config.cmake
-      PATH_VARS EIGEN_INCLUDE_DIR EIGEN_ROOT_DIR
-      INSTALL_DESTINATION ${CMAKEPACKAGE_INSTALL_DIR}
-      NO_CHECK_REQUIRED_COMPONENTS_MACRO # Eigen does not provide components
-    )
-  else()
-    # The PACKAGE_* variables are defined by the configure_package_config_file
-    # but without it we define them manually to the hardcoded paths
-    set(PACKAGE_INIT "")
-    set(PACKAGE_EIGEN_INCLUDE_DIR ${EIGEN_INCLUDE_DIR})
-    set(PACKAGE_EIGEN_ROOT_DIR ${EIGEN_ROOT_DIR})
-    configure_file ( ${CMAKE_CURRENT_SOURCE_DIR}/cmake/Eigen3ConfigLegacy.cmake.in
-                     ${CMAKE_CURRENT_BINARY_DIR}/Eigen3Config.cmake
-                     @ONLY ESCAPE_QUOTES )
-  endif()
-
-  write_basic_package_version_file( Eigen3ConfigVersion.cmake
-                                    VERSION ${EIGEN_VERSION_NUMBER}
-                                    COMPATIBILITY SameMajorVersion )
-
-endif ()
+install (EXPORT Eigen3Targets NAMESPACE Eigen3:: DESTINATION ${CMAKEPACKAGE_INSTALL_DIR})
 
 install ( FILES ${CMAKE_CURRENT_SOURCE_DIR}/cmake/UseEigen3.cmake
                 ${CMAKE_CURRENT_BINARY_DIR}/Eigen3Config.cmake
                 ${CMAKE_CURRENT_BINARY_DIR}/Eigen3ConfigVersion.cmake
           DESTINATION ${CMAKEPACKAGE_INSTALL_DIR} )
 
 # Add uninstall target
 add_custom_target ( uninstall
     COMMAND ${CMAKE_COMMAND} -P ${CMAKE_CURRENT_SOURCE_DIR}/cmake/EigenUninstall.cmake)
+
+if (EIGEN_SPLIT_TESTSUITE)
+  ei_split_testsuite("${EIGEN_SPLIT_TESTSUITE}")
+endif()
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/Cholesky` & `lightgbm-4.0.0/external_libs/eigen/Eigen/Cholesky`

 * *Files 20% similar despite different names*

```diff
@@ -39,8 +39,7 @@
 #endif
 #include "src/Cholesky/LLT_LAPACKE.h"
 #endif
 
 #include "src/Core/util/ReenableStupidWarnings.h"
 
 #endif // EIGEN_CHOLESKY_MODULE_H
-/* vim: set filetype=cpp et sw=2 ts=2 ai: */
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/Core` & `lightgbm-4.0.0/external_libs/eigen/Eigen/Core`

 * *Files 4% similar despite different names*

```diff
@@ -18,15 +18,15 @@
 // it's where we do all the compiler/OS/arch detections and define most defaults.
 #include "src/Core/util/Macros.h"
 
 // This detects SSE/AVX/NEON/etc. and configure alignment settings
 #include "src/Core/util/ConfigureVectorization.h"
 
 // We need cuda_runtime.h/hip_runtime.h to ensure that
-// the EIGEN_USING_STD_MATH macro works properly on the device side
+// the EIGEN_USING_STD macro works properly on the device side
 #if defined(EIGEN_CUDACC)
   #include <cuda_runtime.h>
 #elif defined(EIGEN_HIPCC)
   #include <hip/hip_runtime.h>
 #endif
 
 
@@ -36,14 +36,21 @@
 
 // Disable the ipa-cp-clone optimization flag with MinGW 6.x or newer (enabled by default with -O3)
 // See http://eigen.tuxfamily.org/bz/show_bug.cgi?id=556 for details.
 #if EIGEN_COMP_MINGW && EIGEN_GNUC_AT_LEAST(4,6) && EIGEN_GNUC_AT_MOST(5,5)
   #pragma GCC optimize ("-fno-ipa-cp-clone")
 #endif
 
+// Prevent ICC from specializing std::complex operators that silently fail
+// on device. This allows us to use our own device-compatible specializations
+// instead.
+#if defined(EIGEN_COMP_ICC) && defined(EIGEN_GPU_COMPILE_PHASE) \
+    && !defined(_OVERRIDE_COMPLEX_SPECIALIZATION_)
+#define _OVERRIDE_COMPLEX_SPECIALIZATION_ 1
+#endif
 #include <complex>
 
 // this include file manages BLAS and MKL related macros
 // and inclusion of their respective header files
 #include "src/Core/util/MKL_support.h"
 
 
@@ -204,14 +211,18 @@
   #include "src/Core/arch/AltiVec/MathFunctions.h"
   #include "src/Core/arch/AltiVec/Complex.h"
 #elif defined EIGEN_VECTORIZE_NEON
   #include "src/Core/arch/NEON/PacketMath.h"
   #include "src/Core/arch/NEON/TypeCasting.h"
   #include "src/Core/arch/NEON/MathFunctions.h"
   #include "src/Core/arch/NEON/Complex.h"
+#elif defined EIGEN_VECTORIZE_SVE
+  #include "src/Core/arch/SVE/PacketMath.h"
+  #include "src/Core/arch/SVE/TypeCasting.h"
+  #include "src/Core/arch/SVE/MathFunctions.h"
 #elif defined EIGEN_VECTORIZE_ZVECTOR
   #include "src/Core/arch/ZVector/PacketMath.h"
   #include "src/Core/arch/ZVector/MathFunctions.h"
   #include "src/Core/arch/ZVector/Complex.h"
 #elif defined EIGEN_VECTORIZE_MSA
   #include "src/Core/arch/MSA/PacketMath.h"
   #include "src/Core/arch/MSA/MathFunctions.h"
@@ -331,16 +342,18 @@
 #include "src/Core/products/TriangularMatrixMatrix.h"
 #include "src/Core/products/TriangularSolverMatrix.h"
 #include "src/Core/products/TriangularSolverVector.h"
 #include "src/Core/BandMatrix.h"
 #include "src/Core/CoreIterators.h"
 #include "src/Core/ConditionEstimator.h"
 
-#if EIGEN_ARCH_PPC
-#include "src/Core/arch/AltiVec/MatrixProduct.h"
+#if defined(EIGEN_VECTORIZE_ALTIVEC) || defined(EIGEN_VECTORIZE_VSX)
+  #include "src/Core/arch/AltiVec/MatrixProduct.h"
+#elif defined EIGEN_VECTORIZE_NEON
+  #include "src/Core/arch/NEON/GeneralBlockPanelKernel.h"
 #endif
 
 #include "src/Core/BooleanRedux.h"
 #include "src/Core/Select.h"
 #include "src/Core/VectorwiseOp.h"
 #include "src/Core/PartialReduxEvaluator.h"
 #include "src/Core/Random.h"
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/Eigenvalues` & `lightgbm-4.0.0/external_libs/eigen/Eigen/Eigenvalues`

 * *Files 2% similar despite different names*

```diff
@@ -54,8 +54,7 @@
 #include "src/Eigenvalues/ComplexSchur_LAPACKE.h"
 #include "src/Eigenvalues/SelfAdjointEigenSolver_LAPACKE.h"
 #endif
 
 #include "src/Core/util/ReenableStupidWarnings.h"
 
 #endif // EIGEN_EIGENVALUES_MODULE_H
-/* vim: set filetype=cpp et sw=2 ts=2 ai: */
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/Geometry` & `lightgbm-4.0.0/external_libs/eigen/Eigen/Geometry`

 * *Files 24% similar despite different names*

```diff
@@ -46,15 +46,14 @@
 #include "src/Geometry/Scaling.h"
 #include "src/Geometry/Hyperplane.h"
 #include "src/Geometry/ParametrizedLine.h"
 #include "src/Geometry/AlignedBox.h"
 #include "src/Geometry/Umeyama.h"
 
 // Use the SSE optimized version whenever possible.
-#if defined EIGEN_VECTORIZE_SSE
-#include "src/Geometry/arch/Geometry_SSE.h"
+#if (defined EIGEN_VECTORIZE_SSE) || (defined EIGEN_VECTORIZE_NEON)
+#include "src/Geometry/arch/Geometry_SIMD.h"
 #endif
 
 #include "src/Core/util/ReenableStupidWarnings.h"
 
 #endif // EIGEN_GEOMETRY_MODULE_H
-/* vim: set filetype=cpp et sw=2 ts=2 ai: */
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/Householder` & `lightgbm-4.0.0/external_libs/eigen/Eigen/Householder`

 * *Files 13% similar despite different names*

```diff
@@ -23,8 +23,7 @@
 #include "src/Householder/Householder.h"
 #include "src/Householder/HouseholderSequence.h"
 #include "src/Householder/BlockHouseholder.h"
 
 #include "src/Core/util/ReenableStupidWarnings.h"
 
 #endif // EIGEN_HOUSEHOLDER_MODULE_H
-/* vim: set filetype=cpp et sw=2 ts=2 ai: */
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/Jacobi` & `lightgbm-4.0.0/external_libs/eigen/Eigen/Jacobi`

 * *Files 5% similar despite different names*

```diff
@@ -25,9 +25,8 @@
   */
 
 #include "src/Jacobi/Jacobi.h"
 
 #include "src/Core/util/ReenableStupidWarnings.h"
 
 #endif // EIGEN_JACOBI_MODULE_H
-/* vim: set filetype=cpp et sw=2 ts=2 ai: */
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/LU` & `lightgbm-4.0.0/external_libs/eigen/Eigen/LU`

 * *Files 11% similar despite different names*

```diff
@@ -34,17 +34,14 @@
 #include "src/misc/lapacke.h"
 #endif
 #include "src/LU/PartialPivLU_LAPACKE.h"
 #endif
 #include "src/LU/Determinant.h"
 #include "src/LU/InverseImpl.h"
 
-// Use the SSE optimized version whenever possible. At the moment the
-// SSE version doesn't compile when AVX is enabled
-#if defined EIGEN_VECTORIZE_SSE && !defined EIGEN_VECTORIZE_AVX
-  #include "src/LU/arch/Inverse_SSE.h"
+#if defined EIGEN_VECTORIZE_SSE || defined EIGEN_VECTORIZE_NEON
+  #include "src/LU/arch/InverseSize4.h"
 #endif
 
 #include "src/Core/util/ReenableStupidWarnings.h"
 
 #endif // EIGEN_LU_MODULE_H
-/* vim: set filetype=cpp et sw=2 ts=2 ai: */
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/QR` & `lightgbm-4.0.0/external_libs/eigen/Eigen/QR`

 * *Files 10% similar despite different names*

```diff
@@ -44,8 +44,7 @@
 #include "src/QR/HouseholderQR_LAPACKE.h"
 #include "src/QR/ColPivHouseholderQR_LAPACKE.h"
 #endif
 
 #include "src/Core/util/ReenableStupidWarnings.h"
 
 #endif // EIGEN_QR_MODULE_H
-/* vim: set filetype=cpp et sw=2 ts=2 ai: */
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/SVD` & `lightgbm-4.0.0/external_libs/eigen/Eigen/SVD`

 * *Files 2% similar despite different names*

```diff
@@ -44,8 +44,7 @@
 #endif
 #include "src/SVD/JacobiSVD_LAPACKE.h"
 #endif
 
 #include "src/Core/util/ReenableStupidWarnings.h"
 
 #endif // EIGEN_SVD_MODULE_H
-/* vim: set filetype=cpp et sw=2 ts=2 ai: */
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Cholesky/LDLT.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Cholesky/LDLT.h`

 * *Files 1% similar despite different names*

```diff
@@ -41,23 +41,23 @@
   * \tparam _UpLo the triangular part that will be used for the decompositon: Lower (default) or Upper.
   *             The other triangular part won't be read.
   *
   * Perform a robust Cholesky decomposition of a positive semidefinite or negative semidefinite
   * matrix \f$ A \f$ such that \f$ A =  P^TLDL^*P \f$, where P is a permutation matrix, L
   * is lower triangular with a unit diagonal and D is a diagonal matrix.
   *
-  * The decomposition uses pivoting to ensure stability, so that L will have
+  * The decomposition uses pivoting to ensure stability, so that D will have
   * zeros in the bottom right rank(A) - n submatrix. Avoiding the square root
   * on D also stabilizes the computation.
   *
   * Remember that Cholesky decompositions are not rank-revealing. Also, do not use a Cholesky
   * decomposition to determine whether a system of equations has a solution.
   *
   * This class supports the \link InplaceDecomposition inplace decomposition \endlink mechanism.
-  * 
+  *
   * \sa MatrixBase::ldlt(), SelfAdjointView::ldlt(), class LLT
   */
 template<typename _MatrixType, int _UpLo> class LDLT
         : public SolverBase<LDLT<_MatrixType, _UpLo> >
 {
   public:
     typedef _MatrixType MatrixType;
@@ -196,15 +196,15 @@
       * \note_about_checking_solutions
       *
       * More precisely, this method solves \f$ A x = b \f$ using the decomposition \f$ A = P^T L D L^* P \f$
       * by solving the systems \f$ P^T y_1 = b \f$, \f$ L y_2 = y_1 \f$, \f$ D y_3 = y_2 \f$,
       * \f$ L^* y_4 = y_3 \f$ and \f$ P x = y_4 \f$ in succession. If the matrix \f$ A \f$ is singular, then
       * \f$ D \f$ will also be singular (all the other matrices are invertible). In that case, the
       * least-square solution of \f$ D y_3 = y_2 \f$ is computed. This does not mean that this function
-      * computes the least-square solution of \f$ A x = b \f$ is \f$ A \f$ is singular.
+      * computes the least-square solution of \f$ A x = b \f$ if \f$ A \f$ is singular.
       *
       * \sa MatrixBase::ldlt(), SelfAdjointView::ldlt()
       */
     template<typename Rhs>
     inline const Solve<LDLT, Rhs>
     solve(const MatrixBase<Rhs>& b) const;
     #endif
@@ -242,16 +242,16 @@
     /** \returns the adjoint of \c *this, that is, a const reference to the decomposition itself as the underlying matrix is self-adjoint.
       *
       * This method is provided for compatibility with other matrix decompositions, thus enabling generic code such as:
       * \code x = decomposition.adjoint().solve(b) \endcode
       */
     const LDLT& adjoint() const { return *this; };
 
-    inline Index rows() const { return m_matrix.rows(); }
-    inline Index cols() const { return m_matrix.cols(); }
+    EIGEN_DEVICE_FUNC inline EIGEN_CONSTEXPR Index rows() const EIGEN_NOEXCEPT { return m_matrix.rows(); }
+    EIGEN_DEVICE_FUNC inline EIGEN_CONSTEXPR Index cols() const EIGEN_NOEXCEPT { return m_matrix.cols(); }
 
     /** \brief Reports whether previous computation was successful.
       *
       * \returns \c Success if computation was successful,
       *          \c NumericalIssue if the factorization failed because of a zero pivot.
       */
     ComputationInfo info() const
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Cholesky/LLT.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Cholesky/LLT.h`

 * *Files 2% similar despite different names*

```diff
@@ -195,18 +195,18 @@
     }
 
     /** \returns the adjoint of \c *this, that is, a const reference to the decomposition itself as the underlying matrix is self-adjoint.
       *
       * This method is provided for compatibility with other matrix decompositions, thus enabling generic code such as:
       * \code x = decomposition.adjoint().solve(b) \endcode
       */
-    const LLT& adjoint() const { return *this; };
+    const LLT& adjoint() const EIGEN_NOEXCEPT { return *this; };
 
-    inline Index rows() const { return m_matrix.rows(); }
-    inline Index cols() const { return m_matrix.cols(); }
+    inline EIGEN_CONSTEXPR Index rows() const EIGEN_NOEXCEPT { return m_matrix.rows(); }
+    inline EIGEN_CONSTEXPR Index cols() const EIGEN_NOEXCEPT { return m_matrix.cols(); }
 
     template<typename VectorType>
     LLT & rankUpdate(const VectorType& vec, const RealScalar& sigma = 1);
 
     #ifndef EIGEN_PARSED_BY_DOXYGEN
     template<typename RhsType, typename DstType>
     void _solve_impl(const RhsType &rhs, DstType &dst) const;
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Cholesky/LLT_LAPACKE.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Cholesky/LLT_LAPACKE.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/ArithmeticSequence.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/ArithmeticSequence.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Array.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Array.h`

 * *Files 0% similar despite different names*

```diff
@@ -113,15 +113,15 @@
       * prevent a default operator= from hiding the templated operator=.
       */
     EIGEN_DEVICE_FUNC
     EIGEN_STRONG_INLINE Array& operator=(const Array& other)
     {
       return Base::_set(other);
     }
-    
+
     /** Default constructor.
       *
       * For fixed-size matrices, does nothing.
       *
       * For dynamic-size matrices, creates an empty matrix of size 0. Does not allocate any array. Such a matrix
       * is called a null matrix. This constructor is the unique way to create null matrices: resizing
       * a matrix to 0 is not supported.
@@ -153,15 +153,15 @@
       : Base(std::move(other))
     {
       Base::_check_template_params();
     }
     EIGEN_DEVICE_FUNC
     Array& operator=(Array&& other) EIGEN_NOEXCEPT_IF(std::is_nothrow_move_assignable<Scalar>::value)
     {
-      other.swap(*this);
+      Base::operator=(std::move(other));
       return *this;
     }
 #endif
 
     #if EIGEN_HAS_CXX11
     /** \copydoc PlainObjectBase(const Scalar& a0, const Scalar& a1, const Scalar& a2, const Scalar& a3, const ArgTypes&... args)
      *
@@ -173,32 +173,32 @@
      */
     template <typename... ArgTypes>
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
     Array(const Scalar& a0, const Scalar& a1, const Scalar& a2, const Scalar& a3, const ArgTypes&... args)
       : Base(a0, a1, a2, a3, args...) {}
 
     /** \brief Constructs an array and initializes it from the coefficients given as initializer-lists grouped by row. \cpp11
-      * 
+      *
       * In the general case, the constructor takes a list of rows, each row being represented as a list of coefficients:
-      * 
+      *
       * Example: \include Array_initializer_list_23_cxx11.cpp
       * Output: \verbinclude Array_initializer_list_23_cxx11.out
-      * 
+      *
       * Each of the inner initializer lists must contain the exact same number of elements, otherwise an assertion is triggered.
-      * 
+      *
       * In the case of a compile-time column 1D array, implicit transposition from a single row is allowed.
       * Therefore <code> Array<int,Dynamic,1>{{1,2,3,4,5}}</code> is legal and the more verbose syntax
       * <code>Array<int,Dynamic,1>{{1},{2},{3},{4},{5}}</code> can be avoided:
-      * 
+      *
       * Example: \include Array_initializer_list_vector_cxx11.cpp
       * Output: \verbinclude Array_initializer_list_vector_cxx11.out
-      * 
+      *
       * In the case of fixed-sized arrays, the initializer list sizes must exactly match the array sizes,
       * and implicit transposition is allowed for compile-time 1D arrays only.
-      * 
+      *
       * \sa  Array(const Scalar& a0, const Scalar& a1, const Scalar& a2, const Scalar& a3, const ArgTypes&... args)
       */
     EIGEN_DEVICE_FUNC
     EIGEN_STRONG_INLINE Array(const std::initializer_list<std::initializer_list<Scalar>>& list) : Base(list) {}
     #endif // end EIGEN_HAS_CXX11
 
     #ifndef EIGEN_PARSED_BY_DOXYGEN
@@ -237,15 +237,15 @@
       * This is useful for dynamic-size arrays. For fixed-size arrays,
       * it is redundant to pass these parameters, so one should use the default constructor
       * Array() instead. */
     Array(Index rows, Index cols);
     /** constructs an initialized 2D vector with given coefficients
       * \sa Array(const Scalar& a0, const Scalar& a1, const Scalar& a2, const Scalar& a3, const ArgTypes&... args) */
     Array(const Scalar& val0, const Scalar& val1);
-    #endif  // end EIGEN_PARSED_BY_DOXYGEN 
+    #endif  // end EIGEN_PARSED_BY_DOXYGEN
 
     /** constructs an initialized 3D vector with given coefficients
       * \sa Array(const Scalar& a0, const Scalar& a1, const Scalar& a2, const Scalar& a3, const ArgTypes&... args)
       */
     EIGEN_DEVICE_FUNC
     EIGEN_STRONG_INLINE Array(const Scalar& val0, const Scalar& val1, const Scalar& val2)
     {
@@ -284,16 +284,18 @@
     EIGEN_DEVICE_FUNC
     EIGEN_STRONG_INLINE Array(const EigenBase<OtherDerived> &other,
                               typename internal::enable_if<internal::is_convertible<typename OtherDerived::Scalar,Scalar>::value,
                                                            PrivateType>::type = PrivateType())
       : Base(other.derived())
     { }
 
-    EIGEN_DEVICE_FUNC inline Index innerStride() const { return 1; }
-    EIGEN_DEVICE_FUNC inline Index outerStride() const { return this->innerSize(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index innerStride() const EIGEN_NOEXCEPT{ return 1; }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index outerStride() const EIGEN_NOEXCEPT { return this->innerSize(); }
 
     #ifdef EIGEN_ARRAY_PLUGIN
     #include EIGEN_ARRAY_PLUGIN
     #endif
 
   private:
 
@@ -318,15 +320,15 @@
   * a fixed-size 1D array of 4 complex floats.
   *
   * With \cpp11, template alias are also defined for common sizes.
   * They follow the same pattern as above except that the scalar type suffix is replaced by a
   * template parameter, i.e.:
   *   - `ArrayRowsCols<Type>` where `Rows` and `Cols` can be \c 2,\c 3,\c 4, or \c X for fixed or dynamic size.
   *   - `ArraySize<Type>` where `Size` can be \c 2,\c 3,\c 4 or \c X for fixed or dynamic size 1D arrays.
-  * 
+  *
   * \sa class Array
   */
 
 #define EIGEN_MAKE_ARRAY_TYPEDEFS(Type, TypeSuffix, Size, SizeSuffix)   \
 /** \ingroup arraytypedefs */                                    \
 typedef Array<Type, Size, Size> Array##SizeSuffix##SizeSuffix##TypeSuffix;  \
 /** \ingroup arraytypedefs */                                    \
@@ -363,15 +365,15 @@
 /** \ingroup arraytypedefs */                                     \
 /** \brief \cpp11 */                                              \
 template <typename Type>                                          \
 using Array##SizeSuffix##SizeSuffix = Array<Type, Size, Size>;    \
 /** \ingroup arraytypedefs */                                     \
 /** \brief \cpp11 */                                              \
 template <typename Type>                                          \
-using Array##SizeSuffix = Array<Type, Size, 1>; 
+using Array##SizeSuffix = Array<Type, Size, 1>;
 
 #define EIGEN_MAKE_ARRAY_FIXED_TYPEDEFS(Size)                     \
 /** \ingroup arraytypedefs */                                     \
 /** \brief \cpp11 */                                              \
 template <typename Type>                                          \
 using Array##Size##X = Array<Type, Size, Dynamic>;                \
 /** \ingroup arraytypedefs */                                     \
@@ -387,15 +389,15 @@
 EIGEN_MAKE_ARRAY_FIXED_TYPEDEFS(3)
 EIGEN_MAKE_ARRAY_FIXED_TYPEDEFS(4)
 
 #undef EIGEN_MAKE_ARRAY_TYPEDEFS
 #undef EIGEN_MAKE_ARRAY_FIXED_TYPEDEFS
 
 #endif // EIGEN_HAS_CXX11
-  
+
 #define EIGEN_USING_ARRAY_TYPEDEFS_FOR_TYPE_AND_SIZE(TypeSuffix, SizeSuffix) \
 using Eigen::Matrix##SizeSuffix##TypeSuffix; \
 using Eigen::Vector##SizeSuffix##TypeSuffix; \
 using Eigen::RowVector##SizeSuffix##TypeSuffix;
 
 #define EIGEN_USING_ARRAY_TYPEDEFS_FOR_TYPE(TypeSuffix) \
 EIGEN_USING_ARRAY_TYPEDEFS_FOR_TYPE_AND_SIZE(TypeSuffix, 2) \
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/ArrayBase.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/ArrayBase.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/ArrayWrapper.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/ArrayWrapper.h`

 * *Files 20% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_ARRAYWRAPPER_H
 #define EIGEN_ARRAYWRAPPER_H
 
-namespace Eigen { 
+namespace Eigen {
 
 /** \class ArrayWrapper
   * \ingroup Core_Module
   *
   * \brief Expression of a mathematical vector or matrix as an array object
   *
   * This class is the return type of MatrixBase::array(), and most of the time
@@ -56,22 +56,22 @@
     typedef typename internal::ref_selector<ExpressionType>::non_const_type NestedExpressionType;
 
     using Base::coeffRef;
 
     EIGEN_DEVICE_FUNC
     explicit EIGEN_STRONG_INLINE ArrayWrapper(ExpressionType& matrix) : m_expression(matrix) {}
 
-    EIGEN_DEVICE_FUNC
-    inline Index rows() const { return m_expression.rows(); }
-    EIGEN_DEVICE_FUNC
-    inline Index cols() const { return m_expression.cols(); }
-    EIGEN_DEVICE_FUNC
-    inline Index outerStride() const { return m_expression.outerStride(); }
-    EIGEN_DEVICE_FUNC
-    inline Index innerStride() const { return m_expression.innerStride(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index rows() const EIGEN_NOEXCEPT { return m_expression.rows(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index cols() const EIGEN_NOEXCEPT { return m_expression.cols(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index outerStride() const EIGEN_NOEXCEPT { return m_expression.outerStride(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index innerStride() const EIGEN_NOEXCEPT { return m_expression.innerStride(); }
 
     EIGEN_DEVICE_FUNC
     inline ScalarWithConstIfNotLvalue* data() { return m_expression.data(); }
     EIGEN_DEVICE_FUNC
     inline const Scalar* data() const { return m_expression.data(); }
 
     EIGEN_DEVICE_FUNC
@@ -87,16 +87,16 @@
     }
 
     template<typename Dest>
     EIGEN_DEVICE_FUNC
     inline void evalTo(Dest& dst) const { dst = m_expression; }
 
     EIGEN_DEVICE_FUNC
-    const typename internal::remove_all<NestedExpressionType>::type& 
-    nestedExpression() const 
+    const typename internal::remove_all<NestedExpressionType>::type&
+    nestedExpression() const
     {
       return m_expression;
     }
 
     /** Forwards the resizing request to the nested expression
       * \sa DenseBase::resize(Index)  */
     EIGEN_DEVICE_FUNC
@@ -154,22 +154,22 @@
     typedef typename internal::ref_selector<ExpressionType>::non_const_type NestedExpressionType;
 
     using Base::coeffRef;
 
     EIGEN_DEVICE_FUNC
     explicit inline MatrixWrapper(ExpressionType& matrix) : m_expression(matrix) {}
 
-    EIGEN_DEVICE_FUNC
-    inline Index rows() const { return m_expression.rows(); }
-    EIGEN_DEVICE_FUNC
-    inline Index cols() const { return m_expression.cols(); }
-    EIGEN_DEVICE_FUNC
-    inline Index outerStride() const { return m_expression.outerStride(); }
-    EIGEN_DEVICE_FUNC
-    inline Index innerStride() const { return m_expression.innerStride(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index rows() const EIGEN_NOEXCEPT { return m_expression.rows(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index cols() const EIGEN_NOEXCEPT { return m_expression.cols(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index outerStride() const EIGEN_NOEXCEPT { return m_expression.outerStride(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index innerStride() const EIGEN_NOEXCEPT { return m_expression.innerStride(); }
 
     EIGEN_DEVICE_FUNC
     inline ScalarWithConstIfNotLvalue* data() { return m_expression.data(); }
     EIGEN_DEVICE_FUNC
     inline const Scalar* data() const { return m_expression.data(); }
 
     EIGEN_DEVICE_FUNC
@@ -181,16 +181,16 @@
     EIGEN_DEVICE_FUNC
     inline const Scalar& coeffRef(Index index) const
     {
       return m_expression.coeffRef(index);
     }
 
     EIGEN_DEVICE_FUNC
-    const typename internal::remove_all<NestedExpressionType>::type& 
-    nestedExpression() const 
+    const typename internal::remove_all<NestedExpressionType>::type&
+    nestedExpression() const
     {
       return m_expression;
     }
 
     /** Forwards the resizing request to the nested expression
       * \sa DenseBase::resize(Index)  */
     EIGEN_DEVICE_FUNC
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Assign.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Assign.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/AssignEvaluator.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/AssignEvaluator.h`

 * *Files 4% similar despite different names*

```diff
@@ -13,32 +13,32 @@
 #define EIGEN_ASSIGN_EVALUATOR_H
 
 namespace Eigen {
 
 // This implementation is based on Assign.h
 
 namespace internal {
-  
+
 /***************************************************************************
 * Part 1 : the logic deciding a strategy for traversal and unrolling       *
 ***************************************************************************/
 
 // copy_using_evaluator_traits is based on assign_traits
 
 template <typename DstEvaluator, typename SrcEvaluator, typename AssignFunc, int MaxPacketSize = -1>
 struct copy_using_evaluator_traits
 {
   typedef typename DstEvaluator::XprType Dst;
   typedef typename Dst::Scalar DstScalar;
-  
+
   enum {
     DstFlags = DstEvaluator::Flags,
     SrcFlags = SrcEvaluator::Flags
   };
-  
+
 public:
   enum {
     DstAlignment = DstEvaluator::Alignment,
     SrcAlignment = SrcEvaluator::Alignment,
     DstHasDirectAccess = (DstFlags & DirectAccessBit) == DirectAccessBit,
     JointAlignment = EIGEN_PLAIN_ENUM_MIN(DstAlignment,SrcAlignment)
   };
@@ -95,15 +95,16 @@
          indicated by InnerMaxSize rather than InnerSize, think of the case of a dynamic block
          in a fixed-size matrix
          However, with EIGEN_UNALIGNED_VECTORIZE and unrolling, slice vectorization is still worth it */
   };
 
 public:
   enum {
-    Traversal = (int(MayLinearVectorize) && (LinearPacketSize>InnerPacketSize)) ? int(LinearVectorizedTraversal)
+    Traversal =  int(Dst::SizeAtCompileTime) == 0 ? int(AllAtOnceTraversal) // If compile-size is zero, traversing will fail at compile-time.
+              : (int(MayLinearVectorize) && (LinearPacketSize>InnerPacketSize)) ? int(LinearVectorizedTraversal)
               : int(MayInnerVectorize)   ? int(InnerVectorizedTraversal)
               : int(MayLinearVectorize)  ? int(LinearVectorizedTraversal)
               : int(MaySliceVectorize)   ? int(SliceVectorizedTraversal)
               : int(MayLinearize)        ? int(LinearTraversal)
                                          : int(DefaultTraversal),
     Vectorized = int(Traversal) == InnerVectorizedTraversal
               || int(Traversal) == LinearVectorizedTraversal
@@ -133,15 +134,15 @@
                                              : int(NoUnrolling)
                   )
               : int(Traversal) == int(LinearVectorizedTraversal)
                 ? ( bool(MayUnrollCompletely) && ( EIGEN_UNALIGNED_VECTORIZE || (int(DstAlignment)>=int(LinearRequiredAlignment)))
                           ? int(CompleteUnrolling)
                           : int(NoUnrolling) )
               : int(Traversal) == int(LinearTraversal)
-                ? ( bool(MayUnrollCompletely) ? int(CompleteUnrolling) 
+                ? ( bool(MayUnrollCompletely) ? int(CompleteUnrolling)
                                               : int(NoUnrolling) )
 #if EIGEN_UNALIGNED_VECTORIZE
               : int(Traversal) == int(SliceVectorizedTraversal)
                 ? ( bool(MayUnrollInner) ? int(InnerUnrolling)
                                          : int(NoUnrolling) )
 #endif
               : int(NoUnrolling)
@@ -195,15 +196,15 @@
 
 template<typename Kernel, int Index, int Stop>
 struct copy_using_evaluator_DefaultTraversal_CompleteUnrolling
 {
   // FIXME: this is not very clean, perhaps this information should be provided by the kernel?
   typedef typename Kernel::DstEvaluatorType DstEvaluatorType;
   typedef typename DstEvaluatorType::XprType DstXprType;
-  
+
   enum {
     outer = Index / DstXprType::InnerSizeAtCompileTime,
     inner = Index % DstXprType::InnerSizeAtCompileTime
   };
 
   EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE void run(Kernel &kernel)
   {
@@ -261,15 +262,15 @@
 template<typename Kernel, int Index, int Stop>
 struct copy_using_evaluator_innervec_CompleteUnrolling
 {
   // FIXME: this is not very clean, perhaps this information should be provided by the kernel?
   typedef typename Kernel::DstEvaluatorType DstEvaluatorType;
   typedef typename DstEvaluatorType::XprType DstXprType;
   typedef typename Kernel::PacketType PacketType;
-  
+
   enum {
     outer = Index / DstXprType::InnerSizeAtCompileTime,
     inner = Index % DstXprType::InnerSizeAtCompileTime,
     SrcAlignment = Kernel::AssignmentTraits::SrcAlignment,
     DstAlignment = Kernel::AssignmentTraits::DstAlignment
   };
 
@@ -313,14 +314,30 @@
 
 template<typename Kernel,
          int Traversal = Kernel::AssignmentTraits::Traversal,
          int Unrolling = Kernel::AssignmentTraits::Unrolling>
 struct dense_assignment_loop;
 
 /************************
+***** Special Cases *****
+************************/
+
+// Zero-sized assignment is a no-op.
+template<typename Kernel, int Unrolling>
+struct dense_assignment_loop<Kernel, AllAtOnceTraversal, Unrolling>
+{
+  EIGEN_DEVICE_FUNC static void EIGEN_STRONG_INLINE run(Kernel& /*kernel*/)
+  {
+    typedef typename Kernel::DstEvaluatorType::XprType DstXprType;
+    EIGEN_STATIC_ASSERT(int(DstXprType::SizeAtCompileTime) == 0,
+      EIGEN_INTERNAL_ERROR_PLEASE_FILE_A_BUG_REPORT)
+  }
+};
+
+/************************
 *** Default traversal ***
 ************************/
 
 template<typename Kernel>
 struct dense_assignment_loop<Kernel, DefaultTraversal, NoUnrolling>
 {
   EIGEN_DEVICE_FUNC static void EIGEN_STRONG_INLINE run(Kernel &kernel)
@@ -426,18 +443,18 @@
 template<typename Kernel>
 struct dense_assignment_loop<Kernel, LinearVectorizedTraversal, CompleteUnrolling>
 {
   EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE void run(Kernel &kernel)
   {
     typedef typename Kernel::DstEvaluatorType::XprType DstXprType;
     typedef typename Kernel::PacketType PacketType;
-    
+
     enum { size = DstXprType::SizeAtCompileTime,
            packetSize =unpacket_traits<PacketType>::size,
-           alignedSize = (size/packetSize)*packetSize };
+           alignedSize = (int(size)/packetSize)*packetSize };
 
     copy_using_evaluator_innervec_CompleteUnrolling<Kernel, 0, alignedSize>::run(kernel);
     copy_using_evaluator_DefaultTraversal_CompleteUnrolling<Kernel, alignedSize, size>::run(kernel);
   }
 };
 
 /**************************
@@ -568,22 +585,23 @@
 struct dense_assignment_loop<Kernel, SliceVectorizedTraversal, InnerUnrolling>
 {
   EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE void run(Kernel &kernel)
   {
     typedef typename Kernel::DstEvaluatorType::XprType DstXprType;
     typedef typename Kernel::PacketType PacketType;
 
-    enum { size = DstXprType::InnerSizeAtCompileTime,
+    enum { innerSize = DstXprType::InnerSizeAtCompileTime,
            packetSize =unpacket_traits<PacketType>::size,
-           vectorizableSize = (size/packetSize)*packetSize };
+           vectorizableSize = (int(innerSize) / int(packetSize)) * int(packetSize),
+           size = DstXprType::SizeAtCompileTime };
 
     for(Index outer = 0; outer < kernel.outerSize(); ++outer)
     {
       copy_using_evaluator_innervec_InnerUnrolling<Kernel, 0, vectorizableSize, 0, 0>::run(kernel, outer);
-      copy_using_evaluator_DefaultTraversal_InnerUnrolling<Kernel, vectorizableSize, size>::run(kernel, outer);
+      copy_using_evaluator_DefaultTraversal_InnerUnrolling<Kernel, vectorizableSize, innerSize>::run(kernel, outer);
     }
   }
 };
 #endif
 
 
 /***************************************************************************
@@ -599,82 +617,82 @@
 template<typename DstEvaluatorTypeT, typename SrcEvaluatorTypeT, typename Functor, int Version = Specialized>
 class generic_dense_assignment_kernel
 {
 protected:
   typedef typename DstEvaluatorTypeT::XprType DstXprType;
   typedef typename SrcEvaluatorTypeT::XprType SrcXprType;
 public:
-  
+
   typedef DstEvaluatorTypeT DstEvaluatorType;
   typedef SrcEvaluatorTypeT SrcEvaluatorType;
   typedef typename DstEvaluatorType::Scalar Scalar;
   typedef copy_using_evaluator_traits<DstEvaluatorTypeT, SrcEvaluatorTypeT, Functor> AssignmentTraits;
   typedef typename AssignmentTraits::PacketType PacketType;
-  
-  
+
+
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   generic_dense_assignment_kernel(DstEvaluatorType &dst, const SrcEvaluatorType &src, const Functor &func, DstXprType& dstExpr)
     : m_dst(dst), m_src(src), m_functor(func), m_dstExpr(dstExpr)
   {
     #ifdef EIGEN_DEBUG_ASSIGN
     AssignmentTraits::debug();
     #endif
   }
-  
-  EIGEN_DEVICE_FUNC Index size() const        { return m_dstExpr.size(); }
-  EIGEN_DEVICE_FUNC Index innerSize() const   { return m_dstExpr.innerSize(); }
-  EIGEN_DEVICE_FUNC Index outerSize() const   { return m_dstExpr.outerSize(); }
-  EIGEN_DEVICE_FUNC Index rows() const        { return m_dstExpr.rows(); }
-  EIGEN_DEVICE_FUNC Index cols() const        { return m_dstExpr.cols(); }
-  EIGEN_DEVICE_FUNC Index outerStride() const { return m_dstExpr.outerStride(); }
-  
-  EIGEN_DEVICE_FUNC DstEvaluatorType& dstEvaluator() { return m_dst; }
-  EIGEN_DEVICE_FUNC const SrcEvaluatorType& srcEvaluator() const { return m_src; }
-  
+
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index size() const EIGEN_NOEXCEPT { return m_dstExpr.size(); }
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index innerSize() const EIGEN_NOEXCEPT { return m_dstExpr.innerSize(); }
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index outerSize() const EIGEN_NOEXCEPT { return m_dstExpr.outerSize(); }
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index rows() const EIGEN_NOEXCEPT { return m_dstExpr.rows(); }
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index cols() const EIGEN_NOEXCEPT { return m_dstExpr.cols(); }
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index outerStride() const EIGEN_NOEXCEPT { return m_dstExpr.outerStride(); }
+
+  EIGEN_DEVICE_FUNC DstEvaluatorType& dstEvaluator() EIGEN_NOEXCEPT { return m_dst; }
+  EIGEN_DEVICE_FUNC const SrcEvaluatorType& srcEvaluator() const EIGEN_NOEXCEPT { return m_src; }
+
   /// Assign src(row,col) to dst(row,col) through the assignment functor.
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void assignCoeff(Index row, Index col)
   {
     m_functor.assignCoeff(m_dst.coeffRef(row,col), m_src.coeff(row,col));
   }
-  
+
   /// \sa assignCoeff(Index,Index)
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void assignCoeff(Index index)
   {
     m_functor.assignCoeff(m_dst.coeffRef(index), m_src.coeff(index));
   }
-  
+
   /// \sa assignCoeff(Index,Index)
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void assignCoeffByOuterInner(Index outer, Index inner)
   {
-    Index row = rowIndexByOuterInner(outer, inner); 
-    Index col = colIndexByOuterInner(outer, inner); 
+    Index row = rowIndexByOuterInner(outer, inner);
+    Index col = colIndexByOuterInner(outer, inner);
     assignCoeff(row, col);
   }
-  
-  
+
+
   template<int StoreMode, int LoadMode, typename PacketType>
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void assignPacket(Index row, Index col)
   {
     m_functor.template assignPacket<StoreMode>(&m_dst.coeffRef(row,col), m_src.template packet<LoadMode,PacketType>(row,col));
   }
-  
+
   template<int StoreMode, int LoadMode, typename PacketType>
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void assignPacket(Index index)
   {
     m_functor.template assignPacket<StoreMode>(&m_dst.coeffRef(index), m_src.template packet<LoadMode,PacketType>(index));
   }
-  
+
   template<int StoreMode, int LoadMode, typename PacketType>
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void assignPacketByOuterInner(Index outer, Index inner)
   {
-    Index row = rowIndexByOuterInner(outer, inner); 
+    Index row = rowIndexByOuterInner(outer, inner);
     Index col = colIndexByOuterInner(outer, inner);
     assignPacket<StoreMode,LoadMode,PacketType>(row, col);
   }
-  
+
   EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE Index rowIndexByOuterInner(Index outer, Index inner)
   {
     typedef typename DstEvaluatorType::ExpressionTraits Traits;
     return int(Traits::RowsAtCompileTime) == 1 ? 0
       : int(Traits::ColsAtCompileTime) == 1 ? inner
       : int(DstEvaluatorType::Flags)&RowMajorBit ? outer
       : inner;
@@ -689,15 +707,15 @@
       : outer;
   }
 
   EIGEN_DEVICE_FUNC const Scalar* dstDataPtr() const
   {
     return m_dstExpr.data();
   }
-  
+
 protected:
   DstEvaluatorType& m_dst;
   const SrcEvaluatorType& m_src;
   const Functor &m_functor;
   // TODO find a way to avoid the needs of the original expression
   DstXprType& m_dstExpr;
 };
@@ -712,21 +730,21 @@
 protected:
   typedef generic_dense_assignment_kernel<DstEvaluatorTypeT, SrcEvaluatorTypeT, Functor, BuiltIn> Base;
  public:
     typedef typename Base::Scalar Scalar;
     typedef typename Base::DstXprType DstXprType;
     typedef copy_using_evaluator_traits<DstEvaluatorTypeT, SrcEvaluatorTypeT, Functor, 4> AssignmentTraits;
     typedef typename AssignmentTraits::PacketType PacketType;
-    
+
     EIGEN_DEVICE_FUNC restricted_packet_dense_assignment_kernel(DstEvaluatorTypeT &dst, const SrcEvaluatorTypeT &src, const Functor &func, DstXprType& dstExpr)
     : Base(dst, src, func, dstExpr)
   {
   }
  };
- 
+
 /***************************************************************************
 * Part 5 : Entry point for dense rectangular assignment
 ***************************************************************************/
 
 template<typename DstXprType,typename SrcXprType, typename Functor>
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
 void resize_if_allowed(DstXprType &dst, const SrcXprType& src, const Functor &/*func*/)
@@ -756,21 +774,31 @@
   SrcEvaluatorType srcEvaluator(src);
 
   // NOTE To properly handle A = (A*A.transpose())/s with A rectangular,
   // we need to resize the destination after the source evaluator has been created.
   resize_if_allowed(dst, src, func);
 
   DstEvaluatorType dstEvaluator(dst);
-    
+
   typedef generic_dense_assignment_kernel<DstEvaluatorType,SrcEvaluatorType,Functor> Kernel;
   Kernel kernel(dstEvaluator, srcEvaluator, func, dst.const_cast_derived());
 
   dense_assignment_loop<Kernel>::run(kernel);
 }
 
+// Specialization for filling the destination with a constant value.
+#ifndef EIGEN_GPU_COMPILE_PHASE
+template<typename DstXprType>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void call_dense_assignment_loop(DstXprType& dst, const Eigen::CwiseNullaryOp<Eigen::internal::scalar_constant_op<typename DstXprType::Scalar>, DstXprType>& src, const internal::assign_op<typename DstXprType::Scalar,typename DstXprType::Scalar>& func)
+{
+  resize_if_allowed(dst, src, func);
+  std::fill_n(dst.data(), dst.size(), src.functor()());
+}
+#endif
+
 template<typename DstXprType, typename SrcXprType>
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void call_dense_assignment_loop(DstXprType& dst, const SrcXprType& src)
 {
   call_dense_assignment_loop(dst, src, internal::assign_op<typename DstXprType::Scalar,typename SrcXprType::Scalar>());
 }
 
 /***************************************************************************
@@ -784,15 +812,15 @@
 
 // Assignment kind defined in this file:
 struct Dense2Dense {};
 struct EigenBase2EigenBase {};
 
 template<typename,typename> struct AssignmentKind { typedef EigenBase2EigenBase Kind; };
 template<> struct AssignmentKind<DenseShape,DenseShape> { typedef Dense2Dense Kind; };
-    
+
 // This is the main assignment class
 template< typename DstXprType, typename SrcXprType, typename Functor,
           typename Kind = typename AssignmentKind< typename evaluator_traits<DstXprType>::Shape , typename evaluator_traits<SrcXprType>::Shape >::Kind,
           typename EnableIf = void>
 struct Assignment;
 
 
@@ -809,15 +837,15 @@
 }
 template<typename Dst, typename Src>
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
 void call_assignment(const Dst& dst, const Src& src)
 {
   call_assignment(dst, src, internal::assign_op<typename Dst::Scalar,typename Src::Scalar>());
 }
-                     
+
 // Deal with "assume-aliasing"
 template<typename Dst, typename Src, typename Func>
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
 void call_assignment(Dst& dst, const Src& src, const Func& func, typename enable_if< evaluator_assume_aliasing<Src>::value, void*>::type = 0)
 {
   typename plain_matrix_type<Src>::type tmp(src);
   call_assignment_no_alias(dst, tmp, func);
@@ -849,20 +877,20 @@
                         || (int(Dst::ColsAtCompileTime) == 1 && int(Src::RowsAtCompileTime) == 1)
                       ) && int(Dst::SizeAtCompileTime) != 1
   };
 
   typedef typename internal::conditional<NeedToTranspose, Transpose<Dst>, Dst>::type ActualDstTypeCleaned;
   typedef typename internal::conditional<NeedToTranspose, Transpose<Dst>, Dst&>::type ActualDstType;
   ActualDstType actualDst(dst);
-  
+
   // TODO check whether this is the right place to perform these checks:
   EIGEN_STATIC_ASSERT_LVALUE(Dst)
   EIGEN_STATIC_ASSERT_SAME_MATRIX_SIZE(ActualDstTypeCleaned,Src)
   EIGEN_CHECK_BINARY_COMPATIBILIY(Func,typename ActualDstTypeCleaned::Scalar,typename Src::Scalar);
-  
+
   Assignment<ActualDstTypeCleaned,Src,Func>::run(actualDst, src, func);
 }
 
 template<typename Dst, typename Src, typename Func>
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
 void call_restricted_packet_assignment_no_alias(Dst& dst, const Src& src, const Func& func)
 {
@@ -871,15 +899,15 @@
     typedef restricted_packet_dense_assignment_kernel<DstEvaluatorType,SrcEvaluatorType,Func> Kernel;
 
     EIGEN_STATIC_ASSERT_LVALUE(Dst)
     EIGEN_CHECK_BINARY_COMPATIBILIY(Func,typename Dst::Scalar,typename Src::Scalar);
 
     SrcEvaluatorType srcEvaluator(src);
     resize_if_allowed(dst, src, func);
-    
+
     DstEvaluatorType dstEvaluator(dst);
     Kernel kernel(dstEvaluator, srcEvaluator, func, dst.const_cast_derived());
 
     dense_assignment_loop<Kernel>::run(kernel);
 }
 
 template<typename Dst, typename Src>
@@ -918,15 +946,15 @@
 {
   EIGEN_DEVICE_FUNC
   static EIGEN_STRONG_INLINE void run(DstXprType &dst, const SrcXprType &src, const Functor &func)
   {
 #ifndef EIGEN_NO_DEBUG
     internal::check_for_aliasing(dst, src);
 #endif
-    
+
     call_dense_assignment_loop(dst, src, func);
   }
 };
 
 // Generic assignment through evalTo.
 // TODO: not sure we have to keep that one, but it helps porting current code to new evaluator mechanism.
 // Note that the last template argument "Weak" is needed to make it possible to perform
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Assign_MKL.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Assign_MKL.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/BandMatrix.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/BandMatrix.h`

 * *Files 2% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_BANDMATRIX_H
 #define EIGEN_BANDMATRIX_H
 
-namespace Eigen { 
+namespace Eigen {
 
 namespace internal {
 
 template<typename Derived>
 class BandMatrixBase : public EigenBase<Derived>
 {
   public:
@@ -41,37 +41,37 @@
       DataRowsAtCompileTime = ((Supers!=Dynamic) && (Subs!=Dynamic))
                             ? 1 + Supers + Subs
                             : Dynamic,
       SizeAtCompileTime = EIGEN_SIZE_MIN_PREFER_DYNAMIC(RowsAtCompileTime,ColsAtCompileTime)
     };
 
   public:
-    
+
     using Base::derived;
     using Base::rows;
     using Base::cols;
 
     /** \returns the number of super diagonals */
     inline Index supers() const { return derived().supers(); }
 
     /** \returns the number of sub diagonals */
     inline Index subs() const { return derived().subs(); }
-    
+
     /** \returns an expression of the underlying coefficient matrix */
     inline const CoefficientsType& coeffs() const { return derived().coeffs(); }
-    
+
     /** \returns an expression of the underlying coefficient matrix */
     inline CoefficientsType& coeffs() { return derived().coeffs(); }
 
     /** \returns a vector expression of the \a i -th column,
       * only the meaningful part is returned.
       * \warning the internal storage must be column major. */
     inline Block<CoefficientsType,Dynamic,1> col(Index i)
     {
-      EIGEN_STATIC_ASSERT((Options&RowMajor)==0,THIS_METHOD_IS_ONLY_FOR_COLUMN_MAJOR_MATRICES);
+      EIGEN_STATIC_ASSERT((int(Options) & int(RowMajor)) == 0, THIS_METHOD_IS_ONLY_FOR_COLUMN_MAJOR_MATRICES);
       Index start = 0;
       Index len = coeffs().rows();
       if (i<=supers())
       {
         start = supers()-i;
         len = (std::min)(rows(),std::max<Index>(0,coeffs().rows() - (supers()-i)));
       }
@@ -86,15 +86,15 @@
 
     /** \returns a vector expression of the main diagonal (const version) */
     inline const Block<const CoefficientsType,1,SizeAtCompileTime> diagonal() const
     { return Block<const CoefficientsType,1,SizeAtCompileTime>(coeffs(),supers(),0,1,(std::min)(rows(),cols())); }
 
     template<int Index> struct DiagonalIntReturnType {
       enum {
-        ReturnOpposite = (Options&SelfAdjoint) && (((Index)>0 && Supers==0) || ((Index)<0 && Subs==0)),
+        ReturnOpposite = (int(Options) & int(SelfAdjoint)) && (((Index) > 0 && Supers == 0) || ((Index) < 0 && Subs == 0)),
         Conjugate = ReturnOpposite && NumTraits<Scalar>::IsComplex,
         ActualIndex = ReturnOpposite ? -Index : Index,
         DiagonalSize = (RowsAtCompileTime==Dynamic || ColsAtCompileTime==Dynamic)
                      ? Dynamic
                      : (ActualIndex<0
                      ? EIGEN_SIZE_MIN_PREFER_DYNAMIC(ColsAtCompileTime, RowsAtCompileTime + ActualIndex)
                      : EIGEN_SIZE_MIN_PREFER_DYNAMIC(RowsAtCompileTime, ColsAtCompileTime - ActualIndex))
@@ -126,15 +126,15 @@
 
     /** \returns a vector expression of the \a i -th sub or super diagonal */
     inline const Block<const CoefficientsType,1,Dynamic> diagonal(Index i) const
     {
       eigen_assert((i<0 && -i<=subs()) || (i>=0 && i<=supers()));
       return Block<const CoefficientsType,1,Dynamic>(coeffs(), supers()-i, std::max<Index>(0,i), 1, diagonalLength(i));
     }
-    
+
     template<typename Dest> inline void evalTo(Dest& dst) const
     {
       dst.resize(rows(),cols());
       dst.setZero();
       dst.diagonal() = diagonal();
       for (Index i=1; i<=supers();++i)
         dst.diagonal(i) = diagonal(i);
@@ -188,15 +188,15 @@
     MaxColsAtCompileTime = _Cols,
     Flags = LvalueBit,
     Supers = _Supers,
     Subs = _Subs,
     Options = _Options,
     DataRowsAtCompileTime = ((Supers!=Dynamic) && (Subs!=Dynamic)) ? 1 + Supers + Subs : Dynamic
   };
-  typedef Matrix<Scalar,DataRowsAtCompileTime,ColsAtCompileTime,Options&RowMajor?RowMajor:ColMajor> CoefficientsType;
+  typedef Matrix<Scalar, DataRowsAtCompileTime, ColsAtCompileTime, int(Options) & int(RowMajor) ? RowMajor : ColMajor> CoefficientsType;
 };
 
 template<typename _Scalar, int Rows, int Cols, int Supers, int Subs, int Options>
 class BandMatrix : public BandMatrixBase<BandMatrix<_Scalar,Rows,Cols,Supers,Subs,Options> >
 {
   public:
 
@@ -207,24 +207,24 @@
     explicit inline BandMatrix(Index rows=Rows, Index cols=Cols, Index supers=Supers, Index subs=Subs)
       : m_coeffs(1+supers+subs,cols),
         m_rows(rows), m_supers(supers), m_subs(subs)
     {
     }
 
     /** \returns the number of columns */
-    inline Index rows() const { return m_rows.value(); }
+    inline EIGEN_CONSTEXPR Index rows() const { return m_rows.value(); }
 
     /** \returns the number of rows */
-    inline Index cols() const { return m_coeffs.cols(); }
+    inline EIGEN_CONSTEXPR Index cols() const { return m_coeffs.cols(); }
 
     /** \returns the number of super diagonals */
-    inline Index supers() const { return m_supers.value(); }
+    inline EIGEN_CONSTEXPR Index supers() const { return m_supers.value(); }
 
     /** \returns the number of sub diagonals */
-    inline Index subs() const { return m_subs.value(); }
+    inline EIGEN_CONSTEXPR Index subs() const { return m_subs.value(); }
 
     inline const CoefficientsType& coeffs() const { return m_coeffs; }
     inline CoefficientsType& coeffs() { return m_coeffs; }
 
   protected:
 
     CoefficientsType m_coeffs;
@@ -271,24 +271,24 @@
         m_rows(rows), m_supers(supers), m_subs(subs)
     {
       EIGEN_UNUSED_VARIABLE(cols);
       //internal::assert(coeffs.cols()==cols() && (supers()+subs()+1)==coeffs.rows());
     }
 
     /** \returns the number of columns */
-    inline Index rows() const { return m_rows.value(); }
+    inline EIGEN_CONSTEXPR Index rows() const { return m_rows.value(); }
 
     /** \returns the number of rows */
-    inline Index cols() const { return m_coeffs.cols(); }
+    inline EIGEN_CONSTEXPR Index cols() const { return m_coeffs.cols(); }
 
     /** \returns the number of super diagonals */
-    inline Index supers() const { return m_supers.value(); }
+    inline EIGEN_CONSTEXPR Index supers() const { return m_supers.value(); }
 
     /** \returns the number of sub diagonals */
-    inline Index subs() const { return m_subs.value(); }
+    inline EIGEN_CONSTEXPR Index subs() const { return m_subs.value(); }
 
     inline const CoefficientsType& coeffs() const { return m_coeffs; }
 
   protected:
 
     const CoefficientsType& m_coeffs;
     internal::variable_if_dynamic<Index, _Rows>   m_rows;
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Block.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Block.h`

 * *Files 2% similar despite different names*

```diff
@@ -7,15 +7,15 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_BLOCK_H
 #define EIGEN_BLOCK_H
 
-namespace Eigen { 
+namespace Eigen {
 
 namespace internal {
 template<typename XprType, int BlockRows, int BlockCols, bool InnerPanel>
 struct traits<Block<XprType, BlockRows, BlockCols, InnerPanel> > : traits<XprType>
 {
   typedef typename traits<XprType>::Scalar Scalar;
   typedef typename traits<XprType>::StorageKind StorageKind;
@@ -48,24 +48,24 @@
                              : int(inner_stride_at_compile_time<XprType>::ret),
 
     // FIXME, this traits is rather specialized for dense object and it needs to be cleaned further
     FlagsLvalueBit = is_lvalue<XprType>::value ? LvalueBit : 0,
     FlagsRowMajorBit = IsRowMajor ? RowMajorBit : 0,
     Flags = (traits<XprType>::Flags & (DirectAccessBit | (InnerPanel?CompressedAccessBit:0))) | FlagsLvalueBit | FlagsRowMajorBit,
     // FIXME DirectAccessBit should not be handled by expressions
-    // 
+    //
     // Alignment is needed by MapBase's assertions
     // We can sefely set it to false here. Internal alignment errors will be detected by an eigen_internal_assert in the respective evaluator
     Alignment = 0
   };
 };
 
 template<typename XprType, int BlockRows=Dynamic, int BlockCols=Dynamic, bool InnerPanel = false,
          bool HasDirectAccess = internal::has_direct_access<XprType>::ret> class BlockImpl_dense;
-         
+
 } // end namespace internal
 
 template<typename XprType, int BlockRows, int BlockCols, bool InnerPanel, typename StorageKind> class BlockImpl;
 
 /** \class Block
   * \ingroup Core_Module
   *
@@ -105,17 +105,17 @@
 {
     typedef BlockImpl<XprType, BlockRows, BlockCols, InnerPanel, typename internal::traits<XprType>::StorageKind> Impl;
   public:
     //typedef typename Impl::Base Base;
     typedef Impl Base;
     EIGEN_GENERIC_PUBLIC_INTERFACE(Block)
     EIGEN_INHERIT_ASSIGNMENT_OPERATORS(Block)
-    
+
     typedef typename internal::remove_all<XprType>::type NestedExpression;
-  
+
     /** Column or Row constructor
       */
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
     Block(XprType& xpr, Index i) : Impl(xpr,i)
     {
       eigen_assert( (i>=0) && (
           ((BlockRows==1) && (BlockCols==XprType::ColsAtCompileTime) && i<xpr.rows())
@@ -143,15 +143,15 @@
     {
       eigen_assert((RowsAtCompileTime==Dynamic || RowsAtCompileTime==blockRows)
           && (ColsAtCompileTime==Dynamic || ColsAtCompileTime==blockCols));
       eigen_assert(startRow >= 0 && blockRows >= 0 && startRow  <= xpr.rows() - blockRows
           && startCol >= 0 && blockCols >= 0 && startCol <= xpr.cols() - blockCols);
     }
 };
-         
+
 // The generic default implementation for dense block simplu forward to the internal::BlockImpl_dense
 // that must be specialized for direct and non-direct access...
 template<typename XprType, int BlockRows, int BlockCols, bool InnerPanel>
 class BlockImpl<XprType, BlockRows, BlockCols, InnerPanel, Dense>
   : public internal::BlockImpl_dense<XprType, BlockRows, BlockCols, InnerPanel>
 {
     typedef internal::BlockImpl_dense<XprType, BlockRows, BlockCols, InnerPanel> Impl;
@@ -292,31 +292,31 @@
     EIGEN_DEVICE_FUNC inline const Scalar* data() const;
     EIGEN_DEVICE_FUNC inline Index innerStride() const;
     EIGEN_DEVICE_FUNC inline Index outerStride() const;
     #endif
 
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
     const typename internal::remove_all<XprTypeNested>::type& nestedExpression() const
-    { 
-      return m_xpr; 
+    {
+      return m_xpr;
     }
 
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
     XprType& nestedExpression() { return m_xpr; }
-      
-    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    StorageIndex startRow() const
-    { 
-      return m_startRow.value(); 
+
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    StorageIndex startRow() const EIGEN_NOEXCEPT
+    {
+      return m_startRow.value();
     }
-      
-    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    StorageIndex startCol() const
-    { 
-      return m_startCol.value(); 
+
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    StorageIndex startCol() const EIGEN_NOEXCEPT
+    {
+      return m_startCol.value();
     }
 
   protected:
 
     XprTypeNested m_xpr;
     const internal::variable_if_dynamic<StorageIndex, (XprType::RowsAtCompileTime == 1 && BlockRows==1) ? 0 : Dynamic> m_startRow;
     const internal::variable_if_dynamic<StorageIndex, (XprType::ColsAtCompileTime == 1 && BlockCols==1) ? 0 : Dynamic> m_startCol;
@@ -340,15 +340,15 @@
     EIGEN_DENSE_PUBLIC_INTERFACE(BlockType)
     EIGEN_INHERIT_ASSIGNMENT_OPERATORS(BlockImpl_dense)
 
     /** Column or Row constructor
       */
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
     BlockImpl_dense(XprType& xpr, Index i)
-      : Base(xpr.data() + i * (    ((BlockRows==1) && (BlockCols==XprType::ColsAtCompileTime) && (!XprTypeIsRowMajor)) 
+      : Base(xpr.data() + i * (    ((BlockRows==1) && (BlockCols==XprType::ColsAtCompileTime) && (!XprTypeIsRowMajor))
                                 || ((BlockRows==XprType::RowsAtCompileTime) && (BlockCols==1) && ( XprTypeIsRowMajor)) ? xpr.innerStride() : xpr.outerStride()),
              BlockRows==1 ? 1 : xpr.rows(),
              BlockCols==1 ? 1 : xpr.cols()),
         m_xpr(xpr),
         m_startRow( (BlockRows==1) && (BlockCols==XprType::ColsAtCompileTime) ? i : 0),
         m_startCol( (BlockRows==XprType::RowsAtCompileTime) && (BlockCols==1) ? i : 0)
     {
@@ -374,49 +374,45 @@
       : Base(xpr.data()+xpr.innerStride()*(XprTypeIsRowMajor?startCol:startRow) + xpr.outerStride()*(XprTypeIsRowMajor?startRow:startCol), blockRows, blockCols),
         m_xpr(xpr), m_startRow(startRow), m_startCol(startCol)
     {
       init();
     }
 
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    const typename internal::remove_all<XprTypeNested>::type& nestedExpression() const
-    { 
-      return m_xpr; 
+    const typename internal::remove_all<XprTypeNested>::type& nestedExpression() const EIGEN_NOEXCEPT
+    {
+      return m_xpr;
     }
 
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
     XprType& nestedExpression() { return m_xpr; }
-      
+
     /** \sa MapBase::innerStride() */
-    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    Index innerStride() const
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    Index innerStride() const EIGEN_NOEXCEPT
     {
       return internal::traits<BlockType>::HasSameStorageOrderAsXprType
              ? m_xpr.innerStride()
              : m_xpr.outerStride();
     }
 
     /** \sa MapBase::outerStride() */
-    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    Index outerStride() const
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    Index outerStride() const EIGEN_NOEXCEPT
     {
-      return m_outerStride;
+      return internal::traits<BlockType>::HasSameStorageOrderAsXprType
+                    ? m_xpr.outerStride()
+                    : m_xpr.innerStride();
     }
 
-    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    StorageIndex startRow() const
-    {
-      return m_startRow.value();
-    }
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    StorageIndex startRow() const EIGEN_NOEXCEPT { return m_startRow.value(); }
 
-    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    StorageIndex startCol() const
-    {
-      return m_startCol.value();
-    }
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    StorageIndex startCol() const EIGEN_NOEXCEPT { return m_startCol.value(); }
 
   #ifndef __SUNPRO_CC
   // FIXME sunstudio is not friendly with the above friend...
   // META-FIXME there is no 'friend' keyword around here. Is this obsolete?
   protected:
   #endif
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/BooleanRedux.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/BooleanRedux.h`

 * *Files 1% similar despite different names*

```diff
@@ -77,15 +77,15 @@
   */
 template<typename Derived>
 EIGEN_DEVICE_FUNC inline bool DenseBase<Derived>::all() const
 {
   typedef internal::evaluator<Derived> Evaluator;
   enum {
     unroll = SizeAtCompileTime != Dynamic
-          && SizeAtCompileTime * (Evaluator::CoeffReadCost + NumTraits<Scalar>::AddCost) <= EIGEN_UNROLLING_LIMIT
+          && SizeAtCompileTime * (int(Evaluator::CoeffReadCost) + int(NumTraits<Scalar>::AddCost)) <= EIGEN_UNROLLING_LIMIT
   };
   Evaluator evaluator(derived());
   if(unroll)
     return internal::all_unroller<Evaluator, unroll ? int(SizeAtCompileTime) : Dynamic, internal::traits<Derived>::RowsAtCompileTime>::run(evaluator);
   else
   {
     for(Index j = 0; j < cols(); ++j)
@@ -101,15 +101,15 @@
   */
 template<typename Derived>
 EIGEN_DEVICE_FUNC inline bool DenseBase<Derived>::any() const
 {
   typedef internal::evaluator<Derived> Evaluator;
   enum {
     unroll = SizeAtCompileTime != Dynamic
-          && SizeAtCompileTime * (Evaluator::CoeffReadCost + NumTraits<Scalar>::AddCost) <= EIGEN_UNROLLING_LIMIT
+          && SizeAtCompileTime * (int(Evaluator::CoeffReadCost) + int(NumTraits<Scalar>::AddCost)) <= EIGEN_UNROLLING_LIMIT
   };
   Evaluator evaluator(derived());
   if(unroll)
     return internal::any_unroller<Evaluator, unroll ? int(SizeAtCompileTime) : Dynamic, internal::traits<Derived>::RowsAtCompileTime>::run(evaluator);
   else
   {
     for(Index j = 0; j < cols(); ++j)
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/CommaInitializer.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/CommaInitializer.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/ConditionEstimator.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/ConditionEstimator.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/CoreEvaluators.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/CoreEvaluators.h`

 * *Files 2% similar despite different names*

```diff
@@ -10,15 +10,15 @@
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 
 #ifndef EIGEN_COREEVALUATORS_H
 #define EIGEN_COREEVALUATORS_H
 
 namespace Eigen {
-  
+
 namespace internal {
 
 // This class returns the evaluator kind from the expression storage kind.
 // Default assumes index based accessors
 template<typename StorageKind>
 struct storage_kind_to_evaluator_kind {
   typedef IndexBased Kind;
@@ -59,16 +59,16 @@
           typename RhsKind   = typename evaluator_traits<typename T::Rhs>::Kind,
           typename LhsScalar = typename traits<typename T::Lhs>::Scalar,
           typename RhsScalar = typename traits<typename T::Rhs>::Scalar> struct binary_evaluator;
 
 template< typename T,
           typename Kind   = typename evaluator_traits<typename T::NestedExpression>::Kind,
           typename Scalar = typename T::Scalar> struct unary_evaluator;
-          
-// evaluator_traits<T> contains traits for evaluator<T> 
+
+// evaluator_traits<T> contains traits for evaluator<T>
 
 template<typename T>
 struct evaluator_traits_base
 {
   // by default, get evaluator kind and shape from storage
   typedef typename storage_kind_to_evaluator_kind<typename traits<T>::StorageKind>::Kind Kind;
   typedef typename storage_kind_to_shape<typename traits<T>::StorageKind>::Shape Shape;
@@ -107,15 +107,15 @@
 // ---------- base class for all evaluators ----------
 
 template<typename ExpressionType>
 struct evaluator_base
 {
   // TODO that's not very nice to have to propagate all these traits. They are currently only needed to handle outer,inner indices.
   typedef traits<ExpressionType> ExpressionTraits;
-  
+
   enum {
     Alignment = 0
   };
   // noncopyable:
   // Don't make this class inherit noncopyable as this kills EBO (Empty Base Optimization)
   // and make complex evaluator much larger than then should do.
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE evaluator_base() {}
@@ -139,16 +139,16 @@
   plainobjectbase_evaluator_data(const Scalar* ptr, Index outerStride) : data(ptr)
   {
 #ifndef EIGEN_INTERNAL_DEBUGGING
     EIGEN_UNUSED_VARIABLE(outerStride);
 #endif
     eigen_internal_assert(outerStride==OuterStride);
   }
-  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-  Index outerStride() const { return OuterStride; }
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+  Index outerStride() const EIGEN_NOEXCEPT { return OuterStride; }
   const Scalar *data;
 };
 
 template<typename Scalar> class plainobjectbase_evaluator_data<Scalar,Dynamic> {
 public:
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   plainobjectbase_evaluator_data(const Scalar* ptr, Index outerStride) : data(ptr), m_outerStride(outerStride) {}
@@ -168,15 +168,15 @@
   typedef typename PlainObjectType::CoeffReturnType CoeffReturnType;
 
   enum {
     IsRowMajor = PlainObjectType::IsRowMajor,
     IsVectorAtCompileTime = PlainObjectType::IsVectorAtCompileTime,
     RowsAtCompileTime = PlainObjectType::RowsAtCompileTime,
     ColsAtCompileTime = PlainObjectType::ColsAtCompileTime,
-    
+
     CoeffReadCost = NumTraits<Scalar>::ReadCost,
     Flags = traits<Derived>::EvaluatorFlags,
     Alignment = traits<Derived>::Alignment
   };
   enum {
     // We do not need to know the outer stride for vectors
     OuterStrideAtCompileTime = IsVectorAtCompileTime  ? 0
@@ -270,49 +270,49 @@
 };
 
 template<typename Scalar, int Rows, int Cols, int Options, int MaxRows, int MaxCols>
 struct evaluator<Matrix<Scalar, Rows, Cols, Options, MaxRows, MaxCols> >
   : evaluator<PlainObjectBase<Matrix<Scalar, Rows, Cols, Options, MaxRows, MaxCols> > >
 {
   typedef Matrix<Scalar, Rows, Cols, Options, MaxRows, MaxCols> XprType;
-  
+
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   evaluator() {}
 
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   explicit evaluator(const XprType& m)
-    : evaluator<PlainObjectBase<XprType> >(m) 
+    : evaluator<PlainObjectBase<XprType> >(m)
   { }
 };
 
 template<typename Scalar, int Rows, int Cols, int Options, int MaxRows, int MaxCols>
 struct evaluator<Array<Scalar, Rows, Cols, Options, MaxRows, MaxCols> >
   : evaluator<PlainObjectBase<Array<Scalar, Rows, Cols, Options, MaxRows, MaxCols> > >
 {
   typedef Array<Scalar, Rows, Cols, Options, MaxRows, MaxCols> XprType;
 
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   evaluator() {}
-  
+
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   explicit evaluator(const XprType& m)
-    : evaluator<PlainObjectBase<XprType> >(m) 
+    : evaluator<PlainObjectBase<XprType> >(m)
   { }
 };
 
 // -------------------- Transpose --------------------
 
 template<typename ArgType>
 struct unary_evaluator<Transpose<ArgType>, IndexBased>
   : evaluator_base<Transpose<ArgType> >
 {
   typedef Transpose<ArgType> XprType;
-  
+
   enum {
-    CoeffReadCost = evaluator<ArgType>::CoeffReadCost,    
+    CoeffReadCost = evaluator<ArgType>::CoeffReadCost,
     Flags = evaluator<ArgType>::Flags ^ RowMajorBit,
     Alignment = evaluator<ArgType>::Alignment
   };
 
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   explicit unary_evaluator(const XprType& t) : m_argImpl(t.nestedExpression()) {}
 
@@ -495,18 +495,18 @@
 
 template<typename NullaryOp, typename PlainObjectType>
 struct evaluator<CwiseNullaryOp<NullaryOp,PlainObjectType> >
   : evaluator_base<CwiseNullaryOp<NullaryOp,PlainObjectType> >
 {
   typedef CwiseNullaryOp<NullaryOp,PlainObjectType> XprType;
   typedef typename internal::remove_all<PlainObjectType>::type PlainObjectTypeCleaned;
-  
+
   enum {
     CoeffReadCost = internal::functor_traits<NullaryOp>::Cost,
-    
+
     Flags = (evaluator<PlainObjectTypeCleaned>::Flags
           &  (  HereditaryBits
               | (functor_has_linear_access<NullaryOp>::ret  ? LinearAccessBit : 0)
               | (functor_traits<NullaryOp>::PacketAccess    ? PacketAccessBit : 0)))
           | (functor_traits<NullaryOp>::IsRepeatable ? 0 : EvalBeforeNestingBit),
     Alignment = AlignedMax
   };
@@ -555,18 +555,18 @@
 // -------------------- CwiseUnaryOp --------------------
 
 template<typename UnaryOp, typename ArgType>
 struct unary_evaluator<CwiseUnaryOp<UnaryOp, ArgType>, IndexBased >
   : evaluator_base<CwiseUnaryOp<UnaryOp, ArgType> >
 {
   typedef CwiseUnaryOp<UnaryOp, ArgType> XprType;
-  
+
   enum {
-    CoeffReadCost = evaluator<ArgType>::CoeffReadCost + functor_traits<UnaryOp>::Cost,
-    
+    CoeffReadCost = int(evaluator<ArgType>::CoeffReadCost) + int(functor_traits<UnaryOp>::Cost),
+
     Flags = evaluator<ArgType>::Flags
           & (HereditaryBits | LinearAccessBit | (functor_traits<UnaryOp>::PacketAccess ? PacketAccessBit : 0)),
     Alignment = evaluator<ArgType>::Alignment
   };
 
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   explicit unary_evaluator(const XprType& op) : m_d(op)
@@ -602,21 +602,21 @@
   {
     return m_d.func().packetOp(m_d.argImpl.template packet<LoadMode, PacketType>(index));
   }
 
 protected:
 
   // this helper permits to completely eliminate the functor if it is empty
-  class Data : private UnaryOp
+  struct Data
   {
-  public:
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    Data(const XprType& xpr) : UnaryOp(xpr.functor()), argImpl(xpr.nestedExpression()) {}
+    Data(const XprType& xpr) : op(xpr.functor()), argImpl(xpr.nestedExpression()) {}
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    const UnaryOp& func() const { return static_cast<const UnaryOp&>(*this); }
+    const UnaryOp& func() const { return op; }
+    UnaryOp op;
     evaluator<ArgType> argImpl;
   };
 
   Data m_d;
 };
 
 // -------------------- CwiseTernaryOp --------------------
@@ -624,27 +624,27 @@
 // this is a ternary expression
 template<typename TernaryOp, typename Arg1, typename Arg2, typename Arg3>
 struct evaluator<CwiseTernaryOp<TernaryOp, Arg1, Arg2, Arg3> >
   : public ternary_evaluator<CwiseTernaryOp<TernaryOp, Arg1, Arg2, Arg3> >
 {
   typedef CwiseTernaryOp<TernaryOp, Arg1, Arg2, Arg3> XprType;
   typedef ternary_evaluator<CwiseTernaryOp<TernaryOp, Arg1, Arg2, Arg3> > Base;
-  
+
   EIGEN_DEVICE_FUNC explicit evaluator(const XprType& xpr) : Base(xpr) {}
 };
 
 template<typename TernaryOp, typename Arg1, typename Arg2, typename Arg3>
 struct ternary_evaluator<CwiseTernaryOp<TernaryOp, Arg1, Arg2, Arg3>, IndexBased, IndexBased>
   : evaluator_base<CwiseTernaryOp<TernaryOp, Arg1, Arg2, Arg3> >
 {
   typedef CwiseTernaryOp<TernaryOp, Arg1, Arg2, Arg3> XprType;
-  
+
   enum {
-    CoeffReadCost = evaluator<Arg1>::CoeffReadCost + evaluator<Arg2>::CoeffReadCost + evaluator<Arg3>::CoeffReadCost + functor_traits<TernaryOp>::Cost,
-    
+    CoeffReadCost = int(evaluator<Arg1>::CoeffReadCost) + int(evaluator<Arg2>::CoeffReadCost) + int(evaluator<Arg3>::CoeffReadCost) + int(functor_traits<TernaryOp>::Cost),
+
     Arg1Flags = evaluator<Arg1>::Flags,
     Arg2Flags = evaluator<Arg2>::Flags,
     Arg3Flags = evaluator<Arg3>::Flags,
     SameType = is_same<typename Arg1::Scalar,typename Arg2::Scalar>::value && is_same<typename Arg1::Scalar,typename Arg3::Scalar>::value,
     StorageOrdersAgree = (int(Arg1Flags)&RowMajorBit)==(int(Arg2Flags)&RowMajorBit) && (int(Arg1Flags)&RowMajorBit)==(int(Arg3Flags)&RowMajorBit),
     Flags0 = (int(Arg1Flags) | int(Arg2Flags) | int(Arg3Flags)) & (
         HereditaryBits
@@ -696,20 +696,21 @@
     return m_d.func().packetOp(m_d.arg1Impl.template packet<LoadMode,PacketType>(index),
                                m_d.arg2Impl.template packet<LoadMode,PacketType>(index),
                                m_d.arg3Impl.template packet<LoadMode,PacketType>(index));
   }
 
 protected:
   // this helper permits to completely eliminate the functor if it is empty
-  struct Data : private TernaryOp
+  struct Data
   {
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    Data(const XprType& xpr) : TernaryOp(xpr.functor()), arg1Impl(xpr.arg1()), arg2Impl(xpr.arg2()), arg3Impl(xpr.arg3()) {}
+    Data(const XprType& xpr) : op(xpr.functor()), arg1Impl(xpr.arg1()), arg2Impl(xpr.arg2()), arg3Impl(xpr.arg3()) {}
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    const TernaryOp& func() const { return static_cast<const TernaryOp&>(*this); }
+    const TernaryOp& func() const { return op; }
+    TernaryOp op;
     evaluator<Arg1> arg1Impl;
     evaluator<Arg2> arg2Impl;
     evaluator<Arg3> arg3Impl;
   };
 
   Data m_d;
 };
@@ -719,28 +720,28 @@
 // this is a binary expression
 template<typename BinaryOp, typename Lhs, typename Rhs>
 struct evaluator<CwiseBinaryOp<BinaryOp, Lhs, Rhs> >
   : public binary_evaluator<CwiseBinaryOp<BinaryOp, Lhs, Rhs> >
 {
   typedef CwiseBinaryOp<BinaryOp, Lhs, Rhs> XprType;
   typedef binary_evaluator<CwiseBinaryOp<BinaryOp, Lhs, Rhs> > Base;
-  
+
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   explicit evaluator(const XprType& xpr) : Base(xpr) {}
 };
 
 template<typename BinaryOp, typename Lhs, typename Rhs>
 struct binary_evaluator<CwiseBinaryOp<BinaryOp, Lhs, Rhs>, IndexBased, IndexBased>
   : evaluator_base<CwiseBinaryOp<BinaryOp, Lhs, Rhs> >
 {
   typedef CwiseBinaryOp<BinaryOp, Lhs, Rhs> XprType;
-  
+
   enum {
-    CoeffReadCost = evaluator<Lhs>::CoeffReadCost + evaluator<Rhs>::CoeffReadCost + functor_traits<BinaryOp>::Cost,
-    
+    CoeffReadCost = int(evaluator<Lhs>::CoeffReadCost) + int(evaluator<Rhs>::CoeffReadCost) + int(functor_traits<BinaryOp>::Cost),
+
     LhsFlags = evaluator<Lhs>::Flags,
     RhsFlags = evaluator<Rhs>::Flags,
     SameType = is_same<typename Lhs::Scalar,typename Rhs::Scalar>::value,
     StorageOrdersAgree = (int(LhsFlags)&RowMajorBit)==(int(RhsFlags)&RowMajorBit),
     Flags0 = (int(LhsFlags) | int(RhsFlags)) & (
         HereditaryBits
       | (int(LhsFlags) & int(RhsFlags) &
@@ -789,40 +790,41 @@
     return m_d.func().packetOp(m_d.lhsImpl.template packet<LoadMode,PacketType>(index),
                                m_d.rhsImpl.template packet<LoadMode,PacketType>(index));
   }
 
 protected:
 
   // this helper permits to completely eliminate the functor if it is empty
-  struct Data : private BinaryOp
+  struct Data
   {
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    Data(const XprType& xpr) : BinaryOp(xpr.functor()), lhsImpl(xpr.lhs()), rhsImpl(xpr.rhs()) {}
+    Data(const XprType& xpr) : op(xpr.functor()), lhsImpl(xpr.lhs()), rhsImpl(xpr.rhs()) {}
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    const BinaryOp& func() const { return static_cast<const BinaryOp&>(*this); }
+    const BinaryOp& func() const { return op; }
+    BinaryOp op;
     evaluator<Lhs> lhsImpl;
     evaluator<Rhs> rhsImpl;
   };
 
   Data m_d;
 };
 
 // -------------------- CwiseUnaryView --------------------
 
 template<typename UnaryOp, typename ArgType>
 struct unary_evaluator<CwiseUnaryView<UnaryOp, ArgType>, IndexBased>
   : evaluator_base<CwiseUnaryView<UnaryOp, ArgType> >
 {
   typedef CwiseUnaryView<UnaryOp, ArgType> XprType;
-  
+
   enum {
-    CoeffReadCost = evaluator<ArgType>::CoeffReadCost + functor_traits<UnaryOp>::Cost,
-    
+    CoeffReadCost = int(evaluator<ArgType>::CoeffReadCost) + int(functor_traits<UnaryOp>::Cost),
+
     Flags = (evaluator<ArgType>::Flags & (HereditaryBits | LinearAccessBit | DirectAccessBit)),
-    
+
     Alignment = 0 // FIXME it is not very clear why alignment is necessarily lost...
   };
 
   EIGEN_DEVICE_FUNC explicit unary_evaluator(const XprType& op) : m_d(op)
   {
     EIGEN_INTERNAL_CHECK_COST_VALUE(functor_traits<UnaryOp>::Cost);
     EIGEN_INTERNAL_CHECK_COST_VALUE(CoeffReadCost);
@@ -854,20 +856,21 @@
   {
     return m_d.func()(m_d.argImpl.coeffRef(index));
   }
 
 protected:
 
   // this helper permits to completely eliminate the functor if it is empty
-  struct Data : private UnaryOp
+  struct Data
   {
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    Data(const XprType& xpr) : UnaryOp(xpr.functor()), argImpl(xpr.nestedExpression()) {}
+    Data(const XprType& xpr) : op(xpr.functor()), argImpl(xpr.nestedExpression()) {}
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    const UnaryOp& func() const { return static_cast<const UnaryOp&>(*this); }
+    const UnaryOp& func() const { return op; }
+    UnaryOp op;
     evaluator<ArgType> argImpl;
   };
 
   Data m_d;
 };
 
 // -------------------- Map --------------------
@@ -880,15 +883,15 @@
 template<typename Derived, typename PlainObjectType>
 struct mapbase_evaluator : evaluator_base<Derived>
 {
   typedef Derived  XprType;
   typedef typename XprType::PointerType PointerType;
   typedef typename XprType::Scalar Scalar;
   typedef typename XprType::CoeffReturnType CoeffReturnType;
-  
+
   enum {
     IsRowMajor = XprType::RowsAtCompileTime,
     ColsAtCompileTime = XprType::ColsAtCompileTime,
     CoeffReadCost = NumTraits<Scalar>::ReadCost
   };
 
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
@@ -952,119 +955,123 @@
   template<int StoreMode, typename PacketType>
   EIGEN_STRONG_INLINE
   void writePacket(Index index, const PacketType& x)
   {
     internal::pstoret<Scalar, PacketType, StoreMode>(m_data + index * m_innerStride.value(), x);
   }
 protected:
-  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-  Index rowStride() const { return XprType::IsRowMajor ? m_outerStride.value() : m_innerStride.value(); }
-  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-  Index colStride() const { return XprType::IsRowMajor ? m_innerStride.value() : m_outerStride.value(); }
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+  Index rowStride() const EIGEN_NOEXCEPT {
+    return XprType::IsRowMajor ? m_outerStride.value() : m_innerStride.value();
+  }
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+  Index colStride() const EIGEN_NOEXCEPT {
+     return XprType::IsRowMajor ? m_innerStride.value() : m_outerStride.value();
+  }
 
   PointerType m_data;
   const internal::variable_if_dynamic<Index, XprType::InnerStrideAtCompileTime> m_innerStride;
   const internal::variable_if_dynamic<Index, XprType::OuterStrideAtCompileTime> m_outerStride;
 };
 
-template<typename PlainObjectType, int MapOptions, typename StrideType> 
+template<typename PlainObjectType, int MapOptions, typename StrideType>
 struct evaluator<Map<PlainObjectType, MapOptions, StrideType> >
   : public mapbase_evaluator<Map<PlainObjectType, MapOptions, StrideType>, PlainObjectType>
 {
   typedef Map<PlainObjectType, MapOptions, StrideType> XprType;
   typedef typename XprType::Scalar Scalar;
   // TODO: should check for smaller packet types once we can handle multi-sized packet types
   typedef typename packet_traits<Scalar>::type PacketScalar;
-  
+
   enum {
     InnerStrideAtCompileTime = StrideType::InnerStrideAtCompileTime == 0
                              ? int(PlainObjectType::InnerStrideAtCompileTime)
                              : int(StrideType::InnerStrideAtCompileTime),
     OuterStrideAtCompileTime = StrideType::OuterStrideAtCompileTime == 0
                              ? int(PlainObjectType::OuterStrideAtCompileTime)
                              : int(StrideType::OuterStrideAtCompileTime),
     HasNoInnerStride = InnerStrideAtCompileTime == 1,
     HasNoOuterStride = StrideType::OuterStrideAtCompileTime == 0,
     HasNoStride = HasNoInnerStride && HasNoOuterStride,
     IsDynamicSize = PlainObjectType::SizeAtCompileTime==Dynamic,
-    
+
     PacketAccessMask = bool(HasNoInnerStride) ? ~int(0) : ~int(PacketAccessBit),
     LinearAccessMask = bool(HasNoStride) || bool(PlainObjectType::IsVectorAtCompileTime) ? ~int(0) : ~int(LinearAccessBit),
     Flags = int( evaluator<PlainObjectType>::Flags) & (LinearAccessMask&PacketAccessMask),
-    
+
     Alignment = int(MapOptions)&int(AlignedMask)
   };
 
   EIGEN_DEVICE_FUNC explicit evaluator(const XprType& map)
-    : mapbase_evaluator<XprType, PlainObjectType>(map) 
+    : mapbase_evaluator<XprType, PlainObjectType>(map)
   { }
 };
 
 // -------------------- Ref --------------------
 
-template<typename PlainObjectType, int RefOptions, typename StrideType> 
+template<typename PlainObjectType, int RefOptions, typename StrideType>
 struct evaluator<Ref<PlainObjectType, RefOptions, StrideType> >
   : public mapbase_evaluator<Ref<PlainObjectType, RefOptions, StrideType>, PlainObjectType>
 {
   typedef Ref<PlainObjectType, RefOptions, StrideType> XprType;
-  
+
   enum {
     Flags = evaluator<Map<PlainObjectType, RefOptions, StrideType> >::Flags,
     Alignment = evaluator<Map<PlainObjectType, RefOptions, StrideType> >::Alignment
   };
 
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   explicit evaluator(const XprType& ref)
-    : mapbase_evaluator<XprType, PlainObjectType>(ref) 
+    : mapbase_evaluator<XprType, PlainObjectType>(ref)
   { }
 };
 
 // -------------------- Block --------------------
 
 template<typename ArgType, int BlockRows, int BlockCols, bool InnerPanel,
          bool HasDirectAccess = internal::has_direct_access<ArgType>::ret> struct block_evaluator;
-         
-template<typename ArgType, int BlockRows, int BlockCols, bool InnerPanel> 
+
+template<typename ArgType, int BlockRows, int BlockCols, bool InnerPanel>
 struct evaluator<Block<ArgType, BlockRows, BlockCols, InnerPanel> >
   : block_evaluator<ArgType, BlockRows, BlockCols, InnerPanel>
 {
   typedef Block<ArgType, BlockRows, BlockCols, InnerPanel> XprType;
   typedef typename XprType::Scalar Scalar;
   // TODO: should check for smaller packet types once we can handle multi-sized packet types
   typedef typename packet_traits<Scalar>::type PacketScalar;
-  
+
   enum {
     CoeffReadCost = evaluator<ArgType>::CoeffReadCost,
-    
+
     RowsAtCompileTime = traits<XprType>::RowsAtCompileTime,
     ColsAtCompileTime = traits<XprType>::ColsAtCompileTime,
     MaxRowsAtCompileTime = traits<XprType>::MaxRowsAtCompileTime,
     MaxColsAtCompileTime = traits<XprType>::MaxColsAtCompileTime,
-    
+
     ArgTypeIsRowMajor = (int(evaluator<ArgType>::Flags)&RowMajorBit) != 0,
     IsRowMajor = (MaxRowsAtCompileTime==1 && MaxColsAtCompileTime!=1) ? 1
                : (MaxColsAtCompileTime==1 && MaxRowsAtCompileTime!=1) ? 0
                : ArgTypeIsRowMajor,
     HasSameStorageOrderAsArgType = (IsRowMajor == ArgTypeIsRowMajor),
     InnerSize = IsRowMajor ? int(ColsAtCompileTime) : int(RowsAtCompileTime),
     InnerStrideAtCompileTime = HasSameStorageOrderAsArgType
                              ? int(inner_stride_at_compile_time<ArgType>::ret)
                              : int(outer_stride_at_compile_time<ArgType>::ret),
     OuterStrideAtCompileTime = HasSameStorageOrderAsArgType
                              ? int(outer_stride_at_compile_time<ArgType>::ret)
                              : int(inner_stride_at_compile_time<ArgType>::ret),
     MaskPacketAccessBit = (InnerStrideAtCompileTime == 1 || HasSameStorageOrderAsArgType) ? PacketAccessBit : 0,
-    
-    FlagsLinearAccessBit = (RowsAtCompileTime == 1 || ColsAtCompileTime == 1 || (InnerPanel && (evaluator<ArgType>::Flags&LinearAccessBit))) ? LinearAccessBit : 0,    
+
+    FlagsLinearAccessBit = (RowsAtCompileTime == 1 || ColsAtCompileTime == 1 || (InnerPanel && (evaluator<ArgType>::Flags&LinearAccessBit))) ? LinearAccessBit : 0,
     FlagsRowMajorBit = XprType::Flags&RowMajorBit,
     Flags0 = evaluator<ArgType>::Flags & ( (HereditaryBits & ~RowMajorBit) |
                                            DirectAccessBit |
                                            MaskPacketAccessBit),
     Flags = Flags0 | FlagsLinearAccessBit | FlagsRowMajorBit,
-    
+
     PacketAlignment = unpacket_traits<PacketScalar>::alignment,
     Alignment0 = (InnerPanel && (OuterStrideAtCompileTime!=Dynamic)
                              && (OuterStrideAtCompileTime!=0)
                              && (((OuterStrideAtCompileTime * int(sizeof(Scalar))) % int(PacketAlignment)) == 0)) ? int(PacketAlignment) : 0,
     Alignment = EIGEN_PLAIN_ENUM_MIN(evaluator<ArgType>::Alignment, Alignment0)
   };
   typedef block_evaluator<ArgType, BlockRows, BlockCols, InnerPanel> block_evaluator_type;
@@ -1080,144 +1087,144 @@
 struct block_evaluator<ArgType, BlockRows, BlockCols, InnerPanel, /*HasDirectAccess*/ false>
   : unary_evaluator<Block<ArgType, BlockRows, BlockCols, InnerPanel> >
 {
   typedef Block<ArgType, BlockRows, BlockCols, InnerPanel> XprType;
 
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   explicit block_evaluator(const XprType& block)
-    : unary_evaluator<XprType>(block) 
+    : unary_evaluator<XprType>(block)
   {}
 };
 
 template<typename ArgType, int BlockRows, int BlockCols, bool InnerPanel>
 struct unary_evaluator<Block<ArgType, BlockRows, BlockCols, InnerPanel>, IndexBased>
   : evaluator_base<Block<ArgType, BlockRows, BlockCols, InnerPanel> >
 {
   typedef Block<ArgType, BlockRows, BlockCols, InnerPanel> XprType;
 
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   explicit unary_evaluator(const XprType& block)
-    : m_argImpl(block.nestedExpression()), 
-      m_startRow(block.startRow()), 
+    : m_argImpl(block.nestedExpression()),
+      m_startRow(block.startRow()),
       m_startCol(block.startCol()),
       m_linear_offset(ForwardLinearAccess?(ArgType::IsRowMajor ? block.startRow()*block.nestedExpression().cols() + block.startCol() : block.startCol()*block.nestedExpression().rows() + block.startRow()):0)
   { }
- 
+
   typedef typename XprType::Scalar Scalar;
   typedef typename XprType::CoeffReturnType CoeffReturnType;
 
   enum {
     RowsAtCompileTime = XprType::RowsAtCompileTime,
     ForwardLinearAccess = (InnerPanel || int(XprType::IsRowMajor)==int(ArgType::IsRowMajor)) && bool(evaluator<ArgType>::Flags&LinearAccessBit)
   };
- 
+
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   CoeffReturnType coeff(Index row, Index col) const
-  { 
-    return m_argImpl.coeff(m_startRow.value() + row, m_startCol.value() + col); 
+  {
+    return m_argImpl.coeff(m_startRow.value() + row, m_startCol.value() + col);
   }
-  
+
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   CoeffReturnType coeff(Index index) const
   {
     return linear_coeff_impl(index, bool_constant<ForwardLinearAccess>());
   }
 
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   Scalar& coeffRef(Index row, Index col)
-  { 
-    return m_argImpl.coeffRef(m_startRow.value() + row, m_startCol.value() + col); 
+  {
+    return m_argImpl.coeffRef(m_startRow.value() + row, m_startCol.value() + col);
   }
-  
+
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   Scalar& coeffRef(Index index)
   {
     return linear_coeffRef_impl(index, bool_constant<ForwardLinearAccess>());
   }
- 
+
   template<int LoadMode, typename PacketType>
   EIGEN_STRONG_INLINE
-  PacketType packet(Index row, Index col) const 
-  { 
-    return m_argImpl.template packet<LoadMode,PacketType>(m_startRow.value() + row, m_startCol.value() + col); 
+  PacketType packet(Index row, Index col) const
+  {
+    return m_argImpl.template packet<LoadMode,PacketType>(m_startRow.value() + row, m_startCol.value() + col);
   }
 
   template<int LoadMode, typename PacketType>
   EIGEN_STRONG_INLINE
-  PacketType packet(Index index) const 
-  { 
+  PacketType packet(Index index) const
+  {
     if (ForwardLinearAccess)
       return m_argImpl.template packet<LoadMode,PacketType>(m_linear_offset.value() + index);
     else
       return packet<LoadMode,PacketType>(RowsAtCompileTime == 1 ? 0 : index,
                                          RowsAtCompileTime == 1 ? index : 0);
   }
-  
+
   template<int StoreMode, typename PacketType>
   EIGEN_STRONG_INLINE
-  void writePacket(Index row, Index col, const PacketType& x) 
+  void writePacket(Index row, Index col, const PacketType& x)
   {
-    return m_argImpl.template writePacket<StoreMode,PacketType>(m_startRow.value() + row, m_startCol.value() + col, x); 
+    return m_argImpl.template writePacket<StoreMode,PacketType>(m_startRow.value() + row, m_startCol.value() + col, x);
   }
-  
+
   template<int StoreMode, typename PacketType>
   EIGEN_STRONG_INLINE
-  void writePacket(Index index, const PacketType& x) 
+  void writePacket(Index index, const PacketType& x)
   {
     if (ForwardLinearAccess)
       return m_argImpl.template writePacket<StoreMode,PacketType>(m_linear_offset.value() + index, x);
     else
       return writePacket<StoreMode,PacketType>(RowsAtCompileTime == 1 ? 0 : index,
                                               RowsAtCompileTime == 1 ? index : 0,
                                               x);
   }
- 
+
 protected:
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   CoeffReturnType linear_coeff_impl(Index index, internal::true_type /* ForwardLinearAccess */) const
   {
-    return m_argImpl.coeff(m_linear_offset.value() + index); 
+    return m_argImpl.coeff(m_linear_offset.value() + index);
   }
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   CoeffReturnType linear_coeff_impl(Index index, internal::false_type /* not ForwardLinearAccess */) const
   {
     return coeff(RowsAtCompileTime == 1 ? 0 : index, RowsAtCompileTime == 1 ? index : 0);
   }
 
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   Scalar& linear_coeffRef_impl(Index index, internal::true_type /* ForwardLinearAccess */)
   {
-    return m_argImpl.coeffRef(m_linear_offset.value() + index); 
+    return m_argImpl.coeffRef(m_linear_offset.value() + index);
   }
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   Scalar& linear_coeffRef_impl(Index index, internal::false_type /* not ForwardLinearAccess */)
   {
     return coeffRef(RowsAtCompileTime == 1 ? 0 : index, RowsAtCompileTime == 1 ? index : 0);
   }
 
   evaluator<ArgType> m_argImpl;
   const variable_if_dynamic<Index, (ArgType::RowsAtCompileTime == 1 && BlockRows==1) ? 0 : Dynamic> m_startRow;
   const variable_if_dynamic<Index, (ArgType::ColsAtCompileTime == 1 && BlockCols==1) ? 0 : Dynamic> m_startCol;
   const variable_if_dynamic<Index, ForwardLinearAccess ? Dynamic : 0> m_linear_offset;
 };
 
-// TODO: This evaluator does not actually use the child evaluator; 
+// TODO: This evaluator does not actually use the child evaluator;
 // all action is via the data() as returned by the Block expression.
 
-template<typename ArgType, int BlockRows, int BlockCols, bool InnerPanel> 
+template<typename ArgType, int BlockRows, int BlockCols, bool InnerPanel>
 struct block_evaluator<ArgType, BlockRows, BlockCols, InnerPanel, /* HasDirectAccess */ true>
   : mapbase_evaluator<Block<ArgType, BlockRows, BlockCols, InnerPanel>,
                       typename Block<ArgType, BlockRows, BlockCols, InnerPanel>::PlainObject>
 {
   typedef Block<ArgType, BlockRows, BlockCols, InnerPanel> XprType;
   typedef typename XprType::Scalar Scalar;
 
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   explicit block_evaluator(const XprType& block)
-    : mapbase_evaluator<XprType, typename XprType::PlainObject>(block) 
+    : mapbase_evaluator<XprType, typename XprType::PlainObject>(block)
   {
     // TODO: for the 3.3 release, this should be turned to an internal assertion, but let's keep it as is for the beta lifetime
     eigen_assert(((internal::UIntPtr(block.data()) % EIGEN_PLAIN_ENUM_MAX(1,evaluator<XprType>::Alignment)) == 0) && "data is not aligned");
   }
 };
 
 
@@ -1232,27 +1239,27 @@
   typedef Select<ConditionMatrixType, ThenMatrixType, ElseMatrixType> XprType;
   enum {
     CoeffReadCost = evaluator<ConditionMatrixType>::CoeffReadCost
                   + EIGEN_PLAIN_ENUM_MAX(evaluator<ThenMatrixType>::CoeffReadCost,
                                          evaluator<ElseMatrixType>::CoeffReadCost),
 
     Flags = (unsigned int)evaluator<ThenMatrixType>::Flags & evaluator<ElseMatrixType>::Flags & HereditaryBits,
-    
+
     Alignment = EIGEN_PLAIN_ENUM_MIN(evaluator<ThenMatrixType>::Alignment, evaluator<ElseMatrixType>::Alignment)
   };
 
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   explicit evaluator(const XprType& select)
     : m_conditionImpl(select.conditionMatrix()),
       m_thenImpl(select.thenMatrix()),
       m_elseImpl(select.elseMatrix())
   {
     EIGEN_INTERNAL_CHECK_COST_VALUE(CoeffReadCost);
   }
- 
+
   typedef typename XprType::CoeffReturnType CoeffReturnType;
 
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   CoeffReturnType coeff(Index row, Index col) const
   {
     if (m_conditionImpl.coeff(row, col))
       return m_thenImpl.coeff(row, col);
@@ -1264,74 +1271,74 @@
   CoeffReturnType coeff(Index index) const
   {
     if (m_conditionImpl.coeff(index))
       return m_thenImpl.coeff(index);
     else
       return m_elseImpl.coeff(index);
   }
- 
+
 protected:
   evaluator<ConditionMatrixType> m_conditionImpl;
   evaluator<ThenMatrixType> m_thenImpl;
   evaluator<ElseMatrixType> m_elseImpl;
 };
 
 
 // -------------------- Replicate --------------------
 
-template<typename ArgType, int RowFactor, int ColFactor> 
+template<typename ArgType, int RowFactor, int ColFactor>
 struct unary_evaluator<Replicate<ArgType, RowFactor, ColFactor> >
   : evaluator_base<Replicate<ArgType, RowFactor, ColFactor> >
 {
   typedef Replicate<ArgType, RowFactor, ColFactor> XprType;
   typedef typename XprType::CoeffReturnType CoeffReturnType;
   enum {
     Factor = (RowFactor==Dynamic || ColFactor==Dynamic) ? Dynamic : RowFactor*ColFactor
   };
   typedef typename internal::nested_eval<ArgType,Factor>::type ArgTypeNested;
   typedef typename internal::remove_all<ArgTypeNested>::type ArgTypeNestedCleaned;
-  
+
   enum {
     CoeffReadCost = evaluator<ArgTypeNestedCleaned>::CoeffReadCost,
     LinearAccessMask = XprType::IsVectorAtCompileTime ? LinearAccessBit : 0,
     Flags = (evaluator<ArgTypeNestedCleaned>::Flags & (HereditaryBits|LinearAccessMask) & ~RowMajorBit) | (traits<XprType>::Flags & RowMajorBit),
-    
+
     Alignment = evaluator<ArgTypeNestedCleaned>::Alignment
   };
 
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   explicit unary_evaluator(const XprType& replicate)
     : m_arg(replicate.nestedExpression()),
       m_argImpl(m_arg),
       m_rows(replicate.nestedExpression().rows()),
       m_cols(replicate.nestedExpression().cols())
   {}
- 
+
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   CoeffReturnType coeff(Index row, Index col) const
   {
     // try to avoid using modulo; this is a pure optimization strategy
     const Index actual_row = internal::traits<XprType>::RowsAtCompileTime==1 ? 0
                            : RowFactor==1 ? row
                            : row % m_rows.value();
     const Index actual_col = internal::traits<XprType>::ColsAtCompileTime==1 ? 0
                            : ColFactor==1 ? col
                            : col % m_cols.value();
-    
+
     return m_argImpl.coeff(actual_row, actual_col);
   }
-  
+
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   CoeffReturnType coeff(Index index) const
   {
     // try to avoid using modulo; this is a pure optimization strategy
     const Index actual_index = internal::traits<XprType>::RowsAtCompileTime==1
                                   ? (ColFactor==1 ?  index : index%m_cols.value())
                                   : (RowFactor==1 ?  index : index%m_rows.value());
-    
+
     return m_argImpl.coeff(actual_index);
   }
 
   template<int LoadMode, typename PacketType>
   EIGEN_STRONG_INLINE
   PacketType packet(Index row, Index col) const
   {
@@ -1340,26 +1347,26 @@
                            : row % m_rows.value();
     const Index actual_col = internal::traits<XprType>::ColsAtCompileTime==1 ? 0
                            : ColFactor==1 ? col
                            : col % m_cols.value();
 
     return m_argImpl.template packet<LoadMode,PacketType>(actual_row, actual_col);
   }
-  
+
   template<int LoadMode, typename PacketType>
   EIGEN_STRONG_INLINE
   PacketType packet(Index index) const
   {
     const Index actual_index = internal::traits<XprType>::RowsAtCompileTime==1
                                   ? (ColFactor==1 ?  index : index%m_cols.value())
                                   : (RowFactor==1 ?  index : index%m_rows.value());
 
     return m_argImpl.template packet<LoadMode,PacketType>(actual_index);
   }
- 
+
 protected:
   const ArgTypeNested m_arg;
   evaluator<ArgTypeNestedCleaned> m_argImpl;
   const variable_if_dynamic<Index, ArgType::RowsAtCompileTime> m_rows;
   const variable_if_dynamic<Index, ArgType::ColsAtCompileTime> m_cols;
 };
 
@@ -1483,36 +1490,36 @@
     IsRowMajor = XprType::IsRowMajor,
     IsColMajor = !IsRowMajor,
     ReverseRow = (Direction == Vertical)   || (Direction == BothDirections),
     ReverseCol = (Direction == Horizontal) || (Direction == BothDirections),
     ReversePacket = (Direction == BothDirections)
                     || ((Direction == Vertical)   && IsColMajor)
                     || ((Direction == Horizontal) && IsRowMajor),
-                    
+
     CoeffReadCost = evaluator<ArgType>::CoeffReadCost,
-    
+
     // let's enable LinearAccess only with vectorization because of the product overhead
     // FIXME enable DirectAccess with negative strides?
     Flags0 = evaluator<ArgType>::Flags,
     LinearAccess = ( (Direction==BothDirections) && (int(Flags0)&PacketAccessBit) )
                   || ((ReverseRow && XprType::ColsAtCompileTime==1) || (ReverseCol && XprType::RowsAtCompileTime==1))
                  ? LinearAccessBit : 0,
 
     Flags = int(Flags0) & (HereditaryBits | PacketAccessBit | LinearAccess),
-    
+
     Alignment = 0 // FIXME in some rare cases, Alignment could be preserved, like a Vector4f.
   };
 
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   explicit unary_evaluator(const XprType& reverse)
     : m_argImpl(reverse.nestedExpression()),
       m_rows(ReverseRow ? reverse.nestedExpression().rows() : 1),
       m_cols(ReverseCol ? reverse.nestedExpression().cols() : 1)
   { }
- 
+
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   CoeffReturnType coeff(Index row, Index col) const
   {
     return m_argImpl.coeff(ReverseRow ? m_rows.value() - row - 1 : row,
                            ReverseCol ? m_cols.value() - col - 1 : col);
   }
 
@@ -1579,15 +1586,15 @@
   EIGEN_STRONG_INLINE
   void writePacket(Index index, const PacketType& x)
   {
     enum { PacketSize = unpacket_traits<PacketType>::size };
     m_argImpl.template writePacket<LoadMode>
       (m_rows.value() * m_cols.value() - index - PacketSize, preverse(x));
   }
- 
+
 protected:
   evaluator<ArgType> m_argImpl;
 
   // If we do not reverse rows, then we do not need to know the number of rows; same for columns
   // Nonetheless, in this case it is important to set to 1 such that the coeff(index) method works fine for vectors.
   const variable_if_dynamic<Index, ReverseRow ? ArgType::RowsAtCompileTime : 1> m_rows;
   const variable_if_dynamic<Index, ReverseCol ? ArgType::ColsAtCompileTime : 1> m_cols;
@@ -1597,29 +1604,29 @@
 // -------------------- Diagonal --------------------
 
 template<typename ArgType, int DiagIndex>
 struct evaluator<Diagonal<ArgType, DiagIndex> >
   : evaluator_base<Diagonal<ArgType, DiagIndex> >
 {
   typedef Diagonal<ArgType, DiagIndex> XprType;
-  
+
   enum {
     CoeffReadCost = evaluator<ArgType>::CoeffReadCost,
-    
+
     Flags = (unsigned int)(evaluator<ArgType>::Flags & (HereditaryBits | DirectAccessBit) & ~RowMajorBit) | LinearAccessBit,
-    
+
     Alignment = 0
   };
 
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   explicit evaluator(const XprType& diagonal)
     : m_argImpl(diagonal.nestedExpression()),
       m_index(diagonal.index())
   { }
- 
+
   typedef typename XprType::Scalar Scalar;
   typedef typename XprType::CoeffReturnType CoeffReturnType;
 
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   CoeffReturnType coeff(Index row, Index) const
   {
     return m_argImpl.coeff(row + rowOffset(), row + colOffset());
@@ -1644,16 +1651,18 @@
   }
 
 protected:
   evaluator<ArgType> m_argImpl;
   const internal::variable_if_dynamicindex<Index, XprType::DiagIndex> m_index;
 
 private:
-  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Index rowOffset() const { return m_index.value() > 0 ? 0 : -m_index.value(); }
-  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Index colOffset() const { return m_index.value() > 0 ? m_index.value() : 0; }
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+  Index rowOffset() const { return m_index.value() > 0 ? 0 : -m_index.value(); }
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+  Index colOffset() const { return m_index.value() > 0 ? m_index.value() : 0; }
 };
 
 
 //----------------------------------------------------------------------
 // deprecated code
 //----------------------------------------------------------------------
 
@@ -1669,49 +1678,49 @@
 { };
 
 template<typename ArgType>
 class EvalToTemp
   : public dense_xpr_base<EvalToTemp<ArgType> >::type
 {
  public:
- 
+
   typedef typename dense_xpr_base<EvalToTemp>::type Base;
   EIGEN_GENERIC_PUBLIC_INTERFACE(EvalToTemp)
- 
+
   explicit EvalToTemp(const ArgType& arg)
     : m_arg(arg)
   { }
- 
+
   const ArgType& arg() const
   {
     return m_arg;
   }
 
-  Index rows() const 
+  EIGEN_CONSTEXPR Index rows() const EIGEN_NOEXCEPT
   {
     return m_arg.rows();
   }
 
-  Index cols() const 
+  EIGEN_CONSTEXPR Index cols() const EIGEN_NOEXCEPT
   {
     return m_arg.cols();
   }
 
  private:
   const ArgType& m_arg;
 };
- 
+
 template<typename ArgType>
 struct evaluator<EvalToTemp<ArgType> >
   : public evaluator<typename ArgType::PlainObject>
 {
   typedef EvalToTemp<ArgType>                   XprType;
   typedef typename ArgType::PlainObject         PlainObject;
   typedef evaluator<PlainObject> Base;
-  
+
   EIGEN_DEVICE_FUNC explicit evaluator(const XprType& xpr)
     : m_result(xpr.arg())
   {
     ::new (static_cast<Base*>(this)) Base(m_result);
   }
 
   // This constructor is used when nesting an EvalTo evaluator in another evaluator
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/CoreIterators.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/CoreIterators.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/CwiseBinaryOp.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/CwiseBinaryOp.h`

 * *Files 6% similar despite different names*

```diff
@@ -70,24 +70,24 @@
   *
   * Most of the time, this is the only way that it is used, so you typically don't have to name
   * CwiseBinaryOp types explicitly.
   *
   * \sa MatrixBase::binaryExpr(const MatrixBase<OtherDerived> &,const CustomBinaryOp &) const, class CwiseUnaryOp, class CwiseNullaryOp
   */
 template<typename BinaryOp, typename LhsType, typename RhsType>
-class CwiseBinaryOp : 
+class CwiseBinaryOp :
   public CwiseBinaryOpImpl<
           BinaryOp, LhsType, RhsType,
           typename internal::cwise_promote_storage_type<typename internal::traits<LhsType>::StorageKind,
                                                         typename internal::traits<RhsType>::StorageKind,
                                                         BinaryOp>::ret>,
   internal::no_assignment_operator
 {
   public:
-    
+
     typedef typename internal::remove_all<BinaryOp>::type Functor;
     typedef typename internal::remove_all<LhsType>::type Lhs;
     typedef typename internal::remove_all<RhsType>::type Rhs;
 
     typedef typename CwiseBinaryOpImpl<
         BinaryOp, LhsType, RhsType,
         typename internal::cwise_promote_storage_type<typename internal::traits<LhsType>::StorageKind,
@@ -98,43 +98,37 @@
     typedef typename internal::ref_selector<LhsType>::type LhsNested;
     typedef typename internal::ref_selector<RhsType>::type RhsNested;
     typedef typename internal::remove_reference<LhsNested>::type _LhsNested;
     typedef typename internal::remove_reference<RhsNested>::type _RhsNested;
 
 #if EIGEN_COMP_MSVC && EIGEN_HAS_CXX11
     //Required for Visual Studio or the Copy constructor will probably not get inlined!
-    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
+    EIGEN_STRONG_INLINE
     CwiseBinaryOp(const CwiseBinaryOp<BinaryOp,LhsType,RhsType>&) = default;
 #endif
 
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
     CwiseBinaryOp(const Lhs& aLhs, const Rhs& aRhs, const BinaryOp& func = BinaryOp())
       : m_lhs(aLhs), m_rhs(aRhs), m_functor(func)
     {
       EIGEN_CHECK_BINARY_COMPATIBILIY(BinaryOp,typename Lhs::Scalar,typename Rhs::Scalar);
       // require the sizes to match
       EIGEN_STATIC_ASSERT_SAME_MATRIX_SIZE(Lhs, Rhs)
       eigen_assert(aLhs.rows() == aRhs.rows() && aLhs.cols() == aRhs.cols());
     }
 
-    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    Index rows() const {
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    Index rows() const EIGEN_NOEXCEPT {
       // return the fixed size type if available to enable compile time optimizations
-      if (internal::traits<typename internal::remove_all<LhsNested>::type>::RowsAtCompileTime==Dynamic)
-        return m_rhs.rows();
-      else
-        return m_lhs.rows();
+      return internal::traits<typename internal::remove_all<LhsNested>::type>::RowsAtCompileTime==Dynamic ? m_rhs.rows() : m_lhs.rows();
     }
-    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    Index cols() const {
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    Index cols() const EIGEN_NOEXCEPT {
       // return the fixed size type if available to enable compile time optimizations
-      if (internal::traits<typename internal::remove_all<LhsNested>::type>::ColsAtCompileTime==Dynamic)
-        return m_rhs.cols();
-      else
-        return m_lhs.cols();
+      return internal::traits<typename internal::remove_all<LhsNested>::type>::ColsAtCompileTime==Dynamic ? m_rhs.cols() : m_lhs.cols();
     }
 
     /** \returns the left hand side nested expression */
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
     const _LhsNested& lhs() const { return m_lhs; }
     /** \returns the right hand side nested expression */
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/CwiseNullaryOp.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/CwiseNullaryOp.h`

 * *Files 8% similar despite different names*

```diff
@@ -70,18 +70,18 @@
     {
       eigen_assert(rows >= 0
             && (RowsAtCompileTime == Dynamic || RowsAtCompileTime == rows)
             &&  cols >= 0
             && (ColsAtCompileTime == Dynamic || ColsAtCompileTime == cols));
     }
 
-    EIGEN_DEVICE_FUNC
-    EIGEN_STRONG_INLINE Index rows() const { return m_rows.value(); }
-    EIGEN_DEVICE_FUNC
-    EIGEN_STRONG_INLINE Index cols() const { return m_cols.value(); }
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    Index rows() const { return m_rows.value(); }
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    Index cols() const { return m_cols.value(); }
 
     /** \returns the functor representing the nullary operation */
     EIGEN_DEVICE_FUNC
     const NullaryOp& functor() const { return m_functor; }
 
   protected:
     const internal::variable_if_dynamic<Index, RowsAtCompileTime> m_rows;
@@ -127,15 +127,15 @@
   * it is redundant to pass \a size as argument, so Zero() should be used
   * instead.
   *
   * The template parameter \a CustomNullaryOp is the type of the functor.
   *
   * Here is an example with C++11 random generators: \include random_cpp11.cpp
   * Output: \verbinclude random_cpp11.out
-  * 
+  *
   * \sa class CwiseNullaryOp
   */
 template<typename Derived>
 template<typename CustomNullaryOp>
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
 #ifndef EIGEN_PARSED_BY_DOXYGEN
 const CwiseNullaryOp<CustomNullaryOp, typename DenseBase<Derived>::PlainObject>
@@ -379,14 +379,41 @@
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&
 PlainObjectBase<Derived>::setConstant(Index rows, Index cols, const Scalar& val)
 {
   resize(rows, cols);
   return setConstant(val);
 }
 
+/** Resizes to the given size, changing only the number of columns, and sets all
+  * coefficients in this expression to the given value \a val. For the parameter
+  * of type NoChange_t, just pass the special value \c NoChange.
+  *
+  * \sa MatrixBase::setConstant(const Scalar&), setConstant(Index,const Scalar&), class CwiseNullaryOp, MatrixBase::Constant(const Scalar&)
+  */
+template<typename Derived>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&
+PlainObjectBase<Derived>::setConstant(NoChange_t, Index cols, const Scalar& val)
+{
+  return setConstant(rows(), cols, val);
+}
+
+/** Resizes to the given size, changing only the number of rows, and sets all
+  * coefficients in this expression to the given value \a val. For the parameter
+  * of type NoChange_t, just pass the special value \c NoChange.
+  *
+  * \sa MatrixBase::setConstant(const Scalar&), setConstant(Index,const Scalar&), class CwiseNullaryOp, MatrixBase::Constant(const Scalar&)
+  */
+template<typename Derived>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&
+PlainObjectBase<Derived>::setConstant(Index rows, NoChange_t, const Scalar& val)
+{
+  return setConstant(rows, cols(), val);
+}
+
+
 /**
   * \brief Sets a linearly spaced vector.
   *
   * The function generates 'size' equally spaced values in the closed interval [low,high].
   * When size is set to 1, a vector of length 1 containing 'high' is returned.
   *
   * \only_for_vectors
@@ -552,14 +579,40 @@
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&
 PlainObjectBase<Derived>::setZero(Index rows, Index cols)
 {
   resize(rows, cols);
   return setConstant(Scalar(0));
 }
 
+/** Resizes to the given size, changing only the number of columns, and sets all
+  * coefficients in this expression to zero. For the parameter of type NoChange_t,
+  * just pass the special value \c NoChange.
+  *
+  * \sa DenseBase::setZero(), setZero(Index), setZero(Index, Index), setZero(Index, NoChange_t), class CwiseNullaryOp, DenseBase::Zero()
+  */
+template<typename Derived>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&
+PlainObjectBase<Derived>::setZero(NoChange_t, Index cols)
+{
+  return setZero(rows(), cols);
+}
+
+/** Resizes to the given size, changing only the number of rows, and sets all
+  * coefficients in this expression to zero. For the parameter of type NoChange_t,
+  * just pass the special value \c NoChange.
+  *
+  * \sa DenseBase::setZero(), setZero(Index), setZero(Index, Index), setZero(NoChange_t, Index), class CwiseNullaryOp, DenseBase::Zero()
+  */
+template<typename Derived>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&
+PlainObjectBase<Derived>::setZero(Index rows, NoChange_t)
+{
+  return setZero(rows, cols());
+}
+
 // ones:
 
 /** \returns an expression of a matrix where all coefficients equal one.
   *
   * The parameters \a rows and \a cols are the number of rows and of columns of
   * the returned matrix. Must be compatible with this MatrixBase type.
   *
@@ -678,14 +731,40 @@
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&
 PlainObjectBase<Derived>::setOnes(Index rows, Index cols)
 {
   resize(rows, cols);
   return setConstant(Scalar(1));
 }
 
+/** Resizes to the given size, changing only the number of rows, and sets all
+  * coefficients in this expression to one. For the parameter of type NoChange_t,
+  * just pass the special value \c NoChange.
+  *
+ * \sa MatrixBase::setOnes(), setOnes(Index), setOnes(Index, Index), setOnes(NoChange_t, Index), class CwiseNullaryOp, MatrixBase::Ones()
+  */
+template<typename Derived>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&
+PlainObjectBase<Derived>::setOnes(Index rows, NoChange_t)
+{
+  return setOnes(rows, cols());
+}
+
+/** Resizes to the given size, changing only the number of columns, and sets all
+  * coefficients in this expression to one. For the parameter of type NoChange_t,
+  * just pass the special value \c NoChange.
+  *
+ * \sa MatrixBase::setOnes(), setOnes(Index), setOnes(Index, Index), setOnes(Index, NoChange_t) class CwiseNullaryOp, MatrixBase::Ones()
+  */
+template<typename Derived>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&
+PlainObjectBase<Derived>::setOnes(NoChange_t, Index cols)
+{
+  return setOnes(rows(), cols);
+}
+
 // Identity:
 
 /** \returns an expression of the identity matrix (not necessarily square).
   *
   * The parameters \a rows and \a cols are the number of rows and of columns of
   * the returned matrix. Must be compatible with this MatrixBase type.
   *
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/CwiseTernaryOp.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/CwiseTernaryOp.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/CwiseUnaryOp.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/CwiseUnaryOp.h`

 * *Files 7% similar despite different names*

```diff
@@ -7,28 +7,28 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_CWISE_UNARY_OP_H
 #define EIGEN_CWISE_UNARY_OP_H
 
-namespace Eigen { 
+namespace Eigen {
 
 namespace internal {
 template<typename UnaryOp, typename XprType>
 struct traits<CwiseUnaryOp<UnaryOp, XprType> >
  : traits<XprType>
 {
   typedef typename result_of<
                      UnaryOp(const typename XprType::Scalar&)
                    >::type Scalar;
   typedef typename XprType::Nested XprTypeNested;
   typedef typename remove_reference<XprTypeNested>::type _XprTypeNested;
   enum {
-    Flags = _XprTypeNested::Flags & RowMajorBit 
+    Flags = _XprTypeNested::Flags & RowMajorBit
   };
 };
 }
 
 template<typename UnaryOp, typename XprType, typename StorageKind>
 class CwiseUnaryOpImpl;
 
@@ -61,18 +61,18 @@
     typedef typename internal::ref_selector<XprType>::type XprTypeNested;
     typedef typename internal::remove_all<XprType>::type NestedExpression;
 
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
     explicit CwiseUnaryOp(const XprType& xpr, const UnaryOp& func = UnaryOp())
       : m_xpr(xpr), m_functor(func) {}
 
-    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    Index rows() const { return m_xpr.rows(); }
-    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    Index cols() const { return m_xpr.cols(); }
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    Index rows() const EIGEN_NOEXCEPT { return m_xpr.rows(); }
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    Index cols() const EIGEN_NOEXCEPT { return m_xpr.cols(); }
 
     /** \returns the functor representing the unary operation */
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
     const UnaryOp& functor() const { return m_functor; }
 
     /** \returns the nested expression */
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/CwiseUnaryView.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/CwiseUnaryView.h`

 * *Files 5% similar despite different names*

```diff
@@ -60,31 +60,33 @@
   public:
 
     typedef typename CwiseUnaryViewImpl<ViewOp, MatrixType,typename internal::traits<MatrixType>::StorageKind>::Base Base;
     EIGEN_GENERIC_PUBLIC_INTERFACE(CwiseUnaryView)
     typedef typename internal::ref_selector<MatrixType>::non_const_type MatrixTypeNested;
     typedef typename internal::remove_all<MatrixType>::type NestedExpression;
 
-    explicit inline CwiseUnaryView(MatrixType& mat, const ViewOp& func = ViewOp())
+    explicit EIGEN_DEVICE_FUNC inline CwiseUnaryView(MatrixType& mat, const ViewOp& func = ViewOp())
       : m_matrix(mat), m_functor(func) {}
 
     EIGEN_INHERIT_ASSIGNMENT_OPERATORS(CwiseUnaryView)
 
-    EIGEN_STRONG_INLINE Index rows() const { return m_matrix.rows(); }
-    EIGEN_STRONG_INLINE Index cols() const { return m_matrix.cols(); }
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    Index rows() const EIGEN_NOEXCEPT { return m_matrix.rows(); }
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    Index cols() const EIGEN_NOEXCEPT { return m_matrix.cols(); }
 
     /** \returns the functor representing unary operation */
-    const ViewOp& functor() const { return m_functor; }
+    EIGEN_DEVICE_FUNC const ViewOp& functor() const { return m_functor; }
 
     /** \returns the nested expression */
-    const typename internal::remove_all<MatrixTypeNested>::type&
+    EIGEN_DEVICE_FUNC const typename internal::remove_all<MatrixTypeNested>::type&
     nestedExpression() const { return m_matrix; }
 
     /** \returns the nested expression */
-    typename internal::remove_reference<MatrixTypeNested>::type&
+    EIGEN_DEVICE_FUNC typename internal::remove_reference<MatrixTypeNested>::type&
     nestedExpression() { return m_matrix; }
 
   protected:
     MatrixTypeNested m_matrix;
     ViewOp m_functor;
 };
 
@@ -104,24 +106,24 @@
   public:
 
     typedef CwiseUnaryView<ViewOp, MatrixType> Derived;
     typedef typename internal::dense_xpr_base< CwiseUnaryView<ViewOp, MatrixType> >::type Base;
 
     EIGEN_DENSE_PUBLIC_INTERFACE(Derived)
     EIGEN_INHERIT_ASSIGNMENT_OPERATORS(CwiseUnaryViewImpl)
-    
+
     EIGEN_DEVICE_FUNC inline Scalar* data() { return &(this->coeffRef(0)); }
     EIGEN_DEVICE_FUNC inline const Scalar* data() const { return &(this->coeff(0)); }
 
-    EIGEN_DEVICE_FUNC inline Index innerStride() const
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index innerStride() const
     {
       return derived().nestedExpression().innerStride() * sizeof(typename internal::traits<MatrixType>::Scalar) / sizeof(Scalar);
     }
 
-    EIGEN_DEVICE_FUNC inline Index outerStride() const
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index outerStride() const
     {
       return derived().nestedExpression().outerStride() * sizeof(typename internal::traits<MatrixType>::Scalar) / sizeof(Scalar);
     }
   protected:
     EIGEN_DEFAULT_EMPTY_CONSTRUCTOR_AND_DESTRUCTOR(CwiseUnaryViewImpl)
 };
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/DenseBase.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/DenseBase.h`

 * *Files 3% similar despite different names*

```diff
@@ -10,23 +10,23 @@
 
 #ifndef EIGEN_DENSEBASE_H
 #define EIGEN_DENSEBASE_H
 
 namespace Eigen {
 
 namespace internal {
-  
+
 // The index type defined by EIGEN_DEFAULT_DENSE_INDEX_TYPE must be a signed type.
 // This dummy function simply aims at checking that at compile time.
 static inline void check_DenseIndex_is_signed() {
-  EIGEN_STATIC_ASSERT(NumTraits<DenseIndex>::IsSigned,THE_INDEX_TYPE_MUST_BE_A_SIGNED_TYPE); 
+  EIGEN_STATIC_ASSERT(NumTraits<DenseIndex>::IsSigned,THE_INDEX_TYPE_MUST_BE_A_SIGNED_TYPE)
 }
 
 } // end namespace internal
-  
+
 /** \class DenseBase
   * \ingroup Core_Module
   *
   * \brief Base class for all dense matrices, vectors, and arrays
   *
   * This class is the base that is inherited by all dense objects (matrix, vector, arrays,
   * and related expression types). The common Eigen API for dense objects is contained in this class.
@@ -60,20 +60,20 @@
       *          PermutationMatrix or Transpositions, otherwise it defaults to Eigen::Index
       * \sa \blank \ref TopicPreprocessorDirectives, Eigen::Index, SparseMatrixBase.
      */
     typedef typename internal::traits<Derived>::StorageIndex StorageIndex;
 
     /** The numeric type of the expression' coefficients, e.g. float, double, int or std::complex<float>, etc. */
     typedef typename internal::traits<Derived>::Scalar Scalar;
-    
+
     /** The numeric type of the expression' coefficients, e.g. float, double, int or std::complex<float>, etc.
       *
       * It is an alias for the Scalar type */
     typedef Scalar value_type;
-    
+
     typedef typename NumTraits<Scalar>::Real RealScalar;
     typedef DenseCoeffsBase<Derived, internal::accessors_level<Derived>::value> Base;
 
     using Base::derived;
     using Base::const_cast_derived;
     using Base::rows;
     using Base::cols;
@@ -154,15 +154,15 @@
                            || internal::traits<Derived>::ColsAtCompileTime == 1,
         /**< This is set to true if either the number of rows or the number of
           * columns is known at compile-time to be equal to 1. Indeed, in that case,
           * we are dealing with a column-vector (if there is only one column) or with
           * a row-vector (if there is only one row). */
 
       NumDimensions = int(MaxSizeAtCompileTime) == 1 ? 0 : bool(IsVectorAtCompileTime) ? 1 : 2,
-        /**< This value is equal to Tensor::NumDimensions, i.e. 0 for scalars, 1 for vectors, 
+        /**< This value is equal to Tensor::NumDimensions, i.e. 0 for scalars, 1 for vectors,
          * and 2 for matrices.
          */
 
       Flags = internal::traits<Derived>::Flags,
         /**< This stores expression \ref flags flags which may or may not be inherited by new expressions
           * constructed from this one. See the \ref flags "list of flags".
           */
@@ -171,29 +171,29 @@
 
       InnerSizeAtCompileTime = int(IsVectorAtCompileTime) ? int(SizeAtCompileTime)
                              : int(IsRowMajor) ? int(ColsAtCompileTime) : int(RowsAtCompileTime),
 
       InnerStrideAtCompileTime = internal::inner_stride_at_compile_time<Derived>::ret,
       OuterStrideAtCompileTime = internal::outer_stride_at_compile_time<Derived>::ret
     };
-    
+
     typedef typename internal::find_best_packet<Scalar,SizeAtCompileTime>::type PacketScalar;
 
     enum { IsPlainObjectBase = 0 };
-    
+
     /** The plain matrix type corresponding to this expression.
       * \sa PlainObject */
     typedef Matrix<typename internal::traits<Derived>::Scalar,
                 internal::traits<Derived>::RowsAtCompileTime,
                 internal::traits<Derived>::ColsAtCompileTime,
                 AutoAlign | (internal::traits<Derived>::Flags&RowMajorBit ? RowMajor : ColMajor),
                 internal::traits<Derived>::MaxRowsAtCompileTime,
                 internal::traits<Derived>::MaxColsAtCompileTime
           > PlainMatrix;
-    
+
     /** The plain array type corresponding to this expression.
       * \sa PlainObject */
     typedef Array<typename internal::traits<Derived>::Scalar,
                 internal::traits<Derived>::RowsAtCompileTime,
                 internal::traits<Derived>::ColsAtCompileTime,
                 AutoAlign | (internal::traits<Derived>::Flags&RowMajorBit ? RowMajor : ColMajor),
                 internal::traits<Derived>::MaxRowsAtCompileTime,
@@ -207,35 +207,35 @@
       * that the return type of eval() is either PlainObject or const PlainObject&.
       */
     typedef typename internal::conditional<internal::is_same<typename internal::traits<Derived>::XprKind,MatrixXpr >::value,
                                  PlainMatrix, PlainArray>::type PlainObject;
 
     /** \returns the number of nonzero coefficients which is in practice the number
       * of stored coefficients. */
-    EIGEN_DEVICE_FUNC
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
     inline Index nonZeros() const { return size(); }
 
     /** \returns the outer size.
       *
       * \note For a vector, this returns just 1. For a matrix (non-vector), this is the major dimension
       * with respect to the \ref TopicStorageOrders "storage order", i.e., the number of columns for a
       * column-major matrix, and the number of rows for a row-major matrix. */
-    EIGEN_DEVICE_FUNC
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
     Index outerSize() const
     {
       return IsVectorAtCompileTime ? 1
            : int(IsRowMajor) ? this->rows() : this->cols();
     }
 
     /** \returns the inner size.
       *
       * \note For a vector, this is just the size. For a matrix (non-vector), this is the minor dimension
-      * with respect to the \ref TopicStorageOrders "storage order", i.e., the number of rows for a 
+      * with respect to the \ref TopicStorageOrders "storage order", i.e., the number of rows for a
       * column-major matrix, and the number of columns for a row-major matrix. */
-    EIGEN_DEVICE_FUNC
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
     Index innerSize() const
     {
       return IsVectorAtCompileTime ? this->size()
            : int(IsRowMajor) ? this->cols() : this->rows();
     }
 
     /** Only plain matrices/arrays, not expressions, may be resized; therefore the only useful resize methods are
@@ -407,15 +407,15 @@
     EIGEN_STRONG_INLINE EvalReturnType eval() const
     {
       // Even though MSVC does not honor strong inlining when the return type
       // is a dynamic matrix, we desperately need strong inlining for fixed
       // size types on MSVC.
       return typename internal::eval<Derived>::type(derived());
     }
-    
+
     /** swaps *this with the expression \a other.
       *
       */
     template<typename OtherDerived>
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
     void swap(const DenseBase<OtherDerived>& other)
     {
@@ -445,26 +445,66 @@
 
     EIGEN_DEVICE_FUNC Scalar sum() const;
     EIGEN_DEVICE_FUNC Scalar mean() const;
     EIGEN_DEVICE_FUNC Scalar trace() const;
 
     EIGEN_DEVICE_FUNC Scalar prod() const;
 
+    template<int NaNPropagation>
     EIGEN_DEVICE_FUNC typename internal::traits<Derived>::Scalar minCoeff() const;
+    template<int NaNPropagation>
     EIGEN_DEVICE_FUNC typename internal::traits<Derived>::Scalar maxCoeff() const;
 
-    template<typename IndexType> EIGEN_DEVICE_FUNC
+
+    // By default, the fastest version with undefined NaN propagation semantics is
+    // used.
+    // TODO(rmlarsen): Replace with default template argument when we move to
+    // c++11 or beyond.
+    EIGEN_DEVICE_FUNC inline typename internal::traits<Derived>::Scalar minCoeff() const {
+      return minCoeff<PropagateFast>();
+    }
+    EIGEN_DEVICE_FUNC inline typename internal::traits<Derived>::Scalar maxCoeff() const {
+      return maxCoeff<PropagateFast>();
+    }
+
+    template<int NaNPropagation, typename IndexType>
+    EIGEN_DEVICE_FUNC
     typename internal::traits<Derived>::Scalar minCoeff(IndexType* row, IndexType* col) const;
-    template<typename IndexType> EIGEN_DEVICE_FUNC
+    template<int NaNPropagation, typename IndexType>
+    EIGEN_DEVICE_FUNC
     typename internal::traits<Derived>::Scalar maxCoeff(IndexType* row, IndexType* col) const;
-    template<typename IndexType> EIGEN_DEVICE_FUNC
+    template<int NaNPropagation, typename IndexType>
+    EIGEN_DEVICE_FUNC
     typename internal::traits<Derived>::Scalar minCoeff(IndexType* index) const;
-    template<typename IndexType> EIGEN_DEVICE_FUNC
+    template<int NaNPropagation, typename IndexType>
+    EIGEN_DEVICE_FUNC
     typename internal::traits<Derived>::Scalar maxCoeff(IndexType* index) const;
 
+    // TODO(rmlarsen): Replace these methods with a default template argument.
+    template<typename IndexType>
+    EIGEN_DEVICE_FUNC inline
+    typename internal::traits<Derived>::Scalar minCoeff(IndexType* row, IndexType* col) const {
+      return minCoeff<PropagateFast>(row, col);
+    }
+    template<typename IndexType>
+    EIGEN_DEVICE_FUNC inline
+    typename internal::traits<Derived>::Scalar maxCoeff(IndexType* row, IndexType* col) const {
+      return maxCoeff<PropagateFast>(row, col);
+    }
+    template<typename IndexType>
+     EIGEN_DEVICE_FUNC inline
+    typename internal::traits<Derived>::Scalar minCoeff(IndexType* index) const {
+      return minCoeff<PropagateFast>(index);
+    }
+    template<typename IndexType>
+    EIGEN_DEVICE_FUNC inline
+    typename internal::traits<Derived>::Scalar maxCoeff(IndexType* index) const {
+      return maxCoeff<PropagateFast>(index);
+    }
+  
     template<typename BinaryOp>
     EIGEN_DEVICE_FUNC
     Scalar redux(const BinaryOp& func) const;
 
     template<typename Visitor>
     EIGEN_DEVICE_FUNC
     void visit(Visitor& func) const;
@@ -526,24 +566,24 @@
 
     typedef CwiseNullaryOp<internal::scalar_random_op<Scalar>,PlainObject> RandomReturnType;
     static const RandomReturnType Random(Index rows, Index cols);
     static const RandomReturnType Random(Index size);
     static const RandomReturnType Random();
 
     template<typename ThenDerived,typename ElseDerived>
-    const Select<Derived,ThenDerived,ElseDerived>
+    inline EIGEN_DEVICE_FUNC const Select<Derived,ThenDerived,ElseDerived>
     select(const DenseBase<ThenDerived>& thenMatrix,
            const DenseBase<ElseDerived>& elseMatrix) const;
 
     template<typename ThenDerived>
-    inline const Select<Derived,ThenDerived, typename ThenDerived::ConstantReturnType>
+    inline EIGEN_DEVICE_FUNC const Select<Derived,ThenDerived, typename ThenDerived::ConstantReturnType>
     select(const DenseBase<ThenDerived>& thenMatrix, const typename ThenDerived::Scalar& elseScalar) const;
 
     template<typename ElseDerived>
-    inline const Select<Derived, typename ElseDerived::ConstantReturnType, ElseDerived >
+    inline EIGEN_DEVICE_FUNC const Select<Derived, typename ElseDerived::ConstantReturnType, ElseDerived >
     select(const typename ElseDerived::Scalar& thenScalar, const DenseBase<ElseDerived>& elseMatrix) const;
 
     template<int p> RealScalar lpNorm() const;
 
     template<int RowFactor, int ColFactor>
     EIGEN_DEVICE_FUNC
     const Replicate<Derived,RowFactor,ColFactor> replicate() const;
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/DenseCoeffsBase.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/DenseCoeffsBase.h`

 * *Files 4% similar despite different names*

```diff
@@ -23,15 +23,15 @@
   * \ingroup Core_Module
   * \tparam Derived Type of the derived class
   *
   * \note #ReadOnlyAccessors Constant indicating read-only access
   *
   * This class defines the \c operator() \c const function and friends, which can be used to read specific
   * entries of a matrix or array.
-  * 
+  *
   * \sa DenseCoeffsBase<Derived, WriteAccessors>, DenseCoeffsBase<Derived, DirectAccessors>,
   *     \ref TopicClassHierarchy
   */
 template<typename Derived>
 class DenseCoeffsBase<Derived,ReadOnlyAccessors> : public EigenBase<Derived>
 {
   public:
@@ -291,15 +291,15 @@
   * \tparam Derived Type of the derived class
   *
   * \note #WriteAccessors Constant indicating read/write access
   *
   * This class defines the non-const \c operator() function and friends, which can be used to write specific
   * entries of a matrix or array. This class inherits DenseCoeffsBase<Derived, ReadOnlyAccessors> which
   * defines the const variant for reading specific entries.
-  * 
+  *
   * \sa DenseCoeffsBase<Derived, DirectAccessors>, \ref TopicClassHierarchy
   */
 template<typename Derived>
 class DenseCoeffsBase<Derived, WriteAccessors> : public DenseCoeffsBase<Derived, ReadOnlyAccessors>
 {
   public:
 
@@ -491,52 +491,52 @@
     using Base::size;
     using Base::derived;
 
     /** \returns the pointer increment between two consecutive elements within a slice in the inner direction.
       *
       * \sa outerStride(), rowStride(), colStride()
       */
-    EIGEN_DEVICE_FUNC
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
     inline Index innerStride() const
     {
       return derived().innerStride();
     }
 
     /** \returns the pointer increment between two consecutive inner slices (for example, between two consecutive columns
       *          in a column-major matrix).
       *
       * \sa innerStride(), rowStride(), colStride()
       */
-    EIGEN_DEVICE_FUNC
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
     inline Index outerStride() const
     {
       return derived().outerStride();
     }
 
     // FIXME shall we remove it ?
-    inline Index stride() const
+    EIGEN_CONSTEXPR inline Index stride() const
     {
       return Derived::IsVectorAtCompileTime ? innerStride() : outerStride();
     }
 
     /** \returns the pointer increment between two consecutive rows.
       *
       * \sa innerStride(), outerStride(), colStride()
       */
-    EIGEN_DEVICE_FUNC
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
     inline Index rowStride() const
     {
       return Derived::IsRowMajor ? outerStride() : innerStride();
     }
 
     /** \returns the pointer increment between two consecutive columns.
       *
       * \sa innerStride(), outerStride(), rowStride()
       */
-    EIGEN_DEVICE_FUNC
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
     inline Index colStride() const
     {
       return Derived::IsRowMajor ? innerStride() : outerStride();
     }
 };
 
 /** \brief Base class providing direct read/write coefficient access to matrices and arrays.
@@ -566,64 +566,64 @@
     using Base::size;
     using Base::derived;
 
     /** \returns the pointer increment between two consecutive elements within a slice in the inner direction.
       *
       * \sa outerStride(), rowStride(), colStride()
       */
-    EIGEN_DEVICE_FUNC
-    inline Index innerStride() const
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index innerStride() const EIGEN_NOEXCEPT
     {
       return derived().innerStride();
     }
 
     /** \returns the pointer increment between two consecutive inner slices (for example, between two consecutive columns
       *          in a column-major matrix).
       *
       * \sa innerStride(), rowStride(), colStride()
       */
-    EIGEN_DEVICE_FUNC
-    inline Index outerStride() const
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index outerStride() const EIGEN_NOEXCEPT
     {
       return derived().outerStride();
     }
 
     // FIXME shall we remove it ?
-    inline Index stride() const
+    EIGEN_CONSTEXPR inline Index stride() const EIGEN_NOEXCEPT
     {
       return Derived::IsVectorAtCompileTime ? innerStride() : outerStride();
     }
 
     /** \returns the pointer increment between two consecutive rows.
       *
       * \sa innerStride(), outerStride(), colStride()
       */
-    EIGEN_DEVICE_FUNC
-    inline Index rowStride() const
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index rowStride() const EIGEN_NOEXCEPT
     {
       return Derived::IsRowMajor ? outerStride() : innerStride();
     }
 
     /** \returns the pointer increment between two consecutive columns.
       *
       * \sa innerStride(), outerStride(), rowStride()
       */
-    EIGEN_DEVICE_FUNC
-    inline Index colStride() const
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index colStride() const EIGEN_NOEXCEPT
     {
       return Derived::IsRowMajor ? innerStride() : outerStride();
     }
 };
 
 namespace internal {
 
 template<int Alignment, typename Derived, bool JustReturnZero>
 struct first_aligned_impl
 {
-  static inline Index run(const Derived&)
+  static EIGEN_CONSTEXPR inline Index run(const Derived&) EIGEN_NOEXCEPT
   { return 0; }
 };
 
 template<int Alignment, typename Derived>
 struct first_aligned_impl<Alignment, Derived, false>
 {
   static inline Index run(const Derived& m)
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/DenseStorage.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/DenseStorage.h`

 * *Files 9% similar despite different names*

```diff
@@ -43,28 +43,28 @@
                         : compute_default_alignment<T,Size>::value >
 struct plain_array
 {
   T array[Size];
 
   EIGEN_DEVICE_FUNC
   plain_array()
-  { 
+  {
     check_static_allocation_size<T,Size>();
   }
 
   EIGEN_DEVICE_FUNC
   plain_array(constructor_without_unaligned_array_assert)
-  { 
+  {
     check_static_allocation_size<T,Size>();
   }
 };
 
 #if defined(EIGEN_DISABLE_UNALIGNED_ARRAY_ASSERT)
   #define EIGEN_MAKE_UNALIGNED_ARRAY_ASSERT(sizemask)
-#elif EIGEN_GNUC_AT_LEAST(4,7) 
+#elif EIGEN_GNUC_AT_LEAST(4,7)
   // GCC 4.7 is too aggressive in its optimizations and remove the alignment test based on the fact the array is declared to be aligned.
   // See this bug report: http://gcc.gnu.org/bugzilla/show_bug.cgi?id=53900
   // Hiding the origin of the array pointer behind a function argument seems to do the trick even if the function is inlined:
   template<typename PtrType>
   EIGEN_ALWAYS_INLINE PtrType eigen_unaligned_array_assert_workaround_gcc47(PtrType array) { return array; }
   #define EIGEN_MAKE_UNALIGNED_ARRAY_ASSERT(sizemask) \
     eigen_assert((internal::UIntPtr(eigen_unaligned_array_assert_workaround_gcc47(array)) & (sizemask)) == 0 \
@@ -81,92 +81,116 @@
 
 template <typename T, int Size, int MatrixOrArrayOptions>
 struct plain_array<T, Size, MatrixOrArrayOptions, 8>
 {
   EIGEN_ALIGN_TO_BOUNDARY(8) T array[Size];
 
   EIGEN_DEVICE_FUNC
-  plain_array() 
+  plain_array()
   {
     EIGEN_MAKE_UNALIGNED_ARRAY_ASSERT(7);
     check_static_allocation_size<T,Size>();
   }
 
   EIGEN_DEVICE_FUNC
-  plain_array(constructor_without_unaligned_array_assert) 
-  { 
+  plain_array(constructor_without_unaligned_array_assert)
+  {
     check_static_allocation_size<T,Size>();
   }
 };
 
 template <typename T, int Size, int MatrixOrArrayOptions>
 struct plain_array<T, Size, MatrixOrArrayOptions, 16>
 {
   EIGEN_ALIGN_TO_BOUNDARY(16) T array[Size];
 
   EIGEN_DEVICE_FUNC
-  plain_array() 
-  { 
+  plain_array()
+  {
     EIGEN_MAKE_UNALIGNED_ARRAY_ASSERT(15);
     check_static_allocation_size<T,Size>();
   }
 
   EIGEN_DEVICE_FUNC
-  plain_array(constructor_without_unaligned_array_assert) 
-  { 
+  plain_array(constructor_without_unaligned_array_assert)
+  {
     check_static_allocation_size<T,Size>();
   }
 };
 
 template <typename T, int Size, int MatrixOrArrayOptions>
 struct plain_array<T, Size, MatrixOrArrayOptions, 32>
 {
   EIGEN_ALIGN_TO_BOUNDARY(32) T array[Size];
 
   EIGEN_DEVICE_FUNC
-  plain_array() 
+  plain_array()
   {
     EIGEN_MAKE_UNALIGNED_ARRAY_ASSERT(31);
     check_static_allocation_size<T,Size>();
   }
 
   EIGEN_DEVICE_FUNC
-  plain_array(constructor_without_unaligned_array_assert) 
-  { 
+  plain_array(constructor_without_unaligned_array_assert)
+  {
     check_static_allocation_size<T,Size>();
   }
 };
 
 template <typename T, int Size, int MatrixOrArrayOptions>
 struct plain_array<T, Size, MatrixOrArrayOptions, 64>
 {
   EIGEN_ALIGN_TO_BOUNDARY(64) T array[Size];
 
   EIGEN_DEVICE_FUNC
-  plain_array() 
-  { 
+  plain_array()
+  {
     EIGEN_MAKE_UNALIGNED_ARRAY_ASSERT(63);
     check_static_allocation_size<T,Size>();
   }
 
   EIGEN_DEVICE_FUNC
-  plain_array(constructor_without_unaligned_array_assert) 
-  { 
+  plain_array(constructor_without_unaligned_array_assert)
+  {
     check_static_allocation_size<T,Size>();
   }
 };
 
 template <typename T, int MatrixOrArrayOptions, int Alignment>
 struct plain_array<T, 0, MatrixOrArrayOptions, Alignment>
 {
   T array[1];
   EIGEN_DEVICE_FUNC plain_array() {}
   EIGEN_DEVICE_FUNC plain_array(constructor_without_unaligned_array_assert) {}
 };
 
+struct plain_array_helper {
+  template<typename T, int Size, int MatrixOrArrayOptions, int Alignment>
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
+  static void copy(const plain_array<T, Size, MatrixOrArrayOptions, Alignment>& src, const Eigen::Index size,
+                         plain_array<T, Size, MatrixOrArrayOptions, Alignment>& dst) {
+    smart_copy(src.array, src.array + size, dst.array);
+  }
+  
+  template<typename T, int Size, int MatrixOrArrayOptions, int Alignment>
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
+  static void swap(plain_array<T, Size, MatrixOrArrayOptions, Alignment>& a, const Eigen::Index a_size,
+                   plain_array<T, Size, MatrixOrArrayOptions, Alignment>& b, const Eigen::Index b_size) {
+    if (a_size < b_size) {
+      std::swap_ranges(b.array, b.array + a_size, a.array);
+      smart_move(b.array + a_size, b.array + b_size, a.array + a_size);
+    } else if (a_size > b_size) {
+      std::swap_ranges(a.array, a.array + b_size, b.array);
+      smart_move(a.array + b_size, a.array + a_size, b.array + b_size);
+    } else {
+      std::swap_ranges(a.array, a.array + a_size, b.array);
+    }
+  }
+};
+
 } // end namespace internal
 
 /** \internal
   *
   * \class DenseStorage
   * \ingroup Core_Module
   *
@@ -186,48 +210,61 @@
   public:
     EIGEN_DEVICE_FUNC DenseStorage() {
       EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN(Index size = Size)
     }
     EIGEN_DEVICE_FUNC
     explicit DenseStorage(internal::constructor_without_unaligned_array_assert)
       : m_data(internal::constructor_without_unaligned_array_assert()) {}
-    EIGEN_DEVICE_FUNC 
+#if !EIGEN_HAS_CXX11 || defined(EIGEN_DENSE_STORAGE_CTOR_PLUGIN)
+    EIGEN_DEVICE_FUNC
     DenseStorage(const DenseStorage& other) : m_data(other.m_data) {
       EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN(Index size = Size)
     }
-    EIGEN_DEVICE_FUNC 
+#else
+    EIGEN_DEVICE_FUNC DenseStorage(const DenseStorage&) = default;
+#endif
+#if !EIGEN_HAS_CXX11
+    EIGEN_DEVICE_FUNC
     DenseStorage& operator=(const DenseStorage& other)
-    { 
+    {
       if (this != &other) m_data = other.m_data;
-      return *this; 
+      return *this;
     }
+#else
+    EIGEN_DEVICE_FUNC DenseStorage& operator=(const DenseStorage&) = default;
+#endif
 #if EIGEN_HAS_RVALUE_REFERENCES
+#if !EIGEN_HAS_CXX11
     EIGEN_DEVICE_FUNC DenseStorage(DenseStorage&& other) EIGEN_NOEXCEPT
       : m_data(std::move(other.m_data))
     {
     }
     EIGEN_DEVICE_FUNC DenseStorage& operator=(DenseStorage&& other) EIGEN_NOEXCEPT
     {
       if (this != &other)
         m_data = std::move(other.m_data);
       return *this;
     }
+#else
+    EIGEN_DEVICE_FUNC DenseStorage(DenseStorage&&) = default;
+    EIGEN_DEVICE_FUNC DenseStorage& operator=(DenseStorage&&) = default;
+#endif
 #endif
     EIGEN_DEVICE_FUNC DenseStorage(Index size, Index rows, Index cols) {
       EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN({})
       eigen_internal_assert(size==rows*cols && rows==_Rows && cols==_Cols);
       EIGEN_UNUSED_VARIABLE(size);
       EIGEN_UNUSED_VARIABLE(rows);
       EIGEN_UNUSED_VARIABLE(cols);
     }
     EIGEN_DEVICE_FUNC void swap(DenseStorage& other) {
       numext::swap(m_data, other.m_data);
     }
-    EIGEN_DEVICE_FUNC static Index rows(void) {return _Rows;}
-    EIGEN_DEVICE_FUNC static Index cols(void) {return _Cols;}
+    EIGEN_DEVICE_FUNC static EIGEN_CONSTEXPR Index rows(void) EIGEN_NOEXCEPT {return _Rows;}
+    EIGEN_DEVICE_FUNC static EIGEN_CONSTEXPR Index cols(void) EIGEN_NOEXCEPT {return _Cols;}
     EIGEN_DEVICE_FUNC void conservativeResize(Index,Index,Index) {}
     EIGEN_DEVICE_FUNC void resize(Index,Index,Index) {}
     EIGEN_DEVICE_FUNC const T *data() const { return m_data.array; }
     EIGEN_DEVICE_FUNC T *data() { return m_data.array; }
 };
 
 // null matrix
@@ -236,16 +273,16 @@
   public:
     EIGEN_DEVICE_FUNC DenseStorage() {}
     EIGEN_DEVICE_FUNC explicit DenseStorage(internal::constructor_without_unaligned_array_assert) {}
     EIGEN_DEVICE_FUNC DenseStorage(const DenseStorage&) {}
     EIGEN_DEVICE_FUNC DenseStorage& operator=(const DenseStorage&) { return *this; }
     EIGEN_DEVICE_FUNC DenseStorage(Index,Index,Index) {}
     EIGEN_DEVICE_FUNC void swap(DenseStorage& ) {}
-    EIGEN_DEVICE_FUNC static Index rows(void) {return _Rows;}
-    EIGEN_DEVICE_FUNC static Index cols(void) {return _Cols;}
+    EIGEN_DEVICE_FUNC static EIGEN_CONSTEXPR Index rows(void) EIGEN_NOEXCEPT {return _Rows;}
+    EIGEN_DEVICE_FUNC static EIGEN_CONSTEXPR Index cols(void) EIGEN_NOEXCEPT {return _Cols;}
     EIGEN_DEVICE_FUNC void conservativeResize(Index,Index,Index) {}
     EIGEN_DEVICE_FUNC void resize(Index,Index,Index) {}
     EIGEN_DEVICE_FUNC const T *data() const { return 0; }
     EIGEN_DEVICE_FUNC T *data() { return 0; }
 };
 
 // more specializations for null matrices; these are necessary to resolve ambiguities
@@ -264,29 +301,33 @@
     internal::plain_array<T,Size,_Options> m_data;
     Index m_rows;
     Index m_cols;
   public:
     EIGEN_DEVICE_FUNC DenseStorage() : m_rows(0), m_cols(0) {}
     EIGEN_DEVICE_FUNC explicit DenseStorage(internal::constructor_without_unaligned_array_assert)
       : m_data(internal::constructor_without_unaligned_array_assert()), m_rows(0), m_cols(0) {}
-    EIGEN_DEVICE_FUNC DenseStorage(const DenseStorage& other) : m_data(other.m_data), m_rows(other.m_rows), m_cols(other.m_cols) {}
-    EIGEN_DEVICE_FUNC DenseStorage& operator=(const DenseStorage& other) 
-    { 
+    EIGEN_DEVICE_FUNC DenseStorage(const DenseStorage& other)
+      : m_data(internal::constructor_without_unaligned_array_assert()), m_rows(other.m_rows), m_cols(other.m_cols)
+    {
+      internal::plain_array_helper::copy(other.m_data, m_rows * m_cols, m_data);
+    }
+    EIGEN_DEVICE_FUNC DenseStorage& operator=(const DenseStorage& other)
+    {
       if (this != &other)
       {
-        m_data = other.m_data;
         m_rows = other.m_rows;
         m_cols = other.m_cols;
+        internal::plain_array_helper::copy(other.m_data, m_rows * m_cols, m_data);
       }
-      return *this; 
+      return *this;
     }
     EIGEN_DEVICE_FUNC DenseStorage(Index, Index rows, Index cols) : m_rows(rows), m_cols(cols) {}
     EIGEN_DEVICE_FUNC void swap(DenseStorage& other)
     {
-      numext::swap(m_data,other.m_data);
+      internal::plain_array_helper::swap(m_data, m_rows * m_cols, other.m_data, other.m_rows * other.m_cols);
       numext::swap(m_rows,other.m_rows);
       numext::swap(m_cols,other.m_cols);
     }
     EIGEN_DEVICE_FUNC Index rows() const {return m_rows;}
     EIGEN_DEVICE_FUNC Index cols() const {return m_cols;}
     EIGEN_DEVICE_FUNC void conservativeResize(Index, Index rows, Index cols) { m_rows = rows; m_cols = cols; }
     EIGEN_DEVICE_FUNC void resize(Index, Index rows, Index cols) { m_rows = rows; m_cols = cols; }
@@ -299,32 +340,37 @@
 {
     internal::plain_array<T,Size,_Options> m_data;
     Index m_rows;
   public:
     EIGEN_DEVICE_FUNC DenseStorage() : m_rows(0) {}
     EIGEN_DEVICE_FUNC explicit DenseStorage(internal::constructor_without_unaligned_array_assert)
       : m_data(internal::constructor_without_unaligned_array_assert()), m_rows(0) {}
-    EIGEN_DEVICE_FUNC DenseStorage(const DenseStorage& other) : m_data(other.m_data), m_rows(other.m_rows) {}
-    EIGEN_DEVICE_FUNC DenseStorage& operator=(const DenseStorage& other) 
+    EIGEN_DEVICE_FUNC DenseStorage(const DenseStorage& other)
+      : m_data(internal::constructor_without_unaligned_array_assert()), m_rows(other.m_rows)
+    {
+      internal::plain_array_helper::copy(other.m_data, m_rows * _Cols, m_data);
+    }
+    
+    EIGEN_DEVICE_FUNC DenseStorage& operator=(const DenseStorage& other)
     {
       if (this != &other)
       {
-        m_data = other.m_data;
         m_rows = other.m_rows;
+        internal::plain_array_helper::copy(other.m_data, m_rows * _Cols, m_data);
       }
-      return *this; 
+      return *this;
     }
     EIGEN_DEVICE_FUNC DenseStorage(Index, Index rows, Index) : m_rows(rows) {}
     EIGEN_DEVICE_FUNC void swap(DenseStorage& other)
-    {
-      numext::swap(m_data,other.m_data);
-      numext::swap(m_rows,other.m_rows);
+    { 
+      internal::plain_array_helper::swap(m_data, m_rows * _Cols, other.m_data, other.m_rows * _Cols);
+      numext::swap(m_rows, other.m_rows);
     }
-    EIGEN_DEVICE_FUNC Index rows(void) const {return m_rows;}
-    EIGEN_DEVICE_FUNC Index cols(void) const {return _Cols;}
+    EIGEN_DEVICE_FUNC Index rows(void) const EIGEN_NOEXCEPT {return m_rows;}
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index cols(void) const EIGEN_NOEXCEPT {return _Cols;}
     EIGEN_DEVICE_FUNC void conservativeResize(Index, Index rows, Index) { m_rows = rows; }
     EIGEN_DEVICE_FUNC void resize(Index, Index rows, Index) { m_rows = rows; }
     EIGEN_DEVICE_FUNC const T *data() const { return m_data.array; }
     EIGEN_DEVICE_FUNC T *data() { return m_data.array; }
 };
 
 // dynamic-size matrix with fixed-size storage and fixed height
@@ -332,31 +378,35 @@
 {
     internal::plain_array<T,Size,_Options> m_data;
     Index m_cols;
   public:
     EIGEN_DEVICE_FUNC DenseStorage() : m_cols(0) {}
     EIGEN_DEVICE_FUNC explicit DenseStorage(internal::constructor_without_unaligned_array_assert)
       : m_data(internal::constructor_without_unaligned_array_assert()), m_cols(0) {}
-    EIGEN_DEVICE_FUNC DenseStorage(const DenseStorage& other) : m_data(other.m_data), m_cols(other.m_cols) {}
+    EIGEN_DEVICE_FUNC DenseStorage(const DenseStorage& other) 
+      : m_data(internal::constructor_without_unaligned_array_assert()), m_cols(other.m_cols)
+    {
+      internal::plain_array_helper::copy(other.m_data, _Rows * m_cols, m_data);
+    }
     EIGEN_DEVICE_FUNC DenseStorage& operator=(const DenseStorage& other)
     {
       if (this != &other)
       {
-        m_data = other.m_data;
         m_cols = other.m_cols;
+        internal::plain_array_helper::copy(other.m_data, _Rows * m_cols, m_data);
       }
       return *this;
     }
     EIGEN_DEVICE_FUNC DenseStorage(Index, Index, Index cols) : m_cols(cols) {}
     EIGEN_DEVICE_FUNC void swap(DenseStorage& other) {
-      numext::swap(m_data,other.m_data);
-      numext::swap(m_cols,other.m_cols);
+      internal::plain_array_helper::swap(m_data, _Rows * m_cols, other.m_data, _Rows * other.m_cols);
+      numext::swap(m_cols, other.m_cols);
     }
-    EIGEN_DEVICE_FUNC Index rows(void) const {return _Rows;}
-    EIGEN_DEVICE_FUNC Index cols(void) const {return m_cols;}
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index rows(void) const EIGEN_NOEXCEPT {return _Rows;}
+    EIGEN_DEVICE_FUNC Index cols(void) const EIGEN_NOEXCEPT {return m_cols;}
     EIGEN_DEVICE_FUNC void conservativeResize(Index, Index, Index cols) { m_cols = cols; }
     EIGEN_DEVICE_FUNC void resize(Index, Index, Index cols) { m_cols = cols; }
     EIGEN_DEVICE_FUNC const T *data() const { return m_data.array; }
     EIGEN_DEVICE_FUNC T *data() { return m_data.array; }
 };
 
 // purely dynamic matrix.
@@ -415,16 +465,16 @@
     EIGEN_DEVICE_FUNC ~DenseStorage() { internal::conditional_aligned_delete_auto<T,(_Options&DontAlign)==0>(m_data, m_rows*m_cols); }
     EIGEN_DEVICE_FUNC void swap(DenseStorage& other)
     {
       numext::swap(m_data,other.m_data);
       numext::swap(m_rows,other.m_rows);
       numext::swap(m_cols,other.m_cols);
     }
-    EIGEN_DEVICE_FUNC Index rows(void) const {return m_rows;}
-    EIGEN_DEVICE_FUNC Index cols(void) const {return m_cols;}
+    EIGEN_DEVICE_FUNC Index rows(void) const EIGEN_NOEXCEPT {return m_rows;}
+    EIGEN_DEVICE_FUNC Index cols(void) const EIGEN_NOEXCEPT {return m_cols;}
     void conservativeResize(Index size, Index rows, Index cols)
     {
       m_data = internal::conditional_aligned_realloc_new_auto<T,(_Options&DontAlign)==0>(m_data, size, m_rows*m_cols);
       m_rows = rows;
       m_cols = cols;
     }
     EIGEN_DEVICE_FUNC void resize(Index size, Index rows, Index cols)
@@ -470,15 +520,15 @@
     {
       if (this != &other)
       {
         DenseStorage tmp(other);
         this->swap(tmp);
       }
       return *this;
-    }    
+    }
 #if EIGEN_HAS_RVALUE_REFERENCES
     EIGEN_DEVICE_FUNC
     DenseStorage(DenseStorage&& other) EIGEN_NOEXCEPT
       : m_data(std::move(other.m_data))
       , m_cols(std::move(other.m_cols))
     {
       other.m_data = nullptr;
@@ -493,16 +543,16 @@
     }
 #endif
     EIGEN_DEVICE_FUNC ~DenseStorage() { internal::conditional_aligned_delete_auto<T,(_Options&DontAlign)==0>(m_data, _Rows*m_cols); }
     EIGEN_DEVICE_FUNC void swap(DenseStorage& other) {
       numext::swap(m_data,other.m_data);
       numext::swap(m_cols,other.m_cols);
     }
-    EIGEN_DEVICE_FUNC static Index rows(void) {return _Rows;}
-    EIGEN_DEVICE_FUNC Index cols(void) const {return m_cols;}
+    EIGEN_DEVICE_FUNC static EIGEN_CONSTEXPR Index rows(void) EIGEN_NOEXCEPT {return _Rows;}
+    EIGEN_DEVICE_FUNC Index cols(void) const EIGEN_NOEXCEPT {return m_cols;}
     EIGEN_DEVICE_FUNC void conservativeResize(Index size, Index, Index cols)
     {
       m_data = internal::conditional_aligned_realloc_new_auto<T,(_Options&DontAlign)==0>(m_data, size, _Rows*m_cols);
       m_cols = cols;
     }
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void resize(Index size, Index, Index cols)
     {
@@ -546,15 +596,15 @@
     {
       if (this != &other)
       {
         DenseStorage tmp(other);
         this->swap(tmp);
       }
       return *this;
-    }    
+    }
 #if EIGEN_HAS_RVALUE_REFERENCES
     EIGEN_DEVICE_FUNC
     DenseStorage(DenseStorage&& other) EIGEN_NOEXCEPT
       : m_data(std::move(other.m_data))
       , m_rows(std::move(other.m_rows))
     {
       other.m_data = nullptr;
@@ -569,16 +619,16 @@
     }
 #endif
     EIGEN_DEVICE_FUNC ~DenseStorage() { internal::conditional_aligned_delete_auto<T,(_Options&DontAlign)==0>(m_data, _Cols*m_rows); }
     EIGEN_DEVICE_FUNC void swap(DenseStorage& other) {
       numext::swap(m_data,other.m_data);
       numext::swap(m_rows,other.m_rows);
     }
-    EIGEN_DEVICE_FUNC Index rows(void) const {return m_rows;}
-    EIGEN_DEVICE_FUNC static Index cols(void) {return _Cols;}
+    EIGEN_DEVICE_FUNC Index rows(void) const EIGEN_NOEXCEPT {return m_rows;}
+    EIGEN_DEVICE_FUNC static EIGEN_CONSTEXPR Index cols(void) {return _Cols;}
     void conservativeResize(Index size, Index rows, Index)
     {
       m_data = internal::conditional_aligned_realloc_new_auto<T,(_Options&DontAlign)==0>(m_data, size, m_rows*_Cols);
       m_rows = rows;
     }
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void resize(Index size, Index rows, Index)
     {
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Diagonal.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Diagonal.h`

 * *Files 8% similar despite different names*

```diff
@@ -7,15 +7,15 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_DIAGONAL_H
 #define EIGEN_DIAGONAL_H
 
-namespace Eigen { 
+namespace Eigen {
 
 /** \class Diagonal
   * \ingroup Core_Module
   *
   * \brief Expression of a diagonal/subdiagonal/superdiagonal in a matrix
   *
   * \param MatrixType the type of the object in which we are taking a sub/main/super diagonal
@@ -80,28 +80,24 @@
     EIGEN_DEVICE_FUNC
     inline Index rows() const
     {
       return m_index.value()<0 ? numext::mini<Index>(m_matrix.cols(),m_matrix.rows()+m_index.value())
                                : numext::mini<Index>(m_matrix.rows(),m_matrix.cols()-m_index.value());
     }
 
-    EIGEN_DEVICE_FUNC
-    inline Index cols() const { return 1; }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index cols() const EIGEN_NOEXCEPT { return 1; }
 
-    EIGEN_DEVICE_FUNC
-    inline Index innerStride() const
-    {
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index innerStride() const EIGEN_NOEXCEPT {
       return m_matrix.outerStride() + 1;
     }
 
-    EIGEN_DEVICE_FUNC
-    inline Index outerStride() const
-    {
-      return 0;
-    }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index outerStride() const EIGEN_NOEXCEPT { return 0; }
 
     typedef typename internal::conditional<
                        internal::is_lvalue<MatrixType>::value,
                        Scalar,
                        const Scalar
                      >::type ScalarWithConstIfNotLvalue;
 
@@ -145,16 +141,16 @@
     EIGEN_DEVICE_FUNC
     inline CoeffReturnType coeff(Index idx) const
     {
       return m_matrix.coeff(idx+rowOffset(), idx+colOffset());
     }
 
     EIGEN_DEVICE_FUNC
-    inline const typename internal::remove_all<typename MatrixType::Nested>::type& 
-    nestedExpression() const 
+    inline const typename internal::remove_all<typename MatrixType::Nested>::type&
+    nestedExpression() const
     {
       return m_matrix;
     }
 
     EIGEN_DEVICE_FUNC
     inline Index index() const
     {
@@ -163,20 +159,20 @@
 
   protected:
     typename internal::ref_selector<MatrixType>::non_const_type m_matrix;
     const internal::variable_if_dynamicindex<Index, DiagIndex> m_index;
 
   private:
     // some compilers may fail to optimize std::max etc in case of compile-time constants...
-    EIGEN_DEVICE_FUNC
-    EIGEN_STRONG_INLINE Index absDiagIndex() const { return m_index.value()>0 ? m_index.value() : -m_index.value(); }
-    EIGEN_DEVICE_FUNC
-    EIGEN_STRONG_INLINE Index rowOffset() const { return m_index.value()>0 ? 0 : -m_index.value(); }
-    EIGEN_DEVICE_FUNC
-    EIGEN_STRONG_INLINE Index colOffset() const { return m_index.value()>0 ? m_index.value() : 0; }
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    Index absDiagIndex() const EIGEN_NOEXCEPT { return m_index.value()>0 ? m_index.value() : -m_index.value(); }
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    Index rowOffset() const EIGEN_NOEXCEPT { return m_index.value()>0 ? 0 : -m_index.value(); }
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    Index colOffset() const EIGEN_NOEXCEPT { return m_index.value()>0 ? m_index.value() : 0; }
     // trigger a compile-time error if someone try to call packet
     template<int LoadMode> typename MatrixType::PacketReturnType packet(Index) const;
     template<int LoadMode> typename MatrixType::PacketReturnType packet(Index,Index) const;
 };
 
 /** \returns an expression of the main diagonal of the matrix \c *this
   *
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/DiagonalMatrix.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/DiagonalMatrix.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/DiagonalProduct.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/DiagonalProduct.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Dot.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Dot.h`

 * *Files 0% similar despite different names*

```diff
@@ -82,15 +82,15 @@
   eigen_assert(size() == other.size());
 
   return internal::dot_nocheck<Derived,OtherDerived>::run(*this, other);
 }
 
 //---------- implementation of L2 norm and related functions ----------
 
-/** \returns, for vectors, the squared \em l2 norm of \c *this, and for matrices the Frobenius norm.
+/** \returns, for vectors, the squared \em l2 norm of \c *this, and for matrices the squared Frobenius norm.
   * In both cases, it consists in the sum of the square of all the matrix entries.
   * For vectors, this is also equals to the dot product of \c *this with itself.
   *
   * \sa dot(), norm(), lpNorm()
   */
 template<typename Derived>
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename NumTraits<typename internal::traits<Derived>::Scalar>::Real MatrixBase<Derived>::squaredNorm() const
@@ -203,15 +203,15 @@
 template<typename Derived, int p>
 struct lpNorm_selector
 {
   typedef typename NumTraits<typename traits<Derived>::Scalar>::Real RealScalar;
   EIGEN_DEVICE_FUNC
   static inline RealScalar run(const MatrixBase<Derived>& m)
   {
-    EIGEN_USING_STD_MATH(pow)
+    EIGEN_USING_STD(pow)
     return pow(m.cwiseAbs().array().pow(p).sum(), RealScalar(1)/p);
   }
 };
 
 template<typename Derived>
 struct lpNorm_selector<Derived, 1>
 {
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/EigenBase.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/EigenBase.h`

 * *Files 2% similar despite different names*

```diff
@@ -11,29 +11,29 @@
 #ifndef EIGEN_EIGENBASE_H
 #define EIGEN_EIGENBASE_H
 
 namespace Eigen {
 
 /** \class EigenBase
   * \ingroup Core_Module
-  * 
+  *
   * Common base class for all classes T such that MatrixBase has an operator=(T) and a constructor MatrixBase(T).
   *
   * In other words, an EigenBase object is an object that can be copied into a MatrixBase.
   *
   * Besides MatrixBase-derived classes, this also includes special matrix classes such as diagonal matrices, etc.
   *
   * Notice that this class is trivial, it is only used to disambiguate overloaded functions.
   *
   * \sa \blank \ref TopicClassHierarchy
   */
 template<typename Derived> struct EigenBase
 {
 //   typedef typename internal::plain_matrix_type<Derived>::type PlainObject;
-  
+
   /** \brief The interface type of indices
     * \details To change this, \c \#define the preprocessor symbol \c EIGEN_DEFAULT_DENSE_INDEX_TYPE.
     * \sa StorageIndex, \ref TopicPreprocessorDirectives.
     * DEPRECATED: Since Eigen 3.3, its usage is deprecated. Use Eigen::Index instead.
     * Deprecation is not marked with a doxygen comment because there are too many existing usages to add the deprecation attribute.
     */
   typedef Eigen::Index Index;
@@ -52,23 +52,23 @@
   inline Derived& const_cast_derived() const
   { return *static_cast<Derived*>(const_cast<EigenBase*>(this)); }
   EIGEN_DEVICE_FUNC
   inline const Derived& const_derived() const
   { return *static_cast<const Derived*>(this); }
 
   /** \returns the number of rows. \sa cols(), RowsAtCompileTime */
-  EIGEN_DEVICE_FUNC
-  inline Index rows() const { return derived().rows(); }
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+  inline Index rows() const EIGEN_NOEXCEPT { return derived().rows(); }
   /** \returns the number of columns. \sa rows(), ColsAtCompileTime*/
-  EIGEN_DEVICE_FUNC
-  inline Index cols() const { return derived().cols(); }
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+  inline Index cols() const EIGEN_NOEXCEPT { return derived().cols(); }
   /** \returns the number of coefficients, which is rows()*cols().
     * \sa rows(), cols(), SizeAtCompileTime. */
-  EIGEN_DEVICE_FUNC
-  inline Index size() const { return rows() * cols(); }
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+  inline Index size() const EIGEN_NOEXCEPT { return rows() * cols(); }
 
   /** \internal Don't use it, but do the equivalent: \code dst = *this; \endcode */
   template<typename Dest>
   EIGEN_DEVICE_FUNC
   inline void evalTo(Dest& dst) const
   { derived().evalTo(dst); }
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/ForceAlignedAccess.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/ForceAlignedAccess.h`

 * *Files 7% similar despite different names*

```diff
@@ -37,18 +37,22 @@
   public:
 
     typedef typename internal::dense_xpr_base<ForceAlignedAccess>::type Base;
     EIGEN_DENSE_PUBLIC_INTERFACE(ForceAlignedAccess)
 
     EIGEN_DEVICE_FUNC explicit inline ForceAlignedAccess(const ExpressionType& matrix) : m_expression(matrix) {}
 
-    EIGEN_DEVICE_FUNC inline Index rows() const { return m_expression.rows(); }
-    EIGEN_DEVICE_FUNC inline Index cols() const { return m_expression.cols(); }
-    EIGEN_DEVICE_FUNC inline Index outerStride() const { return m_expression.outerStride(); }
-    EIGEN_DEVICE_FUNC inline Index innerStride() const { return m_expression.innerStride(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index rows() const EIGEN_NOEXCEPT { return m_expression.rows(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index cols() const EIGEN_NOEXCEPT { return m_expression.cols(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index outerStride() const EIGEN_NOEXCEPT { return m_expression.outerStride(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index innerStride() const EIGEN_NOEXCEPT { return m_expression.innerStride(); }
 
     EIGEN_DEVICE_FUNC inline const CoeffReturnType coeff(Index row, Index col) const
     {
       return m_expression.coeff(row, col);
     }
 
     EIGEN_DEVICE_FUNC inline Scalar& coeffRef(Index row, Index col)
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Fuzzy.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Fuzzy.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/GeneralProduct.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/GeneralProduct.h`

 * *Files 2% similar despite different names*

```diff
@@ -224,16 +224,15 @@
     typedef typename RhsBlasTraits::DirectLinearAccessType ActualRhsType;
   
     typedef Map<Matrix<ResScalar,Dynamic,1>, EIGEN_PLAIN_ENUM_MIN(AlignedMax,internal::packet_traits<ResScalar>::size)> MappedDest;
 
     ActualLhsType actualLhs = LhsBlasTraits::extract(lhs);
     ActualRhsType actualRhs = RhsBlasTraits::extract(rhs);
 
-    ResScalar actualAlpha = alpha * LhsBlasTraits::extractScalarFactor(lhs)
-                                  * RhsBlasTraits::extractScalarFactor(rhs);
+    ResScalar actualAlpha = combine_scalar_factors(alpha, lhs, rhs);
 
     // make sure Dest is a compile-time vector type (bug 1166)
     typedef typename conditional<Dest::IsVectorAtCompileTime, Dest, typename Dest::ColXpr>::type ActualDest;
 
     enum {
       // FIXME find a way to allow an inner stride on the result if packet_traits<Scalar>::size==1
       // on, the other hand it is good for the cache to pack the vector anyways...
@@ -316,16 +315,15 @@
     typedef internal::blas_traits<Rhs> RhsBlasTraits;
     typedef typename RhsBlasTraits::DirectLinearAccessType ActualRhsType;
     typedef typename internal::remove_all<ActualRhsType>::type ActualRhsTypeCleaned;
 
     typename add_const<ActualLhsType>::type actualLhs = LhsBlasTraits::extract(lhs);
     typename add_const<ActualRhsType>::type actualRhs = RhsBlasTraits::extract(rhs);
 
-    ResScalar actualAlpha = alpha * LhsBlasTraits::extractScalarFactor(lhs)
-                                  * RhsBlasTraits::extractScalarFactor(rhs);
+    ResScalar actualAlpha = combine_scalar_factors(alpha, lhs, rhs);
 
     enum {
       // FIXME find a way to allow an inner stride on the result if packet_traits<Scalar>::size==1
       // on, the other hand it is good for the cache to pack the vector anyways...
       DirectlyUseRhs = ActualRhsTypeCleaned::InnerStrideAtCompileTime==1 || ActualRhsTypeCleaned::MaxSizeAtCompileTime==0
     };
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/GenericPacketMath.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/GenericPacketMath.h`

 * *Files 19% similar despite different names*

```diff
@@ -125,14 +125,30 @@
     HasConj   = 0,
     HasSetLinear = 0
   };
 };
 
 template<typename T> struct packet_traits<const T> : packet_traits<T> { };
 
+template<typename T> struct unpacket_traits
+{
+  typedef T type;
+  typedef T half;
+  enum
+  {
+    size = 1,
+    alignment = 1,
+    vectorizable = false,
+    masked_load_available=false,
+    masked_store_available=false
+  };
+};
+
+template<typename T> struct unpacket_traits<const T> : unpacket_traits<T> { };
+
 template <typename Src, typename Tgt> struct type_casting_traits {
   enum {
     VectorizedCast = 0,
     SrcCoeffRatio = 1,
     TgtCoeffRatio = 1
   };
 };
@@ -150,14 +166,26 @@
     m_val = v;
     return *this;
   }
 
   T m_val;
 };
 
+
+/** \internal A convenience utility for determining if the type is a scalar.
+ * This is used to enable some generic packet implementations.
+ */
+template<typename Packet>
+struct is_scalar {
+  typedef typename unpacket_traits<Packet>::type Scalar;
+  enum {
+    value = internal::is_same<Packet, Scalar>::value
+  };
+};
+
 /** \internal \returns static_cast<TgtType>(a) (coeff-wise) */
 template <typename SrcPacket, typename TgtPacket>
 EIGEN_DEVICE_FUNC inline TgtPacket
 pcast(const SrcPacket& a) {
   return static_cast<TgtPacket>(a);
 }
 template <typename SrcPacket, typename TgtPacket>
@@ -211,32 +239,317 @@
 template<> EIGEN_DEVICE_FUNC inline bool
 pmul(const bool& a, const bool& b) { return a && b; }
 
 /** \internal \returns a / b (coeff-wise) */
 template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
 pdiv(const Packet& a, const Packet& b) { return a/b; }
 
-/** \internal \returns the min of \a a and \a b  (coeff-wise) */
+// In the generic case, memset to all one bits.
+template<typename Packet, typename EnableIf = void>
+struct ptrue_impl {
+  static EIGEN_DEVICE_FUNC inline Packet run(const Packet& /*a*/){
+    Packet b;
+    memset(static_cast<void*>(&b), 0xff, sizeof(Packet));
+    return b;
+  }
+};
+
+// For non-trivial scalars, set to Scalar(1) (i.e. a non-zero value).
+// Although this is technically not a valid bitmask, the scalar path for pselect
+// uses a comparison to zero, so this should still work in most cases. We don't
+// have another option, since the scalar type requires initialization.
+template<typename T>
+struct ptrue_impl<T, 
+    typename internal::enable_if<is_scalar<T>::value && NumTraits<T>::RequireInitialization>::type > {
+  static EIGEN_DEVICE_FUNC inline T run(const T& /*a*/){
+    return T(1);
+  }
+};
+
+/** \internal \returns one bits. */
 template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
-pmin(const Packet& a, const Packet& b) { return numext::mini(a, b); }
+ptrue(const Packet& a) {
+  return ptrue_impl<Packet>::run(a);
+}
+
+// In the general case, memset to zero.
+template<typename Packet, typename EnableIf = void>
+struct pzero_impl {
+  static EIGEN_DEVICE_FUNC inline Packet run(const Packet& /*a*/) {
+    Packet b;
+    memset(static_cast<void*>(&b), 0x00, sizeof(Packet));
+    return b;
+  }
+};
 
-/** \internal \returns the max of \a a and \a b  (coeff-wise) */
+// For scalars, explicitly set to Scalar(0), since the underlying representation
+// for zero may not consist of all-zero bits.
+template<typename T>
+struct pzero_impl<T,
+    typename internal::enable_if<is_scalar<T>::value>::type> {
+  static EIGEN_DEVICE_FUNC inline T run(const T& /*a*/) {
+    return T(0);
+  }
+};
+
+/** \internal \returns packet of zeros */
+template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
+pzero(const Packet& a) {
+  return pzero_impl<Packet>::run(a);
+}
+
+/** \internal \returns a <= b as a bit mask */
+template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
+pcmp_le(const Packet& a, const Packet& b)  { return a<=b ? ptrue(a) : pzero(a); }
+
+/** \internal \returns a < b as a bit mask */
+template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
+pcmp_lt(const Packet& a, const Packet& b)  { return a<b ? ptrue(a) : pzero(a); }
+
+/** \internal \returns a == b as a bit mask */
+template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
+pcmp_eq(const Packet& a, const Packet& b) { return a==b ? ptrue(a) : pzero(a); }
+
+/** \internal \returns a < b or a==NaN or b==NaN as a bit mask */
+template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
+pcmp_lt_or_nan(const Packet& a, const Packet& b) { return a>=b ? pzero(a) : ptrue(a); }
+
+template<typename T>
+struct bit_and {
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR EIGEN_ALWAYS_INLINE T operator()(const T& a, const T& b) const {
+    return a & b;
+  }
+};
+
+template<typename T>
+struct bit_or {
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR EIGEN_ALWAYS_INLINE T operator()(const T& a, const T& b) const {
+    return a | b;
+  }
+};
+
+template<typename T>
+struct bit_xor {
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR EIGEN_ALWAYS_INLINE T operator()(const T& a, const T& b) const {
+    return a ^ b;
+  }
+};
+
+template<typename T>
+struct bit_not {
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR EIGEN_ALWAYS_INLINE T operator()(const T& a) const {
+    return ~a;
+  }
+};
+
+// Use operators &, |, ^, ~.
+template<typename T>
+struct operator_bitwise_helper {
+  EIGEN_DEVICE_FUNC static inline T bitwise_and(const T& a, const T& b) { return bit_and<T>()(a, b); }
+  EIGEN_DEVICE_FUNC static inline T bitwise_or(const T& a, const T& b) { return bit_or<T>()(a, b); }
+  EIGEN_DEVICE_FUNC static inline T bitwise_xor(const T& a, const T& b) { return bit_xor<T>()(a, b); }
+  EIGEN_DEVICE_FUNC static inline T bitwise_not(const T& a) { return bit_not<T>()(a); }
+};
+
+// Apply binary operations byte-by-byte
+template<typename T>
+struct bytewise_bitwise_helper {
+  EIGEN_DEVICE_FUNC static inline T bitwise_and(const T& a, const T& b) {
+    return binary(a, b, bit_and<unsigned char>());
+  }
+  EIGEN_DEVICE_FUNC static inline T bitwise_or(const T& a, const T& b) { 
+    return binary(a, b, bit_or<unsigned char>());
+   }
+  EIGEN_DEVICE_FUNC static inline T bitwise_xor(const T& a, const T& b) {
+    return binary(a, b, bit_xor<unsigned char>());
+  }
+  EIGEN_DEVICE_FUNC static inline T bitwise_not(const T& a) { 
+    return unary(a,bit_not<unsigned char>());
+   }
+  
+ private:
+  template<typename Op>
+  EIGEN_DEVICE_FUNC static inline T unary(const T& a, Op op) {
+    const unsigned char* a_ptr = reinterpret_cast<const unsigned char*>(&a);
+    T c;
+    unsigned char* c_ptr = reinterpret_cast<unsigned char*>(&c);
+    for (size_t i = 0; i < sizeof(T); ++i) {
+      *c_ptr++ = op(*a_ptr++);
+    }
+    return c;
+  }
+
+  template<typename Op>
+  EIGEN_DEVICE_FUNC static inline T binary(const T& a, const T& b, Op op) {
+    const unsigned char* a_ptr = reinterpret_cast<const unsigned char*>(&a);
+    const unsigned char* b_ptr = reinterpret_cast<const unsigned char*>(&b);
+    T c;
+    unsigned char* c_ptr = reinterpret_cast<unsigned char*>(&c);
+    for (size_t i = 0; i < sizeof(T); ++i) {
+      *c_ptr++ = op(*a_ptr++, *b_ptr++);
+    }
+    return c;
+  }
+};
+
+// In the general case, use byte-by-byte manipulation.
+template<typename T, typename EnableIf = void>
+struct bitwise_helper : public bytewise_bitwise_helper<T> {};
+
+// For integers or non-trivial scalars, use binary operators.
+template<typename T>
+struct bitwise_helper<T,
+  typename internal::enable_if<
+    is_scalar<T>::value && (NumTraits<T>::IsInteger || NumTraits<T>::RequireInitialization)>::type
+  > : public operator_bitwise_helper<T> {};
+
+/** \internal \returns the bitwise and of \a a and \a b */
+template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
+pand(const Packet& a, const Packet& b) {
+  return bitwise_helper<Packet>::bitwise_and(a, b);
+}
+
+/** \internal \returns the bitwise or of \a a and \a b */
+template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
+por(const Packet& a, const Packet& b) {
+  return bitwise_helper<Packet>::bitwise_or(a, b);
+}
+
+/** \internal \returns the bitwise xor of \a a and \a b */
+template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
+pxor(const Packet& a, const Packet& b) {
+  return bitwise_helper<Packet>::bitwise_xor(a, b);
+}
+
+/** \internal \returns the bitwise not of \a a */
+template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
+pnot(const Packet& a) {
+  return bitwise_helper<Packet>::bitwise_not(a);
+}
+
+/** \internal \returns the bitwise and of \a a and not \a b */
+template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
+pandnot(const Packet& a, const Packet& b) { return pand(a, pnot(b)); }
+
+// In the general case, use bitwise select.
+template<typename Packet, typename EnableIf = void>
+struct pselect_impl {
+  static EIGEN_DEVICE_FUNC inline Packet run(const Packet& mask, const Packet& a, const Packet& b) {
+    return por(pand(a,mask),pandnot(b,mask));
+  }
+};
+
+// For scalars, use ternary select.
+template<typename Packet>
+struct pselect_impl<Packet, 
+    typename internal::enable_if<is_scalar<Packet>::value>::type > {
+  static EIGEN_DEVICE_FUNC inline Packet run(const Packet& mask, const Packet& a, const Packet& b) {
+    return numext::equal_strict(mask, Packet(0)) ? b : a;
+  }
+};
+
+/** \internal \returns \a or \b for each field in packet according to \mask */
+template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
+pselect(const Packet& mask, const Packet& a, const Packet& b) {
+  return pselect_impl<Packet>::run(mask, a, b);
+}
+
+template<> EIGEN_DEVICE_FUNC inline bool pselect<bool>(
+    const bool& cond, const bool& a, const bool& b) {
+  return cond ? a : b;
+}
+
+/** \internal \returns the min or of \a a and \a b (coeff-wise)
+    If either \a a or \a b are NaN, the result is implementation defined. */
+template<int NaNPropagation>
+struct pminmax_impl {
+  template <typename Packet, typename Op>
+  static EIGEN_DEVICE_FUNC inline Packet run(const Packet& a, const Packet& b, Op op) {
+    return op(a,b);
+  }
+};
+
+/** \internal \returns the min or max of \a a and \a b (coeff-wise)
+    If either \a a or \a b are NaN, NaN is returned. */
+template<>
+struct pminmax_impl<PropagateNaN> {
+  template <typename Packet, typename Op>
+  static EIGEN_DEVICE_FUNC inline Packet run(const Packet& a, const Packet& b, Op op) {
+  Packet not_nan_mask_a = pcmp_eq(a, a);
+  Packet not_nan_mask_b = pcmp_eq(b, b);
+  return pselect(not_nan_mask_a,
+                 pselect(not_nan_mask_b, op(a, b), b),
+                 a);
+  }
+};
+
+/** \internal \returns the min or max of \a a and \a b (coeff-wise)
+    If both \a a and \a b are NaN, NaN is returned.
+    Equivalent to std::fmin(a, b).  */
+template<>
+struct pminmax_impl<PropagateNumbers> {
+  template <typename Packet, typename Op>
+  static EIGEN_DEVICE_FUNC inline Packet run(const Packet& a, const Packet& b, Op op) {
+  Packet not_nan_mask_a = pcmp_eq(a, a);
+  Packet not_nan_mask_b = pcmp_eq(b, b);
+  return pselect(not_nan_mask_a,
+                 pselect(not_nan_mask_b, op(a, b), a),
+                 b);
+  }
+};
+
+
+#ifndef SYCL_DEVICE_ONLY
+#define EIGEN_BINARY_OP_NAN_PROPAGATION(Type, Func) Func
+#else
+#define EIGEN_BINARY_OP_NAN_PROPAGATION(Type, Func) \
+[](const Type& a, const Type& b) { \
+        return Func(a, b);}
+#endif
+
+/** \internal \returns the min of \a a and \a b  (coeff-wise).
+    If \a a or \b b is NaN, the return value is implementation defined. */
+template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
+pmin(const Packet& a, const Packet& b) { return numext::mini(a,b); }
+
+/** \internal \returns the min of \a a and \a b  (coeff-wise).
+    NaNPropagation determines the NaN propagation semantics. */
+template <int NaNPropagation, typename Packet>
+EIGEN_DEVICE_FUNC inline Packet pmin(const Packet& a, const Packet& b) {
+  return pminmax_impl<NaNPropagation>::run(a, b, EIGEN_BINARY_OP_NAN_PROPAGATION(Packet, (pmin<Packet>)));
+}
+
+/** \internal \returns the max of \a a and \a b  (coeff-wise)
+    If \a a or \b b is NaN, the return value is implementation defined. */
 template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
 pmax(const Packet& a, const Packet& b) { return numext::maxi(a, b); }
 
+/** \internal \returns the max of \a a and \a b  (coeff-wise).
+    NaNPropagation determines the NaN propagation semantics. */
+template <int NaNPropagation, typename Packet>
+EIGEN_DEVICE_FUNC inline Packet pmax(const Packet& a, const Packet& b) {
+  return pminmax_impl<NaNPropagation>::run(a, b, EIGEN_BINARY_OP_NAN_PROPAGATION(Packet,(pmax<Packet>)));
+}
+
 /** \internal \returns the absolute value of \a a */
 template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
-pabs(const Packet& a) { using std::abs; return abs(a); }
+pabs(const Packet& a) { return numext::abs(a); }
 template<> EIGEN_DEVICE_FUNC inline unsigned int
 pabs(const unsigned int& a) { return a; }
 template<> EIGEN_DEVICE_FUNC inline unsigned long
 pabs(const unsigned long& a) { return a; }
 template<> EIGEN_DEVICE_FUNC inline unsigned long long
 pabs(const unsigned long long& a) { return a; }
 
+/** \internal \returns the addsub value of \a a,b */
+template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
+paddsub(const Packet& a, const Packet& b) {
+  return pselect(peven_mask(a), padd(a, b), psub(a, b));
+ }
+
 /** \internal \returns the phase angle of \a a */
 template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
 parg(const Packet& a) { using numext::arg; return arg(a); }
 
 
 /** \internal \returns \a a logically shifted by N bits to the right */
 template<int N> EIGEN_DEVICE_FUNC inline int
@@ -258,105 +571,27 @@
 
 /** \internal \returns the significant and exponent of the underlying floating point numbers
   * See https://en.cppreference.com/w/cpp/numeric/math/frexp
   */
 template <typename Packet>
 EIGEN_DEVICE_FUNC inline Packet pfrexp(const Packet& a, Packet& exponent) {
   int exp;
-  EIGEN_USING_STD_MATH(frexp);
-  Packet result = frexp(a, &exp);
+  EIGEN_USING_STD(frexp);
+  Packet result = static_cast<Packet>(frexp(a, &exp));
   exponent = static_cast<Packet>(exp);
   return result;
 }
 
-/** \internal \returns a * 2^exponent
+/** \internal \returns a * 2^((int)exponent)
   * See https://en.cppreference.com/w/cpp/numeric/math/ldexp
   */
 template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
 pldexp(const Packet &a, const Packet &exponent) {
-  EIGEN_USING_STD_MATH(ldexp);
-  return ldexp(a, static_cast<int>(exponent));
-}
-
-/** \internal \returns zero bits */
-template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
-pzero(const Packet& /*a*/) { Packet b; memset((void*)&b, 0, sizeof(b)); return b;}
-
-template<> EIGEN_DEVICE_FUNC inline float pzero<float>(const float& a) {
-  EIGEN_UNUSED_VARIABLE(a);
-  return 0.f;
-}
-
-template<> EIGEN_DEVICE_FUNC inline double pzero<double>(const double& a) {
-  EIGEN_UNUSED_VARIABLE(a);
-  return 0.;
-}
-
-/** \internal \returns one bits */
-template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
-ptrue(const Packet& /*a*/) { Packet b; memset((void*)&b, 0xff, sizeof(b)); return b;}
-
-template <typename RealScalar>
-EIGEN_DEVICE_FUNC inline std::complex<RealScalar> ptrue(const std::complex<RealScalar>& /*a*/) {
-  RealScalar b;
-  b = ptrue(b);
-  return std::complex<RealScalar>(b, b);
-}
-
-/** \internal \returns the bitwise and of \a a and \a b */
-template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
-pand(const Packet& a, const Packet& b) { return a & b; }
-
-/** \internal \returns the bitwise or of \a a and \a b */
-template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
-por(const Packet& a, const Packet& b) { return a | b; }
-
-/** \internal \returns the bitwise xor of \a a and \a b */
-template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
-pxor(const Packet& a, const Packet& b) { return a ^ b; }
-
-/** \internal \returns the bitwise and of \a a and not \a b */
-template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
-pandnot(const Packet& a, const Packet& b) { return pand(a, pxor(ptrue(b), b)); }
-
-/** \internal \returns a <= b as a bit mask */
-template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
-pcmp_le(const Packet& a, const Packet& b)  { return a<=b ? ptrue(a) : pzero(a); }
-
-/** \internal \returns a < b as a bit mask */
-template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
-pcmp_lt(const Packet& a, const Packet& b)  { return a<b ? ptrue(a) : pzero(a); }
-
-/** \internal \returns a == b as a bit mask */
-template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
-pcmp_eq(const Packet& a, const Packet& b) { return a==b ? ptrue(a) : pzero(a); }
-
-/** \internal \returns a < b or a==NaN or b==NaN as a bit mask */
-template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
-pcmp_lt_or_nan(const Packet& a, const Packet& b) { return a>=b ? pzero(a) : ptrue(a); }
-
-/** \internal \returns \a or \b for each field in packet according to \mask */
-template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
-pselect(const Packet& mask, const Packet& a, const Packet& b) {
-  return por(pand(a,mask),pandnot(b,mask));
-}
-
-template<> EIGEN_DEVICE_FUNC inline float pselect<float>(
-    const float& cond, const float& a, const float&b) {
-  return numext::equal_strict(cond,0.f) ? b : a;
-}
-
-template<> EIGEN_DEVICE_FUNC inline double pselect<double>(
-    const double& cond, const double& a, const double& b) {
-  return numext::equal_strict(cond,0.) ? b : a;
-}
-
-template<> EIGEN_DEVICE_FUNC inline bool pselect<bool>(
-    const bool& cond, const bool& a, const bool& b) {
-  return cond ? a : b;
+  EIGEN_USING_STD(ldexp)
+  return static_cast<Packet>(ldexp(a, static_cast<int>(exponent)));
 }
 
 /** \internal \returns the min of \a a and \a b  (coeff-wise) */
 template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
 pabsdiff(const Packet& a, const Packet& b) { return pselect(pcmp_lt(a, b), psub(b, a), psub(a, b)); }
 
 /** \internal \returns a packet version of \a *from, from must be 16 bytes aligned */
@@ -439,14 +674,28 @@
   a1 = pload1<Packet>(a+1);
 }
 
 /** \internal \brief Returns a packet with coefficients (a,a+1,...,a+packet_size-1). */
 template<typename Packet> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet
 plset(const typename unpacket_traits<Packet>::type& a) { return a; }
 
+/** \internal \returns a packet with constant coefficients \a a, e.g.: (x, 0, x, 0),
+     where x is the value of all 1-bits. */
+template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
+peven_mask(const Packet& /*a*/) {
+  typedef typename unpacket_traits<Packet>::type Scalar;
+  const size_t n = unpacket_traits<Packet>::size;
+  EIGEN_ALIGN_TO_BOUNDARY(sizeof(Packet)) Scalar elements[n];
+  for(size_t i = 0; i < n; ++i) {
+    memset(elements+i, ((i & 1) == 0 ? 0xff : 0), sizeof(Scalar));
+  }
+  return ploadu<Packet>(elements);
+}
+
+
 /** \internal copy the packet \a from to \a *to, \a to must be 16 bytes aligned */
 template<typename Scalar, typename Packet> EIGEN_DEVICE_FUNC inline void pstore(Scalar* to, const Packet& from)
 { (*to) = from; }
 
 /** \internal copy the packet \a from to \a *to, (un-aligned store) */
 template<typename Scalar, typename Packet> EIGEN_DEVICE_FUNC inline void pstoreu(Scalar* to, const Packet& from)
 {  (*to) = from; }
@@ -468,77 +717,26 @@
 
 /** \internal tries to do cache prefetching of \a addr */
 template<typename Scalar> EIGEN_DEVICE_FUNC inline void prefetch(const Scalar* addr)
 {
 #if defined(EIGEN_HIP_DEVICE_COMPILE)
   // do nothing
 #elif defined(EIGEN_CUDA_ARCH)
-#if defined(__LP64__)
+#if defined(__LP64__) || EIGEN_OS_WIN64
   // 64-bit pointer operand constraint for inlined asm
   asm(" prefetch.L1 [ %1 ];" : "=l"(addr) : "l"(addr));
 #else
   // 32-bit pointer operand constraint for inlined asm
   asm(" prefetch.L1 [ %1 ];" : "=r"(addr) : "r"(addr));
 #endif
 #elif (!EIGEN_COMP_MSVC) && (EIGEN_COMP_GNUC || EIGEN_COMP_CLANG || EIGEN_COMP_ICC)
   __builtin_prefetch(addr);
 #endif
 }
 
-/** \internal \returns the first element of a packet */
-template<typename Packet> EIGEN_DEVICE_FUNC inline typename unpacket_traits<Packet>::type pfirst(const Packet& a)
-{ return a; }
-
-/** \internal \returns the sum of the elements of \a a*/
-template<typename Packet> EIGEN_DEVICE_FUNC inline typename unpacket_traits<Packet>::type predux(const Packet& a)
-{ return a; }
-
-/** \internal \returns the sum of the elements of upper and lower half of \a a if \a a is larger than 4.
-  * For a packet {a0, a1, a2, a3, a4, a5, a6, a7}, it returns a half packet {a0+a4, a1+a5, a2+a6, a3+a7}
-  * For packet-size smaller or equal to 4, this boils down to a noop.
-  */
-template<typename Packet> EIGEN_DEVICE_FUNC inline
-typename conditional<(unpacket_traits<Packet>::size%8)==0,typename unpacket_traits<Packet>::half,Packet>::type
-predux_half_dowto4(const Packet& a)
-{ return a; }
-
-/** \internal \returns the product of the elements of \a a */
-template<typename Packet> EIGEN_DEVICE_FUNC inline typename unpacket_traits<Packet>::type predux_mul(const Packet& a)
-{ return a; }
-
-/** \internal \returns the min of the elements of \a a */
-template<typename Packet> EIGEN_DEVICE_FUNC inline typename unpacket_traits<Packet>::type predux_min(const Packet& a)
-{ return a; }
-
-/** \internal \returns the max of the elements of \a a */
-template<typename Packet> EIGEN_DEVICE_FUNC inline typename unpacket_traits<Packet>::type predux_max(const Packet& a)
-{ return a; }
-
-/** \internal \returns true if all coeffs of \a a means "true"
-  * It is supposed to be called on values returned by pcmp_*.
-  */
-// not needed yet
-// template<typename Packet> EIGEN_DEVICE_FUNC inline bool predux_all(const Packet& a)
-// { return bool(a); }
-
-/** \internal \returns true if any coeffs of \a a means "true"
-  * It is supposed to be called on values returned by pcmp_*.
-  */
-template<typename Packet> EIGEN_DEVICE_FUNC inline bool predux_any(const Packet& a)
-{
-  // Dirty but generic implementation where "true" is assumed to be non 0 and all the sames.
-  // It is expected that "true" is either:
-  //  - Scalar(1)
-  //  - bits full of ones (NaN for floats),
-  //  - or first bit equals to 1 (1 for ints, smallest denormal for floats).
-  // For all these cases, taking the sum is just fine, and this boils down to a no-op for scalars.
-  typedef typename unpacket_traits<Packet>::type Scalar;
-  return numext::not_equal_strict(predux(a), Scalar(0));
-}
-
 /** \internal \returns the reversed elements of \a a*/
 template<typename Packet> EIGEN_DEVICE_FUNC inline Packet preverse(const Packet& a)
 { return a; }
 
 /** \internal \returns \a a with real and imaginary part flipped (for complex type only) */
 template<typename Packet> EIGEN_DEVICE_FUNC inline Packet pcplxflip(const Packet& a)
 {
@@ -547,76 +745,84 @@
 
 /**************************
 * Special math functions
 ***************************/
 
 /** \internal \returns the sine of \a a (coeff-wise) */
 template<typename Packet> EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
-Packet psin(const Packet& a) { EIGEN_USING_STD_MATH(sin); return sin(a); }
+Packet psin(const Packet& a) { EIGEN_USING_STD(sin); return sin(a); }
 
 /** \internal \returns the cosine of \a a (coeff-wise) */
 template<typename Packet> EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
-Packet pcos(const Packet& a) { EIGEN_USING_STD_MATH(cos); return cos(a); }
+Packet pcos(const Packet& a) { EIGEN_USING_STD(cos); return cos(a); }
 
 /** \internal \returns the tan of \a a (coeff-wise) */
 template<typename Packet> EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
-Packet ptan(const Packet& a) { EIGEN_USING_STD_MATH(tan); return tan(a); }
+Packet ptan(const Packet& a) { EIGEN_USING_STD(tan); return tan(a); }
 
 /** \internal \returns the arc sine of \a a (coeff-wise) */
 template<typename Packet> EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
-Packet pasin(const Packet& a) { EIGEN_USING_STD_MATH(asin); return asin(a); }
+Packet pasin(const Packet& a) { EIGEN_USING_STD(asin); return asin(a); }
 
 /** \internal \returns the arc cosine of \a a (coeff-wise) */
 template<typename Packet> EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
-Packet pacos(const Packet& a) { EIGEN_USING_STD_MATH(acos); return acos(a); }
+Packet pacos(const Packet& a) { EIGEN_USING_STD(acos); return acos(a); }
 
 /** \internal \returns the arc tangent of \a a (coeff-wise) */
 template<typename Packet> EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
-Packet patan(const Packet& a) { EIGEN_USING_STD_MATH(atan); return atan(a); }
+Packet patan(const Packet& a) { EIGEN_USING_STD(atan); return atan(a); }
 
 /** \internal \returns the hyperbolic sine of \a a (coeff-wise) */
 template<typename Packet> EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
-Packet psinh(const Packet& a) { EIGEN_USING_STD_MATH(sinh); return sinh(a); }
+Packet psinh(const Packet& a) { EIGEN_USING_STD(sinh); return sinh(a); }
 
 /** \internal \returns the hyperbolic cosine of \a a (coeff-wise) */
 template<typename Packet> EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
-Packet pcosh(const Packet& a) { EIGEN_USING_STD_MATH(cosh); return cosh(a); }
+Packet pcosh(const Packet& a) { EIGEN_USING_STD(cosh); return cosh(a); }
 
 /** \internal \returns the hyperbolic tan of \a a (coeff-wise) */
 template<typename Packet> EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
-Packet ptanh(const Packet& a) { EIGEN_USING_STD_MATH(tanh); return tanh(a); }
+Packet ptanh(const Packet& a) { EIGEN_USING_STD(tanh); return tanh(a); }
 
 /** \internal \returns the exp of \a a (coeff-wise) */
 template<typename Packet> EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
-Packet pexp(const Packet& a) { EIGEN_USING_STD_MATH(exp); return exp(a); }
+Packet pexp(const Packet& a) { EIGEN_USING_STD(exp); return exp(a); }
 
 /** \internal \returns the expm1 of \a a (coeff-wise) */
 template<typename Packet> EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
 Packet pexpm1(const Packet& a) { return numext::expm1(a); }
 
 /** \internal \returns the log of \a a (coeff-wise) */
 template<typename Packet> EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
-Packet plog(const Packet& a) { EIGEN_USING_STD_MATH(log); return log(a); }
+Packet plog(const Packet& a) { EIGEN_USING_STD(log); return log(a); }
 
 /** \internal \returns the log1p of \a a (coeff-wise) */
 template<typename Packet> EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
 Packet plog1p(const Packet& a) { return numext::log1p(a); }
 
 /** \internal \returns the log10 of \a a (coeff-wise) */
 template<typename Packet> EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
-Packet plog10(const Packet& a) { EIGEN_USING_STD_MATH(log10); return log10(a); }
+Packet plog10(const Packet& a) { EIGEN_USING_STD(log10); return log10(a); }
+
+/** \internal \returns the log10 of \a a (coeff-wise) */
+template<typename Packet> EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
+Packet plog2(const Packet& a) {
+  typedef typename internal::unpacket_traits<Packet>::type Scalar;
+  return pmul(pset1<Packet>(Scalar(EIGEN_LOG2E)), plog(a)); 
+}
 
 /** \internal \returns the square-root of \a a (coeff-wise) */
 template<typename Packet> EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
-Packet psqrt(const Packet& a) { EIGEN_USING_STD_MATH(sqrt); return sqrt(a); }
+Packet psqrt(const Packet& a) { return numext::sqrt(a); }
 
 /** \internal \returns the reciprocal square-root of \a a (coeff-wise) */
 template<typename Packet> EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
 Packet prsqrt(const Packet& a) {
-  return pdiv(pset1<Packet>(1), psqrt(a));
+  typedef typename internal::unpacket_traits<Packet>::type Scalar;
+  return pdiv(pset1<Packet>(Scalar(1)), psqrt(a));
 }
 
 /** \internal \returns the rounded value of \a a (coeff-wise) */
 template<typename Packet> EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
 Packet pround(const Packet& a) { using numext::round; return round(a); }
 
 /** \internal \returns the floor of \a a (coeff-wise) */
@@ -628,14 +834,115 @@
 template<typename Packet> EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
 Packet print(const Packet& a) { using numext::rint; return rint(a); }
 
 /** \internal \returns the ceil of \a a (coeff-wise) */
 template<typename Packet> EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
 Packet pceil(const Packet& a) { using numext::ceil; return ceil(a); }
 
+/** \internal \returns the first element of a packet */
+template<typename Packet>
+EIGEN_DEVICE_FUNC inline typename unpacket_traits<Packet>::type
+pfirst(const Packet& a)
+{ return a; }
+
+/** \internal \returns the sum of the elements of upper and lower half of \a a if \a a is larger than 4.
+  * For a packet {a0, a1, a2, a3, a4, a5, a6, a7}, it returns a half packet {a0+a4, a1+a5, a2+a6, a3+a7}
+  * For packet-size smaller or equal to 4, this boils down to a noop.
+  */
+template<typename Packet>
+EIGEN_DEVICE_FUNC inline typename conditional<(unpacket_traits<Packet>::size%8)==0,typename unpacket_traits<Packet>::half,Packet>::type
+predux_half_dowto4(const Packet& a)
+{ return a; }
+
+// Slow generic implementation of Packet reduction.
+template <typename Packet, typename Op>
+EIGEN_DEVICE_FUNC inline typename unpacket_traits<Packet>::type
+predux_helper(const Packet& a, Op op) {
+  typedef typename unpacket_traits<Packet>::type Scalar;
+  const size_t n = unpacket_traits<Packet>::size;
+  EIGEN_ALIGN_TO_BOUNDARY(sizeof(Packet)) Scalar elements[n];
+  pstoreu<Scalar>(elements, a);
+  for(size_t k = n / 2; k > 0; k /= 2)  {
+    for(size_t i = 0; i < k; ++i) {
+      elements[i] = op(elements[i], elements[i + k]);
+    }
+  }
+  return elements[0];
+}
+
+/** \internal \returns the sum of the elements of \a a*/
+template<typename Packet>
+EIGEN_DEVICE_FUNC inline typename unpacket_traits<Packet>::type
+predux(const Packet& a)
+{
+  return a;
+}
+
+/** \internal \returns the product of the elements of \a a */
+template <typename Packet>
+EIGEN_DEVICE_FUNC inline typename unpacket_traits<Packet>::type predux_mul(
+    const Packet& a) {
+  typedef typename unpacket_traits<Packet>::type Scalar; 
+  return predux_helper(a, EIGEN_BINARY_OP_NAN_PROPAGATION(Scalar, (pmul<Scalar>)));
+}
+
+/** \internal \returns the min of the elements of \a a */
+template <typename Packet>
+EIGEN_DEVICE_FUNC inline typename unpacket_traits<Packet>::type predux_min(
+    const Packet &a) {
+  typedef typename unpacket_traits<Packet>::type Scalar; 
+  return predux_helper(a, EIGEN_BINARY_OP_NAN_PROPAGATION(Scalar, (pmin<PropagateFast, Scalar>)));
+}
+
+template <int NaNPropagation, typename Packet>
+EIGEN_DEVICE_FUNC inline typename unpacket_traits<Packet>::type predux_min(
+    const Packet& a) {
+  typedef typename unpacket_traits<Packet>::type Scalar; 
+  return predux_helper(a, EIGEN_BINARY_OP_NAN_PROPAGATION(Scalar, (pmin<NaNPropagation, Scalar>)));
+}
+
+/** \internal \returns the min of the elements of \a a */
+template <typename Packet>
+EIGEN_DEVICE_FUNC inline typename unpacket_traits<Packet>::type predux_max(
+    const Packet &a) {
+  typedef typename unpacket_traits<Packet>::type Scalar; 
+  return predux_helper(a, EIGEN_BINARY_OP_NAN_PROPAGATION(Scalar, (pmax<PropagateFast, Scalar>)));
+}
+
+template <int NaNPropagation, typename Packet>
+EIGEN_DEVICE_FUNC inline typename unpacket_traits<Packet>::type predux_max(
+    const Packet& a) {
+  typedef typename unpacket_traits<Packet>::type Scalar; 
+  return predux_helper(a, EIGEN_BINARY_OP_NAN_PROPAGATION(Scalar, (pmax<NaNPropagation, Scalar>)));
+}
+
+#undef EIGEN_BINARY_OP_NAN_PROPAGATION
+
+/** \internal \returns true if all coeffs of \a a means "true"
+  * It is supposed to be called on values returned by pcmp_*.
+  */
+// not needed yet
+// template<typename Packet> EIGEN_DEVICE_FUNC inline bool predux_all(const Packet& a)
+// { return bool(a); }
+
+/** \internal \returns true if any coeffs of \a a means "true"
+  * It is supposed to be called on values returned by pcmp_*.
+  */
+template<typename Packet> EIGEN_DEVICE_FUNC inline bool predux_any(const Packet& a)
+{
+  // Dirty but generic implementation where "true" is assumed to be non 0 and all the sames.
+  // It is expected that "true" is either:
+  //  - Scalar(1)
+  //  - bits full of ones (NaN for floats),
+  //  - or first bit equals to 1 (1 for ints, smallest denormal for floats).
+  // For all these cases, taking the sum is just fine, and this boils down to a no-op for scalars.
+  typedef typename unpacket_traits<Packet>::type Scalar;
+  return numext::not_equal_strict(predux(a), Scalar(0));
+}
+
 /***************************************************************************
 * The following functions might not have to be overwritten for vectorized types
 ***************************************************************************/
 
 /** \internal copy a packet with constant coefficient \a a (e.g., [a,a,a,a]) to \a *to. \a to must be 16 bytes aligned */
 // NOTE: this function must really be templated on the packet type (think about different packet types for the same scalar type)
 template<typename Packet>
@@ -722,28 +1029,12 @@
 };
 
 template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
 pblend(const Selector<unpacket_traits<Packet>::size>& ifPacket, const Packet& thenPacket, const Packet& elsePacket) {
   return ifPacket.select[0] ? thenPacket : elsePacket;
 }
 
-/***************************************************************************
- * Some generic implementations to be used by implementors
-***************************************************************************/
-
-/** Default implementation of pfrexp for float.
-  * It is expected to be called by implementers of template<> pfrexp.
-  */
-template<typename Packet> EIGEN_STRONG_INLINE Packet
-pfrexp_float(const Packet& a, Packet& exponent);
-
-/** Default implementation of pldexp for float.
-  * It is expected to be called by implementers of template<> pldexp.
-  */
-template<typename Packet> EIGEN_STRONG_INLINE Packet
-pldexp_float(Packet a, Packet exponent);
-
 } // end namespace internal
 
 } // end namespace Eigen
 
 #endif // EIGEN_GENERIC_PACKET_MATH_H
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/GlobalFunctions.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/GlobalFunctions.h`

 * *Files 1% similar despite different names*

```diff
@@ -77,18 +77,19 @@
   EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(erf,scalar_erf_op,error function,\sa ArrayBase::erf)
   EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(erfc,scalar_erfc_op,complement error function,\sa ArrayBase::erfc)
   EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(ndtri,scalar_ndtri_op,inverse normal distribution function,\sa ArrayBase::ndtri)
   EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(exp,scalar_exp_op,exponential,\sa ArrayBase::exp)
   EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(expm1,scalar_expm1_op,exponential of a value minus 1,\sa ArrayBase::expm1)
   EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(log,scalar_log_op,natural logarithm,\sa Eigen::log10 DOXCOMMA ArrayBase::log)
   EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(log1p,scalar_log1p_op,natural logarithm of 1 plus the value,\sa ArrayBase::log1p)
-  EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(log10,scalar_log10_op,base 10 logarithm,\sa Eigen::log DOXCOMMA ArrayBase::log)
+  EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(log10,scalar_log10_op,base 10 logarithm,\sa Eigen::log DOXCOMMA ArrayBase::log10)
+  EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(log2,scalar_log2_op,base 2 logarithm,\sa Eigen::log DOXCOMMA ArrayBase::log2)
   EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(abs,scalar_abs_op,absolute value,\sa ArrayBase::abs DOXCOMMA MatrixBase::cwiseAbs)
   EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(abs2,scalar_abs2_op,squared absolute value,\sa ArrayBase::abs2 DOXCOMMA MatrixBase::cwiseAbs2)
-  EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(arg,scalar_arg_op,complex argument,\sa ArrayBase::arg)
+  EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(arg,scalar_arg_op,complex argument,\sa ArrayBase::arg DOXCOMMA MatrixBase::cwiseArg)
   EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(sqrt,scalar_sqrt_op,square root,\sa ArrayBase::sqrt DOXCOMMA MatrixBase::cwiseSqrt)
   EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(rsqrt,scalar_rsqrt_op,reciprocal square root,\sa ArrayBase::rsqrt)
   EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(square,scalar_square_op,square (power 2),\sa Eigen::abs2 DOXCOMMA Eigen::pow DOXCOMMA ArrayBase::square)
   EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(cube,scalar_cube_op,cube (power 3),\sa Eigen::pow DOXCOMMA ArrayBase::cube)
   EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(rint,scalar_rint_op,nearest integer,\sa Eigen::floor DOXCOMMA Eigen::ceil DOXCOMMA ArrayBase::round)
   EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(round,scalar_round_op,nearest integer,\sa Eigen::floor DOXCOMMA Eigen::ceil DOXCOMMA ArrayBase::round)
   EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(floor,scalar_floor_op,nearest integer not greater than the giben value,\sa Eigen::ceil DOXCOMMA ArrayBase::floor)
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/IO.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/IO.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/IndexedView.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/IndexedView.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Inverse.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Inverse.h`

 * *Files 4% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_INVERSE_H
 #define EIGEN_INVERSE_H
 
-namespace Eigen { 
+namespace Eigen {
 
 template<typename XprType,typename StorageKind> class InverseImpl;
 
 namespace internal {
 
 template<typename XprType>
 struct traits<Inverse<XprType> >
@@ -45,21 +45,21 @@
 public:
   typedef typename XprType::StorageIndex StorageIndex;
   typedef typename XprType::Scalar                            Scalar;
   typedef typename internal::ref_selector<XprType>::type      XprTypeNested;
   typedef typename internal::remove_all<XprTypeNested>::type  XprTypeNestedCleaned;
   typedef typename internal::ref_selector<Inverse>::type Nested;
   typedef typename internal::remove_all<XprType>::type NestedExpression;
-  
+
   explicit EIGEN_DEVICE_FUNC Inverse(const XprType &xpr)
     : m_xpr(xpr)
   {}
 
-  EIGEN_DEVICE_FUNC Index rows() const { return m_xpr.cols(); }
-  EIGEN_DEVICE_FUNC Index cols() const { return m_xpr.rows(); }
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR  Index rows() const EIGEN_NOEXCEPT { return m_xpr.cols(); }
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR  Index cols() const EIGEN_NOEXCEPT { return m_xpr.rows(); }
 
   EIGEN_DEVICE_FUNC const XprTypeNestedCleaned& nestedExpression() const { return m_xpr; }
 
 protected:
   XprTypeNested m_xpr;
 };
 
@@ -77,41 +77,41 @@
   Scalar coeff(Index i) const;
 };
 
 namespace internal {
 
 /** \internal
   * \brief Default evaluator for Inverse expression.
-  * 
+  *
   * This default evaluator for Inverse expression simply evaluate the inverse into a temporary
   * by a call to internal::call_assignment_no_alias.
   * Therefore, inverse implementers only have to specialize Assignment<Dst,Inverse<...>, ...> for
   * there own nested expression.
   *
   * \sa class Inverse
   */
 template<typename ArgType>
 struct unary_evaluator<Inverse<ArgType> >
   : public evaluator<typename Inverse<ArgType>::PlainObject>
 {
   typedef Inverse<ArgType> InverseType;
   typedef typename InverseType::PlainObject PlainObject;
   typedef evaluator<PlainObject> Base;
-  
+
   enum { Flags = Base::Flags | EvalBeforeNestingBit };
 
   unary_evaluator(const InverseType& inv_xpr)
     : m_result(inv_xpr.rows(), inv_xpr.cols())
   {
     ::new (static_cast<Base*>(this)) Base(m_result);
     internal::call_assignment_no_alias(m_result, inv_xpr);
   }
-  
+
 protected:
   PlainObject m_result;
 };
-  
+
 } // end namespace internal
 
 } // end namespace Eigen
 
 #endif // EIGEN_INVERSE_H
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Map.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Map.h`

 * *Files 2% similar despite different names*

```diff
@@ -7,15 +7,15 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_MAP_H
 #define EIGEN_MAP_H
 
-namespace Eigen { 
+namespace Eigen {
 
 namespace internal {
 template<typename PlainObjectType, int MapOptions, typename StrideType>
 struct traits<Map<PlainObjectType, MapOptions, StrideType> >
   : public traits<PlainObjectType>
 {
   typedef traits<PlainObjectType> TraitsBase;
@@ -43,15 +43,15 @@
 
 /** \class Map
   * \ingroup Core_Module
   *
   * \brief A matrix or vector expression mapping an existing array of data.
   *
   * \tparam PlainObjectType the equivalent matrix type of the mapped data
-  * \tparam MapOptions specifies the pointer alignment in bytes. It can be: \c #Aligned128, , \c #Aligned64, \c #Aligned32, \c #Aligned16, \c #Aligned8 or \c #Unaligned.
+  * \tparam MapOptions specifies the pointer alignment in bytes. It can be: \c #Aligned128, \c #Aligned64, \c #Aligned32, \c #Aligned16, \c #Aligned8 or \c #Unaligned.
   *                The default is \c #Unaligned.
   * \tparam StrideType optionally specifies strides. By default, Map assumes the memory layout
   *                   of an ordinary, contiguous array. This can be overridden by specifying strides.
   *                   The type passed here must be a specialization of the Stride template, see examples below.
   *
   * This class represents a matrix or vector expression mapping an existing array of data.
   * It can be used to let Eigen interface without any overhead with non-Eigen data structures,
@@ -100,21 +100,21 @@
     EIGEN_DENSE_PUBLIC_INTERFACE(Map)
 
     typedef typename Base::PointerType PointerType;
     typedef PointerType PointerArgType;
     EIGEN_DEVICE_FUNC
     inline PointerType cast_to_pointer_type(PointerArgType ptr) { return ptr; }
 
-    EIGEN_DEVICE_FUNC
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
     inline Index innerStride() const
     {
       return StrideType::InnerStrideAtCompileTime != 0 ? m_stride.inner() : 1;
     }
 
-    EIGEN_DEVICE_FUNC
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
     inline Index outerStride() const
     {
       return StrideType::OuterStrideAtCompileTime != 0 ? m_stride.outer()
            : internal::traits<Map>::OuterStrideAtCompileTime != Dynamic ? Index(internal::traits<Map>::OuterStrideAtCompileTime)
            : IsVectorAtCompileTime ? (this->size() * innerStride())
            : int(Flags)&RowMajorBit ? (this->cols() * innerStride())
            : (this->rows() * innerStride());
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/MapBase.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/MapBase.h`

 * *Files 1% similar despite different names*

```diff
@@ -11,15 +11,15 @@
 #ifndef EIGEN_MAPBASE_H
 #define EIGEN_MAPBASE_H
 
 #define EIGEN_STATIC_ASSERT_INDEX_BASED_ACCESS(Derived) \
       EIGEN_STATIC_ASSERT((int(internal::evaluator<Derived>::Flags) & LinearAccessBit) || Derived::IsVectorAtCompileTime, \
                           YOU_ARE_TRYING_TO_USE_AN_INDEX_BASED_ACCESSOR_ON_AN_EXPRESSION_THAT_DOES_NOT_SUPPORT_THAT)
 
-namespace Eigen { 
+namespace Eigen {
 
 /** \ingroup Core_Module
   *
   * \brief Base class for dense Map and Block expression with direct access
   *
   * This base class provides the const low-level accessors (e.g. coeff, coeffRef) of dense
   * Map and Block objects with direct access.
@@ -83,17 +83,19 @@
 
     // bug 217 - compile error on ICC 11.1
     using Base::operator=;
 
     typedef typename Base::CoeffReturnType CoeffReturnType;
 
     /** \copydoc DenseBase::rows() */
-    EIGEN_DEVICE_FUNC inline Index rows() const { return m_rows.value(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index rows() const EIGEN_NOEXCEPT { return m_rows.value(); }
     /** \copydoc DenseBase::cols() */
-    EIGEN_DEVICE_FUNC inline Index cols() const { return m_cols.value(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index cols() const EIGEN_NOEXCEPT { return m_cols.value(); }
 
     /** Returns a pointer to the first coefficient of the matrix or vector.
       *
       * \note When addressing this data, make sure to honor the strides returned by innerStride() and outerStride().
       *
       * \sa innerStride(), outerStride()
       */
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/MathFunctions.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/MathFunctions.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,22 +1,25 @@
 // This file is part of Eigen, a lightweight C++ template library
 // for linear algebra.
 //
 // Copyright (C) 2006-2010 Benoit Jacob <jacob.benoit.1@gmail.com>
+// Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
 //
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_MATHFUNCTIONS_H
 #define EIGEN_MATHFUNCTIONS_H
 
-// source: http://www.geom.uiuc.edu/~huberty/math5337/groupe/digits.html
 // TODO this should better be moved to NumTraits
-#define EIGEN_PI 3.141592653589793238462643383279502884197169399375105820974944592307816406L
+// Source: WolframAlpha
+#define EIGEN_PI    3.141592653589793238462643383279502884197169399375105820974944592307816406L
+#define EIGEN_LOG2E 1.442695040888963407359924681001892137426645954152985934135449406931109219L
+#define EIGEN_LN2   0.693147180559945309417232121458176568075500134360255254120680009493393621L
 
 namespace Eigen {
 
 // On WINCE, std::abs is defined for int only, so let's defined our own overloads:
 // This issue has been confirmed with MSVC 2008 only, but the issue might exist for more recent versions too.
 #if EIGEN_OS_WINCE && EIGEN_COMP_MSVC && EIGEN_COMP_MSVC<=1500
 long        abs(long        x) { return (labs(x));  }
@@ -208,20 +211,20 @@
     return reinterpret_cast<RealScalar*>(&x)[1];
   }
 };
 
 template<typename Scalar>
 struct imag_ref_default_impl<Scalar, false>
 {
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static inline Scalar run(Scalar&)
   {
     return Scalar(0);
   }
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static inline const Scalar run(const Scalar&)
   {
     return Scalar(0);
   }
 };
 
 template<typename Scalar>
@@ -254,27 +257,16 @@
   static inline Scalar run(const Scalar& x)
   {
     using std::conj;
     return conj(x);
   }
 };
 
-template<typename Scalar> struct conj_impl : conj_default_impl<Scalar> {};
-
-#if defined(EIGEN_GPU_COMPILE_PHASE)
-template<typename T>
-struct conj_impl<std::complex<T> >
-{
-  EIGEN_DEVICE_FUNC
-  static inline std::complex<T> run(const std::complex<T>& x)
-  {
-    return std::complex<T>(x.real(), -x.imag());
-  }
-};
-#endif
+template<typename Scalar, bool IsComplex = NumTraits<Scalar>::IsComplex>
+struct conj_impl : conj_default_impl<Scalar, IsComplex> {};
 
 template<typename Scalar>
 struct conj_retval
 {
   typedef Scalar type;
 };
 
@@ -318,39 +310,98 @@
 template<typename Scalar>
 struct abs2_retval
 {
   typedef typename NumTraits<Scalar>::Real type;
 };
 
 /****************************************************************************
+* Implementation of sqrt/rsqrt                                             *
+****************************************************************************/
+
+template<typename Scalar>
+struct sqrt_impl
+{
+  EIGEN_DEVICE_FUNC
+  static EIGEN_ALWAYS_INLINE Scalar run(const Scalar& x)
+  {
+    EIGEN_USING_STD(sqrt);
+    return sqrt(x);
+  }
+};
+
+// Complex sqrt defined in MathFunctionsImpl.h.
+template<typename T> EIGEN_DEVICE_FUNC std::complex<T> complex_sqrt(const std::complex<T>& a_x);
+
+// Custom implementation is faster than `std::sqrt`, works on
+// GPU, and correctly handles special cases (unlike MSVC).
+template<typename T>
+struct sqrt_impl<std::complex<T> >
+{
+  EIGEN_DEVICE_FUNC
+  static EIGEN_ALWAYS_INLINE std::complex<T> run(const std::complex<T>& x)
+  {
+    return complex_sqrt<T>(x);
+  }
+};
+
+template<typename Scalar>
+struct sqrt_retval
+{
+  typedef Scalar type;
+};
+
+// Default implementation relies on numext::sqrt, at bottom of file.
+template<typename T>
+struct rsqrt_impl;
+
+// Complex rsqrt defined in MathFunctionsImpl.h.
+template<typename T> EIGEN_DEVICE_FUNC std::complex<T> complex_rsqrt(const std::complex<T>& a_x);
+
+template<typename T>
+struct rsqrt_impl<std::complex<T> >
+{
+  EIGEN_DEVICE_FUNC
+  static EIGEN_ALWAYS_INLINE std::complex<T> run(const std::complex<T>& x)
+  {
+    return complex_rsqrt<T>(x);
+  }
+};
+
+template<typename Scalar>
+struct rsqrt_retval
+{
+  typedef Scalar type;
+};
+
+/****************************************************************************
 * Implementation of norm1                                                *
 ****************************************************************************/
 
 template<typename Scalar, bool IsComplex>
 struct norm1_default_impl;
 
 template<typename Scalar>
 struct norm1_default_impl<Scalar,true>
 {
   typedef typename NumTraits<Scalar>::Real RealScalar;
   EIGEN_DEVICE_FUNC
   static inline RealScalar run(const Scalar& x)
   {
-    EIGEN_USING_STD_MATH(abs);
+    EIGEN_USING_STD(abs);
     return abs(x.real()) + abs(x.imag());
   }
 };
 
 template<typename Scalar>
 struct norm1_default_impl<Scalar, false>
 {
   EIGEN_DEVICE_FUNC
   static inline Scalar run(const Scalar& x)
   {
-    EIGEN_USING_STD_MATH(abs);
+    EIGEN_USING_STD(abs);
     return abs(x);
   }
 };
 
 template<typename Scalar>
 struct norm1_impl : norm1_default_impl<Scalar, NumTraits<Scalar>::IsComplex> {};
 
@@ -372,62 +423,106 @@
   typedef typename NumTraits<Scalar>::Real type;
 };
 
 /****************************************************************************
 * Implementation of cast                                                 *
 ****************************************************************************/
 
-template<typename OldType, typename NewType>
+template<typename OldType, typename NewType, typename EnableIf = void>
 struct cast_impl
 {
   EIGEN_DEVICE_FUNC
   static inline NewType run(const OldType& x)
   {
     return static_cast<NewType>(x);
   }
 };
 
+// Casting from S -> Complex<T> leads to an implicit conversion from S to T,
+// generating warnings on clang.  Here we explicitly cast the real component.
+template<typename OldType, typename NewType>
+struct cast_impl<OldType, NewType,
+  typename internal::enable_if<
+    !NumTraits<OldType>::IsComplex && NumTraits<NewType>::IsComplex
+  >::type>
+{
+  EIGEN_DEVICE_FUNC
+  static inline NewType run(const OldType& x)
+  {
+    typedef typename NumTraits<NewType>::Real NewReal;
+    return static_cast<NewType>(static_cast<NewReal>(x));
+  }
+};
+
 // here, for once, we're plainly returning NewType: we don't want cast to do weird things.
 
 template<typename OldType, typename NewType>
 EIGEN_DEVICE_FUNC
 inline NewType cast(const OldType& x)
 {
   return cast_impl<OldType, NewType>::run(x);
 }
 
 /****************************************************************************
 * Implementation of round                                                   *
 ****************************************************************************/
 
+template<typename Scalar>
+struct round_impl
+{
+  EIGEN_DEVICE_FUNC
+  static inline Scalar run(const Scalar& x)
+  {
+    EIGEN_STATIC_ASSERT((!NumTraits<Scalar>::IsComplex), NUMERIC_TYPE_MUST_BE_REAL)
 #if EIGEN_HAS_CXX11_MATH
-  template<typename Scalar>
-  struct round_impl {
-    EIGEN_DEVICE_FUNC
-    static inline Scalar run(const Scalar& x)
-    {
-      EIGEN_STATIC_ASSERT((!NumTraits<Scalar>::IsComplex), NUMERIC_TYPE_MUST_BE_REAL)
-      EIGEN_USING_STD_MATH(round);
-      return round(x);
-    }
-  };
+    EIGEN_USING_STD(round);
+#endif
+    return Scalar(round(x));
+  }
+};
+
+#if !EIGEN_HAS_CXX11_MATH
+#if EIGEN_HAS_C99_MATH
+// Use ::roundf for float.
+template<>
+struct round_impl<float> {
+  EIGEN_DEVICE_FUNC
+  static inline float run(const float& x)
+  {
+    return ::roundf(x);
+  }
+};
 #else
-  template<typename Scalar>
-  struct round_impl
+template<typename Scalar>
+struct round_using_floor_ceil_impl
+{
+  EIGEN_DEVICE_FUNC
+  static inline Scalar run(const Scalar& x)
   {
-    EIGEN_DEVICE_FUNC
-    static inline Scalar run(const Scalar& x)
-    {
-      EIGEN_STATIC_ASSERT((!NumTraits<Scalar>::IsComplex), NUMERIC_TYPE_MUST_BE_REAL)
-      EIGEN_USING_STD_MATH(floor);
-      EIGEN_USING_STD_MATH(ceil);
-      return (x > Scalar(0)) ? floor(x + Scalar(0.5)) : ceil(x - Scalar(0.5));
+    EIGEN_STATIC_ASSERT((!NumTraits<Scalar>::IsComplex), NUMERIC_TYPE_MUST_BE_REAL)
+    // Without C99 round/roundf, resort to floor/ceil.
+    EIGEN_USING_STD(floor);
+    EIGEN_USING_STD(ceil);
+    // If not enough precision to resolve a decimal at all, return the input.
+    // Otherwise, adding 0.5 can trigger an increment by 1.
+    const Scalar limit = Scalar(1ull << (NumTraits<Scalar>::digits() - 1));
+    if (x >= limit || x <= -limit) {
+      return x;
     }
-  };
-#endif
+    return (x > Scalar(0)) ? Scalar(floor(x + Scalar(0.5))) : Scalar(ceil(x - Scalar(0.5)));
+  }
+};
+
+template<>
+struct round_impl<float> : round_using_floor_ceil_impl<float> {};
+
+template<>
+struct round_impl<double> : round_using_floor_ceil_impl<double> {};
+#endif // EIGEN_HAS_C99_MATH
+#endif // !EIGEN_HAS_CXX11_MATH
 
 template<typename Scalar>
 struct round_retval
 {
   typedef Scalar type;
 };
 
@@ -438,15 +533,15 @@
 template<typename Scalar>
 struct rint_impl {
   EIGEN_DEVICE_FUNC
   static inline Scalar run(const Scalar& x)
   {
     EIGEN_STATIC_ASSERT((!NumTraits<Scalar>::IsComplex), NUMERIC_TYPE_MUST_BE_REAL)
 #if EIGEN_HAS_CXX11_MATH
-      EIGEN_USING_STD_MATH(rint);
+      EIGEN_USING_STD(rint);
 #endif
     return rint(x);
   }
 };
 
 #if !EIGEN_HAS_CXX11_MATH
 template<>
@@ -473,54 +568,75 @@
   typedef Scalar type;
 };
 
 /****************************************************************************
 * Implementation of arg                                                     *
 ****************************************************************************/
 
-#if EIGEN_HAS_CXX11_MATH
-  template<typename Scalar>
-  struct arg_impl {
-    EIGEN_DEVICE_FUNC
-    static inline Scalar run(const Scalar& x)
-    {
-      #if defined(EIGEN_HIP_DEVICE_COMPILE)
-      // HIP does not seem to have a native device side implementation for the math routine "arg"
-      using std::arg;
-      #else 		  
-      EIGEN_USING_STD_MATH(arg);
-      #endif
-      return arg(x);
-    }
-  };
-#else
-  template<typename Scalar, bool IsComplex = NumTraits<Scalar>::IsComplex>
-  struct arg_default_impl
+// Visual Studio 2017 has a bug where arg(float) returns 0 for negative inputs.
+// This seems to be fixed in VS 2019.
+#if EIGEN_HAS_CXX11_MATH && (!EIGEN_COMP_MSVC || EIGEN_COMP_MSVC >= 1920)
+// std::arg is only defined for types of std::complex, or integer types or float/double/long double
+template<typename Scalar,
+          bool HasStdImpl = NumTraits<Scalar>::IsComplex || is_integral<Scalar>::value
+                            || is_same<Scalar, float>::value || is_same<Scalar, double>::value
+                            || is_same<Scalar, long double>::value >
+struct arg_default_impl;
+
+template<typename Scalar>
+struct arg_default_impl<Scalar, true> {
+  typedef typename NumTraits<Scalar>::Real RealScalar;
+  EIGEN_DEVICE_FUNC
+  static inline RealScalar run(const Scalar& x)
   {
-    typedef typename NumTraits<Scalar>::Real RealScalar;
-    EIGEN_DEVICE_FUNC
-    static inline RealScalar run(const Scalar& x)
-    {
-      return (x < Scalar(0)) ? Scalar(EIGEN_PI) : Scalar(0); }
-  };
+    #if defined(EIGEN_HIP_DEVICE_COMPILE)
+    // HIP does not seem to have a native device side implementation for the math routine "arg"
+    using std::arg;
+    #else
+    EIGEN_USING_STD(arg);
+    #endif
+    return static_cast<RealScalar>(arg(x));
+  }
+};
 
-  template<typename Scalar>
-  struct arg_default_impl<Scalar,true>
+// Must be non-complex floating-point type (e.g. half/bfloat16).
+template<typename Scalar>
+struct arg_default_impl<Scalar, false> {
+  typedef typename NumTraits<Scalar>::Real RealScalar;
+  EIGEN_DEVICE_FUNC
+  static inline RealScalar run(const Scalar& x)
   {
-    typedef typename NumTraits<Scalar>::Real RealScalar;
-    EIGEN_DEVICE_FUNC
-    static inline RealScalar run(const Scalar& x)
-    {
-      EIGEN_USING_STD_MATH(arg);
-      return arg(x);
-    }
-  };
+    return (x < Scalar(0)) ? RealScalar(EIGEN_PI) : RealScalar(0);
+  }
+};
+#else
+template<typename Scalar, bool IsComplex = NumTraits<Scalar>::IsComplex>
+struct arg_default_impl
+{
+  typedef typename NumTraits<Scalar>::Real RealScalar;
+  EIGEN_DEVICE_FUNC
+  static inline RealScalar run(const Scalar& x)
+  {
+    return (x < RealScalar(0)) ? RealScalar(EIGEN_PI) : RealScalar(0);
+  }
+};
 
-  template<typename Scalar> struct arg_impl : arg_default_impl<Scalar> {};
+template<typename Scalar>
+struct arg_default_impl<Scalar,true>
+{
+  typedef typename NumTraits<Scalar>::Real RealScalar;
+  EIGEN_DEVICE_FUNC
+  static inline RealScalar run(const Scalar& x)
+  {
+    EIGEN_USING_STD(arg);
+    return arg(x);
+  }
+};
 #endif
+template<typename Scalar> struct arg_impl : arg_default_impl<Scalar> {};
 
 template<typename Scalar>
 struct arg_retval
 {
   typedef typename NumTraits<Scalar>::Real type;
 };
 
@@ -534,25 +650,25 @@
   // or that there is no suitable std::expm1 function available. Implementation
   // attributed to Kahan. See: http://www.plunk.org/~hatch/rightway.php.
   template<typename Scalar>
   EIGEN_DEVICE_FUNC inline Scalar expm1(const Scalar& x) {
     EIGEN_STATIC_ASSERT_NON_INTEGER(Scalar)
     typedef typename NumTraits<Scalar>::Real RealScalar;
 
-    EIGEN_USING_STD_MATH(exp);
+    EIGEN_USING_STD(exp);
     Scalar u = exp(x);
     if (numext::equal_strict(u, Scalar(1))) {
       return x;
     }
     Scalar um1 = u - RealScalar(1);
     if (numext::equal_strict(um1, Scalar(-1))) {
       return RealScalar(-1);
     }
 
-    EIGEN_USING_STD_MATH(log);
+    EIGEN_USING_STD(log);
     Scalar logu = log(u);
     return numext::equal_strict(u, logu) ? u : (u - RealScalar(1)) * x / logu;
   }
 }
 
 template<typename Scalar>
 struct expm1_impl {
@@ -564,64 +680,58 @@
     #else
     using std_fallback::expm1;
     #endif
     return expm1(x);
   }
 };
 
-// Specialization for complex types that are not supported by std::expm1.
-template <typename RealScalar>
-struct expm1_impl<std::complex<RealScalar> > {
-  EIGEN_DEVICE_FUNC static inline std::complex<RealScalar> run(
-      const std::complex<RealScalar>& x) {
-    EIGEN_STATIC_ASSERT_NON_INTEGER(RealScalar)
-    RealScalar xr = x.real();
-    RealScalar xi = x.imag();
-    // expm1(z) = exp(z) - 1
-    //          = exp(x +  i * y) - 1
-    //          = exp(x) * (cos(y) + i * sin(y)) - 1
-    //          = exp(x) * cos(y) - 1 + i * exp(x) * sin(y)
-    // Imag(expm1(z)) = exp(x) * sin(y)
-    // Real(expm1(z)) = exp(x) * cos(y) - 1
-    //          = exp(x) * cos(y) - 1.
-    //          = expm1(x) + exp(x) * (cos(y) - 1)
-    //          = expm1(x) + exp(x) * (2 * sin(y / 2) ** 2)
+template<typename Scalar>
+struct expm1_retval
+{
+  typedef Scalar type;
+};
 
-    // TODO better use numext::expm1 and numext::sin (but that would require forward declarations or moving this specialization down).
-    RealScalar erm1 = expm1_impl<RealScalar>::run(xr);
-    RealScalar er = erm1 + RealScalar(1.);
-    EIGEN_USING_STD_MATH(sin);
-    RealScalar sin2 = sin(xi / RealScalar(2.));
-    sin2 = sin2 * sin2;
-    RealScalar s = sin(xi);
-    RealScalar real_part = erm1 - RealScalar(2.) * er * sin2;
-    return std::complex<RealScalar>(real_part, er * s);
+/****************************************************************************
+* Implementation of log                                                     *
+****************************************************************************/
+
+// Complex log defined in MathFunctionsImpl.h.
+template<typename T> EIGEN_DEVICE_FUNC std::complex<T> complex_log(const std::complex<T>& z);
+
+template<typename Scalar>
+struct log_impl {
+  EIGEN_DEVICE_FUNC static inline Scalar run(const Scalar& x)
+  {
+    EIGEN_USING_STD(log);
+    return static_cast<Scalar>(log(x));
   }
 };
 
 template<typename Scalar>
-struct expm1_retval
-{
-  typedef Scalar type;
+struct log_impl<std::complex<Scalar> > {
+  EIGEN_DEVICE_FUNC static inline std::complex<Scalar> run(const std::complex<Scalar>& z)
+  {
+    return complex_log(z);
+  }
 };
 
 /****************************************************************************
 * Implementation of log1p                                                   *
 ****************************************************************************/
 
 namespace std_fallback {
   // fallback log1p implementation in case there is no log1p(Scalar) function in namespace of Scalar,
   // or that there is no suitable std::log1p function available
   template<typename Scalar>
   EIGEN_DEVICE_FUNC inline Scalar log1p(const Scalar& x) {
     EIGEN_STATIC_ASSERT_NON_INTEGER(Scalar)
     typedef typename NumTraits<Scalar>::Real RealScalar;
-    EIGEN_USING_STD_MATH(log);
+    EIGEN_USING_STD(log);
     Scalar x1p = RealScalar(1) + x;
-    Scalar log_1p = log(x1p);
+    Scalar log_1p = log_impl<Scalar>::run(x1p);
     const bool is_small = numext::equal_strict(x1p, Scalar(1));
     const bool is_inf = numext::equal_strict(x1p, log_1p);
     return (is_small || is_inf) ? x : x * (log_1p / (x1p - RealScalar(1)));
   }
 }
 
 template<typename Scalar>
@@ -661,15 +771,15 @@
 template<typename ScalarX,typename ScalarY, bool IsInteger = NumTraits<ScalarX>::IsInteger&&NumTraits<ScalarY>::IsInteger>
 struct pow_impl
 {
   //typedef Scalar retval;
   typedef typename ScalarBinaryOpTraits<ScalarX,ScalarY,internal::scalar_pow_op<ScalarX,ScalarY> >::ReturnType result_type;
   static EIGEN_DEVICE_FUNC inline result_type run(const ScalarX& x, const ScalarY& y)
   {
-    EIGEN_USING_STD_MATH(pow);
+    EIGEN_USING_STD(pow);
     return pow(x, y);
   }
 };
 
 template<typename ScalarX,typename ScalarY>
 struct pow_impl<ScalarX,ScalarY, true>
 {
@@ -963,28 +1073,28 @@
 
 /****************************************************************************
 * Generic math functions                                                    *
 ****************************************************************************/
 
 namespace numext {
 
-#if (!defined(EIGEN_GPUCC) || defined(EIGEN_CONSTEXPR_ARE_DEVICE_FUNC)) 
+#if (!defined(EIGEN_GPUCC) || defined(EIGEN_CONSTEXPR_ARE_DEVICE_FUNC))
 template<typename T>
 EIGEN_DEVICE_FUNC
 EIGEN_ALWAYS_INLINE T mini(const T& x, const T& y)
 {
-  EIGEN_USING_STD_MATH(min);
+  EIGEN_USING_STD(min)
   return min EIGEN_NOT_A_MACRO (x,y);
 }
 
 template<typename T>
 EIGEN_DEVICE_FUNC
 EIGEN_ALWAYS_INLINE T maxi(const T& x, const T& y)
 {
-  EIGEN_USING_STD_MATH(max);
+  EIGEN_USING_STD(max)
   return max EIGEN_NOT_A_MACRO (x,y);
 }
 #else
 template<typename T>
 EIGEN_DEVICE_FUNC
 EIGEN_ALWAYS_INLINE T mini(const T& x, const T& y)
 {
@@ -1195,25 +1305,23 @@
 }
 template<>
 EIGEN_DEVICE_FUNC
 EIGEN_ALWAYS_INLINE double absdiff(const double& x, const double& y)
 {
   return fabs(x - y);
 }
+
+#if !defined(EIGEN_GPUCC)
+// HIP and CUDA do not support long double.
 template<>
 EIGEN_DEVICE_FUNC
-EIGEN_ALWAYS_INLINE long double absdiff(const long double& x, const long double& y)
-{
-#if defined(EIGEN_HIPCC)
-  // no "fabsl" on HIP yet
-  return (x > y) ? x : y;
-#else
+EIGEN_ALWAYS_INLINE long double absdiff(const long double& x, const long double& y) {
   return fabsl(x - y);
-#endif
 }
+#endif
 
 template<typename Scalar>
 EIGEN_DEVICE_FUNC
 inline EIGEN_MATHFUNC_RETVAL(norm1, Scalar) norm1(const Scalar& x)
 {
   return EIGEN_MATHFUNC_IMPL(norm1, Scalar)::run(x);
 }
@@ -1287,15 +1395,15 @@
 SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(round, round)
 #endif
 
 template<typename T>
 EIGEN_DEVICE_FUNC
 T (floor)(const T& x)
 {
-  EIGEN_USING_STD_MATH(floor);
+  EIGEN_USING_STD(floor)
   return floor(x);
 }
 
 #if defined(SYCL_DEVICE_ONLY)
 SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(floor, floor)
 #endif
 
@@ -1307,15 +1415,15 @@
 double floor(const double &x) { return ::floor(x); }
 #endif
 
 template<typename T>
 EIGEN_DEVICE_FUNC
 T (ceil)(const T& x)
 {
-  EIGEN_USING_STD_MATH(ceil);
+  EIGEN_USING_STD(ceil);
   return ceil(x);
 }
 
 #if defined(SYCL_DEVICE_ONLY)
 SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(ceil, ceil)
 #endif
 
@@ -1348,31 +1456,42 @@
   * It is essentially equivalent to
   * \code using std::sqrt; return sqrt(x); \endcode
   * but slightly faster for float/double and some compilers (e.g., gcc), thanks to
   * specializations when SSE is enabled.
   *
   * It's usage is justified in performance critical functions, like norm/normalize.
   */
-template<typename T>
-EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
-T sqrt(const T &x)
+template<typename Scalar>
+EIGEN_DEVICE_FUNC
+EIGEN_ALWAYS_INLINE EIGEN_MATHFUNC_RETVAL(sqrt, Scalar) sqrt(const Scalar& x)
 {
-  EIGEN_USING_STD_MATH(sqrt);
-  return sqrt(x);
+  return EIGEN_MATHFUNC_IMPL(sqrt, Scalar)::run(x);
 }
 
+// Boolean specialization, avoids implicit float to bool conversion (-Wimplicit-conversion-floating-point-to-bool).
+template<>
+EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_DEVICE_FUNC
+bool sqrt<bool>(const bool &x) { return x; }
+
 #if defined(SYCL_DEVICE_ONLY)
 SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(sqrt, sqrt)
 #endif
 
+/** \returns the reciprocal square root of \a x. **/
+template<typename T>
+EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
+T rsqrt(const T& x)
+{
+  return internal::rsqrt_impl<T>::run(x);
+}
+
 template<typename T>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 T log(const T &x) {
-  EIGEN_USING_STD_MATH(log);
-  return log(x);
+  return internal::log_impl<T>::run(x);
 }
 
 #if defined(SYCL_DEVICE_ONLY)
 SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(log, log)
 #endif
 
 
@@ -1384,15 +1503,15 @@
 double log(const double &x) { return ::log(x); }
 #endif
 
 template<typename T>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 typename internal::enable_if<NumTraits<T>::IsSigned || NumTraits<T>::IsComplex,typename NumTraits<T>::Real>::type
 abs(const T &x) {
-  EIGEN_USING_STD_MATH(abs);
+  EIGEN_USING_STD(abs);
   return abs(x);
 }
 
 template<typename T>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 typename internal::enable_if<!(NumTraits<T>::IsSigned || NumTraits<T>::IsComplex),typename NumTraits<T>::Real>::type
 abs(const T &x) {
@@ -1421,15 +1540,15 @@
   return ::hypot(x.real(), x.imag());
 }
 #endif
 
 template<typename T>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 T exp(const T &x) {
-  EIGEN_USING_STD_MATH(exp);
+  EIGEN_USING_STD(exp);
   return exp(x);
 }
 
 #if defined(SYCL_DEVICE_ONLY)
 SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(exp, exp)
 #endif
 
@@ -1475,15 +1594,15 @@
 template<> EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 double expm1(const double &x) { return ::expm1(x); }
 #endif
 
 template<typename T>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 T cos(const T &x) {
-  EIGEN_USING_STD_MATH(cos);
+  EIGEN_USING_STD(cos);
   return cos(x);
 }
 
 #if defined(SYCL_DEVICE_ONLY)
 SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(cos,cos)
 #endif
 
@@ -1494,15 +1613,15 @@
 template<> EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 double cos(const double &x) { return ::cos(x); }
 #endif
 
 template<typename T>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 T sin(const T &x) {
-  EIGEN_USING_STD_MATH(sin);
+  EIGEN_USING_STD(sin);
   return sin(x);
 }
 
 #if defined(SYCL_DEVICE_ONLY)
 SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(sin, sin)
 #endif
 
@@ -1513,15 +1632,15 @@
 template<> EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 double sin(const double &x) { return ::sin(x); }
 #endif
 
 template<typename T>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 T tan(const T &x) {
-  EIGEN_USING_STD_MATH(tan);
+  EIGEN_USING_STD(tan);
   return tan(x);
 }
 
 #if defined(SYCL_DEVICE_ONLY)
 SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(tan, tan)
 #endif
 
@@ -1532,24 +1651,24 @@
 template<> EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 double tan(const double &x) { return ::tan(x); }
 #endif
 
 template<typename T>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 T acos(const T &x) {
-  EIGEN_USING_STD_MATH(acos);
+  EIGEN_USING_STD(acos);
   return acos(x);
 }
 
 #if EIGEN_HAS_CXX11_MATH
 template<typename T>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 T acosh(const T &x) {
-  EIGEN_USING_STD_MATH(acosh);
-  return acosh(x);
+  EIGEN_USING_STD(acosh);
+  return static_cast<T>(acosh(x));
 }
 #endif
 
 #if defined(SYCL_DEVICE_ONLY)
 SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(acos, acos)
 SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(acosh, acosh)
 #endif
@@ -1561,24 +1680,24 @@
 template<> EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 double acos(const double &x) { return ::acos(x); }
 #endif
 
 template<typename T>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 T asin(const T &x) {
-  EIGEN_USING_STD_MATH(asin);
+  EIGEN_USING_STD(asin);
   return asin(x);
 }
 
 #if EIGEN_HAS_CXX11_MATH
 template<typename T>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 T asinh(const T &x) {
-  EIGEN_USING_STD_MATH(asinh);
-  return asinh(x);
+  EIGEN_USING_STD(asinh);
+  return static_cast<T>(asinh(x));
 }
 #endif
 
 #if defined(SYCL_DEVICE_ONLY)
 SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(asin, asin)
 SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(asinh, asinh)
 #endif
@@ -1590,24 +1709,24 @@
 template<> EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 double asin(const double &x) { return ::asin(x); }
 #endif
 
 template<typename T>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 T atan(const T &x) {
-  EIGEN_USING_STD_MATH(atan);
-  return atan(x);
+  EIGEN_USING_STD(atan);
+  return static_cast<T>(atan(x));
 }
 
 #if EIGEN_HAS_CXX11_MATH
 template<typename T>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 T atanh(const T &x) {
-  EIGEN_USING_STD_MATH(atanh);
-  return atanh(x);
+  EIGEN_USING_STD(atanh);
+  return static_cast<T>(atanh(x));
 }
 #endif
 
 #if defined(SYCL_DEVICE_ONLY)
 SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(atan, atan)
 SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(atanh, atanh)
 #endif
@@ -1620,16 +1739,16 @@
 double atan(const double &x) { return ::atan(x); }
 #endif
 
 
 template<typename T>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 T cosh(const T &x) {
-  EIGEN_USING_STD_MATH(cosh);
-  return cosh(x);
+  EIGEN_USING_STD(cosh);
+  return static_cast<T>(cosh(x));
 }
 
 #if defined(SYCL_DEVICE_ONLY)
 SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(cosh, cosh)
 #endif
 
 #if defined(EIGEN_GPUCC)
@@ -1639,16 +1758,16 @@
 template<> EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 double cosh(const double &x) { return ::cosh(x); }
 #endif
 
 template<typename T>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 T sinh(const T &x) {
-  EIGEN_USING_STD_MATH(sinh);
-  return sinh(x);
+  EIGEN_USING_STD(sinh);
+  return static_cast<T>(sinh(x));
 }
 
 #if defined(SYCL_DEVICE_ONLY)
 SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(sinh, sinh)
 #endif
 
 #if defined(EIGEN_GPUCC)
@@ -1658,15 +1777,15 @@
 template<> EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 double sinh(const double &x) { return ::sinh(x); }
 #endif
 
 template<typename T>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 T tanh(const T &x) {
-  EIGEN_USING_STD_MATH(tanh);
+  EIGEN_USING_STD(tanh);
   return tanh(x);
 }
 
 #if (!defined(EIGEN_GPUCC)) && EIGEN_FAST_MATH && !defined(SYCL_DEVICE_ONLY)
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 float tanh(float x) { return internal::generic_fast_tanh_float(x); }
 #endif
@@ -1682,15 +1801,15 @@
 template<> EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 double tanh(const double &x) { return ::tanh(x); }
 #endif
 
 template <typename T>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 T fmod(const T& a, const T& b) {
-  EIGEN_USING_STD_MATH(fmod);
+  EIGEN_USING_STD(fmod);
   return fmod(a, b);
 }
 
 #if defined(SYCL_DEVICE_ONLY)
 SYCL_SPECIALIZE_FLOATING_TYPES_BINARY(fmod, fmod)
 #endif
 
@@ -1844,14 +1963,19 @@
 
 template<> struct random_impl<bool>
 {
   static inline bool run()
   {
     return random<int>(0,1)==0 ? false : true;
   }
+
+  static inline bool run(const bool& a, const bool& b)
+  {
+    return random<int>(a, b)==0 ? false : true;
+  }
 };
 
 template<> struct scalar_fuzzy_impl<bool>
 {
   typedef bool RealScalar;
 
   template<typename OtherScalar> EIGEN_DEVICE_FUNC
@@ -1870,13 +1994,64 @@
   static inline bool isApproxOrLessThan(const bool& x, const bool& y, const bool&)
   {
     return (!x) || y;
   }
 
 };
 
+} // end namespace internal
+
+// Default implementations that rely on other numext implementations
+namespace internal {
+
+// Specialization for complex types that are not supported by std::expm1.
+template <typename RealScalar>
+struct expm1_impl<std::complex<RealScalar> > {
+  EIGEN_DEVICE_FUNC static inline std::complex<RealScalar> run(
+      const std::complex<RealScalar>& x) {
+    EIGEN_STATIC_ASSERT_NON_INTEGER(RealScalar)
+    RealScalar xr = x.real();
+    RealScalar xi = x.imag();
+    // expm1(z) = exp(z) - 1
+    //          = exp(x +  i * y) - 1
+    //          = exp(x) * (cos(y) + i * sin(y)) - 1
+    //          = exp(x) * cos(y) - 1 + i * exp(x) * sin(y)
+    // Imag(expm1(z)) = exp(x) * sin(y)
+    // Real(expm1(z)) = exp(x) * cos(y) - 1
+    //          = exp(x) * cos(y) - 1.
+    //          = expm1(x) + exp(x) * (cos(y) - 1)
+    //          = expm1(x) + exp(x) * (2 * sin(y / 2) ** 2)
+    RealScalar erm1 = numext::expm1<RealScalar>(xr);
+    RealScalar er = erm1 + RealScalar(1.);
+    RealScalar sin2 = numext::sin(xi / RealScalar(2.));
+    sin2 = sin2 * sin2;
+    RealScalar s = numext::sin(xi);
+    RealScalar real_part = erm1 - RealScalar(2.) * er * sin2;
+    return std::complex<RealScalar>(real_part, er * s);
+  }
+};
+
+template<typename T>
+struct rsqrt_impl {
+  EIGEN_DEVICE_FUNC
+  static EIGEN_ALWAYS_INLINE T run(const T& x) {
+    return T(1)/numext::sqrt(x);
+  }
+};
+
+#if defined(EIGEN_GPU_COMPILE_PHASE)
+template<typename T>
+struct conj_impl<std::complex<T>, true>
+{
+  EIGEN_DEVICE_FUNC
+  static inline std::complex<T> run(const std::complex<T>& x)
+  {
+    return std::complex<T>(numext::real(x), -numext::imag(x));
+  }
+};
+#endif
 
 } // end namespace internal
 
 } // end namespace Eigen
 
 #endif // EIGEN_MATHFUNCTIONS_H
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Matrix.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Matrix.h`

 * *Files 2% similar despite different names*

```diff
@@ -25,30 +25,30 @@
       is_dynamic_size_storage = _MaxRows==Dynamic || _MaxCols==Dynamic,
       max_size = is_dynamic_size_storage ? Dynamic : _MaxRows*_MaxCols,
       default_alignment = compute_default_alignment<_Scalar,max_size>::value,
       actual_alignment = ((_Options&DontAlign)==0) ? default_alignment : 0,
       required_alignment = unpacket_traits<PacketScalar>::alignment,
       packet_access_bit = (packet_traits<_Scalar>::Vectorizable && (EIGEN_UNALIGNED_VECTORIZE || (actual_alignment>=required_alignment))) ? PacketAccessBit : 0
     };
-    
+
 public:
   typedef _Scalar Scalar;
   typedef Dense StorageKind;
   typedef Eigen::Index StorageIndex;
   typedef MatrixXpr XprKind;
   enum {
     RowsAtCompileTime = _Rows,
     ColsAtCompileTime = _Cols,
     MaxRowsAtCompileTime = _MaxRows,
     MaxColsAtCompileTime = _MaxCols,
     Flags = compute_matrix_flags<_Scalar, _Rows, _Cols, _Options, _MaxRows, _MaxCols>::ret,
     Options = _Options,
     InnerStrideAtCompileTime = 1,
     OuterStrideAtCompileTime = (Options&RowMajor) ? ColsAtCompileTime : RowsAtCompileTime,
-    
+
     // FIXME, the following flag in only used to define NeedsToAlign in PlainObjectBase
     EvaluatorFlags = LinearAccessBit | DirectAccessBit | packet_access_bit | row_major_bit,
     Alignment = actual_alignment
   };
 };
 }
 
@@ -274,15 +274,15 @@
       : Base(std::move(other))
     {
       Base::_check_template_params();
     }
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
     Matrix& operator=(Matrix&& other) EIGEN_NOEXCEPT_IF(std::is_nothrow_move_assignable<Scalar>::value)
     {
-      other.swap(*this);
+      Base::operator=(std::move(other));
       return *this;
     }
 #endif
 
 #if EIGEN_HAS_CXX11
     /** \copydoc PlainObjectBase(const Scalar&, const Scalar&, const Scalar&,  const Scalar&, const ArgTypes&... args)
      *
@@ -293,32 +293,32 @@
      */
     template <typename... ArgTypes>
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
     Matrix(const Scalar& a0, const Scalar& a1, const Scalar& a2,  const Scalar& a3, const ArgTypes&... args)
       : Base(a0, a1, a2, a3, args...) {}
 
     /** \brief Constructs a Matrix and initializes it from the coefficients given as initializer-lists grouped by row. \cpp11
-      * 
+      *
       * In the general case, the constructor takes a list of rows, each row being represented as a list of coefficients:
-      * 
+      *
       * Example: \include Matrix_initializer_list_23_cxx11.cpp
       * Output: \verbinclude Matrix_initializer_list_23_cxx11.out
-      * 
+      *
       * Each of the inner initializer lists must contain the exact same number of elements, otherwise an assertion is triggered.
-      * 
+      *
       * In the case of a compile-time column vector, implicit transposition from a single row is allowed.
       * Therefore <code>VectorXd{{1,2,3,4,5}}</code> is legal and the more verbose syntax
       * <code>RowVectorXd{{1},{2},{3},{4},{5}}</code> can be avoided:
-      * 
+      *
       * Example: \include Matrix_initializer_list_vector_cxx11.cpp
       * Output: \verbinclude Matrix_initializer_list_vector_cxx11.out
-      * 
+      *
       * In the case of fixed-sized matrices, the initializer list sizes must exactly match the matrix sizes,
       * and implicit transposition is allowed for compile-time vectors only.
-      * 
+      *
       * \sa Matrix(const Scalar& a0, const Scalar& a1, const Scalar& a2,  const Scalar& a3, const ArgTypes&... args)
       */
     EIGEN_DEVICE_FUNC
     explicit EIGEN_STRONG_INLINE Matrix(const std::initializer_list<std::initializer_list<Scalar>>& list) : Base(list) {}
 #endif // end EIGEN_HAS_CXX11
 
 #ifndef EIGEN_PARSED_BY_DOXYGEN
@@ -347,15 +347,15 @@
     explicit Matrix(const Scalar *data);
 
     /** \brief Constructs a vector or row-vector with given dimension. \only_for_vectors
       *
       * This is useful for dynamic-size vectors. For fixed-size vectors,
       * it is redundant to pass these parameters, so one should use the default constructor
       * Matrix() instead.
-      * 
+      *
       * \warning This constructor is disabled for fixed-size \c 1x1 matrices. For instance,
       * calling Matrix<double,1,1>(1) will call the initialization constructor: Matrix(const Scalar&).
       * For fixed-size \c 1x1 matrices it is therefore recommended to use the default
       * constructor Matrix() instead, especially when using one of the non standard
       * \c EIGEN_INITIALIZE_MATRICES_BY_{ZERO,\c NAN} macros (see \ref TopicPreprocessorDirectives).
       */
     EIGEN_STRONG_INLINE explicit Matrix(Index dim);
@@ -363,24 +363,24 @@
       * \sa Matrix(const Scalar&, const Scalar&, const Scalar&,  const Scalar&, const ArgTypes&...) */
     Matrix(const Scalar& x);
     /** \brief Constructs an uninitialized matrix with \a rows rows and \a cols columns.
       *
       * This is useful for dynamic-size matrices. For fixed-size matrices,
       * it is redundant to pass these parameters, so one should use the default constructor
       * Matrix() instead.
-      * 
+      *
       * \warning This constructor is disabled for fixed-size \c 1x2 and \c 2x1 vectors. For instance,
       * calling Matrix2f(2,1) will call the initialization constructor: Matrix(const Scalar& x, const Scalar& y).
       * For fixed-size \c 1x2 or \c 2x1 vectors it is therefore recommended to use the default
       * constructor Matrix() instead, especially when using one of the non standard
       * \c EIGEN_INITIALIZE_MATRICES_BY_{ZERO,\c NAN} macros (see \ref TopicPreprocessorDirectives).
       */
     EIGEN_DEVICE_FUNC
     Matrix(Index rows, Index cols);
-    
+
     /** \brief Constructs an initialized 2D vector with given coefficients
       * \sa Matrix(const Scalar&, const Scalar&, const Scalar&,  const Scalar&, const ArgTypes&...) */
     Matrix(const Scalar& x, const Scalar& y);
     #endif  // end EIGEN_PARSED_BY_DOXYGEN
 
     /** \brief Constructs an initialized 3D vector with given coefficients
       * \sa Matrix(const Scalar&, const Scalar&, const Scalar&,  const Scalar&, const ArgTypes&...)
@@ -419,16 +419,18 @@
       */
     template<typename OtherDerived>
     EIGEN_DEVICE_FUNC
     EIGEN_STRONG_INLINE Matrix(const EigenBase<OtherDerived> &other)
       : Base(other.derived())
     { }
 
-    EIGEN_DEVICE_FUNC inline Index innerStride() const { return 1; }
-    EIGEN_DEVICE_FUNC inline Index outerStride() const { return this->innerSize(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index innerStride() const EIGEN_NOEXCEPT { return 1; }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index outerStride() const EIGEN_NOEXCEPT { return this->innerSize(); }
 
     /////////// Geometry module ///////////
 
     template<typename OtherDerived>
     EIGEN_DEVICE_FUNC
     explicit Matrix(const RotationBase<OtherDerived,ColsAtCompileTime>& r);
     template<typename OtherDerived>
@@ -459,22 +461,22 @@
   * and where \c Type can be \c i for integer, \c f for float, \c d for double, \c cf for complex float, \c cd
   * for complex double.
   *
   * For example, \c Matrix3d is a fixed-size 3x3 matrix type of doubles, and \c MatrixXf is a dynamic-size matrix of floats.
   *
   * There are also \c VectorSizeType and \c RowVectorSizeType which are self-explanatory. For example, \c Vector4cf is
   * a fixed-size vector of 4 complex floats.
-  * 
+  *
   * With \cpp11, template alias are also defined for common sizes.
   * They follow the same pattern as above except that the scalar type suffix is replaced by a
   * template parameter, i.e.:
   *   - `MatrixSize<Type>` where `Size` can be \c 2,\c 3,\c 4 for fixed size square matrices or \c X for dynamic size.
   *   - `MatrixXSize<Type>` and `MatrixSizeX<Type>` where `Size` can be \c 2,\c 3,\c 4 for hybrid dynamic/fixed matrices.
   *   - `VectorSize<Type>` and `RowVectorSize<Type>` for column and row vectors.
-  * 
+  *
   * With \cpp11, you can also use fully generic column and row vector types: `Vector<Type,Size>` and `RowVector<Type,Size>`.
   *
   * \sa class Matrix
   */
 
 #define EIGEN_MAKE_TYPEDEFS(Type, TypeSuffix, Size, SizeSuffix)   \
 /** \ingroup matrixtypedefs */                                    \
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/MatrixBase.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/MatrixBase.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/NestByValue.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/NestByValue.h`

 * *Files 5% similar despite different names*

```diff
@@ -41,16 +41,16 @@
   public:
 
     typedef typename internal::dense_xpr_base<NestByValue>::type Base;
     EIGEN_DENSE_PUBLIC_INTERFACE(NestByValue)
 
     EIGEN_DEVICE_FUNC explicit inline NestByValue(const ExpressionType& matrix) : m_expression(matrix) {}
 
-    EIGEN_DEVICE_FUNC inline Index rows() const { return m_expression.rows(); }
-    EIGEN_DEVICE_FUNC inline Index cols() const { return m_expression.cols(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index rows() const EIGEN_NOEXCEPT { return m_expression.rows(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index cols() const EIGEN_NOEXCEPT { return m_expression.cols(); }
 
     EIGEN_DEVICE_FUNC operator const ExpressionType&() const { return m_expression; }
 
     EIGEN_DEVICE_FUNC const ExpressionType& nestedExpression() const { return m_expression; }
 
   protected:
     const ExpressionType m_expression;
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/NoAlias.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/NoAlias.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/NumTraits.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/NumTraits.h`

 * *Files 14% similar despite different names*

```diff
@@ -17,70 +17,91 @@
 // default implementation of digits10(), based on numeric_limits if specialized,
 // 0 for integer types, and log10(epsilon()) otherwise.
 template< typename T,
           bool use_numeric_limits = std::numeric_limits<T>::is_specialized,
           bool is_integer = NumTraits<T>::IsInteger>
 struct default_digits10_impl
 {
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static int run() { return std::numeric_limits<T>::digits10; }
 };
 
 template<typename T>
 struct default_digits10_impl<T,false,false> // Floating point
 {
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static int run() {
     using std::log10;
     using std::ceil;
     typedef typename NumTraits<T>::Real Real;
     return int(ceil(-log10(NumTraits<Real>::epsilon())));
   }
 };
 
 template<typename T>
 struct default_digits10_impl<T,false,true> // Integer
 {
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static int run() { return 0; }
 };
 
 
 // default implementation of digits(), based on numeric_limits if specialized,
 // 0 for integer types, and log2(epsilon()) otherwise.
 template< typename T,
           bool use_numeric_limits = std::numeric_limits<T>::is_specialized,
           bool is_integer = NumTraits<T>::IsInteger>
 struct default_digits_impl
 {
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static int run() { return std::numeric_limits<T>::digits; }
 };
 
 template<typename T>
 struct default_digits_impl<T,false,false> // Floating point
 {
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static int run() {
     using std::log;
     using std::ceil;
     typedef typename NumTraits<T>::Real Real;
     return int(ceil(-log(NumTraits<Real>::epsilon())/log(static_cast<Real>(2))));
   }
 };
 
 template<typename T>
 struct default_digits_impl<T,false,true> // Integer
 {
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static int run() { return 0; }
 };
 
 } // end namespace internal
 
+namespace numext {
+/** \internal bit-wise cast without changing the underlying bit representation. */
+
+// TODO: Replace by std::bit_cast (available in C++20)
+template <typename Tgt, typename Src>
+EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC Tgt bit_cast(const Src& src) {
+#if EIGEN_HAS_TYPE_TRAITS
+  // The behaviour of memcpy is not specified for non-trivially copyable types
+  EIGEN_STATIC_ASSERT(std::is_trivially_copyable<Src>::value, THIS_TYPE_IS_NOT_SUPPORTED);
+  EIGEN_STATIC_ASSERT(std::is_trivially_copyable<Tgt>::value && std::is_default_constructible<Tgt>::value,
+                      THIS_TYPE_IS_NOT_SUPPORTED);
+#endif
+
+  EIGEN_STATIC_ASSERT(sizeof(Src) == sizeof(Tgt), THIS_TYPE_IS_NOT_SUPPORTED);
+  Tgt tgt;
+  EIGEN_USING_STD(memcpy)
+  memcpy(&tgt, &src, sizeof(Tgt));
+  return tgt;
+}
+}  // namespace numext
+
 /** \class NumTraits
   * \ingroup Core_Module
   *
   * \brief Holds information about the various numeric (i.e. scalar) types allowed by Eigen.
   *
   * \tparam T the numeric type at hand
   *
@@ -110,17 +131,26 @@
   * \li An enum value \a RequireInitialization. It is equal to \c 1 if the constructor of the numeric type \a T must
   *     be called, and to 0 if it is safe not to call it. Default is 0 if \a T is an arithmetic type, and 1 otherwise.
   * \li An epsilon() function which, unlike <a href="http://en.cppreference.com/w/cpp/types/numeric_limits/epsilon">std::numeric_limits::epsilon()</a>,
   *     it returns a \a Real instead of a \a T.
   * \li A dummy_precision() function returning a weak epsilon value. It is mainly used as a default
   *     value by the fuzzy comparison operators.
   * \li highest() and lowest() functions returning the highest and lowest possible values respectively.
+  * \li digits() function returning the number of radix digits (non-sign digits for integers, mantissa for floating-point). This is
+  *     the analogue of <a href="http://en.cppreference.com/w/cpp/types/numeric_limits/digits">std::numeric_limits<T>::digits</a>
+  *     which is used as the default implementation if specialized.
   * \li digits10() function returning the number of decimal digits that can be represented without change. This is
   *     the analogue of <a href="http://en.cppreference.com/w/cpp/types/numeric_limits/digits10">std::numeric_limits<T>::digits10</a>
   *     which is used as the default implementation if specialized.
+  * \li min_exponent() and max_exponent() functions returning the highest and lowest possible values, respectively,
+  *     such that the radix raised to the power exponent-1 is a normalized floating-point number.  These are equivalent to
+  *     <a href="http://en.cppreference.com/w/cpp/types/numeric_limits/min_exponent">std::numeric_limits<T>::min_exponent</a>/
+  *     <a href="http://en.cppreference.com/w/cpp/types/numeric_limits/max_exponent">std::numeric_limits<T>::max_exponent</a>.
+  * \li infinity() function returning a representation of positive infinity, if available.
+  * \li quiet_NaN function returning a non-signaling "not-a-number", if available.
   */
 
 template<typename T> struct GenericNumTraits
 {
   enum {
     IsInteger = std::numeric_limits<T>::is_integer,
     IsSigned = std::numeric_limits<T>::is_signed,
@@ -136,81 +166,93 @@
                      IsInteger,
                      typename internal::conditional<sizeof(T)<=2, float, double>::type,
                      T
                    >::type NonInteger;
   typedef T Nested;
   typedef T Literal;
 
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static inline Real epsilon()
   {
     return numext::numeric_limits<T>::epsilon();
   }
 
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static inline int digits10()
   {
     return internal::default_digits10_impl<T>::run();
   }
 
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static inline int digits()
   {
     return internal::default_digits_impl<T>::run();
   }
 
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+  static inline int min_exponent()
+  {
+    return numext::numeric_limits<T>::min_exponent;
+  }
+
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+  static inline int max_exponent()
+  {
+    return numext::numeric_limits<T>::max_exponent;
+  }
+
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static inline Real dummy_precision()
   {
     // make sure to override this for floating-point types
     return Real(0);
   }
 
-
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static inline T highest() {
     return (numext::numeric_limits<T>::max)();
   }
 
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static inline T lowest()  {
     return IsInteger ? (numext::numeric_limits<T>::min)()
                      : static_cast<T>(-(numext::numeric_limits<T>::max)());
   }
 
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static inline T infinity() {
     return numext::numeric_limits<T>::infinity();
   }
 
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static inline T quiet_NaN() {
     return numext::numeric_limits<T>::quiet_NaN();
   }
 };
 
 template<typename T> struct NumTraits : GenericNumTraits<T>
 {};
 
 template<> struct NumTraits<float>
   : GenericNumTraits<float>
 {
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static inline float dummy_precision() { return 1e-5f; }
 };
 
 template<> struct NumTraits<double> : GenericNumTraits<double>
 {
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static inline double dummy_precision() { return 1e-12; }
 };
 
 template<> struct NumTraits<long double>
   : GenericNumTraits<long double>
 {
+  EIGEN_CONSTEXPR
   static inline long double dummy_precision() { return 1e-15l; }
 };
 
 template<typename _Real> struct NumTraits<std::complex<_Real> >
   : GenericNumTraits<std::complex<_Real> >
 {
   typedef _Real Real;
@@ -219,19 +261,19 @@
     IsComplex = 1,
     RequireInitialization = NumTraits<_Real>::RequireInitialization,
     ReadCost = 2 * NumTraits<_Real>::ReadCost,
     AddCost = 2 * NumTraits<Real>::AddCost,
     MulCost = 4 * NumTraits<Real>::MulCost + 2 * NumTraits<Real>::AddCost
   };
 
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static inline Real epsilon() { return NumTraits<Real>::epsilon(); }
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static inline Real dummy_precision() { return NumTraits<Real>::dummy_precision(); }
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static inline int digits10() { return NumTraits<Real>::digits10(); }
 };
 
 template<typename Scalar, int Rows, int Cols, int Options, int MaxRows, int MaxCols>
 struct NumTraits<Array<Scalar, Rows, Cols, Options, MaxRows, MaxCols> >
 {
   typedef Array<Scalar, Rows, Cols, Options, MaxRows, MaxCols> ArrayType;
@@ -243,37 +285,39 @@
   typedef typename NumTraits<Scalar>::Literal Literal;
 
   enum {
     IsComplex = NumTraits<Scalar>::IsComplex,
     IsInteger = NumTraits<Scalar>::IsInteger,
     IsSigned  = NumTraits<Scalar>::IsSigned,
     RequireInitialization = 1,
-    ReadCost = ArrayType::SizeAtCompileTime==Dynamic ? HugeCost : ArrayType::SizeAtCompileTime * NumTraits<Scalar>::ReadCost,
-    AddCost  = ArrayType::SizeAtCompileTime==Dynamic ? HugeCost : ArrayType::SizeAtCompileTime * NumTraits<Scalar>::AddCost,
-    MulCost  = ArrayType::SizeAtCompileTime==Dynamic ? HugeCost : ArrayType::SizeAtCompileTime * NumTraits<Scalar>::MulCost
+    ReadCost = ArrayType::SizeAtCompileTime==Dynamic ? HugeCost : ArrayType::SizeAtCompileTime * int(NumTraits<Scalar>::ReadCost),
+    AddCost  = ArrayType::SizeAtCompileTime==Dynamic ? HugeCost : ArrayType::SizeAtCompileTime * int(NumTraits<Scalar>::AddCost),
+    MulCost  = ArrayType::SizeAtCompileTime==Dynamic ? HugeCost : ArrayType::SizeAtCompileTime * int(NumTraits<Scalar>::MulCost)
   };
 
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static inline RealScalar epsilon() { return NumTraits<RealScalar>::epsilon(); }
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static inline RealScalar dummy_precision() { return NumTraits<RealScalar>::dummy_precision(); }
 
+  EIGEN_CONSTEXPR
   static inline int digits10() { return NumTraits<Scalar>::digits10(); }
 };
 
 template<> struct NumTraits<std::string>
   : GenericNumTraits<std::string>
 {
   enum {
     RequireInitialization = 1,
     ReadCost = HugeCost,
     AddCost  = HugeCost,
     MulCost  = HugeCost
   };
 
+  EIGEN_CONSTEXPR
   static inline int digits10() { return 0; }
 
 private:
   static inline std::string epsilon();
   static inline std::string dummy_precision();
   static inline std::string lowest();
   static inline std::string highest();
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/PartialReduxEvaluator.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/PartialReduxEvaluator.h`

 * *Files 1% similar despite different names*

```diff
@@ -141,15 +141,15 @@
   enum {
     TraversalSize = Direction==int(Vertical) ? int(ArgType::RowsAtCompileTime) :  int(ArgType::ColsAtCompileTime)
   };
   typedef typename MemberOp::template Cost<int(TraversalSize)> CostOpType;
   enum {
     CoeffReadCost = TraversalSize==Dynamic ? HugeCost
                   : TraversalSize==0 ? 1
-                  : TraversalSize * evaluator<ArgType>::CoeffReadCost + int(CostOpType::value),
+                  : int(TraversalSize) * int(evaluator<ArgType>::CoeffReadCost) + int(CostOpType::value),
     
     _ArgFlags = evaluator<ArgType>::Flags,
 
     _Vectorizable =  bool(int(_ArgFlags)&PacketAccessBit)
                   && bool(MemberOp::Vectorizable)
                   && (Direction==int(Vertical) ? bool(_ArgFlags&RowMajorBit) : (_ArgFlags&RowMajorBit)==0)
                   && (TraversalSize!=0),
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/PermutationMatrix.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/PermutationMatrix.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/PlainObjectBase.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/PlainObjectBase.h`

 * *Files 2% similar despite different names*

```diff
@@ -9,18 +9,18 @@
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_DENSESTORAGEBASE_H
 #define EIGEN_DENSESTORAGEBASE_H
 
 #if defined(EIGEN_INITIALIZE_MATRICES_BY_ZERO)
 # define EIGEN_INITIALIZE_COEFFS
-# define EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED for(int i=0;i<base().size();++i) coeffRef(i)=Scalar(0);
+# define EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED for(Index i=0;i<base().size();++i) coeffRef(i)=Scalar(0);
 #elif defined(EIGEN_INITIALIZE_MATRICES_BY_NAN)
 # define EIGEN_INITIALIZE_COEFFS
-# define EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED for(int i=0;i<base().size();++i) coeffRef(i)=std::numeric_limits<Scalar>::quiet_NaN();
+# define EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED for(Index i=0;i<base().size();++i) coeffRef(i)=std::numeric_limits<Scalar>::quiet_NaN();
 #else
 # undef EIGEN_INITIALIZE_COEFFS
 # define EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED
 #endif
 
 namespace Eigen {
 
@@ -114,24 +114,16 @@
     using Base::SizeAtCompileTime;
     using Base::MaxRowsAtCompileTime;
     using Base::MaxColsAtCompileTime;
     using Base::MaxSizeAtCompileTime;
     using Base::IsVectorAtCompileTime;
     using Base::Flags;
 
-    template<typename PlainObjectType, int MapOptions, typename StrideType> friend class Eigen::Map;
-    friend  class Eigen::Map<Derived, Unaligned>;
     typedef Eigen::Map<Derived, Unaligned>  MapType;
-    friend  class Eigen::Map<const Derived, Unaligned>;
     typedef const Eigen::Map<const Derived, Unaligned> ConstMapType;
-#if EIGEN_MAX_ALIGN_BYTES>0
-    // for EIGEN_MAX_ALIGN_BYTES==0, AlignedMax==Unaligned, and many compilers generate warnings for friend-ing a class twice.
-    friend  class Eigen::Map<Derived, AlignedMax>;
-    friend  class Eigen::Map<const Derived, AlignedMax>;
-#endif
     typedef Eigen::Map<Derived, AlignedMax> AlignedMapType;
     typedef const Eigen::Map<const Derived, AlignedMax> ConstAlignedMapType;
     template<typename StrideType> struct StridedMapType { typedef Eigen::Map<Derived, Unaligned, StrideType> type; };
     template<typename StrideType> struct StridedConstMapType { typedef Eigen::Map<const Derived, Unaligned, StrideType> type; };
     template<typename StrideType> struct StridedAlignedMapType { typedef Eigen::Map<Derived, AlignedMax, StrideType> type; };
     template<typename StrideType> struct StridedConstAlignedMapType { typedef Eigen::Map<const Derived, AlignedMax, StrideType> type; };
 
@@ -143,18 +135,18 @@
     EIGEN_MAKE_ALIGNED_OPERATOR_NEW_IF(NeedsToAlign)
 
     EIGEN_DEVICE_FUNC
     Base& base() { return *static_cast<Base*>(this); }
     EIGEN_DEVICE_FUNC
     const Base& base() const { return *static_cast<const Base*>(this); }
 
-    EIGEN_DEVICE_FUNC
-    EIGEN_STRONG_INLINE Index rows() const { return m_storage.rows(); }
-    EIGEN_DEVICE_FUNC
-    EIGEN_STRONG_INLINE Index cols() const { return m_storage.cols(); }
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    Index rows() const EIGEN_NOEXCEPT { return m_storage.rows(); }
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    Index cols() const EIGEN_NOEXCEPT { return m_storage.cols(); }
 
     /** This is an overloaded version of DenseCoeffsBase<Derived,ReadOnlyAccessors>::coeff(Index,Index) const
       * provided to by-pass the creation of an evaluator of the expression, thus saving compilation efforts.
       *
       * See DenseCoeffsBase<Derived,ReadOnlyAccessors>::coeff(Index) const for details. */
     EIGEN_DEVICE_FUNC
     EIGEN_STRONG_INLINE const Scalar& coeff(Index rowId, Index colId) const
@@ -504,16 +496,16 @@
       : m_storage( std::move(other.m_storage) )
     {
     }
 
     EIGEN_DEVICE_FUNC
     PlainObjectBase& operator=(PlainObjectBase&& other) EIGEN_NOEXCEPT
     {
-      using std::swap;
-      swap(m_storage, other.m_storage);
+      _check_template_params();
+      m_storage = std::move(other.m_storage);
       return *this;
     }
 #endif
 
     /** Copy constructor */
     EIGEN_DEVICE_FUNC
     EIGEN_STRONG_INLINE PlainObjectBase(const PlainObjectBase& other)
@@ -526,33 +518,33 @@
 //       EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED
     }
 
     #if EIGEN_HAS_CXX11
     /** \brief Construct a row of column vector with fixed size from an arbitrary number of coefficients. \cpp11
       *
       * \only_for_vectors
-      * 
+      *
       * This constructor is for 1D array or vectors with more than 4 coefficients.
       * There exists C++98 analogue constructors for fixed-size array/vector having 1, 2, 3, or 4 coefficients.
-      * 
-      * \warning To construct a column (resp. row) vector of fixed length, the number of values passed to this 
+      *
+      * \warning To construct a column (resp. row) vector of fixed length, the number of values passed to this
       * constructor must match the the fixed number of rows (resp. columns) of \c *this.
       */
     template <typename... ArgTypes>
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
     PlainObjectBase(const Scalar& a0, const Scalar& a1, const Scalar& a2,  const Scalar& a3, const ArgTypes&... args)
       : m_storage()
     {
       _check_template_params();
       EIGEN_STATIC_ASSERT_VECTOR_SPECIFIC_SIZE(PlainObjectBase, sizeof...(args) + 4);
       m_storage.data()[0] = a0;
       m_storage.data()[1] = a1;
       m_storage.data()[2] = a2;
       m_storage.data()[3] = a3;
-      int i = 4;
+      Index i = 4;
       auto x = {(m_storage.data()[i++] = args, 0)...};
       static_cast<void>(x);
     }
 
     /** \brief Constructs a Matrix or Array and initializes it by elements given by an initializer list of initializer
       * lists \cpp11
       */
@@ -572,15 +564,15 @@
         eigen_assert(list_size == static_cast<size_t>(RowsAtCompileTime) || RowsAtCompileTime == Dynamic);
         resize(list_size, ColsAtCompileTime);
         std::copy(list.begin()->begin(), list.begin()->end(), m_storage.data());
       } else {
         eigen_assert(list.size() == static_cast<size_t>(RowsAtCompileTime) || RowsAtCompileTime == Dynamic);
         eigen_assert(list_size == static_cast<size_t>(ColsAtCompileTime) || ColsAtCompileTime == Dynamic);
         resize(list.size(), list_size);
-       
+
         Index row_index = 0;
         for (const std::initializer_list<Scalar>& row : list) {
           eigen_assert(list_size == row.size());
           Index col_index = 0;
           for (const Scalar& e : row) {
             coeffRef(row_index, col_index) = e;
             ++col_index;
@@ -713,26 +705,34 @@
     static inline typename StridedAlignedMapType<Stride<Outer, Inner> >::type MapAligned(Scalar* data, Index rows, Index cols, const Stride<Outer, Inner>& stride)
     { return typename StridedAlignedMapType<Stride<Outer, Inner> >::type(data, rows, cols, stride); }
     //@}
 
     using Base::setConstant;
     EIGEN_DEVICE_FUNC Derived& setConstant(Index size, const Scalar& val);
     EIGEN_DEVICE_FUNC Derived& setConstant(Index rows, Index cols, const Scalar& val);
+    EIGEN_DEVICE_FUNC Derived& setConstant(NoChange_t, Index cols, const Scalar& val);
+    EIGEN_DEVICE_FUNC Derived& setConstant(Index rows, NoChange_t, const Scalar& val);
 
     using Base::setZero;
     EIGEN_DEVICE_FUNC Derived& setZero(Index size);
     EIGEN_DEVICE_FUNC Derived& setZero(Index rows, Index cols);
+    EIGEN_DEVICE_FUNC Derived& setZero(NoChange_t, Index cols);
+    EIGEN_DEVICE_FUNC Derived& setZero(Index rows, NoChange_t);
 
     using Base::setOnes;
     EIGEN_DEVICE_FUNC Derived& setOnes(Index size);
     EIGEN_DEVICE_FUNC Derived& setOnes(Index rows, Index cols);
+    EIGEN_DEVICE_FUNC Derived& setOnes(NoChange_t, Index cols);
+    EIGEN_DEVICE_FUNC Derived& setOnes(Index rows, NoChange_t);
 
     using Base::setRandom;
     Derived& setRandom(Index size);
     Derived& setRandom(Index rows, Index cols);
+    Derived& setRandom(NoChange_t, Index cols);
+    Derived& setRandom(Index rows, NoChange_t);
 
     #ifdef EIGEN_PLAINOBJECTBASE_PLUGIN
     #include EIGEN_PLAINOBJECTBASE_PLUGIN
     #endif
 
   protected:
     /** \internal Resizes *this in preparation for assigning \a other to it.
@@ -963,28 +963,39 @@
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
     void swap(DenseBase<OtherDerived> const & other)
     { Base::swap(other.derived()); }
 
     EIGEN_DEVICE_FUNC
     static EIGEN_STRONG_INLINE void _check_template_params()
     {
-      EIGEN_STATIC_ASSERT((EIGEN_IMPLIES(MaxRowsAtCompileTime==1 && MaxColsAtCompileTime!=1, (Options&RowMajor)==RowMajor)
-                        && EIGEN_IMPLIES(MaxColsAtCompileTime==1 && MaxRowsAtCompileTime!=1, (Options&RowMajor)==0)
+      EIGEN_STATIC_ASSERT((EIGEN_IMPLIES(MaxRowsAtCompileTime==1 && MaxColsAtCompileTime!=1, (int(Options)&RowMajor)==RowMajor)
+                        && EIGEN_IMPLIES(MaxColsAtCompileTime==1 && MaxRowsAtCompileTime!=1, (int(Options)&RowMajor)==0)
                         && ((RowsAtCompileTime == Dynamic) || (RowsAtCompileTime >= 0))
                         && ((ColsAtCompileTime == Dynamic) || (ColsAtCompileTime >= 0))
                         && ((MaxRowsAtCompileTime == Dynamic) || (MaxRowsAtCompileTime >= 0))
                         && ((MaxColsAtCompileTime == Dynamic) || (MaxColsAtCompileTime >= 0))
                         && (MaxRowsAtCompileTime == RowsAtCompileTime || RowsAtCompileTime==Dynamic)
                         && (MaxColsAtCompileTime == ColsAtCompileTime || ColsAtCompileTime==Dynamic)
                         && (Options & (DontAlign|RowMajor)) == Options),
         INVALID_MATRIX_TEMPLATE_PARAMETERS)
     }
 
     enum { IsPlainObjectBase = 1 };
 #endif
+  public:
+    // These apparently need to be down here for nvcc+icc to prevent duplicate
+    // Map symbol.
+    template<typename PlainObjectType, int MapOptions, typename StrideType> friend class Eigen::Map;
+    friend class Eigen::Map<Derived, Unaligned>;
+    friend class Eigen::Map<const Derived, Unaligned>;
+#if EIGEN_MAX_ALIGN_BYTES>0
+    // for EIGEN_MAX_ALIGN_BYTES==0, AlignedMax==Unaligned, and many compilers generate warnings for friend-ing a class twice.
+    friend class Eigen::Map<Derived, AlignedMax>;
+    friend class Eigen::Map<const Derived, AlignedMax>;
+#endif
 };
 
 namespace internal {
 
 template <typename Derived, typename OtherDerived, bool IsVector>
 struct conservative_resize_like_impl
 {
@@ -1004,15 +1015,15 @@
     {
       internal::check_rows_cols_for_overflow<Derived::MaxSizeAtCompileTime>::run(rows, cols);
       _this.derived().m_storage.conservativeResize(rows*cols,rows,cols);
     }
     else
     {
       // The storage order does not allow us to use reallocation.
-      typename Derived::PlainObject tmp(rows,cols);
+      Derived tmp(rows,cols);
       const Index common_rows = numext::mini(rows, _this.rows());
       const Index common_cols = numext::mini(cols, _this.cols());
       tmp.block(0,0,common_rows,common_cols) = _this.block(0,0,common_rows,common_cols);
       _this.derived().swap(tmp);
     }
   }
 
@@ -1039,15 +1050,15 @@
         _this.bottomRightCorner(new_rows, other.cols()) = other.bottomRows(new_rows);
       else if (new_cols>0)
         _this.bottomRightCorner(other.rows(), new_cols) = other.rightCols(new_cols);
     }
     else
     {
       // The storage order does not allow us to use reallocation.
-      typename Derived::PlainObject tmp(other);
+      Derived tmp(other);
       const Index common_rows = numext::mini(tmp.rows(), _this.rows());
       const Index common_cols = numext::mini(tmp.cols(), _this.cols());
       tmp.block(0,0,common_rows,common_cols) = _this.block(0,0,common_rows,common_cols);
       _this.derived().swap(tmp);
     }
   }
 };
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Product.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Product.h`

 * *Files 6% similar despite different names*

```diff
@@ -19,33 +19,33 @@
 template<typename Lhs, typename Rhs, int Option>
 struct traits<Product<Lhs, Rhs, Option> >
 {
   typedef typename remove_all<Lhs>::type LhsCleaned;
   typedef typename remove_all<Rhs>::type RhsCleaned;
   typedef traits<LhsCleaned> LhsTraits;
   typedef traits<RhsCleaned> RhsTraits;
-  
+
   typedef MatrixXpr XprKind;
-  
+
   typedef typename ScalarBinaryOpTraits<typename traits<LhsCleaned>::Scalar, typename traits<RhsCleaned>::Scalar>::ReturnType Scalar;
   typedef typename product_promote_storage_type<typename LhsTraits::StorageKind,
                                                 typename RhsTraits::StorageKind,
                                                 internal::product_type<Lhs,Rhs>::ret>::ret StorageKind;
   typedef typename promote_index_type<typename LhsTraits::StorageIndex,
                                       typename RhsTraits::StorageIndex>::type StorageIndex;
-  
+
   enum {
     RowsAtCompileTime    = LhsTraits::RowsAtCompileTime,
     ColsAtCompileTime    = RhsTraits::ColsAtCompileTime,
     MaxRowsAtCompileTime = LhsTraits::MaxRowsAtCompileTime,
     MaxColsAtCompileTime = RhsTraits::MaxColsAtCompileTime,
-    
+
     // FIXME: only needed by GeneralMatrixMatrixTriangular
     InnerSize = EIGEN_SIZE_MIN_PREFER_FIXED(LhsTraits::ColsAtCompileTime, RhsTraits::RowsAtCompileTime),
-    
+
     // The storage order is somewhat arbitrary here. The correct one will be determined through the evaluator.
     Flags = (MaxRowsAtCompileTime==1 && MaxColsAtCompileTime!=1) ? RowMajorBit
           : (MaxColsAtCompileTime==1 && MaxRowsAtCompileTime!=1) ? 0
           : (   ((LhsTraits::Flags&NoPreferredStorageOrderBit) && (RhsTraits::Flags&RowMajorBit))
              || ((RhsTraits::Flags&NoPreferredStorageOrderBit) && (LhsTraits::Flags&RowMajorBit)) ) ? RowMajorBit
           : NoPreferredStorageOrderBit
   };
@@ -70,18 +70,18 @@
 template<typename _Lhs, typename _Rhs, int Option>
 class Product : public ProductImpl<_Lhs,_Rhs,Option,
                                    typename internal::product_promote_storage_type<typename internal::traits<_Lhs>::StorageKind,
                                                                                    typename internal::traits<_Rhs>::StorageKind,
                                                                                    internal::product_type<_Lhs,_Rhs>::ret>::ret>
 {
   public:
-    
+
     typedef _Lhs Lhs;
     typedef _Rhs Rhs;
-    
+
     typedef typename ProductImpl<
         Lhs, Rhs, Option,
         typename internal::product_promote_storage_type<typename internal::traits<Lhs>::StorageKind,
                                                         typename internal::traits<Rhs>::StorageKind,
                                                         internal::product_type<Lhs,Rhs>::ret>::ret>::Base Base;
     EIGEN_GENERIC_PUBLIC_INTERFACE(Product)
 
@@ -94,32 +94,32 @@
     Product(const Lhs& lhs, const Rhs& rhs) : m_lhs(lhs), m_rhs(rhs)
     {
       eigen_assert(lhs.cols() == rhs.rows()
         && "invalid matrix product"
         && "if you wanted a coeff-wise or a dot product use the respective explicit functions");
     }
 
-    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    Index rows() const { return m_lhs.rows(); }
-    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    Index cols() const { return m_rhs.cols(); }
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    Index rows() const EIGEN_NOEXCEPT { return m_lhs.rows(); }
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    Index cols() const EIGEN_NOEXCEPT { return m_rhs.cols(); }
 
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
     const LhsNestedCleaned& lhs() const { return m_lhs; }
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
     const RhsNestedCleaned& rhs() const { return m_rhs; }
 
   protected:
 
     LhsNested m_lhs;
     RhsNested m_rhs;
 };
 
 namespace internal {
-  
+
 template<typename Lhs, typename Rhs, int Option, int ProductTag = internal::product_type<Lhs,Rhs>::ret>
 class dense_product_base
  : public internal::dense_xpr_base<Product<Lhs,Rhs,Option> >::type
 {};
 
 /** Conversion to scalar for inner-products */
 template<typename Lhs, typename Rhs, int Option>
@@ -127,15 +127,15 @@
  : public internal::dense_xpr_base<Product<Lhs,Rhs,Option> >::type
 {
   typedef Product<Lhs,Rhs,Option> ProductXpr;
   typedef typename internal::dense_xpr_base<ProductXpr>::type Base;
 public:
   using Base::derived;
   typedef typename Base::Scalar Scalar;
-  
+
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE operator const Scalar() const
   {
     return internal::evaluator<ProductXpr>(derived()).coeff(0,0);
   }
 };
 
 } // namespace internal
@@ -149,43 +149,43 @@
 };
 
 template<typename Lhs, typename Rhs, int Option>
 class ProductImpl<Lhs,Rhs,Option,Dense>
   : public internal::dense_product_base<Lhs,Rhs,Option>
 {
     typedef Product<Lhs, Rhs, Option> Derived;
-    
+
   public:
-    
+
     typedef typename internal::dense_product_base<Lhs, Rhs, Option> Base;
     EIGEN_DENSE_PUBLIC_INTERFACE(Derived)
   protected:
     enum {
-      IsOneByOne = (RowsAtCompileTime == 1 || RowsAtCompileTime == Dynamic) && 
+      IsOneByOne = (RowsAtCompileTime == 1 || RowsAtCompileTime == Dynamic) &&
                    (ColsAtCompileTime == 1 || ColsAtCompileTime == Dynamic),
       EnableCoeff = IsOneByOne || Option==LazyProduct
     };
-    
+
   public:
-  
+
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar coeff(Index row, Index col) const
     {
       EIGEN_STATIC_ASSERT(EnableCoeff, THIS_METHOD_IS_ONLY_FOR_INNER_OR_LAZY_PRODUCTS);
       eigen_assert( (Option==LazyProduct) || (this->rows() == 1 && this->cols() == 1) );
-      
+
       return internal::evaluator<Derived>(derived()).coeff(row,col);
     }
 
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar coeff(Index i) const
     {
       EIGEN_STATIC_ASSERT(EnableCoeff, THIS_METHOD_IS_ONLY_FOR_INNER_OR_LAZY_PRODUCTS);
       eigen_assert( (Option==LazyProduct) || (this->rows() == 1 && this->cols() == 1) );
-      
+
       return internal::evaluator<Derived>(derived()).coeff(i);
     }
-    
-  
+
+
 };
 
 } // end namespace Eigen
 
 #endif // EIGEN_PRODUCT_H
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/ProductEvaluators.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/ProductEvaluators.h`

 * *Files 2% similar despite different names*

```diff
@@ -10,35 +10,35 @@
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 
 #ifndef EIGEN_PRODUCTEVALUATORS_H
 #define EIGEN_PRODUCTEVALUATORS_H
 
 namespace Eigen {
-  
+
 namespace internal {
 
 /** \internal
   * Evaluator of a product expression.
   * Since products require special treatments to handle all possible cases,
   * we simply defer the evaluation logic to a product_evaluator class
   * which offers more partial specialization possibilities.
-  * 
+  *
   * \sa class product_evaluator
   */
 template<typename Lhs, typename Rhs, int Options>
-struct evaluator<Product<Lhs, Rhs, Options> > 
+struct evaluator<Product<Lhs, Rhs, Options> >
  : public product_evaluator<Product<Lhs, Rhs, Options> >
 {
   typedef Product<Lhs, Rhs, Options> XprType;
   typedef product_evaluator<XprType> Base;
-  
+
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit evaluator(const XprType& xpr) : Base(xpr) {}
 };
- 
+
 // Catch "scalar * ( A * B )" and transform it to "(A*scalar) * B"
 // TODO we should apply that rule only if that's really helpful
 template<typename Lhs, typename Rhs, typename Scalar1, typename Scalar2, typename Plain1>
 struct evaluator_assume_aliasing<CwiseBinaryOp<internal::scalar_product_op<Scalar1,Scalar2>,
                                                const CwiseNullaryOp<internal::scalar_constant_op<Scalar1>, Plain1>,
                                                const Product<Lhs, Rhs, DefaultProduct> > >
 {
@@ -58,20 +58,20 @@
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit evaluator(const XprType& xpr)
     : Base(xpr.lhs().functor().m_other * xpr.rhs().lhs() * xpr.rhs().rhs())
   {}
 };
 
 
 template<typename Lhs, typename Rhs, int DiagIndex>
-struct evaluator<Diagonal<const Product<Lhs, Rhs, DefaultProduct>, DiagIndex> > 
+struct evaluator<Diagonal<const Product<Lhs, Rhs, DefaultProduct>, DiagIndex> >
  : public evaluator<Diagonal<const Product<Lhs, Rhs, LazyProduct>, DiagIndex> >
 {
   typedef Diagonal<const Product<Lhs, Rhs, DefaultProduct>, DiagIndex> XprType;
   typedef evaluator<Diagonal<const Product<Lhs, Rhs, LazyProduct>, DiagIndex> > Base;
-  
+
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit evaluator(const XprType& xpr)
     : Base(Diagonal<const Product<Lhs, Rhs, LazyProduct>, DiagIndex>(
         Product<Lhs, Rhs, LazyProduct>(xpr.nestedExpression().lhs(), xpr.nestedExpression().rhs()),
         xpr.index() ))
   {}
 };
 
@@ -104,31 +104,31 @@
   };
 
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   explicit product_evaluator(const XprType& xpr)
     : m_result(xpr.rows(), xpr.cols())
   {
     ::new (static_cast<Base*>(this)) Base(m_result);
-    
+
 // FIXME shall we handle nested_eval here?,
 // if so, then we must take care at removing the call to nested_eval in the specializations (e.g., in permutation_matrix_product, transposition_matrix_product, etc.)
 //     typedef typename internal::nested_eval<Lhs,Rhs::ColsAtCompileTime>::type LhsNested;
 //     typedef typename internal::nested_eval<Rhs,Lhs::RowsAtCompileTime>::type RhsNested;
 //     typedef typename internal::remove_all<LhsNested>::type LhsNestedCleaned;
 //     typedef typename internal::remove_all<RhsNested>::type RhsNestedCleaned;
-//     
+//
 //     const LhsNested lhs(xpr.lhs());
 //     const RhsNested rhs(xpr.rhs());
-//   
+//
 //     generic_product_impl<LhsNestedCleaned, RhsNestedCleaned>::evalTo(m_result, lhs, rhs);
 
     generic_product_impl<Lhs, Rhs, LhsShape, RhsShape, ProductTag>::evalTo(m_result, xpr.lhs(), xpr.rhs());
   }
-  
-protected:  
+
+protected:
   PlainObject m_result;
 };
 
 // The following three shortcuts are enabled only if the scalar types match exactly.
 // TODO: we could enable them for different scalar types when the product is not vectorized.
 
 // Dense = Product
@@ -246,21 +246,21 @@
 struct generic_product_impl<Lhs,Rhs,DenseShape,DenseShape,InnerProduct>
 {
   template<typename Dst>
   static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void evalTo(Dst& dst, const Lhs& lhs, const Rhs& rhs)
   {
     dst.coeffRef(0,0) = (lhs.transpose().cwiseProduct(rhs)).sum();
   }
-  
+
   template<typename Dst>
   static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void addTo(Dst& dst, const Lhs& lhs, const Rhs& rhs)
   {
     dst.coeffRef(0,0) += (lhs.transpose().cwiseProduct(rhs)).sum();
   }
-  
+
   template<typename Dst>
   static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void subTo(Dst& dst, const Lhs& lhs, const Rhs& rhs)
   { dst.coeffRef(0,0) -= (lhs.transpose().cwiseProduct(rhs)).sum(); }
 };
 
 
 /***********************************************************************
@@ -294,72 +294,72 @@
 }
 
 template<typename Lhs, typename Rhs>
 struct generic_product_impl<Lhs,Rhs,DenseShape,DenseShape,OuterProduct>
 {
   template<typename T> struct is_row_major : internal::conditional<(int(T::Flags)&RowMajorBit), internal::true_type, internal::false_type>::type {};
   typedef typename Product<Lhs,Rhs>::Scalar Scalar;
-  
+
   // TODO it would be nice to be able to exploit our *_assign_op functors for that purpose
   struct set  { template<typename Dst, typename Src> EIGEN_DEVICE_FUNC void operator()(const Dst& dst, const Src& src) const { dst.const_cast_derived()  = src; } };
   struct add  { template<typename Dst, typename Src> EIGEN_DEVICE_FUNC void operator()(const Dst& dst, const Src& src) const { dst.const_cast_derived() += src; } };
   struct sub  { template<typename Dst, typename Src> EIGEN_DEVICE_FUNC void operator()(const Dst& dst, const Src& src) const { dst.const_cast_derived() -= src; } };
   struct adds {
     Scalar m_scale;
     explicit adds(const Scalar& s) : m_scale(s) {}
     template<typename Dst, typename Src> void EIGEN_DEVICE_FUNC operator()(const Dst& dst, const Src& src) const {
       dst.const_cast_derived() += m_scale * src;
     }
   };
-  
+
   template<typename Dst>
   static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void evalTo(Dst& dst, const Lhs& lhs, const Rhs& rhs)
   {
     internal::outer_product_selector_run(dst, lhs, rhs, set(), is_row_major<Dst>());
   }
-  
+
   template<typename Dst>
   static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void addTo(Dst& dst, const Lhs& lhs, const Rhs& rhs)
   {
     internal::outer_product_selector_run(dst, lhs, rhs, add(), is_row_major<Dst>());
   }
-  
+
   template<typename Dst>
   static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void subTo(Dst& dst, const Lhs& lhs, const Rhs& rhs)
   {
     internal::outer_product_selector_run(dst, lhs, rhs, sub(), is_row_major<Dst>());
   }
-  
+
   template<typename Dst>
   static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void scaleAndAddTo(Dst& dst, const Lhs& lhs, const Rhs& rhs, const Scalar& alpha)
   {
     internal::outer_product_selector_run(dst, lhs, rhs, adds(alpha), is_row_major<Dst>());
   }
-  
+
 };
 
 
 // This base class provides default implementations for evalTo, addTo, subTo, in terms of scaleAndAddTo
 template<typename Lhs, typename Rhs, typename Derived>
 struct generic_product_impl_base
 {
   typedef typename Product<Lhs,Rhs>::Scalar Scalar;
-  
+
   template<typename Dst>
   static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void evalTo(Dst& dst, const Lhs& lhs, const Rhs& rhs)
   { dst.setZero(); scaleAndAddTo(dst, lhs, rhs, Scalar(1)); }
 
   template<typename Dst>
   static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void addTo(Dst& dst, const Lhs& lhs, const Rhs& rhs)
   { scaleAndAddTo(dst,lhs, rhs, Scalar(1)); }
 
   template<typename Dst>
   static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void subTo(Dst& dst, const Lhs& lhs, const Rhs& rhs)
   { scaleAndAddTo(dst, lhs, rhs, Scalar(-1)); }
-  
+
   template<typename Dst>
   static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void scaleAndAddTo(Dst& dst, const Lhs& lhs, const Rhs& rhs, const Scalar& alpha)
   { Derived::scaleAndAddTo(dst,lhs,rhs,alpha); }
 
 };
 
 template<typename Lhs, typename Rhs>
@@ -371,43 +371,48 @@
   typedef typename Product<Lhs,Rhs>::Scalar Scalar;
   enum { Side = Lhs::IsVectorAtCompileTime ? OnTheLeft : OnTheRight };
   typedef typename internal::remove_all<typename internal::conditional<int(Side)==OnTheRight,LhsNested,RhsNested>::type>::type MatrixType;
 
   template<typename Dest>
   static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void scaleAndAddTo(Dest& dst, const Lhs& lhs, const Rhs& rhs, const Scalar& alpha)
   {
+    // Fallback to inner product if both the lhs and rhs is a runtime vector.
+    if (lhs.rows() == 1 && rhs.cols() == 1) {
+      dst.coeffRef(0,0) += alpha * lhs.row(0).conjugate().dot(rhs.col(0));
+      return;
+    }
     LhsNested actual_lhs(lhs);
     RhsNested actual_rhs(rhs);
     internal::gemv_dense_selector<Side,
                             (int(MatrixType::Flags)&RowMajorBit) ? RowMajor : ColMajor,
                             bool(internal::blas_traits<MatrixType>::HasUsableDirectAccess)
                            >::run(actual_lhs, actual_rhs, dst, alpha);
   }
 };
 
 template<typename Lhs, typename Rhs>
-struct generic_product_impl<Lhs,Rhs,DenseShape,DenseShape,CoeffBasedProductMode> 
+struct generic_product_impl<Lhs,Rhs,DenseShape,DenseShape,CoeffBasedProductMode>
 {
   typedef typename Product<Lhs,Rhs>::Scalar Scalar;
-  
+
   template<typename Dst>
   static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void evalTo(Dst& dst, const Lhs& lhs, const Rhs& rhs)
   {
     // Same as: dst.noalias() = lhs.lazyProduct(rhs);
     // but easier on the compiler side
     call_assignment_no_alias(dst, lhs.lazyProduct(rhs), internal::assign_op<typename Dst::Scalar,Scalar>());
   }
 
   template<typename Dst>
   static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void addTo(Dst& dst, const Lhs& lhs, const Rhs& rhs)
   {
     // dst.noalias() += lhs.lazyProduct(rhs);
     call_assignment_no_alias(dst, lhs.lazyProduct(rhs), internal::add_assign_op<typename Dst::Scalar,Scalar>());
   }
-  
+
   template<typename Dst>
   static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void subTo(Dst& dst, const Lhs& lhs, const Rhs& rhs)
   {
     // dst.noalias() -= lhs.lazyProduct(rhs);
     call_assignment_no_alias(dst, lhs.lazyProduct(rhs), internal::sub_assign_op<typename Dst::Scalar,Scalar>());
   }
 
@@ -432,16 +437,16 @@
     enum {
       HasScalarFactor = blas_traits<Lhs>::HasScalarFactor || blas_traits<Rhs>::HasScalarFactor,
       ConjLhs = blas_traits<Lhs>::NeedToConjugate,
       ConjRhs = blas_traits<Rhs>::NeedToConjugate
     };
     // FIXME: in c++11 this should be auto, and extractScalarFactor should also return auto
     //        this is important for real*complex_mat
-    Scalar actualAlpha =    blas_traits<Lhs>::extractScalarFactor(lhs)
-                          * blas_traits<Rhs>::extractScalarFactor(rhs);
+    Scalar actualAlpha = combine_scalar_factors<Scalar>(lhs, rhs);
+
     eval_dynamic_impl(dst,
                       blas_traits<Lhs>::extract(lhs).template conjugateIf<ConjLhs>(),
                       blas_traits<Rhs>::extract(rhs).template conjugateIf<ConjRhs>(),
                       func,
                       actualAlpha,
                       typename conditional<HasScalarFactor,true_type,false_type>::type());
   }
@@ -516,15 +521,15 @@
 #endif
   }
 
   // Everything below here is taken from CoeffBasedProduct.h
 
   typedef typename internal::nested_eval<Lhs,Rhs::ColsAtCompileTime>::type LhsNested;
   typedef typename internal::nested_eval<Rhs,Lhs::RowsAtCompileTime>::type RhsNested;
-  
+
   typedef typename internal::remove_all<LhsNested>::type LhsNestedCleaned;
   typedef typename internal::remove_all<RhsNested>::type RhsNestedCleaned;
 
   typedef evaluator<LhsNestedCleaned> LhsEtorType;
   typedef evaluator<RhsNestedCleaned> RhsEtorType;
 
   enum {
@@ -535,52 +540,52 @@
     MaxColsAtCompileTime = RhsNestedCleaned::MaxColsAtCompileTime
   };
 
   typedef typename find_best_packet<Scalar,RowsAtCompileTime>::type LhsVecPacketType;
   typedef typename find_best_packet<Scalar,ColsAtCompileTime>::type RhsVecPacketType;
 
   enum {
-      
+
     LhsCoeffReadCost = LhsEtorType::CoeffReadCost,
     RhsCoeffReadCost = RhsEtorType::CoeffReadCost,
     CoeffReadCost = InnerSize==0 ? NumTraits<Scalar>::ReadCost
                   : InnerSize == Dynamic ? HugeCost
-                  : InnerSize * (NumTraits<Scalar>::MulCost + LhsCoeffReadCost + RhsCoeffReadCost)
+                    : InnerSize * (NumTraits<Scalar>::MulCost + int(LhsCoeffReadCost) + int(RhsCoeffReadCost))
                     + (InnerSize - 1) * NumTraits<Scalar>::AddCost,
 
     Unroll = CoeffReadCost <= EIGEN_UNROLLING_LIMIT,
-    
+
     LhsFlags = LhsEtorType::Flags,
     RhsFlags = RhsEtorType::Flags,
-    
+
     LhsRowMajor = LhsFlags & RowMajorBit,
     RhsRowMajor = RhsFlags & RowMajorBit,
 
     LhsVecPacketSize = unpacket_traits<LhsVecPacketType>::size,
     RhsVecPacketSize = unpacket_traits<RhsVecPacketType>::size,
 
     // Here, we don't care about alignment larger than the usable packet size.
     LhsAlignment = EIGEN_PLAIN_ENUM_MIN(LhsEtorType::Alignment,LhsVecPacketSize*int(sizeof(typename LhsNestedCleaned::Scalar))),
     RhsAlignment = EIGEN_PLAIN_ENUM_MIN(RhsEtorType::Alignment,RhsVecPacketSize*int(sizeof(typename RhsNestedCleaned::Scalar))),
-      
+
     SameType = is_same<typename LhsNestedCleaned::Scalar,typename RhsNestedCleaned::Scalar>::value,
 
     CanVectorizeRhs = bool(RhsRowMajor) && (RhsFlags & PacketAccessBit) && (ColsAtCompileTime!=1),
     CanVectorizeLhs = (!LhsRowMajor) && (LhsFlags & PacketAccessBit) && (RowsAtCompileTime!=1),
 
     EvalToRowMajor = (MaxRowsAtCompileTime==1&&MaxColsAtCompileTime!=1) ? 1
                     : (MaxColsAtCompileTime==1&&MaxRowsAtCompileTime!=1) ? 0
                     : (bool(RhsRowMajor) && !CanVectorizeLhs),
 
-    Flags = ((unsigned int)(LhsFlags | RhsFlags) & HereditaryBits & ~RowMajorBit)
+    Flags = ((int(LhsFlags) | int(RhsFlags)) & HereditaryBits & ~RowMajorBit)
           | (EvalToRowMajor ? RowMajorBit : 0)
           // TODO enable vectorization for mixed types
           | (SameType && (CanVectorizeLhs || CanVectorizeRhs) ? PacketAccessBit : 0)
           | (XprType::IsVectorAtCompileTime ? LinearAccessBit : 0),
-          
+
     LhsOuterStrideBytes = int(LhsNestedCleaned::OuterStrideAtCompileTime) * int(sizeof(typename LhsNestedCleaned::Scalar)),
     RhsOuterStrideBytes = int(RhsNestedCleaned::OuterStrideAtCompileTime) * int(sizeof(typename RhsNestedCleaned::Scalar)),
 
     Alignment = bool(CanVectorizeLhs) ? (LhsOuterStrideBytes<=0 || (int(LhsOuterStrideBytes) % EIGEN_PLAIN_ENUM_MAX(1,LhsAlignment))!=0 ? 0 : LhsAlignment)
               : bool(CanVectorizeRhs) ? (RhsOuterStrideBytes<=0 || (int(RhsOuterStrideBytes) % EIGEN_PLAIN_ENUM_MAX(1,RhsAlignment))!=0 ? 0 : RhsAlignment)
               : 0,
 
@@ -588,18 +593,18 @@
      * of Product. If the Product itself is not a packet-access expression, there is still a chance that the inner
      * loop of the product might be vectorized. This is the meaning of CanVectorizeInner. Since it doesn't affect
      * the Flags, it is safe to make this value depend on ActualPacketAccessBit, that doesn't affect the ABI.
      */
     CanVectorizeInner =    SameType
                         && LhsRowMajor
                         && (!RhsRowMajor)
-                        && (LhsFlags & RhsFlags & ActualPacketAccessBit)
-                        && (InnerSize % packet_traits<Scalar>::size == 0)
+                        && (int(LhsFlags) & int(RhsFlags) & ActualPacketAccessBit)
+                        && (int(InnerSize) % packet_traits<Scalar>::size == 0)
   };
-  
+
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const CoeffReturnType coeff(Index row, Index col) const
   {
     return (m_lhs.row(row).transpose().cwiseProduct( m_rhs.col(col) )).sum();
   }
 
   /* Allow index-based non-packet access. It is impossible though to allow index-based packed access,
    * which is why we don't set the LinearAccessBit.
@@ -633,15 +638,15 @@
     const Index col = (RowsAtCompileTime == 1 || MaxRowsAtCompileTime==1) ? index : 0;
     return packet<LoadMode,PacketType>(row,col);
   }
 
 protected:
   typename internal::add_const_on_value_type<LhsNested>::type m_lhs;
   typename internal::add_const_on_value_type<RhsNested>::type m_rhs;
-  
+
   LhsEtorType m_lhsImpl;
   RhsEtorType m_rhsImpl;
 
   // TODO: Get rid of m_innerDim if known at compile time
   Index m_innerDim;
 };
 
@@ -664,82 +669,82 @@
 /****************************************
 *** Coeff based product, Packet path  ***
 ****************************************/
 
 template<int UnrollingIndex, typename Lhs, typename Rhs, typename Packet, int LoadMode>
 struct etor_product_packet_impl<RowMajor, UnrollingIndex, Lhs, Rhs, Packet, LoadMode>
 {
-  static EIGEN_STRONG_INLINE void run(Index row, Index col, const Lhs& lhs, const Rhs& rhs, Index innerDim, Packet &res)
+  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Index row, Index col, const Lhs& lhs, const Rhs& rhs, Index innerDim, Packet &res)
   {
     etor_product_packet_impl<RowMajor, UnrollingIndex-1, Lhs, Rhs, Packet, LoadMode>::run(row, col, lhs, rhs, innerDim, res);
     res =  pmadd(pset1<Packet>(lhs.coeff(row, Index(UnrollingIndex-1))), rhs.template packet<LoadMode,Packet>(Index(UnrollingIndex-1), col), res);
   }
 };
 
 template<int UnrollingIndex, typename Lhs, typename Rhs, typename Packet, int LoadMode>
 struct etor_product_packet_impl<ColMajor, UnrollingIndex, Lhs, Rhs, Packet, LoadMode>
 {
-  static EIGEN_STRONG_INLINE void run(Index row, Index col, const Lhs& lhs, const Rhs& rhs, Index innerDim, Packet &res)
+  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Index row, Index col, const Lhs& lhs, const Rhs& rhs, Index innerDim, Packet &res)
   {
     etor_product_packet_impl<ColMajor, UnrollingIndex-1, Lhs, Rhs, Packet, LoadMode>::run(row, col, lhs, rhs, innerDim, res);
     res =  pmadd(lhs.template packet<LoadMode,Packet>(row, Index(UnrollingIndex-1)), pset1<Packet>(rhs.coeff(Index(UnrollingIndex-1), col)), res);
   }
 };
 
 template<typename Lhs, typename Rhs, typename Packet, int LoadMode>
 struct etor_product_packet_impl<RowMajor, 1, Lhs, Rhs, Packet, LoadMode>
 {
-  static EIGEN_STRONG_INLINE void run(Index row, Index col, const Lhs& lhs, const Rhs& rhs, Index /*innerDim*/, Packet &res)
+  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Index row, Index col, const Lhs& lhs, const Rhs& rhs, Index /*innerDim*/, Packet &res)
   {
     res = pmul(pset1<Packet>(lhs.coeff(row, Index(0))),rhs.template packet<LoadMode,Packet>(Index(0), col));
   }
 };
 
 template<typename Lhs, typename Rhs, typename Packet, int LoadMode>
 struct etor_product_packet_impl<ColMajor, 1, Lhs, Rhs, Packet, LoadMode>
 {
-  static EIGEN_STRONG_INLINE void run(Index row, Index col, const Lhs& lhs, const Rhs& rhs, Index /*innerDim*/, Packet &res)
+  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Index row, Index col, const Lhs& lhs, const Rhs& rhs, Index /*innerDim*/, Packet &res)
   {
     res = pmul(lhs.template packet<LoadMode,Packet>(row, Index(0)), pset1<Packet>(rhs.coeff(Index(0), col)));
   }
 };
 
 template<typename Lhs, typename Rhs, typename Packet, int LoadMode>
 struct etor_product_packet_impl<RowMajor, 0, Lhs, Rhs, Packet, LoadMode>
 {
-  static EIGEN_STRONG_INLINE void run(Index /*row*/, Index /*col*/, const Lhs& /*lhs*/, const Rhs& /*rhs*/, Index /*innerDim*/, Packet &res)
+  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Index /*row*/, Index /*col*/, const Lhs& /*lhs*/, const Rhs& /*rhs*/, Index /*innerDim*/, Packet &res)
   {
     res = pset1<Packet>(typename unpacket_traits<Packet>::type(0));
   }
 };
 
 template<typename Lhs, typename Rhs, typename Packet, int LoadMode>
 struct etor_product_packet_impl<ColMajor, 0, Lhs, Rhs, Packet, LoadMode>
 {
-  static EIGEN_STRONG_INLINE void run(Index /*row*/, Index /*col*/, const Lhs& /*lhs*/, const Rhs& /*rhs*/, Index /*innerDim*/, Packet &res)
+  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Index /*row*/, Index /*col*/, const Lhs& /*lhs*/, const Rhs& /*rhs*/, Index /*innerDim*/, Packet &res)
   {
     res = pset1<Packet>(typename unpacket_traits<Packet>::type(0));
   }
 };
 
 template<typename Lhs, typename Rhs, typename Packet, int LoadMode>
 struct etor_product_packet_impl<RowMajor, Dynamic, Lhs, Rhs, Packet, LoadMode>
 {
-  static EIGEN_STRONG_INLINE void run(Index row, Index col, const Lhs& lhs, const Rhs& rhs, Index innerDim, Packet& res)
+  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Index row, Index col, const Lhs& lhs, const Rhs& rhs, Index innerDim, Packet& res)
   {
     res = pset1<Packet>(typename unpacket_traits<Packet>::type(0));
     for(Index i = 0; i < innerDim; ++i)
       res =  pmadd(pset1<Packet>(lhs.coeff(row, i)), rhs.template packet<LoadMode,Packet>(i, col), res);
   }
 };
 
 template<typename Lhs, typename Rhs, typename Packet, int LoadMode>
 struct etor_product_packet_impl<ColMajor, Dynamic, Lhs, Rhs, Packet, LoadMode>
 {
-  static EIGEN_STRONG_INLINE void run(Index row, Index col, const Lhs& lhs, const Rhs& rhs, Index innerDim, Packet& res)
+  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Index row, Index col, const Lhs& lhs, const Rhs& rhs, Index innerDim, Packet& res)
   {
     res = pset1<Packet>(typename unpacket_traits<Packet>::type(0));
     for(Index i = 0; i < innerDim; ++i)
       res =  pmadd(lhs.template packet<LoadMode,Packet>(row, i), pset1<Packet>(rhs.coeff(i, col)), res);
   }
 };
 
@@ -753,29 +758,29 @@
 struct triangular_product_impl;
 
 template<typename Lhs, typename Rhs, int ProductTag>
 struct generic_product_impl<Lhs,Rhs,TriangularShape,DenseShape,ProductTag>
   : generic_product_impl_base<Lhs,Rhs,generic_product_impl<Lhs,Rhs,TriangularShape,DenseShape,ProductTag> >
 {
   typedef typename Product<Lhs,Rhs>::Scalar Scalar;
-  
+
   template<typename Dest>
   static void scaleAndAddTo(Dest& dst, const Lhs& lhs, const Rhs& rhs, const Scalar& alpha)
   {
     triangular_product_impl<Lhs::Mode,true,typename Lhs::MatrixType,false,Rhs, Rhs::ColsAtCompileTime==1>
         ::run(dst, lhs.nestedExpression(), rhs, alpha);
   }
 };
 
 template<typename Lhs, typename Rhs, int ProductTag>
 struct generic_product_impl<Lhs,Rhs,DenseShape,TriangularShape,ProductTag>
 : generic_product_impl_base<Lhs,Rhs,generic_product_impl<Lhs,Rhs,DenseShape,TriangularShape,ProductTag> >
 {
   typedef typename Product<Lhs,Rhs>::Scalar Scalar;
-  
+
   template<typename Dest>
   static void scaleAndAddTo(Dest& dst, const Lhs& lhs, const Rhs& rhs, const Scalar& alpha)
   {
     triangular_product_impl<Rhs::Mode,false,Lhs,Lhs::RowsAtCompileTime==1, typename Rhs::MatrixType, false>::run(dst, lhs, rhs.nestedExpression(), alpha);
   }
 };
 
@@ -788,53 +793,53 @@
 struct selfadjoint_product_impl;
 
 template<typename Lhs, typename Rhs, int ProductTag>
 struct generic_product_impl<Lhs,Rhs,SelfAdjointShape,DenseShape,ProductTag>
   : generic_product_impl_base<Lhs,Rhs,generic_product_impl<Lhs,Rhs,SelfAdjointShape,DenseShape,ProductTag> >
 {
   typedef typename Product<Lhs,Rhs>::Scalar Scalar;
-  
+
   template<typename Dest>
   static EIGEN_DEVICE_FUNC
   void scaleAndAddTo(Dest& dst, const Lhs& lhs, const Rhs& rhs, const Scalar& alpha)
   {
     selfadjoint_product_impl<typename Lhs::MatrixType,Lhs::Mode,false,Rhs,0,Rhs::IsVectorAtCompileTime>::run(dst, lhs.nestedExpression(), rhs, alpha);
   }
 };
 
 template<typename Lhs, typename Rhs, int ProductTag>
 struct generic_product_impl<Lhs,Rhs,DenseShape,SelfAdjointShape,ProductTag>
 : generic_product_impl_base<Lhs,Rhs,generic_product_impl<Lhs,Rhs,DenseShape,SelfAdjointShape,ProductTag> >
 {
   typedef typename Product<Lhs,Rhs>::Scalar Scalar;
-  
+
   template<typename Dest>
   static void scaleAndAddTo(Dest& dst, const Lhs& lhs, const Rhs& rhs, const Scalar& alpha)
   {
     selfadjoint_product_impl<Lhs,0,Lhs::IsVectorAtCompileTime,typename Rhs::MatrixType,Rhs::Mode,false>::run(dst, lhs, rhs.nestedExpression(), alpha);
   }
 };
 
 
 /***************************************************************************
 * Diagonal products
 ***************************************************************************/
-  
+
 template<typename MatrixType, typename DiagonalType, typename Derived, int ProductOrder>
 struct diagonal_product_evaluator_base
   : evaluator_base<Derived>
 {
    typedef typename ScalarBinaryOpTraits<typename MatrixType::Scalar, typename DiagonalType::Scalar>::ReturnType Scalar;
 public:
   enum {
-    CoeffReadCost = NumTraits<Scalar>::MulCost + evaluator<MatrixType>::CoeffReadCost + evaluator<DiagonalType>::CoeffReadCost,
-    
+    CoeffReadCost = int(NumTraits<Scalar>::MulCost) + int(evaluator<MatrixType>::CoeffReadCost) + int(evaluator<DiagonalType>::CoeffReadCost),
+
     MatrixFlags = evaluator<MatrixType>::Flags,
     DiagFlags = evaluator<DiagonalType>::Flags,
-    
+
     _StorageOrder = (Derived::MaxRowsAtCompileTime==1 && Derived::MaxColsAtCompileTime!=1) ? RowMajor
                   : (Derived::MaxColsAtCompileTime==1 && Derived::MaxRowsAtCompileTime!=1) ? ColMajor
                   : MatrixFlags & RowMajorBit ? RowMajor : ColMajor,
     _SameStorageOrder = _StorageOrder == (MatrixFlags & RowMajorBit ? RowMajor : ColMajor),
 
     _ScalarAccessOnDiag =  !((int(_StorageOrder) == ColMajor && int(ProductOrder) == OnTheLeft)
                            ||(int(_StorageOrder) == RowMajor && int(ProductOrder) == OnTheRight)),
@@ -849,91 +854,91 @@
     Flags = ((HereditaryBits|_LinearAccessMask) & (unsigned int)(MatrixFlags)) | (_Vectorizable ? PacketAccessBit : 0),
     Alignment = evaluator<MatrixType>::Alignment,
 
     AsScalarProduct =     (DiagonalType::SizeAtCompileTime==1)
                       ||  (DiagonalType::SizeAtCompileTime==Dynamic && MatrixType::RowsAtCompileTime==1 && ProductOrder==OnTheLeft)
                       ||  (DiagonalType::SizeAtCompileTime==Dynamic && MatrixType::ColsAtCompileTime==1 && ProductOrder==OnTheRight)
   };
-  
+
   EIGEN_DEVICE_FUNC diagonal_product_evaluator_base(const MatrixType &mat, const DiagonalType &diag)
     : m_diagImpl(diag), m_matImpl(mat)
   {
     EIGEN_INTERNAL_CHECK_COST_VALUE(NumTraits<Scalar>::MulCost);
     EIGEN_INTERNAL_CHECK_COST_VALUE(CoeffReadCost);
   }
-  
+
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Scalar coeff(Index idx) const
   {
     if(AsScalarProduct)
       return m_diagImpl.coeff(0) * m_matImpl.coeff(idx);
     else
       return m_diagImpl.coeff(idx) * m_matImpl.coeff(idx);
   }
-  
+
 protected:
   template<int LoadMode,typename PacketType>
   EIGEN_STRONG_INLINE PacketType packet_impl(Index row, Index col, Index id, internal::true_type) const
   {
     return internal::pmul(m_matImpl.template packet<LoadMode,PacketType>(row, col),
                           internal::pset1<PacketType>(m_diagImpl.coeff(id)));
   }
-  
+
   template<int LoadMode,typename PacketType>
   EIGEN_STRONG_INLINE PacketType packet_impl(Index row, Index col, Index id, internal::false_type) const
   {
     enum {
       InnerSize = (MatrixType::Flags & RowMajorBit) ? MatrixType::ColsAtCompileTime : MatrixType::RowsAtCompileTime,
       DiagonalPacketLoadMode = EIGEN_PLAIN_ENUM_MIN(LoadMode,((InnerSize%16) == 0) ? int(Aligned16) : int(evaluator<DiagonalType>::Alignment)) // FIXME hardcoded 16!!
     };
     return internal::pmul(m_matImpl.template packet<LoadMode,PacketType>(row, col),
                           m_diagImpl.template packet<DiagonalPacketLoadMode,PacketType>(id));
   }
-  
+
   evaluator<DiagonalType> m_diagImpl;
   evaluator<MatrixType>   m_matImpl;
 };
 
 // diagonal * dense
 template<typename Lhs, typename Rhs, int ProductKind, int ProductTag>
 struct product_evaluator<Product<Lhs, Rhs, ProductKind>, ProductTag, DiagonalShape, DenseShape>
   : diagonal_product_evaluator_base<Rhs, typename Lhs::DiagonalVectorType, Product<Lhs, Rhs, LazyProduct>, OnTheLeft>
 {
   typedef diagonal_product_evaluator_base<Rhs, typename Lhs::DiagonalVectorType, Product<Lhs, Rhs, LazyProduct>, OnTheLeft> Base;
   using Base::m_diagImpl;
   using Base::m_matImpl;
   using Base::coeff;
   typedef typename Base::Scalar Scalar;
-  
+
   typedef Product<Lhs, Rhs, ProductKind> XprType;
   typedef typename XprType::PlainObject PlainObject;
   typedef typename Lhs::DiagonalVectorType DiagonalType;
 
-  
+
   enum { StorageOrder = Base::_StorageOrder };
 
   EIGEN_DEVICE_FUNC explicit product_evaluator(const XprType& xpr)
     : Base(xpr.rhs(), xpr.lhs().diagonal())
   {
   }
-  
+
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Scalar coeff(Index row, Index col) const
   {
     return m_diagImpl.coeff(row) * m_matImpl.coeff(row, col);
   }
-  
+
 #ifndef EIGEN_GPUCC
   template<int LoadMode,typename PacketType>
   EIGEN_STRONG_INLINE PacketType packet(Index row, Index col) const
   {
     // FIXME: NVCC used to complain about the template keyword, but we have to check whether this is still the case.
     // See also similar calls below.
     return this->template packet_impl<LoadMode,PacketType>(row,col, row,
                                  typename internal::conditional<int(StorageOrder)==RowMajor, internal::true_type, internal::false_type>::type());
   }
-  
+
   template<int LoadMode,typename PacketType>
   EIGEN_STRONG_INLINE PacketType packet(Index idx) const
   {
     return packet<LoadMode,PacketType>(int(StorageOrder)==ColMajor?idx:0,int(StorageOrder)==ColMajor?0:idx);
   }
 #endif
 };
@@ -944,38 +949,38 @@
   : diagonal_product_evaluator_base<Lhs, typename Rhs::DiagonalVectorType, Product<Lhs, Rhs, LazyProduct>, OnTheRight>
 {
   typedef diagonal_product_evaluator_base<Lhs, typename Rhs::DiagonalVectorType, Product<Lhs, Rhs, LazyProduct>, OnTheRight> Base;
   using Base::m_diagImpl;
   using Base::m_matImpl;
   using Base::coeff;
   typedef typename Base::Scalar Scalar;
-  
+
   typedef Product<Lhs, Rhs, ProductKind> XprType;
   typedef typename XprType::PlainObject PlainObject;
-  
+
   enum { StorageOrder = Base::_StorageOrder };
 
   EIGEN_DEVICE_FUNC explicit product_evaluator(const XprType& xpr)
     : Base(xpr.lhs(), xpr.rhs().diagonal())
   {
   }
-  
+
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Scalar coeff(Index row, Index col) const
   {
     return m_matImpl.coeff(row, col) * m_diagImpl.coeff(col);
   }
-  
+
 #ifndef EIGEN_GPUCC
   template<int LoadMode,typename PacketType>
   EIGEN_STRONG_INLINE PacketType packet(Index row, Index col) const
   {
     return this->template packet_impl<LoadMode,PacketType>(row,col, col,
                                  typename internal::conditional<int(StorageOrder)==ColMajor, internal::true_type, internal::false_type>::type());
   }
-  
+
   template<int LoadMode,typename PacketType>
   EIGEN_STRONG_INLINE PacketType packet(Index idx) const
   {
     return packet<LoadMode,PacketType>(int(StorageOrder)==ColMajor?idx:0,int(StorageOrder)==ColMajor?0:idx);
   }
 #endif
 };
@@ -995,15 +1000,15 @@
 template<typename ExpressionType, int Side, bool Transposed>
 struct permutation_matrix_product<ExpressionType, Side, Transposed, DenseShape>
 {
     typedef typename nested_eval<ExpressionType, 1>::type MatrixType;
     typedef typename remove_all<MatrixType>::type MatrixTypeCleaned;
 
     template<typename Dest, typename PermutationType>
-    static inline void run(Dest& dst, const PermutationType& perm, const ExpressionType& xpr)
+    static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Dest& dst, const PermutationType& perm, const ExpressionType& xpr)
     {
       MatrixType mat(xpr);
       const Index n = Side==OnTheLeft ? mat.rows() : mat.cols();
       // FIXME we need an is_same for expression that is not sensitive to constness. For instance
       // is_same_xpr<Block<const Matrix>, Block<Matrix> >::value should be true.
       //if(is_same<MatrixTypeCleaned,Dest>::value && extract_data(dst) == extract_data(mat))
       if(is_same_dense(dst, mat))
@@ -1049,45 +1054,45 @@
     }
 };
 
 template<typename Lhs, typename Rhs, int ProductTag, typename MatrixShape>
 struct generic_product_impl<Lhs, Rhs, PermutationShape, MatrixShape, ProductTag>
 {
   template<typename Dest>
-  static void evalTo(Dest& dst, const Lhs& lhs, const Rhs& rhs)
+  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void evalTo(Dest& dst, const Lhs& lhs, const Rhs& rhs)
   {
     permutation_matrix_product<Rhs, OnTheLeft, false, MatrixShape>::run(dst, lhs, rhs);
   }
 };
 
 template<typename Lhs, typename Rhs, int ProductTag, typename MatrixShape>
 struct generic_product_impl<Lhs, Rhs, MatrixShape, PermutationShape, ProductTag>
 {
   template<typename Dest>
-  static void evalTo(Dest& dst, const Lhs& lhs, const Rhs& rhs)
+  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void evalTo(Dest& dst, const Lhs& lhs, const Rhs& rhs)
   {
     permutation_matrix_product<Lhs, OnTheRight, false, MatrixShape>::run(dst, rhs, lhs);
   }
 };
 
 template<typename Lhs, typename Rhs, int ProductTag, typename MatrixShape>
 struct generic_product_impl<Inverse<Lhs>, Rhs, PermutationShape, MatrixShape, ProductTag>
 {
   template<typename Dest>
-  static void evalTo(Dest& dst, const Inverse<Lhs>& lhs, const Rhs& rhs)
+  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void evalTo(Dest& dst, const Inverse<Lhs>& lhs, const Rhs& rhs)
   {
     permutation_matrix_product<Rhs, OnTheLeft, true, MatrixShape>::run(dst, lhs.nestedExpression(), rhs);
   }
 };
 
 template<typename Lhs, typename Rhs, int ProductTag, typename MatrixShape>
 struct generic_product_impl<Lhs, Inverse<Rhs>, MatrixShape, PermutationShape, ProductTag>
 {
   template<typename Dest>
-  static void evalTo(Dest& dst, const Lhs& lhs, const Inverse<Rhs>& rhs)
+  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void evalTo(Dest& dst, const Lhs& lhs, const Inverse<Rhs>& rhs)
   {
     permutation_matrix_product<Lhs, OnTheRight, true, MatrixShape>::run(dst, rhs.nestedExpression(), lhs);
   }
 };
 
 
 /***************************************************************************
@@ -1101,17 +1106,17 @@
   * Internal helper class implementing the product between a permutation matrix and a matrix.
   */
 template<typename ExpressionType, int Side, bool Transposed, typename ExpressionShape>
 struct transposition_matrix_product
 {
   typedef typename nested_eval<ExpressionType, 1>::type MatrixType;
   typedef typename remove_all<MatrixType>::type MatrixTypeCleaned;
-  
+
   template<typename Dest, typename TranspositionType>
-  static inline void run(Dest& dst, const TranspositionType& tr, const ExpressionType& xpr)
+  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Dest& dst, const TranspositionType& tr, const ExpressionType& xpr)
   {
     MatrixType mat(xpr);
     typedef typename TranspositionType::StorageIndex StorageIndex;
     const Index size = tr.size();
     StorageIndex j = 0;
 
     if(!is_same_dense(dst,mat))
@@ -1126,46 +1131,46 @@
   }
 };
 
 template<typename Lhs, typename Rhs, int ProductTag, typename MatrixShape>
 struct generic_product_impl<Lhs, Rhs, TranspositionsShape, MatrixShape, ProductTag>
 {
   template<typename Dest>
-  static void evalTo(Dest& dst, const Lhs& lhs, const Rhs& rhs)
+  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void evalTo(Dest& dst, const Lhs& lhs, const Rhs& rhs)
   {
     transposition_matrix_product<Rhs, OnTheLeft, false, MatrixShape>::run(dst, lhs, rhs);
   }
 };
 
 template<typename Lhs, typename Rhs, int ProductTag, typename MatrixShape>
 struct generic_product_impl<Lhs, Rhs, MatrixShape, TranspositionsShape, ProductTag>
 {
   template<typename Dest>
-  static void evalTo(Dest& dst, const Lhs& lhs, const Rhs& rhs)
+  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void evalTo(Dest& dst, const Lhs& lhs, const Rhs& rhs)
   {
     transposition_matrix_product<Lhs, OnTheRight, false, MatrixShape>::run(dst, rhs, lhs);
   }
 };
 
 
 template<typename Lhs, typename Rhs, int ProductTag, typename MatrixShape>
 struct generic_product_impl<Transpose<Lhs>, Rhs, TranspositionsShape, MatrixShape, ProductTag>
 {
   template<typename Dest>
-  static void evalTo(Dest& dst, const Transpose<Lhs>& lhs, const Rhs& rhs)
+  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void evalTo(Dest& dst, const Transpose<Lhs>& lhs, const Rhs& rhs)
   {
     transposition_matrix_product<Rhs, OnTheLeft, true, MatrixShape>::run(dst, lhs.nestedExpression(), rhs);
   }
 };
 
 template<typename Lhs, typename Rhs, int ProductTag, typename MatrixShape>
 struct generic_product_impl<Lhs, Transpose<Rhs>, MatrixShape, TranspositionsShape, ProductTag>
 {
   template<typename Dest>
-  static void evalTo(Dest& dst, const Lhs& lhs, const Transpose<Rhs>& rhs)
+  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void evalTo(Dest& dst, const Lhs& lhs, const Transpose<Rhs>& rhs)
   {
     transposition_matrix_product<Lhs, OnTheRight, true, MatrixShape>::run(dst, rhs.nestedExpression(), lhs);
   }
 };
 
 } // end namespace internal
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Random.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Random.h`

 * *Files 13% similar despite different names*

```diff
@@ -173,10 +173,46 @@
 EIGEN_STRONG_INLINE Derived&
 PlainObjectBase<Derived>::setRandom(Index rows, Index cols)
 {
   resize(rows, cols);
   return setRandom();
 }
 
+/** Resizes to the given size, changing only the number of columns, and sets all
+  * coefficients in this expression to random values. For the parameter of type
+  * NoChange_t, just pass the special value \c NoChange.
+  *
+  * Numbers are uniformly spread through their whole definition range for integer types,
+  * and in the [-1:1] range for floating point scalar types.
+  *
+  * \not_reentrant
+  *
+  * \sa DenseBase::setRandom(), setRandom(Index), setRandom(Index, NoChange_t), class CwiseNullaryOp, DenseBase::Random()
+  */
+template<typename Derived>
+EIGEN_STRONG_INLINE Derived&
+PlainObjectBase<Derived>::setRandom(NoChange_t, Index cols)
+{
+  return setRandom(rows(), cols);
+}
+
+/** Resizes to the given size, changing only the number of rows, and sets all
+  * coefficients in this expression to random values. For the parameter of type
+  * NoChange_t, just pass the special value \c NoChange.
+  *
+  * Numbers are uniformly spread through their whole definition range for integer types,
+  * and in the [-1:1] range for floating point scalar types.
+  *
+  * \not_reentrant
+  *
+  * \sa DenseBase::setRandom(), setRandom(Index), setRandom(NoChange_t, Index), class CwiseNullaryOp, DenseBase::Random()
+  */
+template<typename Derived>
+EIGEN_STRONG_INLINE Derived&
+PlainObjectBase<Derived>::setRandom(Index rows, NoChange_t)
+{
+  return setRandom(rows, cols());
+}
+
 } // end namespace Eigen
 
 #endif // EIGEN_RANDOM_H
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Redux.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Redux.h`

 * *Files 3% similar despite different names*

```diff
@@ -54,15 +54,15 @@
               : int(MaySliceVectorize)  ? int(SliceVectorizedTraversal)
                                         : int(DefaultTraversal)
   };
 
 public:
   enum {
     Cost = Evaluator::SizeAtCompileTime == Dynamic ? HugeCost
-         : Evaluator::SizeAtCompileTime * Evaluator::CoeffReadCost + (Evaluator::SizeAtCompileTime-1) * functor_traits<Func>::Cost,
+         : int(Evaluator::SizeAtCompileTime) * int(Evaluator::CoeffReadCost) + (Evaluator::SizeAtCompileTime-1) * functor_traits<Func>::Cost,
     UnrollingLimit = EIGEN_UNROLLING_LIMIT * (int(Traversal) == int(DefaultTraversal) ? 1 : int(PacketSize))
   };
 
 public:
   enum {
     Unrolling = Cost <= UnrollingLimit ? CompleteUnrolling : NoUnrolling
   };
@@ -327,15 +327,15 @@
 {
   typedef typename Evaluator::Scalar Scalar;
 
   typedef typename redux_traits<Func, Evaluator>::PacketType PacketType;
   enum {
     PacketSize = redux_traits<Func, Evaluator>::PacketSize,
     Size = Evaluator::SizeAtCompileTime,
-    VectorizedSize = (Size / PacketSize) * PacketSize
+    VectorizedSize = (int(Size) / int(PacketSize)) * int(PacketSize)
   };
 
   template<typename XprType>
   EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE
   Scalar run(const Evaluator &eval, const Func& func, const XprType &xpr)
   {
     EIGEN_ONLY_USED_FOR_DEBUG(xpr)
@@ -415,33 +415,41 @@
 
   // The initial expression is passed to the reducer as an additional argument instead of
   // passing it as a member of redux_evaluator to help  
   return internal::redux_impl<Func, ThisEvaluator>::run(thisEval, func, derived());
 }
 
 /** \returns the minimum of all coefficients of \c *this.
+  * In case \c *this contains NaN, NaNPropagation determines the behavior:
+  *   NaNPropagation == PropagateFast : undefined
+  *   NaNPropagation == PropagateNaN : result is NaN
+  *   NaNPropagation == PropagateNumbers : result is minimum of elements that are not NaN
   * \warning the matrix must be not empty, otherwise an assertion is triggered.
-  * \warning the result is undefined if \c *this contains NaN.
   */
 template<typename Derived>
+template<int NaNPropagation>
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename internal::traits<Derived>::Scalar
 DenseBase<Derived>::minCoeff() const
 {
-  return derived().redux(Eigen::internal::scalar_min_op<Scalar,Scalar>());
+  return derived().redux(Eigen::internal::scalar_min_op<Scalar,Scalar, NaNPropagation>());
 }
 
-/** \returns the maximum of all coefficients of \c *this.
+/** \returns the maximum of all coefficients of \c *this. 
+  * In case \c *this contains NaN, NaNPropagation determines the behavior:
+  *   NaNPropagation == PropagateFast : undefined
+  *   NaNPropagation == PropagateNaN : result is NaN
+  *   NaNPropagation == PropagateNumbers : result is maximum of elements that are not NaN
   * \warning the matrix must be not empty, otherwise an assertion is triggered.
-  * \warning the result is undefined if \c *this contains NaN.
   */
 template<typename Derived>
+template<int NaNPropagation>
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename internal::traits<Derived>::Scalar
 DenseBase<Derived>::maxCoeff() const
 {
-  return derived().redux(Eigen::internal::scalar_max_op<Scalar,Scalar>());
+  return derived().redux(Eigen::internal::scalar_max_op<Scalar,Scalar, NaNPropagation>());
 }
 
 /** \returns the sum of all coefficients of \c *this
   *
   * If \c *this is empty, then the value 0 is returned.
   *
   * \sa trace(), prod(), mean()
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Ref.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Ref.h`

 * *Files 21% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_REF_H
 #define EIGEN_REF_H
 
-namespace Eigen { 
+namespace Eigen {
 
 namespace internal {
 
 template<typename _PlainObjectType, int _Options, typename _StrideType>
 struct traits<Ref<_PlainObjectType, _Options, _StrideType> >
   : public traits<Map<_PlainObjectType, _Options, _StrideType> >
 {
@@ -44,15 +44,15 @@
       DerivedAlignment = int(evaluator<Derived>::Alignment),
       AlignmentMatch = (int(traits<PlainObjectType>::Alignment)==int(Unaligned)) || (DerivedAlignment >= int(Alignment)), // FIXME the first condition is not very clear, it should be replaced by the required alignment
       ScalarTypeMatch = internal::is_same<typename PlainObjectType::Scalar, typename Derived::Scalar>::value,
       MatchAtCompileTime = HasDirectAccess && StorageOrderMatch && InnerStrideMatch && OuterStrideMatch && AlignmentMatch && ScalarTypeMatch
     };
     typedef typename internal::conditional<MatchAtCompileTime,internal::true_type,internal::false_type>::type type;
   };
-  
+
 };
 
 template<typename Derived>
 struct traits<RefBase<Derived> > : public traits<Derived> {};
 
 }
 
@@ -63,63 +63,149 @@
   typedef typename internal::traits<Derived>::StrideType StrideType;
 
 public:
 
   typedef MapBase<Derived> Base;
   EIGEN_DENSE_PUBLIC_INTERFACE(RefBase)
 
-  EIGEN_DEVICE_FUNC inline Index innerStride() const
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index innerStride() const
   {
     return StrideType::InnerStrideAtCompileTime != 0 ? m_stride.inner() : 1;
   }
 
-  EIGEN_DEVICE_FUNC inline Index outerStride() const
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index outerStride() const
   {
     return StrideType::OuterStrideAtCompileTime != 0 ? m_stride.outer()
          : IsVectorAtCompileTime ? this->size()
          : int(Flags)&RowMajorBit ? this->cols()
          : this->rows();
   }
 
   EIGEN_DEVICE_FUNC RefBase()
     : Base(0,RowsAtCompileTime==Dynamic?0:RowsAtCompileTime,ColsAtCompileTime==Dynamic?0:ColsAtCompileTime),
       // Stride<> does not allow default ctor for Dynamic strides, so let' initialize it with dummy values:
       m_stride(StrideType::OuterStrideAtCompileTime==Dynamic?0:StrideType::OuterStrideAtCompileTime,
                StrideType::InnerStrideAtCompileTime==Dynamic?0:StrideType::InnerStrideAtCompileTime)
   {}
-  
+
   EIGEN_INHERIT_ASSIGNMENT_OPERATORS(RefBase)
 
 protected:
 
   typedef Stride<StrideType::OuterStrideAtCompileTime,StrideType::InnerStrideAtCompileTime> StrideBase;
 
+  // Resolves inner stride if default 0.
+  static EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index resolveInnerStride(Index inner) {
+    return inner == 0 ? 1 : inner;
+  }
+
+  // Resolves outer stride if default 0.
+  static EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index resolveOuterStride(Index inner, Index outer, Index rows, Index cols, bool isVectorAtCompileTime, bool isRowMajor) {
+    return outer == 0 ? isVectorAtCompileTime ? inner * rows * cols : isRowMajor ? inner * cols : inner * rows : outer;
+  }
+
+  // Returns true if construction is valid, false if there is a stride mismatch,
+  // and fails if there is a size mismatch.
   template<typename Expression>
-  EIGEN_DEVICE_FUNC void construct(Expression& expr)
+  EIGEN_DEVICE_FUNC bool construct(Expression& expr)
   {
-    EIGEN_STATIC_ASSERT_SAME_MATRIX_SIZE(PlainObjectType,Expression);
-
+    // Check matrix sizes.  If this is a compile-time vector, we do allow
+    // implicitly transposing.
+    EIGEN_STATIC_ASSERT(
+      EIGEN_PREDICATE_SAME_MATRIX_SIZE(PlainObjectType, Expression)
+      // If it is a vector, the transpose sizes might match.
+      || ( PlainObjectType::IsVectorAtCompileTime
+            && ((int(PlainObjectType::RowsAtCompileTime)==Eigen::Dynamic
+              || int(Expression::ColsAtCompileTime)==Eigen::Dynamic
+              || int(PlainObjectType::RowsAtCompileTime)==int(Expression::ColsAtCompileTime))
+            &&  (int(PlainObjectType::ColsAtCompileTime)==Eigen::Dynamic
+              || int(Expression::RowsAtCompileTime)==Eigen::Dynamic
+              || int(PlainObjectType::ColsAtCompileTime)==int(Expression::RowsAtCompileTime)))),
+      YOU_MIXED_MATRICES_OF_DIFFERENT_SIZES
+    )
+
+    // Determine runtime rows and columns.
+    Index rows = expr.rows();
+    Index cols = expr.cols();
     if(PlainObjectType::RowsAtCompileTime==1)
     {
       eigen_assert(expr.rows()==1 || expr.cols()==1);
-      ::new (static_cast<Base*>(this)) Base(expr.data(), 1, expr.size());
+      rows = 1;
+      cols = expr.size();
     }
     else if(PlainObjectType::ColsAtCompileTime==1)
     {
       eigen_assert(expr.rows()==1 || expr.cols()==1);
-      ::new (static_cast<Base*>(this)) Base(expr.data(), expr.size(), 1);
+      rows = expr.size();
+      cols = 1;
+    }
+    // Verify that the sizes are valid.
+    eigen_assert(
+      (PlainObjectType::RowsAtCompileTime == Dynamic) || (PlainObjectType::RowsAtCompileTime == rows));
+    eigen_assert(
+      (PlainObjectType::ColsAtCompileTime == Dynamic) || (PlainObjectType::ColsAtCompileTime == cols));
+
+
+    // If this is a vector, we might be transposing, which means that stride should swap.
+    const bool transpose = PlainObjectType::IsVectorAtCompileTime && (rows != expr.rows());
+    // If the storage format differs, we also need to swap the stride.
+    const bool row_major = ((PlainObjectType::Flags)&RowMajorBit) != 0;
+    const bool expr_row_major = (Expression::Flags&RowMajorBit) != 0;
+    const bool storage_differs =  (row_major != expr_row_major);
+
+    const bool swap_stride = (transpose != storage_differs);
+
+    // Determine expr's actual strides, resolving any defaults if zero.
+    const Index expr_inner_actual = resolveInnerStride(expr.innerStride());
+    const Index expr_outer_actual = resolveOuterStride(expr_inner_actual,
+                                                       expr.outerStride(),
+                                                       expr.rows(),
+                                                       expr.cols(),
+                                                       Expression::IsVectorAtCompileTime != 0,
+                                                       expr_row_major);
+
+    // If this is a column-major row vector or row-major column vector, the inner-stride
+    // is arbitrary, so set it to either the compile-time inner stride or 1.
+    const bool row_vector = (rows == 1);
+    const bool col_vector = (cols == 1);
+    const Index inner_stride =
+        ( (!row_major && row_vector) || (row_major && col_vector) ) ?
+            ( StrideType::InnerStrideAtCompileTime > 0 ? Index(StrideType::InnerStrideAtCompileTime) : 1)
+            : swap_stride ? expr_outer_actual : expr_inner_actual;
+
+    // If this is a column-major column vector or row-major row vector, the outer-stride
+    // is arbitrary, so set it to either the compile-time outer stride or vector size.
+    const Index outer_stride =
+      ( (!row_major && col_vector) || (row_major && row_vector) ) ?
+          ( StrideType::OuterStrideAtCompileTime > 0 ? Index(StrideType::OuterStrideAtCompileTime) : rows * cols * inner_stride)
+          : swap_stride ? expr_inner_actual : expr_outer_actual;
+
+    // Check if given inner/outer strides are compatible with compile-time strides.
+    const bool inner_valid = (StrideType::InnerStrideAtCompileTime == Dynamic)
+        || (resolveInnerStride(Index(StrideType::InnerStrideAtCompileTime)) == inner_stride);
+    if (!inner_valid) {
+      return false;
     }
-    else
-      ::new (static_cast<Base*>(this)) Base(expr.data(), expr.rows(), expr.cols());
-    
-    if(Expression::IsVectorAtCompileTime && (!PlainObjectType::IsVectorAtCompileTime) && ((Expression::Flags&RowMajorBit)!=(PlainObjectType::Flags&RowMajorBit)))
-      ::new (&m_stride) StrideBase(expr.innerStride(), StrideType::InnerStrideAtCompileTime==0?0:1);
-    else
-      ::new (&m_stride) StrideBase(StrideType::OuterStrideAtCompileTime==0?0:expr.outerStride(),
-                                   StrideType::InnerStrideAtCompileTime==0?0:expr.innerStride());    
+
+    const bool outer_valid = (StrideType::OuterStrideAtCompileTime == Dynamic)
+        || (resolveOuterStride(
+              inner_stride,
+              Index(StrideType::OuterStrideAtCompileTime),
+              rows, cols, PlainObjectType::IsVectorAtCompileTime != 0,
+              row_major)
+            == outer_stride);
+    if (!outer_valid) {
+      return false;
+    }
+
+    ::new (static_cast<Base*>(this)) Base(expr.data(), rows, cols);
+    ::new (&m_stride) StrideBase(
+      (StrideType::OuterStrideAtCompileTime == 0) ? 0 : outer_stride,
+      (StrideType::InnerStrideAtCompileTime == 0) ? 0 : inner_stride );
+    return true;
   }
 
   StrideBase m_stride;
 };
 
 /** \class Ref
   * \ingroup Core_Module
@@ -208,29 +294,35 @@
 
     #ifndef EIGEN_PARSED_BY_DOXYGEN
     template<typename Derived>
     EIGEN_DEVICE_FUNC inline Ref(PlainObjectBase<Derived>& expr,
                                  typename internal::enable_if<bool(Traits::template match<Derived>::MatchAtCompileTime),Derived>::type* = 0)
     {
       EIGEN_STATIC_ASSERT(bool(Traits::template match<Derived>::MatchAtCompileTime), STORAGE_LAYOUT_DOES_NOT_MATCH);
-      Base::construct(expr.derived());
+      // Construction must pass since we will not create temprary storage in the non-const case.
+      const bool success = Base::construct(expr.derived());
+      EIGEN_UNUSED_VARIABLE(success)
+      eigen_assert(success);
     }
     template<typename Derived>
     EIGEN_DEVICE_FUNC inline Ref(const DenseBase<Derived>& expr,
                                  typename internal::enable_if<bool(Traits::template match<Derived>::MatchAtCompileTime),Derived>::type* = 0)
     #else
     /** Implicit constructor from any dense expression */
     template<typename Derived>
     inline Ref(DenseBase<Derived>& expr)
     #endif
     {
       EIGEN_STATIC_ASSERT(bool(internal::is_lvalue<Derived>::value), THIS_EXPRESSION_IS_NOT_A_LVALUE__IT_IS_READ_ONLY);
       EIGEN_STATIC_ASSERT(bool(Traits::template match<Derived>::MatchAtCompileTime), STORAGE_LAYOUT_DOES_NOT_MATCH);
       EIGEN_STATIC_ASSERT(!Derived::IsPlainObjectBase,THIS_EXPRESSION_IS_NOT_A_LVALUE__IT_IS_READ_ONLY);
-      Base::construct(expr.const_cast_derived());
+      // Construction must pass since we will not create temporary storage in the non-const case.
+      const bool success = Base::construct(expr.const_cast_derived());
+      EIGEN_UNUSED_VARIABLE(success)
+      eigen_assert(success);
     }
 
     EIGEN_INHERIT_ASSIGNMENT_OPERATORS(Ref)
 
 };
 
 // this is the const ref version
@@ -263,15 +355,18 @@
     }
 
   protected:
 
     template<typename Expression>
     EIGEN_DEVICE_FUNC void construct(const Expression& expr,internal::true_type)
     {
-      Base::construct(expr);
+      // Check if we can use the underlying expr's storage directly, otherwise call the copy version.
+      if (!Base::construct(expr)) {
+        construct(expr, internal::false_type());
+      }
     }
 
     template<typename Expression>
     EIGEN_DEVICE_FUNC void construct(const Expression& expr, internal::false_type)
     {
       internal::call_assignment_no_alias(m_object,expr,internal::assign_op<Scalar,Scalar>());
       Base::construct(m_object);
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Replicate.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Replicate.h`

 * *Files 1% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_REPLICATE_H
 #define EIGEN_REPLICATE_H
 
-namespace Eigen { 
+namespace Eigen {
 
 namespace internal {
 template<typename MatrixType,int RowFactor,int ColFactor>
 struct traits<Replicate<MatrixType,RowFactor,ColFactor> >
  : traits<MatrixType>
 {
   typedef typename MatrixType::Scalar Scalar;
@@ -31,15 +31,15 @@
                       : ColFactor * MatrixType::ColsAtCompileTime,
    //FIXME we don't propagate the max sizes !!!
     MaxRowsAtCompileTime = RowsAtCompileTime,
     MaxColsAtCompileTime = ColsAtCompileTime,
     IsRowMajor = MaxRowsAtCompileTime==1 && MaxColsAtCompileTime!=1 ? 1
                : MaxColsAtCompileTime==1 && MaxRowsAtCompileTime!=1 ? 0
                : (MatrixType::Flags & RowMajorBit) ? 1 : 0,
-    
+
     // FIXME enable DirectAccess with negative strides?
     Flags = IsRowMajor ? RowMajorBit : 0
   };
 };
 }
 
 /**
@@ -84,23 +84,23 @@
     inline Replicate(const OriginalMatrixType& matrix, Index rowFactor, Index colFactor)
       : m_matrix(matrix), m_rowFactor(rowFactor), m_colFactor(colFactor)
     {
       EIGEN_STATIC_ASSERT((internal::is_same<typename internal::remove_const<MatrixType>::type,OriginalMatrixType>::value),
                           THE_MATRIX_OR_EXPRESSION_THAT_YOU_PASSED_DOES_NOT_HAVE_THE_EXPECTED_TYPE)
     }
 
-    EIGEN_DEVICE_FUNC
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
     inline Index rows() const { return m_matrix.rows() * m_rowFactor.value(); }
-    EIGEN_DEVICE_FUNC
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
     inline Index cols() const { return m_matrix.cols() * m_colFactor.value(); }
 
     EIGEN_DEVICE_FUNC
     const _MatrixTypeNested& nestedExpression() const
-    { 
-      return m_matrix; 
+    {
+      return m_matrix;
     }
 
   protected:
     MatrixTypeNested m_matrix;
     const internal::variable_if_dynamic<Index, RowFactor> m_rowFactor;
     const internal::variable_if_dynamic<Index, ColFactor> m_colFactor;
 };
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Reshaped.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Reshaped.h`

 * *Files 1% similar despite different names*

```diff
@@ -8,15 +8,14 @@
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_RESHAPED_H
 #define EIGEN_RESHAPED_H
 
 namespace Eigen {
-namespace internal {
 
 /** \class Reshaped
   * \ingroup Core_Module
   *
   * \brief Expression of a fixed-size or dynamic-size reshape
   *
   * \tparam XprType the type of the expression in which we are taking a reshape
@@ -40,14 +39,16 @@
   * Here is an example illustrating the fixed-size case:
   * \include class_FixedReshaped.cpp
   * Output: \verbinclude class_FixedReshaped.out
   *
   * \sa DenseBase::reshaped(NRowsType,NColsType)
   */
 
+namespace internal {
+
 template<typename XprType, int Rows, int Cols, int Order>
 struct traits<Reshaped<XprType, Rows, Cols, Order> > : traits<XprType>
 {
   typedef typename traits<XprType>::Scalar Scalar;
   typedef typename traits<XprType>::StorageKind StorageKind;
   typedef typename traits<XprType>::XprKind XprKind;
   enum{
@@ -235,22 +236,22 @@
       return m_xpr;
     }
 
     EIGEN_DEVICE_FUNC
     XprType& nestedExpression() { return m_xpr; }
 
     /** \sa MapBase::innerStride() */
-    EIGEN_DEVICE_FUNC
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
     inline Index innerStride() const
     {
       return m_xpr.innerStride();
     }
 
     /** \sa MapBase::outerStride() */
-    EIGEN_DEVICE_FUNC
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
     inline Index outerStride() const
     {
       return ((Flags&RowMajorBit)==RowMajorBit) ? this->cols() : this->rows();
     }
 
   protected:
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/ReturnByValue.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/ReturnByValue.h`

 * *Files 2% similar despite different names*

```diff
@@ -56,16 +56,18 @@
     typedef typename internal::dense_xpr_base<ReturnByValue>::type Base;
     EIGEN_DENSE_PUBLIC_INTERFACE(ReturnByValue)
 
     template<typename Dest>
     EIGEN_DEVICE_FUNC
     inline void evalTo(Dest& dst) const
     { static_cast<const Derived*>(this)->evalTo(dst); }
-    EIGEN_DEVICE_FUNC inline Index rows() const { return static_cast<const Derived*>(this)->rows(); }
-    EIGEN_DEVICE_FUNC inline Index cols() const { return static_cast<const Derived*>(this)->cols(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index rows() const EIGEN_NOEXCEPT { return static_cast<const Derived*>(this)->rows(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index cols() const EIGEN_NOEXCEPT { return static_cast<const Derived*>(this)->cols(); }
 
 #ifndef EIGEN_PARSED_BY_DOXYGEN
 #define Unusable YOU_ARE_TRYING_TO_ACCESS_A_SINGLE_COEFFICIENT_IN_A_SPECIAL_EXPRESSION_WHERE_THAT_IS_NOT_ALLOWED_BECAUSE_THAT_WOULD_BE_INEFFICIENT
     class Unusable{
       Unusable(const Unusable&) {}
       Unusable& operator=(const Unusable&) {return *this;}
     };
@@ -86,23 +88,23 @@
 }
 
 namespace internal {
 
 // Expression is evaluated in a temporary; default implementation of Assignment is bypassed so that
 // when a ReturnByValue expression is assigned, the evaluator is not constructed.
 // TODO: Finalize port to new regime; ReturnByValue should not exist in the expression world
-  
+
 template<typename Derived>
 struct evaluator<ReturnByValue<Derived> >
   : public evaluator<typename internal::traits<Derived>::ReturnType>
 {
   typedef ReturnByValue<Derived> XprType;
   typedef typename internal::traits<Derived>::ReturnType PlainObject;
   typedef evaluator<PlainObject> Base;
-  
+
   EIGEN_DEVICE_FUNC explicit evaluator(const XprType& xpr)
     : m_result(xpr.rows(), xpr.cols())
   {
     ::new (static_cast<Base*>(this)) Base(m_result);
     xpr.evalTo(m_result);
   }
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Reverse.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Reverse.h`

 * *Files 4% similar despite different names*

```diff
@@ -8,15 +8,15 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_REVERSE_H
 #define EIGEN_REVERSE_H
 
-namespace Eigen { 
+namespace Eigen {
 
 namespace internal {
 
 template<typename MatrixType, int Direction>
 struct traits<Reverse<MatrixType, Direction> >
  : traits<MatrixType>
 {
@@ -40,15 +40,15 @@
 };
 
 template<typename PacketType> struct reverse_packet_cond<PacketType,false>
 {
   static inline PacketType run(const PacketType& x) { return x; }
 };
 
-} // end namespace internal 
+} // end namespace internal
 
 /** \class Reverse
   * \ingroup Core_Module
   *
   * \brief Expression of the reverse of a vector or matrix
   *
   * \tparam MatrixType the type of the object of which we are taking the reverse
@@ -85,24 +85,26 @@
     typedef internal::reverse_packet_cond<PacketScalar,ReversePacket> reverse_packet;
   public:
 
     EIGEN_DEVICE_FUNC explicit inline Reverse(const MatrixType& matrix) : m_matrix(matrix) { }
 
     EIGEN_INHERIT_ASSIGNMENT_OPERATORS(Reverse)
 
-    EIGEN_DEVICE_FUNC inline Index rows() const { return m_matrix.rows(); }
-    EIGEN_DEVICE_FUNC inline Index cols() const { return m_matrix.cols(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index rows() const EIGEN_NOEXCEPT { return m_matrix.rows(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index cols() const EIGEN_NOEXCEPT { return m_matrix.cols(); }
 
     EIGEN_DEVICE_FUNC inline Index innerStride() const
     {
       return -m_matrix.innerStride();
     }
 
     EIGEN_DEVICE_FUNC const typename internal::remove_all<typename MatrixType::Nested>::type&
-    nestedExpression() const 
+    nestedExpression() const
     {
       return m_matrix;
     }
 
   protected:
     typename MatrixType::Nested m_matrix;
 };
@@ -157,15 +159,15 @@
       Index half2 = cols()/2;
       row(half).head(half2).swap(row(half).tail(half2).reverse());
     }
   }
 }
 
 namespace internal {
-  
+
 template<int Direction>
 struct vectorwise_reverse_inplace_impl;
 
 template<>
 struct vectorwise_reverse_inplace_impl<Vertical>
 {
   template<typename ExpressionType>
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Select.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Select.h`

 * *Files 9% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_SELECT_H
 #define EIGEN_SELECT_H
 
-namespace Eigen { 
+namespace Eigen {
 
 /** \class Select
   * \ingroup Core_Module
   *
   * \brief Expression of a coefficient wise version of the C++ ternary operator ?:
   *
   * \param ConditionMatrixType the type of the \em condition expression which must be a boolean matrix
@@ -63,16 +63,18 @@
            const ElseMatrixType& a_elseMatrix)
       : m_condition(a_conditionMatrix), m_then(a_thenMatrix), m_else(a_elseMatrix)
     {
       eigen_assert(m_condition.rows() == m_then.rows() && m_condition.rows() == m_else.rows());
       eigen_assert(m_condition.cols() == m_then.cols() && m_condition.cols() == m_else.cols());
     }
 
-    inline EIGEN_DEVICE_FUNC Index rows() const { return m_condition.rows(); }
-    inline EIGEN_DEVICE_FUNC Index cols() const { return m_condition.cols(); }
+    inline EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    Index rows() const EIGEN_NOEXCEPT { return m_condition.rows(); }
+    inline EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    Index cols() const EIGEN_NOEXCEPT { return m_condition.cols(); }
 
     inline EIGEN_DEVICE_FUNC
     const Scalar coeff(Index i, Index j) const
     {
       if (m_condition.coeff(i,j))
         return m_then.coeff(i,j);
       else
@@ -116,44 +118,44 @@
   * Example: \include MatrixBase_select.cpp
   * Output: \verbinclude MatrixBase_select.out
   *
   * \sa class Select
   */
 template<typename Derived>
 template<typename ThenDerived,typename ElseDerived>
-inline const Select<Derived,ThenDerived,ElseDerived>
+inline EIGEN_DEVICE_FUNC const Select<Derived,ThenDerived,ElseDerived>
 DenseBase<Derived>::select(const DenseBase<ThenDerived>& thenMatrix,
                             const DenseBase<ElseDerived>& elseMatrix) const
 {
   return Select<Derived,ThenDerived,ElseDerived>(derived(), thenMatrix.derived(), elseMatrix.derived());
 }
 
 /** Version of DenseBase::select(const DenseBase&, const DenseBase&) with
   * the \em else expression being a scalar value.
   *
   * \sa DenseBase::select(const DenseBase<ThenDerived>&, const DenseBase<ElseDerived>&) const, class Select
   */
 template<typename Derived>
 template<typename ThenDerived>
-inline const Select<Derived,ThenDerived, typename ThenDerived::ConstantReturnType>
+inline EIGEN_DEVICE_FUNC const Select<Derived,ThenDerived, typename ThenDerived::ConstantReturnType>
 DenseBase<Derived>::select(const DenseBase<ThenDerived>& thenMatrix,
                            const typename ThenDerived::Scalar& elseScalar) const
 {
   return Select<Derived,ThenDerived,typename ThenDerived::ConstantReturnType>(
     derived(), thenMatrix.derived(), ThenDerived::Constant(rows(),cols(),elseScalar));
 }
 
 /** Version of DenseBase::select(const DenseBase&, const DenseBase&) with
   * the \em then expression being a scalar value.
   *
   * \sa DenseBase::select(const DenseBase<ThenDerived>&, const DenseBase<ElseDerived>&) const, class Select
   */
 template<typename Derived>
 template<typename ElseDerived>
-inline const Select<Derived, typename ElseDerived::ConstantReturnType, ElseDerived >
+inline EIGEN_DEVICE_FUNC const Select<Derived, typename ElseDerived::ConstantReturnType, ElseDerived >
 DenseBase<Derived>::select(const typename ElseDerived::Scalar& thenScalar,
                            const DenseBase<ElseDerived>& elseMatrix) const
 {
   return Select<Derived,typename ElseDerived::ConstantReturnType,ElseDerived>(
     derived(), ElseDerived::Constant(rows(),cols(),thenScalar), elseMatrix.derived());
 }
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/SelfAdjointView.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/SelfAdjointView.h`

 * *Files 2% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_SELFADJOINTMATRIX_H
 #define EIGEN_SELFADJOINTMATRIX_H
 
-namespace Eigen { 
+namespace Eigen {
 
 /** \class SelfAdjointView
   * \ingroup Core_Module
   *
   *
   * \brief Expression of a selfadjoint matrix from a triangular part of a dense matrix
   *
@@ -54,40 +54,40 @@
     typedef _MatrixType MatrixType;
     typedef TriangularBase<SelfAdjointView> Base;
     typedef typename internal::traits<SelfAdjointView>::MatrixTypeNested MatrixTypeNested;
     typedef typename internal::traits<SelfAdjointView>::MatrixTypeNestedCleaned MatrixTypeNestedCleaned;
     typedef MatrixTypeNestedCleaned NestedExpression;
 
     /** \brief The type of coefficients in this matrix */
-    typedef typename internal::traits<SelfAdjointView>::Scalar Scalar; 
+    typedef typename internal::traits<SelfAdjointView>::Scalar Scalar;
     typedef typename MatrixType::StorageIndex StorageIndex;
     typedef typename internal::remove_all<typename MatrixType::ConjugateReturnType>::type MatrixConjugateReturnType;
     typedef SelfAdjointView<typename internal::add_const<MatrixType>::type, UpLo> ConstSelfAdjointView;
 
     enum {
       Mode = internal::traits<SelfAdjointView>::Mode,
       Flags = internal::traits<SelfAdjointView>::Flags,
-      TransposeMode = ((Mode & Upper) ? Lower : 0) | ((Mode & Lower) ? Upper : 0)
+      TransposeMode = ((int(Mode) & int(Upper)) ? Lower : 0) | ((int(Mode) & int(Lower)) ? Upper : 0)
     };
     typedef typename MatrixType::PlainObject PlainObject;
 
     EIGEN_DEVICE_FUNC
     explicit inline SelfAdjointView(MatrixType& matrix) : m_matrix(matrix)
     {
       EIGEN_STATIC_ASSERT(UpLo==Lower || UpLo==Upper,SELFADJOINTVIEW_ACCEPTS_UPPER_AND_LOWER_MODE_ONLY);
     }
 
-    EIGEN_DEVICE_FUNC
-    inline Index rows() const { return m_matrix.rows(); }
-    EIGEN_DEVICE_FUNC
-    inline Index cols() const { return m_matrix.cols(); }
-    EIGEN_DEVICE_FUNC
-    inline Index outerStride() const { return m_matrix.outerStride(); }
-    EIGEN_DEVICE_FUNC
-    inline Index innerStride() const { return m_matrix.innerStride(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index rows() const EIGEN_NOEXCEPT { return m_matrix.rows(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index cols() const EIGEN_NOEXCEPT { return m_matrix.cols(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index outerStride() const EIGEN_NOEXCEPT { return m_matrix.outerStride(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index innerStride() const EIGEN_NOEXCEPT { return m_matrix.innerStride(); }
 
     /** \sa MatrixBase::coeff()
       * \warning the coordinates must fit into the referenced triangular part
       */
     EIGEN_DEVICE_FUNC
     inline Scalar coeff(Index row, Index col) const
     {
@@ -128,15 +128,15 @@
     template<typename OtherDerived> friend
     EIGEN_DEVICE_FUNC
     const Product<OtherDerived,SelfAdjointView>
     operator*(const MatrixBase<OtherDerived>& lhs, const SelfAdjointView& rhs)
     {
       return Product<OtherDerived,SelfAdjointView>(lhs.derived(),rhs);
     }
-    
+
     friend EIGEN_DEVICE_FUNC
     const SelfAdjointView<const EIGEN_SCALAR_BINARYOP_EXPR_RETURN_TYPE(Scalar,MatrixType,product),UpLo>
     operator*(const Scalar& s, const SelfAdjointView& mat)
     {
       return (s*mat.nestedExpression()).template selfadjointView<UpLo>();
     }
 
@@ -296,38 +296,38 @@
   typedef generic_dense_assignment_kernel<DstEvaluatorTypeT, SrcEvaluatorTypeT, Functor, Version> Base;
   typedef typename Base::DstXprType DstXprType;
   typedef typename Base::SrcXprType SrcXprType;
   using Base::m_dst;
   using Base::m_src;
   using Base::m_functor;
 public:
-  
+
   typedef typename Base::DstEvaluatorType DstEvaluatorType;
   typedef typename Base::SrcEvaluatorType SrcEvaluatorType;
   typedef typename Base::Scalar Scalar;
   typedef typename Base::AssignmentTraits AssignmentTraits;
-  
-  
+
+
   EIGEN_DEVICE_FUNC triangular_dense_assignment_kernel(DstEvaluatorType &dst, const SrcEvaluatorType &src, const Functor &func, DstXprType& dstExpr)
     : Base(dst, src, func, dstExpr)
   {}
-  
+
   EIGEN_DEVICE_FUNC void assignCoeff(Index row, Index col)
   {
     eigen_internal_assert(row!=col);
     Scalar tmp = m_src.coeff(row,col);
     m_functor.assignCoeff(m_dst.coeffRef(row,col), tmp);
     m_functor.assignCoeff(m_dst.coeffRef(col,row), numext::conj(tmp));
   }
-  
+
   EIGEN_DEVICE_FUNC void assignDiagonalCoeff(Index id)
   {
     Base::assignCoeff(id,id);
   }
-  
+
   EIGEN_DEVICE_FUNC void assignOppositeCoeff(Index, Index)
   { eigen_internal_assert(false && "should never be called"); }
 };
 
 } // end namespace internal
 
 /***************************************************************************
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/SelfCwiseBinaryOp.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/SelfCwiseBinaryOp.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Solve.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Solve.h`

 * *Files 2% similar despite different names*

```diff
@@ -9,15 +9,15 @@
 
 #ifndef EIGEN_SOLVE_H
 #define EIGEN_SOLVE_H
 
 namespace Eigen {
 
 template<typename Decomposition, typename RhsType, typename StorageKind> class SolveImpl;
-  
+
 /** \class Solve
   * \ingroup Core_Module
   *
   * \brief Pseudo expression representing a solving operation
   *
   * \tparam Decomposition the type of the matrix or decomposition object
   * \tparam Rhstype the type of the right-hand side
@@ -60,21 +60,21 @@
 
 template<typename Decomposition, typename RhsType>
 class Solve : public SolveImpl<Decomposition,RhsType,typename internal::traits<RhsType>::StorageKind>
 {
 public:
   typedef typename internal::traits<Solve>::PlainObject PlainObject;
   typedef typename internal::traits<Solve>::StorageIndex StorageIndex;
-  
+
   Solve(const Decomposition &dec, const RhsType &rhs)
     : m_dec(dec), m_rhs(rhs)
   {}
-  
-  EIGEN_DEVICE_FUNC Index rows() const { return m_dec.cols(); }
-  EIGEN_DEVICE_FUNC Index cols() const { return m_rhs.cols(); }
+
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index rows() const EIGEN_NOEXCEPT { return m_dec.cols(); }
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index cols() const EIGEN_NOEXCEPT { return m_rhs.cols(); }
 
   EIGEN_DEVICE_FUNC const Decomposition& dec() const { return m_dec; }
   EIGEN_DEVICE_FUNC const RhsType&       rhs() const { return m_rhs; }
 
 protected:
   const Decomposition &m_dec;
   const RhsType       &m_rhs;
@@ -83,22 +83,22 @@
 
 // Specialization of the Solve expression for dense results
 template<typename Decomposition, typename RhsType>
 class SolveImpl<Decomposition,RhsType,Dense>
   : public MatrixBase<Solve<Decomposition,RhsType> >
 {
   typedef Solve<Decomposition,RhsType> Derived;
-  
+
 public:
-  
+
   typedef MatrixBase<Solve<Decomposition,RhsType> > Base;
   EIGEN_DENSE_PUBLIC_INTERFACE(Derived)
 
 private:
-  
+
   Scalar coeff(Index row, Index col) const;
   Scalar coeff(Index i) const;
 };
 
 // Generic API dispatcher
 template<typename Decomposition, typename RhsType, typename StorageKind>
 class SolveImpl : public internal::generic_xpr_base<Solve<Decomposition,RhsType>, MatrixXpr, StorageKind>::type
@@ -115,23 +115,23 @@
   : public evaluator<typename Solve<Decomposition,RhsType>::PlainObject>
 {
   typedef Solve<Decomposition,RhsType> SolveType;
   typedef typename SolveType::PlainObject PlainObject;
   typedef evaluator<PlainObject> Base;
 
   enum { Flags = Base::Flags | EvalBeforeNestingBit };
-  
+
   EIGEN_DEVICE_FUNC explicit evaluator(const SolveType& solve)
     : m_result(solve.rows(), solve.cols())
   {
     ::new (static_cast<Base*>(this)) Base(m_result);
     solve.dec()._solve_impl(solve.rhs(), m_result);
   }
-  
-protected:  
+
+protected:
   PlainObject m_result;
 };
 
 // Specialization for "dst = dec.solve(rhs)"
 // NOTE we need to specialize it for Dense2Dense to avoid ambiguous specialization error and a Sparse2Sparse specialization must exist somewhere
 template<typename DstXprType, typename DecType, typename RhsType, typename Scalar>
 struct Assignment<DstXprType, Solve<DecType,RhsType>, internal::assign_op<Scalar,Scalar>, Dense2Dense>
@@ -172,15 +172,15 @@
   typedef Solve<CwiseUnaryOp<internal::scalar_conjugate_op<typename DecType::Scalar>, const Transpose<const DecType> >,RhsType> SrcXprType;
   static void run(DstXprType &dst, const SrcXprType &src, const internal::assign_op<Scalar,Scalar> &)
   {
     Index dstRows = src.rows();
     Index dstCols = src.cols();
     if((dst.rows()!=dstRows) || (dst.cols()!=dstCols))
       dst.resize(dstRows, dstCols);
-    
+
     src.dec().nestedExpression().nestedExpression().template _solve_impl_transposed<true>(src.rhs(), dst);
   }
 };
 
 } // end namespace internal
 
 } // end namespace Eigen
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/SolveTriangular.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/SolveTriangular.h`

 * *Files 8% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_SOLVETRIANGULAR_H
 #define EIGEN_SOLVETRIANGULAR_H
 
-namespace Eigen { 
+namespace Eigen {
 
 namespace internal {
 
 // Forward declarations:
 // The following two routines are implemented in the products/TriangularSolver*.h files
 template<typename LhsScalar, typename RhsScalar, typename Index, int Side, int Mode, bool Conjugate, int StorageOrder>
 struct triangular_solve_vector;
@@ -50,25 +50,25 @@
 struct triangular_solver_selector<Lhs,Rhs,Side,Mode,NoUnrolling,1>
 {
   typedef typename Lhs::Scalar LhsScalar;
   typedef typename Rhs::Scalar RhsScalar;
   typedef blas_traits<Lhs> LhsProductTraits;
   typedef typename LhsProductTraits::ExtractType ActualLhsType;
   typedef Map<Matrix<RhsScalar,Dynamic,1>, Aligned> MappedRhs;
-  static void run(const Lhs& lhs, Rhs& rhs)
+  static EIGEN_DEVICE_FUNC void run(const Lhs& lhs, Rhs& rhs)
   {
     ActualLhsType actualLhs = LhsProductTraits::extract(lhs);
 
     // FIXME find a way to allow an inner stride if packet_traits<Scalar>::size==1
 
     bool useRhsDirectly = Rhs::InnerStrideAtCompileTime==1 || rhs.innerStride()==1;
 
     ei_declare_aligned_stack_constructed_variable(RhsScalar,actualRhs,rhs.size(),
                                                   (useRhsDirectly ? rhs.data() : 0));
-                                                  
+
     if(!useRhsDirectly)
       MappedRhs(actualRhs,rhs.size()) = rhs;
 
     triangular_solve_vector<LhsScalar, RhsScalar, Index, Side, Mode, LhsProductTraits::NeedToConjugate,
                             (int(Lhs::Flags) & RowMajorBit) ? RowMajor : ColMajor>
       ::run(actualLhs.cols(), actualLhs.data(), actualLhs.outerStride(), actualRhs);
 
@@ -81,15 +81,15 @@
 template<typename Lhs, typename Rhs, int Side, int Mode>
 struct triangular_solver_selector<Lhs,Rhs,Side,Mode,NoUnrolling,Dynamic>
 {
   typedef typename Rhs::Scalar Scalar;
   typedef blas_traits<Lhs> LhsProductTraits;
   typedef typename LhsProductTraits::DirectLinearAccessType ActualLhsType;
 
-  static void run(const Lhs& lhs, Rhs& rhs)
+  static EIGEN_DEVICE_FUNC void run(const Lhs& lhs, Rhs& rhs)
   {
     typename internal::add_const_on_value_type<ActualLhsType>::type actualLhs = LhsProductTraits::extract(lhs);
 
     const Index size = lhs.rows();
     const Index othersize = Side==OnTheLeft? rhs.cols() : rhs.rows();
 
     typedef internal::gemm_blocking_space<(Rhs::Flags&RowMajorBit) ? RowMajor : ColMajor,Scalar,Scalar,
@@ -114,45 +114,45 @@
 template<typename Lhs, typename Rhs, int Mode, int LoopIndex, int Size>
 struct triangular_solver_unroller<Lhs,Rhs,Mode,LoopIndex,Size,false> {
   enum {
     IsLower = ((Mode&Lower)==Lower),
     DiagIndex  = IsLower ? LoopIndex : Size - LoopIndex - 1,
     StartIndex = IsLower ? 0         : DiagIndex+1
   };
-  static void run(const Lhs& lhs, Rhs& rhs)
+  static EIGEN_DEVICE_FUNC void run(const Lhs& lhs, Rhs& rhs)
   {
     if (LoopIndex>0)
       rhs.coeffRef(DiagIndex) -= lhs.row(DiagIndex).template segment<LoopIndex>(StartIndex).transpose()
                                 .cwiseProduct(rhs.template segment<LoopIndex>(StartIndex)).sum();
 
     if(!(Mode & UnitDiag))
       rhs.coeffRef(DiagIndex) /= lhs.coeff(DiagIndex,DiagIndex);
 
     triangular_solver_unroller<Lhs,Rhs,Mode,LoopIndex+1,Size>::run(lhs,rhs);
   }
 };
 
 template<typename Lhs, typename Rhs, int Mode, int LoopIndex, int Size>
 struct triangular_solver_unroller<Lhs,Rhs,Mode,LoopIndex,Size,true> {
-  static void run(const Lhs&, Rhs&) {}
+  static EIGEN_DEVICE_FUNC void run(const Lhs&, Rhs&) {}
 };
 
 template<typename Lhs, typename Rhs, int Mode>
 struct triangular_solver_selector<Lhs,Rhs,OnTheLeft,Mode,CompleteUnrolling,1> {
-  static void run(const Lhs& lhs, Rhs& rhs)
+  static EIGEN_DEVICE_FUNC void run(const Lhs& lhs, Rhs& rhs)
   { triangular_solver_unroller<Lhs,Rhs,Mode,0,Rhs::SizeAtCompileTime>::run(lhs,rhs); }
 };
 
 template<typename Lhs, typename Rhs, int Mode>
 struct triangular_solver_selector<Lhs,Rhs,OnTheRight,Mode,CompleteUnrolling,1> {
-  static void run(const Lhs& lhs, Rhs& rhs)
+  static EIGEN_DEVICE_FUNC void run(const Lhs& lhs, Rhs& rhs)
   {
     Transpose<const Lhs> trLhs(lhs);
     Transpose<Rhs> trRhs(rhs);
-    
+
     triangular_solver_unroller<Transpose<const Lhs>,Transpose<Rhs>,
                               ((Mode&Upper)==Upper ? Lower : Upper) | (Mode&UnitDiag),
                               0,Rhs::SizeAtCompileTime>::run(trLhs,trRhs);
   }
 };
 
 } // end namespace internal
@@ -164,15 +164,15 @@
 #ifndef EIGEN_PARSED_BY_DOXYGEN
 template<typename MatrixType, unsigned int Mode>
 template<int Side, typename OtherDerived>
 EIGEN_DEVICE_FUNC void TriangularViewImpl<MatrixType,Mode,Dense>::solveInPlace(const MatrixBase<OtherDerived>& _other) const
 {
   OtherDerived& other = _other.const_cast_derived();
   eigen_assert( derived().cols() == derived().rows() && ((Side==OnTheLeft && derived().cols() == other.rows()) || (Side==OnTheRight && derived().cols() == other.cols())) );
-  eigen_assert((!(Mode & ZeroDiag)) && bool(Mode & (Upper|Lower)));
+  eigen_assert((!(int(Mode) & int(ZeroDiag))) && bool(int(Mode) & (int(Upper) | int(Lower))));
   // If solving for a 0x0 matrix, nothing to do, simply return.
   if (derived().cols() == 0)
     return;
 
   enum { copy = (internal::traits<OtherDerived>::Flags & RowMajorBit)  && OtherDerived::IsVectorAtCompileTime && OtherDerived::SizeAtCompileTime!=1};
   typedef typename internal::conditional<copy,
     typename internal::plain_matrix_type_column_major<OtherDerived>::type, OtherDerived&>::type OtherCopy;
@@ -209,16 +209,16 @@
   typedef typename remove_all<typename Rhs::Nested>::type RhsNestedCleaned;
   typedef ReturnByValue<triangular_solve_retval> Base;
 
   triangular_solve_retval(const TriangularType& tri, const Rhs& rhs)
     : m_triangularMatrix(tri), m_rhs(rhs)
   {}
 
-  inline Index rows() const { return m_rhs.rows(); }
-  inline Index cols() const { return m_rhs.cols(); }
+  inline EIGEN_CONSTEXPR Index rows() const EIGEN_NOEXCEPT { return m_rhs.rows(); }
+  inline EIGEN_CONSTEXPR Index cols() const EIGEN_NOEXCEPT { return m_rhs.cols(); }
 
   template<typename Dest> inline void evalTo(Dest& dst) const
   {
     if(!is_same_dense(dst,m_rhs))
       dst = m_rhs;
     m_triangularMatrix.template solveInPlace<Side>(dst);
   }
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/SolverBase.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/SolverBase.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/StableNorm.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/StableNorm.h`

 * *Files 10% similar despite different names*

```diff
@@ -119,60 +119,47 @@
 inline typename NumTraits<typename traits<Derived>::Scalar>::Real
 blueNorm_impl(const EigenBase<Derived>& _vec)
 {
   typedef typename Derived::RealScalar RealScalar;  
   using std::pow;
   using std::sqrt;
   using std::abs;
-  const Derived& vec(_vec.derived());
-  static bool initialized = false;
-  static RealScalar b1, b2, s1m, s2m, rbig, relerr;
-  if(!initialized)
-  {
-    int ibeta, it, iemin, iemax, iexp;
-    RealScalar eps;
-    // This program calculates the machine-dependent constants
-    // bl, b2, slm, s2m, relerr overfl
-    // from the "basic" machine-dependent numbers
-    // nbig, ibeta, it, iemin, iemax, rbig.
-    // The following define the basic machine-dependent constants.
-    // For portability, the PORT subprograms "ilmaeh" and "rlmach"
-    // are used. For any specific computer, each of the assignment
-    // statements can be replaced
-    ibeta = std::numeric_limits<RealScalar>::radix;                 // base for floating-point numbers
-    it    = NumTraits<RealScalar>::digits();                        // number of base-beta digits in mantissa
-    iemin = std::numeric_limits<RealScalar>::min_exponent;          // minimum exponent
-    iemax = std::numeric_limits<RealScalar>::max_exponent;          // maximum exponent
-    rbig  = (std::numeric_limits<RealScalar>::max)();               // largest floating-point number
-
-    iexp  = -((1-iemin)/2);
-    b1    = RealScalar(pow(RealScalar(ibeta),RealScalar(iexp)));    // lower boundary of midrange
-    iexp  = (iemax + 1 - it)/2;
-    b2    = RealScalar(pow(RealScalar(ibeta),RealScalar(iexp)));    // upper boundary of midrange
 
-    iexp  = (2-iemin)/2;
-    s1m   = RealScalar(pow(RealScalar(ibeta),RealScalar(iexp)));    // scaling factor for lower range
-    iexp  = - ((iemax+it)/2);
-    s2m   = RealScalar(pow(RealScalar(ibeta),RealScalar(iexp)));    // scaling factor for upper range
+  // This program calculates the machine-dependent constants
+  // bl, b2, slm, s2m, relerr overfl
+  // from the "basic" machine-dependent numbers
+  // nbig, ibeta, it, iemin, iemax, rbig.
+  // The following define the basic machine-dependent constants.
+  // For portability, the PORT subprograms "ilmaeh" and "rlmach"
+  // are used. For any specific computer, each of the assignment
+  // statements can be replaced
+  static const int ibeta = std::numeric_limits<RealScalar>::radix;  // base for floating-point numbers
+  static const int it    = NumTraits<RealScalar>::digits();  // number of base-beta digits in mantissa
+  static const int iemin = NumTraits<RealScalar>::min_exponent();  // minimum exponent
+  static const int iemax = NumTraits<RealScalar>::max_exponent();  // maximum exponent
+  static const RealScalar rbig   = NumTraits<RealScalar>::highest();  // largest floating-point number
+  static const RealScalar b1     = RealScalar(pow(RealScalar(ibeta),RealScalar(-((1-iemin)/2))));  // lower boundary of midrange
+  static const RealScalar b2     = RealScalar(pow(RealScalar(ibeta),RealScalar((iemax + 1 - it)/2)));  // upper boundary of midrange
+  static const RealScalar s1m    = RealScalar(pow(RealScalar(ibeta),RealScalar((2-iemin)/2)));  // scaling factor for lower range
+  static const RealScalar s2m    = RealScalar(pow(RealScalar(ibeta),RealScalar(- ((iemax+it)/2))));  // scaling factor for upper range
+  static const RealScalar eps    = RealScalar(pow(double(ibeta), 1-it));
+  static const RealScalar relerr = sqrt(eps);  // tolerance for neglecting asml
 
-    eps     = RealScalar(pow(double(ibeta), 1-it));
-    relerr  = sqrt(eps);                                            // tolerance for neglecting asml
-    initialized = true;
-  }
+  const Derived& vec(_vec.derived());
   Index n = vec.size();
   RealScalar ab2 = b2 / RealScalar(n);
   RealScalar asml = RealScalar(0);
   RealScalar amed = RealScalar(0);
   RealScalar abig = RealScalar(0);
 
   for(Index j=0; j<vec.outerSize(); ++j)
   {
-    for(typename Derived::InnerIterator it(vec, j); it; ++it)
+    for(typename Derived::InnerIterator iter(vec, j); iter; ++iter)
     {
-      RealScalar ax = abs(it.value());
+      RealScalar ax = abs(iter.value());
       if(ax > ab2)     abig += numext::abs2(ax*s2m);
       else if(ax < b1) asml += numext::abs2(ax*s1m);
       else             amed += numext::abs2(ax);
     }
   }
   if(amed!=amed)
     return amed;  // we got a NaN
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/StlIterators.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/StlIterators.h`

 * *Files 4% similar despite different names*

```diff
@@ -3,14 +3,17 @@
 //
 // Copyright (C) 2018 Gael Guennebaud <gael.guennebaud@inria.fr>
 //
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
+#ifndef EIGEN_STLITERATORS_H
+#define EIGEN_STLITERATORS_H
+
 namespace Eigen {
 
 namespace internal {
 
 template<typename IteratorType>
 struct indexed_based_stl_iterator_traits;
 
@@ -26,18 +29,18 @@
   // NOTE: in C++03 we cannot declare friend classes through typedefs because we need to write friend class:
   friend class indexed_based_stl_iterator_base<typename traits::const_iterator>;
   friend class indexed_based_stl_iterator_base<typename traits::non_const_iterator>;
 public:
   typedef Index difference_type;
   typedef std::random_access_iterator_tag iterator_category;
 
-  indexed_based_stl_iterator_base() : mp_xpr(0), m_index(0) {}
-  indexed_based_stl_iterator_base(XprType& xpr, Index index) : mp_xpr(&xpr), m_index(index) {}
+  indexed_based_stl_iterator_base() EIGEN_NO_THROW : mp_xpr(0), m_index(0) {}
+  indexed_based_stl_iterator_base(XprType& xpr, Index index) EIGEN_NO_THROW : mp_xpr(&xpr), m_index(index) {}
 
-  indexed_based_stl_iterator_base(const non_const_iterator& other)
+  indexed_based_stl_iterator_base(const non_const_iterator& other) EIGEN_NO_THROW
     : mp_xpr(other.mp_xpr), m_index(other.m_index)
   {}
 
   indexed_based_stl_iterator_base& operator=(const non_const_iterator& other)
   {
     mp_xpr = other.mp_xpr;
     m_index = other.m_index;
@@ -186,25 +189,25 @@
   typedef Index difference_type;
   typedef typename XprType::Scalar value_type;
   typedef std::random_access_iterator_tag iterator_category;
   typedef typename internal::conditional<bool(is_lvalue), value_type*, const value_type*>::type pointer;
   typedef typename internal::conditional<bool(is_lvalue), value_type&, const value_type&>::type reference;
 
 
-  pointer_based_stl_iterator() : m_ptr(0) {}
-  pointer_based_stl_iterator(XprType& xpr, Index index) : m_incr(xpr.innerStride())
+  pointer_based_stl_iterator() EIGEN_NO_THROW : m_ptr(0) {}
+  pointer_based_stl_iterator(XprType& xpr, Index index) EIGEN_NO_THROW : m_incr(xpr.innerStride())
   {
     m_ptr = xpr.data() + index * m_incr.value();
   }
 
-  pointer_based_stl_iterator(const non_const_iterator& other)
+  pointer_based_stl_iterator(const non_const_iterator& other) EIGEN_NO_THROW
     : m_ptr(other.m_ptr), m_incr(other.m_incr)
   {}
 
-  pointer_based_stl_iterator& operator=(const non_const_iterator& other)
+  pointer_based_stl_iterator& operator=(const non_const_iterator& other) EIGEN_NO_THROW
   {
     m_ptr = other.m_ptr;
     m_incr.setValue(other.m_incr);
     return *this;
   }
 
   reference operator*()         const { return *m_ptr;   }
@@ -452,7 +455,9 @@
 inline typename DenseBase<Derived>::const_iterator DenseBase<Derived>::cend() const
 {
   EIGEN_STATIC_ASSERT_VECTOR_ONLY(Derived);
   return const_iterator(derived(), size());
 }
 
 } // namespace Eigen
+
+#endif // EIGEN_STLITERATORS_H
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Stride.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Stride.h`

 * *Files 3% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_STRIDE_H
 #define EIGEN_STRIDE_H
 
-namespace Eigen { 
+namespace Eigen {
 
 /** \class Stride
   * \ingroup Core_Module
   *
   * \brief Holds strides information for Map
   *
   * This class holds the strides information for mapping arrays with strides with class Map.
@@ -34,14 +34,18 @@
   *  \tparam _OuterStrideAtCompileTime the outer stride, or Dynamic if you want to specify it at runtime.
   *  \tparam _InnerStrideAtCompileTime the inner stride, or Dynamic if you want to specify it at runtime.
   *
   * Here is an example:
   * \include Map_general_stride.cpp
   * Output: \verbinclude Map_general_stride.out
   *
+  * Both strides can be negative, however, a negative stride of -1 cannot be specified at compiletime
+  * because of the ambiguity with Dynamic which is defined to -1 (historically, negative strides were
+  * not allowed).
+  *
   * \sa class InnerStride, class OuterStride, \ref TopicStorageOrders
   */
 template<int _OuterStrideAtCompileTime, int _InnerStrideAtCompileTime>
 class Stride
 {
   public:
     typedef Eigen::Index Index; ///< \deprecated since Eigen 3.3
@@ -51,36 +55,37 @@
     };
 
     /** Default constructor, for use when strides are fixed at compile time */
     EIGEN_DEVICE_FUNC
     Stride()
       : m_outer(OuterStrideAtCompileTime), m_inner(InnerStrideAtCompileTime)
     {
+      // FIXME: for Eigen 4 we should use DynamicIndex instead of Dynamic.
+      // FIXME: for Eigen 4 we should also unify this API with fix<>
       eigen_assert(InnerStrideAtCompileTime != Dynamic && OuterStrideAtCompileTime != Dynamic);
     }
 
     /** Constructor allowing to pass the strides at runtime */
     EIGEN_DEVICE_FUNC
     Stride(Index outerStride, Index innerStride)
       : m_outer(outerStride), m_inner(innerStride)
     {
-      eigen_assert(innerStride>=0 && outerStride>=0);
     }
 
     /** Copy constructor */
     EIGEN_DEVICE_FUNC
     Stride(const Stride& other)
       : m_outer(other.outer()), m_inner(other.inner())
     {}
 
     /** \returns the outer stride */
-    EIGEN_DEVICE_FUNC
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
     inline Index outer() const { return m_outer.value(); }
     /** \returns the inner stride */
-    EIGEN_DEVICE_FUNC
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
     inline Index inner() const { return m_inner.value(); }
 
   protected:
     internal::variable_if_dynamic<Index, OuterStrideAtCompileTime> m_outer;
     internal::variable_if_dynamic<Index, InnerStrideAtCompileTime> m_inner;
 };
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Swap.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Swap.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Transpose.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Transpose.h`

 * *Files 1% similar despite different names*

```diff
@@ -7,15 +7,15 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_TRANSPOSE_H
 #define EIGEN_TRANSPOSE_H
 
-namespace Eigen { 
+namespace Eigen {
 
 namespace internal {
 template<typename MatrixType>
 struct traits<Transpose<MatrixType> > : public traits<MatrixType>
 {
   typedef typename ref_selector<MatrixType>::type MatrixTypeNested;
   typedef typename remove_reference<MatrixTypeNested>::type MatrixTypeNestedPlain;
@@ -61,18 +61,18 @@
     typedef typename internal::remove_all<MatrixType>::type NestedExpression;
 
     EIGEN_DEVICE_FUNC
     explicit EIGEN_STRONG_INLINE Transpose(MatrixType& matrix) : m_matrix(matrix) {}
 
     EIGEN_INHERIT_ASSIGNMENT_OPERATORS(Transpose)
 
-    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    Index rows() const { return m_matrix.cols(); }
-    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    Index cols() const { return m_matrix.rows(); }
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    Index rows() const EIGEN_NOEXCEPT { return m_matrix.cols(); }
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    Index cols() const EIGEN_NOEXCEPT { return m_matrix.rows(); }
 
     /** \returns the nested expression */
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
     const typename internal::remove_all<MatrixTypeNested>::type&
     nestedExpression() const { return m_matrix; }
 
     /** \returns the nested expression */
@@ -332,15 +332,15 @@
   * \endcode
   * and is faster and also safer because in the latter line of code, forgetting the eval() results
   * in a bug caused by \ref TopicAliasing "aliasing".
   *
   * Notice however that this method is only useful if you want to replace a matrix by its own transpose.
   * If you just need the transpose of a matrix, use transpose().
   *
-  * \note if the matrix is not square, then \c *this must be a resizable matrix. 
+  * \note if the matrix is not square, then \c *this must be a resizable matrix.
   * This excludes (non-square) fixed-size matrices, block-expressions and maps.
   *
   * \sa transpose(), adjoint(), adjointInPlace() */
 template<typename Derived>
 EIGEN_DEVICE_FUNC inline void DenseBase<Derived>::transposeInPlace()
 {
   eigen_assert((rows() == cols() || (RowsAtCompileTime == Dynamic && ColsAtCompileTime == Dynamic))
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Transpositions.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Transpositions.h`

 * *Files 4% similar despite different names*

```diff
@@ -6,61 +6,69 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_TRANSPOSITIONS_H
 #define EIGEN_TRANSPOSITIONS_H
 
-namespace Eigen { 
+namespace Eigen {
 
 template<typename Derived>
 class TranspositionsBase
 {
     typedef internal::traits<Derived> Traits;
-    
+
   public:
 
     typedef typename Traits::IndicesType IndicesType;
     typedef typename IndicesType::Scalar StorageIndex;
     typedef Eigen::Index Index; ///< \deprecated since Eigen 3.3
 
+    EIGEN_DEVICE_FUNC
     Derived& derived() { return *static_cast<Derived*>(this); }
+    EIGEN_DEVICE_FUNC
     const Derived& derived() const { return *static_cast<const Derived*>(this); }
 
     /** Copies the \a other transpositions into \c *this */
     template<typename OtherDerived>
     Derived& operator=(const TranspositionsBase<OtherDerived>& other)
     {
       indices() = other.indices();
       return derived();
     }
 
     /** \returns the number of transpositions */
+    EIGEN_DEVICE_FUNC
     Index size() const { return indices().size(); }
     /** \returns the number of rows of the equivalent permutation matrix */
+    EIGEN_DEVICE_FUNC
     Index rows() const { return indices().size(); }
     /** \returns the number of columns of the equivalent permutation matrix */
+    EIGEN_DEVICE_FUNC
     Index cols() const { return indices().size(); }
 
     /** Direct access to the underlying index vector */
+    EIGEN_DEVICE_FUNC
     inline const StorageIndex& coeff(Index i) const { return indices().coeff(i); }
     /** Direct access to the underlying index vector */
     inline StorageIndex& coeffRef(Index i) { return indices().coeffRef(i); }
     /** Direct access to the underlying index vector */
     inline const StorageIndex& operator()(Index i) const { return indices()(i); }
     /** Direct access to the underlying index vector */
     inline StorageIndex& operator()(Index i) { return indices()(i); }
     /** Direct access to the underlying index vector */
     inline const StorageIndex& operator[](Index i) const { return indices()(i); }
     /** Direct access to the underlying index vector */
     inline StorageIndex& operator[](Index i) { return indices()(i); }
 
     /** const version of indices(). */
+    EIGEN_DEVICE_FUNC
     const IndicesType& indices() const { return derived().indices(); }
     /** \returns a reference to the stored array representing the transpositions. */
+    EIGEN_DEVICE_FUNC
     IndicesType& indices() { return derived().indices(); }
 
     /** Resizes to given size. */
     inline void resize(Index newSize)
     {
       indices().resize(newSize);
     }
@@ -174,16 +182,18 @@
 
     /** Constructs an uninitialized permutation matrix of given size.
       */
     inline Transpositions(Index size) : m_indices(size)
     {}
 
     /** const version of indices(). */
+    EIGEN_DEVICE_FUNC
     const IndicesType& indices() const { return m_indices; }
     /** \returns a reference to the stored array representing the transpositions. */
+    EIGEN_DEVICE_FUNC
     IndicesType& indices() { return m_indices; }
 
   protected:
 
     IndicesType m_indices;
 };
 
@@ -233,17 +243,19 @@
     {
       m_indices = other.m_indices;
       return *this;
     }
     #endif
 
     /** const version of indices(). */
+    EIGEN_DEVICE_FUNC
     const IndicesType& indices() const { return m_indices; }
-    
+
     /** \returns a reference to the stored array representing the transpositions. */
+    EIGEN_DEVICE_FUNC
     IndicesType& indices() { return m_indices; }
 
   protected:
 
     IndicesType m_indices;
 };
 
@@ -275,17 +287,19 @@
     template<typename OtherDerived>
     TranspositionsWrapper& operator=(const TranspositionsBase<OtherDerived>& other)
     {
       return Base::operator=(other);
     }
 
     /** const version of indices(). */
+    EIGEN_DEVICE_FUNC
     const IndicesType& indices() const { return m_indices; }
 
     /** \returns a reference to the stored array representing the transpositions. */
+    EIGEN_DEVICE_FUNC
     IndicesType& indices() { return m_indices; }
 
   protected:
 
     typename IndicesType::Nested m_indices;
 };
 
@@ -331,17 +345,20 @@
 {
     typedef TranspositionsDerived TranspositionType;
     typedef typename TranspositionType::IndicesType IndicesType;
   public:
 
     explicit Transpose(const TranspositionType& t) : m_transpositions(t) {}
 
-    Index size() const { return m_transpositions.size(); }
-    Index rows() const { return m_transpositions.size(); }
-    Index cols() const { return m_transpositions.size(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    Index size() const EIGEN_NOEXCEPT { return m_transpositions.size(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    Index rows() const EIGEN_NOEXCEPT { return m_transpositions.size(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    Index cols() const EIGEN_NOEXCEPT { return m_transpositions.size(); }
 
     /** \returns the \a matrix with the inverse transpositions applied to the columns.
       */
     template<typename OtherDerived> friend
     const Product<OtherDerived, Transpose, AliasFreeProduct>
     operator*(const MatrixBase<OtherDerived>& matrix, const Transpose& trt)
     {
@@ -352,15 +369,16 @@
       */
     template<typename OtherDerived>
     const Product<Transpose, OtherDerived, AliasFreeProduct>
     operator*(const MatrixBase<OtherDerived>& matrix) const
     {
       return Product<Transpose, OtherDerived, AliasFreeProduct>(*this, matrix.derived());
     }
-    
+
+    EIGEN_DEVICE_FUNC
     const TranspositionType& nestedExpression() const { return m_transpositions; }
 
   protected:
     const TranspositionType& m_transpositions;
 };
 
 } // end namespace Eigen
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/TriangularMatrix.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/TriangularMatrix.h`

 * *Files 4% similar despite different names*

```diff
@@ -7,20 +7,20 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_TRIANGULARMATRIX_H
 #define EIGEN_TRIANGULARMATRIX_H
 
-namespace Eigen { 
+namespace Eigen {
 
 namespace internal {
-  
+
 template<int Side, typename TriangularType, typename Rhs> struct triangular_solve_retval;
-  
+
 }
 
 /** \class TriangularBase
   * \ingroup Core_Module
   *
   * \brief Base class for triangular part in a matrix
   */
@@ -30,44 +30,44 @@
 
     enum {
       Mode = internal::traits<Derived>::Mode,
       RowsAtCompileTime = internal::traits<Derived>::RowsAtCompileTime,
       ColsAtCompileTime = internal::traits<Derived>::ColsAtCompileTime,
       MaxRowsAtCompileTime = internal::traits<Derived>::MaxRowsAtCompileTime,
       MaxColsAtCompileTime = internal::traits<Derived>::MaxColsAtCompileTime,
-      
+
       SizeAtCompileTime = (internal::size_at_compile_time<internal::traits<Derived>::RowsAtCompileTime,
                                                    internal::traits<Derived>::ColsAtCompileTime>::ret),
       /**< This is equal to the number of coefficients, i.e. the number of
           * rows times the number of columns, or to \a Dynamic if this is not
           * known at compile-time. \sa RowsAtCompileTime, ColsAtCompileTime */
-      
+
       MaxSizeAtCompileTime = (internal::size_at_compile_time<internal::traits<Derived>::MaxRowsAtCompileTime,
                                                    internal::traits<Derived>::MaxColsAtCompileTime>::ret)
-        
+
     };
     typedef typename internal::traits<Derived>::Scalar Scalar;
     typedef typename internal::traits<Derived>::StorageKind StorageKind;
     typedef typename internal::traits<Derived>::StorageIndex StorageIndex;
     typedef typename internal::traits<Derived>::FullMatrixType DenseMatrixType;
     typedef DenseMatrixType DenseType;
     typedef Derived const& Nested;
 
     EIGEN_DEVICE_FUNC
-    inline TriangularBase() { eigen_assert(!((Mode&UnitDiag) && (Mode&ZeroDiag))); }
+    inline TriangularBase() { eigen_assert(!((int(Mode) & int(UnitDiag)) && (int(Mode) & int(ZeroDiag)))); }
+
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index rows() const EIGEN_NOEXCEPT { return derived().rows(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index cols() const EIGEN_NOEXCEPT { return derived().cols(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index outerStride() const EIGEN_NOEXCEPT { return derived().outerStride(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index innerStride() const EIGEN_NOEXCEPT { return derived().innerStride(); }
 
-    EIGEN_DEVICE_FUNC
-    inline Index rows() const { return derived().rows(); }
-    EIGEN_DEVICE_FUNC
-    inline Index cols() const { return derived().cols(); }
-    EIGEN_DEVICE_FUNC
-    inline Index outerStride() const { return derived().outerStride(); }
-    EIGEN_DEVICE_FUNC
-    inline Index innerStride() const { return derived().innerStride(); }
-    
     // dummy resize function
     EIGEN_DEVICE_FUNC
     void resize(Index rows, Index cols)
     {
       EIGEN_UNUSED_VARIABLE(rows);
       EIGEN_UNUSED_VARIABLE(cols);
       eigen_assert(rows==this->rows() && cols==this->cols());
@@ -152,15 +152,15 @@
   * \ingroup Core_Module
   *
   * \brief Expression of a triangular part in a matrix
   *
   * \param MatrixType the type of the object in which we are taking the triangular part
   * \param Mode the kind of triangular matrix expression to construct. Can be #Upper,
   *             #Lower, #UnitUpper, #UnitLower, #StrictlyUpper, or #StrictlyLower.
-  *             This is in fact a bit field; it must have either #Upper or #Lower, 
+  *             This is in fact a bit field; it must have either #Upper or #Lower,
   *             and additionally it may have #UnitDiag or #ZeroDiag or neither.
   *
   * This class represents a triangular part of a matrix, not necessarily square. Strictly speaking, for rectangular
   * matrices one should speak of "trapezoid" parts. This class is the return type
   * of MatrixBase::triangularView() and SparseMatrixBase::triangularView(), and most of the time this is the only way it is used.
   *
   * \sa MatrixBase::triangularView()
@@ -195,15 +195,15 @@
 
   protected:
     typedef typename internal::traits<TriangularView>::MatrixTypeNested MatrixTypeNested;
     typedef typename internal::traits<TriangularView>::MatrixTypeNestedNonRef MatrixTypeNestedNonRef;
 
     typedef typename internal::remove_all<typename MatrixType::ConjugateReturnType>::type MatrixConjugateReturnType;
     typedef TriangularView<typename internal::add_const<MatrixType>::type, _Mode> ConstTriangularView;
-    
+
   public:
 
     typedef typename internal::traits<TriangularView>::StorageKind StorageKind;
     typedef typename internal::traits<TriangularView>::MatrixTypeNestedCleaned NestedExpression;
 
     enum {
       Mode = _Mode,
@@ -214,32 +214,32 @@
                     | (Mode & (ZeroDiag)),
       IsVectorAtCompileTime = false
     };
 
     EIGEN_DEVICE_FUNC
     explicit inline TriangularView(MatrixType& matrix) : m_matrix(matrix)
     {}
-    
+
     EIGEN_INHERIT_ASSIGNMENT_OPERATORS(TriangularView)
 
     /** \copydoc EigenBase::rows() */
-    EIGEN_DEVICE_FUNC
-    inline Index rows() const { return m_matrix.rows(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index rows() const EIGEN_NOEXCEPT { return m_matrix.rows(); }
     /** \copydoc EigenBase::cols() */
-    EIGEN_DEVICE_FUNC
-    inline Index cols() const { return m_matrix.cols(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index cols() const EIGEN_NOEXCEPT { return m_matrix.cols(); }
 
     /** \returns a const reference to the nested expression */
     EIGEN_DEVICE_FUNC
     const NestedExpression& nestedExpression() const { return m_matrix; }
 
     /** \returns a reference to the nested expression */
     EIGEN_DEVICE_FUNC
     NestedExpression& nestedExpression() { return m_matrix; }
-    
+
     typedef TriangularView<const MatrixConjugateReturnType,Mode> ConjugateReturnType;
     /** \sa MatrixBase::conjugate() const */
     EIGEN_DEVICE_FUNC
     inline const ConjugateReturnType conjugate() const
     { return ConjugateReturnType(m_matrix.conjugate()); }
 
     /** \returns an expression of the complex conjugate of \c *this if Cond==true,
@@ -265,29 +265,29 @@
     EIGEN_DEVICE_FUNC
     inline TransposeReturnType transpose()
     {
       EIGEN_STATIC_ASSERT_LVALUE(MatrixType)
       typename MatrixType::TransposeReturnType tmp(m_matrix);
       return TransposeReturnType(tmp);
     }
-    
+
     typedef TriangularView<const typename MatrixType::ConstTransposeReturnType,TransposeMode> ConstTransposeReturnType;
     /** \sa MatrixBase::transpose() const */
     EIGEN_DEVICE_FUNC
     inline const ConstTransposeReturnType transpose() const
     {
       return ConstTransposeReturnType(m_matrix.transpose());
     }
 
     template<typename Other>
     EIGEN_DEVICE_FUNC
-    inline const Solve<TriangularView, Other> 
+    inline const Solve<TriangularView, Other>
     solve(const MatrixBase<Other>& other) const
     { return Solve<TriangularView, Other>(*this, other.derived()); }
-    
+
   // workaround MSVC ICE
   #if EIGEN_COMP_MSVC
     template<int Side, typename Other>
     EIGEN_DEVICE_FUNC
     inline const internal::triangular_solve_retval<Side,TriangularView, Other>
     solve(const MatrixBase<Other>& other) const
     { return Base::template solve<Side>(other); }
@@ -323,15 +323,15 @@
       if (Mode & UnitDiag)
         return 1;
       else if (Mode & ZeroDiag)
         return 0;
       else
         return m_matrix.diagonal().prod();
     }
-      
+
   protected:
 
     MatrixTypeNested m_matrix;
 };
 
 /** \ingroup Core_Module
   *
@@ -385,15 +385,15 @@
     /** \sa MatrixBase::operator-=() */
     template<typename Other>
     EIGEN_DEVICE_FUNC
     TriangularViewType&  operator-=(const DenseBase<Other>& other) {
       internal::call_assignment_no_alias(derived(), other.derived(), internal::sub_assign_op<Scalar,typename Other::Scalar>());
       return derived();
     }
-    
+
     /** \sa MatrixBase::operator*=() */
     EIGEN_DEVICE_FUNC
     TriangularViewType&  operator*=(const typename internal::traits<MatrixType>::Scalar& other) { return *this = derived().nestedExpression() * other; }
     /** \sa DenseBase::operator/=() */
     EIGEN_DEVICE_FUNC
     TriangularViewType&  operator/=(const typename internal::traits<MatrixType>::Scalar& other) { return *this = derived().nestedExpression() / other; }
 
@@ -711,15 +711,15 @@
 ****************************************************************************
 * Evaluators and Assignment of triangular expressions
 ***************************************************************************
 ***************************************************************************/
 
 namespace internal {
 
-  
+
 // TODO currently a triangular expression has the form TriangularView<.,.>
 //      in the future triangular-ness should be defined by the expression traits
 //      such that Transpose<TriangularView<.,.> > is valid. (currently TriangularBase::transpose() is overloaded to make it work)
 template<typename MatrixType, unsigned int Mode>
 struct evaluator_traits<TriangularView<MatrixType,Mode> >
 {
   typedef typename storage_kind_to_evaluator_kind<typename MatrixType::StorageKind>::Kind Kind;
@@ -740,15 +740,15 @@
 struct Triangular2Triangular    {};
 struct Triangular2Dense         {};
 struct Dense2Triangular         {};
 
 
 template<typename Kernel, unsigned int Mode, int UnrollCount, bool ClearOpposite> struct triangular_assignment_loop;
 
- 
+
 /** \internal Specialization of the dense assignment kernel for triangular matrices.
   * The main difference is that the triangular, diagonal, and opposite parts are processed through three different functions.
   * \tparam UpLo must be either Lower or Upper
   * \tparam Mode must be either 0, UnitDiag, ZeroDiag, or SelfAdjoint
   */
 template<int UpLo, int Mode, int SetOpposite, typename DstEvaluatorTypeT, typename SrcEvaluatorTypeT, typename Functor, int Version = Specialized>
 class triangular_dense_assignment_kernel : public generic_dense_assignment_kernel<DstEvaluatorTypeT, SrcEvaluatorTypeT, Functor, Version>
@@ -757,44 +757,44 @@
   typedef generic_dense_assignment_kernel<DstEvaluatorTypeT, SrcEvaluatorTypeT, Functor, Version> Base;
   typedef typename Base::DstXprType DstXprType;
   typedef typename Base::SrcXprType SrcXprType;
   using Base::m_dst;
   using Base::m_src;
   using Base::m_functor;
 public:
-  
+
   typedef typename Base::DstEvaluatorType DstEvaluatorType;
   typedef typename Base::SrcEvaluatorType SrcEvaluatorType;
   typedef typename Base::Scalar Scalar;
   typedef typename Base::AssignmentTraits AssignmentTraits;
-  
-  
+
+
   EIGEN_DEVICE_FUNC triangular_dense_assignment_kernel(DstEvaluatorType &dst, const SrcEvaluatorType &src, const Functor &func, DstXprType& dstExpr)
     : Base(dst, src, func, dstExpr)
   {}
-  
+
 #ifdef EIGEN_INTERNAL_DEBUGGING
   EIGEN_DEVICE_FUNC void assignCoeff(Index row, Index col)
   {
     eigen_internal_assert(row!=col);
     Base::assignCoeff(row,col);
   }
 #else
   using Base::assignCoeff;
 #endif
-  
+
   EIGEN_DEVICE_FUNC void assignDiagonalCoeff(Index id)
   {
          if(Mode==UnitDiag && SetOpposite) m_functor.assignCoeff(m_dst.coeffRef(id,id), Scalar(1));
     else if(Mode==ZeroDiag && SetOpposite) m_functor.assignCoeff(m_dst.coeffRef(id,id), Scalar(0));
     else if(Mode==0)                       Base::assignCoeff(id,id);
   }
-  
+
   EIGEN_DEVICE_FUNC void assignOppositeCoeff(Index row, Index col)
-  { 
+  {
     eigen_internal_assert(row!=col);
     if(SetOpposite)
       m_functor.assignCoeff(m_dst.coeffRef(row,col), Scalar(0));
   }
 };
 
 template<int Mode, bool SetOpposite, typename DstXprType, typename SrcXprType, typename Functor>
@@ -807,25 +807,25 @@
   SrcEvaluatorType srcEvaluator(src);
 
   Index dstRows = src.rows();
   Index dstCols = src.cols();
   if((dst.rows()!=dstRows) || (dst.cols()!=dstCols))
     dst.resize(dstRows, dstCols);
   DstEvaluatorType dstEvaluator(dst);
-    
+
   typedef triangular_dense_assignment_kernel< Mode&(Lower|Upper),Mode&(UnitDiag|ZeroDiag|SelfAdjoint),SetOpposite,
                                               DstEvaluatorType,SrcEvaluatorType,Functor> Kernel;
   Kernel kernel(dstEvaluator, srcEvaluator, func, dst.const_cast_derived());
-  
+
   enum {
       unroll = DstXprType::SizeAtCompileTime != Dynamic
             && SrcEvaluatorType::CoeffReadCost < HugeCost
-            && DstXprType::SizeAtCompileTime * (DstEvaluatorType::CoeffReadCost+SrcEvaluatorType::CoeffReadCost) / 2 <= EIGEN_UNROLLING_LIMIT
+            && DstXprType::SizeAtCompileTime * (int(DstEvaluatorType::CoeffReadCost) + int(SrcEvaluatorType::CoeffReadCost)) / 2 <= EIGEN_UNROLLING_LIMIT
     };
-  
+
   triangular_assignment_loop<Kernel, Mode, unroll ? int(DstXprType::SizeAtCompileTime) : Dynamic, SetOpposite>::run(kernel);
 }
 
 template<int Mode, bool SetOpposite, typename DstXprType, typename SrcXprType>
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
 void call_triangular_assignment_loop(DstXprType& dst, const SrcXprType& src)
 {
@@ -839,57 +839,57 @@
 
 template< typename DstXprType, typename SrcXprType, typename Functor>
 struct Assignment<DstXprType, SrcXprType, Functor, Triangular2Triangular>
 {
   EIGEN_DEVICE_FUNC static void run(DstXprType &dst, const SrcXprType &src, const Functor &func)
   {
     eigen_assert(int(DstXprType::Mode) == int(SrcXprType::Mode));
-    
-    call_triangular_assignment_loop<DstXprType::Mode, false>(dst, src, func);  
+
+    call_triangular_assignment_loop<DstXprType::Mode, false>(dst, src, func);
   }
 };
 
 template< typename DstXprType, typename SrcXprType, typename Functor>
 struct Assignment<DstXprType, SrcXprType, Functor, Triangular2Dense>
 {
   EIGEN_DEVICE_FUNC static void run(DstXprType &dst, const SrcXprType &src, const Functor &func)
   {
-    call_triangular_assignment_loop<SrcXprType::Mode, (SrcXprType::Mode&SelfAdjoint)==0>(dst, src, func);  
+    call_triangular_assignment_loop<SrcXprType::Mode, (int(SrcXprType::Mode) & int(SelfAdjoint)) == 0>(dst, src, func);
   }
 };
 
 template< typename DstXprType, typename SrcXprType, typename Functor>
 struct Assignment<DstXprType, SrcXprType, Functor, Dense2Triangular>
 {
   EIGEN_DEVICE_FUNC static void run(DstXprType &dst, const SrcXprType &src, const Functor &func)
   {
-    call_triangular_assignment_loop<DstXprType::Mode, false>(dst, src, func);  
+    call_triangular_assignment_loop<DstXprType::Mode, false>(dst, src, func);
   }
 };
 
 
 template<typename Kernel, unsigned int Mode, int UnrollCount, bool SetOpposite>
 struct triangular_assignment_loop
 {
   // FIXME: this is not very clean, perhaps this information should be provided by the kernel?
   typedef typename Kernel::DstEvaluatorType DstEvaluatorType;
   typedef typename DstEvaluatorType::XprType DstXprType;
-  
+
   enum {
     col = (UnrollCount-1) / DstXprType::RowsAtCompileTime,
     row = (UnrollCount-1) % DstXprType::RowsAtCompileTime
   };
-  
+
   typedef typename Kernel::Scalar Scalar;
 
   EIGEN_DEVICE_FUNC
   static inline void run(Kernel &kernel)
   {
     triangular_assignment_loop<Kernel, Mode, UnrollCount-1, SetOpposite>::run(kernel);
-    
+
     if(row==col)
       kernel.assignDiagonalCoeff(row);
     else if( ((Mode&Lower) && row>col) || ((Mode&Upper) && row<col) )
       kernel.assignCoeff(row,col);
     else if(SetOpposite)
       kernel.assignOppositeCoeff(row,col);
   }
@@ -924,18 +924,18 @@
       {
         for(; i < maxi; ++i)
           if(Mode&Upper) kernel.assignCoeff(i, j);
           else           kernel.assignOppositeCoeff(i, j);
       }
       else
         i = maxi;
-      
+
       if(i<kernel.rows()) // then i==j
         kernel.assignDiagonalCoeff(i++);
-      
+
       if (((Mode&Upper) && SetOpposite) || (Mode&Lower))
       {
         for(; i < kernel.rows(); ++i)
           if(Mode&Lower) kernel.assignCoeff(i, j);
           else           kernel.assignOppositeCoeff(i, j);
       }
     }
@@ -947,54 +947,54 @@
 /** Assigns a triangular or selfadjoint matrix to a dense matrix.
   * If the matrix is triangular, the opposite part is set to zero. */
 template<typename Derived>
 template<typename DenseDerived>
 EIGEN_DEVICE_FUNC void TriangularBase<Derived>::evalToLazy(MatrixBase<DenseDerived> &other) const
 {
   other.derived().resize(this->rows(), this->cols());
-  internal::call_triangular_assignment_loop<Derived::Mode,(Derived::Mode&SelfAdjoint)==0 /* SetOpposite */>(other.derived(), derived().nestedExpression());
+  internal::call_triangular_assignment_loop<Derived::Mode, (int(Derived::Mode) & int(SelfAdjoint)) == 0 /* SetOpposite */>(other.derived(), derived().nestedExpression());
 }
 
 namespace internal {
-  
+
 // Triangular = Product
 template< typename DstXprType, typename Lhs, typename Rhs, typename Scalar>
 struct Assignment<DstXprType, Product<Lhs,Rhs,DefaultProduct>, internal::assign_op<Scalar,typename Product<Lhs,Rhs,DefaultProduct>::Scalar>, Dense2Triangular>
 {
   typedef Product<Lhs,Rhs,DefaultProduct> SrcXprType;
   static void run(DstXprType &dst, const SrcXprType &src, const internal::assign_op<Scalar,typename SrcXprType::Scalar> &)
   {
     Index dstRows = src.rows();
     Index dstCols = src.cols();
     if((dst.rows()!=dstRows) || (dst.cols()!=dstCols))
       dst.resize(dstRows, dstCols);
 
-    dst._assignProduct(src, 1, 0);
+    dst._assignProduct(src, Scalar(1), false);
   }
 };
 
 // Triangular += Product
 template< typename DstXprType, typename Lhs, typename Rhs, typename Scalar>
 struct Assignment<DstXprType, Product<Lhs,Rhs,DefaultProduct>, internal::add_assign_op<Scalar,typename Product<Lhs,Rhs,DefaultProduct>::Scalar>, Dense2Triangular>
 {
   typedef Product<Lhs,Rhs,DefaultProduct> SrcXprType;
   static void run(DstXprType &dst, const SrcXprType &src, const internal::add_assign_op<Scalar,typename SrcXprType::Scalar> &)
   {
-    dst._assignProduct(src, 1, 1);
+    dst._assignProduct(src, Scalar(1), true);
   }
 };
 
 // Triangular -= Product
 template< typename DstXprType, typename Lhs, typename Rhs, typename Scalar>
 struct Assignment<DstXprType, Product<Lhs,Rhs,DefaultProduct>, internal::sub_assign_op<Scalar,typename Product<Lhs,Rhs,DefaultProduct>::Scalar>, Dense2Triangular>
 {
   typedef Product<Lhs,Rhs,DefaultProduct> SrcXprType;
   static void run(DstXprType &dst, const SrcXprType &src, const internal::sub_assign_op<Scalar,typename SrcXprType::Scalar> &)
   {
-    dst._assignProduct(src, -1, 1);
+    dst._assignProduct(src, Scalar(-1), true);
   }
 };
 
 } // end namespace internal
 
 } // end namespace Eigen
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/VectorBlock.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/VectorBlock.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/VectorwiseOp.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/VectorwiseOp.h`

 * *Files 0% similar despite different names*

```diff
@@ -61,18 +61,18 @@
     typedef typename internal::dense_xpr_base<PartialReduxExpr>::type Base;
     EIGEN_DENSE_PUBLIC_INTERFACE(PartialReduxExpr)
 
     EIGEN_DEVICE_FUNC
     explicit PartialReduxExpr(const MatrixType& mat, const MemberOp& func = MemberOp())
       : m_matrix(mat), m_functor(func) {}
 
-    EIGEN_DEVICE_FUNC
-    Index rows() const { return (Direction==Vertical   ? 1 : m_matrix.rows()); }
-    EIGEN_DEVICE_FUNC
-    Index cols() const { return (Direction==Horizontal ? 1 : m_matrix.cols()); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    Index rows() const EIGEN_NOEXCEPT { return (Direction==Vertical   ? 1 : m_matrix.rows()); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    Index cols() const EIGEN_NOEXCEPT { return (Direction==Horizontal ? 1 : m_matrix.cols()); }
 
     EIGEN_DEVICE_FUNC
     typename MatrixType::Nested nestedExpression() const { return m_matrix; }
 
     EIGEN_DEVICE_FUNC
     const MemberOp& functor() const { return m_functor; }
 
@@ -130,15 +130,15 @@
 
 template <typename BinaryOpT, typename Scalar>
 struct member_redux {
   typedef BinaryOpT BinaryOp;
   typedef typename result_of<
                      BinaryOp(const Scalar&,const Scalar&)
                    >::type  result_type;
-  
+
   enum { Vectorizable = functor_traits<BinaryOp>::PacketAccess };
   template<int Size> struct Cost { enum { value = (Size-1) * functor_traits<BinaryOp>::Cost }; };
   EIGEN_DEVICE_FUNC explicit member_redux(const BinaryOp func) : m_functor(func) {}
   template<typename Derived>
   EIGEN_DEVICE_FUNC inline result_type operator()(const DenseBase<Derived>& mat) const
   { return mat.redux(m_functor); }
   const BinaryOp& binaryFunc() const { return m_functor; }
@@ -158,33 +158,33 @@
   * It is the return type of DenseBase::colwise() and DenseBase::rowwise()
   * and most of the time this is the only way it is explicitly used.
   *
   * To understand the logic of rowwise/colwise expression, let's consider a generic case `A.colwise().foo()`
   * where `foo` is any method of `VectorwiseOp`. This expression is equivalent to applying `foo()` to each
   * column of `A` and then re-assemble the outputs in a matrix expression:
   * \code [A.col(0).foo(), A.col(1).foo(), ..., A.col(A.cols()-1).foo()] \endcode
-  * 
+  *
   * Example: \include MatrixBase_colwise.cpp
   * Output: \verbinclude MatrixBase_colwise.out
   *
   * The begin() and end() methods are obviously exceptions to the previous rule as they
   * return STL-compatible begin/end iterators to the rows or columns of the nested expression.
   * Typical use cases include for-range-loop and calls to STL algorithms:
-  * 
+  *
   * Example: \include MatrixBase_colwise_iterator_cxx11.cpp
   * Output: \verbinclude MatrixBase_colwise_iterator_cxx11.out
-  * 
+  *
   * For a partial reduction on an empty input, some rules apply.
   * For the sake of clarity, let's consider a vertical reduction:
   *   - If the number of columns is zero, then a 1x0 row-major vector expression is returned.
   *   - Otherwise, if the number of rows is zero, then
   *       - a row vector of zeros is returned for sum-like reductions (sum, squaredNorm, norm, etc.)
   *       - a row vector of ones is returned for a product reduction (e.g., <code>MatrixXd(n,0).colwise().prod()</code>)
   *       - an assert is triggered for all other reductions (minCoeff,maxCoeff,redux(bin_op))
-  * 
+  *
   * \sa DenseBase::colwise(), DenseBase::rowwise(), class PartialReduxExpr
   */
 template<typename ExpressionType, int Direction> class VectorwiseOp
 {
   public:
 
     typedef typename ExpressionType::Scalar Scalar;
@@ -212,15 +212,15 @@
 
     enum {
       isVertical   = (Direction==Vertical) ? 1 : 0,
       isHorizontal = (Direction==Horizontal) ? 1 : 0
     };
 
   protected:
-  
+
     template<typename OtherDerived> struct ExtendedType {
       typedef Replicate<OtherDerived,
                         isVertical   ? 1 : ExpressionType::RowsAtCompileTime,
                         isHorizontal ? 1 : ExpressionType::ColsAtCompileTime> Type;
     };
 
     /** \internal
@@ -324,15 +324,15 @@
     /** \returns a row or column vector expression of \c *this reduxed by \a func
       *
       * The template parameter \a BinaryOp is the type of the functor
       * of the custom redux operator. Note that func must be an associative operator.
       *
       * \warning the size along the reduction direction must be strictly positive,
       *          otherwise an assertion is triggered.
-      * 
+      *
       * \sa class VectorwiseOp, DenseBase::colwise(), DenseBase::rowwise()
       */
     template<typename BinaryOp>
     EIGEN_DEVICE_FUNC
     const typename ReduxReturnType<BinaryOp>::Type
     redux(const BinaryOp& func = BinaryOp()) const
     {
@@ -361,15 +361,15 @@
     };
 
     /** \returns a row (or column) vector expression of the smallest coefficient
       * of each column (or row) of the referenced expression.
       *
       * \warning the size along the reduction direction must be strictly positive,
       *          otherwise an assertion is triggered.
-      * 
+      *
       * \warning the result is undefined if \c *this contains NaN.
       *
       * Example: \include PartialRedux_minCoeff.cpp
       * Output: \verbinclude PartialRedux_minCoeff.out
       *
       * \sa DenseBase::minCoeff() */
     EIGEN_DEVICE_FUNC
@@ -380,15 +380,15 @@
     }
 
     /** \returns a row (or column) vector expression of the largest coefficient
       * of each column (or row) of the referenced expression.
       *
       * \warning the size along the reduction direction must be strictly positive,
       *          otherwise an assertion is triggered.
-      * 
+      *
       * \warning the result is undefined if \c *this contains NaN.
       *
       * Example: \include PartialRedux_maxCoeff.cpp
       * Output: \verbinclude PartialRedux_maxCoeff.out
       *
       * \sa DenseBase::maxCoeff() */
     EIGEN_DEVICE_FUNC
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/Visitor.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/Visitor.h`

 * *Files 19% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_VISITOR_H
 #define EIGEN_VISITOR_H
 
-namespace Eigen { 
+namespace Eigen {
 
 namespace internal {
 
 template<typename Visitor, typename Derived, int UnrollCount>
 struct visitor_impl
 {
   enum {
@@ -66,30 +66,30 @@
 // evaluator adaptor
 template<typename XprType>
 class visitor_evaluator
 {
 public:
   EIGEN_DEVICE_FUNC
   explicit visitor_evaluator(const XprType &xpr) : m_evaluator(xpr), m_xpr(xpr) {}
-  
+
   typedef typename XprType::Scalar Scalar;
   typedef typename XprType::CoeffReturnType CoeffReturnType;
-  
+
   enum {
     RowsAtCompileTime = XprType::RowsAtCompileTime,
     CoeffReadCost = internal::evaluator<XprType>::CoeffReadCost
   };
-  
-  EIGEN_DEVICE_FUNC Index rows() const { return m_xpr.rows(); }
-  EIGEN_DEVICE_FUNC Index cols() const { return m_xpr.cols(); }
-  EIGEN_DEVICE_FUNC Index size() const { return m_xpr.size(); }
+
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index rows() const EIGEN_NOEXCEPT { return m_xpr.rows(); }
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index cols() const EIGEN_NOEXCEPT { return m_xpr.cols(); }
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index size() const EIGEN_NOEXCEPT { return m_xpr.size(); }
 
   EIGEN_DEVICE_FUNC CoeffReturnType coeff(Index row, Index col) const
   { return m_evaluator.coeff(row, col); }
-  
+
 protected:
   internal::evaluator<XprType> m_evaluator;
   const XprType &m_xpr;
 };
 } // end namespace internal
 
 /** Applies the visitor \a visitor to the whole coefficients of the matrix or vector.
@@ -102,33 +102,33 @@
   *   // called for all other coefficients
   *   void operator() (const Scalar& value, Index i, Index j);
   * };
   * \endcode
   *
   * \note compared to one or two \em for \em loops, visitors offer automatic
   * unrolling for small fixed size matrix.
-  * 
+  *
   * \note if the matrix is empty, then the visitor is left unchanged.
   *
   * \sa minCoeff(Index*,Index*), maxCoeff(Index*,Index*), DenseBase::redux()
   */
 template<typename Derived>
 template<typename Visitor>
 EIGEN_DEVICE_FUNC
 void DenseBase<Derived>::visit(Visitor& visitor) const
 {
   if(size()==0)
     return;
-  
+
   typedef typename internal::visitor_evaluator<Derived> ThisEvaluator;
   ThisEvaluator thisEval(derived());
-  
+
   enum {
     unroll =  SizeAtCompileTime != Dynamic
-           && SizeAtCompileTime * ThisEvaluator::CoeffReadCost + (SizeAtCompileTime-1) * internal::functor_traits<Visitor>::Cost <= EIGEN_UNROLLING_LIMIT
+           && SizeAtCompileTime * int(ThisEvaluator::CoeffReadCost) + (SizeAtCompileTime-1) * int(internal::functor_traits<Visitor>::Cost) <= EIGEN_UNROLLING_LIMIT
   };
   return internal::visitor_impl<Visitor, ThisEvaluator, unroll ? int(SizeAtCompileTime) : Dynamic>::run(thisEval, visitor);
 }
 
 namespace internal {
 
 /** \internal
@@ -153,15 +153,15 @@
 };
 
 /** \internal
   * \brief Visitor computing the min coefficient with its value and coordinates
   *
   * \sa DenseBase::minCoeff(Index*, Index*)
   */
-template <typename Derived>
+template <typename Derived, int NaNPropagation>
 struct min_coeff_visitor : coeff_visitor<Derived>
 {
   typedef typename Derived::Scalar Scalar;
   EIGEN_DEVICE_FUNC
   void operator() (const Scalar& value, Index i, Index j)
   {
     if(value < this->res)
@@ -169,140 +169,212 @@
       this->res = value;
       this->row = i;
       this->col = j;
     }
   }
 };
 
-template<typename Scalar>
-struct functor_traits<min_coeff_visitor<Scalar> > {
+template <typename Derived>
+struct min_coeff_visitor<Derived, PropagateNumbers> : coeff_visitor<Derived>
+{
+  typedef typename Derived::Scalar Scalar;
+  EIGEN_DEVICE_FUNC
+  void operator() (const Scalar& value, Index i, Index j)
+  {
+    if((numext::isnan)(this->res) || (!(numext::isnan)(value) && value < this->res))
+    {
+      this->res = value;
+      this->row = i;
+      this->col = j;
+    }
+  }
+};
+
+template <typename Derived>
+struct min_coeff_visitor<Derived, PropagateNaN> : coeff_visitor<Derived>
+{
+  typedef typename Derived::Scalar Scalar;
+  EIGEN_DEVICE_FUNC
+  void operator() (const Scalar& value, Index i, Index j)
+  {
+    if((numext::isnan)(value) || value < this->res)
+    {
+      this->res = value;
+      this->row = i;
+      this->col = j;
+    }
+  }
+};
+
+template<typename Scalar, int NaNPropagation>
+    struct functor_traits<min_coeff_visitor<Scalar, NaNPropagation> > {
   enum {
     Cost = NumTraits<Scalar>::AddCost
   };
 };
 
 /** \internal
   * \brief Visitor computing the max coefficient with its value and coordinates
   *
   * \sa DenseBase::maxCoeff(Index*, Index*)
   */
-template <typename Derived>
+template <typename Derived, int NaNPropagation>
 struct max_coeff_visitor : coeff_visitor<Derived>
 {
-  typedef typename Derived::Scalar Scalar; 
+  typedef typename Derived::Scalar Scalar;
   EIGEN_DEVICE_FUNC
   void operator() (const Scalar& value, Index i, Index j)
   {
     if(value > this->res)
     {
       this->res = value;
       this->row = i;
       this->col = j;
     }
   }
 };
 
-template<typename Scalar>
-struct functor_traits<max_coeff_visitor<Scalar> > {
+template <typename Derived>
+struct max_coeff_visitor<Derived, PropagateNumbers> : coeff_visitor<Derived>
+{
+  typedef typename Derived::Scalar Scalar;
+  EIGEN_DEVICE_FUNC
+  void operator() (const Scalar& value, Index i, Index j)
+  {
+    if((numext::isnan)(this->res) || (!(numext::isnan)(value) && value > this->res))
+    {
+      this->res = value;
+      this->row = i;
+      this->col = j;
+    }
+  }
+};
+
+template <typename Derived>
+struct max_coeff_visitor<Derived, PropagateNaN> : coeff_visitor<Derived>
+{
+  typedef typename Derived::Scalar Scalar;
+  EIGEN_DEVICE_FUNC
+  void operator() (const Scalar& value, Index i, Index j)
+  {
+    if((numext::isnan)(value) || value > this->res)
+    {
+      this->res = value;
+      this->row = i;
+      this->col = j;
+    }
+  }
+};
+
+template<typename Scalar, int NaNPropagation>
+struct functor_traits<max_coeff_visitor<Scalar, NaNPropagation> > {
   enum {
     Cost = NumTraits<Scalar>::AddCost
   };
 };
 
 } // end namespace internal
 
 /** \fn DenseBase<Derived>::minCoeff(IndexType* rowId, IndexType* colId) const
   * \returns the minimum of all coefficients of *this and puts in *row and *col its location.
-  * 
+  *
+  * In case \c *this contains NaN, NaNPropagation determines the behavior:
+  *   NaNPropagation == PropagateFast : undefined
+  *   NaNPropagation == PropagateNaN : result is NaN
+  *   NaNPropagation == PropagateNumbers : result is maximum of elements that are not NaN
   * \warning the matrix must be not empty, otherwise an assertion is triggered.
-  * 
-  * \warning the result is undefined if \c *this contains NaN.
   *
   * \sa DenseBase::minCoeff(Index*), DenseBase::maxCoeff(Index*,Index*), DenseBase::visit(), DenseBase::minCoeff()
   */
 template<typename Derived>
-template<typename IndexType>
+template<int NaNPropagation, typename IndexType>
 EIGEN_DEVICE_FUNC
 typename internal::traits<Derived>::Scalar
 DenseBase<Derived>::minCoeff(IndexType* rowId, IndexType* colId) const
 {
   eigen_assert(this->rows()>0 && this->cols()>0 && "you are using an empty matrix");
 
-  internal::min_coeff_visitor<Derived> minVisitor;
+  internal::min_coeff_visitor<Derived, NaNPropagation> minVisitor;
   this->visit(minVisitor);
   *rowId = minVisitor.row;
   if (colId) *colId = minVisitor.col;
   return minVisitor.res;
 }
 
 /** \returns the minimum of all coefficients of *this and puts in *index its location.
-  * 
+  *
+  * In case \c *this contains NaN, NaNPropagation determines the behavior:
+  *   NaNPropagation == PropagateFast : undefined
+  *   NaNPropagation == PropagateNaN : result is NaN
+  *   NaNPropagation == PropagateNumbers : result is maximum of elements that are not NaN
   * \warning the matrix must be not empty, otherwise an assertion is triggered.
-  * 
-  * \warning the result is undefined if \c *this contains NaN. 
   *
   * \sa DenseBase::minCoeff(IndexType*,IndexType*), DenseBase::maxCoeff(IndexType*,IndexType*), DenseBase::visit(), DenseBase::minCoeff()
   */
 template<typename Derived>
-template<typename IndexType>
+template<int NaNPropagation, typename IndexType>
 EIGEN_DEVICE_FUNC
 typename internal::traits<Derived>::Scalar
 DenseBase<Derived>::minCoeff(IndexType* index) const
 {
   eigen_assert(this->rows()>0 && this->cols()>0 && "you are using an empty matrix");
 
   EIGEN_STATIC_ASSERT_VECTOR_ONLY(Derived)
-  internal::min_coeff_visitor<Derived> minVisitor;
+      internal::min_coeff_visitor<Derived, NaNPropagation> minVisitor;
   this->visit(minVisitor);
   *index = IndexType((RowsAtCompileTime==1) ? minVisitor.col : minVisitor.row);
   return minVisitor.res;
 }
 
 /** \fn DenseBase<Derived>::maxCoeff(IndexType* rowId, IndexType* colId) const
   * \returns the maximum of all coefficients of *this and puts in *row and *col its location.
-  * 
+  *
+  * In case \c *this contains NaN, NaNPropagation determines the behavior:
+  *   NaNPropagation == PropagateFast : undefined
+  *   NaNPropagation == PropagateNaN : result is NaN
+  *   NaNPropagation == PropagateNumbers : result is maximum of elements that are not NaN
   * \warning the matrix must be not empty, otherwise an assertion is triggered.
-  * 
-  * \warning the result is undefined if \c *this contains NaN. 
   *
   * \sa DenseBase::minCoeff(IndexType*,IndexType*), DenseBase::visit(), DenseBase::maxCoeff()
   */
 template<typename Derived>
-template<typename IndexType>
+template<int NaNPropagation, typename IndexType>
 EIGEN_DEVICE_FUNC
 typename internal::traits<Derived>::Scalar
 DenseBase<Derived>::maxCoeff(IndexType* rowPtr, IndexType* colPtr) const
 {
   eigen_assert(this->rows()>0 && this->cols()>0 && "you are using an empty matrix");
 
-  internal::max_coeff_visitor<Derived> maxVisitor;
+  internal::max_coeff_visitor<Derived, NaNPropagation> maxVisitor;
   this->visit(maxVisitor);
   *rowPtr = maxVisitor.row;
   if (colPtr) *colPtr = maxVisitor.col;
   return maxVisitor.res;
 }
 
 /** \returns the maximum of all coefficients of *this and puts in *index its location.
-  * 
-  * \warning the matrix must be not empty, otherwise an assertion is triggered.
   *
-  * \warning the result is undefined if \c *this contains NaN.
+  * In case \c *this contains NaN, NaNPropagation determines the behavior:
+  *   NaNPropagation == PropagateFast : undefined
+  *   NaNPropagation == PropagateNaN : result is NaN
+  *   NaNPropagation == PropagateNumbers : result is maximum of elements that are not NaN
+  * \warning the matrix must be not empty, otherwise an assertion is triggered.
   *
   * \sa DenseBase::maxCoeff(IndexType*,IndexType*), DenseBase::minCoeff(IndexType*,IndexType*), DenseBase::visitor(), DenseBase::maxCoeff()
   */
 template<typename Derived>
-template<typename IndexType>
+template<int NaNPropagation, typename IndexType>
 EIGEN_DEVICE_FUNC
 typename internal::traits<Derived>::Scalar
 DenseBase<Derived>::maxCoeff(IndexType* index) const
 {
   eigen_assert(this->rows()>0 && this->cols()>0 && "you are using an empty matrix");
 
   EIGEN_STATIC_ASSERT_VECTOR_ONLY(Derived)
-  internal::max_coeff_visitor<Derived> maxVisitor;
+      internal::max_coeff_visitor<Derived, NaNPropagation> maxVisitor;
   this->visit(maxVisitor);
   *index = (RowsAtCompileTime==1) ? maxVisitor.col : maxVisitor.row;
   return maxVisitor.res;
 }
 
 } // end namespace Eigen
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/AVX/Complex.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/AVX/Complex.h`

 * *Files 8% similar despite different names*

```diff
@@ -34,24 +34,36 @@
     HasHalfPacket = 1,
 
     HasAdd    = 1,
     HasSub    = 1,
     HasMul    = 1,
     HasDiv    = 1,
     HasNegate = 1,
+    HasSqrt   = 1,
     HasAbs    = 0,
     HasAbs2   = 0,
     HasMin    = 0,
     HasMax    = 0,
     HasSetLinear = 0
   };
 };
 #endif
 
-template<> struct unpacket_traits<Packet4cf> { typedef std::complex<float> type; enum {size=4, alignment=Aligned32, vectorizable=true, masked_load_available=false, masked_store_available=false}; typedef Packet2cf half; };
+template<> struct unpacket_traits<Packet4cf> {
+  typedef std::complex<float> type;
+  typedef Packet2cf half;
+  typedef Packet8f as_real;
+  enum {
+    size=4,
+    alignment=Aligned32,
+    vectorizable=true,
+    masked_load_available=false,
+    masked_store_available=false
+  };
+};
 
 template<> EIGEN_STRONG_INLINE Packet4cf padd<Packet4cf>(const Packet4cf& a, const Packet4cf& b) { return Packet4cf(_mm256_add_ps(a.v,b.v)); }
 template<> EIGEN_STRONG_INLINE Packet4cf psub<Packet4cf>(const Packet4cf& a, const Packet4cf& b) { return Packet4cf(_mm256_sub_ps(a.v,b.v)); }
 template<> EIGEN_STRONG_INLINE Packet4cf pnegate(const Packet4cf& a)
 {
   return Packet4cf(pnegate(a.v));
 }
@@ -151,47 +163,14 @@
 
 template<> EIGEN_STRONG_INLINE std::complex<float> predux_mul<Packet4cf>(const Packet4cf& a)
 {
   return predux_mul(pmul(Packet2cf(_mm256_extractf128_ps(a.v, 0)),
                          Packet2cf(_mm256_extractf128_ps(a.v, 1))));
 }
 
-template<> struct conj_helper<Packet4cf, Packet4cf, false,true>
-{
-  EIGEN_STRONG_INLINE Packet4cf pmadd(const Packet4cf& x, const Packet4cf& y, const Packet4cf& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet4cf pmul(const Packet4cf& a, const Packet4cf& b) const
-  {
-    return internal::pmul(a, pconj(b));
-  }
-};
-
-template<> struct conj_helper<Packet4cf, Packet4cf, true,false>
-{
-  EIGEN_STRONG_INLINE Packet4cf pmadd(const Packet4cf& x, const Packet4cf& y, const Packet4cf& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet4cf pmul(const Packet4cf& a, const Packet4cf& b) const
-  {
-    return internal::pmul(pconj(a), b);
-  }
-};
-
-template<> struct conj_helper<Packet4cf, Packet4cf, true,true>
-{
-  EIGEN_STRONG_INLINE Packet4cf pmadd(const Packet4cf& x, const Packet4cf& y, const Packet4cf& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet4cf pmul(const Packet4cf& a, const Packet4cf& b) const
-  {
-    return pconj(internal::pmul(a, b));
-  }
-};
-
 EIGEN_MAKE_CONJ_HELPER_CPLX_REAL(Packet4cf,Packet8f)
 
 template<> EIGEN_STRONG_INLINE Packet4cf pdiv<Packet4cf>(const Packet4cf& a, const Packet4cf& b)
 {
   Packet4cf num = pmul(a, pconj(b));
   __m256 tmp = _mm256_mul_ps(b.v, b.v);
   __m256 tmp2    = _mm256_shuffle_ps(tmp,tmp,0xB1);
@@ -224,24 +203,36 @@
     HasHalfPacket = 1,
 
     HasAdd    = 1,
     HasSub    = 1,
     HasMul    = 1,
     HasDiv    = 1,
     HasNegate = 1,
+    HasSqrt   = 1,
     HasAbs    = 0,
     HasAbs2   = 0,
     HasMin    = 0,
     HasMax    = 0,
     HasSetLinear = 0
   };
 };
 #endif
 
-template<> struct unpacket_traits<Packet2cd> { typedef std::complex<double> type; enum {size=2, alignment=Aligned32, vectorizable=true, masked_load_available=false, masked_store_available=false}; typedef Packet1cd half; };
+template<> struct unpacket_traits<Packet2cd> {
+  typedef std::complex<double> type;
+  typedef Packet1cd half;
+  typedef Packet4d as_real;
+  enum {
+    size=2,
+    alignment=Aligned32,
+    vectorizable=true,
+    masked_load_available=false,
+    masked_store_available=false
+  };
+};
 
 template<> EIGEN_STRONG_INLINE Packet2cd padd<Packet2cd>(const Packet2cd& a, const Packet2cd& b) { return Packet2cd(_mm256_add_pd(a.v,b.v)); }
 template<> EIGEN_STRONG_INLINE Packet2cd psub<Packet2cd>(const Packet2cd& a, const Packet2cd& b) { return Packet2cd(_mm256_sub_pd(a.v,b.v)); }
 template<> EIGEN_STRONG_INLINE Packet2cd pnegate(const Packet2cd& a) { return Packet2cd(pnegate(a.v)); }
 template<> EIGEN_STRONG_INLINE Packet2cd pconj(const Packet2cd& a)
 {
   const __m256d mask = _mm256_castsi256_pd(_mm256_set_epi32(0x80000000,0x0,0x0,0x0,0x80000000,0x0,0x0,0x0));
@@ -322,47 +313,14 @@
 
 template<> EIGEN_STRONG_INLINE std::complex<double> predux_mul<Packet2cd>(const Packet2cd& a)
 {
   return predux(pmul(Packet1cd(_mm256_extractf128_pd(a.v,0)),
                      Packet1cd(_mm256_extractf128_pd(a.v,1))));
 }
 
-template<> struct conj_helper<Packet2cd, Packet2cd, false,true>
-{
-  EIGEN_STRONG_INLINE Packet2cd pmadd(const Packet2cd& x, const Packet2cd& y, const Packet2cd& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet2cd pmul(const Packet2cd& a, const Packet2cd& b) const
-  {
-    return internal::pmul(a, pconj(b));
-  }
-};
-
-template<> struct conj_helper<Packet2cd, Packet2cd, true,false>
-{
-  EIGEN_STRONG_INLINE Packet2cd pmadd(const Packet2cd& x, const Packet2cd& y, const Packet2cd& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet2cd pmul(const Packet2cd& a, const Packet2cd& b) const
-  {
-    return internal::pmul(pconj(a), b);
-  }
-};
-
-template<> struct conj_helper<Packet2cd, Packet2cd, true,true>
-{
-  EIGEN_STRONG_INLINE Packet2cd pmadd(const Packet2cd& x, const Packet2cd& y, const Packet2cd& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet2cd pmul(const Packet2cd& a, const Packet2cd& b) const
-  {
-    return pconj(internal::pmul(a, b));
-  }
-};
-
 EIGEN_MAKE_CONJ_HELPER_CPLX_REAL(Packet2cd,Packet4d)
 
 template<> EIGEN_STRONG_INLINE Packet2cd pdiv<Packet2cd>(const Packet2cd& a, const Packet2cd& b)
 {
   Packet2cd num = pmul(a, pconj(b));
   __m256d tmp = _mm256_mul_pd(b.v, b.v);
   __m256d denom = _mm256_hadd_pd(tmp, tmp);
@@ -395,12 +353,20 @@
 EIGEN_DEVICE_FUNC inline void
 ptranspose(PacketBlock<Packet2cd,2>& kernel) {
   __m256d tmp = _mm256_permute2f128_pd(kernel.packet[0].v, kernel.packet[1].v, 0+(2<<4));
   kernel.packet[1].v = _mm256_permute2f128_pd(kernel.packet[0].v, kernel.packet[1].v, 1+(3<<4));
  kernel.packet[0].v = tmp;
 }
 
+template<> EIGEN_STRONG_INLINE Packet2cd psqrt<Packet2cd>(const Packet2cd& a) {
+  return psqrt_complex<Packet2cd>(a);
+}
+
+template<> EIGEN_STRONG_INLINE Packet4cf psqrt<Packet4cf>(const Packet4cf& a) {
+  return psqrt_complex<Packet4cf>(a);
+}
+
 } // end namespace internal
 
 } // end namespace Eigen
 
 #endif // EIGEN_COMPLEX_AVX_H
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/AVX/MathFunctions.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/AVX/MathFunctions.h`

 * *Files 19% similar despite different names*

```diff
@@ -32,14 +32,32 @@
 
 template <>
 EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED Packet8f
 plog<Packet8f>(const Packet8f& _x) {
   return plog_float(_x);
 }
 
+template <>
+EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED Packet4d
+plog<Packet4d>(const Packet4d& _x) {
+  return plog_double(_x);
+}
+
+template <>
+EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED Packet8f
+plog2<Packet8f>(const Packet8f& _x) {
+  return plog2_float(_x);
+}
+
+template <>
+EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED Packet4d
+plog2<Packet4d>(const Packet4d& _x) {
+  return plog2_double(_x);
+}
+
 template<> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
 Packet8f plog1p<Packet8f>(const Packet8f& _x) {
   return generic_plog1p(_x);
 }
 
 template<> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
 Packet8f pexpm1<Packet8f>(const Packet8f& _x) {
@@ -75,41 +93,44 @@
 // exact solution. It does not handle +inf, or denormalized numbers correctly.
 // The main advantage of this approach is not just speed, but also the fact that
 // it can be inlined and pipelined with other computations, further reducing its
 // effective latency. This is similar to Quake3's fast inverse square root.
 // For detail see here: http://www.beyond3d.com/content/articles/8/
 #if EIGEN_FAST_MATH
 template <>
-EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED Packet8f
-psqrt<Packet8f>(const Packet8f& _x) {
-  Packet8f half = pmul(_x, pset1<Packet8f>(.5f));
-  Packet8f denormal_mask = _mm256_and_ps(
-      _mm256_cmp_ps(_x, pset1<Packet8f>((std::numeric_limits<float>::min)()),
-                    _CMP_LT_OQ),
-      _mm256_cmp_ps(_x, _mm256_setzero_ps(), _CMP_GE_OQ));
+EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
+Packet8f psqrt<Packet8f>(const Packet8f& _x) {
+  Packet8f minus_half_x = pmul(_x, pset1<Packet8f>(-0.5f));
+  Packet8f denormal_mask = pandnot(
+      pcmp_lt(_x, pset1<Packet8f>((std::numeric_limits<float>::min)())),
+      pcmp_lt(_x, pzero(_x)));
 
   // Compute approximate reciprocal sqrt.
   Packet8f x = _mm256_rsqrt_ps(_x);
   // Do a single step of Newton's iteration.
-  x = pmul(x, psub(pset1<Packet8f>(1.5f), pmul(half, pmul(x,x))));
+  x = pmul(x, pmadd(minus_half_x, pmul(x,x), pset1<Packet8f>(1.5f)));
   // Flush results for denormals to zero.
-  return _mm256_andnot_ps(denormal_mask, pmul(_x,x));
+  return pandnot(pmul(_x,x), denormal_mask);
 }
+
 #else
+
 template <> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
 Packet8f psqrt<Packet8f>(const Packet8f& _x) {
   return _mm256_sqrt_ps(_x);
 }
+
 #endif
+
 template <> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
 Packet4d psqrt<Packet4d>(const Packet4d& _x) {
   return _mm256_sqrt_pd(_x);
 }
-#if EIGEN_FAST_MATH
 
+#if EIGEN_FAST_MATH
 template<> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
 Packet8f prsqrt<Packet8f>(const Packet8f& _x) {
   _EIGEN_DECLARE_CONST_Packet8f_FROM_INT(inf, 0x7f800000);
   _EIGEN_DECLARE_CONST_Packet8f(one_point_five, 1.5f);
   _EIGEN_DECLARE_CONST_Packet8f(minus_half, -0.5f);
   _EIGEN_DECLARE_CONST_Packet8f_FROM_INT(flt_min, 0x00800000);
 
@@ -148,22 +169,60 @@
 
 template <> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
 Packet4d prsqrt<Packet4d>(const Packet4d& _x) {
   _EIGEN_DECLARE_CONST_Packet4d(one, 1.0);
   return _mm256_div_pd(p4d_one, _mm256_sqrt_pd(_x));
 }
 
+F16_PACKET_FUNCTION(Packet8f, Packet8h, psin)
+F16_PACKET_FUNCTION(Packet8f, Packet8h, pcos)
+F16_PACKET_FUNCTION(Packet8f, Packet8h, plog)
+F16_PACKET_FUNCTION(Packet8f, Packet8h, plog2)
+F16_PACKET_FUNCTION(Packet8f, Packet8h, plog1p)
+F16_PACKET_FUNCTION(Packet8f, Packet8h, pexpm1)
+F16_PACKET_FUNCTION(Packet8f, Packet8h, pexp)
+F16_PACKET_FUNCTION(Packet8f, Packet8h, ptanh)
+F16_PACKET_FUNCTION(Packet8f, Packet8h, psqrt)
+F16_PACKET_FUNCTION(Packet8f, Packet8h, prsqrt)
+
+template <>
+EIGEN_STRONG_INLINE Packet8h pfrexp(const Packet8h& a, Packet8h& exponent) {
+  Packet8f fexponent;
+  const Packet8h out = float2half(pfrexp<Packet8f>(half2float(a), fexponent));
+  exponent = float2half(fexponent);
+  return out;
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet8h pldexp(const Packet8h& a, const Packet8h& exponent) {
+  return float2half(pldexp<Packet8f>(half2float(a), half2float(exponent)));
+}
+
 BF16_PACKET_FUNCTION(Packet8f, Packet8bf, psin)
 BF16_PACKET_FUNCTION(Packet8f, Packet8bf, pcos)
 BF16_PACKET_FUNCTION(Packet8f, Packet8bf, plog)
+BF16_PACKET_FUNCTION(Packet8f, Packet8bf, plog2)
 BF16_PACKET_FUNCTION(Packet8f, Packet8bf, plog1p)
 BF16_PACKET_FUNCTION(Packet8f, Packet8bf, pexpm1)
 BF16_PACKET_FUNCTION(Packet8f, Packet8bf, pexp)
 BF16_PACKET_FUNCTION(Packet8f, Packet8bf, ptanh)
 BF16_PACKET_FUNCTION(Packet8f, Packet8bf, psqrt)
 BF16_PACKET_FUNCTION(Packet8f, Packet8bf, prsqrt)
 
+template <>
+EIGEN_STRONG_INLINE Packet8bf pfrexp(const Packet8bf& a, Packet8bf& exponent) {
+  Packet8f fexponent;
+  const Packet8bf out = F32ToBf16(pfrexp<Packet8f>(Bf16ToF32(a), fexponent));
+  exponent = F32ToBf16(fexponent);
+  return out;
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet8bf pldexp(const Packet8bf& a, const Packet8bf& exponent) {
+  return F32ToBf16(pldexp<Packet8f>(Bf16ToF32(a), Bf16ToF32(exponent)));
+}
+
 }  // end namespace internal
 
 }  // end namespace Eigen
 
 #endif  // EIGEN_MATH_FUNCTIONS_AVX_H
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/AVX/PacketMath.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/AVX/PacketMath.h`

 * *Files 8% similar despite different names*

```diff
@@ -94,50 +94,66 @@
     Vectorizable = 1,
     AlignedOnScalar = 1,
     size=4,
     HasHalfPacket = 1,
 
     HasCmp  = 1,
     HasDiv  = 1,
+    HasLog  = 1,
     HasExp  = 1,
     HasSqrt = 1,
     HasRsqrt = 1,
     HasBlend = 1,
     HasRound = 1,
     HasFloor = 1,
-    HasCeil = 1
+    HasCeil = 1,
+    HasRint = 1
   };
 };
 
 template <>
 struct packet_traits<Eigen::half> : default_packet_traits {
   typedef Packet8h type;
   // There is no half-size packet for Packet8h.
   typedef Packet8h half;
   enum {
     Vectorizable = 1,
     AlignedOnScalar = 1,
     size = 8,
     HasHalfPacket = 0,
+
+    HasCmp    = 1,
     HasAdd    = 1,
     HasSub    = 1,
     HasMul    = 1,
     HasDiv    = 1,
+    HasSin    = EIGEN_FAST_MATH,
+    HasCos    = EIGEN_FAST_MATH,
     HasNegate = 1,
-    HasAbs    = 0,
+    HasAbs    = 1,
     HasAbs2   = 0,
-    HasMin    = 0,
-    HasMax    = 0,
-    HasConj   = 0,
+    HasMin    = 1,
+    HasMax    = 1,
+    HasConj   = 1,
     HasSetLinear = 0,
-    HasSqrt = 0,
-    HasRsqrt = 0,
-    HasExp = 0,
-    HasLog = 0,
-    HasBlend = 0
+    HasLog    = 1,
+    HasLog1p  = 1,
+    HasExpm1  = 1,
+    HasExp    = 1,
+    HasSqrt   = 1,
+    HasRsqrt  = 1,
+    HasTanh   = EIGEN_FAST_MATH,
+    HasErf    = EIGEN_FAST_MATH,
+    HasBlend  = 0,
+    HasRound  = 1,
+    HasFloor  = 1,
+    HasCeil   = 1,
+    HasRint   = 1,
+    HasBessel = 1,
+    HasNdtri  = 1
   };
 };
 
 template <>
 struct packet_traits<bfloat16> : default_packet_traits {
   typedef Packet8bf type;
   // There is no half-size packet for current Packet8bf.
@@ -145,33 +161,43 @@
   typedef Packet8bf half;
   enum {
     Vectorizable = 1,
     AlignedOnScalar = 1,
     size = 8,
     HasHalfPacket = 0,
 
-    HasCmp  = 1,
+    HasCmp = 1,
+    HasAdd = 1,
+    HasSub = 1,
+    HasMul = 1,
     HasDiv = 1,
     HasSin = EIGEN_FAST_MATH,
     HasCos = EIGEN_FAST_MATH,
+    HasNegate = 1,
+    HasAbs    = 1,
+    HasAbs2   = 0,
+    HasMin    = 1,
+    HasMax    = 1,
+    HasConj   = 1,
+    HasSetLinear = 0,
     HasLog = 1,
     HasLog1p  = 1,
     HasExpm1  = 1,
     HasExp = 1,
-    HasNdtri = 1,
-    HasBessel  = 1,
     HasSqrt = 1,
     HasRsqrt = 1,
     HasTanh = EIGEN_FAST_MATH,
     HasErf = EIGEN_FAST_MATH,
     HasBlend = 0,
     HasRound = 1,
     HasFloor = 1,
     HasCeil = 1,
-    HasRint = 1
+    HasRint = 1,
+    HasBessel = 1,
+    HasNdtri  = 1
   };
 };
 #endif
 
 template<> struct scalar_div_cost<float,true> { enum { value = 14 }; };
 template<> struct scalar_div_cost<double,true> { enum { value = 16 }; };
 
@@ -206,24 +232,31 @@
 // Helper function for bit packing snippet of low precision comparison.
 // It packs the flags from 16x16 to 8x16.
 EIGEN_STRONG_INLINE __m128i Pack16To8(Packet8f rf) {
   return _mm_packs_epi32(_mm256_extractf128_si256(_mm256_castps_si256(rf), 0),
                          _mm256_extractf128_si256(_mm256_castps_si256(rf), 1));
 }
 
+
 template<> EIGEN_STRONG_INLINE Packet8f pset1<Packet8f>(const float&  from) { return _mm256_set1_ps(from); }
 template<> EIGEN_STRONG_INLINE Packet4d pset1<Packet4d>(const double& from) { return _mm256_set1_pd(from); }
 template<> EIGEN_STRONG_INLINE Packet8i pset1<Packet8i>(const int&    from) { return _mm256_set1_epi32(from); }
 
 template<> EIGEN_STRONG_INLINE Packet8f pset1frombits<Packet8f>(unsigned int from) { return _mm256_castsi256_ps(pset1<Packet8i>(from)); }
+template<> EIGEN_STRONG_INLINE Packet4d pset1frombits<Packet4d>(uint64_t from) { return _mm256_castsi256_pd(_mm256_set1_epi64x(from)); }
 
 template<> EIGEN_STRONG_INLINE Packet8f pzero(const Packet8f& /*a*/) { return _mm256_setzero_ps(); }
 template<> EIGEN_STRONG_INLINE Packet4d pzero(const Packet4d& /*a*/) { return _mm256_setzero_pd(); }
 template<> EIGEN_STRONG_INLINE Packet8i pzero(const Packet8i& /*a*/) { return _mm256_setzero_si256(); }
 
+
+template<> EIGEN_STRONG_INLINE Packet8f peven_mask(const Packet8f& /*a*/) { return _mm256_castsi256_ps(_mm256_set_epi32(0, -1, 0, -1, 0, -1, 0, -1)); }
+template<> EIGEN_STRONG_INLINE Packet8i peven_mask(const Packet8i& /*a*/) { return _mm256_set_epi32(0, -1, 0, -1, 0, -1, 0, -1); }
+template<> EIGEN_STRONG_INLINE Packet4d peven_mask(const Packet4d& /*a*/) { return _mm256_castsi256_pd(_mm256_set_epi32(0, 0, -1, -1, 0, 0, -1, -1)); }
+
 template<> EIGEN_STRONG_INLINE Packet8f pload1<Packet8f>(const float*  from) { return _mm256_broadcast_ss(from); }
 template<> EIGEN_STRONG_INLINE Packet4d pload1<Packet4d>(const double* from) { return _mm256_broadcast_sd(from); }
 
 template<> EIGEN_STRONG_INLINE Packet8f plset<Packet8f>(const float& a) { return _mm256_add_ps(_mm256_set1_ps(a), _mm256_set_ps(7.0,6.0,5.0,4.0,3.0,2.0,1.0,0.0)); }
 template<> EIGEN_STRONG_INLINE Packet4d plset<Packet4d>(const double& a) { return _mm256_add_pd(_mm256_set1_pd(a), _mm256_set_pd(3.0,2.0,1.0,0.0)); }
 
 template<> EIGEN_STRONG_INLINE Packet8f padd<Packet8f>(const Packet8f& a, const Packet8f& b) { return _mm256_add_ps(a,b); }
@@ -236,14 +269,23 @@
   __m128i hi = _mm_add_epi32(_mm256_extractf128_si256(a, 1), _mm256_extractf128_si256(b, 1));
   return _mm256_insertf128_si256(_mm256_castsi128_si256(lo), (hi), 1);
 #endif
 }
 
 template<> EIGEN_STRONG_INLINE Packet8f psub<Packet8f>(const Packet8f& a, const Packet8f& b) { return _mm256_sub_ps(a,b); }
 template<> EIGEN_STRONG_INLINE Packet4d psub<Packet4d>(const Packet4d& a, const Packet4d& b) { return _mm256_sub_pd(a,b); }
+template<> EIGEN_STRONG_INLINE Packet8i psub<Packet8i>(const Packet8i& a, const Packet8i& b) {
+#ifdef EIGEN_VECTORIZE_AVX2
+  return _mm256_sub_epi32(a,b);
+#else
+  __m128i lo = _mm_sub_epi32(_mm256_extractf128_si256(a, 0), _mm256_extractf128_si256(b, 0));
+  __m128i hi = _mm_sub_epi32(_mm256_extractf128_si256(a, 1), _mm256_extractf128_si256(b, 1));
+  return _mm256_insertf128_si256(_mm256_castsi128_si256(lo), (hi), 1);
+#endif
+}
 
 template<> EIGEN_STRONG_INLINE Packet8f pnegate(const Packet8f& a)
 {
   return _mm256_sub_ps(_mm256_set1_ps(0.0),a);
 }
 template<> EIGEN_STRONG_INLINE Packet4d pnegate(const Packet4d& a)
 {
@@ -252,15 +294,23 @@
 
 template<> EIGEN_STRONG_INLINE Packet8f pconj(const Packet8f& a) { return a; }
 template<> EIGEN_STRONG_INLINE Packet4d pconj(const Packet4d& a) { return a; }
 template<> EIGEN_STRONG_INLINE Packet8i pconj(const Packet8i& a) { return a; }
 
 template<> EIGEN_STRONG_INLINE Packet8f pmul<Packet8f>(const Packet8f& a, const Packet8f& b) { return _mm256_mul_ps(a,b); }
 template<> EIGEN_STRONG_INLINE Packet4d pmul<Packet4d>(const Packet4d& a, const Packet4d& b) { return _mm256_mul_pd(a,b); }
-
+template<> EIGEN_STRONG_INLINE Packet8i pmul<Packet8i>(const Packet8i& a, const Packet8i& b) {
+#ifdef EIGEN_VECTORIZE_AVX2
+  return _mm256_mullo_epi32(a,b);
+#else
+  const __m128i lo = _mm_mullo_epi32(_mm256_extractf128_si256(a, 0), _mm256_extractf128_si256(b, 0));
+  const __m128i hi = _mm_mullo_epi32(_mm256_extractf128_si256(a, 1), _mm256_extractf128_si256(b, 1));
+  return _mm256_insertf128_si256(_mm256_castsi128_si256(lo), (hi), 1);
+#endif
+}
 
 template<> EIGEN_STRONG_INLINE Packet8f pdiv<Packet8f>(const Packet8f& a, const Packet8f& b) { return _mm256_div_ps(a,b); }
 template<> EIGEN_STRONG_INLINE Packet4d pdiv<Packet4d>(const Packet4d& a, const Packet4d& b) { return _mm256_div_pd(a,b); }
 template<> EIGEN_STRONG_INLINE Packet8i pdiv<Packet8i>(const Packet8i& /*a*/, const Packet8i& /*b*/)
 { eigen_assert(false && "packet integer division are not supported by AVX");
   return pset1<Packet8i>(0);
 }
@@ -288,14 +338,35 @@
   return res;
 #else
   return _mm256_fmadd_pd(a,b,c);
 #endif
 }
 #endif
 
+template<> EIGEN_STRONG_INLINE Packet8f pcmp_le(const Packet8f& a, const Packet8f& b) { return _mm256_cmp_ps(a,b,_CMP_LE_OQ); }
+template<> EIGEN_STRONG_INLINE Packet8f pcmp_lt(const Packet8f& a, const Packet8f& b) { return _mm256_cmp_ps(a,b,_CMP_LT_OQ); }
+template<> EIGEN_STRONG_INLINE Packet8f pcmp_lt_or_nan(const Packet8f& a, const Packet8f& b) { return _mm256_cmp_ps(a, b, _CMP_NGE_UQ); }
+template<> EIGEN_STRONG_INLINE Packet8f pcmp_eq(const Packet8f& a, const Packet8f& b) { return _mm256_cmp_ps(a,b,_CMP_EQ_OQ); }
+
+template<> EIGEN_STRONG_INLINE Packet4d pcmp_le(const Packet4d& a, const Packet4d& b) { return _mm256_cmp_pd(a,b,_CMP_LE_OQ); }
+template<> EIGEN_STRONG_INLINE Packet4d pcmp_lt(const Packet4d& a, const Packet4d& b) { return _mm256_cmp_pd(a,b,_CMP_LT_OQ); }
+template<> EIGEN_STRONG_INLINE Packet4d pcmp_lt_or_nan(const Packet4d& a, const Packet4d& b) { return _mm256_cmp_pd(a, b, _CMP_NGE_UQ); }
+template<> EIGEN_STRONG_INLINE Packet4d pcmp_eq(const Packet4d& a, const Packet4d& b) { return _mm256_cmp_pd(a,b,_CMP_EQ_OQ); }
+
+
+template<> EIGEN_STRONG_INLINE Packet8i pcmp_eq(const Packet8i& a, const Packet8i& b) {
+#ifdef EIGEN_VECTORIZE_AVX2
+  return _mm256_cmpeq_epi32(a,b);
+#else
+  __m128i lo = _mm_cmpeq_epi32(_mm256_extractf128_si256(a, 0), _mm256_extractf128_si256(b, 0));
+  __m128i hi = _mm_cmpeq_epi32(_mm256_extractf128_si256(a, 1), _mm256_extractf128_si256(b, 1));
+  return _mm256_insertf128_si256(_mm256_castsi128_si256(lo), (hi), 1);
+#endif
+}
+
 template<> EIGEN_STRONG_INLINE Packet8f pmin<Packet8f>(const Packet8f& a, const Packet8f& b) {
 #if EIGEN_COMP_GNUC && EIGEN_COMP_GNUC < 63
   // There appears to be a bug in GCC, by which the optimizer may flip
   // the argument order in calls to _mm_min_ps/_mm_max_ps, so we have to
   // resort to inline ASM here. This is supposed to be fixed in gcc6.3,
   // see also: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=72867
   Packet8f res;
@@ -313,14 +384,15 @@
   asm("vminpd %[a], %[b], %[res]" : [res] "=x" (res) : [a] "x" (a), [b] "x" (b));
   return res;
 #else
   // Arguments are swapped to match NaN propagation behavior of std::min.
   return _mm256_min_pd(b,a);
 #endif
 }
+
 template<> EIGEN_STRONG_INLINE Packet8f pmax<Packet8f>(const Packet8f& a, const Packet8f& b) {
 #if EIGEN_COMP_GNUC && EIGEN_COMP_GNUC < 63
   // See pmin above
   Packet8f res;
   asm("vmaxps %[a], %[b], %[res]" : [res] "=x" (res) : [a] "x" (a), [b] "x" (b));
   return res;
 #else
@@ -336,33 +408,46 @@
   return res;
 #else
   // Arguments are swapped to match NaN propagation behavior of std::max.
   return _mm256_max_pd(b,a);
 #endif
 }
 
-template<> EIGEN_STRONG_INLINE Packet8f pcmp_le(const Packet8f& a, const Packet8f& b) { return _mm256_cmp_ps(a,b,_CMP_LE_OQ); }
-template<> EIGEN_STRONG_INLINE Packet8f pcmp_lt(const Packet8f& a, const Packet8f& b) { return _mm256_cmp_ps(a,b,_CMP_LT_OQ); }
-template<> EIGEN_STRONG_INLINE Packet8f pcmp_lt_or_nan(const Packet8f& a, const Packet8f& b) { return _mm256_cmp_ps(a, b, _CMP_NGE_UQ); }
-template<> EIGEN_STRONG_INLINE Packet8f pcmp_eq(const Packet8f& a, const Packet8f& b) { return _mm256_cmp_ps(a,b,_CMP_EQ_OQ); }
-
-template<> EIGEN_STRONG_INLINE Packet4d pcmp_le(const Packet4d& a, const Packet4d& b) { return _mm256_cmp_pd(a,b,_CMP_LE_OQ); }
-template<> EIGEN_STRONG_INLINE Packet4d pcmp_lt(const Packet4d& a, const Packet4d& b) { return _mm256_cmp_pd(a,b,_CMP_LT_OQ); }
-template<> EIGEN_STRONG_INLINE Packet4d pcmp_lt_or_nan(const Packet4d& a, const Packet4d& b) { return _mm256_cmp_pd(a, b, _CMP_NGE_UQ); }
-template<> EIGEN_STRONG_INLINE Packet4d pcmp_eq(const Packet4d& a, const Packet4d& b) { return _mm256_cmp_pd(a,b,_CMP_EQ_OQ); }
-
-
-template<> EIGEN_STRONG_INLINE Packet8i pcmp_eq(const Packet8i& a, const Packet8i& b) {
-#ifdef EIGEN_VECTORIZE_AVX2
-  return _mm256_cmpeq_epi32(a,b);
-#else
-  __m128i lo = _mm_cmpeq_epi32(_mm256_extractf128_si256(a, 0), _mm256_extractf128_si256(b, 0));
-  __m128i hi = _mm_cmpeq_epi32(_mm256_extractf128_si256(a, 1), _mm256_extractf128_si256(b, 1));
-  return _mm256_insertf128_si256(_mm256_castsi128_si256(lo), (hi), 1);
-#endif
+// Add specializations for min/max with prescribed NaN progation.
+template<>
+EIGEN_STRONG_INLINE Packet8f pmin<PropagateNumbers, Packet8f>(const Packet8f& a, const Packet8f& b) {
+  return pminmax_propagate_numbers(a, b, pmin<Packet8f>);
+}
+template<>
+EIGEN_STRONG_INLINE Packet4d pmin<PropagateNumbers, Packet4d>(const Packet4d& a, const Packet4d& b) {
+  return pminmax_propagate_numbers(a, b, pmin<Packet4d>);
+}
+template<>
+EIGEN_STRONG_INLINE Packet8f pmax<PropagateNumbers, Packet8f>(const Packet8f& a, const Packet8f& b) {
+  return pminmax_propagate_numbers(a, b, pmax<Packet8f>);
+}
+template<>
+EIGEN_STRONG_INLINE Packet4d pmax<PropagateNumbers, Packet4d>(const Packet4d& a, const Packet4d& b) {
+  return pminmax_propagate_numbers(a, b, pmax<Packet4d>);
+}
+template<>
+EIGEN_STRONG_INLINE Packet8f pmin<PropagateNaN, Packet8f>(const Packet8f& a, const Packet8f& b) {
+  return pminmax_propagate_nan(a, b, pmin<Packet8f>);
+}
+template<>
+EIGEN_STRONG_INLINE Packet4d pmin<PropagateNaN, Packet4d>(const Packet4d& a, const Packet4d& b) {
+  return pminmax_propagate_nan(a, b, pmin<Packet4d>);
+}
+template<>
+EIGEN_STRONG_INLINE Packet8f pmax<PropagateNaN, Packet8f>(const Packet8f& a, const Packet8f& b) {
+  return pminmax_propagate_nan(a, b, pmax<Packet8f>);
+}
+template<>
+EIGEN_STRONG_INLINE Packet4d pmax<PropagateNaN, Packet4d>(const Packet4d& a, const Packet4d& b) {
+  return pminmax_propagate_nan(a, b, pmax<Packet4d>);
 }
 
 template<> EIGEN_STRONG_INLINE Packet8f print<Packet8f>(const Packet8f& a) { return _mm256_round_ps(a, _MM_FROUND_CUR_DIRECTION); }
 template<> EIGEN_STRONG_INLINE Packet4d print<Packet4d>(const Packet4d& a) { return _mm256_round_pd(a, _MM_FROUND_CUR_DIRECTION); }
 
 template<> EIGEN_STRONG_INLINE Packet8f pceil<Packet8f>(const Packet8f& a) { return _mm256_ceil_ps(a); }
 template<> EIGEN_STRONG_INLINE Packet4d pceil<Packet4d>(const Packet4d& a) { return _mm256_ceil_pd(a); }
@@ -439,22 +524,22 @@
 #else
   return _mm256_castps_si256(_mm256_andnot_ps(_mm256_castsi256_ps(b),_mm256_castsi256_ps(a)));
 #endif
 }
 
 template<> EIGEN_STRONG_INLINE Packet8f pround<Packet8f>(const Packet8f& a)
 {
-  const Packet8f mask = pset1frombits<Packet8f>(0x80000000u);
-  const Packet8f prev0dot5 = pset1frombits<Packet8f>(0x3EFFFFFFu);
+  const Packet8f mask = pset1frombits<Packet8f>(static_cast<numext::uint32_t>(0x80000000u));
+  const Packet8f prev0dot5 = pset1frombits<Packet8f>(static_cast<numext::uint32_t>(0x3EFFFFFFu));
   return _mm256_round_ps(padd(por(pand(a, mask), prev0dot5), a), _MM_FROUND_TO_ZERO);
 }
 template<> EIGEN_STRONG_INLINE Packet4d pround<Packet4d>(const Packet4d& a)
 {
-  const Packet4d mask = _mm256_castsi256_pd(_mm256_set_epi64x(0x8000000000000000ull, 0x8000000000000000ull, 0x8000000000000000ull, 0x8000000000000000ull));
-  const Packet4d prev0dot5 = _mm256_castsi256_pd(_mm256_set_epi64x(0x3FDFFFFFFFFFFFFFull, 0x3FDFFFFFFFFFFFFFull, 0x3FDFFFFFFFFFFFFFull, 0x3FDFFFFFFFFFFFFFull));
+  const Packet4d mask = pset1frombits<Packet4d>(static_cast<numext::uint64_t>(0x8000000000000000ull));
+  const Packet4d prev0dot5 = pset1frombits<Packet4d>(static_cast<numext::uint64_t>(0x3FDFFFFFFFFFFFFFull));
   return _mm256_round_pd(padd(por(pand(a, mask), prev0dot5), a), _MM_FROUND_TO_ZERO);
 }
 
 template<> EIGEN_STRONG_INLINE Packet8f pselect<Packet8f>(const Packet8f& mask, const Packet8f& a, const Packet8f& b)
 { return _mm256_blendv_ps(b,a,mask); }
 template<> EIGEN_STRONG_INLINE Packet4d pselect<Packet4d>(const Packet4d& mask, const Packet4d& a, const Packet4d& b)
 { return _mm256_blendv_pd(b,a,mask); }
@@ -645,33 +730,73 @@
 template<> EIGEN_STRONG_INLINE Packet4d pabs(const Packet4d& a)
 {
   const Packet4d mask = _mm256_castsi256_pd(_mm256_setr_epi32(0xFFFFFFFF,0x7FFFFFFF,0xFFFFFFFF,0x7FFFFFFF,0xFFFFFFFF,0x7FFFFFFF,0xFFFFFFFF,0x7FFFFFFF));
   return _mm256_and_pd(a,mask);
 }
 
 template<> EIGEN_STRONG_INLINE Packet8f pfrexp<Packet8f>(const Packet8f& a, Packet8f& exponent) {
-  return pfrexp_float(a,exponent);
+  return pfrexp_generic(a,exponent);
+}
+
+// Extract exponent without existence of Packet4l.
+template<>
+EIGEN_STRONG_INLINE  
+Packet4d pfrexp_generic_get_biased_exponent(const Packet4d& a) {
+  const Packet4d cst_exp_mask  = pset1frombits<Packet4d>(static_cast<uint64_t>(0x7ff0000000000000ull));
+  __m256i a_expo = _mm256_castpd_si256(pand(a, cst_exp_mask));
+#ifdef EIGEN_VECTORIZE_AVX2
+  a_expo = _mm256_srli_epi64(a_expo, 52);
+  __m128i lo = _mm256_extractf128_si256(a_expo, 0);
+  __m128i hi = _mm256_extractf128_si256(a_expo, 1);
+#else
+  __m128i lo = _mm256_extractf128_si256(a_expo, 0);
+  __m128i hi = _mm256_extractf128_si256(a_expo, 1);
+  lo = _mm_srli_epi64(lo, 52);
+  hi = _mm_srli_epi64(hi, 52);
+#endif
+  Packet2d exponent_lo = _mm_cvtepi32_pd(vec4i_swizzle1(lo, 0, 2, 1, 3));
+  Packet2d exponent_hi = _mm_cvtepi32_pd(vec4i_swizzle1(hi, 0, 2, 1, 3));
+  Packet4d exponent = _mm256_insertf128_pd(_mm256_setzero_pd(), exponent_lo, 0);
+  exponent = _mm256_insertf128_pd(exponent, exponent_hi, 1);
+  return exponent;
+}
+
+
+template<> EIGEN_STRONG_INLINE Packet4d pfrexp<Packet4d>(const Packet4d& a, Packet4d& exponent) {
+  return pfrexp_generic(a, exponent);
 }
 
 template<> EIGEN_STRONG_INLINE Packet8f pldexp<Packet8f>(const Packet8f& a, const Packet8f& exponent) {
-  return pldexp_float(a,exponent);
+  return pldexp_generic(a, exponent);
 }
 
 template<> EIGEN_STRONG_INLINE Packet4d pldexp<Packet4d>(const Packet4d& a, const Packet4d& exponent) {
-  // Build e=2^n by constructing the exponents in a 128-bit vector and
-  // shifting them to where they belong in double-precision values.
-  Packet4i cst_1023 = pset1<Packet4i>(1023);
-  __m128i emm0 = _mm256_cvtpd_epi32(exponent);
-  emm0 = _mm_add_epi32(emm0, cst_1023);
-  emm0 = _mm_shuffle_epi32(emm0, _MM_SHUFFLE(3, 1, 2, 0));
-  __m128i lo = _mm_slli_epi64(emm0, 52);
-  __m128i hi = _mm_slli_epi64(_mm_srli_epi64(emm0, 32), 52);
-  __m256i e = _mm256_insertf128_si256(_mm256_setzero_si256(), lo, 0);
-  e = _mm256_insertf128_si256(e, hi, 1);
-  return pmul(a,_mm256_castsi256_pd(e));
+  // Clamp exponent to [-2099, 2099]
+  const Packet4d max_exponent = pset1<Packet4d>(2099.0);
+  const Packet4i e = _mm256_cvtpd_epi32(pmin(pmax(exponent, pnegate(max_exponent)), max_exponent));
+  
+  // Split 2^e into four factors and multiply.
+  const Packet4i bias = pset1<Packet4i>(1023);
+  Packet4i b = parithmetic_shift_right<2>(e);  // floor(e/4)
+  
+  // 2^b
+  Packet4i hi = vec4i_swizzle1(padd(b, bias), 0, 2, 1, 3);
+  Packet4i lo = _mm_slli_epi64(hi, 52);
+  hi = _mm_slli_epi64(_mm_srli_epi64(hi, 32), 52);
+  Packet4d c = _mm256_castsi256_pd(_mm256_insertf128_si256(_mm256_castsi128_si256(lo), hi, 1));
+  Packet4d out = pmul(pmul(pmul(a, c), c), c);  // a * 2^(3b)
+  
+  // 2^(e - 3b)
+  b = psub(psub(psub(e, b), b), b);  // e - 3b
+  hi = vec4i_swizzle1(padd(b, bias), 0, 2, 1, 3);
+  lo = _mm_slli_epi64(hi, 52);
+  hi = _mm_slli_epi64(_mm_srli_epi64(hi, 32), 52);
+  c = _mm256_castsi256_pd(_mm256_insertf128_si256(_mm256_castsi128_si256(lo), hi, 1));
+  out = pmul(out, c); // a * 2^e
+  return out;
 }
 
 template<> EIGEN_STRONG_INLINE float predux<Packet8f>(const Packet8f& a)
 {
   return predux(Packet4f(_mm_add_ps(_mm256_castps256_ps128(a),_mm256_extractf128_ps(a,1))));
 }
 template<> EIGEN_STRONG_INLINE double predux<Packet4d>(const Packet4d& a)
@@ -803,22 +928,23 @@
   const __m256d zero = _mm256_setzero_pd();
   const __m256d select = _mm256_set_pd(ifPacket.select[3], ifPacket.select[2], ifPacket.select[1], ifPacket.select[0]);
   __m256d false_mask = _mm256_cmp_pd(select, zero, _CMP_EQ_UQ);
   return _mm256_blendv_pd(thenPacket, elsePacket, false_mask);
 }
 
 // Packet math for Eigen::half
+
 template<> struct unpacket_traits<Packet8h> { typedef Eigen::half type; enum {size=8, alignment=Aligned16, vectorizable=true, masked_load_available=false, masked_store_available=false}; typedef Packet8h half; };
 
 template<> EIGEN_STRONG_INLINE Packet8h pset1<Packet8h>(const Eigen::half& from) {
-  return _mm_set1_epi16(from.x);
+  return _mm_set1_epi16(numext::bit_cast<numext::uint16_t>(from));
 }
 
 template<> EIGEN_STRONG_INLINE Eigen::half pfirst<Packet8h>(const Packet8h& from) {
-  return half_impl::raw_uint16_to_half(static_cast<unsigned short>(_mm_extract_epi16(from, 0)));
+  return numext::bit_cast<Eigen::half>(static_cast<numext::uint16_t>(_mm_extract_epi16(from, 0)));
 }
 
 template<> EIGEN_STRONG_INLINE Packet8h pload<Packet8h>(const Eigen::half* from) {
   return _mm_load_si128(reinterpret_cast<const __m128i*>(from));
 }
 
 template<> EIGEN_STRONG_INLINE Packet8h ploadu<Packet8h>(const Eigen::half* from) {
@@ -831,28 +957,38 @@
 
 template<> EIGEN_STRONG_INLINE void pstoreu<Eigen::half>(Eigen::half* to, const Packet8h& from) {
   _mm_storeu_si128(reinterpret_cast<__m128i*>(to), from);
 }
 
 template<> EIGEN_STRONG_INLINE Packet8h
 ploaddup<Packet8h>(const Eigen::half*  from) {
-  unsigned short a = from[0].x;
-  unsigned short b = from[1].x;
-  unsigned short c = from[2].x;
-  unsigned short d = from[3].x;
+  const numext::uint16_t a = numext::bit_cast<numext::uint16_t>(from[0]);
+  const numext::uint16_t b = numext::bit_cast<numext::uint16_t>(from[1]);
+  const numext::uint16_t c = numext::bit_cast<numext::uint16_t>(from[2]);
+  const numext::uint16_t d = numext::bit_cast<numext::uint16_t>(from[3]);
   return _mm_set_epi16(d, d, c, c, b, b, a, a);
 }
 
 template<> EIGEN_STRONG_INLINE Packet8h
 ploadquad<Packet8h>(const Eigen::half* from) {
-  unsigned short a = from[0].x;
-  unsigned short b = from[1].x;
+  const numext::uint16_t a = numext::bit_cast<numext::uint16_t>(from[0]);
+  const numext::uint16_t b = numext::bit_cast<numext::uint16_t>(from[1]);
   return _mm_set_epi16(b, b, b, b, a, a, a, a);
 }
 
+template<> EIGEN_STRONG_INLINE Packet8h ptrue(const Packet8h& a) {
+ return _mm_cmpeq_epi32(a, a);
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet8h pabs(const Packet8h& a) {
+  const __m128i sign_mask = _mm_set1_epi16(static_cast<numext::uint16_t>(0x8000));
+  return _mm_andnot_si128(sign_mask, a);
+}
+
 EIGEN_STRONG_INLINE Packet8f half2float(const Packet8h& a) {
 #ifdef EIGEN_HAS_FP16_C
   return _mm256_cvtph_ps(a);
 #else
   EIGEN_ALIGN32 Eigen::half aux[8];
   pstore(aux, a);
   float f0(aux[0]);
@@ -870,29 +1006,41 @@
 
 EIGEN_STRONG_INLINE Packet8h float2half(const Packet8f& a) {
 #ifdef EIGEN_HAS_FP16_C
   return _mm256_cvtps_ph(a, _MM_FROUND_TO_NEAREST_INT|_MM_FROUND_NO_EXC);
 #else
   EIGEN_ALIGN32 float aux[8];
   pstore(aux, a);
-  Eigen::half h0(aux[0]);
-  Eigen::half h1(aux[1]);
-  Eigen::half h2(aux[2]);
-  Eigen::half h3(aux[3]);
-  Eigen::half h4(aux[4]);
-  Eigen::half h5(aux[5]);
-  Eigen::half h6(aux[6]);
-  Eigen::half h7(aux[7]);
-
-  return _mm_set_epi16(h7.x, h6.x, h5.x, h4.x, h3.x, h2.x, h1.x, h0.x);
+  const numext::uint16_t s0 = numext::bit_cast<numext::uint16_t>(Eigen::half(aux[0]));
+  const numext::uint16_t s1 = numext::bit_cast<numext::uint16_t>(Eigen::half(aux[1]));
+  const numext::uint16_t s2 = numext::bit_cast<numext::uint16_t>(Eigen::half(aux[2]));
+  const numext::uint16_t s3 = numext::bit_cast<numext::uint16_t>(Eigen::half(aux[3]));
+  const numext::uint16_t s4 = numext::bit_cast<numext::uint16_t>(Eigen::half(aux[4]));
+  const numext::uint16_t s5 = numext::bit_cast<numext::uint16_t>(Eigen::half(aux[5]));
+  const numext::uint16_t s6 = numext::bit_cast<numext::uint16_t>(Eigen::half(aux[6]));
+  const numext::uint16_t s7 = numext::bit_cast<numext::uint16_t>(Eigen::half(aux[7]));
+  return _mm_set_epi16(s7, s6, s5, s4, s3, s2, s1, s0);
 #endif
 }
 
-template<> EIGEN_STRONG_INLINE Packet8h ptrue(const Packet8h& a) {
- return _mm_cmpeq_epi32(a, a);
+template <>
+EIGEN_STRONG_INLINE Packet8h pmin<Packet8h>(const Packet8h& a,
+                                            const Packet8h& b) {
+  return float2half(pmin<Packet8f>(half2float(a), half2float(b)));
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet8h pmax<Packet8h>(const Packet8h& a,
+                                            const Packet8h& b) {
+  return float2half(pmax<Packet8f>(half2float(a), half2float(b)));
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet8h plset<Packet8h>(const half& a) {
+  return float2half(plset<Packet8f>(static_cast<float>(a)));
 }
 
 template<> EIGEN_STRONG_INLINE Packet8h por(const Packet8h& a,const Packet8h& b) {
   // in some cases Packet4i is a wrapper around __m128i, so we either need to
   // cast to Packet4i to directly call the intrinsics as below:
   return _mm_or_si128(a,b);
 }
@@ -906,27 +1054,50 @@
   return _mm_andnot_si128(b,a);
 }
 
 template<> EIGEN_STRONG_INLINE Packet8h pselect(const Packet8h& mask, const Packet8h& a, const Packet8h& b) {
   return _mm_blendv_epi8(b, a, mask);
 }
 
+template<> EIGEN_STRONG_INLINE Packet8h pround<Packet8h>(const Packet8h& a) {
+  return float2half(pround<Packet8f>(half2float(a)));
+}
+
+template<> EIGEN_STRONG_INLINE Packet8h print<Packet8h>(const Packet8h& a) {
+  return float2half(print<Packet8f>(half2float(a)));
+}
+
+template<> EIGEN_STRONG_INLINE Packet8h pceil<Packet8h>(const Packet8h& a) {
+  return float2half(pceil<Packet8f>(half2float(a)));
+}
+
+template<> EIGEN_STRONG_INLINE Packet8h pfloor<Packet8h>(const Packet8h& a) {
+  return float2half(pfloor<Packet8f>(half2float(a)));
+}
+
 template<> EIGEN_STRONG_INLINE Packet8h pcmp_eq(const Packet8h& a,const Packet8h& b) {
-  Packet8f af = half2float(a);
-  Packet8f bf = half2float(b);
-  Packet8f rf = pcmp_eq(af, bf);
-  // Pack the 32-bit flags into 16-bits flags.
-  return _mm_packs_epi32(_mm256_extractf128_si256(_mm256_castps_si256(rf), 0),
-                         _mm256_extractf128_si256(_mm256_castps_si256(rf), 1));
+  return Pack16To8(pcmp_eq(half2float(a), half2float(b)));
+}
+
+template<> EIGEN_STRONG_INLINE Packet8h pcmp_le(const Packet8h& a,const Packet8h& b) {
+  return Pack16To8(pcmp_le(half2float(a), half2float(b)));
+}
+
+template<> EIGEN_STRONG_INLINE Packet8h pcmp_lt(const Packet8h& a,const Packet8h& b) {
+  return Pack16To8(pcmp_lt(half2float(a), half2float(b)));
+}
+
+template<> EIGEN_STRONG_INLINE Packet8h pcmp_lt_or_nan(const Packet8h& a,const Packet8h& b) {
+  return Pack16To8(pcmp_lt_or_nan(half2float(a), half2float(b)));
 }
 
 template<> EIGEN_STRONG_INLINE Packet8h pconj(const Packet8h& a) { return a; }
 
 template<> EIGEN_STRONG_INLINE Packet8h pnegate(const Packet8h& a) {
-  Packet8h sign_mask = _mm_set1_epi16(static_cast<unsigned short>(0x8000));
+  Packet8h sign_mask = _mm_set1_epi16(static_cast<numext::uint16_t>(0x8000));
   return _mm_xor_si128(a, sign_mask);
 }
 
 template<> EIGEN_STRONG_INLINE Packet8h padd<Packet8h>(const Packet8h& a, const Packet8h& b) {
   Packet8f af = half2float(a);
   Packet8f bf = half2float(b);
   Packet8f rf = padd(af, bf);
@@ -952,15 +1123,23 @@
   Packet8f bf = half2float(b);
   Packet8f rf = pdiv(af, bf);
   return float2half(rf);
 }
 
 template<> EIGEN_STRONG_INLINE Packet8h pgather<Eigen::half, Packet8h>(const Eigen::half* from, Index stride)
 {
-  return _mm_set_epi16(from[7*stride].x, from[6*stride].x, from[5*stride].x, from[4*stride].x, from[3*stride].x, from[2*stride].x, from[1*stride].x, from[0*stride].x);
+  const numext::uint16_t s0 = numext::bit_cast<numext::uint16_t>(from[0*stride]);
+  const numext::uint16_t s1 = numext::bit_cast<numext::uint16_t>(from[1*stride]);
+  const numext::uint16_t s2 = numext::bit_cast<numext::uint16_t>(from[2*stride]);
+  const numext::uint16_t s3 = numext::bit_cast<numext::uint16_t>(from[3*stride]);
+  const numext::uint16_t s4 = numext::bit_cast<numext::uint16_t>(from[4*stride]);
+  const numext::uint16_t s5 = numext::bit_cast<numext::uint16_t>(from[5*stride]);
+  const numext::uint16_t s6 = numext::bit_cast<numext::uint16_t>(from[6*stride]);
+  const numext::uint16_t s7 = numext::bit_cast<numext::uint16_t>(from[7*stride]);
+  return _mm_set_epi16(s7, s6, s5, s4, s3, s2, s1, s0);
 }
 
 template<> EIGEN_STRONG_INLINE void pscatter<Eigen::half, Packet8h>(Eigen::half* to, const Packet8h& from, Index stride)
 {
   EIGEN_ALIGN32 Eigen::half aux[8];
   pstore(aux, from);
   to[stride*0] = aux[0];
@@ -1072,14 +1251,16 @@
 
   kernel.packet[0] = pload<Packet8h>(out[0]);
   kernel.packet[1] = pload<Packet8h>(out[1]);
   kernel.packet[2] = pload<Packet8h>(out[2]);
   kernel.packet[3] = pload<Packet8h>(out[3]);
 }
 
+// BFloat16 implementation.
+
 EIGEN_STRONG_INLINE Packet8f Bf16ToF32(const Packet8bf& a) {
 #ifdef EIGEN_VECTORIZE_AVX2
   __m256i extend = _mm256_cvtepu16_epi32(a);
   return _mm256_castsi256_ps(_mm256_slli_epi32(extend, 16));
 #else
   __m128i lo = _mm_cvtepu16_epi32(a);
   __m128i hi = _mm_cvtepu16_epi32(_mm_srli_si128(a, 8));
@@ -1089,37 +1270,32 @@
 #endif
 }
 
 // Convert float to bfloat16 according to round-to-nearest-even/denormals algorithm.
 EIGEN_STRONG_INLINE Packet8bf F32ToBf16(const Packet8f& a) {
   Packet8bf r;
 
-  // Flush input denormals value to zero with hardware capability.
-  _MM_SET_DENORMALS_ZERO_MODE(_MM_DENORMALS_ZERO_ON);
-  __m256 flush = _mm256_and_ps(a, a);
-  _MM_SET_DENORMALS_ZERO_MODE(_MM_DENORMALS_ZERO_OFF);
-
-  __m256i input = _mm256_castps_si256(flush);
+  __m256i input = _mm256_castps_si256(a);
 
 #ifdef EIGEN_VECTORIZE_AVX2
   // uint32_t lsb = (input >> 16);
   __m256i t = _mm256_srli_epi32(input, 16);
   // uint32_t lsb = lsb & 1;
   t = _mm256_and_si256(t, _mm256_set1_epi32(1));
   // uint32_t rounding_bias = 0x7fff + lsb;
   t = _mm256_add_epi32(t, _mm256_set1_epi32(0x7fff));
   // input += rounding_bias;
   t = _mm256_add_epi32(t, input);
   // input = input >> 16;
   t = _mm256_srli_epi32(t, 16);
   // Check NaN before converting back to bf16
-  __m256 mask = _mm256_cmp_ps(flush, flush, _CMP_ORD_Q);
+  __m256 mask = _mm256_cmp_ps(a, a, _CMP_ORD_Q);
   __m256i nan = _mm256_set1_epi32(0x7fc0);
   t = _mm256_blendv_epi8(nan, t, _mm256_castps_si256(mask));
-  // output.value = static_cast<uint16_t>(input);
+  // output = numext::bit_cast<uint16_t>(input);
   return _mm_packus_epi32(_mm256_extractf128_si256(t, 0),
                          _mm256_extractf128_si256(t, 1));
 #else
   // uint32_t lsb = (input >> 16);
   __m128i lo = _mm_srli_epi32(_mm256_extractf128_si256(input, 0), 16);
   __m128i hi = _mm_srli_epi32(_mm256_extractf128_si256(input, 1), 16);
   // uint32_t lsb = lsb & 1;
@@ -1131,29 +1307,29 @@
   // input += rounding_bias;
   lo = _mm_add_epi32(lo, _mm256_extractf128_si256(input, 0));
   hi = _mm_add_epi32(hi, _mm256_extractf128_si256(input, 1));
   // input = input >> 16;
   lo = _mm_srli_epi32(lo, 16);
   hi = _mm_srli_epi32(hi, 16);
   // Check NaN before converting back to bf16
-  __m256 mask = _mm256_cmp_ps(flush, flush, _CMP_ORD_Q);
+  __m256 mask = _mm256_cmp_ps(a, a, _CMP_ORD_Q);
   __m128i nan = _mm_set1_epi32(0x7fc0);
   lo = _mm_blendv_epi8(nan, lo, _mm_castps_si128(_mm256_castps256_ps128(mask)));
   hi = _mm_blendv_epi8(nan, hi, _mm_castps_si128(_mm256_extractf128_ps(mask, 1)));
-  // output.value = static_cast<uint16_t>(input);
+  // output = numext::bit_cast<uint16_t>(input);
   return _mm_packus_epi32(lo, hi);
 #endif
 }
 
 template<> EIGEN_STRONG_INLINE Packet8bf pset1<Packet8bf>(const bfloat16& from) {
-  return _mm_set1_epi16(from.value);
+  return _mm_set1_epi16(numext::bit_cast<numext::uint16_t>(from));
 }
 
 template<> EIGEN_STRONG_INLINE bfloat16 pfirst<Packet8bf>(const Packet8bf& from) {
-  return bfloat16_impl::raw_uint16_to_bfloat16(static_cast<unsigned short>(_mm_extract_epi16(from, 0)));
+  return numext::bit_cast<bfloat16>(static_cast<numext::uint16_t>(_mm_extract_epi16(from, 0)));
 }
 
 template<> EIGEN_STRONG_INLINE Packet8bf pload<Packet8bf>(const bfloat16* from) {
   return _mm_load_si128(reinterpret_cast<const __m128i*>(from));
 }
 
 template<> EIGEN_STRONG_INLINE Packet8bf ploadu<Packet8bf>(const bfloat16* from) {
@@ -1166,49 +1342,55 @@
 
 template<> EIGEN_STRONG_INLINE void pstoreu<bfloat16>(bfloat16* to, const Packet8bf& from) {
   _mm_storeu_si128(reinterpret_cast<__m128i*>(to), from);
 }
 
 template<> EIGEN_STRONG_INLINE Packet8bf
 ploaddup<Packet8bf>(const bfloat16* from) {
-  unsigned short a = from[0].value;
-  unsigned short b = from[1].value;
-  unsigned short c = from[2].value;
-  unsigned short d = from[3].value;
+  const numext::uint16_t a = numext::bit_cast<numext::uint16_t>(from[0]);
+  const numext::uint16_t b = numext::bit_cast<numext::uint16_t>(from[1]);
+  const numext::uint16_t c = numext::bit_cast<numext::uint16_t>(from[2]);
+  const numext::uint16_t d = numext::bit_cast<numext::uint16_t>(from[3]);
   return _mm_set_epi16(d, d, c, c, b, b, a, a);
 }
 
 template<> EIGEN_STRONG_INLINE Packet8bf
 ploadquad<Packet8bf>(const bfloat16* from) {
-  unsigned short a = from[0].value;
-  unsigned short b = from[1].value;
+  const numext::uint16_t a = numext::bit_cast<numext::uint16_t>(from[0]);
+  const numext::uint16_t b = numext::bit_cast<numext::uint16_t>(from[1]);
   return _mm_set_epi16(b, b, b, b, a, a, a, a);
 }
 
 template<> EIGEN_STRONG_INLINE Packet8bf ptrue(const Packet8bf& a) {
  return _mm_cmpeq_epi32(a, a);
 }
 
 template <>
 EIGEN_STRONG_INLINE Packet8bf pabs(const Packet8bf& a) {
-  return F32ToBf16(pabs<Packet8f>(Bf16ToF32(a)));
+  const __m128i sign_mask = _mm_set1_epi16(static_cast<numext::uint16_t>(0x8000));
+  return _mm_andnot_si128(sign_mask, a);
 }
 
 template <>
 EIGEN_STRONG_INLINE Packet8bf pmin<Packet8bf>(const Packet8bf& a,
                                                 const Packet8bf& b) {
   return F32ToBf16(pmin<Packet8f>(Bf16ToF32(a), Bf16ToF32(b)));
 }
 
 template <>
 EIGEN_STRONG_INLINE Packet8bf pmax<Packet8bf>(const Packet8bf& a,
                                                 const Packet8bf& b) {
   return F32ToBf16(pmax<Packet8f>(Bf16ToF32(a), Bf16ToF32(b)));
 }
 
+template <>
+EIGEN_STRONG_INLINE Packet8bf plset<Packet8bf>(const bfloat16& a) {
+  return F32ToBf16(plset<Packet8f>(static_cast<float>(a)));
+}
+
 template<> EIGEN_STRONG_INLINE Packet8bf por(const Packet8bf& a,const Packet8bf& b) {
   return _mm_or_si128(a,b);
 }
 template<> EIGEN_STRONG_INLINE Packet8bf pxor(const Packet8bf& a,const Packet8bf& b) {
   return _mm_xor_si128(a,b);
 }
 template<> EIGEN_STRONG_INLINE Packet8bf pand(const Packet8bf& a,const Packet8bf& b) {
@@ -1254,15 +1436,15 @@
 template<> EIGEN_STRONG_INLINE Packet8bf pcmp_lt_or_nan(const Packet8bf& a,const Packet8bf& b) {
   return Pack16To8(pcmp_lt_or_nan(Bf16ToF32(a), Bf16ToF32(b)));
 }
 
 template<> EIGEN_STRONG_INLINE Packet8bf pconj(const Packet8bf& a) { return a; }
 
 template<> EIGEN_STRONG_INLINE Packet8bf pnegate(const Packet8bf& a) {
-  Packet8bf sign_mask = _mm_set1_epi16(static_cast<unsigned short>(0x8000));
+  Packet8bf sign_mask = _mm_set1_epi16(static_cast<numext::uint16_t>(0x8000));
   return _mm_xor_si128(a, sign_mask);
 }
 
 template<> EIGEN_STRONG_INLINE Packet8bf padd<Packet8bf>(const Packet8bf& a, const Packet8bf& b) {
   return F32ToBf16(padd<Packet8f>(Bf16ToF32(a), Bf16ToF32(b)));
 }
 
@@ -1277,15 +1459,23 @@
 template<> EIGEN_STRONG_INLINE Packet8bf pdiv<Packet8bf>(const Packet8bf& a, const Packet8bf& b) {
   return F32ToBf16(pdiv<Packet8f>(Bf16ToF32(a), Bf16ToF32(b)));
 }
 
 
 template<> EIGEN_STRONG_INLINE Packet8bf pgather<bfloat16, Packet8bf>(const bfloat16* from, Index stride)
 {
-  return _mm_set_epi16(from[7*stride].value, from[6*stride].value, from[5*stride].value, from[4*stride].value, from[3*stride].value, from[2*stride].value, from[1*stride].value, from[0*stride].value);
+  const numext::uint16_t s0 = numext::bit_cast<numext::uint16_t>(from[0*stride]);
+  const numext::uint16_t s1 = numext::bit_cast<numext::uint16_t>(from[1*stride]);
+  const numext::uint16_t s2 = numext::bit_cast<numext::uint16_t>(from[2*stride]);
+  const numext::uint16_t s3 = numext::bit_cast<numext::uint16_t>(from[3*stride]);
+  const numext::uint16_t s4 = numext::bit_cast<numext::uint16_t>(from[4*stride]);
+  const numext::uint16_t s5 = numext::bit_cast<numext::uint16_t>(from[5*stride]);
+  const numext::uint16_t s6 = numext::bit_cast<numext::uint16_t>(from[6*stride]);
+  const numext::uint16_t s7 = numext::bit_cast<numext::uint16_t>(from[7*stride]);
+  return _mm_set_epi16(s7, s6, s5, s4, s3, s2, s1, s0);
 }
 
 template<> EIGEN_STRONG_INLINE void pscatter<bfloat16, Packet8bf>(bfloat16* to, const Packet8bf& from, Index stride)
 {
   EIGEN_ALIGN32 bfloat16 aux[8];
   pstore(aux, from);
   to[stride*0] = aux[0];
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/AVX/TypeCasting.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/AVX/TypeCasting.h`

 * *Ordering differences only*

 * *Files 1% similar despite different names*

```diff
@@ -31,45 +31,25 @@
     VectorizedCast = 0,
     SrcCoeffRatio = 1,
     TgtCoeffRatio = 1
   };
 };
 
 
-
-template<> EIGEN_STRONG_INLINE Packet8i pcast<Packet8f, Packet8i>(const Packet8f& a) {
-  return _mm256_cvttps_epi32(a);
-}
-
-template<> EIGEN_STRONG_INLINE Packet8f pcast<Packet8i, Packet8f>(const Packet8i& a) {
-  return _mm256_cvtepi32_ps(a);
-}
-
-template<> EIGEN_STRONG_INLINE Packet8i preinterpret<Packet8i,Packet8f>(const Packet8f& a) {
-  return _mm256_castps_si256(a);
-}
-
-template<> EIGEN_STRONG_INLINE Packet8f preinterpret<Packet8f,Packet8i>(const Packet8i& a) {
-  return _mm256_castsi256_ps(a);
-}
-
 #ifndef EIGEN_VECTORIZE_AVX512
 
 template <>
 struct type_casting_traits<Eigen::half, float> {
   enum {
     VectorizedCast = 1,
     SrcCoeffRatio = 1,
     TgtCoeffRatio = 1
   };
 };
 
-template<> EIGEN_STRONG_INLINE Packet8f pcast<Packet8h, Packet8f>(const Packet8h& a) {
-  return half2float(a);
-}
 
 template <>
 struct type_casting_traits<float, Eigen::half> {
   enum {
     VectorizedCast = 1,
     SrcCoeffRatio = 1,
     TgtCoeffRatio = 1
@@ -81,29 +61,49 @@
   enum {
     VectorizedCast = 1,
     SrcCoeffRatio = 1,
     TgtCoeffRatio = 1
   };
 };
 
-template<> EIGEN_STRONG_INLINE Packet8f pcast<Packet8bf, Packet8f>(const Packet8bf& a) {
-  return Bf16ToF32(a);
-}
-
 template <>
 struct type_casting_traits<float, bfloat16> {
   enum {
     VectorizedCast = 1,
     SrcCoeffRatio = 1,
     TgtCoeffRatio = 1
   };
 };
 
 #endif  // EIGEN_VECTORIZE_AVX512
 
+template<> EIGEN_STRONG_INLINE Packet8i pcast<Packet8f, Packet8i>(const Packet8f& a) {
+  return _mm256_cvttps_epi32(a);
+}
+
+template<> EIGEN_STRONG_INLINE Packet8f pcast<Packet8i, Packet8f>(const Packet8i& a) {
+  return _mm256_cvtepi32_ps(a);
+}
+
+template<> EIGEN_STRONG_INLINE Packet8i preinterpret<Packet8i,Packet8f>(const Packet8f& a) {
+  return _mm256_castps_si256(a);
+}
+
+template<> EIGEN_STRONG_INLINE Packet8f preinterpret<Packet8f,Packet8i>(const Packet8i& a) {
+  return _mm256_castsi256_ps(a);
+}
+
+template<> EIGEN_STRONG_INLINE Packet8f pcast<Packet8h, Packet8f>(const Packet8h& a) {
+  return half2float(a);
+}
+
+template<> EIGEN_STRONG_INLINE Packet8f pcast<Packet8bf, Packet8f>(const Packet8bf& a) {
+  return Bf16ToF32(a);
+}
+
 template<> EIGEN_STRONG_INLINE Packet8h pcast<Packet8f, Packet8h>(const Packet8f& a) {
   return float2half(a);
 }
 
 template<> EIGEN_STRONG_INLINE Packet8bf pcast<Packet8f, Packet8bf>(const Packet8f& a) {
   return F32ToBf16(a);
 }
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/AVX512/Complex.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/AVX512/Complex.h`

 * *Files 4% similar despite different names*

```diff
@@ -33,32 +33,34 @@
     HasHalfPacket = 1,
 
     HasAdd    = 1,
     HasSub    = 1,
     HasMul    = 1,
     HasDiv    = 1,
     HasNegate = 1,
+    HasSqrt   = 1,
     HasAbs    = 0,
     HasAbs2   = 0,
     HasMin    = 0,
     HasMax    = 0,
     HasSetLinear = 0
   };
 };
 
 template<> struct unpacket_traits<Packet8cf> {
   typedef std::complex<float> type;
+  typedef Packet4cf half;
+  typedef Packet16f as_real;
   enum {
     size = 8,
     alignment=unpacket_traits<Packet16f>::alignment,
     vectorizable=true,
     masked_load_available=false,
     masked_store_available=false
   };
-  typedef Packet4cf half;
 };
 
 template<> EIGEN_STRONG_INLINE Packet8cf ptrue<Packet8cf>(const Packet8cf& a) { return Packet8cf(ptrue(Packet16f(a.v))); }
 template<> EIGEN_STRONG_INLINE Packet8cf padd<Packet8cf>(const Packet8cf& a, const Packet8cf& b) { return Packet8cf(_mm512_add_ps(a.v,b.v)); }
 template<> EIGEN_STRONG_INLINE Packet8cf psub<Packet8cf>(const Packet8cf& a, const Packet8cf& b) { return Packet8cf(_mm512_sub_ps(a.v,b.v)); }
 template<> EIGEN_STRONG_INLINE Packet8cf pnegate(const Packet8cf& a)
 {
@@ -147,47 +149,14 @@
 EIGEN_STRONG_INLINE Packet4cf predux_half_dowto4<Packet8cf>(const Packet8cf& a) {
   __m256 lane0 = extract256<0>(a.v);
   __m256 lane1 = extract256<1>(a.v);
   __m256 res = _mm256_add_ps(lane0, lane1);
   return Packet4cf(res);
 }
 
-template<> struct conj_helper<Packet8cf, Packet8cf, false,true>
-{
-  EIGEN_STRONG_INLINE Packet8cf pmadd(const Packet8cf& x, const Packet8cf& y, const Packet8cf& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet8cf pmul(const Packet8cf& a, const Packet8cf& b) const
-  {
-    return internal::pmul(a, pconj(b));
-  }
-};
-
-template<> struct conj_helper<Packet8cf, Packet8cf, true,false>
-{
-  EIGEN_STRONG_INLINE Packet8cf pmadd(const Packet8cf& x, const Packet8cf& y, const Packet8cf& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet8cf pmul(const Packet8cf& a, const Packet8cf& b) const
-  {
-    return internal::pmul(pconj(a), b);
-  }
-};
-
-template<> struct conj_helper<Packet8cf, Packet8cf, true,true>
-{
-  EIGEN_STRONG_INLINE Packet8cf pmadd(const Packet8cf& x, const Packet8cf& y, const Packet8cf& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet8cf pmul(const Packet8cf& a, const Packet8cf& b) const
-  {
-    return pconj(internal::pmul(a, b));
-  }
-};
-
 EIGEN_MAKE_CONJ_HELPER_CPLX_REAL(Packet8cf,Packet16f)
 
 template<> EIGEN_STRONG_INLINE Packet8cf pdiv<Packet8cf>(const Packet8cf& a, const Packet8cf& b)
 {
   Packet8cf num = pmul(a, pconj(b));
   __m512 tmp = _mm512_mul_ps(b.v, b.v);
   __m512 tmp2    = _mm512_shuffle_ps(tmp,tmp,0xB1);
@@ -219,32 +188,34 @@
     HasHalfPacket = 1,
 
     HasAdd    = 1,
     HasSub    = 1,
     HasMul    = 1,
     HasDiv    = 1,
     HasNegate = 1,
+    HasSqrt   = 1,
     HasAbs    = 0,
     HasAbs2   = 0,
     HasMin    = 0,
     HasMax    = 0,
     HasSetLinear = 0
   };
 };
 
 template<> struct unpacket_traits<Packet4cd> {
   typedef std::complex<double> type;
+  typedef Packet2cd half;
+  typedef Packet8d as_real;
   enum {
     size = 4,
     alignment = unpacket_traits<Packet8d>::alignment,
     vectorizable=true,
     masked_load_available=false,
     masked_store_available=false
   };
-  typedef Packet2cd half;
 };
 
 template<> EIGEN_STRONG_INLINE Packet4cd padd<Packet4cd>(const Packet4cd& a, const Packet4cd& b) { return Packet4cd(_mm512_add_pd(a.v,b.v)); }
 template<> EIGEN_STRONG_INLINE Packet4cd psub<Packet4cd>(const Packet4cd& a, const Packet4cd& b) { return Packet4cd(_mm512_sub_pd(a.v,b.v)); }
 template<> EIGEN_STRONG_INLINE Packet4cd pnegate(const Packet4cd& a) { return Packet4cd(pnegate(a.v)); }
 template<> EIGEN_STRONG_INLINE Packet4cd pconj(const Packet4cd& a)
 {
@@ -319,15 +290,15 @@
   __m128d low = extract128<0>(a.v);
   EIGEN_ALIGN16 double res[2];
   _mm_store_pd(res, low);
   return std::complex<double>(res[0],res[1]);
 }
 
 template<> EIGEN_STRONG_INLINE Packet4cd preverse(const Packet4cd& a) {
-  return Packet4cd(_mm512_shuffle_f64x2(a.v, a.v, EIGEN_SSE_SHUFFLE_MASK(3,2,1,0)));
+  return Packet4cd(_mm512_shuffle_f64x2(a.v, a.v, (shuffle_mask<3,2,1,0>::mask)));
 }
 
 template<> EIGEN_STRONG_INLINE std::complex<double> predux<Packet4cd>(const Packet4cd& a)
 {
   return predux(padd(Packet2cd(_mm512_extractf64x4_pd(a.v,0)),
                      Packet2cd(_mm512_extractf64x4_pd(a.v,1))));
 }
@@ -422,23 +393,30 @@
   kernel.packet[5].v = _mm512_castpd_ps(pb.packet[5]);
   kernel.packet[6].v = _mm512_castpd_ps(pb.packet[6]);
   kernel.packet[7].v = _mm512_castpd_ps(pb.packet[7]);
 }
 
 EIGEN_DEVICE_FUNC inline void
 ptranspose(PacketBlock<Packet4cd,4>& kernel) {
-  __m512d T0 = _mm512_shuffle_f64x2(kernel.packet[0].v, kernel.packet[1].v, EIGEN_SSE_SHUFFLE_MASK(0,1,0,1)); // [a0 a1 b0 b1]
-  __m512d T1 = _mm512_shuffle_f64x2(kernel.packet[0].v, kernel.packet[1].v, EIGEN_SSE_SHUFFLE_MASK(2,3,2,3)); // [a2 a3 b2 b3]
-  __m512d T2 = _mm512_shuffle_f64x2(kernel.packet[2].v, kernel.packet[3].v, EIGEN_SSE_SHUFFLE_MASK(0,1,0,1)); // [c0 c1 d0 d1]
-  __m512d T3 = _mm512_shuffle_f64x2(kernel.packet[2].v, kernel.packet[3].v, EIGEN_SSE_SHUFFLE_MASK(2,3,2,3)); // [c2 c3 d2 d3]
-
-  kernel.packet[3] = Packet4cd(_mm512_shuffle_f64x2(T1, T3, EIGEN_SSE_SHUFFLE_MASK(1,3,1,3))); // [a3 b3 c3 d3]
-  kernel.packet[2] = Packet4cd(_mm512_shuffle_f64x2(T1, T3, EIGEN_SSE_SHUFFLE_MASK(0,2,0,2))); // [a2 b2 c2 d2]
-  kernel.packet[1] = Packet4cd(_mm512_shuffle_f64x2(T0, T2, EIGEN_SSE_SHUFFLE_MASK(1,3,1,3))); // [a1 b1 c1 d1]
-  kernel.packet[0] = Packet4cd(_mm512_shuffle_f64x2(T0, T2, EIGEN_SSE_SHUFFLE_MASK(0,2,0,2))); // [a0 b0 c0 d0]
+  __m512d T0 = _mm512_shuffle_f64x2(kernel.packet[0].v, kernel.packet[1].v, (shuffle_mask<0,1,0,1>::mask)); // [a0 a1 b0 b1]
+  __m512d T1 = _mm512_shuffle_f64x2(kernel.packet[0].v, kernel.packet[1].v, (shuffle_mask<2,3,2,3>::mask)); // [a2 a3 b2 b3]
+  __m512d T2 = _mm512_shuffle_f64x2(kernel.packet[2].v, kernel.packet[3].v, (shuffle_mask<0,1,0,1>::mask)); // [c0 c1 d0 d1]
+  __m512d T3 = _mm512_shuffle_f64x2(kernel.packet[2].v, kernel.packet[3].v, (shuffle_mask<2,3,2,3>::mask)); // [c2 c3 d2 d3]
+
+  kernel.packet[3] = Packet4cd(_mm512_shuffle_f64x2(T1, T3, (shuffle_mask<1,3,1,3>::mask))); // [a3 b3 c3 d3]
+  kernel.packet[2] = Packet4cd(_mm512_shuffle_f64x2(T1, T3, (shuffle_mask<0,2,0,2>::mask))); // [a2 b2 c2 d2]
+  kernel.packet[1] = Packet4cd(_mm512_shuffle_f64x2(T0, T2, (shuffle_mask<1,3,1,3>::mask))); // [a1 b1 c1 d1]
+  kernel.packet[0] = Packet4cd(_mm512_shuffle_f64x2(T0, T2, (shuffle_mask<0,2,0,2>::mask))); // [a0 b0 c0 d0]
 }
 
-} // end namespace internal
+template<> EIGEN_STRONG_INLINE Packet4cd psqrt<Packet4cd>(const Packet4cd& a) {
+  return psqrt_complex<Packet4cd>(a);
+}
+
+template<> EIGEN_STRONG_INLINE Packet8cf psqrt<Packet8cf>(const Packet8cf& a) {
+  return psqrt_complex<Packet8cf>(a);
+}
 
+} // end namespace internal
 } // end namespace Eigen
 
 #endif // EIGEN_COMPLEX_AVX512_H
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/AVX512/MathFunctions.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/AVX512/MathFunctions.h`

 * *Files 23% similar despite different names*

```diff
@@ -31,116 +31,43 @@
 
 #define _EIGEN_DECLARE_CONST_Packet16bf(NAME, X) \
   const Packet16bf p16bf_##NAME = pset1<Packet16bf>(X)
 
 #define _EIGEN_DECLARE_CONST_Packet16bf_FROM_INT(NAME, X) \
   const Packet16bf p16bf_##NAME =  preinterpret<Packet16bf,Packet16i>(pset1<Packet16i>(X))
 
-// Natural logarithm
-// Computes log(x) as log(2^e * m) = C*e + log(m), where the constant C =log(2)
-// and m is in the range [sqrt(1/2),sqrt(2)). In this range, the logarithm can
-// be easily approximated by a polynomial centered on m=1 for stability.
-#if defined(EIGEN_VECTORIZE_AVX512DQ)
 template <>
 EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED Packet16f
 plog<Packet16f>(const Packet16f& _x) {
-  Packet16f x = _x;
-  _EIGEN_DECLARE_CONST_Packet16f(1, 1.0f);
-  _EIGEN_DECLARE_CONST_Packet16f(half, 0.5f);
-  _EIGEN_DECLARE_CONST_Packet16f(126f, 126.0f);
+  return plog_float(_x);
+}
 
-  _EIGEN_DECLARE_CONST_Packet16f_FROM_INT(inv_mant_mask, ~0x7f800000);
+template <>
+EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED Packet8d
+plog<Packet8d>(const Packet8d& _x) {
+  return plog_double(_x);
+}
 
-  // The smallest non denormalized float number.
-  _EIGEN_DECLARE_CONST_Packet16f_FROM_INT(min_norm_pos, 0x00800000);
-  _EIGEN_DECLARE_CONST_Packet16f_FROM_INT(minus_inf, 0xff800000);
-  _EIGEN_DECLARE_CONST_Packet16f_FROM_INT(pos_inf, 0x7f800000);
-  _EIGEN_DECLARE_CONST_Packet16f_FROM_INT(nan, 0x7fc00000);
-
-  // Polynomial coefficients.
-  _EIGEN_DECLARE_CONST_Packet16f(cephes_SQRTHF, 0.707106781186547524f);
-  _EIGEN_DECLARE_CONST_Packet16f(cephes_log_p0, 7.0376836292E-2f);
-  _EIGEN_DECLARE_CONST_Packet16f(cephes_log_p1, -1.1514610310E-1f);
-  _EIGEN_DECLARE_CONST_Packet16f(cephes_log_p2, 1.1676998740E-1f);
-  _EIGEN_DECLARE_CONST_Packet16f(cephes_log_p3, -1.2420140846E-1f);
-  _EIGEN_DECLARE_CONST_Packet16f(cephes_log_p4, +1.4249322787E-1f);
-  _EIGEN_DECLARE_CONST_Packet16f(cephes_log_p5, -1.6668057665E-1f);
-  _EIGEN_DECLARE_CONST_Packet16f(cephes_log_p6, +2.0000714765E-1f);
-  _EIGEN_DECLARE_CONST_Packet16f(cephes_log_p7, -2.4999993993E-1f);
-  _EIGEN_DECLARE_CONST_Packet16f(cephes_log_p8, +3.3333331174E-1f);
-  _EIGEN_DECLARE_CONST_Packet16f(cephes_log_q1, -2.12194440e-4f);
-  _EIGEN_DECLARE_CONST_Packet16f(cephes_log_q2, 0.693359375f);
-
-  // invalid_mask is set to true when x is NaN
-  __mmask16 invalid_mask =  _mm512_cmp_ps_mask(x, _mm512_setzero_ps(), _CMP_NGE_UQ);
-  __mmask16 iszero_mask  =  _mm512_cmp_ps_mask(x, _mm512_setzero_ps(), _CMP_EQ_OQ);
-      
-  // Truncate input values to the minimum positive normal.
-  x = pmax(x, p16f_min_norm_pos);
-
-  // Extract the shifted exponents.
-  Packet16f emm0 = _mm512_cvtepi32_ps(_mm512_srli_epi32((preinterpret<Packet16i,Packet16f>(x)), 23));
-  Packet16f e = _mm512_sub_ps(emm0, p16f_126f);
-
-  // Set the exponents to -1, i.e. x are in the range [0.5,1).
-  x = _mm512_and_ps(x, p16f_inv_mant_mask);
-  x = _mm512_or_ps(x, p16f_half);
-
-  // part2: Shift the inputs from the range [0.5,1) to [sqrt(1/2),sqrt(2))
-  // and shift by -1. The values are then centered around 0, which improves
-  // the stability of the polynomial evaluation.
-  //   if( x < SQRTHF ) {
-  //     e -= 1;
-  //     x = x + x - 1.0;
-  //   } else { x = x - 1.0; }
-  __mmask16 mask = _mm512_cmp_ps_mask(x, p16f_cephes_SQRTHF, _CMP_LT_OQ);
-  Packet16f tmp = _mm512_mask_blend_ps(mask, _mm512_setzero_ps(), x);
-  x = psub(x, p16f_1);
-  e = psub(e, _mm512_mask_blend_ps(mask, _mm512_setzero_ps(), p16f_1));
-  x = padd(x, tmp);
+F16_PACKET_FUNCTION(Packet16f, Packet16h, plog)
+BF16_PACKET_FUNCTION(Packet16f, Packet16bf, plog)
 
-  Packet16f x2 = pmul(x, x);
-  Packet16f x3 = pmul(x2, x);
+template <>
+EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED Packet16f
+plog2<Packet16f>(const Packet16f& _x) {
+  return plog2_float(_x);
+}
 
-  // Evaluate the polynomial approximant of degree 8 in three parts, probably
-  // to improve instruction-level parallelism.
-  Packet16f y, y1, y2;
-  y = pmadd(p16f_cephes_log_p0, x, p16f_cephes_log_p1);
-  y1 = pmadd(p16f_cephes_log_p3, x, p16f_cephes_log_p4);
-  y2 = pmadd(p16f_cephes_log_p6, x, p16f_cephes_log_p7);
-  y = pmadd(y, x, p16f_cephes_log_p2);
-  y1 = pmadd(y1, x, p16f_cephes_log_p5);
-  y2 = pmadd(y2, x, p16f_cephes_log_p8);
-  y = pmadd(y, x3, y1);
-  y = pmadd(y, x3, y2);
-  y = pmul(y, x3);
-
-  // Add the logarithm of the exponent back to the result of the interpolation.
-  y1 = pmul(e, p16f_cephes_log_q1);
-  tmp = pmul(x2, p16f_half);
-  y = padd(y, y1);
-  x = psub(x, tmp);
-  y2 = pmul(e, p16f_cephes_log_q2);
-  x = padd(x, y);
-  x = padd(x, y2);
-
-  __mmask16 pos_inf_mask = _mm512_cmp_ps_mask(_x,p16f_pos_inf,_CMP_EQ_OQ);
-  // Filter out invalid inputs, i.e.:
-  //  - negative arg will be NAN,
-  //  - 0 will be -INF.
-  //  - +INF will be +INF
-  return _mm512_mask_blend_ps(iszero_mask,
-            _mm512_mask_blend_ps(invalid_mask,
-              _mm512_mask_blend_ps(pos_inf_mask,x,p16f_pos_inf),
-              p16f_nan),
-            p16f_minus_inf);
+template <>
+EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED Packet8d
+plog2<Packet8d>(const Packet8d& _x) {
+  return plog2_double(_x);
 }
 
-BF16_PACKET_FUNCTION(Packet16f, Packet16bf, plog)
-#endif
+F16_PACKET_FUNCTION(Packet16f, Packet16h, plog2)
+BF16_PACKET_FUNCTION(Packet16f, Packet16bf, plog2)
 
 // Exponential function. Works by writing "x = m*log(2) + r" where
 // "m = floor(x/log(2)+1/2)" and "r" is the remainder. The result is then
 // "exp(x) = 2^m*exp(r)" where exp(r) is in the range [-1,1).
 template <>
 EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED Packet16f
 pexp<Packet16f>(const Packet16f& _x) {
@@ -168,104 +95,68 @@
   Packet16f m = _mm512_floor_ps(pmadd(x, p16f_cephes_LOG2EF, p16f_half));
 
   // Get r = x - m*ln(2). Note that we can do this without losing more than one
   // ulp precision due to the FMA instruction.
   _EIGEN_DECLARE_CONST_Packet16f(nln2, -0.6931471805599453f);
   Packet16f r = _mm512_fmadd_ps(m, p16f_nln2, x);
   Packet16f r2 = pmul(r, r);
+  Packet16f r3 = pmul(r2, r);
 
-  // TODO(gonnet): Split into odd/even polynomials and try to exploit
-  //               instruction-level parallelism.
-  Packet16f y = p16f_cephes_exp_p0;
-  y = pmadd(y, r, p16f_cephes_exp_p1);
-  y = pmadd(y, r, p16f_cephes_exp_p2);
-  y = pmadd(y, r, p16f_cephes_exp_p3);
-  y = pmadd(y, r, p16f_cephes_exp_p4);
-  y = pmadd(y, r, p16f_cephes_exp_p5);
-  y = pmadd(y, r2, r);
-  y = padd(y, p16f_1);
+  // Evaluate the polynomial approximant,improved by instruction-level parallelism.
+  Packet16f y, y1, y2;
+  y  = pmadd(p16f_cephes_exp_p0, r, p16f_cephes_exp_p1);
+  y1 = pmadd(p16f_cephes_exp_p3, r, p16f_cephes_exp_p4);
+  y2 = padd(r, p16f_1);
+  y  = pmadd(y, r, p16f_cephes_exp_p2);
+  y1 = pmadd(y1, r, p16f_cephes_exp_p5);
+  y  = pmadd(y, r3, y1);
+  y  = pmadd(y, r2, y2);
 
   // Build emm0 = 2^m.
   Packet16i emm0 = _mm512_cvttps_epi32(padd(m, p16f_127));
   emm0 = _mm512_slli_epi32(emm0, 23);
 
   // Return 2^m * exp(r).
   return pmax(pmul(y, _mm512_castsi512_ps(emm0)), _x);
 }
 
-/*template <>
+template <>
 EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED Packet8d
 pexp<Packet8d>(const Packet8d& _x) {
-  Packet8d x = _x;
+  return pexp_double(_x);
+}
 
-  _EIGEN_DECLARE_CONST_Packet8d(1, 1.0);
-  _EIGEN_DECLARE_CONST_Packet8d(2, 2.0);
+F16_PACKET_FUNCTION(Packet16f, Packet16h, pexp)
+BF16_PACKET_FUNCTION(Packet16f, Packet16bf, pexp)
 
-  _EIGEN_DECLARE_CONST_Packet8d(exp_hi, 709.437);
-  _EIGEN_DECLARE_CONST_Packet8d(exp_lo, -709.436139303);
+template <>
+EIGEN_STRONG_INLINE Packet16h pfrexp(const Packet16h& a, Packet16h& exponent) {
+  Packet16f fexponent;
+  const Packet16h out = float2half(pfrexp<Packet16f>(half2float(a), fexponent));
+  exponent = float2half(fexponent);
+  return out;
+}
 
-  _EIGEN_DECLARE_CONST_Packet8d(cephes_LOG2EF, 1.4426950408889634073599);
-
-  _EIGEN_DECLARE_CONST_Packet8d(cephes_exp_p0, 1.26177193074810590878e-4);
-  _EIGEN_DECLARE_CONST_Packet8d(cephes_exp_p1, 3.02994407707441961300e-2);
-  _EIGEN_DECLARE_CONST_Packet8d(cephes_exp_p2, 9.99999999999999999910e-1);
-
-  _EIGEN_DECLARE_CONST_Packet8d(cephes_exp_q0, 3.00198505138664455042e-6);
-  _EIGEN_DECLARE_CONST_Packet8d(cephes_exp_q1, 2.52448340349684104192e-3);
-  _EIGEN_DECLARE_CONST_Packet8d(cephes_exp_q2, 2.27265548208155028766e-1);
-  _EIGEN_DECLARE_CONST_Packet8d(cephes_exp_q3, 2.00000000000000000009e0);
-
-  _EIGEN_DECLARE_CONST_Packet8d(cephes_exp_C1, 0.693145751953125);
-  _EIGEN_DECLARE_CONST_Packet8d(cephes_exp_C2, 1.42860682030941723212e-6);
-
-  // clamp x
-  x = pmax(pmin(x, p8d_exp_hi), p8d_exp_lo);
-
-  // Express exp(x) as exp(g + n*log(2)).
-  const Packet8d n =
-      _mm512_mul_round_pd(p8d_cephes_LOG2EF, x, _MM_FROUND_TO_NEAREST_INT);
-
-  // Get the remainder modulo log(2), i.e. the "g" described above. Subtract
-  // n*log(2) out in two steps, i.e. n*C1 + n*C2, C1+C2=log2 to get the last
-  // digits right.
-  const Packet8d nC1 = pmul(n, p8d_cephes_exp_C1);
-  const Packet8d nC2 = pmul(n, p8d_cephes_exp_C2);
-  x = psub(x, nC1);
-  x = psub(x, nC2);
-
-  const Packet8d x2 = pmul(x, x);
-
-  // Evaluate the numerator polynomial of the rational interpolant.
-  Packet8d px = p8d_cephes_exp_p0;
-  px = pmadd(px, x2, p8d_cephes_exp_p1);
-  px = pmadd(px, x2, p8d_cephes_exp_p2);
-  px = pmul(px, x);
-
-  // Evaluate the denominator polynomial of the rational interpolant.
-  Packet8d qx = p8d_cephes_exp_q0;
-  qx = pmadd(qx, x2, p8d_cephes_exp_q1);
-  qx = pmadd(qx, x2, p8d_cephes_exp_q2);
-  qx = pmadd(qx, x2, p8d_cephes_exp_q3);
-
-  // I don't really get this bit, copied from the SSE2 routines, so...
-  // TODO(gonnet): Figure out what is going on here, perhaps find a better
-  // rational interpolant?
-  x = _mm512_div_pd(px, psub(qx, px));
-  x = pmadd(p8d_2, x, p8d_1);
-
-  // Build e=2^n.
-  const Packet8d e = _mm512_castsi512_pd(_mm512_slli_epi64(
-      _mm512_add_epi64(_mm512_cvtpd_epi64(n), _mm512_set1_epi64(1023)), 52));
-
-  // Construct the result 2^n * exp(g) = e * x. The max is used to catch
-  // non-finite values in the input.
-  return pmax(pmul(x, e), _x);
-  }*/
+template <>
+EIGEN_STRONG_INLINE Packet16h pldexp(const Packet16h& a, const Packet16h& exponent) {
+  return float2half(pldexp<Packet16f>(half2float(a), half2float(exponent)));
+}
 
-BF16_PACKET_FUNCTION(Packet16f, Packet16bf, pexp)
+template <>
+EIGEN_STRONG_INLINE Packet16bf pfrexp(const Packet16bf& a, Packet16bf& exponent) {
+  Packet16f fexponent;
+  const Packet16bf out = F32ToBf16(pfrexp<Packet16f>(Bf16ToF32(a), fexponent));
+  exponent = F32ToBf16(fexponent);
+  return out;
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet16bf pldexp(const Packet16bf& a, const Packet16bf& exponent) {
+  return F32ToBf16(pldexp<Packet16f>(Bf16ToF32(a), Bf16ToF32(exponent)));
+}
 
 // Functions for sqrt.
 // The EIGEN_FAST_MATH version uses the _mm_rsqrt_ps approximation and one step
 // of Newton's method, at a cost of 1-2 bits of precision as opposed to the
 // exact solution. The main advantage of this approach is not just speed, but
 // also the fact that it can be inlined and pipelined with other computations,
 // further reducing its effective latency.
@@ -315,14 +206,15 @@
 
 template <>
 EIGEN_STRONG_INLINE Packet8d psqrt<Packet8d>(const Packet8d& x) {
   return _mm512_sqrt_pd(x);
 }
 #endif
 
+F16_PACKET_FUNCTION(Packet16f, Packet16h, psqrt)
 BF16_PACKET_FUNCTION(Packet16f, Packet16bf, psqrt)
 
 // prsqrt for float.
 #if defined(EIGEN_VECTORIZE_AVX512ER)
 
 template <>
 EIGEN_STRONG_INLINE Packet16f prsqrt<Packet16f>(const Packet16f& x) {
@@ -339,15 +231,15 @@
 
   Packet16f neg_half = pmul(_x, p16f_minus_half);
 
   // Identity infinite, negative and denormal arguments.
   __mmask16 inf_mask = _mm512_cmp_ps_mask(_x, p16f_inf, _CMP_EQ_OQ);
   __mmask16 not_pos_mask = _mm512_cmp_ps_mask(_x, _mm512_setzero_ps(), _CMP_LE_OQ);
   __mmask16 not_finite_pos_mask = not_pos_mask | inf_mask;
-  
+
   // Compute an approximate result using the rsqrt intrinsic, forcing +inf
   // for denormals for consistency with AVX and SSE implementations.
   Packet16f y_approx = _mm512_rsqrt14_ps(_x);
 
   // Do a single step of Newton-Raphson iteration to improve the approximation.
   // This uses the formula y_{n+1} = y_n * (1.5 - y_n * (0.5 * x) * y_n).
   // It is essential to evaluate the inner term like this because forming
@@ -364,14 +256,15 @@
 template <>
 EIGEN_STRONG_INLINE Packet16f prsqrt<Packet16f>(const Packet16f& x) {
   _EIGEN_DECLARE_CONST_Packet16f(one, 1.0f);
   return _mm512_div_ps(p16f_one, _mm512_sqrt_ps(x));
 }
 #endif
 
+F16_PACKET_FUNCTION(Packet16f, Packet16h, prsqrt)
 BF16_PACKET_FUNCTION(Packet16f, Packet16bf, prsqrt)
 
 // prsqrt for double.
 #if EIGEN_FAST_MATH
 template <>
 EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED Packet8d
 prsqrt<Packet8d>(const Packet8d& _x) {
@@ -413,29 +306,29 @@
 template <>
 EIGEN_STRONG_INLINE Packet8d prsqrt<Packet8d>(const Packet8d& x) {
   _EIGEN_DECLARE_CONST_Packet8d(one, 1.0f);
   return _mm512_div_pd(p8d_one, _mm512_sqrt_pd(x));
 }
 #endif
 
-#if defined(EIGEN_VECTORIZE_AVX512DQ)
 template<> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
 Packet16f plog1p<Packet16f>(const Packet16f& _x) {
   return generic_plog1p(_x);
 }
 
+F16_PACKET_FUNCTION(Packet16f, Packet16h, plog1p)
 BF16_PACKET_FUNCTION(Packet16f, Packet16bf, plog1p)
 
 template<> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
 Packet16f pexpm1<Packet16f>(const Packet16f& _x) {
   return generic_expm1(_x);
 }
 
+F16_PACKET_FUNCTION(Packet16f, Packet16h, pexpm1)
 BF16_PACKET_FUNCTION(Packet16f, Packet16bf, pexpm1)
-#endif
 
 #endif
 
 
 template <>
 EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED Packet16f
 psin<Packet16f>(const Packet16f& _x) {
@@ -450,14 +343,18 @@
 
 template <>
 EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED Packet16f
 ptanh<Packet16f>(const Packet16f& _x) {
   return internal::generic_fast_tanh_float(_x);
 }
 
+F16_PACKET_FUNCTION(Packet16f, Packet16h, psin)
+F16_PACKET_FUNCTION(Packet16f, Packet16h, pcos)
+F16_PACKET_FUNCTION(Packet16f, Packet16h, ptanh)
+
 BF16_PACKET_FUNCTION(Packet16f, Packet16bf, psin)
 BF16_PACKET_FUNCTION(Packet16f, Packet16bf, pcos)
 BF16_PACKET_FUNCTION(Packet16f, Packet16bf, ptanh)
 
 }  // end namespace internal
 
 }  // end namespace Eigen
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/AVX512/PacketMath.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/AVX512/PacketMath.h`

 * *Files 5% similar despite different names*

```diff
@@ -54,79 +54,106 @@
   typedef Packet16h type;
   // There is no half-size packet for Packet16h.
   typedef Packet16h half;
   enum {
     Vectorizable = 1,
     AlignedOnScalar = 1,
     size = 16,
-    HasHalfPacket = 0,
+    HasHalfPacket = 1,
+
+    HasCmp    = 1,
     HasAdd    = 1,
     HasSub    = 1,
     HasMul    = 1,
     HasDiv    = 1,
     HasNegate = 1,
-    HasAbs    = 0,
+    HasAbs    = 1,
     HasAbs2   = 0,
-    HasMin    = 0,
-    HasMax    = 0,
-    HasConj   = 0,
+    HasMin    = 1,
+    HasMax    = 1,
+    HasConj   = 1,
     HasSetLinear = 0,
-    HasSqrt = 0,
-    HasRsqrt = 0,
-    HasExp = 0,
-    HasLog = 0,
-    HasBlend = 0
+    HasLog    = 1,
+    HasLog1p  = 1,
+    HasExpm1  = 1,
+    HasExp    = 1,
+    HasSqrt   = 1,
+    HasRsqrt  = 1,
+    HasSin    = EIGEN_FAST_MATH,
+    HasCos    = EIGEN_FAST_MATH,
+    HasTanh   = EIGEN_FAST_MATH,
+    HasErf    = EIGEN_FAST_MATH,
+    HasBlend = 0,
+    HasRound  = 1,
+    HasFloor  = 1,
+    HasCeil   = 1,
+    HasRint   = 1,
+    HasBessel = 1,
+    HasNdtri  = 1
   };
 };
 
 template<> struct packet_traits<float>  : default_packet_traits
 {
   typedef Packet16f type;
   typedef Packet8f half;
   enum {
     Vectorizable = 1,
     AlignedOnScalar = 1,
     size = 16,
     HasHalfPacket = 1,
+
+    HasAbs = 1,
+    HasMin    = 1,
+    HasMax    = 1,
+    HasConj   = 1,
     HasBlend = 0,
     HasSin = EIGEN_FAST_MATH,
     HasCos = EIGEN_FAST_MATH,
 #if EIGEN_GNUC_AT_LEAST(5, 3) || (!EIGEN_COMP_GNUC_STRICT)
-#ifdef EIGEN_VECTORIZE_AVX512DQ
     HasLog = 1,
     HasLog1p  = 1,
     HasExpm1  = 1,
     HasNdtri = 1,
     HasBessel  = 1,
-#endif
     HasExp = 1,
     HasSqrt = EIGEN_FAST_MATH,
     HasRsqrt = EIGEN_FAST_MATH,
     HasTanh = EIGEN_FAST_MATH,
     HasErf = EIGEN_FAST_MATH,
 #endif
     HasCmp  = 1,
-    HasDiv = 1
+    HasDiv = 1,
+    HasRound = 1,
+    HasFloor = 1,
+    HasCeil = 1,
+    HasRint = 1
   };
  };
 template<> struct packet_traits<double> : default_packet_traits
 {
   typedef Packet8d type;
   typedef Packet4d half;
   enum {
     Vectorizable = 1,
     AlignedOnScalar = 1,
     size = 8,
     HasHalfPacket = 1,
 #if EIGEN_GNUC_AT_LEAST(5, 3) || (!EIGEN_COMP_GNUC_STRICT)
+    HasLog  = 1,
+    HasExp = 1,
     HasSqrt = EIGEN_FAST_MATH,
     HasRsqrt = EIGEN_FAST_MATH,
 #endif
     HasCmp  = 1,
-    HasDiv = 1
+    HasDiv = 1,
+    HasRound = 1,
+    HasFloor = 1,
+    HasCeil = 1,
+    HasRint = 1
   };
 };
 
 /* TODO Implement AVX512 for integers
 template<> struct packet_traits<int>    : default_packet_traits
 {
   typedef Packet16i type;
@@ -158,15 +185,15 @@
   typedef Packet8i half;
   enum { size = 16, alignment=Aligned64, vectorizable=false, masked_load_available=false, masked_store_available=false };
 };
 
 template<>
 struct unpacket_traits<Packet16h> {
   typedef Eigen::half type;
-  typedef Packet16h half;
+  typedef Packet8h half;
   enum {size=16, alignment=Aligned32, vectorizable=true, masked_load_available=false, masked_store_available=false};
 };
 
 template <>
 EIGEN_STRONG_INLINE Packet16f pset1<Packet16f>(const float& from) {
   return _mm512_set1_ps(from);
 }
@@ -181,14 +208,36 @@
 
 template <>
 EIGEN_STRONG_INLINE Packet16f pset1frombits<Packet16f>(unsigned int from) {
   return _mm512_castsi512_ps(_mm512_set1_epi32(from));
 }
 
 template <>
+EIGEN_STRONG_INLINE Packet8d pset1frombits<Packet8d>(const numext::uint64_t from) {
+  return _mm512_castsi512_pd(_mm512_set1_epi64(from));
+}
+
+template<> EIGEN_STRONG_INLINE Packet16f pzero(const Packet16f& /*a*/) { return _mm512_setzero_ps(); }
+template<> EIGEN_STRONG_INLINE Packet8d pzero(const Packet8d& /*a*/) { return _mm512_setzero_pd(); }
+template<> EIGEN_STRONG_INLINE Packet16i pzero(const Packet16i& /*a*/) { return _mm512_setzero_si512(); }
+
+template<> EIGEN_STRONG_INLINE Packet16f peven_mask(const Packet16f& /*a*/) {
+  return _mm512_castsi512_ps(_mm512_set_epi32(0, -1, 0, -1, 0, -1, 0, -1,
+                                              0, -1, 0, -1, 0, -1, 0, -1));
+}
+template<> EIGEN_STRONG_INLINE Packet16i peven_mask(const Packet16i& /*a*/) {
+  return _mm512_set_epi32(0, -1, 0, -1, 0, -1, 0, -1,
+                          0, -1, 0, -1, 0, -1, 0, -1);
+}
+template<> EIGEN_STRONG_INLINE Packet8d peven_mask(const Packet8d& /*a*/) {
+  return _mm512_castsi512_pd(_mm512_set_epi32(0, 0, -1, -1, 0, 0, -1, -1,
+                                              0, 0, -1, -1, 0, 0, -1, -1));
+}
+
+template <>
 EIGEN_STRONG_INLINE Packet16f pload1<Packet16f>(const float* from) {
   return _mm512_broadcastss_ps(_mm_load_ps1(from));
 }
 template <>
 EIGEN_STRONG_INLINE Packet8d pload1<Packet8d>(const double* from) {
   return _mm512_set1_pd(*from);
 }
@@ -269,15 +318,15 @@
 EIGEN_STRONG_INLINE Packet8d pmul<Packet8d>(const Packet8d& a,
                                             const Packet8d& b) {
   return _mm512_mul_pd(a, b);
 }
 template <>
 EIGEN_STRONG_INLINE Packet16i pmul<Packet16i>(const Packet16i& a,
                                               const Packet16i& b) {
-  return _mm512_mul_epi32(a, b);
+  return _mm512_mullo_epi32(a, b);
 }
 
 template <>
 EIGEN_STRONG_INLINE Packet16f pdiv<Packet16f>(const Packet16f& a,
                                               const Packet16f& b) {
   return _mm512_div_ps(a, b);
 }
@@ -340,14 +389,49 @@
 template <>
 EIGEN_STRONG_INLINE Packet8d pmax<Packet8d>(const Packet8d& a,
                                             const Packet8d& b) {
   // Arguments are reversed to match NaN propagation behavior of std::max.
   return _mm512_max_pd(b, a);
 }
 
+// Add specializations for min/max with prescribed NaN progation.
+template<>
+EIGEN_STRONG_INLINE Packet16f pmin<PropagateNumbers, Packet16f>(const Packet16f& a, const Packet16f& b) {
+  return pminmax_propagate_numbers(a, b, pmin<Packet16f>);
+}
+template<>
+EIGEN_STRONG_INLINE Packet8d pmin<PropagateNumbers, Packet8d>(const Packet8d& a, const Packet8d& b) {
+  return pminmax_propagate_numbers(a, b, pmin<Packet8d>);
+}
+template<>
+EIGEN_STRONG_INLINE Packet16f pmax<PropagateNumbers, Packet16f>(const Packet16f& a, const Packet16f& b) {
+  return pminmax_propagate_numbers(a, b, pmax<Packet16f>);
+}
+template<>
+EIGEN_STRONG_INLINE Packet8d pmax<PropagateNumbers, Packet8d>(const Packet8d& a, const Packet8d& b) {
+  return pminmax_propagate_numbers(a, b, pmax<Packet8d>);
+}
+template<>
+EIGEN_STRONG_INLINE Packet16f pmin<PropagateNaN, Packet16f>(const Packet16f& a, const Packet16f& b) {
+  return pminmax_propagate_nan(a, b, pmin<Packet16f>);
+}
+template<>
+EIGEN_STRONG_INLINE Packet8d pmin<PropagateNaN, Packet8d>(const Packet8d& a, const Packet8d& b) {
+  return pminmax_propagate_nan(a, b, pmin<Packet8d>);
+}
+template<>
+EIGEN_STRONG_INLINE Packet16f pmax<PropagateNaN, Packet16f>(const Packet16f& a, const Packet16f& b) {
+  return pminmax_propagate_nan(a, b, pmax<Packet16f>);
+}
+template<>
+EIGEN_STRONG_INLINE Packet8d pmax<PropagateNaN, Packet8d>(const Packet8d& a, const Packet8d& b) {
+  return pminmax_propagate_nan(a, b, pmax<Packet8d>);
+}
+
+
 #ifdef EIGEN_VECTORIZE_AVX512DQ
 template<int I_> EIGEN_STRONG_INLINE Packet8f extract256(Packet16f x) { return _mm512_extractf32x8_ps(x,I_); }
 template<int I_> EIGEN_STRONG_INLINE Packet2d extract128(Packet8d x) { return _mm512_extractf64x2_pd(x,I_); }
 EIGEN_STRONG_INLINE Packet16f cat256(Packet8f a, Packet8f b) { return _mm512_insertf32x8(_mm512_castps256_ps512(a),b,1); }
 #else
 // AVX512F does not define _mm512_extractf32x8_ps to extract _m256 from _m512
 template<int I_> EIGEN_STRONG_INLINE Packet8f extract256(Packet16f x) {
@@ -399,15 +483,15 @@
 template<> EIGEN_STRONG_INLINE Packet16f pcmp_lt(const Packet16f& a, const Packet16f& b) {
   __mmask16 mask = _mm512_cmp_ps_mask(a, b, _CMP_LT_OQ);
   return _mm512_castsi512_ps(
       _mm512_mask_set1_epi32(_mm512_set1_epi32(0), mask, 0xffffffffu));
 }
 
 template<> EIGEN_STRONG_INLINE Packet16f pcmp_lt_or_nan(const Packet16f& a, const Packet16f& b) {
-  __mmask16 mask = _mm512_cmp_ps_mask(a, b, _CMP_NGT_UQ);
+  __mmask16 mask = _mm512_cmp_ps_mask(a, b, _CMP_NGE_UQ);
   return _mm512_castsi512_ps(
       _mm512_mask_set1_epi32(_mm512_set1_epi32(0), mask, 0xffffffffu));
 }
 
 template<> EIGEN_STRONG_INLINE Packet16i pcmp_eq(const Packet16i& a, const Packet16i& b) {
   __mmask16 mask = _mm512_cmp_epi32_mask(a, b, _CMP_EQ_OQ);
   return _mm512_mask_set1_epi32(_mm512_set1_epi32(0), mask, 0xffffffffu);
@@ -430,19 +514,28 @@
 EIGEN_STRONG_INLINE Packet8d pcmp_lt(const Packet8d& a, const Packet8d& b) {
   __mmask8 mask = _mm512_cmp_pd_mask(a, b, _CMP_LT_OQ);
   return _mm512_castsi512_pd(
       _mm512_mask_set1_epi64(_mm512_set1_epi64(0), mask, 0xffffffffffffffffu));
 }
 template <>
 EIGEN_STRONG_INLINE Packet8d pcmp_lt_or_nan(const Packet8d& a, const Packet8d& b) {
-  __mmask8 mask = _mm512_cmp_pd_mask(a, b, _CMP_NGT_UQ);
+  __mmask8 mask = _mm512_cmp_pd_mask(a, b, _CMP_NGE_UQ);
   return _mm512_castsi512_pd(
       _mm512_mask_set1_epi64(_mm512_set1_epi64(0), mask, 0xffffffffffffffffu));
 }
 
+template<> EIGEN_STRONG_INLINE Packet16f print<Packet16f>(const Packet16f& a) { return _mm512_roundscale_ps(a, _MM_FROUND_CUR_DIRECTION); }
+template<> EIGEN_STRONG_INLINE Packet8d print<Packet8d>(const Packet8d& a) { return _mm512_roundscale_pd(a, _MM_FROUND_CUR_DIRECTION); }
+
+template<> EIGEN_STRONG_INLINE Packet16f pceil<Packet16f>(const Packet16f& a) { return _mm512_roundscale_ps(a, _MM_FROUND_TO_POS_INF); }
+template<> EIGEN_STRONG_INLINE Packet8d pceil<Packet8d>(const Packet8d& a) { return _mm512_roundscale_pd(a, _MM_FROUND_TO_POS_INF); }
+
+template<> EIGEN_STRONG_INLINE Packet16f pfloor<Packet16f>(const Packet16f& a) { return _mm512_roundscale_ps(a, _MM_FROUND_TO_NEG_INF); }
+template<> EIGEN_STRONG_INLINE Packet8d pfloor<Packet8d>(const Packet8d& a) { return _mm512_roundscale_pd(a, _MM_FROUND_TO_NEG_INF); }
+
 template <>
 EIGEN_STRONG_INLINE Packet16i ptrue<Packet16i>(const Packet16i& /*a*/) {
   return _mm512_set1_epi32(0xffffffffu);
 }
 
 template <>
 EIGEN_STRONG_INLINE Packet16f ptrue<Packet16f>(const Packet16f& a) {
@@ -551,14 +644,29 @@
 #ifdef EIGEN_VECTORIZE_AVX512DQ
   return _mm512_andnot_pd(b, a);
 #else
   return _mm512_castsi512_pd(pandnot(_mm512_castpd_si512(a),_mm512_castpd_si512(b)));
 #endif
 }
 
+template<> EIGEN_STRONG_INLINE Packet16f pround<Packet16f>(const Packet16f& a)
+{
+  // Work-around for default std::round rounding mode.
+  const Packet16f mask = pset1frombits<Packet16f>(static_cast<numext::uint32_t>(0x80000000u));
+  const Packet16f prev0dot5 = pset1frombits<Packet16f>(static_cast<numext::uint32_t>(0x3EFFFFFFu));
+  return _mm512_roundscale_ps(padd(por(pand(a, mask), prev0dot5), a), _MM_FROUND_TO_ZERO);
+}
+template<> EIGEN_STRONG_INLINE Packet8d pround<Packet8d>(const Packet8d& a)
+{
+  // Work-around for default std::round rounding mode.
+  const Packet8d mask = pset1frombits<Packet8d>(static_cast<numext::uint64_t>(0x8000000000000000ull));
+  const Packet8d prev0dot5 = pset1frombits<Packet8d>(static_cast<numext::uint64_t>(0x3FDFFFFFFFFFFFFFull));
+  return _mm512_roundscale_pd(padd(por(pand(a, mask), prev0dot5), a), _MM_FROUND_TO_ZERO);
+}
+
 template<int N> EIGEN_STRONG_INLINE Packet16i parithmetic_shift_right(Packet16i a) {
   return _mm512_srai_epi32(a, N);
 }
 
 template<int N> EIGEN_STRONG_INLINE Packet16i plogical_shift_right(Packet16i a) {
   return _mm512_srli_epi32(a, N);
 }
@@ -782,14 +890,67 @@
 template <>
 EIGEN_STRONG_INLINE Packet8d pabs(const Packet8d& a) {
   // _mm512_abs_ps intrinsic not found, so hack around it
   return _mm512_castsi512_pd(_mm512_and_si512(_mm512_castpd_si512(a),
                                    _mm512_set1_epi64(0x7fffffffffffffff)));
 }
 
+template<>
+EIGEN_STRONG_INLINE Packet16f pfrexp<Packet16f>(const Packet16f& a, Packet16f& exponent){
+  return pfrexp_generic(a, exponent);
+}
+
+// Extract exponent without existence of Packet8l.
+template<>
+EIGEN_STRONG_INLINE  
+Packet8d pfrexp_generic_get_biased_exponent(const Packet8d& a) {
+  const Packet8d cst_exp_mask  = pset1frombits<Packet8d>(static_cast<uint64_t>(0x7ff0000000000000ull));
+  #ifdef EIGEN_VECTORIZE_AVX512DQ
+  return _mm512_cvtepi64_pd(_mm512_srli_epi64(_mm512_castpd_si512(pand(a, cst_exp_mask)), 52));
+  #else
+  return _mm512_cvtepi32_pd(_mm512_cvtepi64_epi32(_mm512_srli_epi64(_mm512_castpd_si512(pand(a, cst_exp_mask)), 52)));
+  #endif
+}
+
+template<>
+EIGEN_STRONG_INLINE Packet8d pfrexp<Packet8d>(const Packet8d& a, Packet8d& exponent) {
+  return pfrexp_generic(a, exponent);
+}
+
+template<> EIGEN_STRONG_INLINE Packet16f pldexp<Packet16f>(const Packet16f& a, const Packet16f& exponent) {
+  return pldexp_generic(a, exponent);
+}
+
+template<> EIGEN_STRONG_INLINE Packet8d pldexp<Packet8d>(const Packet8d& a, const Packet8d& exponent) {
+  // Clamp exponent to [-2099, 2099]
+  const Packet8d max_exponent = pset1<Packet8d>(2099.0);
+  const Packet8i e = _mm512_cvtpd_epi32(pmin(pmax(exponent, pnegate(max_exponent)), max_exponent));
+  
+  // Split 2^e into four factors and multiply.
+  const Packet8i bias = pset1<Packet8i>(1023);
+  Packet8i b = parithmetic_shift_right<2>(e);  // floor(e/4)
+  
+  // 2^b
+  const Packet8i permute_idx = _mm256_setr_epi32(0, 4, 1, 5, 2, 6, 3, 7);
+  Packet8i hi = _mm256_permutevar8x32_epi32(padd(b, bias), permute_idx);
+  Packet8i lo = _mm256_slli_epi64(hi, 52);
+  hi = _mm256_slli_epi64(_mm256_srli_epi64(hi, 32), 52);
+  Packet8d c = _mm512_castsi512_pd(_mm512_inserti64x4(_mm512_castsi256_si512(lo), hi, 1));
+  Packet8d out = pmul(pmul(pmul(a, c), c), c);  // a * 2^(3b)
+  
+  // 2^(e - 3b)
+  b = psub(psub(psub(e, b), b), b);  // e - 3b
+  hi = _mm256_permutevar8x32_epi32(padd(b, bias), permute_idx);
+  lo = _mm256_slli_epi64(hi, 52);
+  hi = _mm256_slli_epi64(_mm256_srli_epi64(hi, 32), 52);
+  c = _mm512_castsi512_pd(_mm512_inserti64x4(_mm512_castsi256_si512(lo), hi, 1));
+  out = pmul(out, c);  // a * 2^e
+  return out;
+}
+
 #ifdef EIGEN_VECTORIZE_AVX512DQ
 // AVX512F does not define _mm512_extractf32x8_ps to extract _m256 from _m512
 #define EIGEN_EXTRACT_8f_FROM_16f(INPUT, OUTPUT)                           \
   __m256 OUTPUT##_0 = _mm512_extractf32x8_ps(INPUT, 0);                    \
   __m256 OUTPUT##_1 = _mm512_extractf32x8_ps(INPUT, 1)
 #else
 #define EIGEN_EXTRACT_8f_FROM_16f(INPUT, OUTPUT)                \
@@ -1209,31 +1370,14 @@
              | (ifPacket.select[4]<<4)
              | (ifPacket.select[5]<<5)
              | (ifPacket.select[6]<<6)
              | (ifPacket.select[7]<<7);
   return _mm512_mask_blend_pd(m, elsePacket, thenPacket);
 }
 
-template<> EIGEN_STRONG_INLINE Packet16i pcast<Packet16f, Packet16i>(const Packet16f& a) {
-  return _mm512_cvttps_epi32(a);
-}
-
-template<> EIGEN_STRONG_INLINE Packet16f pcast<Packet16i, Packet16f>(const Packet16i& a) {
-  return _mm512_cvtepi32_ps(a);
-}
-
-template<> EIGEN_STRONG_INLINE Packet16i preinterpret<Packet16i,Packet16f>(const Packet16f& a) {
-  return _mm512_castps_si512(a);
-}
-
-template<> EIGEN_STRONG_INLINE Packet16f preinterpret<Packet16f,Packet16i>(const Packet16i& a) {
-  return _mm512_castsi512_ps(a);
-}
-
-
 // Packet math for Eigen::half
 template<> EIGEN_STRONG_INLINE Packet16h pset1<Packet16h>(const Eigen::half& from) {
   return _mm256_set1_epi16(from.x);
 }
 
 template<> EIGEN_STRONG_INLINE Eigen::half pfirst<Packet16h>(const Packet16h& from) {
   return half_impl::raw_uint16_to_half(static_cast<unsigned short>(_mm256_extract_epi16(from, 0)));
@@ -1338,14 +1482,37 @@
 #endif
 }
 
 template<> EIGEN_STRONG_INLINE Packet16h ptrue(const Packet16h& a) {
   return ptrue(Packet8i(a));
 }
 
+template <>
+EIGEN_STRONG_INLINE Packet16h pabs(const Packet16h& a) {
+  const __m256i sign_mask = _mm256_set1_epi16(static_cast<numext::uint16_t>(0x8000));
+  return _mm256_andnot_si256(sign_mask, a);
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet16h pmin<Packet16h>(const Packet16h& a,
+                                              const Packet16h& b) {
+  return float2half(pmin<Packet16f>(half2float(a), half2float(b)));
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet16h pmax<Packet16h>(const Packet16h& a,
+                                              const Packet16h& b) {
+  return float2half(pmax<Packet16f>(half2float(a), half2float(b)));
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet16h plset<Packet16h>(const half& a) {
+  return float2half(plset<Packet16f>(static_cast<float>(a)));
+}
+
 template<> EIGEN_STRONG_INLINE Packet16h por(const Packet16h& a,const Packet16h& b) {
   // in some cases Packet8i is a wrapper around __m256i, so we need to
   // cast to Packet8i to call the correct overload.
   return por(Packet8i(a),Packet8i(b));
 }
 template<> EIGEN_STRONG_INLINE Packet16h pxor(const Packet16h& a,const Packet16h& b) {
   return pxor(Packet8i(a),Packet8i(b));
@@ -1357,20 +1524,50 @@
   return pandnot(Packet8i(a),Packet8i(b));
 }
 
 template<> EIGEN_STRONG_INLINE Packet16h pselect(const Packet16h& mask, const Packet16h& a, const Packet16h& b) {
   return _mm256_blendv_epi8(b, a, mask);
 }
 
+template<> EIGEN_STRONG_INLINE Packet16h pround<Packet16h>(const Packet16h& a) {
+  return float2half(pround<Packet16f>(half2float(a)));
+}
+
+template<> EIGEN_STRONG_INLINE Packet16h print<Packet16h>(const Packet16h& a) {
+  return float2half(print<Packet16f>(half2float(a)));
+}
+
+template<> EIGEN_STRONG_INLINE Packet16h pceil<Packet16h>(const Packet16h& a) {
+  return float2half(pceil<Packet16f>(half2float(a)));
+}
+
+template<> EIGEN_STRONG_INLINE Packet16h pfloor<Packet16h>(const Packet16h& a) {
+  return float2half(pfloor<Packet16f>(half2float(a)));
+}
+
 template<> EIGEN_STRONG_INLINE Packet16h pcmp_eq(const Packet16h& a,const Packet16h& b) {
   Packet16f af = half2float(a);
   Packet16f bf = half2float(b);
   return Pack32To16(pcmp_eq(af, bf));
 }
 
+template<> EIGEN_STRONG_INLINE Packet16h pcmp_le(const Packet16h& a,const Packet16h& b) {
+  return Pack32To16(pcmp_le(half2float(a), half2float(b)));
+}
+
+template<> EIGEN_STRONG_INLINE Packet16h pcmp_lt(const Packet16h& a,const Packet16h& b) {
+  return Pack32To16(pcmp_lt(half2float(a), half2float(b)));
+}
+
+template<> EIGEN_STRONG_INLINE Packet16h pcmp_lt_or_nan(const Packet16h& a,const Packet16h& b) {
+  return Pack32To16(pcmp_lt_or_nan(half2float(a), half2float(b)));
+}
+
+template<> EIGEN_STRONG_INLINE Packet16h pconj(const Packet16h& a) { return a; }
+
 template<> EIGEN_STRONG_INLINE Packet16h pnegate(const Packet16h& a) {
   Packet16h sign_mask = _mm256_set1_epi16(static_cast<unsigned short>(0x8000));
   return _mm256_xor_si256(a, sign_mask);
 }
 
 template<> EIGEN_STRONG_INLINE Packet16h padd<Packet16h>(const Packet16h& a, const Packet16h& b) {
   Packet16f af = half2float(a);
@@ -1401,14 +1598,33 @@
 }
 
 template<> EIGEN_STRONG_INLINE half predux<Packet16h>(const Packet16h& from) {
   Packet16f from_float = half2float(from);
   return half(predux(from_float));
 }
 
+template <>
+EIGEN_STRONG_INLINE Packet8h predux_half_dowto4<Packet16h>(const Packet16h& a) {
+  Packet8h lane0 = _mm256_extractf128_si256(a, 0);
+  Packet8h lane1 = _mm256_extractf128_si256(a, 1);
+  return padd<Packet8h>(lane0, lane1);
+}
+
+template<> EIGEN_STRONG_INLINE Eigen::half predux_max<Packet16h>(const Packet16h& a) {
+  Packet16f af = half2float(a);
+  float reduced = predux_max<Packet16f>(af);
+  return Eigen::half(reduced);
+}
+
+template<> EIGEN_STRONG_INLINE Eigen::half predux_min<Packet16h>(const Packet16h& a) {
+  Packet16f af = half2float(a);
+  float reduced = predux_min<Packet16f>(af);
+  return Eigen::half(reduced);
+}
+
 template<> EIGEN_STRONG_INLINE half predux_mul<Packet16h>(const Packet16h& from) {
   Packet16f from_float = half2float(from);
   return half(predux_mul(from_float));
 }
 
 template<> EIGEN_STRONG_INLINE Packet16h preverse(const Packet16h& a)
 {
@@ -1427,30 +1643,30 @@
       from[3*stride].x, from[2*stride].x, from[1*stride].x, from[0*stride].x);
 }
 
 template<> EIGEN_STRONG_INLINE void pscatter<half, Packet16h>(half* to, const Packet16h& from, Index stride)
 {
   EIGEN_ALIGN64 half aux[16];
   pstore(aux, from);
-  to[stride*0].x = aux[0].x;
-  to[stride*1].x = aux[1].x;
-  to[stride*2].x = aux[2].x;
-  to[stride*3].x = aux[3].x;
-  to[stride*4].x = aux[4].x;
-  to[stride*5].x = aux[5].x;
-  to[stride*6].x = aux[6].x;
-  to[stride*7].x = aux[7].x;
-  to[stride*8].x = aux[8].x;
-  to[stride*9].x = aux[9].x;
-  to[stride*10].x = aux[10].x;
-  to[stride*11].x = aux[11].x;
-  to[stride*12].x = aux[12].x;
-  to[stride*13].x = aux[13].x;
-  to[stride*14].x = aux[14].x;
-  to[stride*15].x = aux[15].x;
+  to[stride*0] = aux[0];
+  to[stride*1] = aux[1];
+  to[stride*2] = aux[2];
+  to[stride*3] = aux[3];
+  to[stride*4] = aux[4];
+  to[stride*5] = aux[5];
+  to[stride*6] = aux[6];
+  to[stride*7] = aux[7];
+  to[stride*8] = aux[8];
+  to[stride*9] = aux[9];
+  to[stride*10] = aux[10];
+  to[stride*11] = aux[11];
+  to[stride*12] = aux[12];
+  to[stride*13] = aux[13];
+  to[stride*14] = aux[14];
+  to[stride*15] = aux[15];
 }
 
 EIGEN_STRONG_INLINE void
 ptranspose(PacketBlock<Packet16h,16>& kernel) {
   __m256i a = kernel.packet[0];
   __m256i b = kernel.packet[1];
   __m256i c = kernel.packet[2];
@@ -1622,29 +1838,27 @@
 }
 
 template <> struct is_arithmetic<Packet16bf> { enum { value = true }; };
 
 template <>
 struct packet_traits<bfloat16> : default_packet_traits {
   typedef Packet16bf type;
-  // There is no half-size packet for current Packet16bf.
-  // TODO: support as SSE path.
   typedef Packet8bf half;
   enum {
     Vectorizable = 1,
     AlignedOnScalar = 1,
     size = 16,
     HasHalfPacket = 1,
     HasBlend = 0,
     HasInsert = 1,
     HasSin = EIGEN_FAST_MATH,
     HasCos = EIGEN_FAST_MATH,
 #if EIGEN_GNUC_AT_LEAST(5, 3) || (!EIGEN_COMP_GNUC_STRICT)
 #ifdef EIGEN_VECTORIZE_AVX512DQ
-    HasLog = 1,
+    HasLog = 1,  // Currently fails test with bad accuracy.
     HasLog1p  = 1,
     HasExpm1  = 1,
     HasNdtri = 1,
     HasBessel  = 1,
 #endif
     HasExp = 1,
     HasSqrt = EIGEN_FAST_MATH,
@@ -1727,46 +1941,38 @@
   return _mm512_castsi512_ps(_mm512_slli_epi32(_mm512_cvtepu16_epi32(a), 16));
 }
 
 // Convert float to bfloat16 according to round-to-nearest-even/denormals algorithm.
 EIGEN_STRONG_INLINE Packet16bf F32ToBf16(const Packet16f& a) {
   Packet16bf r;
 
-  // Flush input denormals value to zero with hardware capability.
-  _MM_SET_DENORMALS_ZERO_MODE(_MM_DENORMALS_ZERO_ON);
-#if defined(EIGEN_VECTORIZE_AVX512DQ)
-  __m512 flush = _mm512_and_ps(a, a);
-#else
-  __m512 flush = _mm512_max_ps(a, a);
-#endif // EIGEN_VECTORIZE_AVX512DQ
-  _MM_SET_DENORMALS_ZERO_MODE(_MM_DENORMALS_ZERO_OFF);
-
 #if defined(EIGEN_VECTORIZE_AVX512BF16) && EIGEN_GNUC_AT_LEAST(10, 1)
   // Since GCC 10.1 supports avx512bf16 and C style explicit cast
   // (C++ static_cast is not supported yet), do converion via intrinsic
   // and register path for performance.
-  r = (__m256i)(_mm512_cvtneps_pbh(flush));
+  r = (__m256i)(_mm512_cvtneps_pbh(a));
+
 #else
   __m512i t;
-  __m512i input = _mm512_castps_si512(flush);
+  __m512i input = _mm512_castps_si512(a);
   __m512i nan = _mm512_set1_epi32(0x7fc0);
 
   // uint32_t lsb = (input >> 16) & 1;
   t = _mm512_and_si512(_mm512_srli_epi32(input, 16), _mm512_set1_epi32(1));
   // uint32_t rounding_bias = 0x7fff + lsb;
   t = _mm512_add_epi32(t, _mm512_set1_epi32(0x7fff));
   // input += rounding_bias;
   t = _mm512_add_epi32(t, input);
   // input = input >> 16;
   t = _mm512_srli_epi32(t, 16);
 
   // Check NaN before converting back to bf16
-  __mmask16 mask = _mm512_cmp_ps_mask(flush, flush, _CMP_ORD_Q);
-  t = _mm512_mask_blend_epi32(mask, nan, t);
+  __mmask16 mask = _mm512_cmp_ps_mask(a, a, _CMP_ORD_Q);
 
+  t = _mm512_mask_blend_epi32(mask, nan, t);
   // output.value = static_cast<uint16_t>(input);
   r = _mm512_cvtepi32_epi16(t);
 #endif // EIGEN_VECTORIZE_AVX512BF16
 
   return r;
 }
 
@@ -1801,14 +2007,31 @@
                                        const Packet16bf& a,
                                        const Packet16bf& b) {
   // Input mask is expected to be all 0/1, handle it with 8-bit
   // intrinsic for performance.
   return _mm256_blendv_epi8(b, a, mask);
 }
 
+template<> EIGEN_STRONG_INLINE Packet16bf pround<Packet16bf>(const Packet16bf& a)
+{
+  return F32ToBf16(pround<Packet16f>(Bf16ToF32(a)));
+}
+
+template<> EIGEN_STRONG_INLINE Packet16bf print<Packet16bf>(const Packet16bf& a) {
+  return F32ToBf16(print<Packet16f>(Bf16ToF32(a)));
+}
+
+template<> EIGEN_STRONG_INLINE Packet16bf pceil<Packet16bf>(const Packet16bf& a) {
+  return F32ToBf16(pceil<Packet16f>(Bf16ToF32(a)));
+}
+
+template<> EIGEN_STRONG_INLINE Packet16bf pfloor<Packet16bf>(const Packet16bf& a) {
+  return F32ToBf16(pfloor<Packet16f>(Bf16ToF32(a)));
+}
+
 template <>
 EIGEN_STRONG_INLINE Packet16bf pcmp_eq(const Packet16bf& a,
                                        const Packet16bf& b) {
   return Pack32To16(pcmp_eq(Bf16ToF32(a), Bf16ToF32(b)));
 }
 
 template <>
@@ -1827,28 +2050,27 @@
 EIGEN_STRONG_INLINE Packet16bf pcmp_lt_or_nan(const Packet16bf& a,
                                               const Packet16bf& b) {
   return Pack32To16(pcmp_lt_or_nan(Bf16ToF32(a), Bf16ToF32(b)));
 }
 
 template <>
 EIGEN_STRONG_INLINE Packet16bf pnegate(const Packet16bf& a) {
-  Packet16bf sign_mask;
-  sign_mask = _mm256_set1_epi16(static_cast<unsigned short>(0x8000));
-  Packet16bf result;
+  Packet16bf sign_mask = _mm256_set1_epi16(static_cast<unsigned short>(0x8000));
   return _mm256_xor_si256(a, sign_mask);
 }
 
 template <>
 EIGEN_STRONG_INLINE Packet16bf pconj(const Packet16bf& a) {
   return a;
 }
 
 template <>
 EIGEN_STRONG_INLINE Packet16bf pabs(const Packet16bf& a) {
-  return F32ToBf16(pabs<Packet16f>(Bf16ToF32(a)));
+  const __m256i sign_mask = _mm256_set1_epi16(static_cast<numext::uint16_t>(0x8000));
+  return _mm256_andnot_si256(sign_mask, a);
 }
 
 template <>
 EIGEN_STRONG_INLINE Packet16bf padd<Packet16bf>(const Packet16bf& a,
                                                 const Packet16bf& b) {
   return F32ToBf16(padd<Packet16f>(Bf16ToF32(a), Bf16ToF32(b)));
 }
@@ -1880,14 +2102,19 @@
 template <>
 EIGEN_STRONG_INLINE Packet16bf pmax<Packet16bf>(const Packet16bf& a,
                                                 const Packet16bf& b) {
   return F32ToBf16(pmax<Packet16f>(Bf16ToF32(a), Bf16ToF32(b)));
 }
 
 template <>
+EIGEN_STRONG_INLINE Packet16bf plset<Packet16bf>(const bfloat16& a) {
+  return F32ToBf16(plset<Packet16f>(static_cast<float>(a)));
+}
+
+template <>
 EIGEN_STRONG_INLINE Packet8bf predux_half_dowto4<Packet16bf>(const Packet16bf& a) {
   Packet8bf lane0 = _mm256_extractf128_si256(a, 0);
   Packet8bf lane1 = _mm256_extractf128_si256(a, 1);
   return padd<Packet8bf>(lane0, lane1);
 }
 
 template <>
@@ -1934,30 +2161,30 @@
 
 template <>
 EIGEN_STRONG_INLINE void pscatter<bfloat16, Packet16bf>(bfloat16* to,
                                                         const Packet16bf& from,
                                                         Index stride) {
   EIGEN_ALIGN64 bfloat16 aux[16];
   pstore(aux, from);
-  to[stride*0].value = aux[0].value;
-  to[stride*1].value = aux[1].value;
-  to[stride*2].value = aux[2].value;
-  to[stride*3].value = aux[3].value;
-  to[stride*4].value = aux[4].value;
-  to[stride*5].value = aux[5].value;
-  to[stride*6].value = aux[6].value;
-  to[stride*7].value = aux[7].value;
-  to[stride*8].value = aux[8].value;
-  to[stride*9].value = aux[9].value;
-  to[stride*10].value = aux[10].value;
-  to[stride*11].value = aux[11].value;
-  to[stride*12].value = aux[12].value;
-  to[stride*13].value = aux[13].value;
-  to[stride*14].value = aux[14].value;
-  to[stride*15].value = aux[15].value;
+  to[stride*0] = aux[0];
+  to[stride*1] = aux[1];
+  to[stride*2] = aux[2];
+  to[stride*3] = aux[3];
+  to[stride*4] = aux[4];
+  to[stride*5] = aux[5];
+  to[stride*6] = aux[6];
+  to[stride*7] = aux[7];
+  to[stride*8] = aux[8];
+  to[stride*9] = aux[9];
+  to[stride*10] = aux[10];
+  to[stride*11] = aux[11];
+  to[stride*12] = aux[12];
+  to[stride*13] = aux[13];
+  to[stride*14] = aux[14];
+  to[stride*15] = aux[15];
 }
 
 EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet16bf,16>& kernel) {
   __m256i a = kernel.packet[0];
   __m256i b = kernel.packet[1];
   __m256i c = kernel.packet[2];
   __m256i d = kernel.packet[3];
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/AVX512/TypeCasting.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/AVX512/TypeCasting.h`

 * *Files 17% similar despite different names*

```diff
@@ -10,14 +10,30 @@
 #ifndef EIGEN_TYPE_CASTING_AVX512_H
 #define EIGEN_TYPE_CASTING_AVX512_H
 
 namespace Eigen {
 
 namespace internal {
 
+template<> EIGEN_STRONG_INLINE Packet16i pcast<Packet16f, Packet16i>(const Packet16f& a) {
+  return _mm512_cvttps_epi32(a);
+}
+
+template<> EIGEN_STRONG_INLINE Packet16f pcast<Packet16i, Packet16f>(const Packet16i& a) {
+  return _mm512_cvtepi32_ps(a);
+}
+
+template<> EIGEN_STRONG_INLINE Packet16i preinterpret<Packet16i, Packet16f>(const Packet16f& a) {
+  return _mm512_castps_si512(a);
+}
+
+template<> EIGEN_STRONG_INLINE Packet16f preinterpret<Packet16f, Packet16i>(const Packet16i& a) {
+  return _mm512_castsi512_ps(a);
+}
+
 template <>
 struct type_casting_traits<half, float> {
   enum {
     VectorizedCast = 1,
     SrcCoeffRatio = 1,
     TgtCoeffRatio = 1
   };
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/AltiVec/Complex.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/AltiVec/Complex.h`

 * *Files 10% similar despite different names*

```diff
@@ -25,23 +25,70 @@
 static Packet2ul  p2ul_CONJ_XOR2 = (Packet2ul) vec_sld((Packet4ui) p2d_MZERO, (Packet4ui) p2l_ZERO, 8);//{ 0x8000000000000000, 0x0000000000000000 };
 #endif
 #endif
 
 //---------- float ----------
 struct Packet2cf
 {
-  EIGEN_STRONG_INLINE explicit Packet2cf() : v(p4f_ZERO) {}
+  EIGEN_STRONG_INLINE explicit Packet2cf() {}
   EIGEN_STRONG_INLINE explicit Packet2cf(const Packet4f& a) : v(a) {}
+
+  EIGEN_STRONG_INLINE Packet2cf pmul(const Packet2cf& a, const Packet2cf& b)
+  {
+    Packet4f v1, v2;
+
+    // Permute and multiply the real parts of a and b
+    v1 = vec_perm(a.v, a.v, p16uc_PSET32_WODD);
+    // Get the imaginary parts of a
+    v2 = vec_perm(a.v, a.v, p16uc_PSET32_WEVEN);
+    // multiply a_re * b
+    v1 = vec_madd(v1, b.v, p4f_ZERO);
+    // multiply a_im * b and get the conjugate result
+    v2 = vec_madd(v2, b.v, p4f_ZERO);
+    v2 = reinterpret_cast<Packet4f>(pxor(v2, reinterpret_cast<Packet4f>(p4ui_CONJ_XOR)));
+    // permute back to a proper order
+    v2 = vec_perm(v2, v2, p16uc_COMPLEX32_REV);
+
+    return Packet2cf(padd<Packet4f>(v1, v2));
+  }
+
+  EIGEN_STRONG_INLINE Packet2cf& operator*=(const Packet2cf& b) {
+    v = pmul(Packet2cf(*this), b).v;
+    return *this;
+  }
+  EIGEN_STRONG_INLINE Packet2cf operator*(const Packet2cf& b) const {
+    return Packet2cf(*this) *= b;
+  }
+
+  EIGEN_STRONG_INLINE Packet2cf& operator+=(const Packet2cf& b) {
+    v = padd(v, b.v);
+    return *this;
+  }
+  EIGEN_STRONG_INLINE Packet2cf operator+(const Packet2cf& b) const {
+    return Packet2cf(*this) += b;
+  }
+  EIGEN_STRONG_INLINE Packet2cf& operator-=(const Packet2cf& b) {
+    v = psub(v, b.v);
+    return *this;
+  }
+  EIGEN_STRONG_INLINE Packet2cf operator-(const Packet2cf& b) const {
+    return Packet2cf(*this) -= b;
+  }
+  EIGEN_STRONG_INLINE Packet2cf operator-(void) const {
+    return Packet2cf(-v);
+  }
+
   Packet4f  v;
 };
 
 template<> struct packet_traits<std::complex<float> >  : default_packet_traits
 {
   typedef Packet2cf type;
   typedef Packet2cf half;
+  typedef Packet4f as_real;
   enum {
     Vectorizable = 1,
     AlignedOnScalar = 1,
     size = 2,
     HasHalfPacket = 0,
 
     HasAdd    = 1,
@@ -56,15 +103,15 @@
 #ifdef __VSX__
     HasBlend  = 1,
 #endif
     HasSetLinear = 0
   };
 };
 
-template<> struct unpacket_traits<Packet2cf> { typedef std::complex<float> type; enum {size=2, alignment=Aligned16, vectorizable=true, masked_load_available=false, masked_store_available=false}; typedef Packet2cf half; };
+template<> struct unpacket_traits<Packet2cf> { typedef std::complex<float> type; enum {size=2, alignment=Aligned16, vectorizable=true, masked_load_available=false, masked_store_available=false}; typedef Packet2cf half; typedef Packet4f as_real; };
 
 template<> EIGEN_STRONG_INLINE Packet2cf pset1<Packet2cf>(const std::complex<float>&  from)
 {
   Packet2cf res;
   if((std::ptrdiff_t(&from) % 16) == 0)
     res.v = pload<Packet4f>((const float *)&from);
   else
@@ -76,14 +123,33 @@
 template<> EIGEN_STRONG_INLINE Packet2cf pload<Packet2cf>(const std::complex<float>*        from) { return Packet2cf(pload<Packet4f>((const float *) from)); }
 template<> EIGEN_STRONG_INLINE Packet2cf ploadu<Packet2cf>(const std::complex<float>*       from) { return Packet2cf(ploadu<Packet4f>((const float*) from)); }
 template<> EIGEN_STRONG_INLINE Packet2cf ploaddup<Packet2cf>(const std::complex<float>*     from) { return pset1<Packet2cf>(*from); }
 
 template<> EIGEN_STRONG_INLINE void pstore <std::complex<float> >(std::complex<float> *   to, const Packet2cf& from) { pstore((float*)to, from.v); }
 template<> EIGEN_STRONG_INLINE void pstoreu<std::complex<float> >(std::complex<float> *   to, const Packet2cf& from) { pstoreu((float*)to, from.v); }
 
+EIGEN_STRONG_INLINE Packet2cf pload2(const std::complex<float>* from0, const std::complex<float>* from1)
+{
+  Packet4f res0, res1;
+#ifdef __VSX__
+  __asm__ ("lxsdx %x0,%y1" : "=wa" (res0) : "Z" (*from0));
+  __asm__ ("lxsdx %x0,%y1" : "=wa" (res1) : "Z" (*from1));
+#ifdef _BIG_ENDIAN
+  __asm__ ("xxpermdi %x0, %x1, %x2, 0" : "=wa" (res0) : "wa" (res0), "wa" (res1));
+#else
+  __asm__ ("xxpermdi %x0, %x2, %x1, 0" : "=wa" (res0) : "wa" (res0), "wa" (res1));
+#endif
+#else
+  *reinterpret_cast<std::complex<float> *>(&res0) = *from0;
+  *reinterpret_cast<std::complex<float> *>(&res1) = *from1;
+  res0 = vec_perm(res0, res1, p16uc_TRANSPOSE64_HI);
+#endif
+  return Packet2cf(res0);
+}
+
 template<> EIGEN_DEVICE_FUNC inline Packet2cf pgather<std::complex<float>, Packet2cf>(const std::complex<float>* from, Index stride)
 {
   EIGEN_ALIGN16 std::complex<float> af[2];
   af[0] = from[0*stride];
   af[1] = from[1*stride];
   return pload<Packet2cf>(af);
 }
@@ -96,33 +162,14 @@
 }
 
 template<> EIGEN_STRONG_INLINE Packet2cf padd<Packet2cf>(const Packet2cf& a, const Packet2cf& b) { return Packet2cf(a.v + b.v); }
 template<> EIGEN_STRONG_INLINE Packet2cf psub<Packet2cf>(const Packet2cf& a, const Packet2cf& b) { return Packet2cf(a.v - b.v); }
 template<> EIGEN_STRONG_INLINE Packet2cf pnegate(const Packet2cf& a) { return Packet2cf(pnegate(a.v)); }
 template<> EIGEN_STRONG_INLINE Packet2cf pconj(const Packet2cf& a) { return Packet2cf(pxor<Packet4f>(a.v, reinterpret_cast<Packet4f>(p4ui_CONJ_XOR))); }
 
-template<> EIGEN_STRONG_INLINE Packet2cf pmul<Packet2cf>(const Packet2cf& a, const Packet2cf& b)
-{
-  Packet4f v1, v2;
-
-  // Permute and multiply the real parts of a and b
-  v1 = vec_perm(a.v, a.v, p16uc_PSET32_WODD);
-  // Get the imaginary parts of a
-  v2 = vec_perm(a.v, a.v, p16uc_PSET32_WEVEN);
-  // multiply a_re * b 
-  v1 = vec_madd(v1, b.v, p4f_ZERO);
-  // multiply a_im * b and get the conjugate result
-  v2 = vec_madd(v2, b.v, p4f_ZERO);
-  v2 = reinterpret_cast<Packet4f>(pxor(v2, reinterpret_cast<Packet4f>(p4ui_CONJ_XOR)));
-  // permute back to a proper order
-  v2 = vec_perm(v2, v2, p16uc_COMPLEX32_REV);
-  
-  return Packet2cf(padd<Packet4f>(v1, v2));
-}
-
 template<> EIGEN_STRONG_INLINE Packet2cf pand   <Packet2cf>(const Packet2cf& a, const Packet2cf& b) { return Packet2cf(pand<Packet4f>(a.v, b.v)); }
 template<> EIGEN_STRONG_INLINE Packet2cf por    <Packet2cf>(const Packet2cf& a, const Packet2cf& b) { return Packet2cf(por<Packet4f>(a.v, b.v)); }
 template<> EIGEN_STRONG_INLINE Packet2cf pxor   <Packet2cf>(const Packet2cf& a, const Packet2cf& b) { return Packet2cf(pxor<Packet4f>(a.v, b.v)); }
 template<> EIGEN_STRONG_INLINE Packet2cf pandnot<Packet2cf>(const Packet2cf& a, const Packet2cf& b) { return Packet2cf(pandnot<Packet4f>(a.v, b.v)); }
 
 template<> EIGEN_STRONG_INLINE void prefetch<std::complex<float> >(const std::complex<float> * addr)    { EIGEN_PPC_PREFETCH(addr); }
 
@@ -155,53 +202,20 @@
   Packet2cf prod;
   b = vec_sld(a.v, a.v, 8);
   prod = pmul<Packet2cf>(a, Packet2cf(b));
 
   return pfirst<Packet2cf>(prod);
 }
 
-template<> struct conj_helper<Packet2cf, Packet2cf, false,true>
-{
-  EIGEN_STRONG_INLINE Packet2cf pmadd(const Packet2cf& x, const Packet2cf& y, const Packet2cf& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet2cf pmul(const Packet2cf& a, const Packet2cf& b) const
-  {
-    return internal::pmul(a, pconj(b));
-  }
-};
-
-template<> struct conj_helper<Packet2cf, Packet2cf, true,false>
-{
-  EIGEN_STRONG_INLINE Packet2cf pmadd(const Packet2cf& x, const Packet2cf& y, const Packet2cf& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet2cf pmul(const Packet2cf& a, const Packet2cf& b) const
-  {
-    return internal::pmul(pconj(a), b);
-  }
-};
-
-template<> struct conj_helper<Packet2cf, Packet2cf, true,true>
-{
-  EIGEN_STRONG_INLINE Packet2cf pmadd(const Packet2cf& x, const Packet2cf& y, const Packet2cf& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet2cf pmul(const Packet2cf& a, const Packet2cf& b) const
-  {
-    return pconj(internal::pmul(a, b));
-  }
-};
-
 EIGEN_MAKE_CONJ_HELPER_CPLX_REAL(Packet2cf,Packet4f)
 
 template<> EIGEN_STRONG_INLINE Packet2cf pdiv<Packet2cf>(const Packet2cf& a, const Packet2cf& b)
 {
   // TODO optimize it for AltiVec
-  Packet2cf res = conj_helper<Packet2cf,Packet2cf,false,true>().pmul(a, b);
+  Packet2cf res = pmul(a, pconj(b));
   Packet4f s = pmul<Packet4f>(b.v, b.v);
   return Packet2cf(pdiv(res.v, padd<Packet4f>(s, vec_perm(s, s, p16uc_COMPLEX32_REV))));
 }
 
 template<> EIGEN_STRONG_INLINE Packet2cf pcplxflip<Packet2cf>(const Packet2cf& x)
 {
   return Packet2cf(vec_perm(x.v, x.v, p16uc_COMPLEX32_REV));
@@ -223,27 +237,78 @@
 template<> EIGEN_STRONG_INLINE Packet2cf pblend(const Selector<2>& ifPacket, const Packet2cf& thenPacket, const Packet2cf& elsePacket) {
   Packet2cf result;
   result.v = reinterpret_cast<Packet4f>(pblend<Packet2d>(ifPacket, reinterpret_cast<Packet2d>(thenPacket.v), reinterpret_cast<Packet2d>(elsePacket.v)));
   return result;
 }
 #endif
 
+template<> EIGEN_STRONG_INLINE Packet2cf psqrt<Packet2cf>(const Packet2cf& a)
+{
+  return psqrt_complex<Packet2cf>(a);
+}
+
 //---------- double ----------
 #ifdef __VSX__
 struct Packet1cd
 {
   EIGEN_STRONG_INLINE Packet1cd() {}
   EIGEN_STRONG_INLINE explicit Packet1cd(const Packet2d& a) : v(a) {}
+
+  EIGEN_STRONG_INLINE Packet1cd pmul(const Packet1cd& a, const Packet1cd& b)
+  {
+    Packet2d a_re, a_im, v1, v2;
+
+    // Permute and multiply the real parts of a and b
+    a_re = vec_perm(a.v, a.v, p16uc_PSET64_HI);
+    // Get the imaginary parts of a
+    a_im = vec_perm(a.v, a.v, p16uc_PSET64_LO);
+    // multiply a_re * b
+    v1 = vec_madd(a_re, b.v, p2d_ZERO);
+    // multiply a_im * b and get the conjugate result
+    v2 = vec_madd(a_im, b.v, p2d_ZERO);
+    v2 = reinterpret_cast<Packet2d>(vec_sld(reinterpret_cast<Packet4ui>(v2), reinterpret_cast<Packet4ui>(v2), 8));
+    v2 = pxor(v2, reinterpret_cast<Packet2d>(p2ul_CONJ_XOR1));
+
+    return Packet1cd(padd<Packet2d>(v1, v2));
+  }
+
+  EIGEN_STRONG_INLINE Packet1cd& operator*=(const Packet1cd& b) {
+    v = pmul(Packet1cd(*this), b).v;
+    return *this;
+  }
+  EIGEN_STRONG_INLINE Packet1cd operator*(const Packet1cd& b) const {
+    return Packet1cd(*this) *= b;
+  }
+
+  EIGEN_STRONG_INLINE Packet1cd& operator+=(const Packet1cd& b) {
+    v = padd(v, b.v);
+    return *this;
+  }
+  EIGEN_STRONG_INLINE Packet1cd operator+(const Packet1cd& b) const {
+    return Packet1cd(*this) += b;
+  }
+  EIGEN_STRONG_INLINE Packet1cd& operator-=(const Packet1cd& b) {
+    v = psub(v, b.v);
+    return *this;
+  }
+  EIGEN_STRONG_INLINE Packet1cd operator-(const Packet1cd& b) const {
+    return Packet1cd(*this) -= b;
+  }
+  EIGEN_STRONG_INLINE Packet1cd operator-(void) const {
+    return Packet1cd(-v);
+  }
+
   Packet2d v;
 };
 
 template<> struct packet_traits<std::complex<double> >  : default_packet_traits
 {
   typedef Packet1cd type;
   typedef Packet1cd half;
+  typedef Packet2d as_real;
   enum {
     Vectorizable = 1,
     AlignedOnScalar = 0,
     size = 1,
     HasHalfPacket = 0,
 
     HasAdd    = 1,
@@ -255,15 +320,15 @@
     HasAbs2   = 0,
     HasMin    = 0,
     HasMax    = 0,
     HasSetLinear = 0
   };
 };
 
-template<> struct unpacket_traits<Packet1cd> { typedef std::complex<double> type; enum {size=1, alignment=Aligned16, vectorizable=true, masked_load_available=false, masked_store_available=false}; typedef Packet1cd half; };
+template<> struct unpacket_traits<Packet1cd> { typedef std::complex<double> type; enum {size=1, alignment=Aligned16, vectorizable=true, masked_load_available=false, masked_store_available=false}; typedef Packet1cd half; typedef Packet2d as_real; };
 
 template<> EIGEN_STRONG_INLINE Packet1cd pload <Packet1cd>(const std::complex<double>* from) { return Packet1cd(pload<Packet2d>((const double*)from)); }
 template<> EIGEN_STRONG_INLINE Packet1cd ploadu<Packet1cd>(const std::complex<double>* from) { return Packet1cd(ploadu<Packet2d>((const double*)from)); }
 template<> EIGEN_STRONG_INLINE void pstore <std::complex<double> >(std::complex<double> *   to, const Packet1cd& from) { pstore((double*)to, from.v); }
 template<> EIGEN_STRONG_INLINE void pstoreu<std::complex<double> >(std::complex<double> *   to, const Packet1cd& from) { pstoreu((double*)to, from.v); }
 
 template<> EIGEN_STRONG_INLINE Packet1cd pset1<Packet1cd>(const std::complex<double>&  from)
@@ -279,32 +344,14 @@
 }
 
 template<> EIGEN_STRONG_INLINE Packet1cd padd<Packet1cd>(const Packet1cd& a, const Packet1cd& b) { return Packet1cd(a.v + b.v); }
 template<> EIGEN_STRONG_INLINE Packet1cd psub<Packet1cd>(const Packet1cd& a, const Packet1cd& b) { return Packet1cd(a.v - b.v); }
 template<> EIGEN_STRONG_INLINE Packet1cd pnegate(const Packet1cd& a) { return Packet1cd(pnegate(Packet2d(a.v))); }
 template<> EIGEN_STRONG_INLINE Packet1cd pconj(const Packet1cd& a) { return Packet1cd(pxor(a.v, reinterpret_cast<Packet2d>(p2ul_CONJ_XOR2))); }
 
-template<> EIGEN_STRONG_INLINE Packet1cd pmul<Packet1cd>(const Packet1cd& a, const Packet1cd& b)
-{
-  Packet2d a_re, a_im, v1, v2;
-
-  // Permute and multiply the real parts of a and b
-  a_re = vec_perm(a.v, a.v, p16uc_PSET64_HI);
-  // Get the imaginary parts of a
-  a_im = vec_perm(a.v, a.v, p16uc_PSET64_LO);
-  // multiply a_re * b
-  v1 = vec_madd(a_re, b.v, p2d_ZERO);
-  // multiply a_im * b and get the conjugate result
-  v2 = vec_madd(a_im, b.v, p2d_ZERO);
-  v2 = reinterpret_cast<Packet2d>(vec_sld(reinterpret_cast<Packet4ui>(v2), reinterpret_cast<Packet4ui>(v2), 8));
-  v2 = pxor(v2, reinterpret_cast<Packet2d>(p2ul_CONJ_XOR1));
-
-  return Packet1cd(padd<Packet2d>(v1, v2));
-}
-
 template<> EIGEN_STRONG_INLINE Packet1cd pand   <Packet1cd>(const Packet1cd& a, const Packet1cd& b) { return Packet1cd(pand(a.v,b.v)); }
 template<> EIGEN_STRONG_INLINE Packet1cd por    <Packet1cd>(const Packet1cd& a, const Packet1cd& b) { return Packet1cd(por(a.v,b.v)); }
 template<> EIGEN_STRONG_INLINE Packet1cd pxor   <Packet1cd>(const Packet1cd& a, const Packet1cd& b) { return Packet1cd(pxor(a.v,b.v)); }
 template<> EIGEN_STRONG_INLINE Packet1cd pandnot<Packet1cd>(const Packet1cd& a, const Packet1cd& b) { return Packet1cd(pandnot(a.v, b.v)); }
 
 template<> EIGEN_STRONG_INLINE Packet1cd ploaddup<Packet1cd>(const std::complex<double>*     from)  { return pset1<Packet1cd>(*from); }
 
@@ -320,53 +367,20 @@
 
 template<> EIGEN_STRONG_INLINE Packet1cd preverse(const Packet1cd& a) { return a; }
 
 template<> EIGEN_STRONG_INLINE std::complex<double> predux<Packet1cd>(const Packet1cd& a) { return pfirst(a); }
 
 template<> EIGEN_STRONG_INLINE std::complex<double> predux_mul<Packet1cd>(const Packet1cd& a) { return pfirst(a); }
 
-template<> struct conj_helper<Packet1cd, Packet1cd, false,true>
-{
-  EIGEN_STRONG_INLINE Packet1cd pmadd(const Packet1cd& x, const Packet1cd& y, const Packet1cd& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet1cd pmul(const Packet1cd& a, const Packet1cd& b) const
-  {
-    return internal::pmul(a, pconj(b));
-  }
-};
-
-template<> struct conj_helper<Packet1cd, Packet1cd, true,false>
-{
-  EIGEN_STRONG_INLINE Packet1cd pmadd(const Packet1cd& x, const Packet1cd& y, const Packet1cd& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet1cd pmul(const Packet1cd& a, const Packet1cd& b) const
-  {
-    return internal::pmul(pconj(a), b);
-  }
-};
-
-template<> struct conj_helper<Packet1cd, Packet1cd, true,true>
-{
-  EIGEN_STRONG_INLINE Packet1cd pmadd(const Packet1cd& x, const Packet1cd& y, const Packet1cd& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet1cd pmul(const Packet1cd& a, const Packet1cd& b) const
-  {
-    return pconj(internal::pmul(a, b));
-  }
-};
-
 EIGEN_MAKE_CONJ_HELPER_CPLX_REAL(Packet1cd,Packet2d)
 
 template<> EIGEN_STRONG_INLINE Packet1cd pdiv<Packet1cd>(const Packet1cd& a, const Packet1cd& b)
 {
   // TODO optimize it for AltiVec
-  Packet1cd res = conj_helper<Packet1cd,Packet1cd,false,true>().pmul(a,b);
+  Packet1cd res = pmul(a,pconj(b));
   Packet2d s = pmul<Packet2d>(b.v, b.v);
   return Packet1cd(pdiv(res.v, padd<Packet2d>(s, vec_perm(s, s, p16uc_REVERSE64))));
 }
 
 EIGEN_STRONG_INLINE Packet1cd pcplxflip/*<Packet1cd>*/(const Packet1cd& x)
 {
   return Packet1cd(preverse(Packet2d(x.v)));
@@ -386,13 +400,18 @@
   // Swap real/imag elements in the mask in to get:
   // [im(a)==im(b), re(a)==re(b)]
   Packet2d eq_swapped = reinterpret_cast<Packet2d>(vec_sld(reinterpret_cast<Packet4ui>(eq), reinterpret_cast<Packet4ui>(eq), 8));
   // Return re(a)==re(b) & im(a)==im(b) by computing bitwise AND of eq and eq_swapped
   return Packet1cd(vec_and(eq, eq_swapped));
 }
 
+template<> EIGEN_STRONG_INLINE Packet1cd psqrt<Packet1cd>(const Packet1cd& a)
+{
+  return psqrt_complex<Packet1cd>(a);
+}
+
 #endif // __VSX__
 } // end namespace internal
 
 } // end namespace Eigen
 
 #endif // EIGEN_COMPLEX32_ALTIVEC_H
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/AltiVec/MathFunctions.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/AltiVec/MathFunctions.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/AltiVec/PacketMath.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/AltiVec/PacketMath.h`

 * *Files 7% similar despite different names*

```diff
@@ -18,31 +18,27 @@
 #define EIGEN_CACHEFRIENDLY_PRODUCT_THRESHOLD 4
 #endif
 
 #ifndef EIGEN_HAS_SINGLE_INSTRUCTION_MADD
 #define EIGEN_HAS_SINGLE_INSTRUCTION_MADD
 #endif
 
-#ifndef EIGEN_HAS_SINGLE_INSTRUCTION_CJMADD
-#define EIGEN_HAS_SINGLE_INSTRUCTION_CJMADD
-#endif
-
 // NOTE Altivec has 32 registers, but Eigen only accepts a value of 8 or 16
 #ifndef EIGEN_ARCH_DEFAULT_NUMBER_OF_REGISTERS
 #define EIGEN_ARCH_DEFAULT_NUMBER_OF_REGISTERS  32
 #endif
 
 typedef __vector float                   Packet4f;
 typedef __vector int                     Packet4i;
 typedef __vector unsigned int            Packet4ui;
 typedef __vector __bool int              Packet4bi;
 typedef __vector short int               Packet8s;
 typedef __vector unsigned short int      Packet8us;
-typedef __vector int8_t                  Packet16c;
-typedef __vector uint8_t                 Packet16uc;
+typedef __vector signed char             Packet16c;
+typedef __vector unsigned char           Packet16uc;
 typedef eigen_packet_wrapper<__vector unsigned short int,0> Packet8bf;
 
 // We don't want to write the same code all the time, but we need to reuse the constants
 // and it doesn't really work to declare them global, so we define macros instead
 #define _EIGEN_DECLARE_CONST_FAST_Packet4f(NAME,X) \
   Packet4f p4f_##NAME = {X, X, X, X}
 
@@ -184,14 +180,15 @@
     HasRsqrt = 0,
     HasTanh = EIGEN_FAST_MATH,
     HasErf = EIGEN_FAST_MATH,
 #endif
     HasRound = 1,
     HasFloor = 1,
     HasCeil = 1,
+    HasRint = 1,
     HasNegate = 1,
     HasBlend = 1
   };
 };
 template <>
 struct packet_traits<bfloat16> : default_packet_traits {
   typedef Packet8bf type;
@@ -225,14 +222,15 @@
     HasRsqrt = 0,
     HasTanh = EIGEN_FAST_MATH,
     HasErf = EIGEN_FAST_MATH,
 #endif
     HasRound = 1,
     HasFloor = 1,
     HasCeil = 1,
+    HasRint = 1,
     HasNegate = 1,
     HasBlend = 1
   };
 };
 
 template <>
 struct packet_traits<int> : default_packet_traits {
@@ -286,15 +284,15 @@
     HasMul  = 1,
     HasDiv  = 0,
     HasBlend = 1
   };
 };
 
 template <>
-struct packet_traits<int8_t> : default_packet_traits {
+struct packet_traits<signed char> : default_packet_traits {
   typedef Packet16c type;
   typedef Packet16c half;
   enum {
     Vectorizable = 1,
     AlignedOnScalar = 1,
     size = 16,
     HasHalfPacket = 0,
@@ -304,15 +302,15 @@
     HasMul  = 1,
     HasDiv  = 0,
     HasBlend = 1
   };
 };
 
 template <>
-struct packet_traits<uint8_t> : default_packet_traits {
+struct packet_traits<unsigned char> : default_packet_traits {
   typedef Packet16uc type;
   typedef Packet16uc half;
   enum {
     Vectorizable = 1,
     AlignedOnScalar = 1,
     size = 16,
     HasHalfPacket = 0,
@@ -349,48 +347,48 @@
   typedef unsigned short int type;
   typedef Packet8us          half;
   enum {size=8, alignment=Aligned16, vectorizable=true, masked_load_available=false, masked_store_available=false};
 };
 
 template<> struct unpacket_traits<Packet16c>
 {
-  typedef int8_t type;
+  typedef signed char type;
   typedef Packet16c  half;
   enum {size=16, alignment=Aligned16, vectorizable=true, masked_load_available=false, masked_store_available=false};
 };
 template<> struct unpacket_traits<Packet16uc>
 {
-  typedef uint8_t type;
+  typedef unsigned char type;
   typedef Packet16uc  half;
   enum {size=16, alignment=Aligned16, vectorizable=true, masked_load_available=false, masked_store_available=false};
 };
 
 template<> struct unpacket_traits<Packet8bf>
 {
   typedef bfloat16 type;
   typedef Packet8bf          half;
   enum {size=8, alignment=Aligned16, vectorizable=true, masked_load_available=false, masked_store_available=false};
 };
 inline std::ostream & operator <<(std::ostream & s, const Packet16c & v)
 {
   union {
     Packet16c   v;
-    int8_t n[16];
+    signed char n[16];
   } vt;
   vt.v = v;
   for (int i=0; i< 16; i++)
     s << vt.n[i] << ", ";
   return s;
 }
 
 inline std::ostream & operator <<(std::ostream & s, const Packet16uc & v)
 {
   union {
     Packet16uc   v;
-    uint8_t n[16];
+    unsigned char n[16];
   } vt;
   vt.v = v;
   for (int i=0; i< 16; i++)
     s << vt.n[i] << ", ";
   return s;
 }
 
@@ -431,15 +429,15 @@
 EIGEN_STRONG_INLINE Packet pload_common(const __UNPACK_TYPE__(Packet)* from)
 {
   // some versions of GCC throw "unused-but-set-parameter".
   // ignoring these warnings for now.
   EIGEN_UNUSED_VARIABLE(from);
   EIGEN_DEBUG_ALIGNED_LOAD
 #ifdef __VSX__
-  return vec_xl(0, from);
+  return vec_xl(0, const_cast<__UNPACK_TYPE__(Packet)*>(from));
 #else
   return vec_ld(0, from);
 #endif
 }
 
 // Need to define them first or we get specialization after instantiation errors
 template<> EIGEN_STRONG_INLINE Packet4f pload<Packet4f>(const float* from)
@@ -458,20 +456,20 @@
 }
 
 template<> EIGEN_STRONG_INLINE Packet8us pload<Packet8us>(const unsigned short int* from)
 {
   return pload_common<Packet8us>(from);
 }
 
-template<> EIGEN_STRONG_INLINE Packet16c pload<Packet16c>(const int8_t*     from)
+template<> EIGEN_STRONG_INLINE Packet16c pload<Packet16c>(const signed char*     from)
 {
   return pload_common<Packet16c>(from);
 }
 
-template<> EIGEN_STRONG_INLINE Packet16uc pload<Packet16uc>(const uint8_t*     from)
+template<> EIGEN_STRONG_INLINE Packet16uc pload<Packet16uc>(const unsigned char*     from)
 {
   return pload_common<Packet16uc>(from);
 }
 
 template<> EIGEN_STRONG_INLINE Packet8bf pload<Packet8bf>(const bfloat16*     from)
 {
   return pload_common<Packet8us>(reinterpret_cast<const unsigned short int*>(from));
@@ -511,20 +509,20 @@
 }
 
 template<> EIGEN_STRONG_INLINE void pstore<bfloat16>(bfloat16*       to, const Packet8bf& from)
 {
   pstore_common<Packet8us>(reinterpret_cast<unsigned short int*>(to), from);
 }
 
-template<> EIGEN_STRONG_INLINE void pstore<int8_t>(int8_t*       to, const Packet16c& from)
+template<> EIGEN_STRONG_INLINE void pstore<signed char>(signed char*       to, const Packet16c& from)
 {
   pstore_common<Packet16c>(to, from);
 }
 
-template<> EIGEN_STRONG_INLINE void pstore<uint8_t>(uint8_t*       to, const Packet16uc& from)
+template<> EIGEN_STRONG_INLINE void pstore<unsigned char>(unsigned char*       to, const Packet16uc& from)
 {
   pstore_common<Packet16uc>(to, from);
 }
 
 template<typename Packet>
 EIGEN_STRONG_INLINE Packet pset1_size4(const __UNPACK_TYPE__(Packet)& from)
 {
@@ -558,19 +556,19 @@
   return pset1_size8<Packet8s>(from);
 }
 
 template<> EIGEN_STRONG_INLINE Packet8us pset1<Packet8us>(const unsigned short int&    from)   {
   return pset1_size8<Packet8us>(from);
 }
 
-template<> EIGEN_STRONG_INLINE Packet16c pset1<Packet16c>(const int8_t&    from)   {
+template<> EIGEN_STRONG_INLINE Packet16c pset1<Packet16c>(const signed char&    from)   {
   return pset1_size16<Packet16c>(from);
 }
 
-template<> EIGEN_STRONG_INLINE Packet16uc pset1<Packet16uc>(const uint8_t&    from)   {
+template<> EIGEN_STRONG_INLINE Packet16uc pset1<Packet16uc>(const unsigned char&    from)   {
   return pset1_size16<Packet16uc>(from);
 }
 
 template<> EIGEN_STRONG_INLINE Packet4f pset1frombits<Packet4f>(unsigned int from) {
   return reinterpret_cast<Packet4f>(pset1<Packet4i>(from));
 }
 
@@ -642,14 +640,19 @@
 }
 
 template<> EIGEN_DEVICE_FUNC inline Packet8us pgather<unsigned short int, Packet8us>(const unsigned short int* from, Index stride)
 {
   return pgather_size8<Packet8us>(from, stride);
 }
 
+template<> EIGEN_DEVICE_FUNC inline Packet8bf pgather<bfloat16, Packet8bf>(const bfloat16* from, Index stride)
+{
+  return pgather_size8<Packet8bf>(from, stride);
+}
+
 template<typename Packet> EIGEN_DEVICE_FUNC inline Packet pgather_size16(const __UNPACK_TYPE__(Packet)* from, Index stride)
 {
   EIGEN_ALIGN16 __UNPACK_TYPE__(Packet) a[16];
   a[0] = from[0*stride];
   a[1] = from[1*stride];
   a[2] = from[2*stride];
   a[3] = from[3*stride];
@@ -665,20 +668,20 @@
   a[13] = from[13*stride];
   a[14] = from[14*stride];
   a[15] = from[15*stride];
   return pload<Packet>(a);
 }
 
 
-template<> EIGEN_DEVICE_FUNC inline Packet16c pgather<int8_t, Packet16c>(const int8_t* from, Index stride)
+template<> EIGEN_DEVICE_FUNC inline Packet16c pgather<signed char, Packet16c>(const signed char* from, Index stride)
 {
   return pgather_size16<Packet16c>(from, stride);
 }
 
-template<> EIGEN_DEVICE_FUNC inline Packet16uc pgather<uint8_t, Packet16uc>(const uint8_t* from, Index stride)
+template<> EIGEN_DEVICE_FUNC inline Packet16uc pgather<unsigned char, Packet16uc>(const unsigned char* from, Index stride)
 {
   return pgather_size16<Packet16uc>(from, stride);
 }
 
 template<typename Packet> EIGEN_DEVICE_FUNC inline void pscatter_size4(__UNPACK_TYPE__(Packet)* to, const Packet& from, Index stride)
 {
   EIGEN_ALIGN16 __UNPACK_TYPE__(Packet) a[4];
@@ -720,14 +723,19 @@
 }
 
 template<> EIGEN_DEVICE_FUNC inline void pscatter<unsigned short int, Packet8us>(unsigned short int* to, const Packet8us& from, Index stride)
 {
   pscatter_size8<Packet8us>(to, from, stride);
 }
 
+template<> EIGEN_DEVICE_FUNC inline void pscatter<bfloat16, Packet8bf>(bfloat16* to, const Packet8bf& from, Index stride)
+{
+  pscatter_size8<Packet8bf>(to, from, stride);
+}
+
 template<typename Packet> EIGEN_DEVICE_FUNC inline void pscatter_size16(__UNPACK_TYPE__(Packet)* to, const Packet& from, Index stride)
 {
   EIGEN_ALIGN16 __UNPACK_TYPE__(Packet) a[16];
   pstore<__UNPACK_TYPE__(Packet)>(a, from);
   to[0*stride] = a[0];
   to[1*stride] = a[1];
   to[2*stride] = a[2];
@@ -742,52 +750,56 @@
   to[11*stride] = a[11];
   to[12*stride] = a[12];
   to[13*stride] = a[13];
   to[14*stride] = a[14];
   to[15*stride] = a[15];
 }
 
-template<> EIGEN_DEVICE_FUNC inline void pscatter<int8_t, Packet16c>(int8_t* to, const Packet16c& from, Index stride)
+template<> EIGEN_DEVICE_FUNC inline void pscatter<signed char, Packet16c>(signed char* to, const Packet16c& from, Index stride)
 {
   pscatter_size16<Packet16c>(to, from, stride);
 }
 
-template<> EIGEN_DEVICE_FUNC inline void pscatter<uint8_t, Packet16uc>(uint8_t* to, const Packet16uc& from, Index stride)
+template<> EIGEN_DEVICE_FUNC inline void pscatter<unsigned char, Packet16uc>(unsigned char* to, const Packet16uc& from, Index stride)
 {
   pscatter_size16<Packet16uc>(to, from, stride);
 }
 
 template<> EIGEN_STRONG_INLINE Packet4f   plset<Packet4f>(const float&     a) { return pset1<Packet4f>(a) + p4f_COUNTDOWN;  }
 template<> EIGEN_STRONG_INLINE Packet4i   plset<Packet4i>(const int&       a) { return pset1<Packet4i>(a) + p4i_COUNTDOWN;  }
 template<> EIGEN_STRONG_INLINE Packet8s   plset<Packet8s>(const short int& a) { return pset1<Packet8s>(a) + p8s_COUNTDOWN; }
 template<> EIGEN_STRONG_INLINE Packet8us  plset<Packet8us>(const unsigned short int& a) { return pset1<Packet8us>(a) + p8us_COUNTDOWN; }
-template<> EIGEN_STRONG_INLINE Packet16c  plset<Packet16c>(const int8_t& a)   { return pset1<Packet16c>(a) + p16c_COUNTDOWN; }
-template<> EIGEN_STRONG_INLINE Packet16uc plset<Packet16uc>(const uint8_t& a)   { return pset1<Packet16uc>(a) + p16uc_COUNTDOWN; }
+template<> EIGEN_STRONG_INLINE Packet16c  plset<Packet16c>(const signed char& a)   { return pset1<Packet16c>(a) + p16c_COUNTDOWN; }
+template<> EIGEN_STRONG_INLINE Packet16uc plset<Packet16uc>(const unsigned char& a)   { return pset1<Packet16uc>(a) + p16uc_COUNTDOWN; }
 
 template<> EIGEN_STRONG_INLINE Packet4f   padd<Packet4f>  (const Packet4f&   a, const Packet4f&   b) { return a + b; }
 template<> EIGEN_STRONG_INLINE Packet4i   padd<Packet4i>  (const Packet4i&   a, const Packet4i&   b) { return a + b; }
 template<> EIGEN_STRONG_INLINE Packet4ui   padd<Packet4ui>  (const Packet4ui&   a, const Packet4ui&   b) { return a + b; }
 template<> EIGEN_STRONG_INLINE Packet8s   padd<Packet8s>  (const Packet8s&   a, const Packet8s&   b) { return a + b; }
 template<> EIGEN_STRONG_INLINE Packet8us  padd<Packet8us> (const Packet8us&  a, const Packet8us&  b) { return a + b; }
 template<> EIGEN_STRONG_INLINE Packet16c  padd<Packet16c> (const Packet16c&  a, const Packet16c&  b) { return a + b; }
 template<> EIGEN_STRONG_INLINE Packet16uc padd<Packet16uc>(const Packet16uc& a, const Packet16uc& b) { return a + b; }
 
 template<> EIGEN_STRONG_INLINE Packet4f   psub<Packet4f>  (const Packet4f&   a, const Packet4f&   b) { return a - b; }
 template<> EIGEN_STRONG_INLINE Packet4i   psub<Packet4i>  (const Packet4i&   a, const Packet4i&   b) { return a - b; }
+template<> EIGEN_STRONG_INLINE Packet8s   psub<Packet8s>  (const Packet8s&   a, const Packet8s&   b) { return a - b; }
+template<> EIGEN_STRONG_INLINE Packet8us  psub<Packet8us> (const Packet8us&  a, const Packet8us&  b) { return a - b; }
 template<> EIGEN_STRONG_INLINE Packet16c  psub<Packet16c> (const Packet16c&  a, const Packet16c&  b) { return a - b; }
 template<> EIGEN_STRONG_INLINE Packet16uc psub<Packet16uc>(const Packet16uc& a, const Packet16uc& b) { return a - b; }
 
 template<> EIGEN_STRONG_INLINE Packet4f pnegate(const Packet4f& a) { return p4f_ZERO - a; }
 template<> EIGEN_STRONG_INLINE Packet4i pnegate(const Packet4i& a) { return p4i_ZERO - a; }
 
 template<> EIGEN_STRONG_INLINE Packet4f pconj(const Packet4f& a) { return a; }
 template<> EIGEN_STRONG_INLINE Packet4i pconj(const Packet4i& a) { return a; }
 
 template<> EIGEN_STRONG_INLINE Packet4f   pmul<Packet4f>  (const Packet4f&   a, const Packet4f&   b) { return vec_madd(a,b, p4f_MZERO); }
 template<> EIGEN_STRONG_INLINE Packet4i   pmul<Packet4i>  (const Packet4i&   a, const Packet4i&   b) { return a * b; }
+template<> EIGEN_STRONG_INLINE Packet8s   pmul<Packet8s>  (const Packet8s&   a, const Packet8s&   b) { return vec_mul(a,b); }
+template<> EIGEN_STRONG_INLINE Packet8us  pmul<Packet8us> (const Packet8us&  a, const Packet8us&  b) { return vec_mul(a,b); }
 template<> EIGEN_STRONG_INLINE Packet16c  pmul<Packet16c> (const Packet16c&  a, const Packet16c&  b) { return vec_mul(a,b); }
 template<> EIGEN_STRONG_INLINE Packet16uc pmul<Packet16uc>(const Packet16uc& a, const Packet16uc& b) { return vec_mul(a,b); }
 
 
 template<> EIGEN_STRONG_INLINE Packet4f pdiv<Packet4f>(const Packet4f& a, const Packet4f& b)
 {
 #ifndef __VSX__  // VSX actually provides a div instruction
@@ -810,14 +822,16 @@
 { eigen_assert(false && "packet integer division are not supported by AltiVec");
   return pset1<Packet4i>(0);
 }
 
 // for some weird raisons, it has to be overloaded for packet of integers
 template<> EIGEN_STRONG_INLINE Packet4f pmadd(const Packet4f& a, const Packet4f& b, const Packet4f& c) { return vec_madd(a,b,c); }
 template<> EIGEN_STRONG_INLINE Packet4i pmadd(const Packet4i& a, const Packet4i& b, const Packet4i& c) { return a*b + c; }
+template<> EIGEN_STRONG_INLINE Packet8s pmadd(const Packet8s& a, const Packet8s& b, const Packet8s& c) { return vec_madd(a,b,c); }
+template<> EIGEN_STRONG_INLINE Packet8us pmadd(const Packet8us& a, const Packet8us& b, const Packet8us& c) { return vec_madd(a,b,c); }
 
 template<> EIGEN_STRONG_INLINE Packet4f pmin<Packet4f>(const Packet4f& a, const Packet4f& b)
 {
   #ifdef __VSX__
   // NOTE: about 10% slower than vec_min, but consistent with std::min and SSE regarding NaN
   Packet4f ret;
   __asm__ ("xvcmpgesp %x0,%x1,%x2\n\txxsel %x0,%x1,%x2,%x0" : "=&wa" (ret) : "wa" (a), "wa" (b));
@@ -849,20 +863,34 @@
 template<> EIGEN_STRONG_INLINE Packet8us pmax<Packet8us>(const Packet8us& a, const Packet8us& b) { return vec_max(a, b); }
 template<> EIGEN_STRONG_INLINE Packet16c pmax<Packet16c>(const Packet16c& a, const Packet16c& b) { return vec_max(a, b); }
 template<> EIGEN_STRONG_INLINE Packet16uc pmax<Packet16uc>(const Packet16uc& a, const Packet16uc& b) { return vec_max(a, b); }
 
 template<> EIGEN_STRONG_INLINE Packet4f pcmp_le(const Packet4f& a, const Packet4f& b) { return reinterpret_cast<Packet4f>(vec_cmple(a,b)); }
 template<> EIGEN_STRONG_INLINE Packet4f pcmp_lt(const Packet4f& a, const Packet4f& b) { return reinterpret_cast<Packet4f>(vec_cmplt(a,b)); }
 template<> EIGEN_STRONG_INLINE Packet4f pcmp_eq(const Packet4f& a, const Packet4f& b) { return reinterpret_cast<Packet4f>(vec_cmpeq(a,b)); }
-
 template<> EIGEN_STRONG_INLINE Packet4f pcmp_lt_or_nan(const Packet4f& a, const Packet4f& b) {
   Packet4f c = reinterpret_cast<Packet4f>(vec_cmpge(a,b));
   return vec_nor(c,c);
 }
+
+template<> EIGEN_STRONG_INLINE Packet4i pcmp_le(const Packet4i& a, const Packet4i& b) { return reinterpret_cast<Packet4i>(vec_cmple(a,b)); }
+template<> EIGEN_STRONG_INLINE Packet4i pcmp_lt(const Packet4i& a, const Packet4i& b) { return reinterpret_cast<Packet4i>(vec_cmplt(a,b)); }
 template<> EIGEN_STRONG_INLINE Packet4i pcmp_eq(const Packet4i& a, const Packet4i& b) { return reinterpret_cast<Packet4i>(vec_cmpeq(a,b)); }
+template<> EIGEN_STRONG_INLINE Packet8s pcmp_le(const Packet8s& a, const Packet8s& b) { return reinterpret_cast<Packet8s>(vec_cmple(a,b)); }
+template<> EIGEN_STRONG_INLINE Packet8s pcmp_lt(const Packet8s& a, const Packet8s& b) { return reinterpret_cast<Packet8s>(vec_cmplt(a,b)); }
+template<> EIGEN_STRONG_INLINE Packet8s pcmp_eq(const Packet8s& a, const Packet8s& b) { return reinterpret_cast<Packet8s>(vec_cmpeq(a,b)); }
+template<> EIGEN_STRONG_INLINE Packet8us pcmp_le(const Packet8us& a, const Packet8us& b) { return reinterpret_cast<Packet8us>(vec_cmple(a,b)); }
+template<> EIGEN_STRONG_INLINE Packet8us pcmp_lt(const Packet8us& a, const Packet8us& b) { return reinterpret_cast<Packet8us>(vec_cmplt(a,b)); }
+template<> EIGEN_STRONG_INLINE Packet8us pcmp_eq(const Packet8us& a, const Packet8us& b) { return reinterpret_cast<Packet8us>(vec_cmpeq(a,b)); }
+template<> EIGEN_STRONG_INLINE Packet16c pcmp_le(const Packet16c& a, const Packet16c& b) { return reinterpret_cast<Packet16c>(vec_cmple(a,b)); }
+template<> EIGEN_STRONG_INLINE Packet16c pcmp_lt(const Packet16c& a, const Packet16c& b) { return reinterpret_cast<Packet16c>(vec_cmplt(a,b)); }
+template<> EIGEN_STRONG_INLINE Packet16c pcmp_eq(const Packet16c& a, const Packet16c& b) { return reinterpret_cast<Packet16c>(vec_cmpeq(a,b)); }
+template<> EIGEN_STRONG_INLINE Packet16uc pcmp_le(const Packet16uc& a, const Packet16uc& b) { return reinterpret_cast<Packet16uc>(vec_cmple(a,b)); }
+template<> EIGEN_STRONG_INLINE Packet16uc pcmp_lt(const Packet16uc& a, const Packet16uc& b) { return reinterpret_cast<Packet16uc>(vec_cmplt(a,b)); }
+template<> EIGEN_STRONG_INLINE Packet16uc pcmp_eq(const Packet16uc& a, const Packet16uc& b) { return reinterpret_cast<Packet16uc>(vec_cmpeq(a,b)); }
 
 template<> EIGEN_STRONG_INLINE Packet4f pand<Packet4f>(const Packet4f& a, const Packet4f& b) { return vec_and(a, b); }
 template<> EIGEN_STRONG_INLINE Packet4i pand<Packet4i>(const Packet4i& a, const Packet4i& b) { return vec_and(a, b); }
 template<> EIGEN_STRONG_INLINE Packet4ui pand<Packet4ui>(const Packet4ui& a, const Packet4ui& b) { return vec_and(a, b); }
 template<> EIGEN_STRONG_INLINE Packet8us pand<Packet8us>(const Packet8us& a, const Packet8us& b) { return vec_and(a, b); }
 template<> EIGEN_STRONG_INLINE Packet8bf pand<Packet8bf>(const Packet8bf& a, const Packet8bf& b) {
   return pand<Packet8us>(a, b);
@@ -879,48 +907,65 @@
 
 template<> EIGEN_STRONG_INLINE Packet4f pxor<Packet4f>(const Packet4f& a, const Packet4f& b) { return vec_xor(a, b); }
 template<> EIGEN_STRONG_INLINE Packet4i pxor<Packet4i>(const Packet4i& a, const Packet4i& b) { return vec_xor(a, b); }
 template<> EIGEN_STRONG_INLINE Packet8bf pxor<Packet8bf>(const Packet8bf& a, const Packet8bf& b) { 
   return pxor<Packet8us>(a, b);
 }
 
-template<> EIGEN_STRONG_INLINE Packet4f pandnot<Packet4f>(const Packet4f& a, const Packet4f& b) { return vec_and(a, vec_nor(b, b)); }
-template<> EIGEN_STRONG_INLINE Packet4i pandnot<Packet4i>(const Packet4i& a, const Packet4i& b) { return vec_and(a, vec_nor(b, b)); }
+template<> EIGEN_STRONG_INLINE Packet4f pandnot<Packet4f>(const Packet4f& a, const Packet4f& b) { return vec_andc(a, b); }
+template<> EIGEN_STRONG_INLINE Packet4i pandnot<Packet4i>(const Packet4i& a, const Packet4i& b) { return vec_andc(a, b); }
 
 template<> EIGEN_STRONG_INLINE Packet4f pselect(const Packet4f& mask, const Packet4f& a, const Packet4f& b) {
   return vec_sel(b, a, reinterpret_cast<Packet4ui>(mask));
 }
 
-template<> EIGEN_STRONG_INLINE Packet4f pround<Packet4f>(const Packet4f& a) {
+template<> EIGEN_STRONG_INLINE Packet4f pround<Packet4f>(const Packet4f& a)
+{
     Packet4f t = vec_add(reinterpret_cast<Packet4f>(vec_or(vec_and(reinterpret_cast<Packet4ui>(a), p4ui_SIGN), p4ui_PREV0DOT5)), a);
     Packet4f res;
 
+#ifdef __VSX__
+    __asm__("xvrspiz %x0, %x1\n\t"
+        : "=&wa" (res)
+        : "wa" (t));
+#else
     __asm__("vrfiz %0, %1\n\t"
         : "=v" (res)
         : "v" (t));
+#endif
 
     return res;
 }
 template<> EIGEN_STRONG_INLINE Packet4f pceil<Packet4f>(const  Packet4f& a) { return vec_ceil(a); }
 template<> EIGEN_STRONG_INLINE Packet4f pfloor<Packet4f>(const Packet4f& a) { return vec_floor(a); }
+template<> EIGEN_STRONG_INLINE Packet4f print<Packet4f>(const Packet4f& a)
+{
+    Packet4f res;
+
+    __asm__("xvrspic %x0, %x1\n\t"
+        : "=&wa" (res)
+        : "wa" (a));
+
+    return res;
+}
 
 template<typename Packet> EIGEN_STRONG_INLINE Packet ploadu_common(const __UNPACK_TYPE__(Packet)* from)
 {
   EIGEN_DEBUG_ALIGNED_LOAD
 #ifdef _BIG_ENDIAN
   Packet16uc MSQ, LSQ;
   Packet16uc mask;
   MSQ = vec_ld(0, (unsigned char *)from);          // most significant quadword
   LSQ = vec_ld(15, (unsigned char *)from);         // least significant quadword
   mask = vec_lvsl(0, from);                        // create the permute mask
   //TODO: Add static_cast here
   return (Packet) vec_perm(MSQ, LSQ, mask);           // align the data
 #else
   EIGEN_DEBUG_UNALIGNED_LOAD
-  return vec_xl(0, from);
+  return vec_xl(0, const_cast<__UNPACK_TYPE__(Packet)*>(from));
 #endif
 }
 
 template<> EIGEN_STRONG_INLINE Packet4f ploadu<Packet4f>(const float* from)
 {
   return ploadu_common<Packet4f>(from);
 }
@@ -936,19 +981,19 @@
 {
   return ploadu_common<Packet8us>(from);
 }
 template<> EIGEN_STRONG_INLINE Packet8bf ploadu<Packet8bf>(const bfloat16* from)
 {
   return ploadu_common<Packet8us>(reinterpret_cast<const unsigned short int*>(from));
 }
-template<> EIGEN_STRONG_INLINE Packet16c ploadu<Packet16c>(const int8_t* from)
+template<> EIGEN_STRONG_INLINE Packet16c ploadu<Packet16c>(const signed char* from)
 {
   return ploadu_common<Packet16c>(from);
 }
-template<> EIGEN_STRONG_INLINE Packet16uc ploadu<Packet16uc>(const uint8_t* from)
+template<> EIGEN_STRONG_INLINE Packet16uc ploadu<Packet16uc>(const unsigned char* from)
 {
   return ploadu_common<Packet16uc>(from);
 }
 
 template<typename Packet> EIGEN_STRONG_INLINE Packet ploaddup_common(const __UNPACK_TYPE__(Packet)*   from)
 {
   Packet p;
@@ -998,23 +1043,23 @@
 }
 
 template<> EIGEN_STRONG_INLINE Packet8bf ploadquad<Packet8bf>(const bfloat16*     from)
 {
   return ploadquad<Packet8us>(reinterpret_cast<const unsigned short int*>(from));
 }
 
-template<> EIGEN_STRONG_INLINE Packet16c ploaddup<Packet16c>(const int8_t*     from)
+template<> EIGEN_STRONG_INLINE Packet16c ploaddup<Packet16c>(const signed char*     from)
 {
   Packet16c p;
   if((std::ptrdiff_t(from) % 16) == 0)  p = pload<Packet16c>(from);
   else                                  p = ploadu<Packet16c>(from);
   return vec_perm(p, p, p16uc_DUPLICATE8_HI);
 }
 
-template<> EIGEN_STRONG_INLINE Packet16uc ploaddup<Packet16uc>(const uint8_t*     from)
+template<> EIGEN_STRONG_INLINE Packet16uc ploaddup<Packet16uc>(const unsigned char*     from)
 {
   Packet16uc p;
   if((std::ptrdiff_t(from) % 16) == 0)  p = pload<Packet16uc>(from);
   else                                  p = ploadu<Packet16uc>(from);
   return vec_perm(p, p, p16uc_DUPLICATE8_HI);
 }
 
@@ -1031,14 +1076,15 @@
   LSQ = vec_ld(15, (unsigned char *)to);                    // least significant quadword
   edgeAlign = vec_lvsl(0, to);                              // permute map to extract edges
   edges=vec_perm(LSQ,MSQ,edgeAlign);                        // extract the edges
   align = vec_lvsr( 0, to );                                // permute map to misalign data
   MSQ = vec_perm(edges,(Packet16uc)from,align);             // misalign the data (MSQ)
   LSQ = vec_perm((Packet16uc)from,edges,align);             // misalign the data (LSQ)
   vec_st( LSQ, 15, (unsigned char *)to );                   // Store the LSQ part first
+  vec_st( MSQ, 0, (unsigned char *)to );                   // Store the MSQ part second
 #else
   vec_xst(from, 0, to);
 #endif
 }
 template<> EIGEN_STRONG_INLINE void pstoreu<float>(float*  to, const Packet4f& from)
 {
   pstoreu_common<Packet4f>(to, from);
@@ -1055,19 +1101,19 @@
 {
   pstoreu_common<Packet8us>(to, from);
 }
 template<> EIGEN_STRONG_INLINE void pstoreu<bfloat16>(bfloat16*      to, const Packet8bf& from)
 {
   pstoreu_common<Packet8us>(reinterpret_cast<unsigned short int*>(to), from);
 }
-template<> EIGEN_STRONG_INLINE void pstoreu<int8_t>(int8_t*      to, const Packet16c& from)
+template<> EIGEN_STRONG_INLINE void pstoreu<signed char>(signed char*      to, const Packet16c& from)
 {
   pstoreu_common<Packet16c>(to, from);
 }
-template<> EIGEN_STRONG_INLINE void pstoreu<uint8_t>(uint8_t*      to, const Packet16uc& from)
+template<> EIGEN_STRONG_INLINE void pstoreu<unsigned char>(unsigned char*      to, const Packet16uc& from)
 {
   pstoreu_common<Packet16uc>(to, from);
 }
 
 template<> EIGEN_STRONG_INLINE void prefetch<float>(const float* addr)    { EIGEN_PPC_PREFETCH(addr); }
 template<> EIGEN_STRONG_INLINE void prefetch<int>(const int*     addr)    { EIGEN_PPC_PREFETCH(addr); }
 
@@ -1084,20 +1130,20 @@
   return pfirst_common<Packet8s>(a);
 }
 
 template<> EIGEN_STRONG_INLINE unsigned short int pfirst<Packet8us>(const Packet8us& a) {
   return pfirst_common<Packet8us>(a);
 }
 
-template<> EIGEN_STRONG_INLINE int8_t pfirst<Packet16c>(const Packet16c& a)
+template<> EIGEN_STRONG_INLINE signed char pfirst<Packet16c>(const Packet16c& a)
 {
   return pfirst_common<Packet16c>(a);
 }
 
-template<> EIGEN_STRONG_INLINE uint8_t pfirst<Packet16uc>(const Packet16uc& a)
+template<> EIGEN_STRONG_INLINE unsigned char pfirst<Packet16uc>(const Packet16uc& a)
 {
   return pfirst_common<Packet16uc>(a);
 }
 
 template<> EIGEN_STRONG_INLINE Packet4f preverse(const Packet4f& a)
 {
   return reinterpret_cast<Packet4f>(vec_perm(reinterpret_cast<Packet16uc>(a), reinterpret_cast<Packet16uc>(a), p16uc_REVERSE32));
@@ -1134,64 +1180,79 @@
 template<> EIGEN_STRONG_INLINE Packet16c pabs(const Packet16c& a) { return vec_abs(a); }
 template<> EIGEN_STRONG_INLINE Packet16uc pabs(const Packet16uc& a) { return a; }
 template<> EIGEN_STRONG_INLINE Packet8bf  pabs(const Packet8bf& a) {
   _EIGEN_DECLARE_CONST_FAST_Packet8us(abs_mask,0x7FFF);
   return pand<Packet8us>(p8us_abs_mask, a);
 }
 
-template<int N> EIGEN_STRONG_INLINE Packet4i parithmetic_shift_right(Packet4i a)
+template<int N> EIGEN_STRONG_INLINE Packet4i parithmetic_shift_right(const Packet4i& a)
 { return vec_sra(a,reinterpret_cast<Packet4ui>(pset1<Packet4i>(N))); }
-template<int N> EIGEN_STRONG_INLINE Packet4i plogical_shift_right(Packet4i a)
+template<int N> EIGEN_STRONG_INLINE Packet4i plogical_shift_right(const Packet4i& a)
 { return vec_sr(a,reinterpret_cast<Packet4ui>(pset1<Packet4i>(N))); }
-template<int N> EIGEN_STRONG_INLINE Packet4i plogical_shift_left(Packet4i a)
+template<int N> EIGEN_STRONG_INLINE Packet4i plogical_shift_left(const Packet4i& a)
 { return vec_sl(a,reinterpret_cast<Packet4ui>(pset1<Packet4i>(N))); }
-template<int N> EIGEN_STRONG_INLINE Packet4f plogical_shift_left(Packet4f a)
+template<int N> EIGEN_STRONG_INLINE Packet4f plogical_shift_left(const Packet4f& a)
 {
   const _EIGEN_DECLARE_CONST_FAST_Packet4ui(mask, N);
   Packet4ui r = vec_sl(reinterpret_cast<Packet4ui>(a), p4ui_mask);
   return reinterpret_cast<Packet4f>(r);
 }
 
-template<int N> EIGEN_STRONG_INLINE Packet4f plogical_shift_right(Packet4f a)
+template<int N> EIGEN_STRONG_INLINE Packet4f plogical_shift_right(const Packet4f& a)
 {
   const _EIGEN_DECLARE_CONST_FAST_Packet4ui(mask, N);
   Packet4ui r = vec_sr(reinterpret_cast<Packet4ui>(a), p4ui_mask);
   return reinterpret_cast<Packet4f>(r);
 }
 
-template<int N> EIGEN_STRONG_INLINE Packet4ui plogical_shift_right(Packet4ui a)
+template<int N> EIGEN_STRONG_INLINE Packet4ui plogical_shift_right(const Packet4ui& a)
 {
   const _EIGEN_DECLARE_CONST_FAST_Packet4ui(mask, N);
   return vec_sr(a, p4ui_mask);
 }
 
-template<int N> EIGEN_STRONG_INLINE Packet4ui plogical_shift_left(Packet4ui a)
+template<int N> EIGEN_STRONG_INLINE Packet4ui plogical_shift_left(const Packet4ui& a)
 {
   const _EIGEN_DECLARE_CONST_FAST_Packet4ui(mask, N);
   return vec_sl(a, p4ui_mask);
 }
 
-template<int N> EIGEN_STRONG_INLINE Packet8us plogical_shift_left(Packet8us a)
+template<int N> EIGEN_STRONG_INLINE Packet8us plogical_shift_left(const Packet8us& a)
 {
   const _EIGEN_DECLARE_CONST_FAST_Packet8us(mask, N);
   return vec_sl(a, p8us_mask);
 }
+template<int N> EIGEN_STRONG_INLINE Packet8us plogical_shift_right(const Packet8us& a)
+{
+  const _EIGEN_DECLARE_CONST_FAST_Packet8us(mask, N);
+  return vec_sr(a, p8us_mask);
+}
 
 EIGEN_STRONG_INLINE Packet4f Bf16ToF32Even(const Packet8bf& bf){
   return plogical_shift_left<16>(reinterpret_cast<Packet4f>(bf.m_val));
 }
 
 EIGEN_STRONG_INLINE Packet4f Bf16ToF32Odd(const Packet8bf& bf){
   const _EIGEN_DECLARE_CONST_FAST_Packet4ui(high_mask, 0xFFFF0000);
   return pand<Packet4f>(
     reinterpret_cast<Packet4f>(bf.m_val),
     reinterpret_cast<Packet4f>(p4ui_high_mask)
   );
 }
 
+// Simple interleaving of bool masks, prevents true values from being
+// converted to NaNs.
+EIGEN_STRONG_INLINE Packet8bf F32ToBf16Bool(Packet4f even, Packet4f odd) {
+  const _EIGEN_DECLARE_CONST_FAST_Packet4ui(high_mask, 0xFFFF0000);
+  Packet4f bf_odd, bf_even;
+  bf_odd = pand(reinterpret_cast<Packet4f>(p4ui_high_mask), odd);
+  bf_even = plogical_shift_right<16>(even);
+  return reinterpret_cast<Packet8us>(por<Packet4f>(bf_even, bf_odd));
+}
+
 EIGEN_STRONG_INLINE Packet8bf F32ToBf16(Packet4f p4f){
   Packet4ui input = reinterpret_cast<Packet4ui>(p4f);
   Packet4ui lsb = plogical_shift_right<16>(input);
   lsb = pand<Packet4ui>(lsb, reinterpret_cast<Packet4ui>(p4i_ONE));
 
   _EIGEN_DECLARE_CONST_FAST_Packet4ui(BIAS,0x7FFFu);
   Packet4ui rounding_bias = padd<Packet4ui>(lsb, p4ui_BIAS);
@@ -1204,23 +1265,23 @@
   const _EIGEN_DECLARE_CONST_FAST_Packet4ui(mantissa_mask, 0x7FFFFF);
   Packet4ui mantissa = pand<Packet4ui>(p4ui_mantissa_mask, reinterpret_cast<Packet4ui>(p4f));
 
   const _EIGEN_DECLARE_CONST_FAST_Packet4ui(max_exp, 0x7F800000);
   Packet4bi is_max_exp = vec_cmpeq(exp, p4ui_max_exp);
   Packet4bi is_zero_exp = vec_cmpeq(exp, reinterpret_cast<Packet4ui>(p4i_ZERO));
 
-  Packet4bi is_mant_not_zero = vec_cmpne(mantissa, reinterpret_cast<Packet4ui>(p4i_ZERO));
-  Packet4ui nan_selector = pand<Packet4ui>(
+  Packet4bi is_mant_zero = vec_cmpeq(mantissa, reinterpret_cast<Packet4ui>(p4i_ZERO));
+  Packet4ui nan_selector = pandnot<Packet4ui>(
       reinterpret_cast<Packet4ui>(is_max_exp),
-      reinterpret_cast<Packet4ui>(is_mant_not_zero)
+      reinterpret_cast<Packet4ui>(is_mant_zero)
   );
 
-  Packet4ui subnormal_selector = pand<Packet4ui>(
+  Packet4ui subnormal_selector = pandnot<Packet4ui>(
       reinterpret_cast<Packet4ui>(is_zero_exp),
-      reinterpret_cast<Packet4ui>(is_mant_not_zero)
+      reinterpret_cast<Packet4ui>(is_mant_zero)
   );
 
   const _EIGEN_DECLARE_CONST_FAST_Packet4ui(nan, 0x7FC00000);
   input = vec_sel(input, p4ui_nan, nan_selector);
   input = vec_sel(input, reinterpret_cast<Packet4ui>(p4f), subnormal_selector);
   //Test NaN and Subnormal - End
 
@@ -1247,14 +1308,23 @@
   Packet4f a_odd = Bf16ToF32Odd(A);\
   Packet4f b_even = Bf16ToF32Even(B);\
   Packet4f b_odd = Bf16ToF32Odd(B);\
   Packet4f op_even = OP(a_even, b_even);\
   Packet4f op_odd = OP(a_odd, b_odd);\
   return F32ToBf16(op_even, op_odd);\
 
+#define BF16_TO_F32_BINARY_OP_WRAPPER_BOOL(OP, A, B) \
+  Packet4f a_even = Bf16ToF32Even(A);\
+  Packet4f a_odd = Bf16ToF32Odd(A);\
+  Packet4f b_even = Bf16ToF32Even(B);\
+  Packet4f b_odd = Bf16ToF32Odd(B);\
+  Packet4f op_even = OP(a_even, b_even);\
+  Packet4f op_odd = OP(a_odd, b_odd);\
+  return F32ToBf16Bool(op_even, op_odd);\
+
 template<> EIGEN_STRONG_INLINE Packet8bf padd<Packet8bf>(const Packet8bf& a, const Packet8bf& b) {
   BF16_TO_F32_BINARY_OP_WRAPPER(padd<Packet4f>, a, b);
 }
 
 template<> EIGEN_STRONG_INLINE Packet8bf pmul<Packet8bf>(const Packet8bf& a, const Packet8bf& b) {
   BF16_TO_F32_BINARY_OP_WRAPPER(pmul<Packet4f>, a, b);
 }
@@ -1270,15 +1340,63 @@
 template<> EIGEN_STRONG_INLINE Packet8bf psub<Packet8bf>(const Packet8bf& a, const Packet8bf& b) {
   BF16_TO_F32_BINARY_OP_WRAPPER(psub<Packet4f>, a, b);
 }
 
 template<> EIGEN_STRONG_INLINE Packet8bf psqrt<Packet8bf> (const Packet8bf& a){
   BF16_TO_F32_UNARY_OP_WRAPPER(vec_sqrt, a);
 }
+template<> EIGEN_STRONG_INLINE Packet8bf prsqrt<Packet8bf> (const Packet8bf& a){
+  BF16_TO_F32_UNARY_OP_WRAPPER(prsqrt<Packet4f>, a);
+}
+template<> EIGEN_STRONG_INLINE Packet8bf pexp<Packet8bf> (const Packet8bf& a){
+  BF16_TO_F32_UNARY_OP_WRAPPER(pexp_float, a);
+}
+
+template<> EIGEN_STRONG_INLINE Packet4f pldexp<Packet4f>(const Packet4f& a, const Packet4f& exponent) {
+  return pldexp_generic(a,exponent);
+}
+template<> EIGEN_STRONG_INLINE Packet8bf pldexp<Packet8bf> (const Packet8bf& a, const Packet8bf& exponent){
+  BF16_TO_F32_BINARY_OP_WRAPPER(pldexp<Packet4f>, a, exponent);
+}
+
+template<> EIGEN_STRONG_INLINE Packet4f pfrexp<Packet4f>(const Packet4f& a, Packet4f& exponent) {
+  return pfrexp_generic(a,exponent);
+}
+template<> EIGEN_STRONG_INLINE Packet8bf pfrexp<Packet8bf> (const Packet8bf& a, Packet8bf& e){
+  Packet4f a_even = Bf16ToF32Even(a);
+  Packet4f a_odd = Bf16ToF32Odd(a);
+  Packet4f e_even;
+  Packet4f e_odd;
+  Packet4f op_even = pfrexp<Packet4f>(a_even, e_even);
+  Packet4f op_odd = pfrexp<Packet4f>(a_odd, e_odd);
+  e = F32ToBf16(e_even, e_odd);
+  return F32ToBf16(op_even, op_odd);
+}
 
+template<> EIGEN_STRONG_INLINE Packet8bf psin<Packet8bf> (const Packet8bf& a){
+  BF16_TO_F32_UNARY_OP_WRAPPER(psin_float, a);
+}
+template<> EIGEN_STRONG_INLINE Packet8bf pcos<Packet8bf> (const Packet8bf& a){
+  BF16_TO_F32_UNARY_OP_WRAPPER(pcos_float, a);
+}
+template<> EIGEN_STRONG_INLINE Packet8bf plog<Packet8bf> (const Packet8bf& a){
+  BF16_TO_F32_UNARY_OP_WRAPPER(plog_float, a);
+}
+template<> EIGEN_STRONG_INLINE Packet8bf pfloor<Packet8bf> (const Packet8bf& a){
+  BF16_TO_F32_UNARY_OP_WRAPPER(pfloor<Packet4f>, a);
+}
+template<> EIGEN_STRONG_INLINE Packet8bf pceil<Packet8bf> (const Packet8bf& a){
+  BF16_TO_F32_UNARY_OP_WRAPPER(pceil<Packet4f>, a);
+}
+template<> EIGEN_STRONG_INLINE Packet8bf pround<Packet8bf> (const Packet8bf& a){
+  BF16_TO_F32_UNARY_OP_WRAPPER(pround<Packet4f>, a);
+}
+template<> EIGEN_STRONG_INLINE Packet8bf print<Packet8bf> (const Packet8bf& a){
+  BF16_TO_F32_UNARY_OP_WRAPPER(print<Packet4f>, a);
+}
 template<> EIGEN_STRONG_INLINE Packet8bf pmadd(const Packet8bf& a, const Packet8bf& b, const Packet8bf& c) {
   Packet4f a_even = Bf16ToF32Even(a);
   Packet4f a_odd = Bf16ToF32Odd(a);
   Packet4f b_even = Bf16ToF32Even(b);
   Packet4f b_odd = Bf16ToF32Odd(b);
   Packet4f c_even = Bf16ToF32Even(c);
   Packet4f c_odd = Bf16ToF32Odd(c);
@@ -1292,38 +1410,39 @@
 }
 
 template<> EIGEN_STRONG_INLINE Packet8bf pmax<Packet8bf>(const Packet8bf& a, const Packet8bf& b) {
   BF16_TO_F32_BINARY_OP_WRAPPER(pmax<Packet4f>, a, b);
 }
 
 template<> EIGEN_STRONG_INLINE Packet8bf pcmp_lt(const Packet8bf& a, const Packet8bf& b) {
-  BF16_TO_F32_BINARY_OP_WRAPPER(pcmp_lt<Packet4f>, a, b);
+  BF16_TO_F32_BINARY_OP_WRAPPER_BOOL(pcmp_lt<Packet4f>, a, b);
+}
+template<> EIGEN_STRONG_INLINE Packet8bf pcmp_lt_or_nan(const Packet8bf& a, const Packet8bf& b) {
+  BF16_TO_F32_BINARY_OP_WRAPPER_BOOL(pcmp_lt_or_nan<Packet4f>, a, b);
 }
 template<> EIGEN_STRONG_INLINE Packet8bf pcmp_le(const Packet8bf& a, const Packet8bf& b) {
-  BF16_TO_F32_BINARY_OP_WRAPPER(pcmp_le<Packet4f>, a, b);
+  BF16_TO_F32_BINARY_OP_WRAPPER_BOOL(pcmp_le<Packet4f>, a, b);
 }
 template<> EIGEN_STRONG_INLINE Packet8bf pcmp_eq(const Packet8bf& a, const Packet8bf& b) {
-  BF16_TO_F32_BINARY_OP_WRAPPER(pcmp_eq<Packet4f>, a, b);
+  BF16_TO_F32_BINARY_OP_WRAPPER_BOOL(pcmp_eq<Packet4f>, a, b);
 }
 
 template<> EIGEN_STRONG_INLINE bfloat16 pfirst(const Packet8bf& a) {
   return Eigen::bfloat16_impl::raw_uint16_to_bfloat16((pfirst<Packet8us>(a)));
 }
 
 template<> EIGEN_STRONG_INLINE Packet8bf ploaddup<Packet8bf>(const  bfloat16*     from)
 {
   return ploaddup<Packet8us>(reinterpret_cast<const unsigned short int*>(from));
 }
 
-template<> EIGEN_STRONG_INLINE Packet4f pfrexp<Packet4f>(const Packet4f& a, Packet4f& exponent) {
-  return pfrexp_float(a,exponent);
-}
-
-template<> EIGEN_STRONG_INLINE Packet4f pldexp<Packet4f>(const Packet4f& a, const Packet4f& exponent) {
-  return pldexp_float(a,exponent);
+template<> EIGEN_STRONG_INLINE Packet8bf plset<Packet8bf>(const bfloat16& a) {
+  bfloat16 countdown[8] = { bfloat16(0), bfloat16(1), bfloat16(2), bfloat16(3),
+                            bfloat16(4), bfloat16(5), bfloat16(6), bfloat16(7) };
+  return padd<Packet8bf>(pset1<Packet8bf>(a), pload<Packet8bf>(countdown));
 }
 
 template<> EIGEN_STRONG_INLINE float predux<Packet4f>(const Packet4f& a)
 {
   Packet4f b, sum;
   b   = vec_sld(a, a, 8);
   sum = a + b;
@@ -1395,20 +1514,20 @@
   Packet4i third_quarter = pload<Packet4i>(third_loader);
   Packet4i fourth_quarter = pload<Packet4i>(fourth_loader);
 
   return static_cast<__UNPACK_TYPE__(Packet)>(predux(first_quarter) + predux(second_quarter)
 		                  + predux(third_quarter) + predux(fourth_quarter));
 }
 
-template<> EIGEN_STRONG_INLINE int8_t predux<Packet16c>(const Packet16c& a)
+template<> EIGEN_STRONG_INLINE signed char predux<Packet16c>(const Packet16c& a)
 {
   return predux_size16<Packet16c>(a);
 }
 
-template<> EIGEN_STRONG_INLINE uint8_t predux<Packet16uc>(const Packet16uc& a)
+template<> EIGEN_STRONG_INLINE unsigned char predux<Packet16uc>(const Packet16uc& a)
 {
   return predux_size16<Packet16uc>(a);
 }
 
 // Other reduction functions:
 // mul
 template<> EIGEN_STRONG_INLINE float predux_mul<Packet4f>(const Packet4f& a)
@@ -1452,27 +1571,27 @@
   float redux_even = predux_mul<Packet4f>(Bf16ToF32Even(a));
   float redux_odd  = predux_mul<Packet4f>(Bf16ToF32Odd(a));
   float f32_result = redux_even * redux_odd;
   return bfloat16(f32_result);
 }
 
 
-template<> EIGEN_STRONG_INLINE int8_t predux_mul<Packet16c>(const Packet16c& a)
+template<> EIGEN_STRONG_INLINE signed char predux_mul<Packet16c>(const Packet16c& a)
 {
   Packet16c pair, quad, octo, result;
 
   pair = vec_mul(a, vec_sld(a, a, 8));
   quad = vec_mul(pair, vec_sld(pair, pair, 4));
   octo = vec_mul(quad, vec_sld(quad, quad, 2));
   result = vec_mul(octo, vec_sld(octo, octo, 1));
 
   return pfirst(result);
 }
 
-template<> EIGEN_STRONG_INLINE uint8_t predux_mul<Packet16uc>(const Packet16uc& a)
+template<> EIGEN_STRONG_INLINE unsigned char predux_mul<Packet16uc>(const Packet16uc& a)
 {
   Packet16uc pair, quad, octo, result;
 
   pair = vec_mul(a, vec_sld(a, a, 8));
   quad = vec_mul(pair, vec_sld(pair, pair, 4));
   octo = vec_mul(quad, vec_sld(quad, quad, 2));
   result = vec_mul(octo, vec_sld(octo, octo, 1));
@@ -1535,27 +1654,27 @@
   quad = vec_min(pair, vec_sld(pair, pair, 4));
 
   //octo = { Min(a0, a4, a2, a6, a1, a5, a3, a7) }
   octo = vec_min(quad, vec_sld(quad, quad, 2));
   return pfirst(octo);
 }
 
-template<> EIGEN_STRONG_INLINE int8_t predux_min<Packet16c>(const Packet16c& a)
+template<> EIGEN_STRONG_INLINE signed char predux_min<Packet16c>(const Packet16c& a)
 {
   Packet16c pair, quad, octo, result;
 
   pair = vec_min(a, vec_sld(a, a, 8));
   quad = vec_min(pair, vec_sld(pair, pair, 4));
   octo = vec_min(quad, vec_sld(quad, quad, 2));
   result = vec_min(octo, vec_sld(octo, octo, 1));
 
   return pfirst(result);
 }
 
-template<> EIGEN_STRONG_INLINE uint8_t predux_min<Packet16uc>(const Packet16uc& a)
+template<> EIGEN_STRONG_INLINE unsigned char predux_min<Packet16uc>(const Packet16uc& a)
 {
   Packet16uc pair, quad, octo, result;
 
   pair = vec_min(a, vec_sld(a, a, 8));
   quad = vec_min(pair, vec_sld(pair, pair, 4));
   octo = vec_min(quad, vec_sld(quad, quad, 2));
   result = vec_min(octo, vec_sld(octo, octo, 1));
@@ -1615,27 +1734,27 @@
   quad = vec_max(pair, vec_sld(pair, pair, 4));
 
   //octo = { Max(a0, a4, a2, a6, a1, a5, a3, a7) }
   octo = vec_max(quad, vec_sld(quad, quad, 2));
   return pfirst(octo);
 }
 
-template<> EIGEN_STRONG_INLINE int8_t predux_max<Packet16c>(const Packet16c& a)
+template<> EIGEN_STRONG_INLINE signed char predux_max<Packet16c>(const Packet16c& a)
 {
   Packet16c pair, quad, octo, result;
 
   pair = vec_max(a, vec_sld(a, a, 8));
   quad = vec_max(pair, vec_sld(pair, pair, 4));
   octo = vec_max(quad, vec_sld(quad, quad, 2));
   result = vec_max(octo, vec_sld(octo, octo, 1));
 
   return pfirst(result);
 }
 
-template<> EIGEN_STRONG_INLINE uint8_t predux_max<Packet16uc>(const Packet16uc& a)
+template<> EIGEN_STRONG_INLINE unsigned char predux_max<Packet16uc>(const Packet16uc& a)
 {
   Packet16uc pair, quad, octo, result;
 
   pair = vec_max(a, vec_sld(a, a, 8));
   quad = vec_max(pair, vec_sld(pair, pair, 4));
   octo = vec_max(quad, vec_sld(quad, quad, 2));
   result = vec_max(octo, vec_sld(octo, octo, 1));
@@ -2141,34 +2260,30 @@
 typedef Packet2ul                    Packet2bl;
 #else
 typedef __vector __bool long         Packet2bl;
 #endif
 
 static Packet2l  p2l_ONE  = { 1, 1 };
 static Packet2l  p2l_ZERO = reinterpret_cast<Packet2l>(p4i_ZERO);
+static Packet2ul p2ul_SIGN = { 0x8000000000000000ull, 0x8000000000000000ull };
+static Packet2ul p2ul_PREV0DOT5 = { 0x3FDFFFFFFFFFFFFFull, 0x3FDFFFFFFFFFFFFFull };
 static Packet2d  p2d_ONE  = { 1.0, 1.0 };
 static Packet2d  p2d_ZERO = reinterpret_cast<Packet2d>(p4f_ZERO);
-static Packet2d  p2d_MZERO = { -0.0, -0.0 };
+static Packet2d  p2d_MZERO = { numext::bit_cast<double>(0x8000000000000000ull),
+                               numext::bit_cast<double>(0x8000000000000000ull) };
 
 #ifdef _BIG_ENDIAN
 static Packet2d p2d_COUNTDOWN = reinterpret_cast<Packet2d>(vec_sld(reinterpret_cast<Packet4f>(p2d_ZERO), reinterpret_cast<Packet4f>(p2d_ONE), 8));
 #else
 static Packet2d p2d_COUNTDOWN = reinterpret_cast<Packet2d>(vec_sld(reinterpret_cast<Packet4f>(p2d_ONE), reinterpret_cast<Packet4f>(p2d_ZERO), 8));
 #endif
 
-template<int index> Packet2d vec_splat_dbl(Packet2d& a);
-
-template<> EIGEN_STRONG_INLINE Packet2d vec_splat_dbl<0>(Packet2d& a)
+template<int index> Packet2d vec_splat_dbl(Packet2d& a)
 {
-  return reinterpret_cast<Packet2d>(vec_perm(a, a, p16uc_PSET64_HI));
-}
-
-template<> EIGEN_STRONG_INLINE Packet2d vec_splat_dbl<1>(Packet2d& a)
-{
-  return reinterpret_cast<Packet2d>(vec_perm(a, a, p16uc_PSET64_LO));
+  return vec_splat(a, index);
 }
 
 template<> struct packet_traits<double> : default_packet_traits
 {
   typedef Packet2d type;
   typedef Packet2d half;
   enum {
@@ -2189,14 +2304,15 @@
     HasLog  = 0,
     HasExp  = 1,
     HasSqrt = 1,
     HasRsqrt = 1,
     HasRound = 1,
     HasFloor = 1,
     HasCeil = 1,
+    HasRint = 1,
     HasNegate = 1,
     HasBlend = 1
   };
 };
 
 template<> struct unpacket_traits<Packet2d> { typedef double type; enum {size=2, alignment=Aligned16, vectorizable=true, masked_load_available=false, masked_store_available=false}; typedef Packet2d half; };
 
@@ -2236,24 +2352,28 @@
 }
 
 template<> EIGEN_STRONG_INLINE Packet2d pset1<Packet2d>(const double&  from) {
   Packet2d v = {from, from};
   return v;
 }
 
+template<> EIGEN_STRONG_INLINE Packet2d pset1frombits<Packet2d>(unsigned long from) {
+  Packet2l v = {static_cast<long long>(from), static_cast<long long>(from)};
+  return reinterpret_cast<Packet2d>(v);
+}
+
 template<> EIGEN_STRONG_INLINE void
 pbroadcast4<Packet2d>(const double *a,
                       Packet2d& a0, Packet2d& a1, Packet2d& a2, Packet2d& a3)
 {
-  a1 = pload<Packet2d>(a);
-  a0 = vec_splat_dbl<0>(a1);
-  a1 = vec_splat_dbl<1>(a1);
-  a3 = pload<Packet2d>(a+2);
-  a2 = vec_splat_dbl<0>(a3);
-  a3 = vec_splat_dbl<1>(a3);
+  //This way is faster than vec_splat (at least for doubles in Power 9)
+  a0 = pset1<Packet2d>(a[0]);
+  a1 = pset1<Packet2d>(a[1]);
+  a2 = pset1<Packet2d>(a[2]);
+  a3 = pset1<Packet2d>(a[3]);
 }
 
 template<> EIGEN_DEVICE_FUNC inline Packet2d pgather<double, Packet2d>(const double* from, Index stride)
 {
   EIGEN_ALIGN16 double af[2];
   af[0] = from[0*stride];
   af[1] = from[1*stride];
@@ -2311,22 +2431,42 @@
 
 template<> EIGEN_STRONG_INLINE Packet2d por<Packet2d>(const Packet2d& a, const Packet2d& b) { return vec_or(a, b); }
 
 template<> EIGEN_STRONG_INLINE Packet2d pxor<Packet2d>(const Packet2d& a, const Packet2d& b) { return vec_xor(a, b); }
 
 template<> EIGEN_STRONG_INLINE Packet2d pandnot<Packet2d>(const Packet2d& a, const Packet2d& b) { return vec_and(a, vec_nor(b, b)); }
 
-template<> EIGEN_STRONG_INLINE Packet2d pround<Packet2d>(const Packet2d& a) { return vec_round(a); }
+template<> EIGEN_STRONG_INLINE Packet2d pround<Packet2d>(const Packet2d& a)
+{
+    Packet2d t = vec_add(reinterpret_cast<Packet2d>(vec_or(vec_and(reinterpret_cast<Packet2ul>(a), p2ul_SIGN), p2ul_PREV0DOT5)), a);
+    Packet2d res;
+
+    __asm__("xvrdpiz %x0, %x1\n\t"
+        : "=&wa" (res)
+        : "wa" (t));
+
+    return res;
+}
 template<> EIGEN_STRONG_INLINE Packet2d pceil<Packet2d>(const  Packet2d& a) { return vec_ceil(a); }
 template<> EIGEN_STRONG_INLINE Packet2d pfloor<Packet2d>(const Packet2d& a) { return vec_floor(a); }
+template<> EIGEN_STRONG_INLINE Packet2d print<Packet2d>(const Packet2d& a)
+{
+    Packet2d res;
+
+    __asm__("xvrdpic %x0, %x1\n\t"
+        : "=&wa" (res)
+        : "wa" (a));
+
+    return res;
+}
 
 template<> EIGEN_STRONG_INLINE Packet2d ploadu<Packet2d>(const double* from)
 {
   EIGEN_DEBUG_UNALIGNED_LOAD
-  return vec_xl(0, from);
+  return vec_xl(0, const_cast<double*>(from));
 }
 
 template<> EIGEN_STRONG_INLINE Packet2d ploaddup<Packet2d>(const double*   from)
 {
   Packet2d p;
   if((std::ptrdiff_t(from) % 16) == 0)  p = pload<Packet2d>(from);
   else                                  p = ploadu<Packet2d>(from);
@@ -2351,59 +2491,177 @@
 
 // VSX support varies between different compilers and even different
 // versions of the same compiler.  For gcc version >= 4.9.3, we can use
 // vec_cts to efficiently convert Packet2d to Packet2l.  Otherwise, use
 // a slow version that works with older compilers. 
 // Update: apparently vec_cts/vec_ctf intrinsics for 64-bit doubles
 // are buggy, https://gcc.gnu.org/bugzilla/show_bug.cgi?id=70963
-static inline Packet2l ConvertToPacket2l(const Packet2d& x) {
+template<>
+inline Packet2l pcast<Packet2d, Packet2l>(const Packet2d& x) {
 #if EIGEN_GNUC_AT_LEAST(5, 4) || \
     (EIGEN_GNUC_AT(6, 1) && __GNUC_PATCHLEVEL__ >= 1)
   return vec_cts(x, 0);    // TODO: check clang version.
 #else
   double tmp[2];
   memcpy(tmp, &x, sizeof(tmp));
   Packet2l l = { static_cast<long long>(tmp[0]),
                  static_cast<long long>(tmp[1]) };
   return l;
 #endif
 }
 
-template<> EIGEN_STRONG_INLINE Packet2d pldexp<Packet2d>(const Packet2d& a, const Packet2d& exponent) {
-  
-  // build 2^n
-  Packet2l emm0 = ConvertToPacket2l(exponent);
+template<>
+inline Packet2d pcast<Packet2l, Packet2d>(const Packet2l& x) {
+  unsigned long long tmp[2];
+  memcpy(tmp, &x, sizeof(tmp));
+  Packet2d d = { static_cast<double>(tmp[0]),
+                 static_cast<double>(tmp[1]) };
+  return d;
+}
+
+
+// Packet2l shifts.
+// For POWER8 we simply use vec_sr/l. 
+//
+// Things are more complicated for POWER7. There is actually a
+// vec_xxsxdi intrinsic but it is not supported by some gcc versions.
+// So we need to shift by N % 32 and rearrage bytes.
+#ifdef __POWER8_VECTOR__
+
+template<int N>
+EIGEN_STRONG_INLINE Packet2l plogical_shift_left(const Packet2l& a) {
+  const Packet2ul shift = { N, N };
+  return vec_sl(a, shift); 
+}
+
+template<int N>
+EIGEN_STRONG_INLINE Packet2l plogical_shift_right(const Packet2l& a) {
+  const Packet2ul shift = { N, N };
+  return vec_sr(a, shift); 
+}
 
-#ifdef __POWER8_VECTOR__ 
-  const Packet2l  p2l_1023 = { 1023, 1023 };
-  const Packet2ul p2ul_52 = { 52, 52 };
-  emm0 = vec_add(emm0, p2l_1023);
-  emm0 = vec_sl(emm0, p2ul_52);
 #else
-  // Code is a bit complex for POWER7.  There is actually a
-  // vec_xxsldi intrinsic but it is not supported by some gcc versions.
-  // So we shift (52-32) bits and do a word swap with zeros.
-  const Packet4i p4i_1023 = pset1<Packet4i>(1023);
-  const Packet4i p4i_20 = pset1<Packet4i>(20);    // 52 - 32
-
-  Packet4i emm04i = reinterpret_cast<Packet4i>(emm0);
-  emm04i = vec_add(emm04i, p4i_1023);
-  emm04i = vec_sl(emm04i, reinterpret_cast<Packet4ui>(p4i_20));
+
+// Shifts [A, B, C, D] to [B, 0, D, 0].
+// Used to implement left shifts for Packet2l.
+EIGEN_ALWAYS_INLINE Packet4i shift_even_left(const Packet4i& a) {
   static const Packet16uc perm = {
-    0x14, 0x15, 0x16, 0x17, 0x00, 0x01, 0x02, 0x03, 
-    0x1c, 0x1d, 0x1e, 0x1f, 0x08, 0x09, 0x0a, 0x0b };
-#ifdef  _BIG_ENDIAN
-  emm0 = reinterpret_cast<Packet2l>(vec_perm(p4i_ZERO, emm04i, perm));
-#else
-  emm0 = reinterpret_cast<Packet2l>(vec_perm(emm04i, p4i_ZERO, perm));
-#endif
+      0x14, 0x15, 0x16, 0x17, 0x00, 0x01, 0x02, 0x03, 
+      0x1c, 0x1d, 0x1e, 0x1f, 0x08, 0x09, 0x0a, 0x0b };
+  #ifdef  _BIG_ENDIAN
+    return vec_perm(p4i_ZERO, a, perm);
+  #else
+    return vec_perm(a, p4i_ZERO, perm);
+  #endif
+}
+
+// Shifts [A, B, C, D] to [0, A, 0, C].
+// Used to implement right shifts for Packet2l.
+EIGEN_ALWAYS_INLINE Packet4i shift_odd_right(const Packet4i& a) {
+  static const Packet16uc perm = {
+      0x04, 0x05, 0x06, 0x07, 0x10, 0x11, 0x12, 0x13, 
+      0x0c, 0x0d, 0x0e, 0x0f, 0x18, 0x19, 0x1a, 0x1b };
+  #ifdef  _BIG_ENDIAN
+    return vec_perm(p4i_ZERO, a, perm);
+  #else
+    return vec_perm(a, p4i_ZERO, perm);
+  #endif
+}
+
+template<int N, typename EnableIf = void>
+struct plogical_shift_left_impl;
+
+template<int N>
+struct plogical_shift_left_impl<N, typename enable_if<(N < 32) && (N >= 0)>::type> {
+  static EIGEN_STRONG_INLINE Packet2l run(const Packet2l& a) {
+    static const unsigned n = static_cast<unsigned>(N);
+    const Packet4ui shift = {n, n, n, n};
+    const Packet4i ai = reinterpret_cast<Packet4i>(a);
+    static const unsigned m = static_cast<unsigned>(32 - N);
+    const Packet4ui shift_right = {m, m, m, m};
+    const Packet4i out_hi = vec_sl(ai, shift);
+    const Packet4i out_lo = shift_even_left(vec_sr(ai, shift_right));
+    return reinterpret_cast<Packet2l>(por<Packet4i>(out_hi, out_lo));
+  }
+};
+
+template<int N>
+struct plogical_shift_left_impl<N, typename enable_if<(N >= 32)>::type> {
+  static EIGEN_STRONG_INLINE Packet2l run(const Packet2l& a) {
+    static const unsigned m = static_cast<unsigned>(N - 32);
+    const Packet4ui shift = {m, m, m, m};
+    const Packet4i ai = reinterpret_cast<Packet4i>(a);
+    return reinterpret_cast<Packet2l>(shift_even_left(vec_sl(ai, shift)));
+  }
+};
+
+template<int N>
+EIGEN_STRONG_INLINE Packet2l plogical_shift_left(const Packet2l& a) {
+  return plogical_shift_left_impl<N>::run(a); 
+}
+
+template<int N, typename EnableIf = void>
+struct plogical_shift_right_impl;
+
+template<int N>
+struct plogical_shift_right_impl<N, typename enable_if<(N < 32) && (N >= 0)>::type> {
+  static EIGEN_STRONG_INLINE Packet2l run(const Packet2l& a) {
+    static const unsigned n = static_cast<unsigned>(N);
+    const Packet4ui shift = {n, n, n, n};
+    const Packet4i ai = reinterpret_cast<Packet4i>(a);
+    static const unsigned m = static_cast<unsigned>(32 - N);
+    const Packet4ui shift_left = {m, m, m, m};
+    const Packet4i out_lo = vec_sr(ai, shift);
+    const Packet4i out_hi = shift_odd_right(vec_sl(ai, shift_left));
+    return reinterpret_cast<Packet2l>(por<Packet4i>(out_hi, out_lo));
+  }
+};
+
+template<int N>
+struct plogical_shift_right_impl<N, typename enable_if<(N >= 32)>::type> {
+  static EIGEN_STRONG_INLINE Packet2l run(const Packet2l& a) {
+    static const unsigned m = static_cast<unsigned>(N - 32);
+    const Packet4ui shift = {m, m, m, m};
+    const Packet4i ai = reinterpret_cast<Packet4i>(a);
+    return reinterpret_cast<Packet2l>(shift_odd_right(vec_sr(ai, shift)));
+  }
+};
 
+template<int N>
+EIGEN_STRONG_INLINE Packet2l plogical_shift_right(const Packet2l& a) {
+  return plogical_shift_right_impl<N>::run(a); 
+}
 #endif
 
-  return pmul(a, reinterpret_cast<Packet2d>(emm0));
+template<> EIGEN_STRONG_INLINE Packet2d pldexp<Packet2d>(const Packet2d& a, const Packet2d& exponent) {
+  // Clamp exponent to [-2099, 2099]
+  const Packet2d max_exponent = pset1<Packet2d>(2099.0);
+  const Packet2l e = pcast<Packet2d, Packet2l>(pmin(pmax(exponent, pnegate(max_exponent)), max_exponent));
+
+  // Split 2^e into four factors and multiply:
+  const Packet2l  bias = { 1023, 1023 };
+  Packet2l b = plogical_shift_right<2>(e);  // floor(e/4)
+  Packet2d c = reinterpret_cast<Packet2d>(plogical_shift_left<52>(b + bias));
+  Packet2d out = pmul(pmul(pmul(a, c), c), c); // a * 2^(3b)
+  b = psub(psub(psub(e, b), b), b);  // e - 3b
+  c = reinterpret_cast<Packet2d>(plogical_shift_left<52>(b + bias)); // 2^(e - 3b)
+  out = pmul(out, c); // a * 2^e
+  return out;
+}
+
+
+// Extract exponent without existence of Packet2l.
+template<>
+EIGEN_STRONG_INLINE  
+Packet2d pfrexp_generic_get_biased_exponent(const Packet2d& a) {
+  return pcast<Packet2l, Packet2d>(plogical_shift_right<52>(reinterpret_cast<Packet2l>(pabs(a))));
+}
+
+template<> EIGEN_STRONG_INLINE Packet2d pfrexp<Packet2d> (const Packet2d& a, Packet2d& exponent) {
+  return pfrexp_generic(a, exponent);
 }
 
 template<> EIGEN_STRONG_INLINE double predux<Packet2d>(const Packet2d& a)
 {
   Packet2d b, sum;
   b   = reinterpret_cast<Packet2d>(vec_sld(reinterpret_cast<Packet4f>(a), reinterpret_cast<Packet4f>(a), 8));
   sum = a + b;
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/Default/BFloat16.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/Default/BFloat16.h`

 * *Files 4% similar despite different names*

```diff
@@ -27,88 +27,80 @@
 
 struct bfloat16;
 
 namespace bfloat16_impl {
 
 // Make our own __bfloat16_raw definition.
 struct __bfloat16_raw {
-  EIGEN_DEVICE_FUNC __bfloat16_raw() : value(0) {}
-  explicit EIGEN_DEVICE_FUNC __bfloat16_raw(unsigned short raw) : value(raw) {}
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR __bfloat16_raw() : value(0) {}
+  explicit EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR __bfloat16_raw(unsigned short raw) : value(raw) {}
   unsigned short value;
 };
 
-EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC __bfloat16_raw raw_uint16_to_bfloat16(unsigned short value);
+EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR __bfloat16_raw raw_uint16_to_bfloat16(unsigned short value);
 template <bool AssumeArgumentIsNormalOrInfinityOrZero>
 EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC __bfloat16_raw float_to_bfloat16_rtne(float ff);
 // Forward declarations of template specializations, to avoid Visual C++ 2019 errors, saying:
 // > error C2908: explicit specialization; 'float_to_bfloat16_rtne' has already been instantiated
 template <>
 EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC __bfloat16_raw float_to_bfloat16_rtne<false>(float ff);
 template <>
 EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC __bfloat16_raw float_to_bfloat16_rtne<true>(float ff);
 EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC float bfloat16_to_float(__bfloat16_raw h);
 
 struct bfloat16_base : public __bfloat16_raw {
-  EIGEN_DEVICE_FUNC bfloat16_base() {}
-  EIGEN_DEVICE_FUNC bfloat16_base(const __bfloat16_raw& h) : __bfloat16_raw(h) {}
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR bfloat16_base() {}
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR bfloat16_base(const __bfloat16_raw& h) : __bfloat16_raw(h) {}
 };
 
 } // namespace bfloat16_impl
 
 // Class definition.
 struct bfloat16 : public bfloat16_impl::bfloat16_base {
 
   typedef bfloat16_impl::__bfloat16_raw __bfloat16_raw;
 
-  EIGEN_DEVICE_FUNC bfloat16() {}
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR bfloat16() {}
 
-  EIGEN_DEVICE_FUNC bfloat16(const __bfloat16_raw& h) : bfloat16_impl::bfloat16_base(h) {}
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR bfloat16(const __bfloat16_raw& h) : bfloat16_impl::bfloat16_base(h) {}
 
-  explicit EIGEN_DEVICE_FUNC bfloat16(bool b)
+  explicit EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR bfloat16(bool b)
       : bfloat16_impl::bfloat16_base(bfloat16_impl::raw_uint16_to_bfloat16(b ? 0x3f80 : 0)) {}
 
   template<class T>
-  explicit EIGEN_DEVICE_FUNC bfloat16(const T& val)
+  explicit EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR bfloat16(T val)
       : bfloat16_impl::bfloat16_base(bfloat16_impl::float_to_bfloat16_rtne<internal::is_integral<T>::value>(static_cast<float>(val))) {}
-  
+
   explicit EIGEN_DEVICE_FUNC bfloat16(float f)
       : bfloat16_impl::bfloat16_base(bfloat16_impl::float_to_bfloat16_rtne<false>(f)) {}
 
   // Following the convention of numpy, converting between complex and
   // float will lead to loss of imag value.
   template<typename RealScalar>
-  explicit EIGEN_DEVICE_FUNC bfloat16(const std::complex<RealScalar>& val)
+  explicit EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR bfloat16(const std::complex<RealScalar>& val)
       : bfloat16_impl::bfloat16_base(bfloat16_impl::float_to_bfloat16_rtne<false>(static_cast<float>(val.real()))) {}
 
   EIGEN_DEVICE_FUNC operator float() const {  // NOLINT: Allow implicit conversion to float, because it is lossless.
     return bfloat16_impl::bfloat16_to_float(*this);
   }
-
-#if EIGEN_HAS_CXX11
-  EIGEN_DEVICE_FUNC EIGEN_EXPLICIT_CAST(bool) const {
-    // +0.0 and -0.0 become false, everything else becomes true.
-    return (value & 0x7fff) != 0;
-  }
-#endif 
-
 };
 } // namespace Eigen
 
 namespace std {
 template<>
 struct numeric_limits<Eigen::bfloat16> {
   static const bool is_specialized = true;
   static const bool is_signed = true;
   static const bool is_integer = false;
   static const bool is_exact = false;
   static const bool has_infinity = true;
   static const bool has_quiet_NaN = true;
   static const bool has_signaling_NaN = true;
-  static const float_denorm_style has_denorm = numeric_limits<float>::has_denorm;
-  static const bool has_denorm_loss = numeric_limits<float>::has_denorm_loss;
+  static const float_denorm_style has_denorm = std::denorm_absent;
+  static const bool has_denorm_loss = false;
   static const std::float_round_style round_style = numeric_limits<float>::round_style;
   static const bool is_iec559 = false;
   static const bool is_bounded = true;
   static const bool is_modulo = false;
   static const int digits = 8;
   static const int digits10 = 2;
   static const int max_digits10 = 4;
@@ -252,34 +244,32 @@
 EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 operator / (const bfloat16& a, Index b) {
   return bfloat16(static_cast<float>(a) / static_cast<float>(b));
 }
 
 EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC __bfloat16_raw truncate_to_bfloat16(const float v) {
   __bfloat16_raw output;
   if (Eigen::numext::isnan EIGEN_NOT_A_MACRO(v)) {
-    output.value = 0x7FC0;
-    return output;
-  } else if (std::fabs(v) < std::numeric_limits<float>::min EIGEN_NOT_A_MACRO()) {
-    // Flush denormal to +/- 0.
-    output.value = std::signbit(v) ? 0x8000 : 0;
+    output.value = std::signbit(v) ? 0xFFC0: 0x7FC0;
     return output;
   }
   const uint16_t* p = reinterpret_cast<const uint16_t*>(&v);
 #if defined(__BYTE_ORDER__) && __BYTE_ORDER__ == __ORDER_BIG_ENDIAN__
   output.value = p[0];
 #else
   output.value = p[1];
 #endif
   return output;
 }
 
-EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC __bfloat16_raw raw_uint16_to_bfloat16(unsigned short value) {
-  __bfloat16_raw h;
-  h.value = value;
-  return h;
+EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR __bfloat16_raw raw_uint16_to_bfloat16(numext::uint16_t value) {
+  return __bfloat16_raw(value);
+}
+
+EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR numext::uint16_t raw_bfloat16_as_uint16(const __bfloat16_raw& bf) {
+  return bf.value;
 }
 
 // float_to_bfloat16_rtne template specialization that does not make any
 // assumption about the value of its function argument (ff).
 template <>
 EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC __bfloat16_raw float_to_bfloat16_rtne<false>(float ff) {
 #if (defined(EIGEN_HAS_CUDA_BF16) && defined(EIGEN_HAS_HIP_BF16))
@@ -289,18 +279,15 @@
 
   if (Eigen::numext::isnan EIGEN_NOT_A_MACRO(ff)) {
     // If the value is a NaN, squash it to a qNaN with msb of fraction set,
     // this makes sure after truncation we don't end up with an inf.
     //
     // qNaN magic: All exponent bits set + most significant bit of fraction
     // set.
-    output.value = 0x7fc0;
-  } else if (std::fabs(ff) < std::numeric_limits<float>::min EIGEN_NOT_A_MACRO()) {
-    // Flush denormal to +/- 0.0
-    output.value = std::signbit(ff) ? 0x8000 : 0;
+    output.value = std::signbit(ff) ? 0xFFC0: 0x7FC0;
   } else {
     // Fast rounding algorithm that rounds a half value to nearest even. This
     // reduces expected error when we convert a large number of floats. Here
     // is how it works:
     //
     // Definitions:
     // To convert a float 32 to bfloat16, a float 32 can be viewed as 32 bits
@@ -452,28 +439,28 @@
   return output;
 #endif
 }
 
 // float_to_bfloat16_rtne template specialization that assumes that its function
 // argument (ff) is either a normal floating point number, or +/-infinity, or
 // zero. Used to improve the runtime performance of conversion from an integer
-// type to bfloat16.  
+// type to bfloat16.
 template <>
 EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC __bfloat16_raw float_to_bfloat16_rtne<true>(float ff) {
 #if (defined(EIGEN_HAS_CUDA_BF16) && defined(EIGEN_HAS_HIP_BF16))
     // Nothing to do here
 #else
-    unsigned int input = numext::as_uint(ff);
+    numext::uint32_t input = numext::bit_cast<numext::uint32_t>(ff);
     __bfloat16_raw output;
 
     // Least significant bit of resulting bfloat.
-    unsigned int lsb = (input >> 16) & 1;
-    unsigned int rounding_bias = 0x7fff + lsb;
+    numext::uint32_t lsb = (input >> 16) & 1;
+    numext::uint32_t rounding_bias = 0x7fff + lsb;
     input += rounding_bias;
-    output.value = static_cast<unsigned short>(input >> 16);
+    output.value = static_cast<numext::uint16_t>(input >> 16);
     return output;
 #endif
 }
 
 EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC float bfloat16_to_float(__bfloat16_raw h) {
     float result = 0;
     unsigned short* q = reinterpret_cast<unsigned short*>(&result);
@@ -483,18 +470,20 @@
     q[1] = h.value;
 #endif
     return result;
 }
 // --- standard functions ---
 
 EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool (isinf)(const bfloat16& a) {
-  return std::isinf EIGEN_NOT_A_MACRO(float(a));
+  EIGEN_USING_STD(isinf);
+  return (isinf)(float(a));
 }
 EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool (isnan)(const bfloat16& a) {
-  return std::isnan EIGEN_NOT_A_MACRO(float(a));
+  EIGEN_USING_STD(isnan);
+  return (isnan)(float(a));
 }
 EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bool (isfinite)(const bfloat16& a) {
   return !(isinf EIGEN_NOT_A_MACRO (a)) && !(isnan EIGEN_NOT_A_MACRO (a));
 }
 
 EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 abs(const bfloat16& a) {
   bfloat16 result;
@@ -512,14 +501,17 @@
 }
 EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 log1p(const bfloat16& a) {
   return bfloat16(numext::log1p(float(a)));
 }
 EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 log10(const bfloat16& a) {
   return bfloat16(::log10f(float(a)));
 }
+EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 log2(const bfloat16& a) {
+  return bfloat16(static_cast<float>(EIGEN_LOG2E) * ::logf(float(a)));
+}
 EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 sqrt(const bfloat16& a) {
     return bfloat16(::sqrtf(float(a)));
 }
 EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 pow(const bfloat16& a, const bfloat16& b) {
   return bfloat16(::powf(float(a), float(b)));
 }
 EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 sin(const bfloat16& a) {
@@ -547,29 +539,35 @@
   return bfloat16(::coshf(float(a)));
 }
 EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 tanh(const bfloat16& a) {
   return bfloat16(::tanhf(float(a)));
 }
 #if EIGEN_HAS_CXX11_MATH
 EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 asinh(const bfloat16& a) {
-  return bfloat16(::asinh(float(a)));
+  return bfloat16(::asinhf(float(a)));
 }
 EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 acosh(const bfloat16& a) {
-  return bfloat16(::acosh(float(a)));
+  return bfloat16(::acoshf(float(a)));
 }
 EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 atanh(const bfloat16& a) {
-  return bfloat16(::atanh(float(a)));
+  return bfloat16(::atanhf(float(a)));
 }
 #endif
 EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 floor(const bfloat16& a) {
   return bfloat16(::floorf(float(a)));
 }
 EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 ceil(const bfloat16& a) {
   return bfloat16(::ceilf(float(a)));
 }
+EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 rint(const bfloat16& a) {
+  return bfloat16(::rintf(float(a)));
+}
+EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 round(const bfloat16& a) {
+  return bfloat16(::roundf(float(a)));
+}
 EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 fmod(const bfloat16& a, const bfloat16& b) {
   return bfloat16(::fmodf(float(a), float(b)));
 }
 
 EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 (min)(const bfloat16& a, const bfloat16& b) {
   const float f1 = static_cast<float>(a);
   const float f2 = static_cast<float>(b);
@@ -577,14 +575,25 @@
 }
 EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 (max)(const bfloat16& a, const bfloat16& b) {
   const float f1 = static_cast<float>(a);
   const float f2 = static_cast<float>(b);
   return f1 < f2 ? b : a;
 }
 
+EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 fmin(const bfloat16& a, const bfloat16& b) {
+  const float f1 = static_cast<float>(a);
+  const float f2 = static_cast<float>(b);
+  return bfloat16(::fminf(f1, f2));
+}
+EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC bfloat16 fmax(const bfloat16& a, const bfloat16& b) {
+  const float f1 = static_cast<float>(a);
+  const float f2 = static_cast<float>(b);
+  return bfloat16(::fmaxf(f1, f2));
+}
+
 #ifndef EIGEN_NO_IO
 EIGEN_ALWAYS_INLINE std::ostream& operator << (std::ostream& os, const bfloat16& v) {
   os << static_cast<float>(v);
   return os;
 }
 #endif
 
@@ -615,48 +624,37 @@
   enum {
     IsSigned = true,
     IsInteger = false,
     IsComplex = false,
     RequireInitialization = false
   };
 
-  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE Eigen::bfloat16 epsilon() {
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static EIGEN_STRONG_INLINE Eigen::bfloat16 epsilon() {
     return bfloat16_impl::raw_uint16_to_bfloat16(0x3c00);
   }
-  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE Eigen::bfloat16 dummy_precision() { return Eigen::bfloat16(5e-2f); }
-  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE Eigen::bfloat16 highest() {
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static EIGEN_STRONG_INLINE Eigen::bfloat16 dummy_precision() {
+    return bfloat16_impl::raw_uint16_to_bfloat16(0x3D4D);  // bfloat16(5e-2f);
+
+  }
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static EIGEN_STRONG_INLINE Eigen::bfloat16 highest() {
     return bfloat16_impl::raw_uint16_to_bfloat16(0x7F7F);
   }
-  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE Eigen::bfloat16 lowest() {
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static EIGEN_STRONG_INLINE Eigen::bfloat16 lowest() {
     return bfloat16_impl::raw_uint16_to_bfloat16(0xFF7F);
   }
-  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE Eigen::bfloat16 infinity() {
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static EIGEN_STRONG_INLINE Eigen::bfloat16 infinity() {
     return bfloat16_impl::raw_uint16_to_bfloat16(0x7f80);
   }
-  EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE Eigen::bfloat16 quiet_NaN() {
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR static EIGEN_STRONG_INLINE Eigen::bfloat16 quiet_NaN() {
     return bfloat16_impl::raw_uint16_to_bfloat16(0x7fc0);
   }
 };
 
 } // namespace Eigen
 
-namespace std {
-
-#if __cplusplus > 199711L
-template <>
-struct hash<Eigen::bfloat16> {
-  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE std::size_t operator()(const Eigen::bfloat16& a) const {
-    return hash<float>()(static_cast<float>(a));
-  }
-};
-#endif
-
-} // namespace std
-
-
 namespace Eigen {
 namespace numext {
 
 template<>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 bool (isnan)(const Eigen::bfloat16& h) {
   return (bfloat16_impl::isnan)(h);
@@ -670,11 +668,33 @@
 
 template<>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 bool (isfinite)(const Eigen::bfloat16& h) {
   return (bfloat16_impl::isfinite)(h);
 }
 
-} // namespace numext
+template <>
+EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC Eigen::bfloat16 bit_cast<Eigen::bfloat16, uint16_t>(const uint16_t& src) {
+  return Eigen::bfloat16(Eigen::bfloat16_impl::raw_uint16_to_bfloat16(src));
+}
+
+template <>
+EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC uint16_t bit_cast<uint16_t, Eigen::bfloat16>(const Eigen::bfloat16& src) {
+  return Eigen::bfloat16_impl::raw_bfloat16_as_uint16(src);
+}
+
+}  // namespace numext
 }  // namespace Eigen
 
+#if EIGEN_HAS_STD_HASH
+namespace std {
+template <>
+struct hash<Eigen::bfloat16> {
+  EIGEN_STRONG_INLINE std::size_t operator()(const Eigen::bfloat16& a) const {
+    return static_cast<std::size_t>(Eigen::numext::bit_cast<Eigen::numext::uint16_t>(a));
+  }
+};
+} // namespace std
+#endif
+
+
 #endif // EIGEN_BFLOAT16_H
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/Default/GenericPacketMathFunctionsFwd.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/Default/GenericPacketMathFunctionsFwd.h`

 * *Files 23% similar despite different names*

```diff
@@ -13,26 +13,60 @@
 namespace Eigen {
 namespace internal {
 
 // Forward declarations of the generic math functions
 // implemented in GenericPacketMathFunctions.h
 // This is needed to workaround a circular dependency.
 
-template<typename Packet> EIGEN_STRONG_INLINE Packet
-pfrexp_float(const Packet& a, Packet& exponent);
-
-template<typename Packet> EIGEN_STRONG_INLINE Packet
-pldexp_float(Packet a, Packet exponent);
+/***************************************************************************
+ * Some generic implementations to be used by implementors
+***************************************************************************/
+
+/** Default implementation of pfrexp.
+  * It is expected to be called by implementers of template<> pfrexp.
+  */
+template<typename Packet> EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC
+Packet pfrexp_generic(const Packet& a, Packet& exponent);
+
+// Extracts the biased exponent value from Packet p, and casts the results to
+// a floating-point Packet type. Used by pfrexp_generic. Override this if
+// there is no unpacket_traits<Packet>::integer_packet.
+template<typename Packet> EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC
+Packet pfrexp_generic_get_biased_exponent(const Packet& p);
+
+/** Default implementation of pldexp.
+  * It is expected to be called by implementers of template<> pldexp.
+  */
+template<typename Packet> EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC
+Packet pldexp_generic(const Packet& a, const Packet& exponent);
 
 /** \internal \returns log(x) for single precision float */
 template <typename Packet>
 EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
 EIGEN_UNUSED
 Packet plog_float(const Packet _x);
 
+/** \internal \returns log2(x) for single precision float */
+template <typename Packet>
+EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
+EIGEN_UNUSED
+Packet plog2_float(const Packet _x);
+
+/** \internal \returns log(x) for single precision float */
+template <typename Packet>
+EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
+EIGEN_UNUSED
+Packet plog_double(const Packet _x);
+
+/** \internal \returns log2(x) for single precision float */
+template <typename Packet>
+EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
+EIGEN_UNUSED
+Packet plog2_double(const Packet _x);
+
 /** \internal \returns log(1 + x) */
 template<typename Packet>
 Packet generic_plog1p(const Packet& x);
 
 /** \internal \returns exp(x)-1 */
 template<typename Packet>
 Packet generic_expm1(const Packet& x);
@@ -57,13 +91,20 @@
 
 /** \internal \returns cos(x) for single precision float */
 template<typename Packet>
 EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
 EIGEN_UNUSED
 Packet pcos_float(const Packet& x);
 
+/** \internal \returns sqrt(x) for complex types */
+template<typename Packet>
+EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
+EIGEN_UNUSED
+Packet psqrt_complex(const Packet& a);
+
 template <typename Packet, int N> struct ppolevl;
 
+
 } // end namespace internal
 } // end namespace Eigen
 
 #endif // EIGEN_ARCH_GENERIC_PACKET_MATH_FUNCTIONS_FWD_H
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/Default/Settings.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/Default/Settings.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/Default/TypeCasting.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/Default/TypeCasting.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/GPU/MathFunctions.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/GPU/MathFunctions.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/GPU/PacketMath.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/GPU/PacketMath.h`

 * *Files 10% similar despite different names*

```diff
@@ -10,18 +10,33 @@
 #ifndef EIGEN_PACKET_MATH_GPU_H
 #define EIGEN_PACKET_MATH_GPU_H
 
 namespace Eigen {
 
 namespace internal {
 
+// Read-only data cached load available.
+#if defined(EIGEN_HIP_DEVICE_COMPILE) || (defined(EIGEN_CUDA_ARCH) && EIGEN_CUDA_ARCH >= 350)
+#define EIGEN_GPU_HAS_LDG 1
+#endif
+
+// FP16 math available.
+#if (defined(EIGEN_CUDA_ARCH) && EIGEN_CUDA_ARCH >= 530)
+#define EIGEN_CUDA_HAS_FP16_ARITHMETIC 1
+#endif
+
+#if defined(EIGEN_HIP_DEVICE_COMPILE) || defined(EIGEN_CUDA_HAS_FP16_ARITHMETIC)
+#define EIGEN_GPU_HAS_FP16_ARITHMETIC 1
+#endif
+
 // Make sure this is only available when targeting a GPU: we don't want to
 // introduce conflicts between these packet_traits definitions and the ones
 // we'll use on the host side (SSE, AVX, ...)
 #if defined(EIGEN_GPUCC) && defined(EIGEN_USE_GPU)
+
 template<> struct is_arithmetic<float4>  { enum { value = true }; };
 template<> struct is_arithmetic<double2> { enum { value = true }; };
 
 template<> struct packet_traits<float> : default_packet_traits
 {
   typedef float4 type;
   typedef float4 half;
@@ -233,15 +248,15 @@
   return make_double2(eq_mask(a.x, b.x), eq_mask(a.y, b.y));
 }
 template <>
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE double2
 pcmp_lt<double2>(const double2& a, const double2& b) {
   return make_double2(lt_mask(a.x, b.x), lt_mask(a.y, b.y));
 }
-#endif  // EIGEN_CUDA_ARCH || defined(EIGEN_HIP_DEVICE_COMPILE)
+#endif // defined(EIGEN_CUDA_ARCH) || defined(EIGEN_HIPCC) || (defined(EIGEN_CUDACC) && EIGEN_COMP_CLANG && !EIGEN_COMP_NVCC)
 
 template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE float4 plset<float4>(const float& a) {
   return make_float4(a, a+1, a+2, a+3);
 }
 template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE double2 plset<double2>(const double& a) {
   return make_double2(a, a+1);
 }
@@ -338,40 +353,40 @@
 template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void pstoreu<double>(double* to, const double2& from) {
   to[0] = from.x;
   to[1] = from.y;
 }
 
 template<>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE float4 ploadt_ro<float4, Aligned>(const float* from) {
-#if defined(EIGEN_CUDA_ARCH) && EIGEN_CUDA_ARCH >= 350
+#if defined(EIGEN_GPU_HAS_LDG)
   return __ldg((const float4*)from);
 #else
   return make_float4(from[0], from[1], from[2], from[3]);
 #endif
 }
 template<>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE double2 ploadt_ro<double2, Aligned>(const double* from) {
-#if defined(EIGEN_CUDA_ARCH) && EIGEN_CUDA_ARCH >= 350
+#if defined(EIGEN_GPU_HAS_LDG)
   return __ldg((const double2*)from);
 #else
   return make_double2(from[0], from[1]);
 #endif
 }
 
 template<>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE float4 ploadt_ro<float4, Unaligned>(const float* from) {
-#if defined(EIGEN_CUDA_ARCH) && EIGEN_CUDA_ARCH >= 350
+#if defined(EIGEN_GPU_HAS_LDG)
   return make_float4(__ldg(from+0), __ldg(from+1), __ldg(from+2), __ldg(from+3));
 #else
   return make_float4(from[0], from[1], from[2], from[3]);
 #endif
 }
 template<>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE double2 ploadt_ro<double2, Unaligned>(const double* from) {
-#if defined(EIGEN_CUDA_ARCH) && EIGEN_CUDA_ARCH >= 350
+#if defined(EIGEN_GPU_HAS_LDG)
   return make_double2(__ldg(from+0), __ldg(from+1));
 #else
   return make_double2(from[0], from[1]);
 #endif
 }
 
 template<> EIGEN_DEVICE_FUNC inline float4 pgather<float, float4>(const float* from, Index stride) {
@@ -476,17 +491,15 @@
   kernel.packet[1].x = tmp;
 }
 
 #endif // defined(EIGEN_GPUCC) && defined(EIGEN_USE_GPU)
 
 // Packet4h2 must be defined in the macro without EIGEN_CUDA_ARCH, meaning
 // its corresponding packet_traits<Eigen::half> must be visible on host.
-#if (defined(EIGEN_HAS_CUDA_FP16) && defined(EIGEN_CUDACC)) || \
-  (defined(EIGEN_HAS_HIP_FP16) && defined(EIGEN_HIPCC)) || \
-  (defined(EIGEN_HAS_CUDA_FP16) && defined(__clang__) && defined(__CUDA__))
+#if defined(EIGEN_HAS_CUDA_FP16) || defined(EIGEN_HAS_HIP_FP16)
 
 typedef ulonglong2 Packet4h2;
 template<> struct unpacket_traits<Packet4h2> { typedef Eigen::half type; enum {size=8, alignment=Aligned16, vectorizable=true, masked_load_available=false, masked_store_available=false}; typedef Packet4h2 half; };
 template<> struct is_arithmetic<Packet4h2> { enum { value = true }; };
 
 template<> struct unpacket_traits<half2> { typedef Eigen::half type; enum {size=2, alignment=Aligned16, vectorizable=true, masked_load_available=false, masked_store_available=false}; typedef half2 half; };
 template<> struct is_arithmetic<half2> { enum { value = true }; };
@@ -509,25 +522,49 @@
     HasExp    = 1,
     HasExpm1  = 1,
     HasLog    = 1,
     HasLog1p  = 1
   };
 };
 
+namespace {
+// This is equivalent to make_half2, which is undocumented and doesn't seem to always exist.
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 combine_half(const __half& a, const __half& b) {
+#if defined(EIGEN_GPU_COMPILE_PHASE)
+  return __halves2half2(a, b);
+#else
+  // Round-about way since __halves2half2 is a __device__ function.
+  return __floats2half2_rn(__half2float(a), __half2float(b));
+#endif
+}
+
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE __half get_half2_low(const half2& a) {
+#if defined(EIGEN_GPU_COMPILE_PHASE)
+  return __low2half(a);
+#else
+  return __float2half(__low2float(a));
+#endif
+}
+
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE __half get_half2_high(const half2& a) {
+#if defined(EIGEN_GPU_COMPILE_PHASE)
+  return __high2half(a);
+#else
+  return __float2half(__high2float(a));
+#endif
+}
+} // namespace
+
 template<>
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pset1<half2>(const Eigen::half& from) {
-#if !defined(EIGEN_CUDA_ARCH) && !defined(EIGEN_HIPCC)
-  half2 r;
-  r.x = from;
-  r.y = from;
-  return r;
-#elif defined(EIGEN_HIPCC)
-  return __half2{from,from};
-#else
+#if defined(EIGEN_GPU_COMPILE_PHASE)
   return __half2half2(from);
+#else
+  const float f = __half2float(from);
+  return __floats2half2_rn(f, f);
 #endif
 }
 
 template <>
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4h2
 pset1<Packet4h2>(const Eigen::half& from) {
   Packet4h2 r;
@@ -535,456 +572,347 @@
   p_alias[0] = pset1<half2>(from);
   p_alias[1] = pset1<half2>(from);
   p_alias[2] = pset1<half2>(from);
   p_alias[3] = pset1<half2>(from);
   return r;
 }
 
-#if defined(EIGEN_CUDA_ARCH) || defined(EIGEN_HIPCC) || (defined(EIGEN_CUDACC) && EIGEN_COMP_CLANG && !EIGEN_COMP_NVCC)
+// We now need this visible on both host and device.
+// #if defined(EIGEN_CUDA_ARCH) || defined(EIGEN_HIPCC) || (defined(EIGEN_CUDACC) && EIGEN_COMP_CLANG && !EIGEN_COMP_NVCC)
 namespace {
 
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pload(const Eigen::half* from) {
   return *reinterpret_cast<const half2*>(from);
 }
 
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 ploadu(const Eigen::half* from) {
-  return __halves2half2(from[0], from[1]);
+  return combine_half(from[0], from[1]);
 }
 
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 ploaddup(const Eigen::half*  from) {
-  return __halves2half2(from[0], from[0]);
+  return combine_half(from[0], from[0]);
 }
 
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void pstore(Eigen::half* to,
                                                   const half2& from) {
   *reinterpret_cast<half2*>(to) = from;
 }
 
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void pstoreu(Eigen::half* to,
                                                    const half2& from) {
-#if !defined(EIGEN_CUDA_ARCH) && !defined(EIGEN_HIPCC)
-  to[0] = from.x;
-  to[1] = from.y;
-#else
-  to[0] = __low2half(from);
-  to[1] = __high2half(from);
-#endif
+  to[0] = get_half2_low(from);
+  to[1] = get_half2_high(from);
 }
 
 
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE half2 ploadt_ro_aligned(
     const Eigen::half* from) {
-
-#if defined(EIGEN_HIP_DEVICE_COMPILE)
-
-  return __ldg((const half2*)from);
-
-#else  // EIGEN_CUDA_ARCH
-
-#if EIGEN_CUDA_ARCH >= 350
-   return __ldg((const half2*)from);
+#if defined(EIGEN_GPU_HAS_LDG)
+  // Input is guaranteed to be properly aligned.
+  return __ldg(reinterpret_cast<const half2*>(from));
 #else
-  return __halves2half2(*(from+0), *(from+1));
-#endif
-
+  return combine_half(*(from+0), *(from+1));
 #endif
 }
 
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE half2 ploadt_ro_unaligned(
     const Eigen::half* from) {
-
-#if defined(EIGEN_HIP_DEVICE_COMPILE)
-
+#if defined(EIGEN_GPU_HAS_LDG)
   return __halves2half2(__ldg(from+0), __ldg(from+1));
-
-#else  // EIGEN_CUDA_ARCH
-
-#if EIGEN_CUDA_ARCH >= 350
-   return __halves2half2(__ldg(from+0), __ldg(from+1));
 #else
-  return __halves2half2(*(from+0), *(from+1));
-#endif
-
+  return combine_half(*(from+0), *(from+1));
 #endif
 }
 
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pgather(const Eigen::half* from,
                                                     Index stride) {
-  return __halves2half2(from[0*stride], from[1*stride]);
+  return combine_half(from[0*stride], from[1*stride]);
 }
 
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void pscatter(
     Eigen::half* to, const half2& from, Index stride) {
-  to[stride*0] = __low2half(from);
-  to[stride*1] = __high2half(from);
+  to[stride*0] = get_half2_low(from);
+  to[stride*1] = get_half2_high(from);
 }
 
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Eigen::half pfirst(const half2& a) {
-  return __low2half(a);
+  return get_half2_low(a);
 }
 
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pabs(const half2& a) {
-  half a1 = __low2half(a);
-  half a2 = __high2half(a);
+  half a1 = get_half2_low(a);
+  half a2 = get_half2_high(a);
   half result1 = half_impl::raw_uint16_to_half(a1.x & 0x7FFF);
   half result2 = half_impl::raw_uint16_to_half(a2.x & 0x7FFF);
-  return __halves2half2(result1, result2);
+  return combine_half(result1, result2);
 }
 
-EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 ptrue(const half2& a) {
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 ptrue(const half2& /*a*/) {
   half true_half = half_impl::raw_uint16_to_half(0xffffu);
   return pset1<half2>(true_half);
 }
 
-EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pzero(const half2& a) {
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pzero(const half2& /*a*/) {
   half false_half = half_impl::raw_uint16_to_half(0x0000u);
   return pset1<half2>(false_half);
 }
 
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void
 ptranspose(PacketBlock<half2,2>& kernel) {
-  __half a1 = __low2half(kernel.packet[0]);
-  __half a2 = __high2half(kernel.packet[0]);
-  __half b1 = __low2half(kernel.packet[1]);
-  __half b2 = __high2half(kernel.packet[1]);
-  kernel.packet[0] = __halves2half2(a1, b1);
-  kernel.packet[1] = __halves2half2(a2, b2);
+  __half a1 = get_half2_low(kernel.packet[0]);
+  __half a2 = get_half2_high(kernel.packet[0]);
+  __half b1 = get_half2_low(kernel.packet[1]);
+  __half b2 = get_half2_high(kernel.packet[1]);
+  kernel.packet[0] = combine_half(a1, b1);
+  kernel.packet[1] = combine_half(a2, b2);
 }
 
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 plset(const Eigen::half& a) {
-#if defined(EIGEN_HIP_DEVICE_COMPILE)
-
-  return __halves2half2(a, __hadd(a, __float2half(1.0f)));
-
-#else  // EIGEN_CUDA_ARCH
-
-#if EIGEN_CUDA_ARCH >= 530
+#if defined(EIGEN_GPU_HAS_FP16_ARITHMETIC)
   return __halves2half2(a, __hadd(a, __float2half(1.0f)));
 #else
   float f = __half2float(a) + 1.0f;
-  return __halves2half2(a, __float2half(f));
-#endif
-
+  return combine_half(a, __float2half(f));
 #endif
 }
 
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pselect(const half2& mask,
                                                     const half2& a,
                                                     const half2& b) {
-  half mask_low = __low2half(mask);
-  half mask_high = __high2half(mask);
-  half result_low = mask_low == half(0) ? __low2half(b) : __low2half(a);
-  half result_high = mask_high == half(0) ? __high2half(b) : __high2half(a);
-  return __halves2half2(result_low, result_high);
+  half mask_low = get_half2_low(mask);
+  half mask_high = get_half2_high(mask);
+  half result_low = mask_low == half(0) ? get_half2_low(b) : get_half2_low(a);
+  half result_high = mask_high == half(0) ? get_half2_high(b) : get_half2_high(a);
+  return combine_half(result_low, result_high);
 }
 
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pcmp_eq(const half2& a,
                                                     const half2& b) {
   half true_half = half_impl::raw_uint16_to_half(0xffffu);
   half false_half = half_impl::raw_uint16_to_half(0x0000u);
-  half a1 = __low2half(a);
-  half a2 = __high2half(a);
-  half b1 = __low2half(b);
-  half b2 = __high2half(b);
+  half a1 = get_half2_low(a);
+  half a2 = get_half2_high(a);
+  half b1 = get_half2_low(b);
+  half b2 = get_half2_high(b);
   half eq1 = __half2float(a1) == __half2float(b1) ? true_half : false_half;
   half eq2 = __half2float(a2) == __half2float(b2) ? true_half : false_half;
-  return __halves2half2(eq1, eq2);
+  return combine_half(eq1, eq2);
 }
 
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pcmp_lt(const half2& a,
                                                     const half2& b) {
   half true_half = half_impl::raw_uint16_to_half(0xffffu);
   half false_half = half_impl::raw_uint16_to_half(0x0000u);
-  half a1 = __low2half(a);
-  half a2 = __high2half(a);
-  half b1 = __low2half(b);
-  half b2 = __high2half(b);
+  half a1 = get_half2_low(a);
+  half a2 = get_half2_high(a);
+  half b1 = get_half2_low(b);
+  half b2 = get_half2_high(b);
   half eq1 = __half2float(a1) < __half2float(b1) ? true_half : false_half;
   half eq2 = __half2float(a2) < __half2float(b2) ? true_half : false_half;
-  return __halves2half2(eq1, eq2);
+  return combine_half(eq1, eq2);
 }
 
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pand(const half2& a,
                                                  const half2& b) {
-  half a1 = __low2half(a);
-  half a2 = __high2half(a);
-  half b1 = __low2half(b);
-  half b2 = __high2half(b);
+  half a1 = get_half2_low(a);
+  half a2 = get_half2_high(a);
+  half b1 = get_half2_low(b);
+  half b2 = get_half2_high(b);
   half result1 = half_impl::raw_uint16_to_half(a1.x & b1.x);
   half result2 = half_impl::raw_uint16_to_half(a2.x & b2.x);
-  return __halves2half2(result1, result2);
+  return combine_half(result1, result2);
 }
 
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 por(const half2& a,
                                                 const half2& b) {
-  half a1 = __low2half(a);
-  half a2 = __high2half(a);
-  half b1 = __low2half(b);
-  half b2 = __high2half(b);
+  half a1 = get_half2_low(a);
+  half a2 = get_half2_high(a);
+  half b1 = get_half2_low(b);
+  half b2 = get_half2_high(b);
   half result1 = half_impl::raw_uint16_to_half(a1.x | b1.x);
   half result2 = half_impl::raw_uint16_to_half(a2.x | b2.x);
-  return __halves2half2(result1, result2);
+  return combine_half(result1, result2);
 }
 
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pxor(const half2& a,
                                                  const half2& b) {
-  half a1 = __low2half(a);
-  half a2 = __high2half(a);
-  half b1 = __low2half(b);
-  half b2 = __high2half(b);
+  half a1 = get_half2_low(a);
+  half a2 = get_half2_high(a);
+  half b1 = get_half2_low(b);
+  half b2 = get_half2_high(b);
   half result1 = half_impl::raw_uint16_to_half(a1.x ^ b1.x);
   half result2 = half_impl::raw_uint16_to_half(a2.x ^ b2.x);
-  return __halves2half2(result1, result2);
+  return combine_half(result1, result2);
 }
 
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pandnot(const half2& a,
                                                     const half2& b) {
-  half a1 = __low2half(a);
-  half a2 = __high2half(a);
-  half b1 = __low2half(b);
-  half b2 = __high2half(b);
+  half a1 = get_half2_low(a);
+  half a2 = get_half2_high(a);
+  half b1 = get_half2_low(b);
+  half b2 = get_half2_high(b);
   half result1 = half_impl::raw_uint16_to_half(a1.x & ~b1.x);
   half result2 = half_impl::raw_uint16_to_half(a2.x & ~b2.x);
-  return __halves2half2(result1, result2);
+  return combine_half(result1, result2);
 }
 
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 padd(const half2& a,
                                                  const half2& b) {
-#if defined(EIGEN_HIP_DEVICE_COMPILE)
-
-  return __hadd2(a, b);
-
-#else  // EIGEN_CUDA_ARCH
-
-#if EIGEN_CUDA_ARCH >= 530
+#if defined(EIGEN_GPU_HAS_FP16_ARITHMETIC)
   return __hadd2(a, b);
 #else
   float a1 = __low2float(a);
   float a2 = __high2float(a);
   float b1 = __low2float(b);
   float b2 = __high2float(b);
   float r1 = a1 + b1;
   float r2 = a2 + b2;
   return __floats2half2_rn(r1, r2);
 #endif
-
-#endif
 }
 
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 psub(const half2& a,
                                                  const half2& b) {
-#if defined(EIGEN_HIP_DEVICE_COMPILE)
-
-  return __hsub2(a, b);
-
-#else  // EIGEN_CUDA_ARCH
-
-#if EIGEN_CUDA_ARCH >= 530
+#if defined(EIGEN_GPU_HAS_FP16_ARITHMETIC)
   return __hsub2(a, b);
 #else
   float a1 = __low2float(a);
   float a2 = __high2float(a);
   float b1 = __low2float(b);
   float b2 = __high2float(b);
   float r1 = a1 - b1;
   float r2 = a2 - b2;
   return __floats2half2_rn(r1, r2);
 #endif
-
-#endif
 }
 
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pnegate(const half2& a) {
-#if defined(EIGEN_HIP_DEVICE_COMPILE)
-
-  return __hneg2(a);
-
-#else  // EIGEN_CUDA_ARCH
-
-#if EIGEN_CUDA_ARCH >= 530
+#if defined(EIGEN_GPU_HAS_FP16_ARITHMETIC)
   return __hneg2(a);
 #else
   float a1 = __low2float(a);
   float a2 = __high2float(a);
   return __floats2half2_rn(-a1, -a2);
 #endif
-
-#endif
 }
 
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pconj(const half2& a) { return a; }
 
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pmul(const half2& a,
                                                  const half2& b) {
-#if defined(EIGEN_HIP_DEVICE_COMPILE)
-
-  return __hmul2(a, b);
-
-#else  // EIGEN_CUDA_ARCH
-
-#if EIGEN_CUDA_ARCH >= 530
+#if defined(EIGEN_GPU_HAS_FP16_ARITHMETIC)
   return __hmul2(a, b);
 #else
   float a1 = __low2float(a);
   float a2 = __high2float(a);
   float b1 = __low2float(b);
   float b2 = __high2float(b);
   float r1 = a1 * b1;
   float r2 = a2 * b2;
   return __floats2half2_rn(r1, r2);
 #endif
-
-#endif
 }
 
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pmadd(const half2& a,
                                                   const half2& b,
                                                   const half2& c) {
-#if defined(EIGEN_HIP_DEVICE_COMPILE)
-
-   return __hfma2(a, b, c);
-
-#else  // EIGEN_CUDA_ARCH
-
-#if EIGEN_CUDA_ARCH >= 530
+#if defined(EIGEN_GPU_HAS_FP16_ARITHMETIC)
    return __hfma2(a, b, c);
 #else
   float a1 = __low2float(a);
   float a2 = __high2float(a);
   float b1 = __low2float(b);
   float b2 = __high2float(b);
   float c1 = __low2float(c);
   float c2 = __high2float(c);
   float r1 = a1 * b1 + c1;
   float r2 = a2 * b2 + c2;
   return __floats2half2_rn(r1, r2);
 #endif
-
-#endif
 }
 
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pdiv(const half2& a,
                                                  const half2& b) {
-#if defined(EIGEN_HIP_DEVICE_COMPILE)
-
+#if defined(EIGEN_GPU_HAS_FP16_ARITHMETIC)
   return __h2div(a, b);
-
-#else // EIGEN_CUDA_ARCH
-
+#else
   float a1 = __low2float(a);
   float a2 = __high2float(a);
   float b1 = __low2float(b);
   float b2 = __high2float(b);
   float r1 = a1 / b1;
   float r2 = a2 / b2;
   return __floats2half2_rn(r1, r2);
-
 #endif
 }
 
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pmin(const half2& a,
                                                  const half2& b) {
   float a1 = __low2float(a);
   float a2 = __high2float(a);
   float b1 = __low2float(b);
   float b2 = __high2float(b);
-  __half r1 = a1 < b1 ? __low2half(a) : __low2half(b);
-  __half r2 = a2 < b2 ? __high2half(a) : __high2half(b);
-  return __halves2half2(r1, r2);
+  __half r1 = a1 < b1 ? get_half2_low(a) : get_half2_low(b);
+  __half r2 = a2 < b2 ? get_half2_high(a) : get_half2_high(b);
+  return combine_half(r1, r2);
 }
 
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pmax(const half2& a,
                                                  const half2& b) {
   float a1 = __low2float(a);
   float a2 = __high2float(a);
   float b1 = __low2float(b);
   float b2 = __high2float(b);
-  __half r1 = a1 > b1 ? __low2half(a) : __low2half(b);
-  __half r2 = a2 > b2 ? __high2half(a) : __high2half(b);
-  return __halves2half2(r1, r2);
+  __half r1 = a1 > b1 ? get_half2_low(a) : get_half2_low(b);
+  __half r2 = a2 > b2 ? get_half2_high(a) : get_half2_high(b);
+  return combine_half(r1, r2);
 }
 
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Eigen::half predux(const half2& a) {
-#if defined(EIGEN_HIP_DEVICE_COMPILE)
-
-  return __hadd(__low2half(a), __high2half(a));
-
-#else  // EIGEN_CUDA_ARCH
-
-#if EIGEN_CUDA_ARCH >= 530
+#if defined(EIGEN_GPU_HAS_FP16_ARITHMETIC)
   return __hadd(__low2half(a), __high2half(a));
 #else
   float a1 = __low2float(a);
   float a2 = __high2float(a);
   return Eigen::half(__float2half(a1 + a2));
 #endif
-
-#endif
 }
 
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Eigen::half predux_max(const half2& a) {
-#if defined(EIGEN_HIP_DEVICE_COMPILE)
-
-  __half first = __low2half(a);
-  __half second = __high2half(a);
-  return __hgt(first, second) ? first : second;
-
-#else  // EIGEN_CUDA_ARCH
-
-#if EIGEN_CUDA_ARCH >= 530
+#if defined(EIGEN_GPU_HAS_FP16_ARITHMETIC)
   __half first = __low2half(a);
   __half second = __high2half(a);
   return __hgt(first, second) ? first : second;
 #else
   float a1 = __low2float(a);
   float a2 = __high2float(a);
-  return a1 > a2 ? __low2half(a) : __high2half(a);
-#endif
-
+  return a1 > a2 ? get_half2_low(a) : get_half2_high(a);
 #endif
 }
 
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Eigen::half predux_min(const half2& a) {
-#if defined(EIGEN_HIP_DEVICE_COMPILE)
-
-  __half first = __low2half(a);
-  __half second = __high2half(a);
-  return __hlt(first, second) ? first : second;
-
-#else  // EIGEN_CUDA_ARCH
-
-#if EIGEN_CUDA_ARCH >= 530
+#if defined(EIGEN_GPU_HAS_FP16_ARITHMETIC)
   __half first = __low2half(a);
   __half second = __high2half(a);
   return __hlt(first, second) ? first : second;
 #else
   float a1 = __low2float(a);
   float a2 = __high2float(a);
-  return a1 < a2 ? __low2half(a) : __high2half(a);
-#endif
-
+  return a1 < a2 ? get_half2_low(a) : get_half2_high(a);
 #endif
 }
 
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Eigen::half predux_mul(const half2& a) {
-#if defined(EIGEN_HIP_DEVICE_COMPILE)
-
-  return __hmul(__low2half(a), __high2half(a));
-
-#else  // EIGEN_CUDA_ARCH
-
-#if EIGEN_CUDA_ARCH >= 530
+#if defined(EIGEN_GPU_HAS_FP16_ARITHMETIC)
   return __hmul(__low2half(a), __high2half(a));
 #else
   float a1 = __low2float(a);
   float a2 = __high2float(a);
   return Eigen::half(__float2half(a1 * a2));
 #endif
-
-#endif
 }
 
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 plog1p(const half2& a) {
   float a1 = __low2float(a);
   float a2 = __high2float(a);
   float r1 = log1pf(a1);
   float r2 = log1pf(a2);
@@ -995,15 +923,15 @@
   float a1 = __low2float(a);
   float a2 = __high2float(a);
   float r1 = expm1f(a1);
   float r2 = expm1f(a2);
   return __floats2half2_rn(r1, r2);
 }
 
-#if (EIGEN_CUDA_SDK_VER >= 80000 && defined EIGEN_CUDA_ARCH && EIGEN_CUDA_ARCH >= 530) || \
+#if (EIGEN_CUDA_SDK_VER >= 80000 && defined(EIGEN_CUDA_HAS_FP16_ARITHMETIC)) || \
   defined(EIGEN_HIP_DEVICE_COMPILE)
 
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
 half2 plog(const half2& a) {
   return h2log(a);
 }
 
@@ -1104,36 +1032,27 @@
   pstoreu(to + 4,from_alias[2]);
   pstoreu(to + 6,from_alias[3]);
 }
 
 template <>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Packet4h2
 ploadt_ro<Packet4h2, Aligned>(const Eigen::half* from) {
-#if defined(EIGEN_HIP_DEVICE_COMPILE)
-
-  Packet4h2 r;
-  r = __ldg((const Packet4h2*)from);
-  return r;
-#else  // EIGEN_CUDA_ARCH
-
-#if EIGEN_CUDA_ARCH >= 350
+#if defined(EIGEN_GPU_HAS_LDG)
   Packet4h2 r;
-  r = __ldg((const Packet4h2*)from);
+  r = __ldg(reinterpret_cast<const Packet4h2*>(from));
   return r;
 #else
   Packet4h2 r;
   half2* r_alias = reinterpret_cast<half2*>(&r);
   r_alias[0] = ploadt_ro_aligned(from + 0);
   r_alias[1] = ploadt_ro_aligned(from + 2);
   r_alias[2] = ploadt_ro_aligned(from + 4);
   r_alias[3] = ploadt_ro_aligned(from + 6);
   return r;
 #endif
-
-#endif
 }
 
 template <>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Packet4h2
 ploadt_ro<Packet4h2, Unaligned>(const Eigen::half* from) {
   Packet4h2 r;
   half2* r_alias = reinterpret_cast<half2*>(&r);
@@ -1145,18 +1064,18 @@
 }
 
 template <>
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4h2
 pgather<Eigen::half, Packet4h2>(const Eigen::half* from, Index stride) {
   Packet4h2 r;
   half2* p_alias = reinterpret_cast<half2*>(&r);
-  p_alias[0] = __halves2half2(from[0 * stride], from[1 * stride]);
-  p_alias[1] = __halves2half2(from[2 * stride], from[3 * stride]);
-  p_alias[2] = __halves2half2(from[4 * stride], from[5 * stride]);
-  p_alias[3] = __halves2half2(from[6 * stride], from[7 * stride]);
+  p_alias[0] = combine_half(from[0 * stride], from[1 * stride]);
+  p_alias[1] = combine_half(from[2 * stride], from[3 * stride]);
+  p_alias[2] = combine_half(from[4 * stride], from[5 * stride]);
+  p_alias[3] = combine_half(from[6 * stride], from[7 * stride]);
   return r;
 }
 
 template <>
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void pscatter<Eigen::half, Packet4h2>(
     Eigen::half* to, const Packet4h2& from, Index stride) {
   const half2* from_alias = reinterpret_cast<const half2*>(&from);
@@ -1183,21 +1102,21 @@
   p_alias[2] = pabs(a_alias[2]);
   p_alias[3] = pabs(a_alias[3]);
   return r;
 }
 
 template <>
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4h2 ptrue<Packet4h2>(
-    const Packet4h2& a) {
+    const Packet4h2& /*a*/) {
   half true_half = half_impl::raw_uint16_to_half(0xffffu);
   return pset1<Packet4h2>(true_half);
 }
 
 template <>
-EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4h2 pzero<Packet4h2>(const Packet4h2& a) {
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4h2 pzero<Packet4h2>(const Packet4h2& /*a*/) {
   half false_half = half_impl::raw_uint16_to_half(0x0000u);
   return pset1<Packet4h2>(false_half);
 }
 
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void ptranspose_double(
     double* d_row0, double* d_row1, double* d_row2, double* d_row3,
     double* d_row4, double* d_row5, double* d_row6, double* d_row7) {
@@ -1229,20 +1148,20 @@
   f_tmp = f_row1[1];
   f_row1[1] = f_row3[0];
   f_row3[0] = f_tmp;
 }
 
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void
 ptranspose_half(half2& f0, half2& f1) {
-  __half a1 = __low2half(f0);
-  __half a2 = __high2half(f0);
-  __half b1 = __low2half(f1);
-  __half b2 = __high2half(f1);
-  f0 = __halves2half2(a1, b1);
-  f1 = __halves2half2(a2, b2);
+  __half a1 = get_half2_low(f0);
+  __half a2 = get_half2_high(f0);
+  __half b1 = get_half2_low(f1);
+  __half b2 = get_half2_high(f1);
+  f0 = combine_half(a1, b1);
+  f1 = combine_half(a2, b2);
 }
 
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void
 ptranspose(PacketBlock<Packet4h2,8>& kernel) {
   double* d_row0 = reinterpret_cast<double*>(&kernel.packet[0]);
   double* d_row1 = reinterpret_cast<double*>(&kernel.packet[1]);
   double* d_row2 = reinterpret_cast<double*>(&kernel.packet[2]);
@@ -1290,15 +1209,15 @@
   f_row2 = reinterpret_cast<half2*>(d_row6 + 1);
   f_row3 = reinterpret_cast<half2*>(d_row7 + 1);
   ptranspose_half2(f_row0, f_row1, f_row2, f_row3);
   ptranspose_half(f_row0[0], f_row1[0]);
   ptranspose_half(f_row0[1], f_row1[1]);
   ptranspose_half(f_row2[0], f_row3[0]);
   ptranspose_half(f_row2[1], f_row3[1]);
-  
+
 }
 
 template <>
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4h2
 plset<Packet4h2>(const Eigen::half& a) {
 #if defined(EIGEN_HIP_DEVICE_COMPILE)
 
@@ -1308,17 +1227,15 @@
   p_alias[1] = __halves2half2(__hadd(a, __float2half(2.0f)),
                               __hadd(a, __float2half(3.0f)));
   p_alias[2] = __halves2half2(__hadd(a, __float2half(4.0f)),
                               __hadd(a, __float2half(5.0f)));
   p_alias[3] = __halves2half2(__hadd(a, __float2half(6.0f)),
                               __hadd(a, __float2half(7.0f)));
   return r;
-#else  // EIGEN_CUDA_ARCH
-
-#if EIGEN_CUDA_ARCH >= 530
+#elif defined(EIGEN_CUDA_HAS_FP16_ARITHMETIC)
   Packet4h2 r;
   half2* r_alias = reinterpret_cast<half2*>(&r);
 
   half2 b = pset1<half2>(a);
   half2 c;
   half2 half_offset0 = __halves2half2(__float2half(0.0f),__float2half(2.0f));
   half2 half_offset1 = __halves2half2(__float2half(4.0f),__float2half(6.0f));
@@ -1333,22 +1250,20 @@
 
   return r;
 
 #else
   float f = __half2float(a);
   Packet4h2 r;
   half2* p_alias = reinterpret_cast<half2*>(&r);
-  p_alias[0] = __halves2half2(a, __float2half(f + 1.0f));
-  p_alias[1] = __halves2half2(__float2half(f + 2.0f), __float2half(f + 3.0f));
-  p_alias[2] = __halves2half2(__float2half(f + 4.0f), __float2half(f + 5.0f));
-  p_alias[3] = __halves2half2(__float2half(f + 6.0f), __float2half(f + 7.0f));
+  p_alias[0] = combine_half(a, __float2half(f + 1.0f));
+  p_alias[1] = combine_half(__float2half(f + 2.0f), __float2half(f + 3.0f));
+  p_alias[2] = combine_half(__float2half(f + 4.0f), __float2half(f + 5.0f));
+  p_alias[3] = combine_half(__float2half(f + 6.0f), __float2half(f + 7.0f));
   return r;
 #endif
-
-#endif
 }
 
 template <>
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4h2
 pselect<Packet4h2>(const Packet4h2& mask, const Packet4h2& a,
                    const Packet4h2& b) {
   Packet4h2 r;
@@ -1558,40 +1473,40 @@
          predux(a_alias[2]) + predux(a_alias[3]);
 }
 
 template <>
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Eigen::half predux_max<Packet4h2>(
     const Packet4h2& a) {
   const half2* a_alias = reinterpret_cast<const half2*>(&a);
-  half2 m0 = __halves2half2(predux_max(a_alias[0]),
+  half2 m0 = combine_half(predux_max(a_alias[0]),
                             predux_max(a_alias[1]));
-  half2 m1 = __halves2half2(predux_max(a_alias[2]),
+  half2 m1 = combine_half(predux_max(a_alias[2]),
                             predux_max(a_alias[3]));
   __half first  = predux_max(m0);
   __half second = predux_max(m1);
-#if EIGEN_CUDA_ARCH >= 530
+#if defined(EIGEN_CUDA_HAS_FP16_ARITHMETIC)
   return (__hgt(first, second) ? first : second);
 #else
   float ffirst  = __half2float(first);
   float fsecond = __half2float(second);
   return (ffirst > fsecond)? first: second;
 #endif
 }
 
 template <>
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Eigen::half predux_min<Packet4h2>(
     const Packet4h2& a) {
   const half2* a_alias = reinterpret_cast<const half2*>(&a);
-  half2 m0 = __halves2half2(predux_min(a_alias[0]),
+  half2 m0 = combine_half(predux_min(a_alias[0]),
                             predux_min(a_alias[1]));
-  half2 m1 = __halves2half2(predux_min(a_alias[2]),
+  half2 m1 = combine_half(predux_min(a_alias[2]),
                             predux_min(a_alias[3]));
   __half first  = predux_min(m0);
   __half second = predux_min(m1);
-#if EIGEN_CUDA_ARCH >= 530
+#if defined(EIGEN_CUDA_HAS_FP16_ARITHMETIC)
   return (__hlt(first, second) ? first : second);
 #else
   float ffirst  = __half2float(first);
   float fsecond = __half2float(second);
   return (ffirst < fsecond)? first: second;
 #endif
 }
@@ -1681,106 +1596,90 @@
 }
 
 // The following specialized padd, pmul, pdiv, pmin, pmax, pset1 are needed for
 // the implementation of GPU half reduction.
 template<>
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 padd<half2>(const half2& a,
                                                         const half2& b) {
-#if defined(EIGEN_HIP_DEVICE_COMPILE)
-
-  return __hadd2(a, b);
-
-#else  // EIGEN_CUDA_ARCH
-
-#if EIGEN_CUDA_ARCH >= 530
+#if defined(EIGEN_GPU_HAS_FP16_ARITHMETIC)
   return __hadd2(a, b);
 #else
   float a1 = __low2float(a);
   float a2 = __high2float(a);
   float b1 = __low2float(b);
   float b2 = __high2float(b);
   float r1 = a1 + b1;
   float r2 = a2 + b2;
   return __floats2half2_rn(r1, r2);
 #endif
-
-#endif
 }
 
 template<>
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pmul<half2>(const half2& a,
                                                         const half2& b) {
-#if defined(EIGEN_HIP_DEVICE_COMPILE)
-
-  return __hmul2(a, b);
-
-#else  // EIGEN_CUDA_ARCH
-
-#if EIGEN_CUDA_ARCH >= 530
+#if defined(EIGEN_GPU_HAS_FP16_ARITHMETIC)
   return __hmul2(a, b);
 #else
   float a1 = __low2float(a);
   float a2 = __high2float(a);
   float b1 = __low2float(b);
   float b2 = __high2float(b);
   float r1 = a1 * b1;
   float r2 = a2 * b2;
   return __floats2half2_rn(r1, r2);
 #endif
-
-#endif
 }
 
 template<>
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pdiv<half2>(const half2& a,
                                                         const half2& b) {
-#if defined(EIGEN_HIP_DEVICE_COMPILE)
-
+#if defined(EIGEN_GPU_HAS_FP16_ARITHMETIC)
   return __h2div(a, b);
-
-#else // EIGEN_CUDA_ARCH
-
+#else
   float a1 = __low2float(a);
   float a2 = __high2float(a);
   float b1 = __low2float(b);
   float b2 = __high2float(b);
   float r1 = a1 / b1;
   float r2 = a2 / b2;
   return __floats2half2_rn(r1, r2);
-
 #endif
 }
 
 template<>
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pmin<half2>(const half2& a,
                                                         const half2& b) {
   float a1 = __low2float(a);
   float a2 = __high2float(a);
   float b1 = __low2float(b);
   float b2 = __high2float(b);
-  __half r1 = a1 < b1 ? __low2half(a) : __low2half(b);
-  __half r2 = a2 < b2 ? __high2half(a) : __high2half(b);
-  return __halves2half2(r1, r2);
+  __half r1 = a1 < b1 ? get_half2_low(a) : get_half2_low(b);
+  __half r2 = a2 < b2 ? get_half2_high(a) : get_half2_high(b);
+  return combine_half(r1, r2);
 }
 
 template<>
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pmax<half2>(const half2& a,
                                                         const half2& b) {
   float a1 = __low2float(a);
   float a2 = __high2float(a);
   float b1 = __low2float(b);
   float b2 = __high2float(b);
-  __half r1 = a1 > b1 ? __low2half(a) : __low2half(b);
-  __half r2 = a2 > b2 ? __high2half(a) : __high2half(b);
-  return __halves2half2(r1, r2);
+  __half r1 = a1 > b1 ? get_half2_low(a) : get_half2_low(b);
+  __half r2 = a2 > b2 ? get_half2_high(a) : get_half2_high(b);
+  return combine_half(r1, r2);
 }
 
-#endif // defined(EIGEN_CUDA_ARCH)
+// #endif // defined(EIGEN_CUDA_ARCH) || defined(EIGEN_HIPCC) || (defined(EIGEN_CUDACC) && EIGEN_COMP_CLANG && !EIGEN_COMP_NVCC)
+
+#endif // defined(EIGEN_HAS_CUDA_FP16) || defined(EIGEN_HAS_HIP_FP16)
 
-#endif // defined(EIGEN_HAS_CUDA_FP16) && defined(EIGEN_CUDACC)
+#undef EIGEN_GPU_HAS_LDG
+#undef EIGEN_CUDA_HAS_FP16_ARITHMETIC
+#undef EIGEN_GPU_HAS_FP16_ARITHMETIC
 
 } // end namespace internal
 
 } // end namespace Eigen
 
 
 #endif // EIGEN_PACKET_MATH_GPU_H
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/GPU/TypeCasting.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/GPU/TypeCasting.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/HIP/hcc/math_constants.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/HIP/hcc/math_constants.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/MSA/Complex.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/MSA/Complex.h`

 * *Files 22% similar despite different names*

```diff
@@ -301,50 +301,14 @@
 EIGEN_STRONG_INLINE std::complex<float> predux_mul<Packet2cf>(const Packet2cf& a) {
   EIGEN_MSA_DEBUG;
 
   return std::complex<float>((a.v[0] * a.v[2]) - (a.v[1] * a.v[3]),
                              (a.v[0] * a.v[3]) + (a.v[1] * a.v[2]));
 }
 
-template <>
-struct conj_helper<Packet2cf, Packet2cf, false, true> {
-  EIGEN_STRONG_INLINE Packet2cf pmadd(const Packet2cf& x, const Packet2cf& y,
-                                      const Packet2cf& c) const {
-    return padd(pmul(x, y), c);
-  }
-
-  EIGEN_STRONG_INLINE Packet2cf pmul(const Packet2cf& a, const Packet2cf& b) const {
-    return internal::pmul(a, pconj(b));
-  }
-};
-
-template <>
-struct conj_helper<Packet2cf, Packet2cf, true, false> {
-  EIGEN_STRONG_INLINE Packet2cf pmadd(const Packet2cf& x, const Packet2cf& y,
-                                      const Packet2cf& c) const {
-    return padd(pmul(x, y), c);
-  }
-
-  EIGEN_STRONG_INLINE Packet2cf pmul(const Packet2cf& a, const Packet2cf& b) const {
-    return internal::pmul(pconj(a), b);
-  }
-};
-
-template <>
-struct conj_helper<Packet2cf, Packet2cf, true, true> {
-  EIGEN_STRONG_INLINE Packet2cf pmadd(const Packet2cf& x, const Packet2cf& y,
-                                      const Packet2cf& c) const {
-    return padd(pmul(x, y), c);
-  }
-
-  EIGEN_STRONG_INLINE Packet2cf pmul(const Packet2cf& a, const Packet2cf& b) const {
-    return pconj(internal::pmul(a, b));
-  }
-};
-
 EIGEN_MAKE_CONJ_HELPER_CPLX_REAL(Packet2cf, Packet4f)
 
 template <>
 EIGEN_STRONG_INLINE Packet2cf pdiv<Packet2cf>(const Packet2cf& a, const Packet2cf& b) {
   EIGEN_MSA_DEBUG;
 
   return a / b;
@@ -640,50 +604,14 @@
 template <>
 EIGEN_STRONG_INLINE std::complex<double> predux_mul<Packet1cd>(const Packet1cd& a) {
   EIGEN_MSA_DEBUG;
 
   return pfirst(a);
 }
 
-template <>
-struct conj_helper<Packet1cd, Packet1cd, false, true> {
-  EIGEN_STRONG_INLINE Packet1cd pmadd(const Packet1cd& x, const Packet1cd& y,
-                                      const Packet1cd& c) const {
-    return padd(pmul(x, y), c);
-  }
-
-  EIGEN_STRONG_INLINE Packet1cd pmul(const Packet1cd& a, const Packet1cd& b) const {
-    return internal::pmul(a, pconj(b));
-  }
-};
-
-template <>
-struct conj_helper<Packet1cd, Packet1cd, true, false> {
-  EIGEN_STRONG_INLINE Packet1cd pmadd(const Packet1cd& x, const Packet1cd& y,
-                                      const Packet1cd& c) const {
-    return padd(pmul(x, y), c);
-  }
-
-  EIGEN_STRONG_INLINE Packet1cd pmul(const Packet1cd& a, const Packet1cd& b) const {
-    return internal::pmul(pconj(a), b);
-  }
-};
-
-template <>
-struct conj_helper<Packet1cd, Packet1cd, true, true> {
-  EIGEN_STRONG_INLINE Packet1cd pmadd(const Packet1cd& x, const Packet1cd& y,
-                                      const Packet1cd& c) const {
-    return padd(pmul(x, y), c);
-  }
-
-  EIGEN_STRONG_INLINE Packet1cd pmul(const Packet1cd& a, const Packet1cd& b) const {
-    return pconj(internal::pmul(a, b));
-  }
-};
-
 EIGEN_MAKE_CONJ_HELPER_CPLX_REAL(Packet1cd, Packet2d)
 
 template <>
 EIGEN_STRONG_INLINE Packet1cd pdiv<Packet1cd>(const Packet1cd& a, const Packet1cd& b) {
   EIGEN_MSA_DEBUG;
 
   return a / b;
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/MSA/MathFunctions.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/MSA/MathFunctions.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/MSA/PacketMath.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/MSA/PacketMath.h`

 * *Files 1% similar despite different names*

```diff
@@ -24,18 +24,14 @@
 #define EIGEN_CACHEFRIENDLY_PRODUCT_THRESHOLD 8
 #endif
 
 #ifndef EIGEN_HAS_SINGLE_INSTRUCTION_MADD
 #define EIGEN_HAS_SINGLE_INSTRUCTION_MADD
 #endif
 
-#ifndef EIGEN_HAS_SINGLE_INSTRUCTION_CJMADD
-#define EIGEN_HAS_SINGLE_INSTRUCTION_CJMADD
-#endif
-
 #ifndef EIGEN_ARCH_DEFAULT_NUMBER_OF_REGISTERS
 #define EIGEN_ARCH_DEFAULT_NUMBER_OF_REGISTERS 32
 #endif
 
 #if 0
 #define EIGEN_MSA_DEBUG                                                             \
   static bool firstTime = true;                                                     \
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/NEON/Complex.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/NEON/Complex.h`

 * *Files 7% similar despite different names*

```diff
@@ -14,15 +14,15 @@
 namespace Eigen {
 
 namespace internal {
 
 inline uint32x4_t p4ui_CONJ_XOR()
 {
 // See bug 1325, clang fails to call vld1q_u64.
-#if EIGEN_COMP_CLANG
+#if EIGEN_COMP_CLANG || EIGEN_COMP_CASTXML
   uint32x4_t ret = { 0x00000000, 0x80000000, 0x00000000, 0x80000000 };
   return ret;
 #else
   static const uint32_t conj_XOR_DATA[] = { 0x00000000, 0x80000000, 0x00000000, 0x80000000 };
   return vld1q_u32( conj_XOR_DATA );
 #endif
 }
@@ -72,27 +72,29 @@
   };
 };
 
 template<> struct unpacket_traits<Packet1cf>
 {
   typedef std::complex<float> type;
   typedef Packet1cf half;
+  typedef Packet2f as_real;
   enum
   {
     size = 1,
     alignment = Aligned16,
     vectorizable = true,
     masked_load_available = false,
     masked_store_available = false
   };
 };
 template<> struct unpacket_traits<Packet2cf>
 {
   typedef std::complex<float> type;
   typedef Packet1cf half;
+  typedef Packet4f as_real;
   enum
   {
     size = 2,
     alignment = Aligned16,
     vectorizable = true,
     masked_load_available = false,
     masked_store_available = false
@@ -336,87 +338,33 @@
   prod = vadd_f32(v1, v2);
 
   vst1_f32(reinterpret_cast<float*>(&s), prod);
 
   return s;
 }
 
-template<> struct conj_helper<Packet1cf,Packet1cf,false,true>
-{
-  EIGEN_STRONG_INLINE Packet1cf pmadd(const Packet1cf& x, const Packet1cf& y, const Packet1cf& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet1cf pmul(const Packet1cf& a, const Packet1cf& b) const
-  { return internal::pmul(a, pconj(b)); }
-};
-
-template<> struct conj_helper<Packet1cf,Packet1cf,true,false>
-{
-  EIGEN_STRONG_INLINE Packet1cf pmadd(const Packet1cf& x, const Packet1cf& y, const Packet1cf& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet1cf pmul(const Packet1cf& a, const Packet1cf& b) const
-  { return internal::pmul(pconj(a), b); }
-};
-
-template<> struct conj_helper<Packet1cf,Packet1cf,true,true>
-{
-  EIGEN_STRONG_INLINE Packet1cf pmadd(const Packet1cf& x, const Packet1cf& y, const Packet1cf& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet1cf pmul(const Packet1cf& a, const Packet1cf& b) const
-  { return pconj(internal::pmul(a,b)); }
-};
-
-template<> struct conj_helper<Packet2cf,Packet2cf,false,true>
-{
-  EIGEN_STRONG_INLINE Packet2cf pmadd(const Packet2cf& x, const Packet2cf& y, const Packet2cf& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet2cf pmul(const Packet2cf& a, const Packet2cf& b) const
-  { return internal::pmul(a, pconj(b)); }
-};
-
-template<> struct conj_helper<Packet2cf,Packet2cf,true,false>
-{
-  EIGEN_STRONG_INLINE Packet2cf pmadd(const Packet2cf& x, const Packet2cf& y, const Packet2cf& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet2cf pmul(const Packet2cf& a, const Packet2cf& b) const
-  { return internal::pmul(pconj(a), b); }
-};
-
-template<> struct conj_helper<Packet2cf,Packet2cf,true,true>
-{
-  EIGEN_STRONG_INLINE Packet2cf pmadd(const Packet2cf& x, const Packet2cf& y, const Packet2cf& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet2cf pmul(const Packet2cf& a, const Packet2cf& b) const
-  { return pconj(internal::pmul(a,b)); }
-};
-
 EIGEN_MAKE_CONJ_HELPER_CPLX_REAL(Packet1cf,Packet2f)
 EIGEN_MAKE_CONJ_HELPER_CPLX_REAL(Packet2cf,Packet4f)
 
 template<> EIGEN_STRONG_INLINE Packet1cf pdiv<Packet1cf>(const Packet1cf& a, const Packet1cf& b)
 {
   // TODO optimize it for NEON
-  Packet1cf res = conj_helper<Packet1cf, Packet1cf, false, true>().pmul(a,b);
+  Packet1cf res = pmul(a, pconj(b));
   Packet2f s, rev_s;
 
   // this computes the norm
   s = vmul_f32(b.v, b.v);
   rev_s = vrev64_f32(s);
 
   return Packet1cf(pdiv<Packet2f>(res.v, vadd_f32(s, rev_s)));
 }
 template<> EIGEN_STRONG_INLINE Packet2cf pdiv<Packet2cf>(const Packet2cf& a, const Packet2cf& b)
 {
   // TODO optimize it for NEON
-  Packet2cf res = conj_helper<Packet2cf, Packet2cf, false, true>().pmul(a,b);
+  Packet2cf res = pmul(a,pconj(b));
   Packet4f s, rev_s;
 
   // this computes the norm
   s = vmulq_f32(b.v, b.v);
   rev_s = vrev64q_f32(s);
 
   return Packet2cf(pdiv<Packet4f>(res.v, vaddq_f32(s, rev_s)));
@@ -426,19 +374,27 @@
 EIGEN_DEVICE_FUNC inline void ptranspose(PacketBlock<Packet2cf, 2>& kernel)
 {
   Packet4f tmp = vcombine_f32(vget_high_f32(kernel.packet[0].v), vget_high_f32(kernel.packet[1].v));
   kernel.packet[0].v = vcombine_f32(vget_low_f32(kernel.packet[0].v), vget_low_f32(kernel.packet[1].v));
   kernel.packet[1].v = tmp;
 }
 
+template<> EIGEN_STRONG_INLINE Packet1cf psqrt<Packet1cf>(const Packet1cf& a) {
+  return psqrt_complex<Packet1cf>(a);
+}
+
+template<> EIGEN_STRONG_INLINE Packet2cf psqrt<Packet2cf>(const Packet2cf& a) {
+  return psqrt_complex<Packet2cf>(a);
+}
+
 //---------- double ----------
 #if EIGEN_ARCH_ARM64 && !EIGEN_APPLE_DOUBLE_NEON_BUG
 
 // See bug 1325, clang fails to call vld1q_u64.
-#if EIGEN_COMP_CLANG
+#if EIGEN_COMP_CLANG || EIGEN_COMP_CASTXML
   static uint64x2_t p2ul_CONJ_XOR = {0x0, 0x8000000000000000};
 #else
   const uint64_t  p2ul_conj_XOR_DATA[] = { 0x0, 0x8000000000000000 };
   static uint64x2_t p2ul_CONJ_XOR = vld1q_u64( p2ul_conj_XOR_DATA );
 #endif
 
 struct Packet1cd
@@ -471,23 +427,24 @@
     HasSetLinear = 0
   };
 };
 
 template<> struct unpacket_traits<Packet1cd>
 {
   typedef std::complex<double> type;
+  typedef Packet1cd half;
+  typedef Packet2d as_real;
   enum
   {
     size=1,
     alignment=Aligned16,
     vectorizable=true,
     masked_load_available=false,
     masked_store_available=false
   };
-  typedef Packet1cd half;
 };
 
 template<> EIGEN_STRONG_INLINE Packet1cd pload<Packet1cd>(const std::complex<double>* from)
 { EIGEN_DEBUG_ALIGNED_LOAD return Packet1cd(pload<Packet2d>(reinterpret_cast<const double*>(from))); }
 
 template<> EIGEN_STRONG_INLINE Packet1cd ploadu<Packet1cd>(const std::complex<double>* from)
 { EIGEN_DEBUG_UNALIGNED_LOAD return Packet1cd(ploadu<Packet2d>(reinterpret_cast<const double*>(from))); }
@@ -588,47 +545,20 @@
 
 template<> EIGEN_STRONG_INLINE Packet1cd preverse(const Packet1cd& a) { return a; }
 
 template<> EIGEN_STRONG_INLINE std::complex<double> predux<Packet1cd>(const Packet1cd& a) { return pfirst(a); }
 
 template<> EIGEN_STRONG_INLINE std::complex<double> predux_mul<Packet1cd>(const Packet1cd& a) { return pfirst(a); }
 
-template<> struct conj_helper<Packet1cd, Packet1cd, false,true>
-{
-  EIGEN_STRONG_INLINE Packet1cd pmadd(const Packet1cd& x, const Packet1cd& y, const Packet1cd& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet1cd pmul(const Packet1cd& a, const Packet1cd& b) const
-  { return internal::pmul(a, pconj(b)); }
-};
-
-template<> struct conj_helper<Packet1cd, Packet1cd, true,false>
-{
-  EIGEN_STRONG_INLINE Packet1cd pmadd(const Packet1cd& x, const Packet1cd& y, const Packet1cd& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet1cd pmul(const Packet1cd& a, const Packet1cd& b) const
-  { return internal::pmul(pconj(a), b); }
-};
-
-template<> struct conj_helper<Packet1cd, Packet1cd, true,true>
-{
-  EIGEN_STRONG_INLINE Packet1cd pmadd(const Packet1cd& x, const Packet1cd& y, const Packet1cd& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet1cd pmul(const Packet1cd& a, const Packet1cd& b) const
-  { return pconj(internal::pmul(a,b)); }
-};
-
 EIGEN_MAKE_CONJ_HELPER_CPLX_REAL(Packet1cd,Packet2d)
 
 template<> EIGEN_STRONG_INLINE Packet1cd pdiv<Packet1cd>(const Packet1cd& a, const Packet1cd& b)
 {
   // TODO optimize it for NEON
-  Packet1cd res = conj_helper<Packet1cd,Packet1cd,false,true>().pmul(a,b);
+  Packet1cd res = pmul(a,pconj(b));
   Packet2d s = pmul<Packet2d>(b.v, b.v);
   Packet2d rev_s = preverse<Packet2d>(s);
 
   return Packet1cd(pdiv(res.v, padd<Packet2d>(s,rev_s)));
 }
 
 EIGEN_STRONG_INLINE Packet1cd pcplxflip/*<Packet1cd>*/(const Packet1cd& x)
@@ -636,14 +566,19 @@
 
 EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet1cd,2>& kernel)
 {
   Packet2d tmp = vcombine_f64(vget_high_f64(kernel.packet[0].v), vget_high_f64(kernel.packet[1].v));
   kernel.packet[0].v = vcombine_f64(vget_low_f64(kernel.packet[0].v), vget_low_f64(kernel.packet[1].v));
   kernel.packet[1].v = tmp;
 }
+
+template<> EIGEN_STRONG_INLINE Packet1cd psqrt<Packet1cd>(const Packet1cd& a) {
+  return psqrt_complex<Packet1cd>(a);
+}
+
 #endif // EIGEN_ARCH_ARM64
 
 } // end namespace internal
 
 } // end namespace Eigen
 
 #endif // EIGEN_COMPLEX_NEON_H
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/NEON/MathFunctions.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/NEON/MathFunctions.h`

 * *Files 24% similar despite different names*

```diff
@@ -40,12 +40,36 @@
 
 BF16_PACKET_FUNCTION(Packet4f, Packet4bf, psin)
 BF16_PACKET_FUNCTION(Packet4f, Packet4bf, pcos)
 BF16_PACKET_FUNCTION(Packet4f, Packet4bf, plog)
 BF16_PACKET_FUNCTION(Packet4f, Packet4bf, pexp)
 BF16_PACKET_FUNCTION(Packet4f, Packet4bf, ptanh)
 
+template <>
+EIGEN_STRONG_INLINE Packet4bf pfrexp(const Packet4bf& a, Packet4bf& exponent) {
+  Packet4f fexponent;
+  const Packet4bf out = F32ToBf16(pfrexp<Packet4f>(Bf16ToF32(a), fexponent));
+  exponent = F32ToBf16(fexponent);
+  return out;
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet4bf pldexp(const Packet4bf& a, const Packet4bf& exponent) {
+  return F32ToBf16(pldexp<Packet4f>(Bf16ToF32(a), Bf16ToF32(exponent)));
+}
+
+//---------- double ----------
+
+#if EIGEN_ARCH_ARM64 && !EIGEN_APPLE_DOUBLE_NEON_BUG
+template<> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED Packet2d pexp<Packet2d>(const Packet2d& x)
+{ return pexp_double(x); }
+
+template<> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED Packet2d plog<Packet2d>(const Packet2d& x)
+{ return plog_double(x); }
+
+#endif
+
 } // end namespace internal
 
 } // end namespace Eigen
 
 #endif // EIGEN_MATH_FUNCTIONS_NEON_H
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/NEON/PacketMath.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/NEON/PacketMath.h`

 * *Files 10% similar despite different names*

```diff
@@ -20,27 +20,23 @@
 #define EIGEN_CACHEFRIENDLY_PRODUCT_THRESHOLD 8
 #endif
 
 #ifndef EIGEN_HAS_SINGLE_INSTRUCTION_MADD
 #define EIGEN_HAS_SINGLE_INSTRUCTION_MADD
 #endif
 
-#ifndef EIGEN_HAS_SINGLE_INSTRUCTION_CJMADD
-#define EIGEN_HAS_SINGLE_INSTRUCTION_CJMADD
-#endif
-
 #ifndef EIGEN_ARCH_DEFAULT_NUMBER_OF_REGISTERS
 #if EIGEN_ARCH_ARM64
 #define EIGEN_ARCH_DEFAULT_NUMBER_OF_REGISTERS 32
 #else
 #define EIGEN_ARCH_DEFAULT_NUMBER_OF_REGISTERS 16
 #endif
 #endif
 
-#if EIGEN_COMP_MSVC
+#if EIGEN_COMP_MSVC_STRICT
 
 // In MSVC's arm_neon.h header file, all NEON vector types
 // are aliases to the same underlying type __n128.
 // We thus have to wrap them to make them different C++ types.
 // (See also bug 1428)
 typedef eigen_packet_wrapper<float32x2_t,0>  Packet2f;
 typedef eigen_packet_wrapper<float32x4_t,1>  Packet4f;
@@ -78,15 +74,72 @@
 typedef int32x2_t                            Packet2i;
 typedef int32x4_t                            Packet4i;
 typedef uint32x2_t                           Packet2ui;
 typedef uint32x4_t                           Packet4ui;
 typedef int64x2_t                            Packet2l;
 typedef uint64x2_t                           Packet2ul;
 
-#endif // EIGEN_COMP_MSVC
+#endif // EIGEN_COMP_MSVC_STRICT
+
+EIGEN_STRONG_INLINE Packet4f shuffle1(const Packet4f& m, int mask){
+  const float* a = reinterpret_cast<const float*>(&m);
+  Packet4f res = {*(a + (mask & 3)), *(a + ((mask >> 2) & 3)), *(a + ((mask >> 4) & 3 )), *(a + ((mask >> 6) & 3))};
+  return res;
+}
+
+// fuctionally equivalent to _mm_shuffle_ps in SSE when interleave
+// == false (i.e. shuffle<false>(m, n, mask) equals _mm_shuffle_ps(m, n, mask)),
+// interleave m and n when interleave == true. Currently used in LU/arch/InverseSize4.h
+// to enable a shared implementation for fast inversion of matrices of size 4. 
+template<bool interleave> 
+EIGEN_STRONG_INLINE Packet4f shuffle2(const Packet4f &m, const Packet4f &n, int mask)
+{
+  const float* a = reinterpret_cast<const float*>(&m);
+  const float* b = reinterpret_cast<const float*>(&n);
+  Packet4f res = {*(a + (mask & 3)), *(a + ((mask >> 2) & 3)), *(b + ((mask >> 4) & 3)), *(b + ((mask >> 6) & 3))};
+  return res;
+}
+
+template<> 
+EIGEN_STRONG_INLINE Packet4f shuffle2<true>(const Packet4f &m, const Packet4f &n, int mask) 
+{
+  const float* a = reinterpret_cast<const float*>(&m);
+  const float* b = reinterpret_cast<const float*>(&n);
+  Packet4f res = {*(a + (mask & 3)), *(b + ((mask >> 2) & 3)), *(a + ((mask >> 4) & 3)), *(b + ((mask >> 6) & 3))};
+  return res;
+}
+
+EIGEN_STRONG_INLINE static int eigen_neon_shuffle_mask(int p, int q, int r, int s) {return ((s)<<6|(r)<<4|(q)<<2|(p));}
+
+EIGEN_STRONG_INLINE Packet4f vec4f_swizzle1(const Packet4f& a, int p, int q, int r, int s)
+{ 
+  return shuffle1(a, eigen_neon_shuffle_mask(p, q, r, s));
+}
+EIGEN_STRONG_INLINE Packet4f vec4f_swizzle2(const Packet4f& a, const Packet4f& b, int p, int q, int r, int s)
+{ 
+  return shuffle2<false>(a,b,eigen_neon_shuffle_mask(p, q, r, s));
+}
+EIGEN_STRONG_INLINE Packet4f vec4f_movelh(const Packet4f& a, const Packet4f& b)
+{
+  return shuffle2<false>(a,b,eigen_neon_shuffle_mask(0, 1, 0, 1));
+}
+EIGEN_STRONG_INLINE Packet4f vec4f_movehl(const Packet4f& a, const Packet4f& b)
+{
+  return shuffle2<false>(b,a,eigen_neon_shuffle_mask(2, 3, 2, 3));
+}
+EIGEN_STRONG_INLINE Packet4f vec4f_unpacklo(const Packet4f& a, const Packet4f& b)
+{
+  return shuffle2<true>(a,b,eigen_neon_shuffle_mask(0, 0, 1, 1));
+}
+EIGEN_STRONG_INLINE Packet4f vec4f_unpackhi(const Packet4f& a, const Packet4f& b)
+{
+  return shuffle2<true>(a,b,eigen_neon_shuffle_mask(2, 2, 3, 3));
+}
+#define vec4f_duplane(a, p) \
+  vdupq_lane_f32(vget_low_f32(a), p)
 
 #define _EIGEN_DECLARE_CONST_Packet4f(NAME,X) \
   const Packet4f p4f_##NAME = pset1<Packet4f>(X)
 
 #define _EIGEN_DECLARE_CONST_Packet4f_FROM_INT(NAME,X) \
   const Packet4f p4f_##NAME = vreinterpretq_f32_u32(pset1<int32_t>(X))
 
@@ -133,23 +186,28 @@
     HasMin       = 1,
     HasMax       = 1,
     HasConj      = 1,
     HasSetLinear = 0,
     HasBlend     = 0,
 
     HasDiv   = 1,
-    HasFloor = 0,
+    HasFloor = 1,
+    HasCeil = 1,
+    HasRint = 1,
 
     HasSin  = EIGEN_FAST_MATH,
     HasCos  = EIGEN_FAST_MATH,
     HasLog  = 1,
     HasExp  = 1,
-    HasSqrt = 0,
+    HasSqrt = 1,
+    HasRsqrt = 1,
     HasTanh = EIGEN_FAST_MATH,
-    HasErf  = EIGEN_FAST_MATH
+    HasErf  = EIGEN_FAST_MATH,
+    HasBessel = 0,  // Issues with accuracy.
+    HasNdtri = 0
   };
 };
 
 template <>
 struct packet_traits<int8_t> : default_packet_traits
 {
   typedef Packet16c type;
@@ -798,14 +856,25 @@
 template<> EIGEN_STRONG_INLINE Packet2i psub<Packet2i>(const Packet2i& a, const Packet2i& b) { return vsub_s32(a,b); }
 template<> EIGEN_STRONG_INLINE Packet4i psub<Packet4i>(const Packet4i& a, const Packet4i& b) { return vsubq_s32(a,b); }
 template<> EIGEN_STRONG_INLINE Packet2ui psub<Packet2ui>(const Packet2ui& a, const Packet2ui& b) { return vsub_u32(a,b); }
 template<> EIGEN_STRONG_INLINE Packet4ui psub<Packet4ui>(const Packet4ui& a, const Packet4ui& b) { return vsubq_u32(a,b); }
 template<> EIGEN_STRONG_INLINE Packet2l psub<Packet2l>(const Packet2l& a, const Packet2l& b) { return vsubq_s64(a,b); }
 template<> EIGEN_STRONG_INLINE Packet2ul psub<Packet2ul>(const Packet2ul& a, const Packet2ul& b) { return vsubq_u64(a,b); }
 
+template<> EIGEN_STRONG_INLINE Packet2f pxor<Packet2f>(const Packet2f& a, const Packet2f& b);
+template<> EIGEN_STRONG_INLINE Packet2f paddsub<Packet2f>(const Packet2f& a, const Packet2f & b) {
+  Packet2f mask = {numext::bit_cast<float>(0x80000000u), 0.0f};
+  return padd(a, pxor(mask, b));
+}
+template<> EIGEN_STRONG_INLINE Packet4f pxor<Packet4f>(const Packet4f& a, const Packet4f& b);
+template<> EIGEN_STRONG_INLINE Packet4f paddsub<Packet4f>(const Packet4f& a, const Packet4f& b) {
+  Packet4f mask = {numext::bit_cast<float>(0x80000000u), 0.0f, numext::bit_cast<float>(0x80000000u), 0.0f};
+  return padd(a, pxor(mask, b));
+}
+
 template<> EIGEN_STRONG_INLINE Packet2f pnegate(const Packet2f& a) { return vneg_f32(a); }
 template<> EIGEN_STRONG_INLINE Packet4f pnegate(const Packet4f& a) { return vnegq_f32(a); }
 template<> EIGEN_STRONG_INLINE Packet4c pnegate(const Packet4c& a)
 { return vget_lane_s32(vreinterpret_s32_s8(vneg_s8(vreinterpret_s8_s32(vdup_n_s32(a)))), 0); }
 template<> EIGEN_STRONG_INLINE Packet8c pnegate(const Packet8c& a) { return vneg_s8(a); }
 template<> EIGEN_STRONG_INLINE Packet16c pnegate(const Packet16c& a) { return vnegq_s8(a); }
 template<> EIGEN_STRONG_INLINE Packet4s pnegate(const Packet4s& a) { return vneg_s16(a); }
@@ -1006,51 +1075,24 @@
 }
 template<> EIGEN_STRONG_INLINE Packet2ul pdiv<Packet2ul>(const Packet2ul& /*a*/, const Packet2ul& /*b*/)
 {
   eigen_assert(false && "packet integer division are not supported by NEON");
   return pset1<Packet2ul>(0ULL);
 }
 
-// Clang/ARM wrongly advertises __ARM_FEATURE_FMA even when it's not available,
-// then implements a slow software scalar fallback calling fmaf()!
-// Filed LLVM bug:
-//     https://llvm.org/bugs/show_bug.cgi?id=27216
-#if (defined __ARM_FEATURE_FMA) && !(EIGEN_COMP_CLANG && EIGEN_ARCH_ARM)
-// See bug 936.
-// FMA is available on VFPv4 i.e. when compiling with -mfpu=neon-vfpv4.
-// FMA is a true fused multiply-add i.e. only 1 rounding at the end, no intermediate rounding.
-// MLA is not fused i.e. does 2 roundings.
-// In addition to giving better accuracy, FMA also gives better performance here on a Krait (Nexus 4):
-// MLA: 10 GFlop/s ; FMA: 12 GFlops/s.
+
+#ifdef __ARM_FEATURE_FMA
 template<> EIGEN_STRONG_INLINE Packet4f pmadd(const Packet4f& a, const Packet4f& b, const Packet4f& c)
 { return vfmaq_f32(c,a,b); }
 template<> EIGEN_STRONG_INLINE Packet2f pmadd(const Packet2f& a, const Packet2f& b, const Packet2f& c)
 { return vfma_f32(c,a,b); }
 #else
 template<> EIGEN_STRONG_INLINE Packet4f pmadd(const Packet4f& a, const Packet4f& b, const Packet4f& c)
 {
-#if EIGEN_COMP_CLANG && EIGEN_ARCH_ARM
-  // Clang/ARM will replace VMLA by VMUL+VADD at least for some values of -mcpu,
-  // at least -mcpu=cortex-a8 and -mcpu=cortex-a7. Since the former is the default on
-  // -march=armv7-a, that is a very common case.
-  // See e.g. this thread:
-  //     http://lists.llvm.org/pipermail/llvm-dev/2013-December/068806.html
-  // Filed LLVM bug:
-  //     https://llvm.org/bugs/show_bug.cgi?id=27219
-  Packet4f r = c;
-  asm volatile(
-    "vmla.f32 %q[r], %q[a], %q[b]"
-    : [r] "+w" (r)
-    : [a] "w" (a),
-      [b] "w" (b)
-    : );
-  return r;
-#else
   return vmlaq_f32(c,a,b);
-#endif
 }
 template<> EIGEN_STRONG_INLINE Packet2f pmadd(const Packet2f& a, const Packet2f& b, const Packet2f& c)
 {
   return vmla_f32(c,a,b);
 }
 #endif
 
@@ -1133,14 +1175,25 @@
 template<> EIGEN_STRONG_INLINE Packet2ui pabsdiff<Packet2ui>(const Packet2ui& a, const Packet2ui& b)
 { return vabd_u32(a,b); }
 template<> EIGEN_STRONG_INLINE Packet4ui pabsdiff<Packet4ui>(const Packet4ui& a, const Packet4ui& b)
 { return vabdq_u32(a,b); }
 
 template<> EIGEN_STRONG_INLINE Packet2f pmin<Packet2f>(const Packet2f& a, const Packet2f& b) { return vmin_f32(a,b); }
 template<> EIGEN_STRONG_INLINE Packet4f pmin<Packet4f>(const Packet4f& a, const Packet4f& b) { return vminq_f32(a,b); }
+
+#ifdef __ARM_FEATURE_NUMERIC_MAXMIN
+// numeric max and min are only available if ARM_FEATURE_NUMERIC_MAXMIN is defined (which can only be the case for Armv8 systems).
+template<> EIGEN_STRONG_INLINE Packet4f pmin<PropagateNumbers, Packet4f>(const Packet4f& a, const Packet4f& b) { return vminnmq_f32(a, b); }
+template<> EIGEN_STRONG_INLINE Packet2f pmin<PropagateNumbers, Packet2f>(const Packet2f& a, const Packet2f& b) { return vminnm_f32(a, b); }
+#endif
+
+template<> EIGEN_STRONG_INLINE Packet4f pmin<PropagateNaN, Packet4f>(const Packet4f& a, const Packet4f& b) { return pmin<Packet4f>(a, b); }
+
+template<> EIGEN_STRONG_INLINE Packet2f pmin<PropagateNaN, Packet2f>(const Packet2f& a, const Packet2f& b) { return pmin<Packet2f>(a, b); }
+
 template<> EIGEN_STRONG_INLINE Packet4c pmin<Packet4c>(const Packet4c& a, const Packet4c& b)
 {
   return vget_lane_s32(vreinterpret_s32_s8(vmin_s8(
       vreinterpret_s8_s32(vdup_n_s32(a)),
       vreinterpret_s8_s32(vdup_n_s32(b)))), 0);
 }
 template<> EIGEN_STRONG_INLINE Packet8c pmin<Packet8c>(const Packet8c& a, const Packet8c& b) { return vmin_s8(a,b); }
@@ -1170,14 +1223,25 @@
   return vcombine_u64(
       vdup_n_u64((std::min)(vgetq_lane_u64(a, 0), vgetq_lane_u64(b, 0))),
       vdup_n_u64((std::min)(vgetq_lane_u64(a, 1), vgetq_lane_u64(b, 1))));
 }
 
 template<> EIGEN_STRONG_INLINE Packet2f pmax<Packet2f>(const Packet2f& a, const Packet2f& b) { return vmax_f32(a,b); }
 template<> EIGEN_STRONG_INLINE Packet4f pmax<Packet4f>(const Packet4f& a, const Packet4f& b) { return vmaxq_f32(a,b); }
+
+#ifdef __ARM_FEATURE_NUMERIC_MAXMIN
+// numeric max and min are only available if ARM_FEATURE_NUMERIC_MAXMIN is defined (which can only be the case for Armv8 systems).
+template<> EIGEN_STRONG_INLINE Packet4f pmax<PropagateNumbers, Packet4f>(const Packet4f& a, const Packet4f& b) { return vmaxnmq_f32(a, b); }
+template<> EIGEN_STRONG_INLINE Packet2f pmax<PropagateNumbers, Packet2f>(const Packet2f& a, const Packet2f& b) { return vmaxnm_f32(a, b); }
+#endif
+
+template<> EIGEN_STRONG_INLINE Packet4f pmax<PropagateNaN, Packet4f>(const Packet4f& a, const Packet4f& b) { return pmax<Packet4f>(a, b); }
+
+template<> EIGEN_STRONG_INLINE Packet2f pmax<PropagateNaN, Packet2f>(const Packet2f& a, const Packet2f& b) { return pmax<Packet2f>(a, b); }
+
 template<> EIGEN_STRONG_INLINE Packet4c pmax<Packet4c>(const Packet4c& a, const Packet4c& b)
 {
   return vget_lane_s32(vreinterpret_s32_s8(vmax_s8(
       vreinterpret_s8_s32(vdup_n_s32(a)),
       vreinterpret_s8_s32(vdup_n_s32(b)))), 0);
 }
 template<> EIGEN_STRONG_INLINE Packet8c pmax<Packet8c>(const Packet8c& a, const Packet8c& b) { return vmax_s8(a,b); }
@@ -1393,40 +1457,14 @@
 }
 
 template<> EIGEN_STRONG_INLINE Packet2f pcmp_lt_or_nan<Packet2f>(const Packet2f& a, const Packet2f& b)
 { return vreinterpret_f32_u32(vmvn_u32(vcge_f32(a,b))); }
 template<> EIGEN_STRONG_INLINE Packet4f pcmp_lt_or_nan<Packet4f>(const Packet4f& a, const Packet4f& b)
 { return vreinterpretq_f32_u32(vmvnq_u32(vcgeq_f32(a,b))); }
 
-// WARNING: this pfloor implementation makes sense for inputs that fit in
-// signed int32 integers (up to ~2.14e9), hence this is currently only used
-// by pexp and not exposed through HasFloor.
-template<> EIGEN_STRONG_INLINE Packet2f pfloor<Packet2f>(const Packet2f& a)
-{
-  const Packet2f cst_1 = pset1<Packet2f>(1.0f);
-  /* perform a floorf */
-  Packet2f tmp = vcvt_f32_s32(vcvt_s32_f32(a));
-
-  /* if greater, substract 1 */
-  Packet2ui mask = vcgt_f32(tmp, a);
-  mask = vand_u32(mask, vreinterpret_u32_f32(cst_1));
-  return vsub_f32(tmp, vreinterpret_f32_u32(mask));
-}
-template<> EIGEN_STRONG_INLINE Packet4f pfloor<Packet4f>(const Packet4f& a)
-{
-  const Packet4f cst_1 = pset1<Packet4f>(1.0f);
-  /* perform a floorf */
-  Packet4f tmp = vcvtq_f32_s32(vcvtq_s32_f32(a));
-
-  /* if greater, substract 1 */
-  Packet4ui mask = vcgtq_f32(tmp, a);
-  mask = vandq_u32(mask, vreinterpretq_u32_f32(cst_1));
-  return vsubq_f32(tmp, vreinterpretq_f32_u32(mask));
-}
-
 // Logical Operations are not supported for float, so we have to reinterpret casts using NEON intrinsics
 template<> EIGEN_STRONG_INLINE Packet2f pand<Packet2f>(const Packet2f& a, const Packet2f& b)
 { return vreinterpret_f32_u32(vand_u32(vreinterpret_u32_f32(a),vreinterpret_u32_f32(b))); }
 template<> EIGEN_STRONG_INLINE Packet4f pand<Packet4f>(const Packet4f& a, const Packet4f& b)
 { return vreinterpretq_f32_u32(vandq_u32(vreinterpretq_u32_f32(a),vreinterpretq_u32_f32(b))); }
 template<> EIGEN_STRONG_INLINE Packet4c pand<Packet4c>(const Packet4c& a, const Packet4c& b)
 { return a & b; }
@@ -1898,48 +1936,48 @@
 template<> EIGEN_STRONG_INLINE void pstoreu<uint32_t>(uint32_t* to, const Packet4ui& from)
 { EIGEN_DEBUG_UNALIGNED_STORE vst1q_u32(to,from); }
 template<> EIGEN_STRONG_INLINE void pstoreu<int64_t>(int64_t* to, const Packet2l& from)
 { EIGEN_DEBUG_UNALIGNED_STORE vst1q_s64(to,from); }
 template<> EIGEN_STRONG_INLINE void pstoreu<uint64_t>(uint64_t* to, const Packet2ul& from)
 { EIGEN_DEBUG_UNALIGNED_STORE vst1q_u64(to,from); }
 
-template<> EIGEN_DEVICE_FUNC inline Packet2f pgather<float, Packet2f>(const float* from, Index stride)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet2f pgather<float, Packet2f>(const float* from, Index stride)
 {
   Packet2f res = vld1_dup_f32(from);
   res = vld1_lane_f32(from + 1*stride, res, 1);
   return res;
 }
-template<> EIGEN_DEVICE_FUNC inline Packet4f pgather<float, Packet4f>(const float* from, Index stride)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4f pgather<float, Packet4f>(const float* from, Index stride)
 {
   Packet4f res = vld1q_dup_f32(from);
   res = vld1q_lane_f32(from + 1*stride, res, 1);
   res = vld1q_lane_f32(from + 2*stride, res, 2);
   res = vld1q_lane_f32(from + 3*stride, res, 3);
   return res;
 }
-template<> EIGEN_DEVICE_FUNC inline Packet4c pgather<int8_t, Packet4c>(const int8_t* from, Index stride)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4c pgather<int8_t, Packet4c>(const int8_t* from, Index stride)
 {
   Packet4c res;
   for (int i = 0; i != 4; i++)
     reinterpret_cast<int8_t*>(&res)[i] = *(from + i * stride);
   return res;
 }
-template<> EIGEN_DEVICE_FUNC inline Packet8c pgather<int8_t, Packet8c>(const int8_t* from, Index stride)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet8c pgather<int8_t, Packet8c>(const int8_t* from, Index stride)
 {
   Packet8c res = vld1_dup_s8(from);
   res = vld1_lane_s8(from + 1*stride, res, 1);
   res = vld1_lane_s8(from + 2*stride, res, 2);
   res = vld1_lane_s8(from + 3*stride, res, 3);
   res = vld1_lane_s8(from + 4*stride, res, 4);
   res = vld1_lane_s8(from + 5*stride, res, 5);
   res = vld1_lane_s8(from + 6*stride, res, 6);
   res = vld1_lane_s8(from + 7*stride, res, 7);
   return res;
 }
-template<> EIGEN_DEVICE_FUNC inline Packet16c pgather<int8_t, Packet16c>(const int8_t* from, Index stride)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet16c pgather<int8_t, Packet16c>(const int8_t* from, Index stride)
 {
   Packet16c res = vld1q_dup_s8(from);
   res = vld1q_lane_s8(from + 1*stride, res, 1);
   res = vld1q_lane_s8(from + 2*stride, res, 2);
   res = vld1q_lane_s8(from + 3*stride, res, 3);
   res = vld1q_lane_s8(from + 4*stride, res, 4);
   res = vld1q_lane_s8(from + 5*stride, res, 5);
@@ -1951,34 +1989,34 @@
   res = vld1q_lane_s8(from + 11*stride, res, 11);
   res = vld1q_lane_s8(from + 12*stride, res, 12);
   res = vld1q_lane_s8(from + 13*stride, res, 13);
   res = vld1q_lane_s8(from + 14*stride, res, 14);
   res = vld1q_lane_s8(from + 15*stride, res, 15);
   return res;
 }
-template<> EIGEN_DEVICE_FUNC inline Packet4uc pgather<uint8_t, Packet4uc>(const uint8_t* from, Index stride)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4uc pgather<uint8_t, Packet4uc>(const uint8_t* from, Index stride)
 {
   Packet4uc res;
   for (int i = 0; i != 4; i++)
     reinterpret_cast<uint8_t*>(&res)[i] = *(from + i * stride);
   return res;
 }
-template<> EIGEN_DEVICE_FUNC inline Packet8uc pgather<uint8_t, Packet8uc>(const uint8_t* from, Index stride)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet8uc pgather<uint8_t, Packet8uc>(const uint8_t* from, Index stride)
 {
   Packet8uc res = vld1_dup_u8(from);
   res = vld1_lane_u8(from + 1*stride, res, 1);
   res = vld1_lane_u8(from + 2*stride, res, 2);
   res = vld1_lane_u8(from + 3*stride, res, 3);
   res = vld1_lane_u8(from + 4*stride, res, 4);
   res = vld1_lane_u8(from + 5*stride, res, 5);
   res = vld1_lane_u8(from + 6*stride, res, 6);
   res = vld1_lane_u8(from + 7*stride, res, 7);
   return res;
 }
-template<> EIGEN_DEVICE_FUNC inline Packet16uc pgather<uint8_t, Packet16uc>(const uint8_t* from, Index stride)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet16uc pgather<uint8_t, Packet16uc>(const uint8_t* from, Index stride)
 {
   Packet16uc res = vld1q_dup_u8(from);
   res = vld1q_lane_u8(from + 1*stride, res, 1);
   res = vld1q_lane_u8(from + 2*stride, res, 2);
   res = vld1q_lane_u8(from + 3*stride, res, 3);
   res = vld1q_lane_u8(from + 4*stride, res, 4);
   res = vld1q_lane_u8(from + 5*stride, res, 5);
@@ -1990,124 +2028,124 @@
   res = vld1q_lane_u8(from + 11*stride, res, 11);
   res = vld1q_lane_u8(from + 12*stride, res, 12);
   res = vld1q_lane_u8(from + 13*stride, res, 13);
   res = vld1q_lane_u8(from + 14*stride, res, 14);
   res = vld1q_lane_u8(from + 15*stride, res, 15);
   return res;
 }
-template<> EIGEN_DEVICE_FUNC inline Packet4s pgather<int16_t, Packet4s>(const int16_t* from, Index stride)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4s pgather<int16_t, Packet4s>(const int16_t* from, Index stride)
 {
   Packet4s res = vld1_dup_s16(from);
   res = vld1_lane_s16(from + 1*stride, res, 1);
   res = vld1_lane_s16(from + 2*stride, res, 2);
   res = vld1_lane_s16(from + 3*stride, res, 3);
   return res;
 }
-template<> EIGEN_DEVICE_FUNC inline Packet8s pgather<int16_t, Packet8s>(const int16_t* from, Index stride)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet8s pgather<int16_t, Packet8s>(const int16_t* from, Index stride)
 {
   Packet8s res = vld1q_dup_s16(from);
   res = vld1q_lane_s16(from + 1*stride, res, 1);
   res = vld1q_lane_s16(from + 2*stride, res, 2);
   res = vld1q_lane_s16(from + 3*stride, res, 3);
   res = vld1q_lane_s16(from + 4*stride, res, 4);
   res = vld1q_lane_s16(from + 5*stride, res, 5);
   res = vld1q_lane_s16(from + 6*stride, res, 6);
   res = vld1q_lane_s16(from + 7*stride, res, 7);
   return res;
 }
-template<> EIGEN_DEVICE_FUNC inline Packet4us pgather<uint16_t, Packet4us>(const uint16_t* from, Index stride)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4us pgather<uint16_t, Packet4us>(const uint16_t* from, Index stride)
 {
   Packet4us res = vld1_dup_u16(from);
   res = vld1_lane_u16(from + 1*stride, res, 1);
   res = vld1_lane_u16(from + 2*stride, res, 2);
   res = vld1_lane_u16(from + 3*stride, res, 3);
   return res;
 }
-template<> EIGEN_DEVICE_FUNC inline Packet8us pgather<uint16_t, Packet8us>(const uint16_t* from, Index stride)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet8us pgather<uint16_t, Packet8us>(const uint16_t* from, Index stride)
 {
   Packet8us res = vld1q_dup_u16(from);
   res = vld1q_lane_u16(from + 1*stride, res, 1);
   res = vld1q_lane_u16(from + 2*stride, res, 2);
   res = vld1q_lane_u16(from + 3*stride, res, 3);
   res = vld1q_lane_u16(from + 4*stride, res, 4);
   res = vld1q_lane_u16(from + 5*stride, res, 5);
   res = vld1q_lane_u16(from + 6*stride, res, 6);
   res = vld1q_lane_u16(from + 7*stride, res, 7);
   return res;
 }
-template<> EIGEN_DEVICE_FUNC inline Packet2i pgather<int32_t, Packet2i>(const int32_t* from, Index stride)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet2i pgather<int32_t, Packet2i>(const int32_t* from, Index stride)
 {
   Packet2i res = vld1_dup_s32(from);
   res = vld1_lane_s32(from + 1*stride, res, 1);
   return res;
 }
-template<> EIGEN_DEVICE_FUNC inline Packet4i pgather<int32_t, Packet4i>(const int32_t* from, Index stride)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4i pgather<int32_t, Packet4i>(const int32_t* from, Index stride)
 {
   Packet4i res = vld1q_dup_s32(from);
   res = vld1q_lane_s32(from + 1*stride, res, 1);
   res = vld1q_lane_s32(from + 2*stride, res, 2);
   res = vld1q_lane_s32(from + 3*stride, res, 3);
   return res;
 }
-template<> EIGEN_DEVICE_FUNC inline Packet2ui pgather<uint32_t, Packet2ui>(const uint32_t* from, Index stride)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet2ui pgather<uint32_t, Packet2ui>(const uint32_t* from, Index stride)
 {
   Packet2ui res = vld1_dup_u32(from);
   res = vld1_lane_u32(from + 1*stride, res, 1);
   return res;
 }
-template<> EIGEN_DEVICE_FUNC inline Packet4ui pgather<uint32_t, Packet4ui>(const uint32_t* from, Index stride)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4ui pgather<uint32_t, Packet4ui>(const uint32_t* from, Index stride)
 {
   Packet4ui res = vld1q_dup_u32(from);
   res = vld1q_lane_u32(from + 1*stride, res, 1);
   res = vld1q_lane_u32(from + 2*stride, res, 2);
   res = vld1q_lane_u32(from + 3*stride, res, 3);
   return res;
 }
-template<> EIGEN_DEVICE_FUNC inline Packet2l pgather<int64_t, Packet2l>(const int64_t* from, Index stride)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet2l pgather<int64_t, Packet2l>(const int64_t* from, Index stride)
 {
   Packet2l res = vld1q_dup_s64(from);
   res = vld1q_lane_s64(from + 1*stride, res, 1);
   return res;
 }
-template<> EIGEN_DEVICE_FUNC inline Packet2ul pgather<uint64_t, Packet2ul>(const uint64_t* from, Index stride)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet2ul pgather<uint64_t, Packet2ul>(const uint64_t* from, Index stride)
 {
   Packet2ul res = vld1q_dup_u64(from);
   res = vld1q_lane_u64(from + 1*stride, res, 1);
   return res;
 }
 
-template<> EIGEN_DEVICE_FUNC inline void pscatter<float, Packet2f>(float* to, const Packet2f& from, Index stride)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void pscatter<float, Packet2f>(float* to, const Packet2f& from, Index stride)
 {
   vst1_lane_f32(to + stride*0, from, 0);
   vst1_lane_f32(to + stride*1, from, 1);
 }
-template<> EIGEN_DEVICE_FUNC inline void pscatter<float, Packet4f>(float* to, const Packet4f& from, Index stride)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void pscatter<float, Packet4f>(float* to, const Packet4f& from, Index stride)
 {
   vst1q_lane_f32(to + stride*0, from, 0);
   vst1q_lane_f32(to + stride*1, from, 1);
   vst1q_lane_f32(to + stride*2, from, 2);
   vst1q_lane_f32(to + stride*3, from, 3);
 }
-template<> EIGEN_DEVICE_FUNC inline void pscatter<int8_t, Packet4c>(int8_t* to, const Packet4c& from, Index stride)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void pscatter<int8_t, Packet4c>(int8_t* to, const Packet4c& from, Index stride)
 {
   for (int i = 0; i != 4; i++)
     *(to + i * stride) = reinterpret_cast<const int8_t*>(&from)[i];
 }
-template<> EIGEN_DEVICE_FUNC inline void pscatter<int8_t, Packet8c>(int8_t* to, const Packet8c& from, Index stride)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void pscatter<int8_t, Packet8c>(int8_t* to, const Packet8c& from, Index stride)
 {
   vst1_lane_s8(to + stride*0, from, 0);
   vst1_lane_s8(to + stride*1, from, 1);
   vst1_lane_s8(to + stride*2, from, 2);
   vst1_lane_s8(to + stride*3, from, 3);
   vst1_lane_s8(to + stride*4, from, 4);
   vst1_lane_s8(to + stride*5, from, 5);
   vst1_lane_s8(to + stride*6, from, 6);
   vst1_lane_s8(to + stride*7, from, 7);
 }
-template<> EIGEN_DEVICE_FUNC inline void pscatter<int8_t, Packet16c>(int8_t* to, const Packet16c& from, Index stride)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void pscatter<int8_t, Packet16c>(int8_t* to, const Packet16c& from, Index stride)
 {
   vst1q_lane_s8(to + stride*0, from, 0);
   vst1q_lane_s8(to + stride*1, from, 1);
   vst1q_lane_s8(to + stride*2, from, 2);
   vst1q_lane_s8(to + stride*3, from, 3);
   vst1q_lane_s8(to + stride*4, from, 4);
   vst1q_lane_s8(to + stride*5, from, 5);
@@ -2118,31 +2156,31 @@
   vst1q_lane_s8(to + stride*10, from, 10);
   vst1q_lane_s8(to + stride*11, from, 11);
   vst1q_lane_s8(to + stride*12, from, 12);
   vst1q_lane_s8(to + stride*13, from, 13);
   vst1q_lane_s8(to + stride*14, from, 14);
   vst1q_lane_s8(to + stride*15, from, 15);
 }
-template<> EIGEN_DEVICE_FUNC inline void pscatter<uint8_t, Packet4uc>(uint8_t* to, const Packet4uc& from, Index stride)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void pscatter<uint8_t, Packet4uc>(uint8_t* to, const Packet4uc& from, Index stride)
 {
   for (int i = 0; i != 4; i++)
     *(to + i * stride) = reinterpret_cast<const uint8_t*>(&from)[i];
 }
-template<> EIGEN_DEVICE_FUNC inline void pscatter<uint8_t, Packet8uc>(uint8_t* to, const Packet8uc& from, Index stride)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void pscatter<uint8_t, Packet8uc>(uint8_t* to, const Packet8uc& from, Index stride)
 {
   vst1_lane_u8(to + stride*0, from, 0);
   vst1_lane_u8(to + stride*1, from, 1);
   vst1_lane_u8(to + stride*2, from, 2);
   vst1_lane_u8(to + stride*3, from, 3);
   vst1_lane_u8(to + stride*4, from, 4);
   vst1_lane_u8(to + stride*5, from, 5);
   vst1_lane_u8(to + stride*6, from, 6);
   vst1_lane_u8(to + stride*7, from, 7);
 }
-template<> EIGEN_DEVICE_FUNC inline void pscatter<uint8_t, Packet16uc>(uint8_t* to, const Packet16uc& from, Index stride)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void pscatter<uint8_t, Packet16uc>(uint8_t* to, const Packet16uc& from, Index stride)
 {
   vst1q_lane_u8(to + stride*0, from, 0);
   vst1q_lane_u8(to + stride*1, from, 1);
   vst1q_lane_u8(to + stride*2, from, 2);
   vst1q_lane_u8(to + stride*3, from, 3);
   vst1q_lane_u8(to + stride*4, from, 4);
   vst1q_lane_u8(to + stride*5, from, 5);
@@ -2153,80 +2191,80 @@
   vst1q_lane_u8(to + stride*10, from, 10);
   vst1q_lane_u8(to + stride*11, from, 11);
   vst1q_lane_u8(to + stride*12, from, 12);
   vst1q_lane_u8(to + stride*13, from, 13);
   vst1q_lane_u8(to + stride*14, from, 14);
   vst1q_lane_u8(to + stride*15, from, 15);
 }
-template<> EIGEN_DEVICE_FUNC inline void pscatter<int16_t, Packet4s>(int16_t* to, const Packet4s& from, Index stride)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void pscatter<int16_t, Packet4s>(int16_t* to, const Packet4s& from, Index stride)
 {
   vst1_lane_s16(to + stride*0, from, 0);
   vst1_lane_s16(to + stride*1, from, 1);
   vst1_lane_s16(to + stride*2, from, 2);
   vst1_lane_s16(to + stride*3, from, 3);
 }
-template<> EIGEN_DEVICE_FUNC inline void pscatter<int16_t, Packet8s>(int16_t* to, const Packet8s& from, Index stride)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void pscatter<int16_t, Packet8s>(int16_t* to, const Packet8s& from, Index stride)
 {
   vst1q_lane_s16(to + stride*0, from, 0);
   vst1q_lane_s16(to + stride*1, from, 1);
   vst1q_lane_s16(to + stride*2, from, 2);
   vst1q_lane_s16(to + stride*3, from, 3);
   vst1q_lane_s16(to + stride*4, from, 4);
   vst1q_lane_s16(to + stride*5, from, 5);
   vst1q_lane_s16(to + stride*6, from, 6);
   vst1q_lane_s16(to + stride*7, from, 7);
 }
-template<> EIGEN_DEVICE_FUNC inline void pscatter<uint16_t, Packet4us>(uint16_t* to, const Packet4us& from, Index stride)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void pscatter<uint16_t, Packet4us>(uint16_t* to, const Packet4us& from, Index stride)
 {
   vst1_lane_u16(to + stride*0, from, 0);
   vst1_lane_u16(to + stride*1, from, 1);
   vst1_lane_u16(to + stride*2, from, 2);
   vst1_lane_u16(to + stride*3, from, 3);
 }
-template<> EIGEN_DEVICE_FUNC inline void pscatter<uint16_t, Packet8us>(uint16_t* to, const Packet8us& from, Index stride)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void pscatter<uint16_t, Packet8us>(uint16_t* to, const Packet8us& from, Index stride)
 {
   vst1q_lane_u16(to + stride*0, from, 0);
   vst1q_lane_u16(to + stride*1, from, 1);
   vst1q_lane_u16(to + stride*2, from, 2);
   vst1q_lane_u16(to + stride*3, from, 3);
   vst1q_lane_u16(to + stride*4, from, 4);
   vst1q_lane_u16(to + stride*5, from, 5);
   vst1q_lane_u16(to + stride*6, from, 6);
   vst1q_lane_u16(to + stride*7, from, 7);
 }
-template<> EIGEN_DEVICE_FUNC inline void pscatter<int32_t, Packet2i>(int32_t* to, const Packet2i& from, Index stride)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void pscatter<int32_t, Packet2i>(int32_t* to, const Packet2i& from, Index stride)
 {
   vst1_lane_s32(to + stride*0, from, 0);
   vst1_lane_s32(to + stride*1, from, 1);
 }
-template<> EIGEN_DEVICE_FUNC inline void pscatter<int32_t, Packet4i>(int32_t* to, const Packet4i& from, Index stride)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void pscatter<int32_t, Packet4i>(int32_t* to, const Packet4i& from, Index stride)
 {
   vst1q_lane_s32(to + stride*0, from, 0);
   vst1q_lane_s32(to + stride*1, from, 1);
   vst1q_lane_s32(to + stride*2, from, 2);
   vst1q_lane_s32(to + stride*3, from, 3);
 }
-template<> EIGEN_DEVICE_FUNC inline void pscatter<uint32_t, Packet2ui>(uint32_t* to, const Packet2ui& from, Index stride)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void pscatter<uint32_t, Packet2ui>(uint32_t* to, const Packet2ui& from, Index stride)
 {
   vst1_lane_u32(to + stride*0, from, 0);
   vst1_lane_u32(to + stride*1, from, 1);
 }
-template<> EIGEN_DEVICE_FUNC inline void pscatter<uint32_t, Packet4ui>(uint32_t* to, const Packet4ui& from, Index stride)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void pscatter<uint32_t, Packet4ui>(uint32_t* to, const Packet4ui& from, Index stride)
 {
   vst1q_lane_u32(to + stride*0, from, 0);
   vst1q_lane_u32(to + stride*1, from, 1);
   vst1q_lane_u32(to + stride*2, from, 2);
   vst1q_lane_u32(to + stride*3, from, 3);
 }
-template<> EIGEN_DEVICE_FUNC inline void pscatter<int64_t, Packet2l>(int64_t* to, const Packet2l& from, Index stride)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void pscatter<int64_t, Packet2l>(int64_t* to, const Packet2l& from, Index stride)
 {
   vst1q_lane_s64(to + stride*0, from, 0);
   vst1q_lane_s64(to + stride*1, from, 1);
 }
-template<> EIGEN_DEVICE_FUNC inline void pscatter<uint64_t, Packet2ul>(uint64_t* to, const Packet2ul& from, Index stride)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void pscatter<uint64_t, Packet2ul>(uint64_t* to, const Packet2ul& from, Index stride)
 {
   vst1q_lane_u64(to + stride*0, from, 0);
   vst1q_lane_u64(to + stride*1, from, 1);
 }
 
 template<> EIGEN_STRONG_INLINE void prefetch<float>(const float* addr) { EIGEN_ARM_PREFETCH(addr); }
 template<> EIGEN_STRONG_INLINE void prefetch<int8_t>(const int8_t* addr) { EIGEN_ARM_PREFETCH(addr); }
@@ -2333,22 +2371,22 @@
       vdup_n_s64((std::abs)(vgetq_lane_s64(a, 0))),
       vdup_n_s64((std::abs)(vgetq_lane_s64(a, 1))));
 #endif
 }
 template<> EIGEN_STRONG_INLINE Packet2ul pabs(const Packet2ul& a) { return a; }
 
 template<> EIGEN_STRONG_INLINE Packet2f pfrexp<Packet2f>(const Packet2f& a, Packet2f& exponent)
-{ return pfrexp_float(a,exponent); }
+{ return pfrexp_generic(a,exponent); }
 template<> EIGEN_STRONG_INLINE Packet4f pfrexp<Packet4f>(const Packet4f& a, Packet4f& exponent)
-{ return pfrexp_float(a,exponent); }
+{ return pfrexp_generic(a,exponent); }
 
 template<> EIGEN_STRONG_INLINE Packet2f pldexp<Packet2f>(const Packet2f& a, const Packet2f& exponent)
-{ return pldexp_float(a,exponent); }
+{ return pldexp_generic(a,exponent); }
 template<> EIGEN_STRONG_INLINE Packet4f pldexp<Packet4f>(const Packet4f& a, const Packet4f& exponent)
-{ return pldexp_float(a,exponent); }
+{ return pldexp_generic(a,exponent); }
 
 template<> EIGEN_STRONG_INLINE float predux<Packet2f>(const Packet2f& a) { return vget_lane_f32(vpadd_f32(a,a), 0); }
 template<> EIGEN_STRONG_INLINE float predux<Packet4f>(const Packet4f& a)
 {
   const float32x2_t sum = vadd_f32(vget_low_f32(a), vget_high_f32(a));
   return vget_lane_f32(vpadd_f32(sum, sum), 0);
 }
@@ -2433,31 +2471,31 @@
   return vget_lane_u32(vpadd_u32(sum, sum), 0);
 }
 template<> EIGEN_STRONG_INLINE int64_t predux<Packet2l>(const Packet2l& a)
 { return vgetq_lane_s64(a, 0) + vgetq_lane_s64(a, 1); }
 template<> EIGEN_STRONG_INLINE uint64_t predux<Packet2ul>(const Packet2ul& a)
 { return vgetq_lane_u64(a, 0) + vgetq_lane_u64(a, 1); }
 
-template<> EIGEN_DEVICE_FUNC inline Packet4c predux_half_dowto4(const Packet8c& a)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4c predux_half_dowto4(const Packet8c& a)
 {
   return vget_lane_s32(vreinterpret_s32_s8(vadd_s8(a,
       vreinterpret_s8_s32(vrev64_s32(vreinterpret_s32_s8(a))))), 0);
 }
-template<> EIGEN_DEVICE_FUNC inline Packet8c predux_half_dowto4(const Packet16c& a)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet8c predux_half_dowto4(const Packet16c& a)
 { return vadd_s8(vget_high_s8(a), vget_low_s8(a)); }
-template<> EIGEN_DEVICE_FUNC inline Packet4uc predux_half_dowto4(const Packet8uc& a)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4uc predux_half_dowto4(const Packet8uc& a)
 {
   return vget_lane_u32(vreinterpret_u32_u8(vadd_u8(a,
       vreinterpret_u8_u32(vrev64_u32(vreinterpret_u32_u8(a))))), 0);
 }
-template<> EIGEN_DEVICE_FUNC inline Packet8uc predux_half_dowto4(const Packet16uc& a)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet8uc predux_half_dowto4(const Packet16uc& a)
 { return vadd_u8(vget_high_u8(a), vget_low_u8(a)); }
-template<> EIGEN_DEVICE_FUNC inline Packet4s predux_half_dowto4(const Packet8s& a)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4s predux_half_dowto4(const Packet8s& a)
 { return vadd_s16(vget_high_s16(a), vget_low_s16(a)); }
-template<> EIGEN_DEVICE_FUNC inline Packet4us predux_half_dowto4(const Packet8us& a)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4us predux_half_dowto4(const Packet8us& a)
 { return vadd_u16(vget_high_u16(a), vget_low_u16(a)); }
 
 // Other reduction functions:
 // mul
 template<> EIGEN_STRONG_INLINE float predux_mul<Packet2f>(const Packet2f& a)
 { return vget_lane_f32(a, 0) * vget_lane_f32(a, 1); }
 template<> EIGEN_STRONG_INLINE float predux_mul<Packet4f>(const Packet4f& a)
@@ -2728,409 +2766,426 @@
 template<> EIGEN_STRONG_INLINE bool predux_any(const Packet4f& x)
 {
   uint32x2_t tmp = vorr_u32(vget_low_u32( vreinterpretq_u32_f32(x)),
                             vget_high_u32(vreinterpretq_u32_f32(x)));
   return vget_lane_u32(vpmax_u32(tmp, tmp), 0);
 }
 
-EIGEN_DEVICE_FUNC inline void ptranspose(PacketBlock<Packet2f, 2>& kernel)
-{
-  const float32x2x2_t z = vzip_f32(kernel.packet[0], kernel.packet[1]);
-  kernel.packet[0] = z.val[0];
-  kernel.packet[1] = z.val[1];
-}
-EIGEN_DEVICE_FUNC inline void ptranspose(PacketBlock<Packet4f, 4>& kernel)
-{
-  const float32x4x2_t tmp1 = vzipq_f32(kernel.packet[0], kernel.packet[1]);
-  const float32x4x2_t tmp2 = vzipq_f32(kernel.packet[2], kernel.packet[3]);
+// Helpers for ptranspose.
+namespace detail {
+  
+template<typename Packet>
+void zip_in_place(Packet& p1, Packet& p2);
 
-  kernel.packet[0] = vcombine_f32(vget_low_f32(tmp1.val[0]), vget_low_f32(tmp2.val[0]));
-  kernel.packet[1] = vcombine_f32(vget_high_f32(tmp1.val[0]), vget_high_f32(tmp2.val[0]));
-  kernel.packet[2] = vcombine_f32(vget_low_f32(tmp1.val[1]), vget_low_f32(tmp2.val[1]));
-  kernel.packet[3] = vcombine_f32(vget_high_f32(tmp1.val[1]), vget_high_f32(tmp2.val[1]));
+template<>
+EIGEN_ALWAYS_INLINE void zip_in_place<Packet2f>(Packet2f& p1, Packet2f& p2) {
+  const float32x2x2_t tmp = vzip_f32(p1, p2);
+  p1 = tmp.val[0];
+  p2 = tmp.val[1];
 }
-EIGEN_DEVICE_FUNC inline void ptranspose(PacketBlock<Packet4c, 4>& kernel)
-{
-  const int8x8_t a = vreinterpret_s8_s32(vset_lane_s32(kernel.packet[2], vdup_n_s32(kernel.packet[0]), 1));
-  const int8x8_t b = vreinterpret_s8_s32(vset_lane_s32(kernel.packet[3], vdup_n_s32(kernel.packet[1]), 1));
-
-  const int8x8x2_t zip8 = vzip_s8(a,b);
-  const int16x4x2_t zip16 = vzip_s16(vreinterpret_s16_s8(zip8.val[0]), vreinterpret_s16_s8(zip8.val[1]));
 
-  kernel.packet[0] = vget_lane_s32(vreinterpret_s32_s16(zip16.val[0]), 0);
-  kernel.packet[1] = vget_lane_s32(vreinterpret_s32_s16(zip16.val[0]), 1);
-  kernel.packet[2] = vget_lane_s32(vreinterpret_s32_s16(zip16.val[1]), 0);
-  kernel.packet[3] = vget_lane_s32(vreinterpret_s32_s16(zip16.val[1]), 1);
+template<>
+EIGEN_ALWAYS_INLINE void zip_in_place<Packet4f>(Packet4f& p1, Packet4f& p2) {
+  const float32x4x2_t tmp = vzipq_f32(p1, p2);
+  p1 = tmp.val[0];
+  p2 = tmp.val[1];
 }
-EIGEN_DEVICE_FUNC inline void ptranspose(PacketBlock<Packet8c, 8>& kernel)
-{
-  int8x8x2_t zip8[4];
-  uint16x4x2_t zip16[4];
-
-  EIGEN_UNROLL_LOOP
-  for (int i = 0; i != 4; i++)
-    zip8[i] = vzip_s8(kernel.packet[i*2], kernel.packet[i*2+1]);
 
-  EIGEN_UNROLL_LOOP
-  for (int i = 0; i != 2; i++)
-  {
-    EIGEN_UNROLL_LOOP
-    for (int j = 0; j != 2; j++)
-      zip16[i*2+j] = vzip_u16(vreinterpret_u16_s8(zip8[i*2].val[j]), vreinterpret_u16_s8(zip8[i*2+1].val[j]));
-  }
-
-  EIGEN_UNROLL_LOOP
-  for (int i = 0; i != 2; i++)
-  {
-    EIGEN_UNROLL_LOOP
-    for (int j = 0; j != 2; j++)
-    {
-      const uint32x2x2_t z = vzip_u32(vreinterpret_u32_u16(zip16[i].val[j]), vreinterpret_u32_u16(zip16[i+2].val[j]));
-      EIGEN_UNROLL_LOOP
-      for (int k = 0; k != 2; k++)
-        kernel.packet[i*4+j*2+k] = vreinterpret_s8_u32(z.val[k]);
-    }
-  }
+template<>
+EIGEN_ALWAYS_INLINE void zip_in_place<Packet8c>(Packet8c& p1, Packet8c& p2) {
+  const int8x8x2_t tmp = vzip_s8(p1, p2);
+  p1 = tmp.val[0];
+  p2 = tmp.val[1];
 }
-EIGEN_DEVICE_FUNC inline void ptranspose(PacketBlock<Packet16c, 16>& kernel)
-{
-  int8x16x2_t zip8[8];
-  uint16x8x2_t zip16[8];
-  uint32x4x2_t zip32[8];
 
-  EIGEN_UNROLL_LOOP
-  for (int i = 0; i != 8; i++)
-    zip8[i] = vzipq_s8(kernel.packet[i*2], kernel.packet[i*2+1]);
+template<>
+EIGEN_ALWAYS_INLINE void zip_in_place<Packet16c>(Packet16c& p1, Packet16c& p2) {
+  const int8x16x2_t tmp = vzipq_s8(p1, p2);
+  p1 = tmp.val[0];
+  p2 = tmp.val[1];
+}
 
-  EIGEN_UNROLL_LOOP
-  for (int i = 0; i != 4; i++)
-  {
-    EIGEN_UNROLL_LOOP
-    for (int j = 0; j != 2; j++)
-    {
-      zip16[i*2+j] = vzipq_u16(vreinterpretq_u16_s8(zip8[i*2].val[j]),
-          vreinterpretq_u16_s8(zip8[i*2+1].val[j]));
-    }
-  }
+template<>
+EIGEN_ALWAYS_INLINE void zip_in_place<Packet8uc>(Packet8uc& p1, Packet8uc& p2) {
+  const uint8x8x2_t tmp = vzip_u8(p1, p2);
+  p1 = tmp.val[0];
+  p2 = tmp.val[1];
+}
 
-  EIGEN_UNROLL_LOOP
-  for (int i = 0; i != 2; i++)
-  {
-    EIGEN_UNROLL_LOOP
-    for (int j = 0; j != 2; j++)
-    {
-      EIGEN_UNROLL_LOOP
-      for (int k = 0; k != 2; k++)
-        zip32[i*4+j*2+k] = vzipq_u32(vreinterpretq_u32_u16(zip16[i*4+j].val[k]),
-            vreinterpretq_u32_u16(zip16[i*4+j+2].val[k]));
-    }
-  }
+template<>
+EIGEN_ALWAYS_INLINE void zip_in_place<Packet16uc>(Packet16uc& p1, Packet16uc& p2) {
+  const uint8x16x2_t tmp = vzipq_u8(p1, p2);
+  p1 = tmp.val[0];
+  p2 = tmp.val[1];
+}
 
-  EIGEN_UNROLL_LOOP
-  for (int i = 0; i != 4; i++)
-  {
-    EIGEN_UNROLL_LOOP
-    for (int j = 0; j != 2; j++)
-    {
-      kernel.packet[i*4+j*2] = vreinterpretq_s8_u32(vcombine_u32(vget_low_u32(zip32[i].val[j]),
-          vget_low_u32(zip32[i+4].val[j])));
-      kernel.packet[i*4+j*2+1] = vreinterpretq_s8_u32(vcombine_u32(vget_high_u32(zip32[i].val[j]),
-          vget_high_u32(zip32[i+4].val[j])));
-    }
-  }
+template<>
+EIGEN_ALWAYS_INLINE void zip_in_place<Packet2i>(Packet2i& p1, Packet2i& p2) {
+  const int32x2x2_t tmp = vzip_s32(p1, p2);
+  p1 = tmp.val[0];
+  p2 = tmp.val[1];
 }
-EIGEN_DEVICE_FUNC inline void ptranspose(PacketBlock<Packet4uc, 4>& kernel)
-{
-  const uint8x8_t a = vreinterpret_u8_u32(vset_lane_u32(kernel.packet[2], vdup_n_u32(kernel.packet[0]), 1));
-  const uint8x8_t b = vreinterpret_u8_u32(vset_lane_u32(kernel.packet[3], vdup_n_u32(kernel.packet[1]), 1));
 
-  const uint8x8x2_t zip8 = vzip_u8(a,b);
-  const uint16x4x2_t zip16 = vzip_u16(vreinterpret_u16_u8(zip8.val[0]), vreinterpret_u16_u8(zip8.val[1]));
+template<>
+EIGEN_ALWAYS_INLINE void zip_in_place<Packet4i>(Packet4i& p1, Packet4i& p2) {
+  const int32x4x2_t tmp = vzipq_s32(p1, p2);
+  p1 = tmp.val[0];
+  p2 = tmp.val[1];
+}
 
-  kernel.packet[0] = vget_lane_u32(vreinterpret_u32_u16(zip16.val[0]), 0);
-  kernel.packet[1] = vget_lane_u32(vreinterpret_u32_u16(zip16.val[0]), 1);
-  kernel.packet[2] = vget_lane_u32(vreinterpret_u32_u16(zip16.val[1]), 0);
-  kernel.packet[3] = vget_lane_u32(vreinterpret_u32_u16(zip16.val[1]), 1);
+template<>
+EIGEN_ALWAYS_INLINE void zip_in_place<Packet2ui>(Packet2ui& p1, Packet2ui& p2) {
+  const uint32x2x2_t tmp = vzip_u32(p1, p2);
+  p1 = tmp.val[0];
+  p2 = tmp.val[1];
 }
-EIGEN_DEVICE_FUNC inline void ptranspose(PacketBlock<Packet8uc, 8>& kernel)
-{
-  uint8x8x2_t zip8[4];
-  uint16x4x2_t zip16[4];
 
-  EIGEN_UNROLL_LOOP
-  for (int i = 0; i != 4; i++)
-    zip8[i] = vzip_u8(kernel.packet[i*2], kernel.packet[i*2+1]);
+template<>
+EIGEN_ALWAYS_INLINE void zip_in_place<Packet4ui>(Packet4ui& p1, Packet4ui& p2) {
+  const uint32x4x2_t tmp = vzipq_u32(p1, p2);
+  p1 = tmp.val[0];
+  p2 = tmp.val[1];
+}
 
-  EIGEN_UNROLL_LOOP
-  for (int i = 0; i != 2; i++)
-  {
-    EIGEN_UNROLL_LOOP
-    for (int j = 0; j != 2; j++)
-      zip16[i*2+j] = vzip_u16(vreinterpret_u16_u8(zip8[i*2].val[j]), vreinterpret_u16_u8(zip8[i*2+1].val[j]));
-  }
+template<>
+EIGEN_ALWAYS_INLINE void zip_in_place<Packet4s>(Packet4s& p1, Packet4s& p2) {
+  const int16x4x2_t tmp = vzip_s16(p1, p2);
+  p1 = tmp.val[0];
+  p2 = tmp.val[1];
+}
 
-  EIGEN_UNROLL_LOOP
-  for (int i = 0; i != 2; i++)
-  {
-    EIGEN_UNROLL_LOOP
-    for (int j = 0; j != 2; j++)
-    {
-      const uint32x2x2_t z = vzip_u32(vreinterpret_u32_u16(zip16[i].val[j]), vreinterpret_u32_u16(zip16[i+2].val[j]));
-      EIGEN_UNROLL_LOOP
-      for (int k = 0; k != 2; k++)
-        kernel.packet[i*4+j*2+k] = vreinterpret_u8_u32(z.val[k]);
-    }
-  }
+template<>
+EIGEN_ALWAYS_INLINE void zip_in_place<Packet8s>(Packet8s& p1, Packet8s& p2) {
+  const int16x8x2_t tmp = vzipq_s16(p1, p2);
+  p1 = tmp.val[0];
+  p2 = tmp.val[1];
 }
-EIGEN_DEVICE_FUNC inline void ptranspose(PacketBlock<Packet16uc, 16>& kernel)
-{
-  uint8x16x2_t zip8[8];
-  uint16x8x2_t zip16[8];
-  uint32x4x2_t zip32[8];
 
-  EIGEN_UNROLL_LOOP
-  for (int i = 0; i != 8; i++)
-    zip8[i] = vzipq_u8(kernel.packet[i*2], kernel.packet[i*2+1]);
+template<>
+EIGEN_ALWAYS_INLINE void zip_in_place<Packet4us>(Packet4us& p1, Packet4us& p2) {
+  const uint16x4x2_t tmp = vzip_u16(p1, p2);
+  p1 = tmp.val[0];
+  p2 = tmp.val[1];
+}
 
-  EIGEN_UNROLL_LOOP
-  for (int i = 0; i != 4; i++)
-  {
-    EIGEN_UNROLL_LOOP
-    for (int j = 0; j != 2; j++)
-      zip16[i*2+j] = vzipq_u16(vreinterpretq_u16_u8(zip8[i*2].val[j]),
-          vreinterpretq_u16_u8(zip8[i*2+1].val[j]));
-  }
+template<>
+EIGEN_ALWAYS_INLINE void zip_in_place<Packet8us>(Packet8us& p1, Packet8us& p2) {
+  const uint16x8x2_t tmp = vzipq_u16(p1, p2);
+  p1 = tmp.val[0];
+  p2 = tmp.val[1];
+}
+
+template<typename Packet>
+EIGEN_ALWAYS_INLINE void ptranspose_impl(PacketBlock<Packet, 2>& kernel) {
+  zip_in_place(kernel.packet[0], kernel.packet[1]);
+}
+
+template<typename Packet>
+EIGEN_ALWAYS_INLINE void ptranspose_impl(PacketBlock<Packet, 4>& kernel) {
+  zip_in_place(kernel.packet[0], kernel.packet[2]);
+  zip_in_place(kernel.packet[1], kernel.packet[3]);
+  zip_in_place(kernel.packet[0], kernel.packet[1]);
+  zip_in_place(kernel.packet[2], kernel.packet[3]);
+}
+
+template<typename Packet>
+EIGEN_ALWAYS_INLINE void ptranspose_impl(PacketBlock<Packet, 8>& kernel) {
+  zip_in_place(kernel.packet[0], kernel.packet[4]);
+  zip_in_place(kernel.packet[1], kernel.packet[5]);
+  zip_in_place(kernel.packet[2], kernel.packet[6]);
+  zip_in_place(kernel.packet[3], kernel.packet[7]);
+
+  zip_in_place(kernel.packet[0], kernel.packet[2]);
+  zip_in_place(kernel.packet[1], kernel.packet[3]);
+  zip_in_place(kernel.packet[4], kernel.packet[6]);
+  zip_in_place(kernel.packet[5], kernel.packet[7]);
+  
+  zip_in_place(kernel.packet[0], kernel.packet[1]);
+  zip_in_place(kernel.packet[2], kernel.packet[3]);
+  zip_in_place(kernel.packet[4], kernel.packet[5]);
+  zip_in_place(kernel.packet[6], kernel.packet[7]);
+}
 
+template<typename Packet>
+EIGEN_ALWAYS_INLINE void ptranspose_impl(PacketBlock<Packet, 16>& kernel) {
   EIGEN_UNROLL_LOOP
-  for (int i = 0; i != 2; i++)
-  {
+  for (int i=0; i<4; ++i) {
+    const int m = (1 << i);
     EIGEN_UNROLL_LOOP
-    for (int j = 0; j != 2; j++)
-    {
+    for (int j=0; j<m; ++j) {
+      const int n = (1 << (3-i));
       EIGEN_UNROLL_LOOP
-      for (int k = 0; k != 2; k++)
-        zip32[i*4+j*2+k] = vzipq_u32(vreinterpretq_u32_u16(zip16[i*4+j].val[k]),
-            vreinterpretq_u32_u16(zip16[i*4+j+2].val[k]));
-    }
-  }
-
-  EIGEN_UNROLL_LOOP
-  for (int i = 0; i != 4; i++)
-  {
-    EIGEN_UNROLL_LOOP
-    for (int j = 0; j != 2; j++)
-    {
-      kernel.packet[i*4+j*2] = vreinterpretq_u8_u32(vcombine_u32(vget_low_u32(zip32[i].val[j]),
-          vget_low_u32(zip32[i+4].val[j])));
-      kernel.packet[i*4+j*2+1] = vreinterpretq_u8_u32(vcombine_u32(vget_high_u32(zip32[i].val[j]),
-          vget_high_u32(zip32[i+4].val[j])));
+      for (int k=0; k<n; ++k) {
+        const int idx = 2*j*n+k;
+        zip_in_place(kernel.packet[idx], kernel.packet[idx + n]);
+      }
     }
   }
 }
-EIGEN_DEVICE_FUNC inline void ptranspose(PacketBlock<Packet4s, 4>& kernel)
-{
-  const int16x4x2_t zip16_1 = vzip_s16(kernel.packet[0], kernel.packet[1]);
-  const int16x4x2_t zip16_2 = vzip_s16(kernel.packet[2], kernel.packet[3]);
 
-  const uint32x2x2_t zip32_1 = vzip_u32(vreinterpret_u32_s16(zip16_1.val[0]), vreinterpret_u32_s16(zip16_2.val[0]));
-  const uint32x2x2_t zip32_2 = vzip_u32(vreinterpret_u32_s16(zip16_1.val[1]), vreinterpret_u32_s16(zip16_2.val[1]));
+} // namespace detail
 
-  kernel.packet[0] = vreinterpret_s16_u32(zip32_1.val[0]);
-  kernel.packet[1] = vreinterpret_s16_u32(zip32_1.val[1]);
-  kernel.packet[2] = vreinterpret_s16_u32(zip32_2.val[0]);
-  kernel.packet[3] = vreinterpret_s16_u32(zip32_2.val[1]);
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet2f, 2>& kernel) {
+  detail::ptranspose_impl(kernel);
 }
-
-EIGEN_DEVICE_FUNC inline void ptranspose(PacketBlock<Packet8s, 4>& kernel)
-{
-  const int16x8x2_t zip16_1 = vzipq_s16(kernel.packet[0], kernel.packet[1]);
-  const int16x8x2_t zip16_2 = vzipq_s16(kernel.packet[2], kernel.packet[3]);
-
-  const uint32x4x2_t zip32_1 = vzipq_u32(vreinterpretq_u32_s16(zip16_1.val[0]), vreinterpretq_u32_s16(zip16_2.val[0]));
-  const uint32x4x2_t zip32_2 = vzipq_u32(vreinterpretq_u32_s16(zip16_1.val[1]), vreinterpretq_u32_s16(zip16_2.val[1]));
-
-  kernel.packet[0] = vreinterpretq_s16_u32(zip32_1.val[0]);
-  kernel.packet[1] = vreinterpretq_s16_u32(zip32_1.val[1]);
-  kernel.packet[2] = vreinterpretq_s16_u32(zip32_2.val[0]);
-  kernel.packet[3] = vreinterpretq_s16_u32(zip32_2.val[1]);
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet4f, 4>& kernel) {
+  detail::ptranspose_impl(kernel);
 }
 
-EIGEN_DEVICE_FUNC inline void ptranspose(PacketBlock<Packet16uc, 4>& kernel)
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet4c, 4>& kernel)
 {
-  const uint8x16x2_t zip8_1 = vzipq_u8(kernel.packet[0], kernel.packet[1]);
-  const uint8x16x2_t zip8_2 = vzipq_u8(kernel.packet[2], kernel.packet[3]);
+  const int8x8_t a = vreinterpret_s8_s32(vset_lane_s32(kernel.packet[2], vdup_n_s32(kernel.packet[0]), 1));
+  const int8x8_t b = vreinterpret_s8_s32(vset_lane_s32(kernel.packet[3], vdup_n_s32(kernel.packet[1]), 1));
 
-  const uint16x8x2_t zip16_1 = vzipq_u16(vreinterpretq_u16_u8(zip8_1.val[0]), vreinterpretq_u16_u8(zip8_2.val[0]));
-  const uint16x8x2_t zip16_2 = vzipq_u16(vreinterpretq_u16_u8(zip8_1.val[1]), vreinterpretq_u16_u8(zip8_2.val[1]));
+  const int8x8x2_t zip8 = vzip_s8(a,b);
+  const int16x4x2_t zip16 = vzip_s16(vreinterpret_s16_s8(zip8.val[0]), vreinterpret_s16_s8(zip8.val[1]));
 
-  kernel.packet[0] = vreinterpretq_u8_u16(zip16_1.val[0]);
-  kernel.packet[1] = vreinterpretq_u8_u16(zip16_1.val[1]);
-  kernel.packet[2] = vreinterpretq_u8_u16(zip16_2.val[0]);
-  kernel.packet[3] = vreinterpretq_u8_u16(zip16_2.val[1]);
+  kernel.packet[0] = vget_lane_s32(vreinterpret_s32_s16(zip16.val[0]), 0);
+  kernel.packet[1] = vget_lane_s32(vreinterpret_s32_s16(zip16.val[0]), 1);
+  kernel.packet[2] = vget_lane_s32(vreinterpret_s32_s16(zip16.val[1]), 0);
+  kernel.packet[3] = vget_lane_s32(vreinterpret_s32_s16(zip16.val[1]), 1);
+}
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet8c, 8>& kernel) {
+  detail::ptranspose_impl(kernel);
+}
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet8c, 4>& kernel) {
+  detail::ptranspose_impl(kernel);
+}
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet16c, 16>& kernel) {
+  detail::ptranspose_impl(kernel);
+}
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet16c, 8>& kernel) {
+  detail::ptranspose_impl(kernel);
+}
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet16c, 4>& kernel) {
+  detail::ptranspose_impl(kernel);
 }
 
-EIGEN_DEVICE_FUNC inline void ptranspose(PacketBlock<Packet8s, 8>& kernel)
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet4uc, 4>& kernel)
 {
-  const int16x8x2_t zip16_1 = vzipq_s16(kernel.packet[0], kernel.packet[1]);
-  const int16x8x2_t zip16_2 = vzipq_s16(kernel.packet[2], kernel.packet[3]);
-  const int16x8x2_t zip16_3 = vzipq_s16(kernel.packet[4], kernel.packet[5]);
-  const int16x8x2_t zip16_4 = vzipq_s16(kernel.packet[6], kernel.packet[7]);
+  const uint8x8_t a = vreinterpret_u8_u32(vset_lane_u32(kernel.packet[2], vdup_n_u32(kernel.packet[0]), 1));
+  const uint8x8_t b = vreinterpret_u8_u32(vset_lane_u32(kernel.packet[3], vdup_n_u32(kernel.packet[1]), 1));
 
-  const uint32x4x2_t zip32_1 = vzipq_u32(vreinterpretq_u32_s16(zip16_1.val[0]), vreinterpretq_u32_s16(zip16_2.val[0]));
-  const uint32x4x2_t zip32_2 = vzipq_u32(vreinterpretq_u32_s16(zip16_1.val[1]), vreinterpretq_u32_s16(zip16_2.val[1]));
-  const uint32x4x2_t zip32_3 = vzipq_u32(vreinterpretq_u32_s16(zip16_3.val[0]), vreinterpretq_u32_s16(zip16_4.val[0]));
-  const uint32x4x2_t zip32_4 = vzipq_u32(vreinterpretq_u32_s16(zip16_3.val[1]), vreinterpretq_u32_s16(zip16_4.val[1]));
+  const uint8x8x2_t zip8 = vzip_u8(a,b);
+  const uint16x4x2_t zip16 = vzip_u16(vreinterpret_u16_u8(zip8.val[0]), vreinterpret_u16_u8(zip8.val[1]));
 
-  kernel.packet[0] = vreinterpretq_s16_u32(vcombine_u32(vget_low_u32(zip32_1.val[0]), vget_low_u32(zip32_3.val[0])));
-  kernel.packet[1] = vreinterpretq_s16_u32(vcombine_u32(vget_high_u32(zip32_1.val[0]), vget_high_u32(zip32_3.val[0])));
-  kernel.packet[2] = vreinterpretq_s16_u32(vcombine_u32(vget_low_u32(zip32_1.val[1]), vget_low_u32(zip32_3.val[1])));
-  kernel.packet[3] = vreinterpretq_s16_u32(vcombine_u32(vget_high_u32(zip32_1.val[1]), vget_high_u32(zip32_3.val[1])));
-  kernel.packet[4] = vreinterpretq_s16_u32(vcombine_u32(vget_low_u32(zip32_2.val[0]), vget_low_u32(zip32_4.val[0])));
-  kernel.packet[5] = vreinterpretq_s16_u32(vcombine_u32(vget_high_u32(zip32_2.val[0]), vget_high_u32(zip32_4.val[0])));
-  kernel.packet[6] = vreinterpretq_s16_u32(vcombine_u32(vget_low_u32(zip32_2.val[1]), vget_low_u32(zip32_4.val[1])));
-  kernel.packet[7] = vreinterpretq_s16_u32(vcombine_u32(vget_high_u32(zip32_2.val[1]), vget_high_u32(zip32_4.val[1])));
+  kernel.packet[0] = vget_lane_u32(vreinterpret_u32_u16(zip16.val[0]), 0);
+  kernel.packet[1] = vget_lane_u32(vreinterpret_u32_u16(zip16.val[0]), 1);
+  kernel.packet[2] = vget_lane_u32(vreinterpret_u32_u16(zip16.val[1]), 0);
+  kernel.packet[3] = vget_lane_u32(vreinterpret_u32_u16(zip16.val[1]), 1);
 }
-EIGEN_DEVICE_FUNC inline void ptranspose(PacketBlock<Packet4us, 4>& kernel)
-{
-  const uint16x4x2_t zip16_1 = vzip_u16(kernel.packet[0], kernel.packet[1]);
-  const uint16x4x2_t zip16_2 = vzip_u16(kernel.packet[2], kernel.packet[3]);
-
-  const uint32x2x2_t zip32_1 = vzip_u32(vreinterpret_u32_u16(zip16_1.val[0]), vreinterpret_u32_u16(zip16_2.val[0]));
-  const uint32x2x2_t zip32_2 = vzip_u32(vreinterpret_u32_u16(zip16_1.val[1]), vreinterpret_u32_u16(zip16_2.val[1]));
-
-  kernel.packet[0] = vreinterpret_u16_u32(zip32_1.val[0]);
-  kernel.packet[1] = vreinterpret_u16_u32(zip32_1.val[1]);
-  kernel.packet[2] = vreinterpret_u16_u32(zip32_2.val[0]);
-  kernel.packet[3] = vreinterpret_u16_u32(zip32_2.val[1]);
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet8uc, 8>& kernel) {
+  detail::ptranspose_impl(kernel);
+}
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet8uc, 4>& kernel) {
+  detail::ptranspose_impl(kernel);
+}
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet16uc, 16>& kernel) {
+  detail::ptranspose_impl(kernel);
+}
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet16uc, 8>& kernel) {
+  detail::ptranspose_impl(kernel);
+}
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet16uc, 4>& kernel) {
+  detail::ptranspose_impl(kernel);
 }
-EIGEN_DEVICE_FUNC inline void ptranspose(PacketBlock<Packet8us, 8>& kernel)
-{
-  const uint16x8x2_t zip16_1 = vzipq_u16(kernel.packet[0], kernel.packet[1]);
-  const uint16x8x2_t zip16_2 = vzipq_u16(kernel.packet[2], kernel.packet[3]);
-  const uint16x8x2_t zip16_3 = vzipq_u16(kernel.packet[4], kernel.packet[5]);
-  const uint16x8x2_t zip16_4 = vzipq_u16(kernel.packet[6], kernel.packet[7]);
-
-  const uint32x4x2_t zip32_1 = vzipq_u32(vreinterpretq_u32_u16(zip16_1.val[0]), vreinterpretq_u32_u16(zip16_2.val[0]));
-  const uint32x4x2_t zip32_2 = vzipq_u32(vreinterpretq_u32_u16(zip16_1.val[1]), vreinterpretq_u32_u16(zip16_2.val[1]));
-  const uint32x4x2_t zip32_3 = vzipq_u32(vreinterpretq_u32_u16(zip16_3.val[0]), vreinterpretq_u32_u16(zip16_4.val[0]));
-  const uint32x4x2_t zip32_4 = vzipq_u32(vreinterpretq_u32_u16(zip16_3.val[1]), vreinterpretq_u32_u16(zip16_4.val[1]));
 
-  kernel.packet[0] = vreinterpretq_u16_u32(vcombine_u32(vget_low_u32(zip32_1.val[0]), vget_low_u32(zip32_3.val[0])));
-  kernel.packet[1] = vreinterpretq_u16_u32(vcombine_u32(vget_high_u32(zip32_1.val[0]), vget_high_u32(zip32_3.val[0])));
-  kernel.packet[2] = vreinterpretq_u16_u32(vcombine_u32(vget_low_u32(zip32_1.val[1]), vget_low_u32(zip32_3.val[1])));
-  kernel.packet[3] = vreinterpretq_u16_u32(vcombine_u32(vget_high_u32(zip32_1.val[1]), vget_high_u32(zip32_3.val[1])));
-  kernel.packet[4] = vreinterpretq_u16_u32(vcombine_u32(vget_low_u32(zip32_2.val[0]), vget_low_u32(zip32_4.val[0])));
-  kernel.packet[5] = vreinterpretq_u16_u32(vcombine_u32(vget_high_u32(zip32_2.val[0]), vget_high_u32(zip32_4.val[0])));
-  kernel.packet[6] = vreinterpretq_u16_u32(vcombine_u32(vget_low_u32(zip32_2.val[1]), vget_low_u32(zip32_4.val[1])));
-  kernel.packet[7] = vreinterpretq_u16_u32(vcombine_u32(vget_high_u32(zip32_2.val[1]), vget_high_u32(zip32_4.val[1])));
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet4s, 4>& kernel) {
+  detail::ptranspose_impl(kernel);
 }
-EIGEN_DEVICE_FUNC inline void ptranspose(PacketBlock<Packet2i, 2>& kernel)
-{
-  const int32x2x2_t z = vzip_s32(kernel.packet[0], kernel.packet[1]);
-  kernel.packet[0] = z.val[0];
-  kernel.packet[1] = z.val[1];
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet8s, 8>& kernel) {
+  detail::ptranspose_impl(kernel);
+}
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet8s, 4>& kernel) {
+  detail::ptranspose_impl(kernel);
 }
-EIGEN_DEVICE_FUNC inline void ptranspose(PacketBlock<Packet4i, 4>& kernel)
-{
-  const int32x4x2_t tmp1 = vzipq_s32(kernel.packet[0], kernel.packet[1]);
-  const int32x4x2_t tmp2 = vzipq_s32(kernel.packet[2], kernel.packet[3]);
 
-  kernel.packet[0] = vcombine_s32(vget_low_s32(tmp1.val[0]), vget_low_s32(tmp2.val[0]));
-  kernel.packet[1] = vcombine_s32(vget_high_s32(tmp1.val[0]), vget_high_s32(tmp2.val[0]));
-  kernel.packet[2] = vcombine_s32(vget_low_s32(tmp1.val[1]), vget_low_s32(tmp2.val[1]));
-  kernel.packet[3] = vcombine_s32(vget_high_s32(tmp1.val[1]), vget_high_s32(tmp2.val[1]));
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet4us, 4>& kernel) {
+  detail::ptranspose_impl(kernel);
 }
-EIGEN_DEVICE_FUNC inline void ptranspose(PacketBlock<Packet2ui, 2>& kernel)
-{
-  const uint32x2x2_t z = vzip_u32(kernel.packet[0], kernel.packet[1]);
-  kernel.packet[0] = z.val[0];
-  kernel.packet[1] = z.val[1];
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet8us, 8>& kernel) {
+  detail::ptranspose_impl(kernel);
+}
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet8us, 4>& kernel) {
+  detail::ptranspose_impl(kernel);
 }
-EIGEN_DEVICE_FUNC inline void ptranspose(PacketBlock<Packet4ui, 4>& kernel)
-{
-  const uint32x4x2_t tmp1 = vzipq_u32(kernel.packet[0], kernel.packet[1]);
-  const uint32x4x2_t tmp2 = vzipq_u32(kernel.packet[2], kernel.packet[3]);
 
-  kernel.packet[0] = vcombine_u32(vget_low_u32(tmp1.val[0]), vget_low_u32(tmp2.val[0]));
-  kernel.packet[1] = vcombine_u32(vget_high_u32(tmp1.val[0]), vget_high_u32(tmp2.val[0]));
-  kernel.packet[2] = vcombine_u32(vget_low_u32(tmp1.val[1]), vget_low_u32(tmp2.val[1]));
-  kernel.packet[3] = vcombine_u32(vget_high_u32(tmp1.val[1]), vget_high_u32(tmp2.val[1]));
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet2i, 2>& kernel) {
+  detail::ptranspose_impl(kernel);
+}
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet4i, 4>& kernel) {
+    detail::ptranspose_impl(kernel);
+}
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet2ui, 2>& kernel) {
+  detail::zip_in_place(kernel.packet[0], kernel.packet[1]);
 }
-EIGEN_DEVICE_FUNC inline void
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet4ui, 4>& kernel) {
+  detail::ptranspose_impl(kernel);
+}
+
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void
 ptranspose(PacketBlock<Packet2l, 2>& kernel)
 {
 #if EIGEN_ARCH_ARM64
   const int64x2_t tmp1 = vzip1q_s64(kernel.packet[0], kernel.packet[1]);
-  const int64x2_t tmp2 = vzip2q_s64(kernel.packet[0], kernel.packet[1]);
-
+  kernel.packet[1] = vzip2q_s64(kernel.packet[0], kernel.packet[1]);
   kernel.packet[0] = tmp1;
-  kernel.packet[1] = tmp2;
 #else
   const int64x1_t tmp[2][2] = {
     { vget_low_s64(kernel.packet[0]), vget_high_s64(kernel.packet[0]) },
     { vget_low_s64(kernel.packet[1]), vget_high_s64(kernel.packet[1]) }
   };
 
   kernel.packet[0] = vcombine_s64(tmp[0][0], tmp[1][0]);
   kernel.packet[1] = vcombine_s64(tmp[0][1], tmp[1][1]);
 #endif
 }
-EIGEN_DEVICE_FUNC inline void
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void
 ptranspose(PacketBlock<Packet2ul, 2>& kernel)
 {
 #if EIGEN_ARCH_ARM64
   const uint64x2_t tmp1 = vzip1q_u64(kernel.packet[0], kernel.packet[1]);
-  const uint64x2_t tmp2 = vzip2q_u64(kernel.packet[0], kernel.packet[1]);
-
+  kernel.packet[1] = vzip2q_u64(kernel.packet[0], kernel.packet[1]);
   kernel.packet[0] = tmp1;
-  kernel.packet[1] = tmp2;
 #else
   const uint64x1_t tmp[2][2] = {
     { vget_low_u64(kernel.packet[0]), vget_high_u64(kernel.packet[0]) },
     { vget_low_u64(kernel.packet[1]), vget_high_u64(kernel.packet[1]) }
   };
 
   kernel.packet[0] = vcombine_u64(tmp[0][0], tmp[1][0]);
   kernel.packet[1] = vcombine_u64(tmp[0][1], tmp[1][1]);
 #endif
 }
 
-template<> EIGEN_DEVICE_FUNC inline Packet2f pselect( const Packet2f& mask, const Packet2f& a, const Packet2f& b)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet2f pselect( const Packet2f& mask, const Packet2f& a, const Packet2f& b)
 { return vbsl_f32(vreinterpret_u32_f32(mask), a, b); }
-template<> EIGEN_DEVICE_FUNC inline Packet4f pselect(const Packet4f& mask, const Packet4f& a, const Packet4f& b)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4f pselect(const Packet4f& mask, const Packet4f& a, const Packet4f& b)
 { return vbslq_f32(vreinterpretq_u32_f32(mask), a, b); }
-template<> EIGEN_DEVICE_FUNC inline Packet8c pselect(const Packet8c& mask, const Packet8c& a, const Packet8c& b)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet8c pselect(const Packet8c& mask, const Packet8c& a, const Packet8c& b)
 { return vbsl_s8(vreinterpret_u8_s8(mask), a, b); }
-template<> EIGEN_DEVICE_FUNC inline Packet16c pselect(const Packet16c& mask, const Packet16c& a, const Packet16c& b)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet16c pselect(const Packet16c& mask, const Packet16c& a, const Packet16c& b)
 { return vbslq_s8(vreinterpretq_u8_s8(mask), a, b); }
-template<> EIGEN_DEVICE_FUNC inline Packet8uc pselect(const Packet8uc& mask, const Packet8uc& a, const Packet8uc& b)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet8uc pselect(const Packet8uc& mask, const Packet8uc& a, const Packet8uc& b)
 { return vbsl_u8(mask, a, b); }
-template<> EIGEN_DEVICE_FUNC inline Packet16uc pselect(const Packet16uc& mask, const Packet16uc& a, const Packet16uc& b)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet16uc pselect(const Packet16uc& mask, const Packet16uc& a, const Packet16uc& b)
 { return vbslq_u8(mask, a, b); }
-template<> EIGEN_DEVICE_FUNC inline Packet4s pselect(const Packet4s& mask, const Packet4s& a, const Packet4s& b)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4s pselect(const Packet4s& mask, const Packet4s& a, const Packet4s& b)
 { return vbsl_s16(vreinterpret_u16_s16(mask), a, b); }
-template<> EIGEN_DEVICE_FUNC inline Packet8s pselect(const Packet8s& mask, const Packet8s& a, const Packet8s& b)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet8s pselect(const Packet8s& mask, const Packet8s& a, const Packet8s& b)
 { return vbslq_s16(vreinterpretq_u16_s16(mask), a, b); }
-template<> EIGEN_DEVICE_FUNC inline Packet4us pselect(const Packet4us& mask, const Packet4us& a, const Packet4us& b)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4us pselect(const Packet4us& mask, const Packet4us& a, const Packet4us& b)
 { return vbsl_u16(mask, a, b); }
-template<> EIGEN_DEVICE_FUNC inline Packet8us pselect(const Packet8us& mask, const Packet8us& a, const Packet8us& b)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet8us pselect(const Packet8us& mask, const Packet8us& a, const Packet8us& b)
 { return vbslq_u16(mask, a, b); }
-template<> EIGEN_DEVICE_FUNC inline Packet2i pselect(const Packet2i& mask, const Packet2i& a, const Packet2i& b)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet2i pselect(const Packet2i& mask, const Packet2i& a, const Packet2i& b)
 { return vbsl_s32(vreinterpret_u32_s32(mask), a, b); }
-template<> EIGEN_DEVICE_FUNC inline Packet4i pselect(const Packet4i& mask, const Packet4i& a, const Packet4i& b)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4i pselect(const Packet4i& mask, const Packet4i& a, const Packet4i& b)
 { return vbslq_s32(vreinterpretq_u32_s32(mask), a, b); }
-template<> EIGEN_DEVICE_FUNC inline Packet2ui pselect(const Packet2ui& mask, const Packet2ui& a, const Packet2ui& b)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet2ui pselect(const Packet2ui& mask, const Packet2ui& a, const Packet2ui& b)
 { return vbsl_u32(mask, a, b); }
-template<> EIGEN_DEVICE_FUNC inline Packet4ui pselect(const Packet4ui& mask, const Packet4ui& a, const Packet4ui& b)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4ui pselect(const Packet4ui& mask, const Packet4ui& a, const Packet4ui& b)
 { return vbslq_u32(mask, a, b); }
-template<> EIGEN_DEVICE_FUNC inline Packet2l pselect(const Packet2l& mask, const Packet2l& a, const Packet2l& b)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet2l pselect(const Packet2l& mask, const Packet2l& a, const Packet2l& b)
 { return vbslq_s64(vreinterpretq_u64_s64(mask), a, b); }
-template<> EIGEN_DEVICE_FUNC inline Packet2ul pselect(const Packet2ul& mask, const Packet2ul& a, const Packet2ul& b)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet2ul pselect(const Packet2ul& mask, const Packet2ul& a, const Packet2ul& b)
 { return vbslq_u64(mask, a, b); }
 
+// Use armv8 rounding intinsics if available.
+#if EIGEN_ARCH_ARMV8
+template<> EIGEN_STRONG_INLINE Packet2f print<Packet2f>(const Packet2f& a)
+{ return vrndn_f32(a); }
+
+template<> EIGEN_STRONG_INLINE Packet4f print<Packet4f>(const Packet4f& a)
+{ return vrndnq_f32(a); }
+
+template<> EIGEN_STRONG_INLINE Packet2f pfloor<Packet2f>(const Packet2f& a)
+{ return vrndm_f32(a); }
+
+template<> EIGEN_STRONG_INLINE Packet4f pfloor<Packet4f>(const Packet4f& a)
+{ return vrndmq_f32(a); }
+
+template<> EIGEN_STRONG_INLINE Packet2f pceil<Packet2f>(const Packet2f& a)
+{ return vrndp_f32(a); }
+
+template<> EIGEN_STRONG_INLINE Packet4f pceil<Packet4f>(const Packet4f& a)
+{ return vrndpq_f32(a); }
+
+#else
+
+template<> EIGEN_STRONG_INLINE Packet4f print(const Packet4f& a) {
+  // Adds and subtracts signum(a) * 2^23 to force rounding.
+  const Packet4f limit = pset1<Packet4f>(static_cast<float>(1<<23));
+  const Packet4f abs_a = pabs(a);
+  Packet4f r = padd(abs_a, limit);
+  // Don't compile-away addition and subtraction.
+  EIGEN_OPTIMIZATION_BARRIER(r);
+  r = psub(r, limit);
+  // If greater than limit, simply return a.  Otherwise, account for sign.
+  r = pselect(pcmp_lt(abs_a, limit),
+              pselect(pcmp_lt(a, pzero(a)), pnegate(r), r), a);
+  return r;
+}
+
+template<> EIGEN_STRONG_INLINE Packet2f print(const Packet2f& a) {
+  // Adds and subtracts signum(a) * 2^23 to force rounding.
+  const Packet2f limit = pset1<Packet2f>(static_cast<float>(1<<23));
+  const Packet2f abs_a = pabs(a);
+  Packet2f r = padd(abs_a, limit);
+  // Don't compile-away addition and subtraction.
+  EIGEN_OPTIMIZATION_BARRIER(r);
+  r = psub(r, limit);
+  // If greater than limit, simply return a.  Otherwise, account for sign.
+  r = pselect(pcmp_lt(abs_a, limit),
+              pselect(pcmp_lt(a, pzero(a)), pnegate(r), r), a);
+  return r;
+}
+
+template<> EIGEN_STRONG_INLINE Packet4f pfloor<Packet4f>(const Packet4f& a)
+{
+  const Packet4f cst_1 = pset1<Packet4f>(1.0f);
+  Packet4f tmp  = print<Packet4f>(a);
+  // If greater, subtract one.
+  Packet4f mask = pcmp_lt(a, tmp);
+  mask = pand(mask, cst_1);
+  return psub(tmp, mask);
+}
+
+template<> EIGEN_STRONG_INLINE Packet2f pfloor<Packet2f>(const Packet2f& a)
+{
+  const Packet2f cst_1 = pset1<Packet2f>(1.0f);
+  Packet2f tmp  = print<Packet2f>(a);
+  // If greater, subtract one.
+  Packet2f mask = pcmp_lt(a, tmp);
+  mask = pand(mask, cst_1);
+  return psub(tmp, mask);
+}
+
+template<> EIGEN_STRONG_INLINE Packet4f pceil<Packet4f>(const Packet4f& a)
+{
+  const Packet4f cst_1 = pset1<Packet4f>(1.0f);
+  Packet4f tmp  = print<Packet4f>(a);
+  // If smaller, add one.
+  Packet4f mask = pcmp_lt(tmp, a);
+  mask = pand(mask, cst_1);
+  return padd(tmp, mask);
+}
+
+template<> EIGEN_STRONG_INLINE Packet2f pceil<Packet2f>(const Packet2f& a)
+{
+  const Packet2f cst_1 = pset1<Packet2f>(1.0);
+  Packet2f tmp  = print<Packet2f>(a);
+  // If smaller, add one.
+  Packet2f mask = pcmp_lt(tmp, a);
+  mask = pand(mask, cst_1);
+  return padd(tmp, mask);
+}
+
+#endif
+
 /**
  * Computes the integer square root
  * @remarks The calculation is performed using an algorithm which iterates through each binary digit of the result
  *   and tests whether setting that digit to 1 would cause the square of the value to be greater than the argument
  *   value. The algorithm is described in detail here: http://ww1.microchip.com/downloads/en/AppNotes/91040a.pdf .
  */
 template<> EIGEN_STRONG_INLINE Packet4uc psqrt(const Packet4uc& a) {
@@ -3214,14 +3269,51 @@
     const uint32x4_t temp = vorrq_u32(res, add);
     res = vbslq_u32(vcgeq_u32(a, vmulq_u32(temp, temp)), temp, res);
     add = vshrq_n_u32(add, 1);
   }
   return res;
 }
 
+template<> EIGEN_STRONG_INLINE Packet4f prsqrt(const Packet4f& a) {
+  // Compute approximate reciprocal sqrt.
+  Packet4f x = vrsqrteq_f32(a);
+  // Do Newton iterations for 1/sqrt(x).
+  x = vmulq_f32(vrsqrtsq_f32(vmulq_f32(a, x), x), x);
+  x = vmulq_f32(vrsqrtsq_f32(vmulq_f32(a, x), x), x);
+  const Packet4f infinity = pset1<Packet4f>(NumTraits<float>::infinity());
+  return pselect(pcmp_eq(a, pzero(a)), infinity, x);
+}
+
+template<> EIGEN_STRONG_INLINE Packet2f prsqrt(const Packet2f& a) {
+  // Compute approximate reciprocal sqrt.
+  Packet2f x = vrsqrte_f32(a);
+  // Do Newton iterations for 1/sqrt(x).
+  x = vmul_f32(vrsqrts_f32(vmul_f32(a, x), x), x);
+  x = vmul_f32(vrsqrts_f32(vmul_f32(a, x), x), x);
+  const Packet2f infinity = pset1<Packet2f>(NumTraits<float>::infinity());
+  return pselect(pcmp_eq(a, pzero(a)), infinity, x);
+}
+
+// Unfortunately vsqrt_f32 is only available for A64.
+#if EIGEN_ARCH_ARM64
+template<> EIGEN_STRONG_INLINE Packet4f psqrt(const Packet4f& _x){return vsqrtq_f32(_x);}
+template<> EIGEN_STRONG_INLINE Packet2f psqrt(const Packet2f& _x){return vsqrt_f32(_x); }
+#else
+template<> EIGEN_STRONG_INLINE Packet4f psqrt(const Packet4f& a) {
+  const Packet4f infinity = pset1<Packet4f>(NumTraits<float>::infinity());
+  const Packet4f is_zero_or_inf = por(pcmp_eq(a, pzero(a)), pcmp_eq(a, infinity));
+  return pselect(is_zero_or_inf, a, pmul(a, prsqrt(a)));
+}
+template<> EIGEN_STRONG_INLINE Packet2f psqrt(const Packet2f& a) {
+  const Packet2f infinity = pset1<Packet2f>(NumTraits<float>::infinity());
+  const Packet2f is_zero_or_inf = por(pcmp_eq(a, pzero(a)), pcmp_eq(a, infinity));
+  return pselect(is_zero_or_inf, a, pmul(a, prsqrt(a)));
+}
+#endif
+
 //---------- bfloat16 ----------
 // TODO: Add support for native armv8.6-a bfloat16_t
 
 // TODO: Guard if we have native bfloat16 support
 typedef eigen_packet_wrapper<uint16x4_t, 19> Packet4bf;
 
 template<> struct is_arithmetic<Packet4bf> { enum { value = true }; };
@@ -3250,22 +3342,26 @@
     HasMin       = 1,
     HasMax       = 1,
     HasConj      = 1,
     HasSetLinear = 0,
     HasBlend     = 0,
     HasDiv       = 1,
     HasFloor     = 1,
+    HasCeil      = 1,
+    HasRint      = 1,
 
     HasSin  = EIGEN_FAST_MATH,
     HasCos  = EIGEN_FAST_MATH,
     HasLog  = 1,
     HasExp  = 1,
     HasSqrt = 0,
     HasTanh = EIGEN_FAST_MATH,
-    HasErf  = EIGEN_FAST_MATH
+    HasErf  = EIGEN_FAST_MATH,
+    HasBessel = 0,  // Issues with accuracy.
+    HasNdtri = 0
   };
 };
 
 template<> struct unpacket_traits<Packet4bf>
 {
   typedef bfloat16 type;
   typedef Packet4bf half;
@@ -3275,14 +3371,23 @@
     alignment = Aligned16,
     vectorizable = true,
     masked_load_available = false,
     masked_store_available = false
   };
 };
 
+namespace detail {  
+template<>
+EIGEN_ALWAYS_INLINE void zip_in_place<Packet4bf>(Packet4bf& p1, Packet4bf& p2) {
+  const uint16x4x2_t tmp = vzip_u16(p1, p2);
+  p1 = tmp.val[0];
+  p2 = tmp.val[1];
+}
+} // namespace detail
+
 EIGEN_STRONG_INLINE Packet4bf F32ToBf16(const Packet4f& p)
 {
   // See the scalar implemention in BFloat16.h for a comprehensible explanation
   // of this fast rounding algorithm
   Packet4ui input = reinterpret_cast<Packet4ui>(p);
 
   // lsb = (input >> 16) & 1
@@ -3307,14 +3412,18 @@
 }
 
 EIGEN_STRONG_INLINE Packet4f Bf16ToF32(const Packet4bf& p)
 {
   return reinterpret_cast<Packet4f>(vshlq_n_u32(vmovl_u16(p), 16));
 }
 
+EIGEN_STRONG_INLINE Packet4bf F32MaskToBf16Mask(const Packet4f& p) {
+  return vmovn_u32(vreinterpretq_u32_f32(p));
+}
+
 template<> EIGEN_STRONG_INLINE Packet4bf pset1<Packet4bf>(const bfloat16& from) {
   return pset1<Packet4us>(from.value);
 }
 
 template<> EIGEN_STRONG_INLINE bfloat16 pfirst<Packet4bf>(const Packet4bf& from) {
   return bfloat16_impl::raw_uint16_to_bfloat16(static_cast<uint16_t>(pfirst<Packet4us>(from)));
 }
@@ -3344,26 +3453,53 @@
   return ploaddup<Packet4us>(reinterpret_cast<const uint16_t*>(from));
 }
 
 template <> EIGEN_STRONG_INLINE Packet4bf pabs(const Packet4bf& a) {
   return F32ToBf16(pabs<Packet4f>(Bf16ToF32(a)));
 }
 
+template <> EIGEN_STRONG_INLINE Packet4bf pmin<PropagateNumbers, Packet4bf>(const Packet4bf &a,
+                                                                            const Packet4bf &b)
+{
+  return F32ToBf16(pmin<PropagateNumbers, Packet4f>(Bf16ToF32(a), Bf16ToF32(b)));
+}
+template <> EIGEN_STRONG_INLINE Packet4bf pmin<PropagateNaN, Packet4bf>(const Packet4bf &a,
+                                                                        const Packet4bf &b)
+{
+  return F32ToBf16(pmin<PropagateNaN, Packet4f>(Bf16ToF32(a), Bf16ToF32(b)));
+}
+
 template <> EIGEN_STRONG_INLINE Packet4bf pmin<Packet4bf>(const Packet4bf &a,
                                                           const Packet4bf &b)
 {
   return F32ToBf16(pmin<Packet4f>(Bf16ToF32(a), Bf16ToF32(b)));
 }
 
+template <> EIGEN_STRONG_INLINE Packet4bf pmax<PropagateNumbers, Packet4bf>(const Packet4bf &a,
+                                                                            const Packet4bf &b)
+{
+  return F32ToBf16(pmax<PropagateNumbers, Packet4f>(Bf16ToF32(a), Bf16ToF32(b)));
+}
+template <> EIGEN_STRONG_INLINE Packet4bf pmax<PropagateNaN, Packet4bf>(const Packet4bf &a,
+                                                                        const Packet4bf &b)
+{
+  return F32ToBf16(pmax<PropagateNaN, Packet4f>(Bf16ToF32(a), Bf16ToF32(b)));
+}
+
 template <> EIGEN_STRONG_INLINE Packet4bf pmax<Packet4bf>(const Packet4bf &a,
                                                           const Packet4bf &b)
 {
   return F32ToBf16(pmax<Packet4f>(Bf16ToF32(a), Bf16ToF32(b)));
 }
 
+template<> EIGEN_STRONG_INLINE Packet4bf plset<Packet4bf>(const bfloat16& a)
+{
+  return F32ToBf16(plset<Packet4f>(static_cast<float>(a)));
+}
+
 template<> EIGEN_STRONG_INLINE Packet4bf por(const Packet4bf& a,const Packet4bf& b) {
   return por<Packet4us>(a, b);
 }
 
 template<> EIGEN_STRONG_INLINE Packet4bf pxor(const Packet4bf& a,const Packet4bf& b) {
   return pxor<Packet4us>(a, b);
 }
@@ -3372,25 +3508,35 @@
   return pand<Packet4us>(a, b);
 }
 
 template<> EIGEN_STRONG_INLINE Packet4bf pandnot(const Packet4bf& a,const Packet4bf& b) {
   return pandnot<Packet4us>(a, b);
 }
 
-template<> EIGEN_DEVICE_FUNC inline Packet4bf pselect(const Packet4bf& mask, const Packet4bf& a,
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4bf pselect(const Packet4bf& mask, const Packet4bf& a,
                                                       const Packet4bf& b)
 {
   return pselect<Packet4us>(mask, a, b);
 }
 
+template<> EIGEN_STRONG_INLINE Packet4bf print<Packet4bf>(const Packet4bf& a)
+{
+  return F32ToBf16(print<Packet4f>(Bf16ToF32(a)));
+}
+
 template<> EIGEN_STRONG_INLINE Packet4bf pfloor<Packet4bf>(const Packet4bf& a)
 {
   return F32ToBf16(pfloor<Packet4f>(Bf16ToF32(a)));
 }
 
+template<> EIGEN_STRONG_INLINE Packet4bf pceil<Packet4bf>(const Packet4bf& a)
+{
+  return F32ToBf16(pceil<Packet4f>(Bf16ToF32(a)));
+}
+
 template<> EIGEN_STRONG_INLINE Packet4bf pconj(const Packet4bf& a) { return a; }
 
 template<> EIGEN_STRONG_INLINE Packet4bf padd<Packet4bf>(const Packet4bf& a, const Packet4bf& b) {
   return F32ToBf16(padd<Packet4f>(Bf16ToF32(a), Bf16ToF32(b)));
 }
 
 template<> EIGEN_STRONG_INLINE Packet4bf psub<Packet4bf>(const Packet4bf& a, const Packet4bf& b) {
@@ -3438,46 +3584,42 @@
 }
 
 template<> EIGEN_STRONG_INLINE Packet4bf preverse<Packet4bf>(const Packet4bf& a)
 {
   return preverse<Packet4us>(a);
 }
 
-EIGEN_DEVICE_FUNC inline void ptranspose(PacketBlock<Packet4bf, 4>& kernel)
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet4bf, 4>& kernel)
 {
-  PacketBlock<Packet4us, 4> k;
-  k.packet[0] = kernel.packet[0];
-  k.packet[1] = kernel.packet[1];
-  k.packet[2] = kernel.packet[2];
-  k.packet[3] = kernel.packet[3];
-  ptranspose(k);
-  kernel.packet[0] = k.packet[0];
-  kernel.packet[1] = k.packet[1];
-  kernel.packet[2] = k.packet[2];
-  kernel.packet[3] = k.packet[3];
+  detail::ptranspose_impl(kernel);
 }
 
 template<> EIGEN_STRONG_INLINE Packet4bf pabsdiff<Packet4bf>(const Packet4bf& a, const Packet4bf& b)
 {
   return F32ToBf16(pabsdiff<Packet4f>(Bf16ToF32(a), Bf16ToF32(b)));
 }
 
 template<> EIGEN_STRONG_INLINE Packet4bf pcmp_eq<Packet4bf>(const Packet4bf& a, const Packet4bf& b)
 {
-  return F32ToBf16(pcmp_eq<Packet4f>(Bf16ToF32(a), Bf16ToF32(b)));
+  return F32MaskToBf16Mask(pcmp_eq<Packet4f>(Bf16ToF32(a), Bf16ToF32(b)));
 }
 
 template<> EIGEN_STRONG_INLINE Packet4bf pcmp_lt<Packet4bf>(const Packet4bf& a, const Packet4bf& b)
 {
-  return F32ToBf16(pcmp_lt<Packet4f>(Bf16ToF32(a), Bf16ToF32(b)));
+  return F32MaskToBf16Mask(pcmp_lt<Packet4f>(Bf16ToF32(a), Bf16ToF32(b)));
+}
+
+template<> EIGEN_STRONG_INLINE Packet4bf pcmp_lt_or_nan<Packet4bf>(const Packet4bf& a, const Packet4bf& b)
+{
+  return F32MaskToBf16Mask(pcmp_lt_or_nan<Packet4f>(Bf16ToF32(a), Bf16ToF32(b)));
 }
 
 template<> EIGEN_STRONG_INLINE Packet4bf pcmp_le<Packet4bf>(const Packet4bf& a, const Packet4bf& b)
 {
-  return F32ToBf16(pcmp_le<Packet4f>(Bf16ToF32(a), Bf16ToF32(b)));
+  return F32MaskToBf16Mask(pcmp_le<Packet4f>(Bf16ToF32(a), Bf16ToF32(b)));
 }
 
 template<> EIGEN_STRONG_INLINE Packet4bf pnegate<Packet4bf>(const Packet4bf& a)
 {
   return pxor<Packet4us>(a, pset1<Packet4us>(static_cast<uint16_t>(0x8000)));
 }
 
@@ -3503,14 +3645,40 @@
 template <typename T> uint64x2_t vreinterpretq_u64_f64(T a) { return (uint64x2_t) a; }
 
 template <typename T> float64x2_t vreinterpretq_f64_u64(T a) { return (float64x2_t) a; }
 
 typedef float64x2_t Packet2d;
 typedef float64x1_t Packet1d;
 
+// fuctionally equivalent to _mm_shuffle_pd in SSE (i.e. shuffle(m, n, mask) equals _mm_shuffle_pd(m,n,mask))
+// Currently used in LU/arch/InverseSize4.h to enable a shared implementation
+// for fast inversion of matrices of size 4.
+EIGEN_STRONG_INLINE Packet2d shuffle(const Packet2d& m, const Packet2d& n, int mask)
+{
+  const double* a = reinterpret_cast<const double*>(&m);
+  const double* b = reinterpret_cast<const double*>(&n);
+  Packet2d res = {*(a + (mask & 1)), *(b + ((mask >> 1) & 1))};
+  return res;
+}
+
+EIGEN_STRONG_INLINE Packet2d vec2d_swizzle2(const Packet2d& a, const Packet2d& b, int mask)
+{
+  return shuffle(a, b, mask);
+}
+EIGEN_STRONG_INLINE Packet2d vec2d_unpacklo(const Packet2d& a,const Packet2d& b)
+{
+  return shuffle(a, b, 0);
+}
+EIGEN_STRONG_INLINE Packet2d vec2d_unpackhi(const Packet2d& a,const Packet2d& b)
+{
+  return shuffle(a, b, 3);
+}
+#define vec2d_duplane(a, p) \
+  vdupq_laneq_f64(a, p)
+
 template<> struct packet_traits<double>  : default_packet_traits
 {
   typedef Packet2d type;
   typedef Packet2d half;
   enum
   {
     Vectorizable = 1,
@@ -3531,21 +3699,24 @@
     HasMin       = 1,
     HasMax       = 1,
     HasConj      = 1,
     HasSetLinear = 0,
     HasBlend     = 0,
 
     HasDiv   = 1,
-    HasFloor = 0,
+    HasFloor = 1,
+    HasCeil = 1,
+    HasRint = 1,
 
     HasSin  = 0,
     HasCos  = 0,
-    HasLog  = 0,
-    HasExp  = 0,
-    HasSqrt = 0,
+    HasLog  = 1,
+    HasExp  = 1,
+    HasSqrt = 1,
+    HasRsqrt = 1,
     HasTanh = 0,
     HasErf  = 0
   };
 };
 
 template<> struct unpacket_traits<Packet2d>
 {
@@ -3570,14 +3741,20 @@
   return vaddq_f64(pset1<Packet2d>(a), vld1q_f64(c));
 }
 
 template<> EIGEN_STRONG_INLINE Packet2d padd<Packet2d>(const Packet2d& a, const Packet2d& b) { return vaddq_f64(a,b); }
 
 template<> EIGEN_STRONG_INLINE Packet2d psub<Packet2d>(const Packet2d& a, const Packet2d& b) { return vsubq_f64(a,b); }
 
+template<> EIGEN_STRONG_INLINE Packet2d pxor<Packet2d>(const Packet2d& , const Packet2d& );
+template<> EIGEN_STRONG_INLINE Packet2d paddsub<Packet2d>(const Packet2d& a, const Packet2d& b){
+  const Packet2d mask = {numext::bit_cast<double>(0x8000000000000000ull),0.0};
+  return padd(a, pxor(mask, b));
+}
+
 template<> EIGEN_STRONG_INLINE Packet2d pnegate(const Packet2d& a) { return vnegq_f64(a); }
 
 template<> EIGEN_STRONG_INLINE Packet2d pconj(const Packet2d& a) { return a; }
 
 template<> EIGEN_STRONG_INLINE Packet2d pmul<Packet2d>(const Packet2d& a, const Packet2d& b) { return vmulq_f64(a,b); }
 
 template<> EIGEN_STRONG_INLINE Packet2d pdiv<Packet2d>(const Packet2d& a, const Packet2d& b) { return vdivq_f64(a,b); }
@@ -3589,30 +3766,27 @@
 #else
 template<> EIGEN_STRONG_INLINE Packet2d pmadd(const Packet2d& a, const Packet2d& b, const Packet2d& c)
 { return vmlaq_f64(c,a,b); }
 #endif
 
 template<> EIGEN_STRONG_INLINE Packet2d pmin<Packet2d>(const Packet2d& a, const Packet2d& b) { return vminq_f64(a,b); }
 
+#ifdef __ARM_FEATURE_NUMERIC_MAXMIN
+// numeric max and min are only available if ARM_FEATURE_NUMERIC_MAXMIN is defined (which can only be the case for Armv8 systems).
+template<> EIGEN_STRONG_INLINE Packet2d pmin<PropagateNumbers, Packet2d>(const Packet2d& a, const Packet2d& b) { return vminnmq_f64(a, b); }
+template<> EIGEN_STRONG_INLINE Packet2d pmax<PropagateNumbers, Packet2d>(const Packet2d& a, const Packet2d& b) { return vmaxnmq_f64(a, b); }
+
+#endif
+
+template<> EIGEN_STRONG_INLINE Packet2d pmin<PropagateNaN, Packet2d>(const Packet2d& a, const Packet2d& b) { return pmin<Packet2d>(a, b); }
+
 template<> EIGEN_STRONG_INLINE Packet2d pmax<Packet2d>(const Packet2d& a, const Packet2d& b) { return vmaxq_f64(a,b); }
 
-// WARNING: this pfloor implementation makes sense for inputs that fit in
-// signed int64 integers (up to ~9.22e18), hence this is currently only used
-// by pexp and not exposed through HasFloor.
-template<> EIGEN_STRONG_INLINE Packet2d pfloor<Packet2d>(const Packet2d& a)
-{
-  const Packet2d cst_1 = pset1<Packet2d>(1.0);
-  /* perform a floorf */
-  const Packet2d tmp = vcvtq_f64_s64(vcvtq_s64_f64(a));
-
-  /* if greater, substract 1 */
-  uint64x2_t mask = vcgtq_f64(tmp, a);
-  mask = vandq_u64(mask, vreinterpretq_u64_f64(cst_1));
-  return vsubq_f64(tmp, vreinterpretq_f64_u64(mask));
-}
+
+template<> EIGEN_STRONG_INLINE Packet2d pmax<PropagateNaN, Packet2d>(const Packet2d& a, const Packet2d& b) { return pmax<Packet2d>(a, b); }
 
 // Logical Operations are not supported for float, so we have to reinterpret casts using NEON intrinsics
 template<> EIGEN_STRONG_INLINE Packet2d pand<Packet2d>(const Packet2d& a, const Packet2d& b)
 { return vreinterpretq_f64_u64(vandq_u64(vreinterpretq_u64_f64(a),vreinterpretq_u64_f64(b))); }
 
 template<> EIGEN_STRONG_INLINE Packet2d por<Packet2d>(const Packet2d& a, const Packet2d& b)
 { return vreinterpretq_f64_u64(vorrq_u64(vreinterpretq_u64_f64(a),vreinterpretq_u64_f64(b))); }
@@ -3625,14 +3799,17 @@
 
 template<> EIGEN_STRONG_INLINE Packet2d pcmp_le(const Packet2d& a, const Packet2d& b)
 { return vreinterpretq_f64_u64(vcleq_f64(a,b)); }
 
 template<> EIGEN_STRONG_INLINE Packet2d pcmp_lt(const Packet2d& a, const Packet2d& b)
 { return vreinterpretq_f64_u64(vcltq_f64(a,b)); }
 
+template<> EIGEN_STRONG_INLINE Packet2d pcmp_lt_or_nan(const Packet2d& a, const Packet2d& b)
+{ return vreinterpretq_f64_u32(vmvnq_u32(vreinterpretq_u32_u64(vcgeq_f64(a,b)))); }
+
 template<> EIGEN_STRONG_INLINE Packet2d pcmp_eq(const Packet2d& a, const Packet2d& b)
 { return vreinterpretq_f64_u64(vceqq_f64(a,b)); }
 
 template<> EIGEN_STRONG_INLINE Packet2d pload<Packet2d>(const double* from)
 { EIGEN_DEBUG_ALIGNED_LOAD return vld1q_f64(from); }
 
 template<> EIGEN_STRONG_INLINE Packet2d ploadu<Packet2d>(const double* from)
@@ -3641,23 +3818,23 @@
 template<> EIGEN_STRONG_INLINE Packet2d ploaddup<Packet2d>(const double* from) { return vld1q_dup_f64(from); }
 template<> EIGEN_STRONG_INLINE void pstore<double>(double* to, const Packet2d& from)
 { EIGEN_DEBUG_ALIGNED_STORE vst1q_f64(to,from); }
 
 template<> EIGEN_STRONG_INLINE void pstoreu<double>(double* to, const Packet2d& from)
 { EIGEN_DEBUG_UNALIGNED_STORE vst1q_f64(to,from); }
 
-template<> EIGEN_DEVICE_FUNC inline Packet2d pgather<double, Packet2d>(const double* from, Index stride)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet2d pgather<double, Packet2d>(const double* from, Index stride)
 {
   Packet2d res = pset1<Packet2d>(0.0);
   res = vld1q_lane_f64(from + 0*stride, res, 0);
   res = vld1q_lane_f64(from + 1*stride, res, 1);
   return res;
 }
 
-template<> EIGEN_DEVICE_FUNC inline void pscatter<double, Packet2d>(double* to, const Packet2d& from, Index stride)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void pscatter<double, Packet2d>(double* to, const Packet2d& from, Index stride)
 {
   vst1q_lane_f64(to + stride*0, from, 0);
   vst1q_lane_f64(to + stride*1, from, 1);
 }
 
 template<> EIGEN_STRONG_INLINE void prefetch<double>(const double* addr) { EIGEN_ARM_PREFETCH(addr); }
 
@@ -3693,27 +3870,718 @@
 { return vgetq_lane_f64(vpminq_f64(a,a), 0); }
 
 // max
 template<> EIGEN_STRONG_INLINE double predux_max<Packet2d>(const Packet2d& a)
 { return vgetq_lane_f64(vpmaxq_f64(a,a), 0); }
 
 
-EIGEN_DEVICE_FUNC inline void
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void
 ptranspose(PacketBlock<Packet2d, 2>& kernel)
 {
   const float64x2_t tmp1 = vzip1q_f64(kernel.packet[0], kernel.packet[1]);
   const float64x2_t tmp2 = vzip2q_f64(kernel.packet[0], kernel.packet[1]);
 
   kernel.packet[0] = tmp1;
   kernel.packet[1] = tmp2;
 }
 
-template<> EIGEN_DEVICE_FUNC inline Packet2d pselect( const Packet2d& mask, const Packet2d& a, const Packet2d& b)
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet2d pselect( const Packet2d& mask, const Packet2d& a, const Packet2d& b)
 { return vbslq_f64(vreinterpretq_u64_f64(mask), a, b); }
 
+template<> EIGEN_STRONG_INLINE Packet2d print<Packet2d>(const Packet2d& a)
+{ return vrndnq_f64(a); }
+
+template<> EIGEN_STRONG_INLINE Packet2d pfloor<Packet2d>(const Packet2d& a)
+{ return vrndmq_f64(a); }
+
+template<> EIGEN_STRONG_INLINE Packet2d pceil<Packet2d>(const Packet2d& a)
+{ return vrndpq_f64(a); }
+
+template<> EIGEN_STRONG_INLINE Packet2d pldexp<Packet2d>(const Packet2d& a, const Packet2d& exponent)
+{ return pldexp_generic(a, exponent); }
+
+template<> EIGEN_STRONG_INLINE Packet2d pfrexp<Packet2d>(const Packet2d& a, Packet2d& exponent)
+{ return pfrexp_generic(a,exponent); }
+
+template<> EIGEN_STRONG_INLINE Packet2d pset1frombits<Packet2d>(uint64_t from)
+{ return vreinterpretq_f64_u64(vdupq_n_u64(from)); }
+
+template<> EIGEN_STRONG_INLINE Packet2d prsqrt(const Packet2d& a) {
+  // Compute approximate reciprocal sqrt.
+  Packet2d x = vrsqrteq_f64(a);
+  // Do Newton iterations for 1/sqrt(x).
+  x = vmulq_f64(vrsqrtsq_f64(vmulq_f64(a, x), x), x);
+  x = vmulq_f64(vrsqrtsq_f64(vmulq_f64(a, x), x), x);
+  x = vmulq_f64(vrsqrtsq_f64(vmulq_f64(a, x), x), x);
+  const Packet2d infinity = pset1<Packet2d>(NumTraits<double>::infinity());
+  return pselect(pcmp_eq(a, pzero(a)), infinity, x);
+}
+
+template<> EIGEN_STRONG_INLINE Packet2d psqrt(const Packet2d& _x){ return vsqrtq_f64(_x); }
+
 #endif // EIGEN_ARCH_ARM64
 
+// Do we have an fp16 types and supporting Neon intrinsics?
+#if EIGEN_HAS_ARM64_FP16_VECTOR_ARITHMETIC
+typedef float16x4_t Packet4hf;
+typedef float16x8_t Packet8hf;
+
+template <>
+struct packet_traits<Eigen::half> : default_packet_traits {
+  typedef Packet8hf type;
+  typedef Packet4hf half;
+  enum {
+    Vectorizable = 1,
+    AlignedOnScalar = 1,
+    size = 8,
+    HasHalfPacket = 1,
+
+    HasCmp = 1,
+    HasCast = 1,
+    HasAdd = 1,
+    HasSub = 1,
+    HasShift = 1,
+    HasMul = 1,
+    HasNegate = 1,
+    HasAbs = 1,
+    HasArg = 0,
+    HasAbs2 = 1,
+    HasAbsDiff = 0,
+    HasMin = 1,
+    HasMax = 1,
+    HasConj = 1,
+    HasSetLinear = 0,
+    HasBlend = 0,
+    HasInsert = 1,
+    HasReduxp = 1,
+    HasDiv = 1,
+    HasFloor = 1,
+    HasCeil = 1,
+    HasRint = 1,
+    HasSin = 0,
+    HasCos = 0,
+    HasLog = 0,
+    HasExp = 0,
+    HasSqrt = 1,
+    HasRsqrt = 1,
+    HasErf = EIGEN_FAST_MATH,
+    HasBessel = 0,  // Issues with accuracy.
+    HasNdtri = 0
+  };
+};
+
+template <>
+struct unpacket_traits<Packet4hf> {
+  typedef Eigen::half type;
+  typedef Packet4hf half;
+  enum {
+    size = 4,
+    alignment = Aligned16,
+    vectorizable = true,
+    masked_load_available = false,
+    masked_store_available = false
+  };
+};
+
+template <>
+struct unpacket_traits<Packet8hf> {
+  typedef Eigen::half type;
+  typedef Packet4hf half;
+  enum {
+    size = 8,
+    alignment = Aligned16,
+    vectorizable = true,
+    masked_load_available = false,
+    masked_store_available = false
+  };
+};
+
+template<>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4hf predux_half_dowto4<Packet8hf>(const Packet8hf& a) {
+  return vadd_f16(vget_low_f16(a), vget_high_f16(a));
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet8hf pset1<Packet8hf>(const Eigen::half& from) {
+  return vdupq_n_f16(from.x);
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet4hf pset1<Packet4hf>(const Eigen::half& from) {
+  return vdup_n_f16(from.x);
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet8hf plset<Packet8hf>(const Eigen::half& a) {
+  const float16_t f[] = {0, 1, 2, 3, 4, 5, 6, 7};
+  Packet8hf countdown = vld1q_f16(f);
+  return vaddq_f16(pset1<Packet8hf>(a), countdown);
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet4hf plset<Packet4hf>(const Eigen::half& a) {
+  const float16_t f[] = {0, 1, 2, 3};
+  Packet4hf countdown = vld1_f16(f);
+  return vadd_f16(pset1<Packet4hf>(a), countdown);
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet8hf padd<Packet8hf>(const Packet8hf& a, const Packet8hf& b) {
+  return vaddq_f16(a, b);
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet4hf padd<Packet4hf>(const Packet4hf& a, const Packet4hf& b) {
+  return vadd_f16(a, b);
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet8hf psub<Packet8hf>(const Packet8hf& a, const Packet8hf& b) {
+  return vsubq_f16(a, b);
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet4hf psub<Packet4hf>(const Packet4hf& a, const Packet4hf& b) {
+  return vsub_f16(a, b);
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet8hf pnegate(const Packet8hf& a) {
+  return vnegq_f16(a);
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet4hf pnegate(const Packet4hf& a) {
+  return vneg_f16(a);
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet8hf pconj(const Packet8hf& a) {
+  return a;
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet4hf pconj(const Packet4hf& a) {
+  return a;
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet8hf pmul<Packet8hf>(const Packet8hf& a, const Packet8hf& b) {
+  return vmulq_f16(a, b);
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet4hf pmul<Packet4hf>(const Packet4hf& a, const Packet4hf& b) {
+  return vmul_f16(a, b);
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet8hf pdiv<Packet8hf>(const Packet8hf& a, const Packet8hf& b) {
+  return vdivq_f16(a, b);
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet4hf pdiv<Packet4hf>(const Packet4hf& a, const Packet4hf& b) {
+  return vdiv_f16(a, b);
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet8hf pmadd(const Packet8hf& a, const Packet8hf& b, const Packet8hf& c) {
+  return vfmaq_f16(c, a, b);
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet4hf pmadd(const Packet4hf& a, const Packet4hf& b, const Packet4hf& c) {
+  return vfma_f16(c, a, b);
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet8hf pmin<Packet8hf>(const Packet8hf& a, const Packet8hf& b) {
+  return vminq_f16(a, b);
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet4hf pmin<Packet4hf>(const Packet4hf& a, const Packet4hf& b) {
+  return vmin_f16(a, b);
+}
+
+#ifdef __ARM_FEATURE_NUMERIC_MAXMIN
+// numeric max and min are only available if ARM_FEATURE_NUMERIC_MAXMIN is defined (which can only be the case for Armv8 systems).
+template<> EIGEN_STRONG_INLINE Packet4hf pmin<PropagateNumbers, Packet4hf>(const Packet4hf& a, const Packet4hf& b) { return vminnm_f16(a, b); }
+template<> EIGEN_STRONG_INLINE Packet8hf pmin<PropagateNumbers, Packet8hf>(const Packet8hf& a, const Packet8hf& b) { return vminnmq_f16(a, b); }
+#endif
+
+template<> EIGEN_STRONG_INLINE Packet4hf pmin<PropagateNaN, Packet4hf>(const Packet4hf& a, const Packet4hf& b) { return pmin<Packet4hf>(a, b); }
+
+template<> EIGEN_STRONG_INLINE Packet8hf pmin<PropagateNaN, Packet8hf>(const Packet8hf& a, const Packet8hf& b) { return pmin<Packet8hf>(a, b); }
+
+template <>
+EIGEN_STRONG_INLINE Packet8hf pmax<Packet8hf>(const Packet8hf& a, const Packet8hf& b) {
+  return vmaxq_f16(a, b);
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet4hf pmax<Packet4hf>(const Packet4hf& a, const Packet4hf& b) {
+  return vmax_f16(a, b);
+}
+
+#ifdef __ARM_FEATURE_NUMERIC_MAXMIN
+// numeric max and min are only available if ARM_FEATURE_NUMERIC_MAXMIN is defined (which can only be the case for Armv8 systems).
+template<> EIGEN_STRONG_INLINE Packet4hf pmax<PropagateNumbers, Packet4hf>(const Packet4hf& a, const Packet4hf& b) { return vmaxnm_f16(a, b); }
+template<> EIGEN_STRONG_INLINE Packet8hf pmax<PropagateNumbers, Packet8hf>(const Packet8hf& a, const Packet8hf& b) { return vmaxnmq_f16(a, b); }
+#endif
+
+template<> EIGEN_STRONG_INLINE Packet4hf pmax<PropagateNaN, Packet4hf>(const Packet4hf& a, const Packet4hf& b) { return pmax<Packet4hf>(a, b); }
+
+template<> EIGEN_STRONG_INLINE Packet8hf pmax<PropagateNaN, Packet8hf>(const Packet8hf& a, const Packet8hf& b) { return pmax<Packet8hf>(a, b); }
+
+#define EIGEN_MAKE_ARM_FP16_CMP_8(name)                                               \
+  template <>                                                                         \
+  EIGEN_STRONG_INLINE Packet8hf pcmp_##name(const Packet8hf& a, const Packet8hf& b) { \
+    return vreinterpretq_f16_u16(vc##name##q_f16(a, b));                              \
+  }
+
+#define EIGEN_MAKE_ARM_FP16_CMP_4(name)                                               \
+  template <>                                                                         \
+  EIGEN_STRONG_INLINE Packet4hf pcmp_##name(const Packet4hf& a, const Packet4hf& b) { \
+    return vreinterpret_f16_u16(vc##name##_f16(a, b));                                \
+  }
+
+EIGEN_MAKE_ARM_FP16_CMP_8(eq)
+EIGEN_MAKE_ARM_FP16_CMP_8(lt)
+EIGEN_MAKE_ARM_FP16_CMP_8(le)
+
+EIGEN_MAKE_ARM_FP16_CMP_4(eq)
+EIGEN_MAKE_ARM_FP16_CMP_4(lt)
+EIGEN_MAKE_ARM_FP16_CMP_4(le)
+
+#undef EIGEN_MAKE_ARM_FP16_CMP_8
+#undef EIGEN_MAKE_ARM_FP16_CMP_4
+
+template <>
+EIGEN_STRONG_INLINE Packet8hf pcmp_lt_or_nan<Packet8hf>(const Packet8hf& a, const Packet8hf& b) {
+  return vreinterpretq_f16_u16(vmvnq_u16(vcgeq_f16(a, b)));
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet4hf pcmp_lt_or_nan<Packet4hf>(const Packet4hf& a, const Packet4hf& b) {
+  return vreinterpret_f16_u16(vmvn_u16(vcge_f16(a, b)));
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet8hf print<Packet8hf>(const Packet8hf& a)
+{ return vrndnq_f16(a); }
+
+template <>
+EIGEN_STRONG_INLINE Packet4hf print<Packet4hf>(const Packet4hf& a)
+{ return vrndn_f16(a); }
+
+template <>
+EIGEN_STRONG_INLINE Packet8hf pfloor<Packet8hf>(const Packet8hf& a)
+{ return vrndmq_f16(a); }
+
+template <>
+EIGEN_STRONG_INLINE Packet4hf pfloor<Packet4hf>(const Packet4hf& a)
+{ return vrndm_f16(a); }
+
+template <>
+EIGEN_STRONG_INLINE Packet8hf pceil<Packet8hf>(const Packet8hf& a)
+{ return vrndpq_f16(a); }
+
+template <>
+EIGEN_STRONG_INLINE Packet4hf pceil<Packet4hf>(const Packet4hf& a)
+{ return vrndp_f16(a); }
+
+template <>
+EIGEN_STRONG_INLINE Packet8hf psqrt<Packet8hf>(const Packet8hf& a) {
+  return vsqrtq_f16(a);
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet4hf psqrt<Packet4hf>(const Packet4hf& a) {
+  return vsqrt_f16(a);
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet8hf pand<Packet8hf>(const Packet8hf& a, const Packet8hf& b) {
+  return vreinterpretq_f16_u16(vandq_u16(vreinterpretq_u16_f16(a), vreinterpretq_u16_f16(b)));
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet4hf pand<Packet4hf>(const Packet4hf& a, const Packet4hf& b) {
+  return vreinterpret_f16_u16(vand_u16(vreinterpret_u16_f16(a), vreinterpret_u16_f16(b)));
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet8hf por<Packet8hf>(const Packet8hf& a, const Packet8hf& b) {
+  return vreinterpretq_f16_u16(vorrq_u16(vreinterpretq_u16_f16(a), vreinterpretq_u16_f16(b)));
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet4hf por<Packet4hf>(const Packet4hf& a, const Packet4hf& b) {
+  return vreinterpret_f16_u16(vorr_u16(vreinterpret_u16_f16(a), vreinterpret_u16_f16(b)));
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet8hf pxor<Packet8hf>(const Packet8hf& a, const Packet8hf& b) {
+  return vreinterpretq_f16_u16(veorq_u16(vreinterpretq_u16_f16(a), vreinterpretq_u16_f16(b)));
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet4hf pxor<Packet4hf>(const Packet4hf& a, const Packet4hf& b) {
+  return vreinterpret_f16_u16(veor_u16(vreinterpret_u16_f16(a), vreinterpret_u16_f16(b)));
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet8hf pandnot<Packet8hf>(const Packet8hf& a, const Packet8hf& b) {
+  return vreinterpretq_f16_u16(vbicq_u16(vreinterpretq_u16_f16(a), vreinterpretq_u16_f16(b)));
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet4hf pandnot<Packet4hf>(const Packet4hf& a, const Packet4hf& b) {
+  return vreinterpret_f16_u16(vbic_u16(vreinterpret_u16_f16(a), vreinterpret_u16_f16(b)));
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet8hf pload<Packet8hf>(const Eigen::half* from) {
+  EIGEN_DEBUG_ALIGNED_LOAD return vld1q_f16(reinterpret_cast<const float16_t*>(from));
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet4hf pload<Packet4hf>(const Eigen::half* from) {
+  EIGEN_DEBUG_ALIGNED_LOAD return vld1_f16(reinterpret_cast<const float16_t*>(from));
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet8hf ploadu<Packet8hf>(const Eigen::half* from) {
+  EIGEN_DEBUG_UNALIGNED_LOAD return vld1q_f16(reinterpret_cast<const float16_t*>(from));
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet4hf ploadu<Packet4hf>(const Eigen::half* from) {
+  EIGEN_DEBUG_UNALIGNED_LOAD return vld1_f16(reinterpret_cast<const float16_t*>(from));
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet8hf ploaddup<Packet8hf>(const Eigen::half* from) {
+  Packet8hf packet;
+  packet[0] = from[0].x;
+  packet[1] = from[0].x;
+  packet[2] = from[1].x;
+  packet[3] = from[1].x;
+  packet[4] = from[2].x;
+  packet[5] = from[2].x;
+  packet[6] = from[3].x;
+  packet[7] = from[3].x;
+  return packet;
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet4hf ploaddup<Packet4hf>(const Eigen::half* from) {
+  float16x4_t packet;
+  float16_t* tmp;
+  tmp = (float16_t*)&packet;
+  tmp[0] = from[0].x;
+  tmp[1] = from[0].x;
+  tmp[2] = from[1].x;
+  tmp[3] = from[1].x;
+  return packet;
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet8hf ploadquad<Packet8hf>(const Eigen::half* from) {
+  Packet4hf lo, hi;
+  lo = vld1_dup_f16(reinterpret_cast<const float16_t*>(from));
+  hi = vld1_dup_f16(reinterpret_cast<const float16_t*>(from+1));
+  return vcombine_f16(lo, hi);
+}
+
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet8hf pinsertfirst(const Packet8hf& a, Eigen::half b) { return vsetq_lane_f16(b.x, a, 0); }
+
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4hf pinsertfirst(const Packet4hf& a, Eigen::half b) { return vset_lane_f16(b.x, a, 0); }
+
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet8hf pselect(const Packet8hf& mask, const Packet8hf& a, const Packet8hf& b) {
+  return vbslq_f16(vreinterpretq_u16_f16(mask), a, b);
+}
+
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4hf pselect(const Packet4hf& mask, const Packet4hf& a, const Packet4hf& b) {
+  return vbsl_f16(vreinterpret_u16_f16(mask), a, b);
+}
+
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet8hf pinsertlast(const Packet8hf& a, Eigen::half b) { return vsetq_lane_f16(b.x, a, 7); }
+
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4hf pinsertlast(const Packet4hf& a, Eigen::half b) { return vset_lane_f16(b.x, a, 3); }
+
+template <>
+EIGEN_STRONG_INLINE void pstore<Eigen::half>(Eigen::half* to, const Packet8hf& from) {
+  EIGEN_DEBUG_ALIGNED_STORE vst1q_f16(reinterpret_cast<float16_t*>(to), from);
+}
+
+template <>
+EIGEN_STRONG_INLINE void pstore<Eigen::half>(Eigen::half* to, const Packet4hf& from) {
+  EIGEN_DEBUG_ALIGNED_STORE vst1_f16(reinterpret_cast<float16_t*>(to), from);
+}
+
+template <>
+EIGEN_STRONG_INLINE void pstoreu<Eigen::half>(Eigen::half* to, const Packet8hf& from) {
+  EIGEN_DEBUG_UNALIGNED_STORE vst1q_f16(reinterpret_cast<float16_t*>(to), from);
+}
+
+template <>
+EIGEN_STRONG_INLINE void pstoreu<Eigen::half>(Eigen::half* to, const Packet4hf& from) {
+  EIGEN_DEBUG_UNALIGNED_STORE vst1_f16(reinterpret_cast<float16_t*>(to), from);
+}
+
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet8hf pgather<Eigen::half, Packet8hf>(const Eigen::half* from, Index stride) {
+  Packet8hf res = pset1<Packet8hf>(Eigen::half(0.f));
+  res = vsetq_lane_f16(from[0 * stride].x, res, 0);
+  res = vsetq_lane_f16(from[1 * stride].x, res, 1);
+  res = vsetq_lane_f16(from[2 * stride].x, res, 2);
+  res = vsetq_lane_f16(from[3 * stride].x, res, 3);
+  res = vsetq_lane_f16(from[4 * stride].x, res, 4);
+  res = vsetq_lane_f16(from[5 * stride].x, res, 5);
+  res = vsetq_lane_f16(from[6 * stride].x, res, 6);
+  res = vsetq_lane_f16(from[7 * stride].x, res, 7);
+  return res;
+}
+
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4hf pgather<Eigen::half, Packet4hf>(const Eigen::half* from, Index stride) {
+  Packet4hf res = pset1<Packet4hf>(Eigen::half(0.f));
+  res = vset_lane_f16(from[0 * stride].x, res, 0);
+  res = vset_lane_f16(from[1 * stride].x, res, 1);
+  res = vset_lane_f16(from[2 * stride].x, res, 2);
+  res = vset_lane_f16(from[3 * stride].x, res, 3);
+  return res;
+}
+
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void pscatter<Eigen::half, Packet8hf>(Eigen::half* to, const Packet8hf& from, Index stride) {
+  to[stride * 0].x = vgetq_lane_f16(from, 0);
+  to[stride * 1].x = vgetq_lane_f16(from, 1);
+  to[stride * 2].x = vgetq_lane_f16(from, 2);
+  to[stride * 3].x = vgetq_lane_f16(from, 3);
+  to[stride * 4].x = vgetq_lane_f16(from, 4);
+  to[stride * 5].x = vgetq_lane_f16(from, 5);
+  to[stride * 6].x = vgetq_lane_f16(from, 6);
+  to[stride * 7].x = vgetq_lane_f16(from, 7);
+}
+
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void pscatter<Eigen::half, Packet4hf>(Eigen::half* to, const Packet4hf& from, Index stride) {
+  to[stride * 0].x = vget_lane_f16(from, 0);
+  to[stride * 1].x = vget_lane_f16(from, 1);
+  to[stride * 2].x = vget_lane_f16(from, 2);
+  to[stride * 3].x = vget_lane_f16(from, 3);
+}
+
+template <>
+EIGEN_STRONG_INLINE void prefetch<Eigen::half>(const Eigen::half* addr) {
+  EIGEN_ARM_PREFETCH(addr);
+}
+
+template <>
+EIGEN_STRONG_INLINE Eigen::half pfirst<Packet8hf>(const Packet8hf& a) {
+  float16_t x[8];
+  vst1q_f16(x, a);
+  Eigen::half h;
+  h.x = x[0];
+  return h;
+}
+
+template <>
+EIGEN_STRONG_INLINE Eigen::half pfirst<Packet4hf>(const Packet4hf& a) {
+  float16_t x[4];
+  vst1_f16(x, a);
+  Eigen::half h;
+  h.x = x[0];
+  return h;
+}
+
+template<> EIGEN_STRONG_INLINE Packet8hf preverse(const Packet8hf& a) {
+  float16x4_t a_lo, a_hi;
+  Packet8hf a_r64;
+
+  a_r64 = vrev64q_f16(a);
+  a_lo = vget_low_f16(a_r64);
+  a_hi = vget_high_f16(a_r64);
+  return vcombine_f16(a_hi, a_lo);
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet4hf preverse<Packet4hf>(const Packet4hf& a) {
+  return vrev64_f16(a);
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet8hf pabs<Packet8hf>(const Packet8hf& a) {
+  return vabsq_f16(a);
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet4hf pabs<Packet4hf>(const Packet4hf& a) {
+  return vabs_f16(a);
+}
+
+template <>
+EIGEN_STRONG_INLINE Eigen::half predux<Packet8hf>(const Packet8hf& a) {
+  float16x4_t a_lo, a_hi, sum;
+
+  a_lo = vget_low_f16(a);
+  a_hi = vget_high_f16(a);
+  sum = vpadd_f16(a_lo, a_hi);
+  sum = vpadd_f16(sum, sum);
+  sum = vpadd_f16(sum, sum);
+
+  Eigen::half h;
+  h.x = vget_lane_f16(sum, 0);
+  return h;
+}
+
+template <>
+EIGEN_STRONG_INLINE Eigen::half predux<Packet4hf>(const Packet4hf& a) {
+  float16x4_t sum;
+
+  sum = vpadd_f16(a, a);
+  sum = vpadd_f16(sum, sum);
+  Eigen::half h;
+  h.x = vget_lane_f16(sum, 0);
+  return h;
+}
+
+template <>
+EIGEN_STRONG_INLINE Eigen::half predux_mul<Packet8hf>(const Packet8hf& a) {
+  float16x4_t a_lo, a_hi, prod;
+
+  a_lo = vget_low_f16(a);
+  a_hi = vget_high_f16(a);
+  prod = vmul_f16(a_lo, a_hi);
+  prod = vmul_f16(prod, vrev64_f16(prod));
+
+  Eigen::half h;
+  h.x = vmulh_f16(vget_lane_f16(prod, 0), vget_lane_f16(prod, 1));
+  return h;
+}
+
+template <>
+EIGEN_STRONG_INLINE Eigen::half predux_mul<Packet4hf>(const Packet4hf& a) {
+  float16x4_t prod;
+  prod = vmul_f16(a, vrev64_f16(a));
+  Eigen::half h;
+  h.x = vmulh_f16(vget_lane_f16(prod, 0), vget_lane_f16(prod, 1));
+  return h;
+}
+
+template <>
+EIGEN_STRONG_INLINE Eigen::half predux_min<Packet8hf>(const Packet8hf& a) {
+  float16x4_t a_lo, a_hi, min;
+
+  a_lo = vget_low_f16(a);
+  a_hi = vget_high_f16(a);
+  min = vpmin_f16(a_lo, a_hi);
+  min = vpmin_f16(min, min);
+  min = vpmin_f16(min, min);
+
+  Eigen::half h;
+  h.x = vget_lane_f16(min, 0);
+  return h;
+}
+
+template <>
+EIGEN_STRONG_INLINE Eigen::half predux_min<Packet4hf>(const Packet4hf& a) {
+  Packet4hf tmp;
+  tmp = vpmin_f16(a, a);
+  tmp = vpmin_f16(tmp, tmp);
+  Eigen::half h;
+  h.x = vget_lane_f16(tmp, 0);
+  return h;
+}
+
+template <>
+EIGEN_STRONG_INLINE Eigen::half predux_max<Packet8hf>(const Packet8hf& a) {
+  float16x4_t a_lo, a_hi, max;
+
+  a_lo = vget_low_f16(a);
+  a_hi = vget_high_f16(a);
+  max = vpmax_f16(a_lo, a_hi);
+  max = vpmax_f16(max, max);
+  max = vpmax_f16(max, max);
+
+  Eigen::half h;
+  h.x = vget_lane_f16(max, 0);
+  return h;
+}
+
+template <>
+EIGEN_STRONG_INLINE Eigen::half predux_max<Packet4hf>(const Packet4hf& a) {
+  Packet4hf tmp;
+  tmp = vpmax_f16(a, a);
+  tmp = vpmax_f16(tmp, tmp);
+  Eigen::half h;
+  h.x = vget_lane_f16(tmp, 0);
+  return h;
+}
+
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet8hf, 4>& kernel)
+{
+  const float16x8x2_t zip16_1 = vzipq_f16(kernel.packet[0], kernel.packet[1]);
+  const float16x8x2_t zip16_2 = vzipq_f16(kernel.packet[2], kernel.packet[3]);
+
+  const float32x4x2_t zip32_1 = vzipq_f32(vreinterpretq_f32_f16(zip16_1.val[0]), vreinterpretq_f32_f16(zip16_2.val[0]));
+  const float32x4x2_t zip32_2 = vzipq_f32(vreinterpretq_f32_f16(zip16_1.val[1]), vreinterpretq_f32_f16(zip16_2.val[1]));
+
+  kernel.packet[0] = vreinterpretq_f16_f32(zip32_1.val[0]);
+  kernel.packet[1] = vreinterpretq_f16_f32(zip32_1.val[1]);
+  kernel.packet[2] = vreinterpretq_f16_f32(zip32_2.val[0]);
+  kernel.packet[3] = vreinterpretq_f16_f32(zip32_2.val[1]);
+}
+
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet4hf, 4>& kernel) {
+  EIGEN_ALIGN16 float16x4x4_t tmp_x4;
+  float16_t* tmp = (float16_t*)&kernel;
+  tmp_x4 = vld4_f16(tmp);
+
+  kernel.packet[0] = tmp_x4.val[0];
+  kernel.packet[1] = tmp_x4.val[1];
+  kernel.packet[2] = tmp_x4.val[2];
+  kernel.packet[3] = tmp_x4.val[3];
+}
+
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet8hf, 8>& kernel) {
+  float16x8x2_t T_1[4];
+
+  T_1[0] = vuzpq_f16(kernel.packet[0], kernel.packet[1]);
+  T_1[1] = vuzpq_f16(kernel.packet[2], kernel.packet[3]);
+  T_1[2] = vuzpq_f16(kernel.packet[4], kernel.packet[5]);
+  T_1[3] = vuzpq_f16(kernel.packet[6], kernel.packet[7]);
+
+  float16x8x2_t T_2[4];
+  T_2[0] = vuzpq_f16(T_1[0].val[0], T_1[1].val[0]);
+  T_2[1] = vuzpq_f16(T_1[0].val[1], T_1[1].val[1]);
+  T_2[2] = vuzpq_f16(T_1[2].val[0], T_1[3].val[0]);
+  T_2[3] = vuzpq_f16(T_1[2].val[1], T_1[3].val[1]);
+
+  float16x8x2_t T_3[4];
+  T_3[0] = vuzpq_f16(T_2[0].val[0], T_2[2].val[0]);
+  T_3[1] = vuzpq_f16(T_2[0].val[1], T_2[2].val[1]);
+  T_3[2] = vuzpq_f16(T_2[1].val[0], T_2[3].val[0]);
+  T_3[3] = vuzpq_f16(T_2[1].val[1], T_2[3].val[1]);
+
+  kernel.packet[0] = T_3[0].val[0];
+  kernel.packet[1] = T_3[2].val[0];
+  kernel.packet[2] = T_3[1].val[0];
+  kernel.packet[3] = T_3[3].val[0];
+  kernel.packet[4] = T_3[0].val[1];
+  kernel.packet[5] = T_3[2].val[1];
+  kernel.packet[6] = T_3[1].val[1];
+  kernel.packet[7] = T_3[3].val[1];
+}
+#endif // end EIGEN_HAS_ARM64_FP16_VECTOR_ARITHMETIC
+
 } // end namespace internal
 
 } // end namespace Eigen
 
 #endif // EIGEN_PACKET_MATH_NEON_H
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/NEON/TypeCasting.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/NEON/TypeCasting.h`

 * *Files 1% similar despite different names*

```diff
@@ -1397,14 +1397,22 @@
 EIGEN_STRONG_INLINE Packet2l preinterpret<Packet2l, Packet2d>(const Packet2d& a) {
   return vreinterpretq_s64_f64(a);
 }
 template <>
 EIGEN_STRONG_INLINE Packet2ul preinterpret<Packet2ul, Packet2d>(const Packet2d& a) {
   return vreinterpretq_u64_f64(a);
 }
+template <>
+EIGEN_STRONG_INLINE Packet2d preinterpret<Packet2d, Packet4i>(const Packet4i& a) {
+  return vreinterpretq_f64_s32(a);
+}
+template <>
+EIGEN_STRONG_INLINE Packet4i preinterpret<Packet4i, Packet2d>(const Packet2d& a) {
+  return vreinterpretq_s32_f64(a);
+}
 
 #endif  // EIGEN_ARCH_ARM64
 
 }  // end namespace internal
 
 }  // end namespace Eigen
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/SSE/MathFunctions.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/SSE/MathFunctions.h`

 * *Files 11% similar despite different names*

```diff
@@ -21,14 +21,29 @@
 
 template<> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
 Packet4f plog<Packet4f>(const Packet4f& _x) {
   return plog_float(_x);
 }
 
 template<> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
+Packet2d plog<Packet2d>(const Packet2d& _x) {
+  return plog_double(_x);
+}
+
+template<> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
+Packet4f plog2<Packet4f>(const Packet4f& _x) {
+  return plog2_float(_x);
+}
+
+template<> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
+Packet2d plog2<Packet2d>(const Packet2d& _x) {
+  return plog2_double(_x);
+}
+
+template<> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
 Packet4f plog1p<Packet4f>(const Packet4f& _x) {
   return generic_plog1p(_x);
 }
 
 template<> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
 Packet4f pexpm1<Packet4f>(const Packet4f& _x) {
   return generic_expm1(_x);
@@ -67,37 +82,40 @@
 // The main advantage of this approach is not just speed, but also the fact that
 // it can be inlined and pipelined with other computations, further reducing its
 // effective latency. This is similar to Quake3's fast inverse square root.
 // For detail see here: http://www.beyond3d.com/content/articles/8/
 template<> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
 Packet4f psqrt<Packet4f>(const Packet4f& _x)
 {
-  Packet4f half = pmul(_x, pset1<Packet4f>(.5f));
-  Packet4f denormal_mask = _mm_and_ps(
-      _mm_cmpge_ps(_x, _mm_setzero_ps()),
-      _mm_cmplt_ps(_x, pset1<Packet4f>((std::numeric_limits<float>::min)())));
+  Packet4f minus_half_x = pmul(_x, pset1<Packet4f>(-0.5f));
+  Packet4f denormal_mask = pandnot(
+      pcmp_lt(_x, pset1<Packet4f>((std::numeric_limits<float>::min)())),
+      pcmp_lt(_x, pzero(_x)));
 
   // Compute approximate reciprocal sqrt.
   Packet4f x = _mm_rsqrt_ps(_x);
   // Do a single step of Newton's iteration.
-  x = pmul(x, psub(pset1<Packet4f>(1.5f), pmul(half, pmul(x,x))));
+  x = pmul(x, pmadd(minus_half_x, pmul(x,x), pset1<Packet4f>(1.5f)));
   // Flush results for denormals to zero.
-  return _mm_andnot_ps(denormal_mask, pmul(_x,x));
+  return pandnot(pmul(_x,x), denormal_mask);
 }
 
 #else
 
 template<>EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
 Packet4f psqrt<Packet4f>(const Packet4f& x) { return _mm_sqrt_ps(x); }
 
 #endif
 
 template<> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
 Packet2d psqrt<Packet2d>(const Packet2d& x) { return _mm_sqrt_pd(x); }
 
+template<> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
+Packet16b psqrt<Packet16b>(const Packet16b& x) { return x; }
+
 #if EIGEN_FAST_MATH
 
 template<> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
 Packet4f prsqrt<Packet4f>(const Packet4f& _x) {
   _EIGEN_DECLARE_CONST_Packet4f(one_point_five, 1.5f);
   _EIGEN_DECLARE_CONST_Packet4f(minus_half, -0.5f);
   _EIGEN_DECLARE_CONST_Packet4f_FROM_INT(inf, 0x7f800000u);
@@ -128,23 +146,22 @@
   return pselect<Packet4f>(not_normal_finite_mask, y_approx, y_newton);
 }
 
 #else
 
 template<> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
 Packet4f prsqrt<Packet4f>(const Packet4f& x) {
-  // Unfortunately we can't use the much faster mm_rqsrt_ps since it only provides an approximation.
+  // Unfortunately we can't use the much faster mm_rsqrt_ps since it only provides an approximation.
   return _mm_div_ps(pset1<Packet4f>(1.0f), _mm_sqrt_ps(x));
 }
 
 #endif
 
 template<> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
 Packet2d prsqrt<Packet2d>(const Packet2d& x) {
-  // Unfortunately we can't use the much faster mm_rqsrt_pd since it only provides an approximation.
   return _mm_div_pd(pset1<Packet2d>(1.0), _mm_sqrt_pd(x));
 }
 
 // Hyperbolic Tangent function.
 template <>
 EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED Packet4f
 ptanh<Packet4f>(const Packet4f& x) {
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/SSE/PacketMath.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/SSE/PacketMath.h`

 * *Files 5% similar despite different names*

```diff
@@ -22,15 +22,15 @@
 // 32 bits =>  8 registers
 // 64 bits => 16 registers
 #define EIGEN_ARCH_DEFAULT_NUMBER_OF_REGISTERS (2*sizeof(void*))
 #endif
 
 #ifdef EIGEN_VECTORIZE_FMA
 #ifndef EIGEN_HAS_SINGLE_INSTRUCTION_MADD
-#define EIGEN_HAS_SINGLE_INSTRUCTION_MADD 1
+#define EIGEN_HAS_SINGLE_INSTRUCTION_MADD
 #endif
 #endif
 
 #if ((defined EIGEN_VECTORIZE_AVX) && (EIGEN_COMP_GNUC_STRICT || EIGEN_COMP_MINGW) && (__GXX_ABI_VERSION < 1004)) || EIGEN_OS_QNX
 // With GCC's default ABI version, a __m128 or __m256 are the same types and therefore we cannot
 // have overloads for both types without linking error.
 // One solution is to increase ABI version using -fabi-version=4 (or greater).
@@ -45,32 +45,70 @@
 
 typedef eigen_packet_wrapper<__m128i, 0> Packet4i;
 typedef eigen_packet_wrapper<__m128i, 1> Packet16b;
 
 template<> struct is_arithmetic<__m128>  { enum { value = true }; };
 template<> struct is_arithmetic<__m128i> { enum { value = true }; };
 template<> struct is_arithmetic<__m128d> { enum { value = true }; };
+template<> struct is_arithmetic<Packet4i>  { enum { value = true }; };
 template<> struct is_arithmetic<Packet16b>  { enum { value = true }; };
 
-#define EIGEN_SSE_SHUFFLE_MASK(p,q,r,s) ((s)<<6|(r)<<4|(q)<<2|(p))
+template<int p, int q, int r, int s>
+struct shuffle_mask{
+ enum { mask = (s)<<6|(r)<<4|(q)<<2|(p) };
+};
 
+// TODO: change the implementation of all swizzle* ops from macro to template,
 #define vec4f_swizzle1(v,p,q,r,s) \
-  (_mm_castsi128_ps(_mm_shuffle_epi32( _mm_castps_si128(v), EIGEN_SSE_SHUFFLE_MASK(p,q,r,s))))
+  Packet4f(_mm_castsi128_ps(_mm_shuffle_epi32( _mm_castps_si128(v), (shuffle_mask<p,q,r,s>::mask))))
 
 #define vec4i_swizzle1(v,p,q,r,s) \
-  (_mm_shuffle_epi32( v, EIGEN_SSE_SHUFFLE_MASK(p,q,r,s)))
+  Packet4i(_mm_shuffle_epi32( v, (shuffle_mask<p,q,r,s>::mask)))
 
 #define vec2d_swizzle1(v,p,q) \
-  (_mm_castsi128_pd(_mm_shuffle_epi32( _mm_castpd_si128(v), EIGEN_SSE_SHUFFLE_MASK(2*p,2*p+1,2*q,2*q+1))))
+  Packet2d(_mm_castsi128_pd(_mm_shuffle_epi32( _mm_castpd_si128(v), (shuffle_mask<2*p,2*p+1,2*q,2*q+1>::mask))))
 
 #define vec4f_swizzle2(a,b,p,q,r,s) \
-  (_mm_shuffle_ps( (a), (b), EIGEN_SSE_SHUFFLE_MASK(p,q,r,s)))
+  Packet4f(_mm_shuffle_ps( (a), (b), (shuffle_mask<p,q,r,s>::mask)))
 
 #define vec4i_swizzle2(a,b,p,q,r,s) \
-  (_mm_castps_si128( (_mm_shuffle_ps( _mm_castsi128_ps(a), _mm_castsi128_ps(b), EIGEN_SSE_SHUFFLE_MASK(p,q,r,s)))))
+  Packet4i(_mm_castps_si128( (_mm_shuffle_ps( _mm_castsi128_ps(a), _mm_castsi128_ps(b), (shuffle_mask<p,q,r,s>::mask)))))
+
+EIGEN_STRONG_INLINE Packet4f vec4f_movelh(const Packet4f& a, const Packet4f& b)
+{
+  return Packet4f(_mm_movelh_ps(a,b));
+}
+EIGEN_STRONG_INLINE Packet4f vec4f_movehl(const Packet4f& a, const Packet4f& b)
+{
+  return Packet4f(_mm_movehl_ps(a,b));
+}
+EIGEN_STRONG_INLINE Packet4f vec4f_unpacklo(const Packet4f& a, const Packet4f& b)
+{
+  return Packet4f(_mm_unpacklo_ps(a,b));
+}
+EIGEN_STRONG_INLINE Packet4f vec4f_unpackhi(const Packet4f& a, const Packet4f& b)
+{
+  return Packet4f(_mm_unpackhi_ps(a,b));
+}
+#define vec4f_duplane(a,p) \
+  vec4f_swizzle2(a,a,p,p,p,p)
+
+#define vec2d_swizzle2(a,b,mask) \
+  Packet2d(_mm_shuffle_pd(a,b,mask))
+
+EIGEN_STRONG_INLINE Packet2d vec2d_unpacklo(const Packet2d& a, const Packet2d& b)
+{
+  return Packet2d(_mm_unpacklo_pd(a,b));
+}
+EIGEN_STRONG_INLINE Packet2d vec2d_unpackhi(const Packet2d& a, const Packet2d& b)
+{
+  return Packet2d(_mm_unpackhi_pd(a,b));
+}
+#define vec2d_duplane(a,p) \
+  vec2d_swizzle2(a,a,(p<<1)|p)
 
 #define _EIGEN_DECLARE_CONST_Packet4f(NAME,X) \
   const Packet4f p4f_##NAME = pset1<Packet4f>(X)
 
 #define _EIGEN_DECLARE_CONST_Packet2d(NAME,X) \
   const Packet2d p2d_##NAME = pset1<Packet2d>(X)
 
@@ -105,48 +143,45 @@
     HasExp = 1,
     HasBessel = 1,
     HasSqrt = 1,
     HasRsqrt = 1,
     HasTanh = EIGEN_FAST_MATH,
     HasErf = EIGEN_FAST_MATH,
     HasBlend = 1,
-    HasFloor = 1
-
+    HasCeil = 1,
+    HasFloor = 1,
 #ifdef EIGEN_VECTORIZE_SSE4_1
-    ,
-    HasRint = 1,
     HasRound = 1,
-    HasCeil = 1
 #endif
+    HasRint = 1
   };
 };
 template <>
 struct packet_traits<double> : default_packet_traits {
   typedef Packet2d type;
   typedef Packet2d half;
   enum {
     Vectorizable = 1,
     AlignedOnScalar = 1,
     size=2,
     HasHalfPacket = 0,
 
     HasCmp  = 1,
     HasDiv  = 1,
+    HasLog  = 1,
     HasExp  = 1,
     HasSqrt = 1,
     HasRsqrt = 1,
-    HasBlend = 1
-
+    HasBlend = 1,
+    HasFloor = 1,
+    HasCeil = 1,
 #ifdef EIGEN_VECTORIZE_SSE4_1
-    ,
     HasRound = 1,
-    HasRint = 1,
-    HasFloor = 1,
-    HasCeil = 1
 #endif
+    HasRint = 1
   };
 };
 #endif
 template<> struct packet_traits<int>    : default_packet_traits
 {
   typedef Packet4i type;
   typedef Packet4i half;
@@ -175,15 +210,16 @@
     HasShift     = 0,
     HasMul       = 1,
     HasNegate    = 1,
     HasAbs       = 0,
     HasAbs2      = 0,
     HasMin       = 0,
     HasMax       = 0,
-    HasConj      = 0
+    HasConj      = 0,
+    HasSqrt      = 1
   };
 };
 
 template<> struct unpacket_traits<Packet4f> {
   typedef float     type;
   typedef Packet4f  half;
   typedef Packet4i  integer_packet;
@@ -221,14 +257,19 @@
 template<> EIGEN_STRONG_INLINE Packet4f pset1<Packet4f>(const float&  from) { return _mm_set_ps1(from); }
 template<> EIGEN_STRONG_INLINE Packet2d pset1<Packet2d>(const double& from) { return _mm_set1_pd(from); }
 template<> EIGEN_STRONG_INLINE Packet4i pset1<Packet4i>(const int&    from) { return _mm_set1_epi32(from); }
 #endif
 template<> EIGEN_STRONG_INLINE Packet16b pset1<Packet16b>(const bool&    from) { return _mm_set1_epi8(static_cast<char>(from)); }
 
 template<> EIGEN_STRONG_INLINE Packet4f pset1frombits<Packet4f>(unsigned int from) { return _mm_castsi128_ps(pset1<Packet4i>(from)); }
+template<> EIGEN_STRONG_INLINE Packet2d pset1frombits<Packet2d>(uint64_t from) { return _mm_castsi128_pd(_mm_set1_epi64x(from)); }
+
+template<> EIGEN_STRONG_INLINE Packet4f peven_mask(const Packet4f& /*a*/) { return _mm_castsi128_ps(_mm_set_epi32(0, -1, 0, -1)); }
+template<> EIGEN_STRONG_INLINE Packet4i peven_mask(const Packet4i& /*a*/) { return _mm_set_epi32(0, -1, 0, -1); }
+template<> EIGEN_STRONG_INLINE Packet2d peven_mask(const Packet2d& /*a*/) { return _mm_castsi128_pd(_mm_set_epi32(0, 0, -1, -1)); }
 
 template<> EIGEN_STRONG_INLINE Packet4f pzero(const Packet4f& /*a*/) { return _mm_setzero_ps(); }
 template<> EIGEN_STRONG_INLINE Packet2d pzero(const Packet2d& /*a*/) { return _mm_setzero_pd(); }
 template<> EIGEN_STRONG_INLINE Packet4i pzero(const Packet4i& /*a*/) { return _mm_setzero_si128(); }
 
 // GCC generates a shufps instruction for _mm_set1_ps/_mm_load1_ps instead of the more efficient pshufd instruction.
 // However, using inrinsics for pset1 makes gcc to generate crappy code in some cases (see bug 203)
@@ -252,14 +293,36 @@
 template<> EIGEN_STRONG_INLINE Packet16b padd<Packet16b>(const Packet16b& a, const Packet16b& b) { return _mm_or_si128(a,b); }
 
 template<> EIGEN_STRONG_INLINE Packet4f psub<Packet4f>(const Packet4f& a, const Packet4f& b) { return _mm_sub_ps(a,b); }
 template<> EIGEN_STRONG_INLINE Packet2d psub<Packet2d>(const Packet2d& a, const Packet2d& b) { return _mm_sub_pd(a,b); }
 template<> EIGEN_STRONG_INLINE Packet4i psub<Packet4i>(const Packet4i& a, const Packet4i& b) { return _mm_sub_epi32(a,b); }
 template<> EIGEN_STRONG_INLINE Packet16b psub<Packet16b>(const Packet16b& a, const Packet16b& b) { return _mm_xor_si128(a,b); }
 
+template<> EIGEN_STRONG_INLINE Packet4f pxor<Packet4f>(const Packet4f& a, const Packet4f& b);
+template<> EIGEN_STRONG_INLINE Packet4f paddsub<Packet4f>(const Packet4f& a, const Packet4f& b)
+{
+#ifdef EIGEN_VECTORIZE_SSE3
+  return _mm_addsub_ps(a,b);
+#else
+  const Packet4f mask = _mm_castsi128_ps(_mm_setr_epi32(0x80000000,0x0,0x80000000,0x0));
+  return padd(a, pxor(mask, b));
+#endif
+}
+
+template<> EIGEN_STRONG_INLINE Packet2d pxor<Packet2d>(const Packet2d& , const Packet2d& );
+template<> EIGEN_STRONG_INLINE Packet2d paddsub<Packet2d>(const Packet2d& a, const Packet2d& b) 
+{
+#ifdef EIGEN_VECTORIZE_SSE3  
+  return _mm_addsub_pd(a,b); 
+#else
+  const Packet2d mask = _mm_castsi128_pd(_mm_setr_epi32(0x0,0x80000000,0x0,0x0)); 
+  return padd(a, pxor(mask, b));
+#endif
+}
+
 template<> EIGEN_STRONG_INLINE Packet4f pnegate(const Packet4f& a)
 {
   const Packet4f mask = _mm_castsi128_ps(_mm_setr_epi32(0x80000000,0x80000000,0x80000000,0x80000000));
   return _mm_xor_ps(a,mask);
 }
 template<> EIGEN_STRONG_INLINE Packet2d pnegate(const Packet2d& a)
 {
@@ -328,15 +391,61 @@
 template<> EIGEN_DEVICE_FUNC inline Packet16b pselect(const Packet16b& mask, const Packet16b& a, const Packet16b& b) {
   Packet16b a_part = _mm_and_si128(mask, a);
   Packet16b b_part = _mm_andnot_si128(mask, b);
   return _mm_or_si128(a_part, b_part);
 }
 #endif
 
+template<> EIGEN_STRONG_INLINE Packet4i ptrue<Packet4i>(const Packet4i& a) { return _mm_cmpeq_epi32(a, a); }
+template<> EIGEN_STRONG_INLINE Packet16b ptrue<Packet16b>(const Packet16b& a) { return _mm_cmpeq_epi8(a, a); }
+template<> EIGEN_STRONG_INLINE Packet4f
+ptrue<Packet4f>(const Packet4f& a) {
+  Packet4i b = _mm_castps_si128(a);
+  return _mm_castsi128_ps(_mm_cmpeq_epi32(b, b));
+}
+template<> EIGEN_STRONG_INLINE Packet2d
+ptrue<Packet2d>(const Packet2d& a) {
+  Packet4i b = _mm_castpd_si128(a);
+  return _mm_castsi128_pd(_mm_cmpeq_epi32(b, b));
+}
+
+
+template<> EIGEN_STRONG_INLINE Packet4f pand<Packet4f>(const Packet4f& a, const Packet4f& b) { return _mm_and_ps(a,b); }
+template<> EIGEN_STRONG_INLINE Packet2d pand<Packet2d>(const Packet2d& a, const Packet2d& b) { return _mm_and_pd(a,b); }
+template<> EIGEN_STRONG_INLINE Packet4i pand<Packet4i>(const Packet4i& a, const Packet4i& b) { return _mm_and_si128(a,b); }
+template<> EIGEN_STRONG_INLINE Packet16b pand<Packet16b>(const Packet16b& a, const Packet16b& b) { return _mm_and_si128(a,b); }
+
+template<> EIGEN_STRONG_INLINE Packet4f por<Packet4f>(const Packet4f& a, const Packet4f& b) { return _mm_or_ps(a,b); }
+template<> EIGEN_STRONG_INLINE Packet2d por<Packet2d>(const Packet2d& a, const Packet2d& b) { return _mm_or_pd(a,b); }
+template<> EIGEN_STRONG_INLINE Packet4i por<Packet4i>(const Packet4i& a, const Packet4i& b) { return _mm_or_si128(a,b); }
+template<> EIGEN_STRONG_INLINE Packet16b por<Packet16b>(const Packet16b& a, const Packet16b& b) { return _mm_or_si128(a,b); }
+
+template<> EIGEN_STRONG_INLINE Packet4f pxor<Packet4f>(const Packet4f& a, const Packet4f& b) { return _mm_xor_ps(a,b); }
+template<> EIGEN_STRONG_INLINE Packet2d pxor<Packet2d>(const Packet2d& a, const Packet2d& b) { return _mm_xor_pd(a,b); }
+template<> EIGEN_STRONG_INLINE Packet4i pxor<Packet4i>(const Packet4i& a, const Packet4i& b) { return _mm_xor_si128(a,b); }
+template<> EIGEN_STRONG_INLINE Packet16b pxor<Packet16b>(const Packet16b& a, const Packet16b& b) { return _mm_xor_si128(a,b); }
+
+template<> EIGEN_STRONG_INLINE Packet4f pandnot<Packet4f>(const Packet4f& a, const Packet4f& b) { return _mm_andnot_ps(b,a); }
+template<> EIGEN_STRONG_INLINE Packet2d pandnot<Packet2d>(const Packet2d& a, const Packet2d& b) { return _mm_andnot_pd(b,a); }
+template<> EIGEN_STRONG_INLINE Packet4i pandnot<Packet4i>(const Packet4i& a, const Packet4i& b) { return _mm_andnot_si128(b,a); }
+
+template<> EIGEN_STRONG_INLINE Packet4f pcmp_le(const Packet4f& a, const Packet4f& b) { return _mm_cmple_ps(a,b); }
+template<> EIGEN_STRONG_INLINE Packet4f pcmp_lt(const Packet4f& a, const Packet4f& b) { return _mm_cmplt_ps(a,b); }
+template<> EIGEN_STRONG_INLINE Packet4f pcmp_lt_or_nan(const Packet4f& a, const Packet4f& b) { return _mm_cmpnge_ps(a,b); }
+template<> EIGEN_STRONG_INLINE Packet4f pcmp_eq(const Packet4f& a, const Packet4f& b) { return _mm_cmpeq_ps(a,b); }
 
+template<> EIGEN_STRONG_INLINE Packet2d pcmp_le(const Packet2d& a, const Packet2d& b) { return _mm_cmple_pd(a,b); }
+template<> EIGEN_STRONG_INLINE Packet2d pcmp_lt(const Packet2d& a, const Packet2d& b) { return _mm_cmplt_pd(a,b); }
+template<> EIGEN_STRONG_INLINE Packet2d pcmp_lt_or_nan(const Packet2d& a, const Packet2d& b) { return _mm_cmpnge_pd(a,b); }
+template<> EIGEN_STRONG_INLINE Packet2d pcmp_eq(const Packet2d& a, const Packet2d& b) { return _mm_cmpeq_pd(a,b); }
+
+template<> EIGEN_STRONG_INLINE Packet4i pcmp_lt(const Packet4i& a, const Packet4i& b) { return _mm_cmplt_epi32(a,b); }
+template<> EIGEN_STRONG_INLINE Packet4i pcmp_eq(const Packet4i& a, const Packet4i& b) { return _mm_cmpeq_epi32(a,b); }
+template<> EIGEN_STRONG_INLINE Packet16b pcmp_eq(const Packet16b& a, const Packet16b& b) { return _mm_cmpeq_epi8(a,b); }
+template<> EIGEN_STRONG_INLINE Packet4i pcmp_le(const Packet4i& a, const Packet4i& b) { return por(pcmp_lt(a,b), pcmp_eq(a,b)); }
 
 template<> EIGEN_STRONG_INLINE Packet4f pmin<Packet4f>(const Packet4f& a, const Packet4f& b) {
 #if EIGEN_COMP_GNUC && EIGEN_COMP_GNUC < 63
   // There appears to be a bug in GCC, by which the optimizer may
   // flip the argument order in calls to _mm_min_ps, so we have to
   // resort to inline ASM here. This is supposed to be fixed in gcc6.3,
   // see also: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=72867
@@ -379,14 +488,15 @@
 #else
   // after some bench, this version *is* faster than a scalar implementation
   Packet4i mask = _mm_cmplt_epi32(a,b);
   return _mm_or_si128(_mm_and_si128(mask,a),_mm_andnot_si128(mask,b));
 #endif
 }
 
+
 template<> EIGEN_STRONG_INLINE Packet4f pmax<Packet4f>(const Packet4f& a, const Packet4f& b) {
 #if EIGEN_COMP_GNUC && EIGEN_COMP_GNUC < 63
   // There appears to be a bug in GCC, by which the optimizer may
   // flip the argument order in calls to _mm_max_ps, so we have to
   // resort to inline ASM here. This is supposed to be fixed in gcc6.3,
   // see also: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=72867
   #ifdef EIGEN_VECTORIZE_AVX
@@ -428,65 +538,89 @@
 #else
   // after some bench, this version *is* faster than a scalar implementation
   Packet4i mask = _mm_cmpgt_epi32(a,b);
   return _mm_or_si128(_mm_and_si128(mask,a),_mm_andnot_si128(mask,b));
 #endif
 }
 
-template<> EIGEN_STRONG_INLINE Packet4f pcmp_le(const Packet4f& a, const Packet4f& b) { return _mm_cmple_ps(a,b); }
-template<> EIGEN_STRONG_INLINE Packet4f pcmp_lt(const Packet4f& a, const Packet4f& b) { return _mm_cmplt_ps(a,b); }
-template<> EIGEN_STRONG_INLINE Packet4f pcmp_lt_or_nan(const Packet4f& a, const Packet4f& b) { return _mm_cmpnge_ps(a,b); }
-template<> EIGEN_STRONG_INLINE Packet4f pcmp_eq(const Packet4f& a, const Packet4f& b) { return _mm_cmpeq_ps(a,b); }
-
-template<> EIGEN_STRONG_INLINE Packet2d pcmp_le(const Packet2d& a, const Packet2d& b) { return _mm_cmple_pd(a,b); }
-template<> EIGEN_STRONG_INLINE Packet2d pcmp_lt(const Packet2d& a, const Packet2d& b) { return _mm_cmplt_pd(a,b); }
-template<> EIGEN_STRONG_INLINE Packet2d pcmp_lt_or_nan(const Packet2d& a, const Packet2d& b) { return _mm_cmpnge_pd(a,b); }
-template<> EIGEN_STRONG_INLINE Packet2d pcmp_eq(const Packet2d& a, const Packet2d& b) { return _mm_cmpeq_pd(a,b); }
+template <typename Packet, typename Op>
+EIGEN_STRONG_INLINE Packet pminmax_propagate_numbers(const Packet& a, const Packet& b, Op op) {
+  // In this implementation, we take advantage of the fact that pmin/pmax for SSE
+  // always return a if either a or b is NaN.
+  Packet not_nan_mask_a = pcmp_eq(a, a);
+  Packet m = op(a, b);
+  return pselect<Packet>(not_nan_mask_a, m, b);
+}
+
+template <typename Packet, typename Op>
+EIGEN_STRONG_INLINE Packet pminmax_propagate_nan(const Packet& a, const Packet& b, Op op) {
+  // In this implementation, we take advantage of the fact that pmin/pmax for SSE
+  // always return a if either a or b is NaN.
+  Packet not_nan_mask_a = pcmp_eq(a, a);
+  Packet m = op(b, a);
+  return pselect<Packet>(not_nan_mask_a, m, a);
+}
+
+// Add specializations for min/max with prescribed NaN progation.
+template<>
+EIGEN_STRONG_INLINE Packet4f pmin<PropagateNumbers, Packet4f>(const Packet4f& a, const Packet4f& b) {
+  return pminmax_propagate_numbers(a, b, pmin<Packet4f>);
+}
+template<>
+EIGEN_STRONG_INLINE Packet2d pmin<PropagateNumbers, Packet2d>(const Packet2d& a, const Packet2d& b) {
+  return pminmax_propagate_numbers(a, b, pmin<Packet2d>);
+}
+template<>
+EIGEN_STRONG_INLINE Packet4f pmax<PropagateNumbers, Packet4f>(const Packet4f& a, const Packet4f& b) {
+  return pminmax_propagate_numbers(a, b, pmax<Packet4f>);
+}
+template<>
+EIGEN_STRONG_INLINE Packet2d pmax<PropagateNumbers, Packet2d>(const Packet2d& a, const Packet2d& b) {
+  return pminmax_propagate_numbers(a, b, pmax<Packet2d>);
+}
+template<>
+EIGEN_STRONG_INLINE Packet4f pmin<PropagateNaN, Packet4f>(const Packet4f& a, const Packet4f& b) {
+  return pminmax_propagate_nan(a, b, pmin<Packet4f>);
+}
+template<>
+EIGEN_STRONG_INLINE Packet2d pmin<PropagateNaN, Packet2d>(const Packet2d& a, const Packet2d& b) {
+  return pminmax_propagate_nan(a, b, pmin<Packet2d>);
+}
+template<>
+EIGEN_STRONG_INLINE Packet4f pmax<PropagateNaN, Packet4f>(const Packet4f& a, const Packet4f& b) {
+  return pminmax_propagate_nan(a, b, pmax<Packet4f>);
+}
+template<>
+EIGEN_STRONG_INLINE Packet2d pmax<PropagateNaN, Packet2d>(const Packet2d& a, const Packet2d& b) {
+  return pminmax_propagate_nan(a, b, pmax<Packet2d>);
+}
+
+template<int N> EIGEN_STRONG_INLINE Packet4i parithmetic_shift_right(const Packet4i& a) { return _mm_srai_epi32(a,N); }
+template<int N> EIGEN_STRONG_INLINE Packet4i plogical_shift_right   (const Packet4i& a) { return _mm_srli_epi32(a,N); }
+template<int N> EIGEN_STRONG_INLINE Packet4i plogical_shift_left    (const Packet4i& a) { return _mm_slli_epi32(a,N); }
 
-template<> EIGEN_STRONG_INLINE Packet4i pcmp_lt(const Packet4i& a, const Packet4i& b) { return _mm_cmplt_epi32(a,b); }
-template<> EIGEN_STRONG_INLINE Packet4i pcmp_eq(const Packet4i& a, const Packet4i& b) { return _mm_cmpeq_epi32(a,b); }
-template<> EIGEN_STRONG_INLINE Packet16b pcmp_eq(const Packet16b& a, const Packet16b& b) { return _mm_cmpeq_epi8(a,b); }
-
-
-template<> EIGEN_STRONG_INLINE Packet4i ptrue<Packet4i>(const Packet4i& a) { return _mm_cmpeq_epi32(a, a); }
-template<> EIGEN_STRONG_INLINE Packet16b ptrue<Packet16b>(const Packet16b& a) { return _mm_cmpeq_epi8(a, a); }
-template<> EIGEN_STRONG_INLINE Packet4f
-ptrue<Packet4f>(const Packet4f& a) {
-  Packet4i b = _mm_castps_si128(a);
-  return _mm_castsi128_ps(_mm_cmpeq_epi32(b, b));
+template<> EIGEN_STRONG_INLINE Packet4f pabs(const Packet4f& a)
+{
+  const Packet4f mask = _mm_castsi128_ps(_mm_setr_epi32(0x7FFFFFFF,0x7FFFFFFF,0x7FFFFFFF,0x7FFFFFFF));
+  return _mm_and_ps(a,mask);
 }
-template<> EIGEN_STRONG_INLINE Packet2d
-ptrue<Packet2d>(const Packet2d& a) {
-  Packet4i b = _mm_castpd_si128(a);
-  return _mm_castsi128_pd(_mm_cmpeq_epi32(b, b));
+template<> EIGEN_STRONG_INLINE Packet2d pabs(const Packet2d& a)
+{
+  const Packet2d mask = _mm_castsi128_pd(_mm_setr_epi32(0xFFFFFFFF,0x7FFFFFFF,0xFFFFFFFF,0x7FFFFFFF));
+  return _mm_and_pd(a,mask);
+}
+template<> EIGEN_STRONG_INLINE Packet4i pabs(const Packet4i& a)
+{
+  #ifdef EIGEN_VECTORIZE_SSSE3
+  return _mm_abs_epi32(a);
+  #else
+  Packet4i aux = _mm_srai_epi32(a,31);
+  return _mm_sub_epi32(_mm_xor_si128(a,aux),aux);
+  #endif
 }
-
-
-template<> EIGEN_STRONG_INLINE Packet4f pand<Packet4f>(const Packet4f& a, const Packet4f& b) { return _mm_and_ps(a,b); }
-template<> EIGEN_STRONG_INLINE Packet2d pand<Packet2d>(const Packet2d& a, const Packet2d& b) { return _mm_and_pd(a,b); }
-template<> EIGEN_STRONG_INLINE Packet4i pand<Packet4i>(const Packet4i& a, const Packet4i& b) { return _mm_and_si128(a,b); }
-template<> EIGEN_STRONG_INLINE Packet16b pand<Packet16b>(const Packet16b& a, const Packet16b& b) { return _mm_and_si128(a,b); }
-
-template<> EIGEN_STRONG_INLINE Packet4f por<Packet4f>(const Packet4f& a, const Packet4f& b) { return _mm_or_ps(a,b); }
-template<> EIGEN_STRONG_INLINE Packet2d por<Packet2d>(const Packet2d& a, const Packet2d& b) { return _mm_or_pd(a,b); }
-template<> EIGEN_STRONG_INLINE Packet4i por<Packet4i>(const Packet4i& a, const Packet4i& b) { return _mm_or_si128(a,b); }
-template<> EIGEN_STRONG_INLINE Packet16b por<Packet16b>(const Packet16b& a, const Packet16b& b) { return _mm_or_si128(a,b); }
-
-template<> EIGEN_STRONG_INLINE Packet4f pxor<Packet4f>(const Packet4f& a, const Packet4f& b) { return _mm_xor_ps(a,b); }
-template<> EIGEN_STRONG_INLINE Packet2d pxor<Packet2d>(const Packet2d& a, const Packet2d& b) { return _mm_xor_pd(a,b); }
-template<> EIGEN_STRONG_INLINE Packet4i pxor<Packet4i>(const Packet4i& a, const Packet4i& b) { return _mm_xor_si128(a,b); }
-template<> EIGEN_STRONG_INLINE Packet16b pxor<Packet16b>(const Packet16b& a, const Packet16b& b) { return _mm_xor_si128(a,b); }
-
-template<> EIGEN_STRONG_INLINE Packet4f pandnot<Packet4f>(const Packet4f& a, const Packet4f& b) { return _mm_andnot_ps(b,a); }
-template<> EIGEN_STRONG_INLINE Packet2d pandnot<Packet2d>(const Packet2d& a, const Packet2d& b) { return _mm_andnot_pd(b,a); }
-template<> EIGEN_STRONG_INLINE Packet4i pandnot<Packet4i>(const Packet4i& a, const Packet4i& b) { return _mm_andnot_si128(b,a); }
-
-template<int N> EIGEN_STRONG_INLINE Packet4i parithmetic_shift_right(Packet4i a) { return _mm_srai_epi32(a,N); }
-template<int N> EIGEN_STRONG_INLINE Packet4i plogical_shift_right(Packet4i a) { return _mm_srli_epi32(a,N); }
-template<int N> EIGEN_STRONG_INLINE Packet4i plogical_shift_left(Packet4i a) { return _mm_slli_epi32(a,N); }
 
 #ifdef EIGEN_VECTORIZE_SSE4_1
 template<> EIGEN_STRONG_INLINE Packet4f pround<Packet4f>(const Packet4f& a)
 {
   // Unfortunatly _mm_round_ps doesn't have a rounding mode to implement numext::round.
   const Packet4f mask = pset1frombits<Packet4f>(0x80000000u);
   const Packet4f prev0dot5 = pset1frombits<Packet4f>(0x3EFFFFFFu);
@@ -505,37 +639,81 @@
 
 template<> EIGEN_STRONG_INLINE Packet4f pceil<Packet4f>(const Packet4f& a) { return _mm_ceil_ps(a); }
 template<> EIGEN_STRONG_INLINE Packet2d pceil<Packet2d>(const Packet2d& a) { return _mm_ceil_pd(a); }
 
 template<> EIGEN_STRONG_INLINE Packet4f pfloor<Packet4f>(const Packet4f& a) { return _mm_floor_ps(a); }
 template<> EIGEN_STRONG_INLINE Packet2d pfloor<Packet2d>(const Packet2d& a) { return _mm_floor_pd(a); }
 #else
+template<> EIGEN_STRONG_INLINE Packet4f print(const Packet4f& a) {
+  // Adds and subtracts signum(a) * 2^23 to force rounding.
+  const Packet4f limit = pset1<Packet4f>(static_cast<float>(1<<23));
+  const Packet4f abs_a = pabs(a);
+  Packet4f r = padd(abs_a, limit);
+  // Don't compile-away addition and subtraction.
+  EIGEN_OPTIMIZATION_BARRIER(r);
+  r = psub(r, limit);
+  // If greater than limit, simply return a.  Otherwise, account for sign.
+  r = pselect(pcmp_lt(abs_a, limit),
+              pselect(pcmp_lt(a, pzero(a)), pnegate(r), r), a);
+  return r;
+}
+
+template<> EIGEN_STRONG_INLINE Packet2d print(const Packet2d& a) {
+  // Adds and subtracts signum(a) * 2^52 to force rounding.
+  const Packet2d limit = pset1<Packet2d>(static_cast<double>(1ull<<52));
+  const Packet2d abs_a = pabs(a);
+  Packet2d r = padd(abs_a, limit);
+  // Don't compile-away addition and subtraction.
+  EIGEN_OPTIMIZATION_BARRIER(r);
+  r = psub(r, limit);
+  // If greater than limit, simply return a.  Otherwise, account for sign.
+  r = pselect(pcmp_lt(abs_a, limit),
+              pselect(pcmp_lt(a, pzero(a)), pnegate(r), r), a);
+  return r;
+}
+
 template<> EIGEN_STRONG_INLINE Packet4f pfloor<Packet4f>(const Packet4f& a)
 {
   const Packet4f cst_1 = pset1<Packet4f>(1.0f);
-  Packet4i emm0 = _mm_cvttps_epi32(a);
-  Packet4f tmp  = _mm_cvtepi32_ps(emm0);
-  /* if greater, substract 1 */
+  Packet4f tmp  = print<Packet4f>(a);
+  // If greater, subtract one.
   Packet4f mask = _mm_cmpgt_ps(tmp, a);
   mask = pand(mask, cst_1);
   return psub(tmp, mask);
 }
 
-// WARNING: this pfloor implementation makes sense for small inputs only,
-// It is currently only used by pexp and not exposed through HasFloor.
 template<> EIGEN_STRONG_INLINE Packet2d pfloor<Packet2d>(const Packet2d& a)
 {
   const Packet2d cst_1 = pset1<Packet2d>(1.0);
-  Packet4i emm0 = _mm_cvttpd_epi32(a);
-  Packet2d tmp  = _mm_cvtepi32_pd(emm0);
-  /* if greater, substract 1 */
+  Packet2d tmp  = print<Packet2d>(a);
+  // If greater, subtract one.
   Packet2d mask = _mm_cmpgt_pd(tmp, a);
   mask = pand(mask, cst_1);
   return psub(tmp, mask);
 }
+
+template<> EIGEN_STRONG_INLINE Packet4f pceil<Packet4f>(const Packet4f& a)
+{
+  const Packet4f cst_1 = pset1<Packet4f>(1.0f);
+  Packet4f tmp  = print<Packet4f>(a);
+  // If smaller, add one.
+  Packet4f mask = _mm_cmplt_ps(tmp, a);
+  mask = pand(mask, cst_1);
+  return padd(tmp, mask);
+}
+
+template<> EIGEN_STRONG_INLINE Packet2d pceil<Packet2d>(const Packet2d& a)
+{
+  const Packet2d cst_1 = pset1<Packet2d>(1.0);
+  Packet2d tmp  = print<Packet2d>(a);
+  // If smaller, add one.
+  Packet2d mask = _mm_cmplt_pd(tmp, a);
+  mask = pand(mask, cst_1);
+  return padd(tmp, mask);
+}
 #endif
 
 template<> EIGEN_STRONG_INLINE Packet4f pload<Packet4f>(const float*   from) { EIGEN_DEBUG_ALIGNED_LOAD return _mm_load_ps(from); }
 template<> EIGEN_STRONG_INLINE Packet2d pload<Packet2d>(const double*  from) { EIGEN_DEBUG_ALIGNED_LOAD return _mm_load_pd(from); }
 template<> EIGEN_STRONG_INLINE Packet4i pload<Packet4i>(const int*     from) { EIGEN_DEBUG_ALIGNED_LOAD return _mm_load_si128(reinterpret_cast<const __m128i*>(from)); }
 template<> EIGEN_STRONG_INLINE Packet16b pload<Packet16b>(const bool*     from) { EIGEN_DEBUG_ALIGNED_LOAD return  _mm_load_si128(reinterpret_cast<const __m128i*>(from)); }
 
@@ -633,15 +811,15 @@
 
 template<> EIGEN_DEVICE_FUNC inline Packet16b pgather<bool, Packet16b>(const bool* from, Index stride)
 {
   return _mm_set_epi8(from[15*stride], from[14*stride], from[13*stride], from[12*stride],
                       from[11*stride], from[10*stride], from[9*stride], from[8*stride],
                       from[7*stride], from[6*stride], from[5*stride], from[4*stride],
                       from[3*stride], from[2*stride], from[1*stride], from[0*stride]);
- }
+}
 
 template<> EIGEN_DEVICE_FUNC inline void pscatter<float, Packet4f>(float* to, const Packet4f& from, Index stride)
 {
   to[stride*0] = _mm_cvtss_f32(from);
   to[stride*1] = _mm_cvtss_f32(_mm_shuffle_ps(from, from, 1));
   to[stride*2] = _mm_cvtss_f32(_mm_shuffle_ps(from, from, 2));
   to[stride*3] = _mm_cvtss_f32(_mm_shuffle_ps(from, from, 3));
@@ -703,16 +881,16 @@
 template<> EIGEN_STRONG_INLINE float  pfirst<Packet4f>(const Packet4f& a) { float x = _mm_cvtss_f32(a); return x; }
 template<> EIGEN_STRONG_INLINE double pfirst<Packet2d>(const Packet2d& a) { double x = _mm_cvtsd_f64(a); return x; }
 template<> EIGEN_STRONG_INLINE int    pfirst<Packet4i>(const Packet4i& a) { int x = _mm_cvtsi128_si32(a); return x; }
 #else
 template<> EIGEN_STRONG_INLINE float  pfirst<Packet4f>(const Packet4f& a) { return _mm_cvtss_f32(a); }
 template<> EIGEN_STRONG_INLINE double pfirst<Packet2d>(const Packet2d& a) { return _mm_cvtsd_f64(a); }
 template<> EIGEN_STRONG_INLINE int    pfirst<Packet4i>(const Packet4i& a) { return _mm_cvtsi128_si32(a); }
-template<> EIGEN_STRONG_INLINE bool   pfirst<Packet16b>(const Packet16b& a) { int x = _mm_cvtsi128_si32(a); return static_cast<bool>(x & 1); }
 #endif
+template<> EIGEN_STRONG_INLINE bool   pfirst<Packet16b>(const Packet16b& a) { int x = _mm_cvtsi128_si32(a); return static_cast<bool>(x & 1); }
 
 template<> EIGEN_STRONG_INLINE Packet4f preverse(const Packet4f& a) { return _mm_shuffle_ps(a,a,0x1B); }
 template<> EIGEN_STRONG_INLINE Packet2d preverse(const Packet2d& a) { return _mm_shuffle_pd(a,a,0x1); }
 template<> EIGEN_STRONG_INLINE Packet4i preverse(const Packet4i& a) { return _mm_shuffle_epi32(a,0x1B); }
 template<> EIGEN_STRONG_INLINE Packet16b preverse(const Packet16b& a) {
 #ifdef EIGEN_VECTORIZE_SSSE3
   __m128i mask = _mm_set_epi8(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15);
@@ -720,49 +898,54 @@
 #else
   Packet16b tmp = _mm_shuffle_epi32(a, _MM_SHUFFLE(0, 1, 2, 3));
   tmp = _mm_shufflehi_epi16(_mm_shufflelo_epi16(tmp, _MM_SHUFFLE(2, 3, 0, 1)), _MM_SHUFFLE(2, 3, 0, 1));
   return _mm_or_si128(_mm_slli_epi16(tmp, 8), _mm_srli_epi16(tmp, 8));
 #endif
 }
 
-template<> EIGEN_STRONG_INLINE Packet4f pabs(const Packet4f& a)
-{
-  const Packet4f mask = _mm_castsi128_ps(_mm_setr_epi32(0x7FFFFFFF,0x7FFFFFFF,0x7FFFFFFF,0x7FFFFFFF));
-  return _mm_and_ps(a,mask);
-}
-template<> EIGEN_STRONG_INLINE Packet2d pabs(const Packet2d& a)
-{
-  const Packet2d mask = _mm_castsi128_pd(_mm_setr_epi32(0xFFFFFFFF,0x7FFFFFFF,0xFFFFFFFF,0x7FFFFFFF));
-  return _mm_and_pd(a,mask);
+template<> EIGEN_STRONG_INLINE Packet4f pfrexp<Packet4f>(const Packet4f& a, Packet4f& exponent) {
+  return pfrexp_generic(a,exponent);
 }
-template<> EIGEN_STRONG_INLINE Packet4i pabs(const Packet4i& a)
-{
-  #ifdef EIGEN_VECTORIZE_SSSE3
-  return _mm_abs_epi32(a);
-  #else
-  Packet4i aux = _mm_srai_epi32(a,31);
-  return _mm_sub_epi32(_mm_xor_si128(a,aux),aux);
-  #endif
+
+// Extract exponent without existence of Packet2l.
+template<>
+EIGEN_STRONG_INLINE  
+Packet2d pfrexp_generic_get_biased_exponent(const Packet2d& a) {
+  const Packet2d cst_exp_mask  = pset1frombits<Packet2d>(static_cast<uint64_t>(0x7ff0000000000000ull));
+  __m128i a_expo = _mm_srli_epi64(_mm_castpd_si128(pand(a, cst_exp_mask)), 52);
+  return _mm_cvtepi32_pd(vec4i_swizzle1(a_expo, 0, 2, 1, 3));
 }
 
-template<> EIGEN_STRONG_INLINE Packet4f pfrexp<Packet4f>(const Packet4f& a, Packet4f& exponent) {
-  return pfrexp_float(a,exponent);
+template<> EIGEN_STRONG_INLINE Packet2d pfrexp<Packet2d>(const Packet2d& a, Packet2d& exponent) {
+  return pfrexp_generic(a, exponent);
 }
 
 template<> EIGEN_STRONG_INLINE Packet4f pldexp<Packet4f>(const Packet4f& a, const Packet4f& exponent) {
-  return pldexp_float(a,exponent);
+  return pldexp_generic(a,exponent);
 }
 
+// We specialize pldexp here, since the generic implementation uses Packet2l, which is not well
+// supported by SSE, and has more range than is needed for exponents.
 template<> EIGEN_STRONG_INLINE Packet2d pldexp<Packet2d>(const Packet2d& a, const Packet2d& exponent) {
-  const Packet4i cst_1023_0 = _mm_setr_epi32(1023, 1023, 0, 0);
-  Packet4i emm0 = _mm_cvttpd_epi32(exponent);
-  emm0 = padd(emm0, cst_1023_0);
-  emm0 = _mm_slli_epi32(emm0, 20);
-  emm0 = _mm_shuffle_epi32(emm0, _MM_SHUFFLE(1,2,0,3));
-  return pmul(a, Packet2d(_mm_castsi128_pd(emm0)));
+  // Clamp exponent to [-2099, 2099]
+  const Packet2d max_exponent = pset1<Packet2d>(2099.0);
+  const Packet2d e = pmin(pmax(exponent, pnegate(max_exponent)), max_exponent);
+  
+  // Convert e to integer and swizzle to low-order bits.
+  const Packet4i ei = vec4i_swizzle1(_mm_cvtpd_epi32(e), 0, 3, 1, 3);
+  
+  // Split 2^e into four factors and multiply:
+  const Packet4i bias = _mm_set_epi32(0, 1023, 0, 1023);
+  Packet4i b = parithmetic_shift_right<2>(ei);  // floor(e/4)
+  Packet2d c = _mm_castsi128_pd(_mm_slli_epi64(padd(b, bias), 52));  // 2^b
+  Packet2d out = pmul(pmul(pmul(a, c), c), c); // a * 2^(3b)
+  b = psub(psub(psub(ei, b), b), b);  // e - 3b
+  c = _mm_castsi128_pd(_mm_slli_epi64(padd(b, bias), 52));  // 2^(e - 3b)
+  out = pmul(out, c);  // a * 2^e
+  return out;
 }
 
 // with AVX, the default implementations based on pload1 are faster
 #ifndef __AVX__
 template<> EIGEN_STRONG_INLINE void
 pbroadcast4<Packet4f>(const float *a,
                       Packet4f& a0, Packet4f& a1, Packet4f& a2, Packet4f& a3)
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/SSE/TypeCasting.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/SSE/TypeCasting.h`

 * *Files 4% similar despite different names*

```diff
@@ -73,14 +73,21 @@
   return _mm_castps_si128(a);
 }
 
 template<> EIGEN_STRONG_INLINE Packet4f preinterpret<Packet4f,Packet4i>(const Packet4i& a) {
   return _mm_castsi128_ps(a);
 }
 
+template<> EIGEN_STRONG_INLINE Packet2d preinterpret<Packet2d,Packet4i>(const Packet4i& a) {
+  return _mm_castsi128_pd(a);
+}
+
+template<> EIGEN_STRONG_INLINE Packet4i preinterpret<Packet4i,Packet2d>(const Packet2d& a) {
+  return _mm_castpd_si128(a);
+}
 
 // Disable the following code since it's broken on too many platforms / compilers.
 //#elif defined(EIGEN_VECTORIZE_SSE) && (!EIGEN_ARCH_x86_64) && (!EIGEN_COMP_MSVC)
 #if 0
 
 template <>
 struct type_casting_traits<Eigen::half, float> {
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/SYCL/InteropHeaders.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/SYCL/InteropHeaders.h`

 * *Files 2% similar despite different names*

```diff
@@ -55,14 +55,17 @@
     HasErf = 0,
     HasErfc = 0,
     HasNdtri = 0,
     HasIGamma = 0,
     HasIGammac = 0,
     HasBetaInc = 0,
     HasBlend = has_blend,
+    // This flag is used to indicate whether packet comparison is supported.
+    // pcmp_eq, pcmp_lt and pcmp_le should be defined for it to be true.
+    HasCmp = 1,
     HasMax = 1,
     HasMin = 1,
     HasMul = 1,
     HasAdd = 1,
     HasFloor = 1,
     HasRound = 1,
     HasRint = 1,
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/SYCL/MathFunctions.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/SYCL/MathFunctions.h`

 * *Files 1% similar despite different names*

```diff
@@ -16,15 +16,14 @@
  * \brief:
  *  MathFunctions
  *
  *****************************************************************/
 
 #ifndef EIGEN_MATH_FUNCTIONS_SYCL_H
 #define EIGEN_MATH_FUNCTIONS_SYCL_H
-
 namespace Eigen {
 
 namespace internal {
 
 // Make sure this is only available when targeting a GPU: we don't want to
 // introduce conflicts between these packet_traits definitions and the ones
 // we'll use on the host side (SSE, AVX, ...)
@@ -66,14 +65,15 @@
   template <>                                                          \
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE packet_type pexp<packet_type>( \
       const packet_type& a) {                                          \
     return cl::sycl::exp(a);                                           \
   }
 
 SYCL_PEXP(cl::sycl::cl_float4)
+SYCL_PEXP(cl::sycl::cl_float)
 SYCL_PEXP(cl::sycl::cl_double2)
 #undef SYCL_PEXP
 
 #define SYCL_PEXPM1(packet_type)                                         \
   template <>                                                            \
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE packet_type pexpm1<packet_type>( \
       const packet_type& a) {                                            \
@@ -233,15 +233,15 @@
   }
 
 SYCL_PROUND(cl::sycl::cl_float4)
 SYCL_PROUND(cl::sycl::cl_double2)
 #undef SYCL_PROUND
 
 #define SYCL_PRINT(packet_type)                                         \
-  template<>                                                            \
+  template <>                                                           \
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE packet_type print<packet_type>( \
       const packet_type& a) {                                           \
     return cl::sycl::rint(a);                                           \
   }
 
 SYCL_PRINT(cl::sycl::cl_float4)
 SYCL_PRINT(cl::sycl::cl_double2)
@@ -276,14 +276,26 @@
     return expr;                                                       \
   }
 
 SYCL_PMAX(cl::sycl::cl_float4, cl::sycl::fmax(a, b))
 SYCL_PMAX(cl::sycl::cl_double2, cl::sycl::fmax(a, b))
 #undef SYCL_PMAX
 
-#endif
+#define SYCL_PLDEXP(packet_type)                                             \
+  template <>                                                                \
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE packet_type pldexp(                  \
+      const packet_type& a, const packet_type& exponent) {                   \
+    return cl::sycl::ldexp(                                                  \
+        a, exponent.template convert<cl::sycl::cl_int,                       \
+                                     cl::sycl::rounding_mode::automatic>()); \
+  }
+
+SYCL_PLDEXP(cl::sycl::cl_float4)
+SYCL_PLDEXP(cl::sycl::cl_double2)
+#undef SYCL_PLDEXP
 
+#endif
 }  // end namespace internal
 
 }  // end namespace Eigen
 
 #endif  // EIGEN_MATH_FUNCTIONS_SYCL_H
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/SYCL/PacketMath.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/SYCL/PacketMath.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/SYCL/SyclMemoryModel.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/SYCL/SyclMemoryModel.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/SYCL/TypeCasting.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/SYCL/TypeCasting.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/ZVector/Complex.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/ZVector/Complex.h`

 * *Files 17% similar despite different names*

```diff
@@ -136,14 +136,19 @@
   return Packet1cd(v1 + v2);
 }
 template<> EIGEN_STRONG_INLINE Packet1cd pand    <Packet1cd>(const Packet1cd& a, const Packet1cd& b) { return Packet1cd(vec_and(a.v,b.v)); }
 template<> EIGEN_STRONG_INLINE Packet1cd por     <Packet1cd>(const Packet1cd& a, const Packet1cd& b) { return Packet1cd(vec_or(a.v,b.v)); }
 template<> EIGEN_STRONG_INLINE Packet1cd pxor    <Packet1cd>(const Packet1cd& a, const Packet1cd& b) { return Packet1cd(vec_xor(a.v,b.v)); }
 template<> EIGEN_STRONG_INLINE Packet1cd pandnot <Packet1cd>(const Packet1cd& a, const Packet1cd& b) { return Packet1cd(vec_and(a.v, vec_nor(b.v,b.v))); }
 template<> EIGEN_STRONG_INLINE Packet1cd ploaddup<Packet1cd>(const std::complex<double>*     from) {  return pset1<Packet1cd>(*from); }
+template<> EIGEN_STRONG_INLINE Packet1cd pcmp_eq(const Packet1cd& a, const Packet1cd& b) {
+  Packet2d eq = vec_cmpeq (a.v, b.v);
+  Packet2d tmp = { eq[1], eq[0] };
+  return (Packet1cd)pand<Packet2d>(eq, tmp);
+}
 
 template<> EIGEN_STRONG_INLINE void prefetch<std::complex<double> >(const std::complex<double> *   addr) { EIGEN_ZVECTOR_PREFETCH(addr); }
 
 template<> EIGEN_STRONG_INLINE std::complex<double>  pfirst<Packet1cd>(const Packet1cd& a)
 {
   std::complex<double> EIGEN_ALIGN16 res;
   pstore<std::complex<double> >(&res, a);
@@ -156,53 +161,20 @@
 {
   return pfirst(a);
 }
 template<> EIGEN_STRONG_INLINE std::complex<double> predux_mul<Packet1cd>(const Packet1cd& a)
 {
   return pfirst(a);
 }
-template<> struct conj_helper<Packet1cd, Packet1cd, false,true>
-{
-  EIGEN_STRONG_INLINE Packet1cd pmadd(const Packet1cd& x, const Packet1cd& y, const Packet1cd& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet1cd pmul(const Packet1cd& a, const Packet1cd& b) const
-  {
-    return internal::pmul(a, pconj(b));
-  }
-};
-
-template<> struct conj_helper<Packet1cd, Packet1cd, true,false>
-{
-  EIGEN_STRONG_INLINE Packet1cd pmadd(const Packet1cd& x, const Packet1cd& y, const Packet1cd& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet1cd pmul(const Packet1cd& a, const Packet1cd& b) const
-  {
-    return internal::pmul(pconj(a), b);
-  }
-};
-
-template<> struct conj_helper<Packet1cd, Packet1cd, true,true>
-{
-  EIGEN_STRONG_INLINE Packet1cd pmadd(const Packet1cd& x, const Packet1cd& y, const Packet1cd& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet1cd pmul(const Packet1cd& a, const Packet1cd& b) const
-  {
-    return pconj(internal::pmul(a, b));
-  }
-};
-
 EIGEN_MAKE_CONJ_HELPER_CPLX_REAL(Packet1cd,Packet2d)
 
 template<> EIGEN_STRONG_INLINE Packet1cd pdiv<Packet1cd>(const Packet1cd& a, const Packet1cd& b)
 {
   // TODO optimize it for AltiVec
-  Packet1cd res = conj_helper<Packet1cd,Packet1cd,false,true>().pmul(a,b);
+  Packet1cd res = pmul(a,pconj(b));
   Packet2d s = vec_madd(b.v, b.v, p2d_ZERO_);
   return Packet1cd(pdiv(res.v, s + vec_perm(s, s, p16uc_REVERSE64)));
 }
 
 EIGEN_STRONG_INLINE Packet1cd pcplxflip/*<Packet1cd>*/(const Packet1cd& x)
 {
   return Packet1cd(preverse(Packet2d(x.v)));
@@ -277,14 +249,25 @@
 
 template<> EIGEN_STRONG_INLINE Packet2cf ploaddup<Packet2cf>(const std::complex<float>*      from) {  return pset1<Packet2cf>(*from); }
 
 template<> EIGEN_STRONG_INLINE void prefetch<std::complex<float> >(const std::complex<float> *     addr) { EIGEN_ZVECTOR_PREFETCH(addr); }
 
 
 #if !defined(__ARCH__) || (defined(__ARCH__) && __ARCH__ < 12)
+
+template<> EIGEN_STRONG_INLINE Packet2cf pcmp_eq(const Packet2cf& a, const Packet2cf& b) {
+  Packet4f eq = pcmp_eq<Packet4f> (a.v, b.v);
+  Packet2cf res;
+  Packet2d tmp1 = { eq.v4f[0][1], eq.v4f[0][0] };
+  Packet2d tmp2 = { eq.v4f[1][1], eq.v4f[1][0] };
+  res.v.v4f[0] = pand<Packet2d>(eq.v4f[0], tmp1);
+  res.v.v4f[1] = pand<Packet2d>(eq.v4f[1], tmp2);
+  return res;
+}
+
 template<> EIGEN_STRONG_INLINE Packet2cf pconj(const Packet2cf& a)
 {
   Packet2cf res;
   res.v.v4f[0] = pconj(Packet1cd(reinterpret_cast<Packet2d>(a.v.v4f[0]))).v;
   res.v.v4f[1] = pconj(Packet1cd(reinterpret_cast<Packet2d>(a.v.v4f[1]))).v;
   return res;
 }
@@ -317,47 +300,14 @@
 {
   std::complex<float> res;
   Packet1cd b = pmul<Packet1cd>(a.cd[0], a.cd[1]);
   vec_st2f(b.v, (float*)&res);
   return res;
 }
 
-template<> struct conj_helper<Packet2cf, Packet2cf, false,true>
-{
-  EIGEN_STRONG_INLINE Packet2cf pmadd(const Packet2cf& x, const Packet2cf& y, const Packet2cf& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet2cf pmul(const Packet2cf& a, const Packet2cf& b) const
-  {
-    return internal::pmul(a, pconj(b));
-  }
-};
-
-template<> struct conj_helper<Packet2cf, Packet2cf, true,false>
-{
-  EIGEN_STRONG_INLINE Packet2cf pmadd(const Packet2cf& x, const Packet2cf& y, const Packet2cf& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet2cf pmul(const Packet2cf& a, const Packet2cf& b) const
-  {
-    return internal::pmul(pconj(a), b);
-  }
-};
-
-template<> struct conj_helper<Packet2cf, Packet2cf, true,true>
-{
-  EIGEN_STRONG_INLINE Packet2cf pmadd(const Packet2cf& x, const Packet2cf& y, const Packet2cf& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet2cf pmul(const Packet2cf& a, const Packet2cf& b) const
-  {
-    return pconj(internal::pmul(a, b));
-  }
-};
-
 EIGEN_MAKE_CONJ_HELPER_CPLX_REAL(Packet2cf,Packet4f)
 
 template<> EIGEN_STRONG_INLINE Packet2cf pdiv<Packet2cf>(const Packet2cf& a, const Packet2cf& b)
 {
   // TODO optimize it for AltiVec
   Packet2cf res;
   res.cd[0] = pdiv<Packet1cd>(a.cd[0], b.cd[0]);
@@ -383,14 +333,19 @@
 template<> EIGEN_STRONG_INLINE Packet2cf pblend(const Selector<2>& ifPacket, const Packet2cf& thenPacket, const Packet2cf& elsePacket) {
   Packet2cf result;
   const Selector<4> ifPacket4 = { ifPacket.select[0], ifPacket.select[0], ifPacket.select[1], ifPacket.select[1] };
   result.v = pblend<Packet4f>(ifPacket4, thenPacket.v, elsePacket.v);
   return result;
 }
 #else
+template<> EIGEN_STRONG_INLINE Packet2cf pcmp_eq(const Packet2cf& a, const Packet2cf& b) {
+  Packet4f eq = vec_cmpeq (a.v, b.v);
+  Packet4f tmp = { eq[1], eq[0], eq[3], eq[2] };
+  return (Packet2cf)pand<Packet4f>(eq, tmp);
+}
 template<> EIGEN_STRONG_INLINE Packet2cf pconj(const Packet2cf& a) { return Packet2cf(pxor<Packet4f>(a.v, reinterpret_cast<Packet4f>(p4ui_CONJ_XOR))); }
 template<> EIGEN_STRONG_INLINE Packet2cf pmul<Packet2cf>(const Packet2cf& a, const Packet2cf& b)
 {
   Packet4f a_re, a_im, prod, prod_im;
 
   // Permute and multiply the real parts of a and b
   a_re = vec_perm(a.v, a.v, p16uc_PSET32_WODD);
@@ -431,53 +386,20 @@
   Packet2cf prod;
   b = vec_sld(a.v, a.v, 8);
   prod = pmul<Packet2cf>(a, Packet2cf(b));
 
   return pfirst<Packet2cf>(prod);
 }
 
-template<> struct conj_helper<Packet2cf, Packet2cf, false,true>
-{
-  EIGEN_STRONG_INLINE Packet2cf pmadd(const Packet2cf& x, const Packet2cf& y, const Packet2cf& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet2cf pmul(const Packet2cf& a, const Packet2cf& b) const
-  {
-    return internal::pmul(a, pconj(b));
-  }
-};
-
-template<> struct conj_helper<Packet2cf, Packet2cf, true,false>
-{
-  EIGEN_STRONG_INLINE Packet2cf pmadd(const Packet2cf& x, const Packet2cf& y, const Packet2cf& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet2cf pmul(const Packet2cf& a, const Packet2cf& b) const
-  {
-    return internal::pmul(pconj(a), b);
-  }
-};
-
-template<> struct conj_helper<Packet2cf, Packet2cf, true,true>
-{
-  EIGEN_STRONG_INLINE Packet2cf pmadd(const Packet2cf& x, const Packet2cf& y, const Packet2cf& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet2cf pmul(const Packet2cf& a, const Packet2cf& b) const
-  {
-    return pconj(internal::pmul(a, b));
-  }
-};
-
 EIGEN_MAKE_CONJ_HELPER_CPLX_REAL(Packet2cf,Packet4f)
 
 template<> EIGEN_STRONG_INLINE Packet2cf pdiv<Packet2cf>(const Packet2cf& a, const Packet2cf& b)
 {
   // TODO optimize it for AltiVec
-  Packet2cf res = conj_helper<Packet2cf,Packet2cf,false,true>().pmul(a, b);
+  Packet2cf res = pmul(a, pconj(b));
   Packet4f s = pmul<Packet4f>(b.v, b.v);
   return Packet2cf(pdiv(res.v, padd<Packet4f>(s, vec_perm(s, s, p16uc_COMPLEX32_REV))));
 }
 
 template<> EIGEN_STRONG_INLINE Packet2cf pcplxflip<Packet2cf>(const Packet2cf& x)
 {
   return Packet2cf(vec_perm(x.v, x.v, p16uc_COMPLEX32_REV));
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/ZVector/MathFunctions.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/ZVector/MathFunctions.h`

 * *Files 2% similar despite different names*

```diff
@@ -136,15 +136,14 @@
                  isnumber_mask);
 }
 
 template<> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
 Packet4f pexp<Packet4f>(const Packet4f& _x)
 {
 #if !defined(__ARCH__) || (defined(__ARCH__) && __ARCH__ >= 12)
-/*
   Packet4f x = _x;
 
   Packet4f tmp, fx;
   Packet4i emm0;
 
   // clamp x
   x = pmax(pmin(x, p4f_exp_hi), p4f_exp_lo);
@@ -167,24 +166,19 @@
   y = pmadd(y, x, p4f_cephes_exp_p3);
   y = pmadd(y, x, p4f_cephes_exp_p4);
   y = pmadd(y, x, p4f_cephes_exp_p5);
   y = pmadd(y, z, x);
   y = padd(y, p4f_1);
 
   // build 2^n
-  emm0 = vec_cts(fx, 0);
+  emm0 = (Packet4i){ (int)fx[0], (int)fx[1], (int)fx[2], (int)fx[3] };
   emm0 = emm0 + p4i_0x7f;
   emm0 = emm0 << reinterpret_cast<Packet4i>(p4i_23);
 
-  // Altivec's max & min operators just drop silent NaNs. Check NaNs in 
-  // inputs and return them unmodified.
-  Packet4ui isnumber_mask = reinterpret_cast<Packet4ui>(vec_cmpeq(_x, _x));
-  return vec_sel(_x, pmax(pmul(y, reinterpret_cast<Packet4f>(emm0)), _x),
-                 isnumber_mask);*/
-  return _x;
+  return pmax(pmul(y, reinterpret_cast<Packet4f>(emm0)), _x);
 #else
   Packet4f res;
   res.v4f[0] = pexp<Packet2d>(_x.v4f[0]);
   res.v4f[1] = pexp<Packet2d>(_x.v4f[1]);
   return res;
 #endif
 }
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/arch/ZVector/PacketMath.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/arch/ZVector/PacketMath.h`

 * *Files 4% similar despite different names*

```diff
@@ -6,32 +6,26 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_PACKET_MATH_ZVECTOR_H
 #define EIGEN_PACKET_MATH_ZVECTOR_H
 
-#include <stdint.h>
-
 namespace Eigen {
 
 namespace internal {
 
 #ifndef EIGEN_CACHEFRIENDLY_PRODUCT_THRESHOLD
 #define EIGEN_CACHEFRIENDLY_PRODUCT_THRESHOLD 16
 #endif
 
 #ifndef EIGEN_HAS_SINGLE_INSTRUCTION_MADD
 #define EIGEN_HAS_SINGLE_INSTRUCTION_MADD
 #endif
 
-#ifndef EIGEN_HAS_SINGLE_INSTRUCTION_CJMADD
-#define EIGEN_HAS_SINGLE_INSTRUCTION_CJMADD
-#endif
-
 #ifndef EIGEN_ARCH_DEFAULT_NUMBER_OF_REGISTERS
 #define EIGEN_ARCH_DEFAULT_NUMBER_OF_REGISTERS  32
 #endif
 
 typedef __vector int                 Packet4i;
 typedef __vector unsigned int        Packet4ui;
 typedef __vector __bool int          Packet4bi;
@@ -47,18 +41,18 @@
 #else
 typedef struct {
 	Packet2d  v4f[2];
 } Packet4f;
 #endif
 
 typedef union {
-  int32_t   i[4];
-  uint32_t ui[4];
-  int64_t   l[2];
-  uint64_t ul[2];
+  numext::int32_t   i[4];
+  numext::uint32_t ui[4];
+  numext::int64_t   l[2];
+  numext::uint64_t ul[2];
   double    d[2];
   float     f[4];
   Packet4i  v4i;
   Packet4ui v4ui;
   Packet2l  v2l;
   Packet2ul v2ul;
   Packet2d  v2d;
@@ -92,16 +86,17 @@
 static _EIGEN_DECLARE_CONST_FAST_Packet4i(ZERO, 0); //{ 0, 0, 0, 0,}
 static _EIGEN_DECLARE_CONST_FAST_Packet4i(ONE, 1); //{ 1, 1, 1, 1}
 
 static _EIGEN_DECLARE_CONST_FAST_Packet2d(ZERO, 0);
 static _EIGEN_DECLARE_CONST_FAST_Packet2l(ZERO, 0);
 static _EIGEN_DECLARE_CONST_FAST_Packet2l(ONE, 1);
 
-static Packet2d p2d_ONE = { 1.0, 1.0 }; 
-static Packet2d p2d_ZERO_ = { -0.0, -0.0 };
+static Packet2d p2d_ONE = { 1.0, 1.0 };
+static Packet2d p2d_ZERO_ = { numext::bit_cast<double>0x8000000000000000ull),
+                              numext::bit_cast<double>0x8000000000000000ull) };
 
 #if !defined(__ARCH__) || (defined(__ARCH__) && __ARCH__ >= 12)
 #define _EIGEN_DECLARE_CONST_FAST_Packet4f(NAME,X) \
   Packet4f p4f_##NAME = reinterpret_cast<Packet4f>(vec_splat_s32(X))
 
 #define _EIGEN_DECLARE_CONST_Packet4f(NAME,X) \
   Packet4f p4f_##NAME = pset1<Packet4f>(X)
@@ -189,19 +184,15 @@
     HasDiv = 1,
     HasMin = 1,
     HasMax = 1,
     HasAbs = 1,
     HasSin = 0,
     HasCos = 0,
     HasLog = 0,
-#if !defined(__ARCH__) || (defined(__ARCH__) && __ARCH__ >= 12)
-    HasExp = 0,
-#else
     HasExp = 1,
-#endif
     HasSqrt = 1,
     HasRsqrt = 1,
     HasTanh = 1,
     HasErf = 1,
     HasRound = 1,
     HasFloor = 1,
     HasCeil = 1,
@@ -737,24 +728,24 @@
   res.v4f[1] = pand(a.v4f[1], b.v4f[1]);
   return res;
 }
 
 template<> EIGEN_STRONG_INLINE Packet4f por<Packet4f>(const Packet4f& a, const Packet4f& b)
 {
   Packet4f res;
-  res.v4f[0] = pand(a.v4f[0], b.v4f[0]);
-  res.v4f[1] = pand(a.v4f[1], b.v4f[1]);
+  res.v4f[0] = por(a.v4f[0], b.v4f[0]);
+  res.v4f[1] = por(a.v4f[1], b.v4f[1]);
   return res;
 }
 
 template<> EIGEN_STRONG_INLINE Packet4f pxor<Packet4f>(const Packet4f& a, const Packet4f& b)
 {
   Packet4f res;
-  res.v4f[0] = pand(a.v4f[0], b.v4f[0]);
-  res.v4f[1] = pand(a.v4f[1], b.v4f[1]);
+  res.v4f[0] = pxor(a.v4f[0], b.v4f[0]);
+  res.v4f[1] = pxor(a.v4f[1], b.v4f[1]);
   return res;
 }
 
 template<> EIGEN_STRONG_INLINE Packet4f pandnot<Packet4f>(const Packet4f& a, const Packet4f& b)
 {
   Packet4f res;
   res.v4f[0] = pandnot(a.v4f[0], b.v4f[0]);
@@ -886,14 +877,39 @@
   Packet2ul mask_hi = vec_cmpeq(select_hi, reinterpret_cast<Packet2ul>(p2l_ONE));
   Packet2ul mask_lo = vec_cmpeq(select_lo, reinterpret_cast<Packet2ul>(p2l_ONE));
   Packet4f result;
   result.v4f[0] = vec_sel(elsePacket.v4f[0], thenPacket.v4f[0], mask_hi);
   result.v4f[1] = vec_sel(elsePacket.v4f[1], thenPacket.v4f[1], mask_lo);
   return result;
 }
+
+template<> Packet4f EIGEN_STRONG_INLINE pcmp_le<Packet4f>(const Packet4f& a, const Packet4f& b)
+{
+  Packet4f res;
+  res.v4f[0] = pcmp_le(a.v4f[0], b.v4f[0]);
+  res.v4f[1] = pcmp_le(a.v4f[1], b.v4f[1]);
+  return res;
+}
+
+template<> Packet4f EIGEN_STRONG_INLINE pcmp_lt<Packet4f>(const Packet4f& a, const Packet4f& b)
+{
+  Packet4f res;
+  res.v4f[0] = pcmp_lt(a.v4f[0], b.v4f[0]);
+  res.v4f[1] = pcmp_lt(a.v4f[1], b.v4f[1]);
+  return res;
+}
+
+template<> Packet4f EIGEN_STRONG_INLINE pcmp_eq<Packet4f>(const Packet4f& a, const Packet4f& b)
+{
+  Packet4f res;
+  res.v4f[0] = pcmp_eq(a.v4f[0], b.v4f[0]);
+  res.v4f[1] = pcmp_eq(a.v4f[1], b.v4f[1]);
+  return res;
+}
+
 #else
 template<> EIGEN_STRONG_INLINE Packet4f pload<Packet4f>(const float* from)
 {
   // FIXME: No intrinsic yet
   EIGEN_DEBUG_ALIGNED_LOAD
   Packet *vfrom;
   vfrom = (Packet *) from;
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/functors/AssignmentFunctors.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/functors/AssignmentFunctors.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/functors/NullaryFunctors.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/functors/NullaryFunctors.h`

 * *Files 2% similar despite different names*

```diff
@@ -40,15 +40,15 @@
 template <typename Scalar, bool IsInteger> struct linspaced_op_impl;
 
 template <typename Scalar>
 struct linspaced_op_impl<Scalar,/*IsInteger*/false>
 {
   typedef typename NumTraits<Scalar>::Real RealScalar;
 
-  linspaced_op_impl(const Scalar& low, const Scalar& high, Index num_steps) :
+  EIGEN_DEVICE_FUNC linspaced_op_impl(const Scalar& low, const Scalar& high, Index num_steps) :
     m_low(low), m_high(high), m_size1(num_steps==1 ? 1 : num_steps-1), m_step(num_steps==1 ? Scalar() : Scalar((high-low)/RealScalar(num_steps-1))),
     m_flip(numext::abs(high)<numext::abs(low))
   {}
 
   template<typename IndexType>
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Scalar operator() (IndexType i) const {
     if(m_flip)
@@ -86,15 +86,15 @@
   const Scalar m_step;
   const bool m_flip;
 };
 
 template <typename Scalar>
 struct linspaced_op_impl<Scalar,/*IsInteger*/true>
 {
-  linspaced_op_impl(const Scalar& low, const Scalar& high, Index num_steps) :
+  EIGEN_DEVICE_FUNC linspaced_op_impl(const Scalar& low, const Scalar& high, Index num_steps) :
     m_low(low),
     m_multiplier((high-low)/convert_index<Scalar>(num_steps<=1 ? 1 : num_steps-1)),
     m_divisor(convert_index<Scalar>((high>=low?num_steps:-num_steps)+(high-low))/((numext::abs(high-low)+1)==0?1:(numext::abs(high-low)+1))),
     m_use_divisor(num_steps>1 && (numext::abs(high-low)+1)<num_steps)
   {}
 
   template<typename IndexType>
@@ -125,15 +125,15 @@
     PacketAccess =   (!NumTraits<Scalar>::IsInteger) && packet_traits<Scalar>::HasSetLinear && packet_traits<Scalar>::HasBlend,
                   /*&& ((!NumTraits<Scalar>::IsInteger) || packet_traits<Scalar>::HasDiv),*/ // <- vectorization for integer is currently disabled
     IsRepeatable = true
   };
 };
 template <typename Scalar> struct linspaced_op
 {
-  linspaced_op(const Scalar& low, const Scalar& high, Index num_steps)
+  EIGEN_DEVICE_FUNC linspaced_op(const Scalar& low, const Scalar& high, Index num_steps)
     : impl((num_steps==1 ? high : low),high,num_steps)
   {}
 
   template<typename IndexType>
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Scalar operator() (IndexType i) const { return impl(i); }
 
   template<typename Packet,typename IndexType>
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/functors/StlFunctors.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/functors/StlFunctors.h`

 * *Files 11% similar despite different names*

```diff
@@ -8,14 +8,36 @@
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_STL_FUNCTORS_H
 #define EIGEN_STL_FUNCTORS_H
 
 namespace Eigen {
 
+// Portable replacements for certain functors.
+namespace numext {
+
+template<typename T = void>
+struct equal_to {
+  typedef bool result_type;
+  EIGEN_DEVICE_FUNC bool operator()(const T& lhs, const T& rhs) const {
+    return lhs == rhs;
+  }
+};
+
+template<typename T = void>
+struct not_equal_to {
+  typedef bool result_type;
+  EIGEN_DEVICE_FUNC bool operator()(const T& lhs, const T& rhs) const {
+    return lhs != rhs;
+  }
+};
+
+}
+
+
 namespace internal {
 
 // default functor traits for STL functors:
 
 template<typename T>
 struct functor_traits<std::multiplies<T> >
 { enum { Cost = NumTraits<T>::MulCost, PacketAccess = false }; };
@@ -65,29 +87,37 @@
 { enum { Cost = 1, PacketAccess = false }; };
 
 template<typename T>
 struct functor_traits<std::equal_to<T> >
 { enum { Cost = 1, PacketAccess = false }; };
 
 template<typename T>
+struct functor_traits<numext::equal_to<T> >
+  : functor_traits<std::equal_to<T> > {};
+
+template<typename T>
 struct functor_traits<std::not_equal_to<T> >
 { enum { Cost = 1, PacketAccess = false }; };
 
-#if (__cplusplus < 201103L) && (EIGEN_COMP_MSVC <= 1900)
+template<typename T>
+struct functor_traits<numext::not_equal_to<T> >
+  : functor_traits<std::not_equal_to<T> > {};
+
+#if (EIGEN_COMP_CXXVER < 11)
 // std::binder* are deprecated since c++11 and will be removed in c++17
 template<typename T>
 struct functor_traits<std::binder2nd<T> >
 { enum { Cost = functor_traits<T>::Cost, PacketAccess = false }; };
 
 template<typename T>
 struct functor_traits<std::binder1st<T> >
 { enum { Cost = functor_traits<T>::Cost, PacketAccess = false }; };
 #endif
 
-#if (__cplusplus < 201703L) && (EIGEN_COMP_MSVC < 1910)
+#if (EIGEN_COMP_CXXVER < 17)
 // std::unary_negate is deprecated since c++17 and will be removed in c++20
 template<typename T>
 struct functor_traits<std::unary_negate<T> >
 { enum { Cost = 1 + functor_traits<T>::Cost, PacketAccess = false }; };
 
 // std::binary_negate is deprecated since c++17 and will be removed in c++20
 template<typename T>
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/functors/TernaryFunctors.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/functors/TernaryFunctors.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/functors/UnaryFunctors.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/functors/UnaryFunctors.h`

 * *Files 2% similar despite different names*

```diff
@@ -105,15 +105,15 @@
   * \brief Template functor to compute the conjugate of a complex value
   *
   * \sa class CwiseUnaryOp, MatrixBase::conjugate()
   */
 template<typename Scalar> struct scalar_conjugate_op {
   EIGEN_EMPTY_STRUCT_CTOR(scalar_conjugate_op)
   EIGEN_DEVICE_FUNC
-  EIGEN_STRONG_INLINE const Scalar operator() (const Scalar& a) const { using numext::conj; return conj(a); }
+  EIGEN_STRONG_INLINE const Scalar operator() (const Scalar& a) const { return numext::conj(a); }
   template<typename Packet>
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Packet packetOp(const Packet& a) const { return internal::pconj(a); }
 };
 template<typename Scalar>
 struct functor_traits<scalar_conjugate_op<Scalar> >
 {
   enum {
@@ -134,15 +134,15 @@
   * \brief Template functor to compute the phase angle of a complex
   *
   * \sa class CwiseUnaryOp, Cwise::arg
   */
 template<typename Scalar> struct scalar_arg_op {
   EIGEN_EMPTY_STRUCT_CTOR(scalar_arg_op)
   typedef typename NumTraits<Scalar>::Real result_type;
-  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const result_type operator() (const Scalar& a) const { using numext::arg; return arg(a); }
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const result_type operator() (const Scalar& a) const { return numext::arg(a); }
   template<typename Packet>
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Packet packetOp(const Packet& a) const
   { return internal::parg(a); }
 };
 template<typename Scalar>
 struct functor_traits<scalar_arg_op<Scalar> >
 {
@@ -383,23 +383,39 @@
   *
   * \brief Template functor to compute the base-10 logarithm of a scalar
   *
   * \sa class CwiseUnaryOp, Cwise::log10()
   */
 template<typename Scalar> struct scalar_log10_op {
   EIGEN_EMPTY_STRUCT_CTOR(scalar_log10_op)
-  EIGEN_DEVICE_FUNC inline const Scalar operator() (const Scalar& a) const { EIGEN_USING_STD_MATH(log10) return log10(a); }
+  EIGEN_DEVICE_FUNC inline const Scalar operator() (const Scalar& a) const { EIGEN_USING_STD(log10) return log10(a); }
   template <typename Packet>
   EIGEN_DEVICE_FUNC inline Packet packetOp(const Packet& a) const { return internal::plog10(a); }
 };
 template<typename Scalar>
 struct functor_traits<scalar_log10_op<Scalar> >
 { enum { Cost = 5 * NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasLog10 }; };
 
 /** \internal
+  *
+  * \brief Template functor to compute the base-2 logarithm of a scalar
+  *
+  * \sa class CwiseUnaryOp, Cwise::log2()
+  */
+template<typename Scalar> struct scalar_log2_op {
+  EIGEN_EMPTY_STRUCT_CTOR(scalar_log2_op)
+  EIGEN_DEVICE_FUNC inline const Scalar operator() (const Scalar& a) const { return Scalar(EIGEN_LOG2E) * numext::log(a); }
+  template <typename Packet>
+  EIGEN_DEVICE_FUNC inline Packet packetOp(const Packet& a) const { return internal::plog2(a); }
+};
+template<typename Scalar>
+struct functor_traits<scalar_log2_op<Scalar> >
+{ enum { Cost = 5 * NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasLog }; };
+
+/** \internal
   * \brief Template functor to compute the square root of a scalar
   * \sa class CwiseUnaryOp, Cwise::sqrt()
   */
 template<typename Scalar> struct scalar_sqrt_op {
   EIGEN_EMPTY_STRUCT_CTOR(scalar_sqrt_op)
   EIGEN_DEVICE_FUNC inline const Scalar operator() (const Scalar& a) const { return numext::sqrt(a); }
   template <typename Packet>
@@ -418,21 +434,33 @@
     // The following numbers are based on min VSQRT throughput on Haswell.
     Cost = (sizeof(Scalar) == 8 ? 28 : 14),
 #endif
     PacketAccess = packet_traits<Scalar>::HasSqrt
   };
 };
 
+// Boolean specialization to eliminate -Wimplicit-conversion-floating-point-to-bool warnings.
+template<> struct scalar_sqrt_op<bool> {
+  EIGEN_EMPTY_STRUCT_CTOR(scalar_sqrt_op)
+  EIGEN_DEPRECATED EIGEN_DEVICE_FUNC inline bool operator() (const bool& a) const { return a; }
+  template <typename Packet>
+  EIGEN_DEPRECATED EIGEN_DEVICE_FUNC inline Packet packetOp(const Packet& a) const { return a; }
+};
+template <>
+struct functor_traits<scalar_sqrt_op<bool> > {
+  enum { Cost = 1, PacketAccess = packet_traits<bool>::Vectorizable };
+};
+
 /** \internal
   * \brief Template functor to compute the reciprocal square root of a scalar
   * \sa class CwiseUnaryOp, Cwise::rsqrt()
   */
 template<typename Scalar> struct scalar_rsqrt_op {
   EIGEN_EMPTY_STRUCT_CTOR(scalar_rsqrt_op)
-  EIGEN_DEVICE_FUNC inline const Scalar operator() (const Scalar& a) const { return Scalar(1)/numext::sqrt(a); }
+  EIGEN_DEVICE_FUNC inline const Scalar operator() (const Scalar& a) const { return numext::rsqrt(a); }
   template <typename Packet>
   EIGEN_DEVICE_FUNC inline Packet packetOp(const Packet& a) const { return internal::prsqrt(a); }
 };
 
 template<typename Scalar>
 struct functor_traits<scalar_rsqrt_op<Scalar> >
 { enum {
@@ -715,14 +743,27 @@
   EIGEN_DEVICE_FUNC inline const Packet packetOp(const Packet& a) const
   { return internal::pmul(a,a); }
 };
 template<typename Scalar>
 struct functor_traits<scalar_square_op<Scalar> >
 { enum { Cost = NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasMul }; };
 
+// Boolean specialization to avoid -Wint-in-bool-context warnings on GCC.
+template<>
+struct scalar_square_op<bool> {
+  EIGEN_EMPTY_STRUCT_CTOR(scalar_square_op)
+  EIGEN_DEPRECATED EIGEN_DEVICE_FUNC inline bool operator() (const bool& a) const { return a; }
+  template<typename Packet>
+  EIGEN_DEPRECATED EIGEN_DEVICE_FUNC inline const Packet packetOp(const Packet& a) const
+  { return a; }
+};
+template<>
+struct functor_traits<scalar_square_op<bool> >
+{ enum { Cost = 0, PacketAccess = packet_traits<bool>::Vectorizable }; };
+
 /** \internal
   * \brief Template functor to compute the cube of a scalar
   * \sa class CwiseUnaryOp, Cwise::cube()
   */
 template<typename Scalar>
 struct scalar_cube_op {
   EIGEN_EMPTY_STRUCT_CTOR(scalar_cube_op)
@@ -731,14 +772,27 @@
   EIGEN_DEVICE_FUNC inline const Packet packetOp(const Packet& a) const
   { return internal::pmul(a,pmul(a,a)); }
 };
 template<typename Scalar>
 struct functor_traits<scalar_cube_op<Scalar> >
 { enum { Cost = 2*NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasMul }; };
 
+// Boolean specialization to avoid -Wint-in-bool-context warnings on GCC.
+template<>
+struct scalar_cube_op<bool> {
+  EIGEN_EMPTY_STRUCT_CTOR(scalar_cube_op)
+  EIGEN_DEPRECATED EIGEN_DEVICE_FUNC inline bool operator() (const bool& a) const { return a; }
+  template<typename Packet>
+  EIGEN_DEPRECATED EIGEN_DEVICE_FUNC inline const Packet packetOp(const Packet& a) const
+  { return a; }
+};
+template<>
+struct functor_traits<scalar_cube_op<bool> >
+{ enum { Cost = 0, PacketAccess = packet_traits<bool>::Vectorizable }; };
+
 /** \internal
   * \brief Template functor to compute the rounded value of a scalar
   * \sa class CwiseUnaryOp, ArrayBase::round()
   */
 template<typename Scalar> struct scalar_round_op {
   EIGEN_EMPTY_STRUCT_CTOR(scalar_round_op)
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Scalar operator() (const Scalar& a) const { return numext::round(a); }
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/products/GeneralBlockPanelKernel.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/products/GeneralBlockPanelKernel.h`

 * *Files 6% similar despite different names*

```diff
@@ -84,7087 +84,6695 @@
 00000530: 2845 4947 454e 5f44 4546 4155 4c54 5f4c  (EIGEN_DEFAULT_L
 00000540: 325f 4341 4348 455f 5349 5a45 290a 0a23  2_CACHE_SIZE)..#
 00000550: 6966 2064 6566 696e 6564 2845 4947 454e  if defined(EIGEN
 00000560: 5f44 4546 4155 4c54 5f4c 335f 4341 4348  _DEFAULT_L3_CACH
 00000570: 455f 5349 5a45 290a 2364 6566 696e 6520  E_SIZE).#define 
 00000580: 4549 4745 4e5f 5345 545f 4445 4641 554c  EIGEN_SET_DEFAUL
 00000590: 545f 4c33 5f43 4143 4845 5f53 495a 4528  T_L3_CACHE_SIZE(
-000005a0: 7661 6c29 2045 4947 454e 5f53 4554 5f44  val) EIGEN_SET_D
-000005b0: 4546 4155 4c54 5f4c 335f 4341 4348 455f  EFAULT_L3_CACHE_
-000005c0: 5349 5a45 0a23 656c 7365 0a23 6465 6669  SIZE.#else.#defi
-000005d0: 6e65 2045 4947 454e 5f53 4554 5f44 4546  ne EIGEN_SET_DEF
-000005e0: 4155 4c54 5f4c 335f 4341 4348 455f 5349  AULT_L3_CACHE_SI
-000005f0: 5a45 2876 616c 2920 7661 6c0a 2365 6e64  ZE(val) val.#end
-00000600: 6966 202f 2f20 6465 6669 6e65 6428 4549  if // defined(EI
-00000610: 4745 4e5f 4445 4641 554c 545f 4c33 5f43  GEN_DEFAULT_L3_C
-00000620: 4143 4845 5f53 495a 4529 0a20 200a 2369  ACHE_SIZE).  .#i
-00000630: 6620 4549 4745 4e5f 4152 4348 5f69 3338  f EIGEN_ARCH_i38
-00000640: 365f 4f52 5f78 3836 5f36 340a 636f 6e73  6_OR_x86_64.cons
-00000650: 7420 7374 643a 3a70 7472 6469 6666 5f74  t std::ptrdiff_t
-00000660: 2064 6566 6175 6c74 4c31 4361 6368 6553   defaultL1CacheS
-00000670: 697a 6520 3d20 4549 4745 4e5f 5345 545f  ize = EIGEN_SET_
-00000680: 4445 4641 554c 545f 4c31 5f43 4143 4845  DEFAULT_L1_CACHE
-00000690: 5f53 495a 4528 3332 2a31 3032 3429 3b0a  _SIZE(32*1024);.
-000006a0: 636f 6e73 7420 7374 643a 3a70 7472 6469  const std::ptrdi
-000006b0: 6666 5f74 2064 6566 6175 6c74 4c32 4361  ff_t defaultL2Ca
-000006c0: 6368 6553 697a 6520 3d20 4549 4745 4e5f  cheSize = EIGEN_
-000006d0: 5345 545f 4445 4641 554c 545f 4c32 5f43  SET_DEFAULT_L2_C
-000006e0: 4143 4845 5f53 495a 4528 3235 362a 3130  ACHE_SIZE(256*10
-000006f0: 3234 293b 0a63 6f6e 7374 2073 7464 3a3a  24);.const std::
-00000700: 7074 7264 6966 665f 7420 6465 6661 756c  ptrdiff_t defaul
-00000710: 744c 3343 6163 6865 5369 7a65 203d 2045  tL3CacheSize = E
-00000720: 4947 454e 5f53 4554 5f44 4546 4155 4c54  IGEN_SET_DEFAULT
-00000730: 5f4c 335f 4341 4348 455f 5349 5a45 2832  _L3_CACHE_SIZE(2
-00000740: 2a31 3032 342a 3130 3234 293b 0a23 656c  *1024*1024);.#el
-00000750: 6966 2045 4947 454e 5f41 5243 485f 5050  if EIGEN_ARCH_PP
-00000760: 430a 636f 6e73 7420 7374 643a 3a70 7472  C.const std::ptr
-00000770: 6469 6666 5f74 2064 6566 6175 6c74 4c31  diff_t defaultL1
-00000780: 4361 6368 6553 697a 6520 3d20 4549 4745  CacheSize = EIGE
-00000790: 4e5f 5345 545f 4445 4641 554c 545f 4c31  N_SET_DEFAULT_L1
-000007a0: 5f43 4143 4845 5f53 495a 4528 3634 2a31  _CACHE_SIZE(64*1
-000007b0: 3032 3429 3b0a 636f 6e73 7420 7374 643a  024);.const std:
-000007c0: 3a70 7472 6469 6666 5f74 2064 6566 6175  :ptrdiff_t defau
-000007d0: 6c74 4c32 4361 6368 6553 697a 6520 3d20  ltL2CacheSize = 
-000007e0: 4549 4745 4e5f 5345 545f 4445 4641 554c  EIGEN_SET_DEFAUL
-000007f0: 545f 4c32 5f43 4143 4845 5f53 495a 4528  T_L2_CACHE_SIZE(
-00000800: 3531 322a 3130 3234 293b 0a63 6f6e 7374  512*1024);.const
-00000810: 2073 7464 3a3a 7074 7264 6966 665f 7420   std::ptrdiff_t 
-00000820: 6465 6661 756c 744c 3343 6163 6865 5369  defaultL3CacheSi
-00000830: 7a65 203d 2045 4947 454e 5f53 4554 5f44  ze = EIGEN_SET_D
-00000840: 4546 4155 4c54 5f4c 335f 4341 4348 455f  EFAULT_L3_CACHE_
-00000850: 5349 5a45 2834 2a31 3032 342a 3130 3234  SIZE(4*1024*1024
-00000860: 293b 0a23 656c 7365 0a63 6f6e 7374 2073  );.#else.const s
-00000870: 7464 3a3a 7074 7264 6966 665f 7420 6465  td::ptrdiff_t de
-00000880: 6661 756c 744c 3143 6163 6865 5369 7a65  faultL1CacheSize
-00000890: 203d 2045 4947 454e 5f53 4554 5f44 4546   = EIGEN_SET_DEF
-000008a0: 4155 4c54 5f4c 315f 4341 4348 455f 5349  AULT_L1_CACHE_SI
-000008b0: 5a45 2831 362a 3130 3234 293b 0a63 6f6e  ZE(16*1024);.con
-000008c0: 7374 2073 7464 3a3a 7074 7264 6966 665f  st std::ptrdiff_
-000008d0: 7420 6465 6661 756c 744c 3243 6163 6865  t defaultL2Cache
-000008e0: 5369 7a65 203d 2045 4947 454e 5f53 4554  Size = EIGEN_SET
-000008f0: 5f44 4546 4155 4c54 5f4c 325f 4341 4348  _DEFAULT_L2_CACH
-00000900: 455f 5349 5a45 2835 3132 2a31 3032 3429  E_SIZE(512*1024)
-00000910: 3b0a 636f 6e73 7420 7374 643a 3a70 7472  ;.const std::ptr
-00000920: 6469 6666 5f74 2064 6566 6175 6c74 4c33  diff_t defaultL3
-00000930: 4361 6368 6553 697a 6520 3d20 4549 4745  CacheSize = EIGE
-00000940: 4e5f 5345 545f 4445 4641 554c 545f 4c33  N_SET_DEFAULT_L3
-00000950: 5f43 4143 4845 5f53 495a 4528 3531 322a  _CACHE_SIZE(512*
-00000960: 3130 3234 293b 0a23 656e 6469 660a 0a23  1024);.#endif..#
-00000970: 756e 6465 6620 4549 4745 4e5f 5345 545f  undef EIGEN_SET_
-00000980: 4445 4641 554c 545f 4c31 5f43 4143 4845  DEFAULT_L1_CACHE
-00000990: 5f53 495a 450a 2375 6e64 6566 2045 4947  _SIZE.#undef EIG
-000009a0: 454e 5f53 4554 5f44 4546 4155 4c54 5f4c  EN_SET_DEFAULT_L
-000009b0: 325f 4341 4348 455f 5349 5a45 0a23 756e  2_CACHE_SIZE.#un
-000009c0: 6465 6620 4549 4745 4e5f 5345 545f 4445  def EIGEN_SET_DE
-000009d0: 4641 554c 545f 4c33 5f43 4143 4845 5f53  FAULT_L3_CACHE_S
-000009e0: 495a 450a 0a2f 2a2a 205c 696e 7465 726e  IZE../** \intern
-000009f0: 616c 202a 2f0a 7374 7275 6374 2043 6163  al */.struct Cac
-00000a00: 6865 5369 7a65 7320 7b0a 2020 4361 6368  heSizes {.  Cach
-00000a10: 6553 697a 6573 2829 3a20 6d5f 6c31 282d  eSizes(): m_l1(-
-00000a20: 3129 2c6d 5f6c 3228 2d31 292c 6d5f 6c33  1),m_l2(-1),m_l3
-00000a30: 282d 3129 207b 0a20 2020 2069 6e74 206c  (-1) {.    int l
-00000a40: 3143 6163 6865 5369 7a65 2c20 6c32 4361  1CacheSize, l2Ca
-00000a50: 6368 6553 697a 652c 206c 3343 6163 6865  cheSize, l3Cache
-00000a60: 5369 7a65 3b0a 2020 2020 7175 6572 7943  Size;.    queryC
-00000a70: 6163 6865 5369 7a65 7328 6c31 4361 6368  acheSizes(l1Cach
-00000a80: 6553 697a 652c 206c 3243 6163 6865 5369  eSize, l2CacheSi
-00000a90: 7a65 2c20 6c33 4361 6368 6553 697a 6529  ze, l3CacheSize)
-00000aa0: 3b0a 2020 2020 6d5f 6c31 203d 206d 616e  ;.    m_l1 = man
-00000ab0: 6167 655f 6361 6368 696e 675f 7369 7a65  age_caching_size
-00000ac0: 735f 6865 6c70 6572 286c 3143 6163 6865  s_helper(l1Cache
-00000ad0: 5369 7a65 2c20 6465 6661 756c 744c 3143  Size, defaultL1C
-00000ae0: 6163 6865 5369 7a65 293b 0a20 2020 206d  acheSize);.    m
-00000af0: 5f6c 3220 3d20 6d61 6e61 6765 5f63 6163  _l2 = manage_cac
-00000b00: 6869 6e67 5f73 697a 6573 5f68 656c 7065  hing_sizes_helpe
-00000b10: 7228 6c32 4361 6368 6553 697a 652c 2064  r(l2CacheSize, d
-00000b20: 6566 6175 6c74 4c32 4361 6368 6553 697a  efaultL2CacheSiz
-00000b30: 6529 3b0a 2020 2020 6d5f 6c33 203d 206d  e);.    m_l3 = m
-00000b40: 616e 6167 655f 6361 6368 696e 675f 7369  anage_caching_si
-00000b50: 7a65 735f 6865 6c70 6572 286c 3343 6163  zes_helper(l3Cac
-00000b60: 6865 5369 7a65 2c20 6465 6661 756c 744c  heSize, defaultL
-00000b70: 3343 6163 6865 5369 7a65 293b 0a20 207d  3CacheSize);.  }
-00000b80: 0a0a 2020 7374 643a 3a70 7472 6469 6666  ..  std::ptrdiff
-00000b90: 5f74 206d 5f6c 313b 0a20 2073 7464 3a3a  _t m_l1;.  std::
-00000ba0: 7074 7264 6966 665f 7420 6d5f 6c32 3b0a  ptrdiff_t m_l2;.
-00000bb0: 2020 7374 643a 3a70 7472 6469 6666 5f74    std::ptrdiff_t
-00000bc0: 206d 5f6c 333b 0a7d 3b0a 0a2f 2a2a 205c   m_l3;.};../** \
-00000bd0: 696e 7465 726e 616c 202a 2f0a 696e 6c69  internal */.inli
-00000be0: 6e65 2076 6f69 6420 6d61 6e61 6765 5f63  ne void manage_c
-00000bf0: 6163 6869 6e67 5f73 697a 6573 2841 6374  aching_sizes(Act
-00000c00: 696f 6e20 6163 7469 6f6e 2c20 7374 643a  ion action, std:
-00000c10: 3a70 7472 6469 6666 5f74 2a20 6c31 2c20  :ptrdiff_t* l1, 
-00000c20: 7374 643a 3a70 7472 6469 6666 5f74 2a20  std::ptrdiff_t* 
-00000c30: 6c32 2c20 7374 643a 3a70 7472 6469 6666  l2, std::ptrdiff
-00000c40: 5f74 2a20 6c33 290a 7b0a 2020 7374 6174  _t* l3).{.  stat
-00000c50: 6963 2043 6163 6865 5369 7a65 7320 6d5f  ic CacheSizes m_
-00000c60: 6361 6368 6553 697a 6573 3b0a 0a20 2069  cacheSizes;..  i
-00000c70: 6628 6163 7469 6f6e 3d3d 5365 7441 6374  f(action==SetAct
-00000c80: 696f 6e29 0a20 207b 0a20 2020 202f 2f20  ion).  {.    // 
-00000c90: 7365 7420 7468 6520 6370 7520 6361 6368  set the cpu cach
-00000ca0: 6520 7369 7a65 2061 6e64 2063 6163 6865  e size and cache
-00000cb0: 2061 6c6c 2062 6c6f 636b 2073 697a 6573   all block sizes
-00000cc0: 2066 726f 6d20 6120 676c 6f62 616c 2063   from a global c
-00000cd0: 6163 6865 2073 697a 6520 696e 2062 7974  ache size in byt
-00000ce0: 650a 2020 2020 6569 6765 6e5f 696e 7465  e.    eigen_inte
-00000cf0: 726e 616c 5f61 7373 6572 7428 6c31 213d  rnal_assert(l1!=
-00000d00: 3020 2626 206c 3221 3d30 293b 0a20 2020  0 && l2!=0);.   
-00000d10: 206d 5f63 6163 6865 5369 7a65 732e 6d5f   m_cacheSizes.m_
-00000d20: 6c31 203d 202a 6c31 3b0a 2020 2020 6d5f  l1 = *l1;.    m_
-00000d30: 6361 6368 6553 697a 6573 2e6d 5f6c 3220  cacheSizes.m_l2 
-00000d40: 3d20 2a6c 323b 0a20 2020 206d 5f63 6163  = *l2;.    m_cac
-00000d50: 6865 5369 7a65 732e 6d5f 6c33 203d 202a  heSizes.m_l3 = *
-00000d60: 6c33 3b0a 2020 7d0a 2020 656c 7365 2069  l3;.  }.  else i
-00000d70: 6628 6163 7469 6f6e 3d3d 4765 7441 6374  f(action==GetAct
-00000d80: 696f 6e29 0a20 207b 0a20 2020 2065 6967  ion).  {.    eig
-00000d90: 656e 5f69 6e74 6572 6e61 6c5f 6173 7365  en_internal_asse
-00000da0: 7274 286c 3121 3d30 2026 2620 6c32 213d  rt(l1!=0 && l2!=
-00000db0: 3029 3b0a 2020 2020 2a6c 3120 3d20 6d5f  0);.    *l1 = m_
-00000dc0: 6361 6368 6553 697a 6573 2e6d 5f6c 313b  cacheSizes.m_l1;
-00000dd0: 0a20 2020 202a 6c32 203d 206d 5f63 6163  .    *l2 = m_cac
-00000de0: 6865 5369 7a65 732e 6d5f 6c32 3b0a 2020  heSizes.m_l2;.  
-00000df0: 2020 2a6c 3320 3d20 6d5f 6361 6368 6553    *l3 = m_cacheS
-00000e00: 697a 6573 2e6d 5f6c 333b 0a20 207d 0a20  izes.m_l3;.  }. 
-00000e10: 2065 6c73 650a 2020 7b0a 2020 2020 6569   else.  {.    ei
-00000e20: 6765 6e5f 696e 7465 726e 616c 5f61 7373  gen_internal_ass
-00000e30: 6572 7428 6661 6c73 6529 3b0a 2020 7d0a  ert(false);.  }.
-00000e40: 7d0a 0a2f 2a20 4865 6c70 6572 2066 6f72  }../* Helper for
-00000e50: 2063 6f6d 7075 7465 5072 6f64 7563 7442   computeProductB
-00000e60: 6c6f 636b 696e 6753 697a 6573 2e0a 202a  lockingSizes.. *
-00000e70: 0a20 2a20 4769 7665 6e20 6120 6d20 7820  . * Given a m x 
-00000e80: 6b20 7469 6d65 7320 6b20 7820 6e20 6d61  k times k x n ma
-00000e90: 7472 6978 2070 726f 6475 6374 206f 6620  trix product of 
-00000ea0: 7363 616c 6172 2074 7970 6573 205c 6320  scalar types \c 
-00000eb0: 4c68 7353 6361 6c61 7220 616e 6420 5c63  LhsScalar and \c
-00000ec0: 2052 6873 5363 616c 6172 2c0a 202a 2074   RhsScalar,. * t
-00000ed0: 6869 7320 6675 6e63 7469 6f6e 2063 6f6d  his function com
-00000ee0: 7075 7465 7320 7468 6520 626c 6f63 6b69  putes the blocki
-00000ef0: 6e67 2073 697a 6520 7061 7261 6d65 7465  ng size paramete
-00000f00: 7273 2061 6c6f 6e67 2074 6865 2072 6573  rs along the res
-00000f10: 7065 6374 6976 6520 6469 6d65 6e73 696f  pective dimensio
-00000f20: 6e73 0a20 2a20 666f 7220 6d61 7472 6978  ns. * for matrix
-00000f30: 2070 726f 6475 6374 7320 616e 6420 7265   products and re
-00000f40: 6c61 7465 6420 616c 676f 7269 7468 6d73  lated algorithms
-00000f50: 2e20 5468 6520 626c 6f63 6b69 6e67 2073  . The blocking s
-00000f60: 697a 6573 2064 6570 656e 6473 206f 6e20  izes depends on 
-00000f70: 7661 7269 6f75 730a 202a 2070 6172 616d  various. * param
-00000f80: 6574 6572 733a 0a20 2a20 2d20 7468 6520  eters:. * - the 
-00000f90: 4c31 2061 6e64 204c 3220 6361 6368 6520  L1 and L2 cache 
-00000fa0: 7369 7a65 732c 0a20 2a20 2d20 7468 6520  sizes,. * - the 
-00000fb0: 7265 6769 7374 6572 206c 6576 656c 2062  register level b
-00000fc0: 6c6f 636b 696e 6720 7369 7a65 7320 6465  locking sizes de
-00000fd0: 6669 6e65 6420 6279 2067 6562 705f 7472  fined by gebp_tr
-00000fe0: 6169 7473 2c0a 202a 202d 2074 6865 206e  aits,. * - the n
-00000ff0: 756d 6265 7220 6f66 2073 6361 6c61 7273  umber of scalars
-00001000: 2074 6861 7420 6669 7420 696e 746f 2061   that fit into a
-00001010: 2070 6163 6b65 7420 2877 6865 6e20 7665   packet (when ve
-00001020: 6374 6f72 697a 6174 696f 6e20 6973 2065  ctorization is e
-00001030: 6e61 626c 6564 292e 0a20 2a0a 202a 205c  nabled).. *. * \
-00001040: 7361 2073 6574 4370 7543 6163 6865 5369  sa setCpuCacheSi
-00001050: 7a65 7320 2a2f 0a0a 7465 6d70 6c61 7465  zes */..template
-00001060: 3c74 7970 656e 616d 6520 4c68 7353 6361  <typename LhsSca
-00001070: 6c61 722c 2074 7970 656e 616d 6520 5268  lar, typename Rh
-00001080: 7353 6361 6c61 722c 2069 6e74 204b 6346  sScalar, int KcF
-00001090: 6163 746f 722c 2074 7970 656e 616d 6520  actor, typename 
-000010a0: 496e 6465 783e 0a76 6f69 6420 6576 616c  Index>.void eval
-000010b0: 7561 7465 5072 6f64 7563 7442 6c6f 636b  uateProductBlock
-000010c0: 696e 6753 697a 6573 4865 7572 6973 7469  ingSizesHeuristi
-000010d0: 6328 496e 6465 7826 206b 2c20 496e 6465  c(Index& k, Inde
-000010e0: 7826 206d 2c20 496e 6465 7826 206e 2c20  x& m, Index& n, 
-000010f0: 496e 6465 7820 6e75 6d5f 7468 7265 6164  Index num_thread
-00001100: 7320 3d20 3129 0a7b 0a20 2074 7970 6564  s = 1).{.  typed
-00001110: 6566 2067 6562 705f 7472 6169 7473 3c4c  ef gebp_traits<L
-00001120: 6873 5363 616c 6172 2c52 6873 5363 616c  hsScalar,RhsScal
-00001130: 6172 3e20 5472 6169 7473 3b0a 0a20 202f  ar> Traits;..  /
-00001140: 2f20 4578 706c 616e 6174 696f 6e73 3a0a  / Explanations:.
-00001150: 2020 2f2f 204c 6574 2773 2072 6563 616c    // Let's recal
-00001160: 6c20 7468 6174 2074 6865 2070 726f 6475  l that the produ
-00001170: 6374 2061 6c67 6f72 6974 686d 7320 666f  ct algorithms fo
-00001180: 726d 206d 6320 7820 6b63 2076 6572 7469  rm mc x kc verti
-00001190: 6361 6c20 7061 6e65 6c73 2041 2720 6f6e  cal panels A' on
-000011a0: 2074 6865 206c 6873 2061 6e64 0a20 202f   the lhs and.  /
-000011b0: 2f20 6b63 2078 206e 6320 626c 6f63 6b73  / kc x nc blocks
-000011c0: 2042 2720 6f6e 2074 6865 2072 6873 2e20   B' on the rhs. 
-000011d0: 4227 2068 6173 2074 6f20 6669 7420 696e  B' has to fit in
-000011e0: 746f 204c 322f 4c33 2063 6163 6865 2e20  to L2/L3 cache. 
-000011f0: 4d6f 7265 6f76 6572 2c20 4127 2069 7320  Moreover, A' is 
-00001200: 7072 6f63 6573 7365 640a 2020 2f2f 2070  processed.  // p
-00001210: 6572 206d 7220 7820 6b63 2068 6f72 697a  er mr x kc horiz
-00001220: 6f6e 7461 6c20 736d 616c 6c20 7061 6e65  ontal small pane
-00001230: 6c73 2077 6865 7265 206d 7220 6973 2074  ls where mr is t
-00001240: 6865 2062 6c6f 636b 696e 6720 7369 7a65  he blocking size
-00001250: 2061 6c6f 6e67 2074 6865 206d 2064 696d   along the m dim
-00001260: 656e 7369 6f6e 0a20 202f 2f20 6174 2074  ension.  // at t
-00001270: 6865 2072 6567 6973 7465 7220 6c65 7665  he register leve
-00001280: 6c2e 2054 6869 7320 736d 616c 6c20 686f  l. This small ho
-00001290: 7269 7a6f 6e74 616c 2070 616e 656c 2068  rizontal panel h
-000012a0: 6173 2074 6f20 7374 6179 2077 6974 6869  as to stay withi
-000012b0: 6e20 4c31 2063 6163 6865 2e0a 2020 7374  n L1 cache..  st
-000012c0: 643a 3a70 7472 6469 6666 5f74 206c 312c  d::ptrdiff_t l1,
-000012d0: 206c 322c 206c 333b 0a20 206d 616e 6167   l2, l3;.  manag
-000012e0: 655f 6361 6368 696e 675f 7369 7a65 7328  e_caching_sizes(
-000012f0: 4765 7441 6374 696f 6e2c 2026 6c31 2c20  GetAction, &l1, 
-00001300: 266c 322c 2026 6c33 293b 0a20 2023 6966  &l2, &l3);.  #if
-00001310: 6465 6620 4549 4745 4e5f 5645 4354 4f52  def EIGEN_VECTOR
-00001320: 495a 455f 4156 5835 3132 0a20 202f 2f20  IZE_AVX512.  // 
-00001330: 5765 206e 6565 6420 746f 2066 696e 6420  We need to find 
-00001340: 6120 7261 7469 6f6e 616c 6520 666f 7220  a rationale for 
-00001350: 7468 6174 2c20 6275 7420 7769 7468 6f75  that, but withou
-00001360: 7420 7468 6973 2061 646a 7573 746d 656e  t this adjustmen
-00001370: 742c 0a20 202f 2f20 7065 7266 6f72 6d61  t,.  // performa
-00001380: 6e63 6520 7769 7468 2041 5658 3531 3220  nce with AVX512 
-00001390: 6973 2070 7265 7474 7920 6261 642c 206c  is pretty bad, l
-000013a0: 696b 6520 2d32 3025 2073 6c6f 7765 722e  ike -20% slower.
-000013b0: 0a20 202f 2f20 4f6e 6520 7265 6173 6f6e  .  // One reason
-000013c0: 2069 7320 7468 6174 2077 6974 6820 696e   is that with in
-000013d0: 6372 6561 7369 6e67 2070 6163 6b65 742d  creasing packet-
-000013e0: 7369 7a65 2c20 7468 6520 626c 6f63 6b69  size, the blocki
-000013f0: 6e67 2073 697a 6520 6b0a 2020 2f2f 2068  ng size k.  // h
-00001400: 6173 2074 6f20 6265 636f 6d65 2070 7265  as to become pre
-00001410: 7474 7920 736d 616c 6c20 6966 2077 6520  tty small if we 
-00001420: 7761 6e74 2074 6861 7420 3120 6c68 7320  want that 1 lhs 
-00001430: 7061 6e65 6c20 6669 7420 7769 7468 696e  panel fit within
-00001440: 204c 312e 0a20 202f 2f20 466f 7220 696e   L1..  // For in
-00001450: 7374 616e 6365 2c20 7769 7468 2074 6865  stance, with the
-00001460: 2033 7058 3420 6b65 726e 656c 2061 6e64   3pX4 kernel and
-00001470: 2064 6f75 626c 652c 2074 6865 2073 697a   double, the siz
-00001480: 6520 6f66 2074 6865 206c 6873 2b72 6873  e of the lhs+rhs
-00001490: 2070 616e 656c 7320 6172 653a 0a20 202f   panels are:.  /
-000014a0: 2f20 2020 6b2a 2833 2a36 3420 2b20 342a  /   k*(3*64 + 4*
-000014b0: 3829 2042 7974 6573 2c20 7769 7468 206c  8) Bytes, with l
-000014c0: 313d 3332 6b42 7974 6573 2c20 616e 6420  1=32kBytes, and 
-000014d0: 6b25 383d 302c 2077 6520 6861 7665 206b  k%8=0, we have k
-000014e0: 3d31 3434 2e0a 2020 2f2f 2054 6869 7320  =144..  // This 
-000014f0: 6973 2071 7569 7465 2073 6d61 6c6c 2066  is quite small f
-00001500: 6f72 2061 2067 6f6f 6420 7265 7573 6520  or a good reuse 
-00001510: 6f66 2074 6865 2061 6363 756d 756c 6174  of the accumulat
-00001520: 696f 6e20 7265 6769 7374 6572 732e 0a20  ion registers.. 
-00001530: 206c 3120 2a3d 2034 3b0a 2020 2365 6e64   l1 *= 4;.  #end
-00001540: 6966 0a0a 2020 6966 2028 6e75 6d5f 7468  if..  if (num_th
-00001550: 7265 6164 7320 3e20 3129 207b 0a20 2020  reads > 1) {.   
-00001560: 2074 7970 6564 6566 2074 7970 656e 616d   typedef typenam
-00001570: 6520 5472 6169 7473 3a3a 5265 7353 6361  e Traits::ResSca
-00001580: 6c61 7220 5265 7353 6361 6c61 723b 0a20  lar ResScalar;. 
-00001590: 2020 2065 6e75 6d20 7b0a 2020 2020 2020     enum {.      
-000015a0: 6b64 6976 203d 204b 6346 6163 746f 7220  kdiv = KcFactor 
-000015b0: 2a20 2854 7261 6974 733a 3a6d 7220 2a20  * (Traits::mr * 
-000015c0: 7369 7a65 6f66 284c 6873 5363 616c 6172  sizeof(LhsScalar
-000015d0: 2920 2b20 5472 6169 7473 3a3a 6e72 202a  ) + Traits::nr *
-000015e0: 2073 697a 656f 6628 5268 7353 6361 6c61   sizeof(RhsScala
-000015f0: 7229 292c 0a20 2020 2020 206b 7375 6220  r)),.      ksub 
-00001600: 3d20 5472 6169 7473 3a3a 6d72 202a 2054  = Traits::mr * T
-00001610: 7261 6974 733a 3a6e 7220 2a20 7369 7a65  raits::nr * size
-00001620: 6f66 2852 6573 5363 616c 6172 292c 0a20  of(ResScalar),. 
-00001630: 2020 2020 206b 7220 3d20 382c 0a20 2020       kr = 8,.   
-00001640: 2020 206d 7220 3d20 5472 6169 7473 3a3a     mr = Traits::
-00001650: 6d72 2c0a 2020 2020 2020 6e72 203d 2054  mr,.      nr = T
-00001660: 7261 6974 733a 3a6e 720a 2020 2020 7d3b  raits::nr.    };
-00001670: 0a20 2020 202f 2f20 496e 6372 6561 7369  .    // Increasi
-00001680: 6e67 206b 2067 6976 6573 2075 7320 6d6f  ng k gives us mo
-00001690: 7265 2074 696d 6520 746f 2070 7265 6665  re time to prefe
-000016a0: 7463 6820 7468 6520 636f 6e74 656e 7420  tch the content 
-000016b0: 6f66 2074 6865 2022 4322 0a20 2020 202f  of the "C".    /
-000016c0: 2f20 7265 6769 7374 6572 732e 2048 6f77  / registers. How
-000016d0: 6576 6572 206f 6e63 6520 7468 6520 6c61  ever once the la
-000016e0: 7465 6e63 7920 6973 2068 6964 6465 6e20  tency is hidden 
-000016f0: 7468 6572 6520 6973 206e 6f20 706f 696e  there is no poin
-00001700: 7420 696e 0a20 2020 202f 2f20 696e 6372  t in.    // incr
-00001710: 6561 7369 6e67 2074 6865 2076 616c 7565  easing the value
-00001720: 206f 6620 6b2c 2073 6f20 7765 276c 6c20   of k, so we'll 
-00001730: 6361 7020 6974 2061 7420 3332 3020 2876  cap it at 320 (v
-00001740: 616c 7565 2064 6574 6572 6d69 6e65 640a  alue determined.
-00001750: 2020 2020 2f2f 2065 7870 6572 696d 656e      // experimen
-00001760: 7461 6c6c 7929 2e0a 2020 2020 636f 6e73  tally)..    cons
-00001770: 7420 496e 6465 7820 6b5f 6361 6368 6520  t Index k_cache 
-00001780: 3d20 286e 756d 6578 743a 3a6d 696e 693c  = (numext::mini<
-00001790: 496e 6465 783e 2928 286c 312d 6b73 7562  Index>)((l1-ksub
-000017a0: 292f 6b64 6976 2c20 3332 3029 3b0a 2020  )/kdiv, 320);.  
-000017b0: 2020 6966 2028 6b5f 6361 6368 6520 3c20    if (k_cache < 
-000017c0: 6b29 207b 0a20 2020 2020 206b 203d 206b  k) {.      k = k
-000017d0: 5f63 6163 6865 202d 2028 6b5f 6361 6368  _cache - (k_cach
-000017e0: 6520 2520 6b72 293b 0a20 2020 2020 2065  e % kr);.      e
-000017f0: 6967 656e 5f69 6e74 6572 6e61 6c5f 6173  igen_internal_as
-00001800: 7365 7274 286b 203e 2030 293b 0a20 2020  sert(k > 0);.   
-00001810: 207d 0a0a 2020 2020 636f 6e73 7420 496e   }..    const In
-00001820: 6465 7820 6e5f 6361 6368 6520 3d20 286c  dex n_cache = (l
-00001830: 322d 6c31 2920 2f20 286e 7220 2a20 7369  2-l1) / (nr * si
-00001840: 7a65 6f66 2852 6873 5363 616c 6172 2920  zeof(RhsScalar) 
-00001850: 2a20 6b29 3b0a 2020 2020 636f 6e73 7420  * k);.    const 
-00001860: 496e 6465 7820 6e5f 7065 725f 7468 7265  Index n_per_thre
-00001870: 6164 203d 206e 756d 6578 743a 3a64 6976  ad = numext::div
-00001880: 5f63 6569 6c28 6e2c 206e 756d 5f74 6872  _ceil(n, num_thr
-00001890: 6561 6473 293b 0a20 2020 2069 6620 286e  eads);.    if (n
-000018a0: 5f63 6163 6865 203c 3d20 6e5f 7065 725f  _cache <= n_per_
-000018b0: 7468 7265 6164 2920 7b0a 2020 2020 2020  thread) {.      
-000018c0: 2f2f 2044 6f6e 2774 2065 7863 6565 6420  // Don't exceed 
-000018d0: 7468 6520 6361 7061 6369 7479 206f 6620  the capacity of 
-000018e0: 7468 6520 6c32 2063 6163 6865 2e0a 2020  the l2 cache..  
-000018f0: 2020 2020 6569 6765 6e5f 696e 7465 726e      eigen_intern
-00001900: 616c 5f61 7373 6572 7428 6e5f 6361 6368  al_assert(n_cach
-00001910: 6520 3e3d 2073 7461 7469 635f 6361 7374  e >= static_cast
-00001920: 3c49 6e64 6578 3e28 6e72 2929 3b0a 2020  <Index>(nr));.  
-00001930: 2020 2020 6e20 3d20 6e5f 6361 6368 6520      n = n_cache 
-00001940: 2d20 286e 5f63 6163 6865 2025 206e 7229  - (n_cache % nr)
-00001950: 3b0a 2020 2020 2020 6569 6765 6e5f 696e  ;.      eigen_in
-00001960: 7465 726e 616c 5f61 7373 6572 7428 6e20  ternal_assert(n 
-00001970: 3e20 3029 3b0a 2020 2020 7d20 656c 7365  > 0);.    } else
-00001980: 207b 0a20 2020 2020 206e 203d 2028 6e75   {.      n = (nu
-00001990: 6d65 7874 3a3a 6d69 6e69 3c49 6e64 6578  mext::mini<Index
-000019a0: 3e29 286e 2c20 286e 5f70 6572 5f74 6872  >)(n, (n_per_thr
-000019b0: 6561 6420 2b20 6e72 202d 2031 2920 2d20  ead + nr - 1) - 
-000019c0: 2828 6e5f 7065 725f 7468 7265 6164 202b  ((n_per_thread +
-000019d0: 206e 7220 2d20 3129 2025 206e 7229 293b   nr - 1) % nr));
-000019e0: 0a20 2020 207d 0a0a 2020 2020 6966 2028  .    }..    if (
-000019f0: 6c33 203e 206c 3229 207b 0a20 2020 2020  l3 > l2) {.     
-00001a00: 202f 2f20 6c33 2069 7320 7368 6172 6564   // l3 is shared
-00001a10: 2062 6574 7765 656e 2061 6c6c 2063 6f72   between all cor
-00001a20: 6573 2c20 736f 2077 6527 6c6c 2067 6976  es, so we'll giv
-00001a30: 6520 6561 6368 2074 6872 6561 6420 6974  e each thread it
-00001a40: 7320 6f77 6e20 6368 756e 6b20 6f66 206c  s own chunk of l
-00001a50: 332e 0a20 2020 2020 2063 6f6e 7374 2049  3..      const I
-00001a60: 6e64 6578 206d 5f63 6163 6865 203d 2028  ndex m_cache = (
-00001a70: 6c33 2d6c 3229 202f 2028 7369 7a65 6f66  l3-l2) / (sizeof
-00001a80: 284c 6873 5363 616c 6172 2920 2a20 6b20  (LhsScalar) * k 
-00001a90: 2a20 6e75 6d5f 7468 7265 6164 7329 3b0a  * num_threads);.
-00001aa0: 2020 2020 2020 636f 6e73 7420 496e 6465        const Inde
-00001ab0: 7820 6d5f 7065 725f 7468 7265 6164 203d  x m_per_thread =
-00001ac0: 206e 756d 6578 743a 3a64 6976 5f63 6569   numext::div_cei
-00001ad0: 6c28 6d2c 206e 756d 5f74 6872 6561 6473  l(m, num_threads
-00001ae0: 293b 0a20 2020 2020 2069 6628 6d5f 6361  );.      if(m_ca
-00001af0: 6368 6520 3c20 6d5f 7065 725f 7468 7265  che < m_per_thre
-00001b00: 6164 2026 2620 6d5f 6361 6368 6520 3e3d  ad && m_cache >=
-00001b10: 2073 7461 7469 635f 6361 7374 3c49 6e64   static_cast<Ind
-00001b20: 6578 3e28 6d72 2929 207b 0a20 2020 2020  ex>(mr)) {.     
-00001b30: 2020 206d 203d 206d 5f63 6163 6865 202d     m = m_cache -
-00001b40: 2028 6d5f 6361 6368 6520 2520 6d72 293b   (m_cache % mr);
-00001b50: 0a20 2020 2020 2020 2065 6967 656e 5f69  .        eigen_i
-00001b60: 6e74 6572 6e61 6c5f 6173 7365 7274 286d  nternal_assert(m
-00001b70: 203e 2030 293b 0a20 2020 2020 207d 2065   > 0);.      } e
-00001b80: 6c73 6520 7b0a 2020 2020 2020 2020 6d20  lse {.        m 
-00001b90: 3d20 286e 756d 6578 743a 3a6d 696e 693c  = (numext::mini<
-00001ba0: 496e 6465 783e 2928 6d2c 2028 6d5f 7065  Index>)(m, (m_pe
-00001bb0: 725f 7468 7265 6164 202b 206d 7220 2d20  r_thread + mr - 
-00001bc0: 3129 202d 2028 286d 5f70 6572 5f74 6872  1) - ((m_per_thr
-00001bd0: 6561 6420 2b20 6d72 202d 2031 2920 2520  ead + mr - 1) % 
-00001be0: 6d72 2929 3b0a 2020 2020 2020 7d0a 2020  mr));.      }.  
-00001bf0: 2020 7d0a 2020 7d0a 2020 656c 7365 207b    }.  }.  else {
-00001c00: 0a20 2020 202f 2f20 496e 2075 6e69 7420  .    // In unit 
-00001c10: 7465 7374 7320 7765 2064 6f20 6e6f 7420  tests we do not 
-00001c20: 7761 6e74 2074 6f20 7573 6520 6578 7472  want to use extr
-00001c30: 6120 6c61 7267 6520 6d61 7472 6963 6573  a large matrices
-00001c40: 2c0a 2020 2020 2f2f 2073 6f20 7765 2072  ,.    // so we r
-00001c50: 6564 7563 6520 7468 6520 6361 6368 6520  educe the cache 
-00001c60: 7369 7a65 2074 6f20 6368 6563 6b20 7468  size to check th
-00001c70: 6520 626c 6f63 6b69 6e67 2073 7472 6174  e blocking strat
-00001c80: 6567 7920 6973 206e 6f74 2066 6c61 7765  egy is not flawe
-00001c90: 640a 2369 6664 6566 2045 4947 454e 5f44  d.#ifdef EIGEN_D
-00001ca0: 4542 5547 5f53 4d41 4c4c 5f50 524f 4455  EBUG_SMALL_PRODU
-00001cb0: 4354 5f42 4c4f 434b 530a 2020 2020 6c31  CT_BLOCKS.    l1
-00001cc0: 203d 2039 2a31 3032 343b 0a20 2020 206c   = 9*1024;.    l
-00001cd0: 3220 3d20 3332 2a31 3032 343b 0a20 2020  2 = 32*1024;.   
-00001ce0: 206c 3320 3d20 3531 322a 3130 3234 3b0a   l3 = 512*1024;.
-00001cf0: 2365 6e64 6966 0a0a 2020 2020 2f2f 2045  #endif..    // E
-00001d00: 6172 6c79 2072 6574 7572 6e20 666f 7220  arly return for 
-00001d10: 736d 616c 6c20 7072 6f62 6c65 6d73 2062  small problems b
-00001d20: 6563 6175 7365 2074 6865 2063 6f6d 7075  ecause the compu
-00001d30: 7461 7469 6f6e 2062 656c 6f77 2061 7265  tation below are
-00001d40: 2074 696d 6520 636f 6e73 756d 696e 6720   time consuming 
-00001d50: 666f 7220 736d 616c 6c20 7072 6f62 6c65  for small proble
-00001d60: 6d73 2e0a 2020 2020 2f2f 2050 6572 6861  ms..    // Perha
-00001d70: 7073 2069 7420 776f 756c 6420 6d61 6b65  ps it would make
-00001d80: 206d 6f72 6520 7365 6e73 6520 746f 2063   more sense to c
-00001d90: 6f6e 7369 6465 7220 6b2a 6e2a 6d3f 3f0a  onsider k*n*m??.
-00001da0: 2020 2020 2f2f 204e 6f74 6520 7468 6174      // Note that
-00001db0: 2066 6f72 2076 6572 7920 7469 6e79 2070   for very tiny p
-00001dc0: 726f 626c 656d 2c20 7468 6973 2066 756e  roblem, this fun
-00001dd0: 6374 696f 6e20 7368 6f75 6c64 2062 6520  ction should be 
-00001de0: 6279 7061 7373 6564 2061 6e79 7761 790a  bypassed anyway.
-00001df0: 2020 2020 2f2f 2062 6563 6175 7365 2077      // because w
-00001e00: 6520 7573 6520 7468 6520 636f 6566 6669  e use the coeffi
-00001e10: 6369 656e 742d 6261 7365 6420 696d 706c  cient-based impl
-00001e20: 656d 656e 7461 7469 6f6e 2066 6f72 2074  ementation for t
-00001e30: 6865 6d2e 0a20 2020 2069 6628 286e 756d  hem..    if((num
-00001e40: 6578 743a 3a6d 6178 6929 286b 2c28 6e75  ext::maxi)(k,(nu
-00001e50: 6d65 7874 3a3a 6d61 7869 2928 6d2c 6e29  mext::maxi)(m,n)
-00001e60: 293c 3438 290a 2020 2020 2020 7265 7475  )<48).      retu
-00001e70: 726e 3b0a 0a20 2020 2074 7970 6564 6566  rn;..    typedef
-00001e80: 2074 7970 656e 616d 6520 5472 6169 7473   typename Traits
-00001e90: 3a3a 5265 7353 6361 6c61 7220 5265 7353  ::ResScalar ResS
-00001ea0: 6361 6c61 723b 0a20 2020 2065 6e75 6d20  calar;.    enum 
-00001eb0: 7b0a 2020 2020 2020 6b5f 7065 656c 696e  {.      k_peelin
-00001ec0: 6720 3d20 382c 0a20 2020 2020 206b 5f64  g = 8,.      k_d
-00001ed0: 6976 203d 204b 6346 6163 746f 7220 2a20  iv = KcFactor * 
-00001ee0: 2854 7261 6974 733a 3a6d 7220 2a20 7369  (Traits::mr * si
-00001ef0: 7a65 6f66 284c 6873 5363 616c 6172 2920  zeof(LhsScalar) 
-00001f00: 2b20 5472 6169 7473 3a3a 6e72 202a 2073  + Traits::nr * s
-00001f10: 697a 656f 6628 5268 7353 6361 6c61 7229  izeof(RhsScalar)
-00001f20: 292c 0a20 2020 2020 206b 5f73 7562 203d  ),.      k_sub =
-00001f30: 2054 7261 6974 733a 3a6d 7220 2a20 5472   Traits::mr * Tr
-00001f40: 6169 7473 3a3a 6e72 202a 2073 697a 656f  aits::nr * sizeo
-00001f50: 6628 5265 7353 6361 6c61 7229 0a20 2020  f(ResScalar).   
-00001f60: 207d 3b0a 0a20 2020 202f 2f20 2d2d 2d2d   };..    // ----
-00001f70: 2031 7374 206c 6576 656c 206f 6620 626c   1st level of bl
-00001f80: 6f63 6b69 6e67 206f 6e20 4c31 2c20 7969  ocking on L1, yi
-00001f90: 656c 6473 206b 6320 2d2d 2d2d 0a0a 2020  elds kc ----..  
-00001fa0: 2020 2f2f 2042 6c6f 636b 696e 6720 6f6e    // Blocking on
-00001fb0: 2074 6865 2074 6869 7264 2064 696d 656e   the third dimen
-00001fc0: 7369 6f6e 2028 692e 652e 2c20 6b29 2069  sion (i.e., k) i
-00001fd0: 7320 6368 6f73 656e 2073 6f20 7468 6174  s chosen so that
-00001fe0: 2061 6e20 686f 7269 7a6f 6e74 616c 2070   an horizontal p
-00001ff0: 616e 656c 0a20 2020 202f 2f20 6f66 2073  anel.    // of s
-00002000: 697a 6520 6d72 2078 206b 6320 6f66 2074  ize mr x kc of t
-00002010: 6865 206c 6873 2070 6c75 7320 6120 7665  he lhs plus a ve
-00002020: 7274 6963 616c 2070 616e 656c 206f 6620  rtical panel of 
-00002030: 6b63 2078 206e 7220 6f66 2074 6865 2072  kc x nr of the r
-00002040: 6873 2062 6f74 6820 6669 7473 2077 6974  hs both fits wit
-00002050: 6869 6e20 4c31 2063 6163 6865 2e0a 2020  hin L1 cache..  
-00002060: 2020 2f2f 2057 6520 616c 736f 2069 6e63    // We also inc
-00002070: 6c75 6465 2061 2072 6567 6973 7465 722d  lude a register-
-00002080: 6c65 7665 6c20 626c 6f63 6b20 6f66 2074  level block of t
-00002090: 6865 2072 6573 756c 7420 286d 7820 7820  he result (mx x 
-000020a0: 6e72 292e 0a20 2020 202f 2f20 2849 6e20  nr)..    // (In 
-000020b0: 616e 2069 6465 616c 2077 6f72 6c64 206f  an ideal world o
-000020c0: 6e6c 7920 7468 6520 6c68 7320 7061 6e65  nly the lhs pane
-000020d0: 6c20 776f 756c 6420 7374 6179 2069 6e20  l would stay in 
-000020e0: 4c31 290a 2020 2020 2f2f 204d 6f72 656f  L1).    // Moreo
-000020f0: 7665 722c 206b 6320 6861 7320 746f 2062  ver, kc has to b
-00002100: 6520 6120 6d75 6c74 6970 6c65 206f 6620  e a multiple of 
-00002110: 3820 746f 2062 6520 636f 6d70 6174 6962  8 to be compatib
-00002120: 6c65 2077 6974 6820 6c6f 6f70 2070 6565  le with loop pee
-00002130: 6c69 6e67 2c20 6c65 6164 696e 6720 746f  ling, leading to
-00002140: 2061 206d 6178 696d 756d 2062 6c6f 636b   a maximum block
-00002150: 696e 6720 7369 7a65 206f 663a 0a20 2020  ing size of:.   
-00002160: 2063 6f6e 7374 2049 6e64 6578 206d 6178   const Index max
-00002170: 5f6b 6320 3d20 6e75 6d65 7874 3a3a 6d61  _kc = numext::ma
-00002180: 7869 3c49 6e64 6578 3e28 2828 6c31 2d6b  xi<Index>(((l1-k
-00002190: 5f73 7562 292f 6b5f 6469 7629 2026 2028  _sub)/k_div) & (
-000021a0: 7e28 6b5f 7065 656c 696e 672d 3129 292c  ~(k_peeling-1)),
-000021b0: 3129 3b0a 2020 2020 636f 6e73 7420 496e  1);.    const In
-000021c0: 6465 7820 6f6c 645f 6b20 3d20 6b3b 0a20  dex old_k = k;. 
-000021d0: 2020 2069 6628 6b3e 6d61 785f 6b63 290a     if(k>max_kc).
-000021e0: 2020 2020 7b0a 2020 2020 2020 2f2f 2057      {.      // W
-000021f0: 6520 6172 6520 7265 616c 6c79 2062 6c6f  e are really blo
-00002200: 636b 696e 6720 6f6e 2074 6865 2074 6869  cking on the thi
-00002210: 7264 2064 696d 656e 7369 6f6e 3a0a 2020  rd dimension:.  
-00002220: 2020 2020 2f2f 202d 3e20 7265 6475 6365      // -> reduce
-00002230: 2062 6c6f 636b 696e 6720 7369 7a65 2074   blocking size t
-00002240: 6f20 6d61 6b65 2073 7572 6520 7468 6520  o make sure the 
-00002250: 6c61 7374 2062 6c6f 636b 2069 7320 6173  last block is as
-00002260: 206c 6172 6765 2061 7320 706f 7373 6962   large as possib
-00002270: 6c65 0a20 2020 2020 202f 2f20 2020 2077  le.      //    w
-00002280: 6869 6c65 206b 6565 7069 6e67 2074 6865  hile keeping the
-00002290: 2073 616d 6520 6e75 6d62 6572 206f 6620   same number of 
-000022a0: 7377 6565 7073 206f 7665 7220 7468 6520  sweeps over the 
-000022b0: 7265 7375 6c74 2e0a 2020 2020 2020 6b20  result..      k 
-000022c0: 3d20 286b 256d 6178 5f6b 6329 3d3d 3020  = (k%max_kc)==0 
-000022d0: 3f20 6d61 785f 6b63 0a20 2020 2020 2020  ? max_kc.       
-000022e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000022f0: 203a 206d 6178 5f6b 6320 2d20 6b5f 7065   : max_kc - k_pe
-00002300: 656c 696e 6720 2a20 2828 6d61 785f 6b63  eling * ((max_kc
-00002310: 2d31 2d28 6b25 6d61 785f 6b63 2929 2f28  -1-(k%max_kc))/(
-00002320: 6b5f 7065 656c 696e 672a 286b 2f6d 6178  k_peeling*(k/max
-00002330: 5f6b 632b 3129 2929 3b0a 0a20 2020 2020  _kc+1)));..     
-00002340: 2065 6967 656e 5f69 6e74 6572 6e61 6c5f   eigen_internal_
-00002350: 6173 7365 7274 2828 286f 6c64 5f6b 2f6b  assert(((old_k/k
-00002360: 2920 3d3d 2028 6f6c 645f 6b2f 6d61 785f  ) == (old_k/max_
-00002370: 6b63 2929 2026 2620 2274 6865 206e 756d  kc)) && "the num
-00002380: 6265 7220 6f66 2073 7765 6570 7320 6861  ber of sweeps ha
-00002390: 7320 746f 2072 656d 6169 6e20 7468 6520  s to remain the 
-000023a0: 7361 6d65 2229 3b0a 2020 2020 7d0a 0a20  same");.    }.. 
-000023b0: 2020 202f 2f20 2d2d 2d2d 2032 6e64 206c     // ---- 2nd l
-000023c0: 6576 656c 206f 6620 626c 6f63 6b69 6e67  evel of blocking
-000023d0: 206f 6e20 6d61 7828 4c32 2c4c 3329 2c20   on max(L2,L3), 
-000023e0: 7969 656c 6473 206e 6320 2d2d 2d2d 0a0a  yields nc ----..
-000023f0: 2020 2020 2f2f 2054 4f44 4f20 6669 6e64      // TODO find
-00002400: 2061 2072 656c 6961 626c 6520 7761 7920   a reliable way 
-00002410: 746f 2067 6574 2074 6865 2061 6374 7561  to get the actua
-00002420: 6c20 616d 6f75 6e74 206f 6620 6361 6368  l amount of cach
-00002430: 6520 7065 7220 636f 7265 2074 6f20 7573  e per core to us
-00002440: 6520 666f 7220 326e 6420 6c65 7665 6c20  e for 2nd level 
-00002450: 626c 6f63 6b69 6e67 2c20 7468 6174 2069  blocking, that i
-00002460: 733a 0a20 2020 202f 2f20 2020 2020 2061  s:.    //      a
-00002470: 6374 7561 6c5f 6c32 203d 206d 6178 286c  ctual_l2 = max(l
-00002480: 322c 206c 332f 6e62 5f63 6f72 655f 7368  2, l3/nb_core_sh
-00002490: 6172 696e 675f 6c33 290a 2020 2020 2f2f  aring_l3).    //
-000024a0: 2054 6865 206e 756d 6265 7220 6265 6c6f   The number belo
-000024b0: 7720 6973 2071 7569 7465 2063 6f6e 7365  w is quite conse
-000024c0: 7276 6174 6976 653a 2069 7420 6973 2062  rvative: it is b
-000024d0: 6574 7465 7220 746f 2075 6e64 6572 6573  etter to underes
-000024e0: 7469 6d61 7465 2074 6865 2063 6163 6865  timate the cache
-000024f0: 2073 697a 6520 7261 7468 6572 2074 6861   size rather tha
-00002500: 6e20 6f76 6572 6573 7469 6d61 7469 6e67  n overestimating
-00002510: 2069 7429 0a20 2020 202f 2f20 466f 7220   it).    // For 
-00002520: 696e 7374 616e 6365 2c20 6974 2063 6f72  instance, it cor
-00002530: 7265 7370 6f6e 6473 2074 6f20 364d 4220  responds to 6MB 
-00002540: 6f66 204c 3320 7368 6172 6564 2061 6d6f  of L3 shared amo
-00002550: 6e67 2034 2063 6f72 6573 2e0a 2020 2020  ng 4 cores..    
-00002560: 2369 6664 6566 2045 4947 454e 5f44 4542  #ifdef EIGEN_DEB
-00002570: 5547 5f53 4d41 4c4c 5f50 524f 4455 4354  UG_SMALL_PRODUCT
-00002580: 5f42 4c4f 434b 530a 2020 2020 636f 6e73  _BLOCKS.    cons
-00002590: 7420 496e 6465 7820 6163 7475 616c 5f6c  t Index actual_l
-000025a0: 3220 3d20 6c33 3b0a 2020 2020 2365 6c73  2 = l3;.    #els
-000025b0: 650a 2020 2020 636f 6e73 7420 496e 6465  e.    const Inde
-000025c0: 7820 6163 7475 616c 5f6c 3220 3d20 3135  x actual_l2 = 15
-000025d0: 3732 3836 343b 202f 2f20 3d3d 2031 2e35  72864; // == 1.5
-000025e0: 204d 420a 2020 2020 2365 6e64 6966 0a0a   MB.    #endif..
-000025f0: 2020 2020 2f2f 2048 6572 652c 206e 6320      // Here, nc 
-00002600: 6973 2063 686f 7365 6e20 7375 6368 2074  is chosen such t
-00002610: 6861 7420 6120 626c 6f63 6b20 6f66 206b  hat a block of k
-00002620: 6320 7820 6e63 206f 6620 7468 6520 7268  c x nc of the rh
-00002630: 7320 6669 7420 7769 7468 696e 2068 616c  s fit within hal
-00002640: 6620 6f66 204c 322e 0a20 2020 202f 2f20  f of L2..    // 
-00002650: 5468 6520 7365 636f 6e64 2068 616c 6620  The second half 
-00002660: 6973 2069 6d70 6c69 6369 746c 7920 7265  is implicitly re
-00002670: 7365 7276 6564 2074 6f20 6163 6365 7373  served to access
-00002680: 2074 6865 2072 6573 756c 7420 616e 6420   the result and 
-00002690: 6c68 7320 636f 6566 6669 6369 656e 7473  lhs coefficients
-000026a0: 2e0a 2020 2020 2f2f 2057 6865 6e20 6b3c  ..    // When k<
-000026b0: 6d61 785f 6b63 2c20 7468 656e 206e 6320  max_kc, then nc 
-000026c0: 6361 6e20 6172 6269 7472 6172 696c 7920  can arbitrarily 
-000026d0: 6772 6f77 7468 2e20 496e 2070 7261 6374  growth. In pract
-000026e0: 6963 652c 2069 7420 7365 656d 7320 746f  ice, it seems to
-000026f0: 2062 6520 6672 7569 7466 756c 0a20 2020   be fruitful.   
-00002700: 202f 2f20 746f 206c 696d 6974 2074 6869   // to limit thi
-00002710: 7320 6772 6f77 7468 3a20 7765 2062 6f75  s growth: we bou
-00002720: 6e64 206e 6320 746f 2067 726f 7774 6820  nd nc to growth 
-00002730: 6279 2061 2066 6163 746f 7220 7831 2e35  by a factor x1.5
-00002740: 2e0a 2020 2020 2f2f 2048 6f77 6576 6572  ..    // However
-00002750: 2c20 6966 2074 6865 2065 6e74 6972 6520  , if the entire 
-00002760: 6c68 7320 626c 6f63 6b20 6669 7420 7769  lhs block fit wi
-00002770: 7468 696e 204c 312c 2074 6865 6e20 7765  thin L1, then we
-00002780: 2061 7265 206e 6f74 2067 6f69 6e67 2074   are not going t
-00002790: 6f20 626c 6f63 6b20 6f6e 2074 6865 2072  o block on the r
-000027a0: 6f77 7320 6174 2061 6c6c 2c0a 2020 2020  ows at all,.    
-000027b0: 2f2f 2061 6e64 2069 7420 6265 636f 6d65  // and it become
-000027c0: 7320 6672 7569 7466 756c 2074 6f20 6b65  s fruitful to ke
-000027d0: 6570 2074 6865 2070 6163 6b65 6420 7268  ep the packed rh
-000027e0: 7320 626c 6f63 6b73 2069 6e20 4c31 2069  s blocks in L1 i
-000027f0: 6620 7468 6572 6520 6973 2065 6e6f 7567  f there is enoug
-00002800: 6820 7265 6d61 696e 696e 6720 7370 6163  h remaining spac
-00002810: 652e 0a20 2020 2049 6e64 6578 206d 6178  e..    Index max
-00002820: 5f6e 633b 0a20 2020 2063 6f6e 7374 2049  _nc;.    const I
-00002830: 6e64 6578 206c 6873 5f62 7974 6573 203d  ndex lhs_bytes =
-00002840: 206d 202a 206b 202a 2073 697a 656f 6628   m * k * sizeof(
-00002850: 4c68 7353 6361 6c61 7229 3b0a 2020 2020  LhsScalar);.    
-00002860: 636f 6e73 7420 496e 6465 7820 7265 6d61  const Index rema
-00002870: 696e 696e 675f 6c31 203d 206c 312d 206b  ining_l1 = l1- k
-00002880: 5f73 7562 202d 206c 6873 5f62 7974 6573  _sub - lhs_bytes
-00002890: 3b0a 2020 2020 6966 2872 656d 6169 6e69  ;.    if(remaini
-000028a0: 6e67 5f6c 3120 3e3d 2049 6e64 6578 2854  ng_l1 >= Index(T
-000028b0: 7261 6974 733a 3a6e 722a 7369 7a65 6f66  raits::nr*sizeof
-000028c0: 2852 6873 5363 616c 6172 2929 2a6b 290a  (RhsScalar))*k).
-000028d0: 2020 2020 7b0a 2020 2020 2020 2f2f 204c      {.      // L
-000028e0: 3120 626c 6f63 6b69 6e67 0a20 2020 2020  1 blocking.     
-000028f0: 206d 6178 5f6e 6320 3d20 7265 6d61 696e   max_nc = remain
-00002900: 696e 675f 6c31 202f 2028 6b2a 7369 7a65  ing_l1 / (k*size
-00002910: 6f66 2852 6873 5363 616c 6172 2929 3b0a  of(RhsScalar));.
-00002920: 2020 2020 7d0a 2020 2020 656c 7365 0a20      }.    else. 
-00002930: 2020 207b 0a20 2020 2020 202f 2f20 4c32     {.      // L2
-00002940: 2062 6c6f 636b 696e 670a 2020 2020 2020   blocking.      
-00002950: 6d61 785f 6e63 203d 2028 332a 6163 7475  max_nc = (3*actu
-00002960: 616c 5f6c 3229 2f28 322a 322a 6d61 785f  al_l2)/(2*2*max_
-00002970: 6b63 2a73 697a 656f 6628 5268 7353 6361  kc*sizeof(RhsSca
-00002980: 6c61 7229 293b 0a20 2020 207d 0a20 2020  lar));.    }.   
-00002990: 202f 2f20 5741 524e 494e 4720 4265 6c6f   // WARNING Belo
-000029a0: 772c 2077 6520 6173 7375 6d65 2074 6861  w, we assume tha
-000029b0: 7420 5472 6169 7473 3a3a 6e72 2069 7320  t Traits::nr is 
-000029c0: 6120 706f 7765 7220 6f66 2074 776f 2e0a  a power of two..
-000029d0: 2020 2020 496e 6465 7820 6e63 203d 206e      Index nc = n
-000029e0: 756d 6578 743a 3a6d 696e 693c 496e 6465  umext::mini<Inde
-000029f0: 783e 2861 6374 7561 6c5f 6c32 2f28 322a  x>(actual_l2/(2*
-00002a00: 6b2a 7369 7a65 6f66 2852 6873 5363 616c  k*sizeof(RhsScal
-00002a10: 6172 2929 2c20 6d61 785f 6e63 2920 2620  ar)), max_nc) & 
-00002a20: 287e 2854 7261 6974 733a 3a6e 722d 3129  (~(Traits::nr-1)
-00002a30: 293b 0a20 2020 2069 6628 6e3e 6e63 290a  );.    if(n>nc).
-00002a40: 2020 2020 7b0a 2020 2020 2020 2f2f 2057      {.      // W
-00002a50: 6520 6172 6520 7265 616c 6c79 2062 6c6f  e are really blo
-00002a60: 636b 696e 6720 6f76 6572 2074 6865 2063  cking over the c
-00002a70: 6f6c 756d 6e73 3a0a 2020 2020 2020 2f2f  olumns:.      //
-00002a80: 202d 3e20 7265 6475 6365 2062 6c6f 636b   -> reduce block
-00002a90: 696e 6720 7369 7a65 2074 6f20 6d61 6b65  ing size to make
-00002aa0: 2073 7572 6520 7468 6520 6c61 7374 2062   sure the last b
-00002ab0: 6c6f 636b 2069 7320 6173 206c 6172 6765  lock is as large
-00002ac0: 2061 7320 706f 7373 6962 6c65 0a20 2020   as possible.   
-00002ad0: 2020 202f 2f20 2020 2077 6869 6c65 206b     //    while k
-00002ae0: 6565 7069 6e67 2074 6865 2073 616d 6520  eeping the same 
-00002af0: 6e75 6d62 6572 206f 6620 7377 6565 7073  number of sweeps
-00002b00: 206f 7665 7220 7468 6520 7061 636b 6564   over the packed
-00002b10: 206c 6873 2e0a 2020 2020 2020 2f2f 2020   lhs..      //  
-00002b20: 2020 4865 7265 2077 6520 616c 6c6f 7720    Here we allow 
-00002b30: 6f6e 6520 6d6f 7265 2073 7765 6570 2069  one more sweep i
-00002b40: 6620 7468 6973 2067 6976 6573 2075 7320  f this gives us 
-00002b50: 6120 7065 7266 6563 7420 6d61 7463 682c  a perfect match,
-00002b60: 2074 6875 7320 7468 6520 636f 6d6d 656e   thus the commen
-00002b70: 7465 6420 222d 3122 0a20 2020 2020 206e  ted "-1".      n
-00002b80: 203d 2028 6e25 6e63 293d 3d30 203f 206e   = (n%nc)==0 ? n
-00002b90: 630a 2020 2020 2020 2020 2020 2020 2020  c.              
-00002ba0: 2020 2020 2020 3a20 286e 6320 2d20 5472        : (nc - Tr
-00002bb0: 6169 7473 3a3a 6e72 202a 2028 286e 632f  aits::nr * ((nc/
-00002bc0: 2a2d 312a 2f2d 286e 256e 6329 292f 2854  *-1*/-(n%nc))/(T
-00002bd0: 7261 6974 733a 3a6e 722a 286e 2f6e 632b  raits::nr*(n/nc+
-00002be0: 3129 2929 293b 0a20 2020 207d 0a20 2020  1))));.    }.   
-00002bf0: 2065 6c73 6520 6966 286f 6c64 5f6b 3d3d   else if(old_k==
-00002c00: 6b29 0a20 2020 207b 0a20 2020 2020 202f  k).    {.      /
-00002c10: 2f20 536f 2066 6172 2c20 6e6f 2062 6c6f  / So far, no blo
-00002c20: 636b 696e 6720 6174 2061 6c6c 2c20 692e  cking at all, i.
-00002c30: 652e 2c20 6b63 3d3d 6b2c 2061 6e64 206e  e., kc==k, and n
-00002c40: 633d 3d6e 2e0a 2020 2020 2020 2f2f 2049  c==n..      // I
-00002c50: 6e20 7468 6973 2063 6173 652c 206c 6574  n this case, let
-00002c60: 2773 2070 6572 666f 726d 2061 2062 6c6f  's perform a blo
-00002c70: 636b 696e 6720 6f76 6572 2074 6865 2072  cking over the r
-00002c80: 6f77 7320 7375 6368 2074 6861 7420 7468  ows such that th
-00002c90: 6520 7061 636b 6564 206c 6873 2064 6174  e packed lhs dat
-00002ca0: 6120 6973 206b 6570 7420 696e 2063 6163  a is kept in cac
-00002cb0: 6865 204c 312f 4c32 0a20 2020 2020 202f  he L1/L2.      /
-00002cc0: 2f20 544f 444f 3a20 7061 7274 206f 6620  / TODO: part of 
-00002cd0: 7468 6973 2062 6c6f 636b 696e 6720 7374  this blocking st
-00002ce0: 7261 7465 6779 2069 7320 6e6f 7720 696d  rategy is now im
-00002cf0: 706c 656d 656e 7465 6420 7769 7468 696e  plemented within
-00002d00: 2074 6865 206b 6572 6e65 6c20 6974 7365   the kernel itse
-00002d10: 6c66 2c20 736f 2074 6865 204c 312d 6261  lf, so the L1-ba
-00002d20: 7365 6420 6865 7572 6973 7469 6320 6865  sed heuristic he
-00002d30: 7265 2073 686f 756c 6420 6265 206f 6273  re should be obs
-00002d40: 6f6c 6574 652e 0a20 2020 2020 2049 6e64  olete..      Ind
-00002d50: 6578 2070 726f 626c 656d 5f73 697a 6520  ex problem_size 
-00002d60: 3d20 6b2a 6e2a 7369 7a65 6f66 284c 6873  = k*n*sizeof(Lhs
-00002d70: 5363 616c 6172 293b 0a20 2020 2020 2049  Scalar);.      I
-00002d80: 6e64 6578 2061 6374 7561 6c5f 6c6d 203d  ndex actual_lm =
-00002d90: 2061 6374 7561 6c5f 6c32 3b0a 2020 2020   actual_l2;.    
-00002da0: 2020 496e 6465 7820 6d61 785f 6d63 203d    Index max_mc =
-00002db0: 206d 3b0a 2020 2020 2020 6966 2870 726f   m;.      if(pro
-00002dc0: 626c 656d 5f73 697a 653c 3d31 3032 3429  blem_size<=1024)
-00002dd0: 0a20 2020 2020 207b 0a20 2020 2020 2020  .      {.       
-00002de0: 202f 2f20 7072 6f62 6c65 6d20 6973 2073   // problem is s
-00002df0: 6d61 6c6c 2065 6e6f 7567 6820 746f 206b  mall enough to k
-00002e00: 6565 7020 696e 204c 310a 2020 2020 2020  eep in L1.      
-00002e10: 2020 2f2f 204c 6574 2773 2063 686f 6f73    // Let's choos
-00002e20: 6520 6d20 7375 6368 2074 6861 7420 6c68  e m such that lh
-00002e30: 7327 7320 626c 6f63 6b20 6669 7420 696e  s's block fit in
-00002e40: 2031 2f33 206f 6620 4c31 0a20 2020 2020   1/3 of L1.     
-00002e50: 2020 2061 6374 7561 6c5f 6c6d 203d 206c     actual_lm = l
-00002e60: 313b 0a20 2020 2020 207d 0a20 2020 2020  1;.      }.     
-00002e70: 2065 6c73 6520 6966 286c 3321 3d30 2026   else if(l3!=0 &
-00002e80: 2620 7072 6f62 6c65 6d5f 7369 7a65 3c3d  & problem_size<=
-00002e90: 3332 3736 3829 0a20 2020 2020 207b 0a20  32768).      {. 
-00002ea0: 2020 2020 2020 202f 2f20 7765 2068 6176         // we hav
-00002eb0: 6520 626f 7468 204c 3220 616e 6420 4c33  e both L2 and L3
-00002ec0: 2c20 616e 6420 7072 6f62 6c65 6d20 6973  , and problem is
-00002ed0: 2073 6d61 6c6c 2065 6e6f 7567 6820 746f   small enough to
-00002ee0: 2062 6520 6b65 7074 2069 6e20 4c32 0a20   be kept in L2. 
-00002ef0: 2020 2020 2020 202f 2f20 4c65 7427 7320         // Let's 
-00002f00: 6368 6f6f 7365 206d 2073 7563 6820 7468  choose m such th
-00002f10: 6174 206c 6873 2773 2062 6c6f 636b 2066  at lhs's block f
-00002f20: 6974 2069 6e20 312f 3320 6f66 204c 320a  it in 1/3 of L2.
-00002f30: 2020 2020 2020 2020 6163 7475 616c 5f6c          actual_l
-00002f40: 6d20 3d20 6c32 3b0a 2020 2020 2020 2020  m = l2;.        
-00002f50: 6d61 785f 6d63 203d 2028 6e75 6d65 7874  max_mc = (numext
-00002f60: 3a3a 6d69 6e69 3c49 6e64 6578 3e29 2835  ::mini<Index>)(5
-00002f70: 3736 2c6d 6178 5f6d 6329 3b0a 2020 2020  76,max_mc);.    
-00002f80: 2020 7d0a 2020 2020 2020 496e 6465 7820    }.      Index 
-00002f90: 6d63 203d 2028 6e75 6d65 7874 3a3a 6d69  mc = (numext::mi
-00002fa0: 6e69 3c49 6e64 6578 3e29 2861 6374 7561  ni<Index>)(actua
-00002fb0: 6c5f 6c6d 2f28 332a 6b2a 7369 7a65 6f66  l_lm/(3*k*sizeof
-00002fc0: 284c 6873 5363 616c 6172 2929 2c20 6d61  (LhsScalar)), ma
-00002fd0: 785f 6d63 293b 0a20 2020 2020 2069 6620  x_mc);.      if 
-00002fe0: 286d 6320 3e20 5472 6169 7473 3a3a 6d72  (mc > Traits::mr
-00002ff0: 2920 6d63 202d 3d20 6d63 2025 2054 7261  ) mc -= mc % Tra
-00003000: 6974 733a 3a6d 723b 0a20 2020 2020 2065  its::mr;.      e
-00003010: 6c73 6520 6966 2028 6d63 3d3d 3029 2072  lse if (mc==0) r
-00003020: 6574 7572 6e3b 0a20 2020 2020 206d 203d  eturn;.      m =
-00003030: 2028 6d25 6d63 293d 3d30 203f 206d 630a   (m%mc)==0 ? mc.
-00003040: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003050: 2020 2020 3a20 286d 6320 2d20 5472 6169      : (mc - Trai
-00003060: 7473 3a3a 6d72 202a 2028 286d 632f 2a2d  ts::mr * ((mc/*-
-00003070: 312a 2f2d 286d 256d 6329 292f 2854 7261  1*/-(m%mc))/(Tra
-00003080: 6974 733a 3a6d 722a 286d 2f6d 632b 3129  its::mr*(m/mc+1)
-00003090: 2929 293b 0a20 2020 207d 0a20 207d 0a7d  )));.    }.  }.}
-000030a0: 0a0a 7465 6d70 6c61 7465 203c 7479 7065  ..template <type
-000030b0: 6e61 6d65 2049 6e64 6578 3e0a 696e 6c69  name Index>.inli
-000030c0: 6e65 2062 6f6f 6c20 7573 6553 7065 6369  ne bool useSpeci
-000030d0: 6669 6342 6c6f 636b 696e 6753 697a 6573  ficBlockingSizes
-000030e0: 2849 6e64 6578 2620 6b2c 2049 6e64 6578  (Index& k, Index
-000030f0: 2620 6d2c 2049 6e64 6578 2620 6e29 0a7b  & m, Index& n).{
-00003100: 0a23 6966 6465 6620 4549 4745 4e5f 5445  .#ifdef EIGEN_TE
-00003110: 5354 5f53 5045 4349 4649 435f 424c 4f43  ST_SPECIFIC_BLOC
-00003120: 4b49 4e47 5f53 495a 4553 0a20 2069 6620  KING_SIZES.  if 
-00003130: 2845 4947 454e 5f54 4553 545f 5350 4543  (EIGEN_TEST_SPEC
-00003140: 4946 4943 5f42 4c4f 434b 494e 475f 5349  IFIC_BLOCKING_SI
-00003150: 5a45 5329 207b 0a20 2020 206b 203d 206e  ZES) {.    k = n
-00003160: 756d 6578 743a 3a6d 696e 693c 496e 6465  umext::mini<Inde
-00003170: 783e 286b 2c20 4549 4745 4e5f 5445 5354  x>(k, EIGEN_TEST
-00003180: 5f53 5045 4349 4649 435f 424c 4f43 4b49  _SPECIFIC_BLOCKI
-00003190: 4e47 5f53 495a 455f 4b29 3b0a 2020 2020  NG_SIZE_K);.    
-000031a0: 6d20 3d20 6e75 6d65 7874 3a3a 6d69 6e69  m = numext::mini
-000031b0: 3c49 6e64 6578 3e28 6d2c 2045 4947 454e  <Index>(m, EIGEN
-000031c0: 5f54 4553 545f 5350 4543 4946 4943 5f42  _TEST_SPECIFIC_B
-000031d0: 4c4f 434b 494e 475f 5349 5a45 5f4d 293b  LOCKING_SIZE_M);
-000031e0: 0a20 2020 206e 203d 206e 756d 6578 743a  .    n = numext:
-000031f0: 3a6d 696e 693c 496e 6465 783e 286e 2c20  :mini<Index>(n, 
-00003200: 4549 4745 4e5f 5445 5354 5f53 5045 4349  EIGEN_TEST_SPECI
-00003210: 4649 435f 424c 4f43 4b49 4e47 5f53 495a  FIC_BLOCKING_SIZ
-00003220: 455f 4e29 3b0a 2020 2020 7265 7475 726e  E_N);.    return
-00003230: 2074 7275 653b 0a20 207d 0a23 656c 7365   true;.  }.#else
-00003240: 0a20 2045 4947 454e 5f55 4e55 5345 445f  .  EIGEN_UNUSED_
-00003250: 5641 5249 4142 4c45 286b 290a 2020 4549  VARIABLE(k).  EI
-00003260: 4745 4e5f 554e 5553 4544 5f56 4152 4941  GEN_UNUSED_VARIA
-00003270: 424c 4528 6d29 0a20 2045 4947 454e 5f55  BLE(m).  EIGEN_U
-00003280: 4e55 5345 445f 5641 5249 4142 4c45 286e  NUSED_VARIABLE(n
-00003290: 290a 2365 6e64 6966 0a20 2072 6574 7572  ).#endif.  retur
-000032a0: 6e20 6661 6c73 653b 0a7d 0a0a 2f2a 2a20  n false;.}../** 
-000032b0: 5c62 7269 6566 2043 6f6d 7075 7465 7320  \brief Computes 
-000032c0: 7468 6520 626c 6f63 6b69 6e67 2070 6172  the blocking par
-000032d0: 616d 6574 6572 7320 666f 7220 6120 6d20  ameters for a m 
-000032e0: 7820 6b20 7469 6d65 7320 6b20 7820 6e20  x k times k x n 
-000032f0: 6d61 7472 6978 2070 726f 6475 6374 0a20  matrix product. 
-00003300: 202a 0a20 202a 205c 7061 7261 6d5b 696e   *.  * \param[in
-00003310: 2c6f 7574 5d20 6b20 496e 7075 743a 2074  ,out] k Input: t
-00003320: 6865 2074 6869 7264 2064 696d 656e 7369  he third dimensi
-00003330: 6f6e 206f 6620 7468 6520 7072 6f64 7563  on of the produc
-00003340: 742e 204f 7574 7075 743a 2074 6865 2062  t. Output: the b
-00003350: 6c6f 636b 696e 6720 7369 7a65 2061 6c6f  locking size alo
-00003360: 6e67 2074 6865 2073 616d 6520 6469 6d65  ng the same dime
-00003370: 6e73 696f 6e2e 0a20 202a 205c 7061 7261  nsion..  * \para
-00003380: 6d5b 696e 2c6f 7574 5d20 6d20 496e 7075  m[in,out] m Inpu
-00003390: 743a 2074 6865 206e 756d 6265 7220 6f66  t: the number of
-000033a0: 2072 6f77 7320 6f66 2074 6865 206c 6566   rows of the lef
-000033b0: 7420 6861 6e64 2073 6964 652e 204f 7574  t hand side. Out
-000033c0: 7075 743a 2074 6865 2062 6c6f 636b 696e  put: the blockin
-000033d0: 6720 7369 7a65 2061 6c6f 6e67 2074 6865  g size along the
-000033e0: 2073 616d 6520 6469 6d65 6e73 696f 6e2e   same dimension.
-000033f0: 0a20 202a 205c 7061 7261 6d5b 696e 2c6f  .  * \param[in,o
-00003400: 7574 5d20 6e20 496e 7075 743a 2074 6865  ut] n Input: the
-00003410: 206e 756d 6265 7220 6f66 2063 6f6c 756d   number of colum
-00003420: 6e73 206f 6620 7468 6520 7269 6768 7420  ns of the right 
-00003430: 6861 6e64 2073 6964 652e 204f 7574 7075  hand side. Outpu
-00003440: 743a 2074 6865 2062 6c6f 636b 696e 6720  t: the blocking 
-00003450: 7369 7a65 2061 6c6f 6e67 2074 6865 2073  size along the s
-00003460: 616d 6520 6469 6d65 6e73 696f 6e2e 0a20  ame dimension.. 
-00003470: 202a 0a20 202a 2047 6976 656e 2061 206d   *.  * Given a m
-00003480: 2078 206b 2074 696d 6573 206b 2078 206e   x k times k x n
-00003490: 206d 6174 7269 7820 7072 6f64 7563 7420   matrix product 
-000034a0: 6f66 2073 6361 6c61 7220 7479 7065 7320  of scalar types 
-000034b0: 5c63 204c 6873 5363 616c 6172 2061 6e64  \c LhsScalar and
-000034c0: 205c 6320 5268 7353 6361 6c61 722c 0a20   \c RhsScalar,. 
-000034d0: 202a 2074 6869 7320 6675 6e63 7469 6f6e   * this function
-000034e0: 2063 6f6d 7075 7465 7320 7468 6520 626c   computes the bl
-000034f0: 6f63 6b69 6e67 2073 697a 6520 7061 7261  ocking size para
-00003500: 6d65 7465 7273 2061 6c6f 6e67 2074 6865  meters along the
-00003510: 2072 6573 7065 6374 6976 6520 6469 6d65   respective dime
-00003520: 6e73 696f 6e73 0a20 202a 2066 6f72 206d  nsions.  * for m
-00003530: 6174 7269 7820 7072 6f64 7563 7473 2061  atrix products a
-00003540: 6e64 2072 656c 6174 6564 2061 6c67 6f72  nd related algor
-00003550: 6974 686d 732e 0a20 202a 0a20 202a 2054  ithms..  *.  * T
-00003560: 6865 2062 6c6f 636b 696e 6720 7369 7a65  he blocking size
-00003570: 2070 6172 616d 6574 6572 7320 6d61 7920   parameters may 
-00003580: 6265 2065 7661 6c75 6174 6564 3a0a 2020  be evaluated:.  
-00003590: 2a20 2020 2d20 6569 7468 6572 2062 7920  *   - either by 
-000035a0: 6120 6865 7572 6973 7469 6320 6261 7365  a heuristic base
-000035b0: 6420 6f6e 2063 6163 6865 2073 697a 6573  d on cache sizes
-000035c0: 3b0a 2020 2a20 2020 2d20 6f72 2075 7369  ;.  *   - or usi
-000035d0: 6e67 2066 6978 6564 2070 7265 7363 7269  ng fixed prescri
-000035e0: 6265 6420 7661 6c75 6573 2028 666f 7220  bed values (for 
-000035f0: 7465 7374 696e 6720 7075 7270 6f73 6573  testing purposes
-00003600: 292e 0a20 202a 0a20 202a 205c 7361 2073  )..  *.  * \sa s
-00003610: 6574 4370 7543 6163 6865 5369 7a65 7320  etCpuCacheSizes 
-00003620: 2a2f 0a0a 7465 6d70 6c61 7465 3c74 7970  */..template<typ
-00003630: 656e 616d 6520 4c68 7353 6361 6c61 722c  ename LhsScalar,
-00003640: 2074 7970 656e 616d 6520 5268 7353 6361   typename RhsSca
-00003650: 6c61 722c 2069 6e74 204b 6346 6163 746f  lar, int KcFacto
-00003660: 722c 2074 7970 656e 616d 6520 496e 6465  r, typename Inde
-00003670: 783e 0a76 6f69 6420 636f 6d70 7574 6550  x>.void computeP
-00003680: 726f 6475 6374 426c 6f63 6b69 6e67 5369  roductBlockingSi
-00003690: 7a65 7328 496e 6465 7826 206b 2c20 496e  zes(Index& k, In
-000036a0: 6465 7826 206d 2c20 496e 6465 7826 206e  dex& m, Index& n
-000036b0: 2c20 496e 6465 7820 6e75 6d5f 7468 7265  , Index num_thre
-000036c0: 6164 7320 3d20 3129 0a7b 0a20 2069 6620  ads = 1).{.  if 
-000036d0: 2821 7573 6553 7065 6369 6669 6342 6c6f  (!useSpecificBlo
-000036e0: 636b 696e 6753 697a 6573 286b 2c20 6d2c  ckingSizes(k, m,
-000036f0: 206e 2929 207b 0a20 2020 2065 7661 6c75   n)) {.    evalu
-00003700: 6174 6550 726f 6475 6374 426c 6f63 6b69  ateProductBlocki
-00003710: 6e67 5369 7a65 7348 6575 7269 7374 6963  ngSizesHeuristic
-00003720: 3c4c 6873 5363 616c 6172 2c20 5268 7353  <LhsScalar, RhsS
-00003730: 6361 6c61 722c 204b 6346 6163 746f 722c  calar, KcFactor,
-00003740: 2049 6e64 6578 3e28 6b2c 206d 2c20 6e2c   Index>(k, m, n,
-00003750: 206e 756d 5f74 6872 6561 6473 293b 0a20   num_threads);. 
-00003760: 207d 0a7d 0a0a 7465 6d70 6c61 7465 3c74   }.}..template<t
-00003770: 7970 656e 616d 6520 4c68 7353 6361 6c61  ypename LhsScala
-00003780: 722c 2074 7970 656e 616d 6520 5268 7353  r, typename RhsS
-00003790: 6361 6c61 722c 2074 7970 656e 616d 6520  calar, typename 
-000037a0: 496e 6465 783e 0a69 6e6c 696e 6520 766f  Index>.inline vo
-000037b0: 6964 2063 6f6d 7075 7465 5072 6f64 7563  id computeProduc
-000037c0: 7442 6c6f 636b 696e 6753 697a 6573 2849  tBlockingSizes(I
-000037d0: 6e64 6578 2620 6b2c 2049 6e64 6578 2620  ndex& k, Index& 
-000037e0: 6d2c 2049 6e64 6578 2620 6e2c 2049 6e64  m, Index& n, Ind
-000037f0: 6578 206e 756d 5f74 6872 6561 6473 203d  ex num_threads =
-00003800: 2031 290a 7b0a 2020 636f 6d70 7574 6550   1).{.  computeP
-00003810: 726f 6475 6374 426c 6f63 6b69 6e67 5369  roductBlockingSi
-00003820: 7a65 733c 4c68 7353 6361 6c61 722c 5268  zes<LhsScalar,Rh
-00003830: 7353 6361 6c61 722c 312c 496e 6465 783e  sScalar,1,Index>
-00003840: 286b 2c20 6d2c 206e 2c20 6e75 6d5f 7468  (k, m, n, num_th
-00003850: 7265 6164 7329 3b0a 7d0a 0a23 6966 6465  reads);.}..#ifde
-00003860: 6620 4549 4745 4e5f 4841 535f 5349 4e47  f EIGEN_HAS_SING
-00003870: 4c45 5f49 4e53 5452 5543 5449 4f4e 5f43  LE_INSTRUCTION_C
-00003880: 4a4d 4144 440a 2020 2364 6566 696e 6520  JMADD.  #define 
-00003890: 434a 4d41 4444 2843 4a2c 412c 422c 432c  CJMADD(CJ,A,B,C,
-000038a0: 5429 2020 4320 3d20 434a 2e70 6d61 6464  T)  C = CJ.pmadd
-000038b0: 2841 2c42 2c43 293b 0a23 656c 7365 0a0a  (A,B,C);.#else..
-000038c0: 2020 2f2f 2046 4958 4d45 2028 6120 6269    // FIXME (a bi
-000038d0: 7420 6f76 6572 6b69 6c6c 206d 6179 6265  t overkill maybe
-000038e0: 203f 290a 0a20 2074 656d 706c 6174 653c   ?)..  template<
-000038f0: 7479 7065 6e61 6d65 2043 4a2c 2074 7970  typename CJ, typ
-00003900: 656e 616d 6520 412c 2074 7970 656e 616d  ename A, typenam
-00003910: 6520 422c 2074 7970 656e 616d 6520 432c  e B, typename C,
-00003920: 2074 7970 656e 616d 6520 543e 2073 7472   typename T> str
-00003930: 7563 7420 6765 6270 5f6d 6164 645f 7365  uct gebp_madd_se
-00003940: 6c65 6374 6f72 207b 0a20 2020 2045 4947  lector {.    EIG
-00003950: 454e 5f41 4c57 4159 535f 494e 4c49 4e45  EN_ALWAYS_INLINE
-00003960: 2073 7461 7469 6320 766f 6964 2072 756e   static void run
-00003970: 2863 6f6e 7374 2043 4a26 2063 6a2c 2041  (const CJ& cj, A
-00003980: 2620 612c 2042 2620 622c 2043 2620 632c  & a, B& b, C& c,
-00003990: 2054 2620 2f2a 742a 2f29 0a20 2020 207b   T& /*t*/).    {
-000039a0: 0a20 2020 2020 2063 203d 2063 6a2e 706d  .      c = cj.pm
-000039b0: 6164 6428 612c 622c 6329 3b0a 2020 2020  add(a,b,c);.    
-000039c0: 7d0a 2020 7d3b 0a0a 2020 7465 6d70 6c61  }.  };..  templa
-000039d0: 7465 3c74 7970 656e 616d 6520 434a 2c20  te<typename CJ, 
-000039e0: 7479 7065 6e61 6d65 2054 3e20 7374 7275  typename T> stru
-000039f0: 6374 2067 6562 705f 6d61 6464 5f73 656c  ct gebp_madd_sel
-00003a00: 6563 746f 723c 434a 2c54 2c54 2c54 2c54  ector<CJ,T,T,T,T
-00003a10: 3e20 7b0a 2020 2020 4549 4745 4e5f 414c  > {.    EIGEN_AL
-00003a20: 5741 5953 5f49 4e4c 494e 4520 7374 6174  WAYS_INLINE stat
-00003a30: 6963 2076 6f69 6420 7275 6e28 636f 6e73  ic void run(cons
-00003a40: 7420 434a 2620 636a 2c20 5426 2061 2c20  t CJ& cj, T& a, 
-00003a50: 5426 2062 2c20 5426 2063 2c20 5426 2074  T& b, T& c, T& t
-00003a60: 290a 2020 2020 7b0a 2020 2020 2020 7420  ).    {.      t 
-00003a70: 3d20 623b 2074 203d 2063 6a2e 706d 756c  = b; t = cj.pmul
-00003a80: 2861 2c74 293b 2063 203d 2070 6164 6428  (a,t); c = padd(
-00003a90: 632c 7429 3b0a 2020 2020 7d0a 2020 7d3b  c,t);.    }.  };
-00003aa0: 0a0a 2020 7465 6d70 6c61 7465 3c74 7970  ..  template<typ
-00003ab0: 656e 616d 6520 434a 2c20 7479 7065 6e61  ename CJ, typena
-00003ac0: 6d65 2041 2c20 7479 7065 6e61 6d65 2042  me A, typename B
-00003ad0: 2c20 7479 7065 6e61 6d65 2043 2c20 7479  , typename C, ty
-00003ae0: 7065 6e61 6d65 2054 3e0a 2020 4549 4745  pename T>.  EIGE
-00003af0: 4e5f 5354 524f 4e47 5f49 4e4c 494e 4520  N_STRONG_INLINE 
-00003b00: 766f 6964 2067 6562 705f 6d61 6464 2863  void gebp_madd(c
-00003b10: 6f6e 7374 2043 4a26 2063 6a2c 2041 2620  onst CJ& cj, A& 
-00003b20: 612c 2042 2620 622c 2043 2620 632c 2054  a, B& b, C& c, T
-00003b30: 2620 7429 0a20 207b 0a20 2020 2067 6562  & t).  {.    geb
-00003b40: 705f 6d61 6464 5f73 656c 6563 746f 723c  p_madd_selector<
-00003b50: 434a 2c41 2c42 2c43 2c54 3e3a 3a72 756e  CJ,A,B,C,T>::run
-00003b60: 2863 6a2c 612c 622c 632c 7429 3b0a 2020  (cj,a,b,c,t);.  
-00003b70: 7d0a 0a20 2023 6465 6669 6e65 2043 4a4d  }..  #define CJM
-00003b80: 4144 4428 434a 2c41 2c42 2c43 2c54 2920  ADD(CJ,A,B,C,T) 
-00003b90: 2067 6562 705f 6d61 6464 2843 4a2c 412c   gebp_madd(CJ,A,
-00003ba0: 422c 432c 5429 3b0a 2f2f 2020 2023 6465  B,C,T);.//   #de
-00003bb0: 6669 6e65 2043 4a4d 4144 4428 434a 2c41  fine CJMADD(CJ,A
-00003bc0: 2c42 2c43 2c54 2920 2054 203d 2042 3b20  ,B,C,T)  T = B; 
-00003bd0: 5420 3d20 434a 2e70 6d75 6c28 412c 5429  T = CJ.pmul(A,T)
-00003be0: 3b20 4320 3d20 7061 6464 2843 2c54 293b  ; C = padd(C,T);
-00003bf0: 0a23 656e 6469 660a 0a74 656d 706c 6174  .#endif..templat
-00003c00: 6520 3c74 7970 656e 616d 6520 5268 7350  e <typename RhsP
-00003c10: 6163 6b65 742c 2074 7970 656e 616d 6520  acket, typename 
-00003c20: 5268 7350 6163 6b65 7478 342c 2069 6e74  RhsPacketx4, int
-00003c30: 2072 6567 6973 7465 7273 5f74 616b 656e   registers_taken
-00003c40: 3e0a 7374 7275 6374 2052 6873 5061 6e65  >.struct RhsPane
-00003c50: 6c48 656c 7065 7220 7b0a 2070 7269 7661  lHelper {. priva
-00003c60: 7465 3a0a 2020 7374 6174 6963 2063 6f6e  te:.  static con
-00003c70: 7374 2069 6e74 2072 656d 6169 6e69 6e67  st int remaining
-00003c80: 5f72 6567 6973 7465 7273 203d 2045 4947  _registers = EIG
-00003c90: 454e 5f41 5243 485f 4445 4641 554c 545f  EN_ARCH_DEFAULT_
-00003ca0: 4e55 4d42 4552 5f4f 465f 5245 4749 5354  NUMBER_OF_REGIST
-00003cb0: 4552 5320 2d20 7265 6769 7374 6572 735f  ERS - registers_
-00003cc0: 7461 6b65 6e3b 0a20 7075 626c 6963 3a0a  taken;. public:.
-00003cd0: 2020 7479 7065 6465 6620 7479 7065 6e61    typedef typena
-00003ce0: 6d65 2063 6f6e 6469 7469 6f6e 616c 3c72  me conditional<r
-00003cf0: 656d 6169 6e69 6e67 5f72 6567 6973 7465  emaining_registe
-00003d00: 7273 3e3d 342c 2052 6873 5061 636b 6574  rs>=4, RhsPacket
-00003d10: 7834 2c20 5268 7350 6163 6b65 743e 3a3a  x4, RhsPacket>::
-00003d20: 7479 7065 2074 7970 653b 0a7d 3b0a 0a74  type type;.};..t
-00003d30: 656d 706c 6174 6520 3c74 7970 656e 616d  emplate <typenam
-00003d40: 6520 5061 636b 6574 3e0a 7374 7275 6374  e Packet>.struct
-00003d50: 2051 7561 6450 6163 6b65 740a 7b0a 2020   QuadPacket.{.  
-00003d60: 5061 636b 6574 2042 5f30 2c20 4231 2c20  Packet B_0, B1, 
-00003d70: 4232 2c20 4233 3b0a 2020 636f 6e73 7420  B2, B3;.  const 
-00003d80: 5061 636b 6574 2620 6765 7428 636f 6e73  Packet& get(cons
-00003d90: 7420 4669 7865 6449 6e74 3c30 3e26 2920  t FixedInt<0>&) 
-00003da0: 636f 6e73 7420 7b20 7265 7475 726e 2042  const { return B
-00003db0: 5f30 3b20 7d0a 2020 636f 6e73 7420 5061  _0; }.  const Pa
-00003dc0: 636b 6574 2620 6765 7428 636f 6e73 7420  cket& get(const 
-00003dd0: 4669 7865 6449 6e74 3c31 3e26 2920 636f  FixedInt<1>&) co
-00003de0: 6e73 7420 7b20 7265 7475 726e 2042 313b  nst { return B1;
-00003df0: 207d 0a20 2063 6f6e 7374 2050 6163 6b65   }.  const Packe
-00003e00: 7426 2067 6574 2863 6f6e 7374 2046 6978  t& get(const Fix
-00003e10: 6564 496e 743c 323e 2629 2063 6f6e 7374  edInt<2>&) const
-00003e20: 207b 2072 6574 7572 6e20 4232 3b20 7d0a   { return B2; }.
-00003e30: 2020 636f 6e73 7420 5061 636b 6574 2620    const Packet& 
-00003e40: 6765 7428 636f 6e73 7420 4669 7865 6449  get(const FixedI
-00003e50: 6e74 3c33 3e26 2920 636f 6e73 7420 7b20  nt<3>&) const { 
-00003e60: 7265 7475 726e 2042 333b 207d 0a7d 3b0a  return B3; }.};.
-00003e70: 0a74 656d 706c 6174 6520 3c69 6e74 204e  .template <int N
-00003e80: 2c20 7479 7065 6e61 6d65 2054 312c 2074  , typename T1, t
-00003e90: 7970 656e 616d 6520 5432 2c20 7479 7065  ypename T2, type
-00003ea0: 6e61 6d65 2054 333e 0a73 7472 7563 7420  name T3>.struct 
-00003eb0: 7061 636b 6574 5f63 6f6e 6469 7469 6f6e  packet_condition
-00003ec0: 616c 207b 2074 7970 6564 6566 2054 3320  al { typedef T3 
-00003ed0: 7479 7065 3b20 7d3b 0a0a 7465 6d70 6c61  type; };..templa
-00003ee0: 7465 203c 7479 7065 6e61 6d65 2054 312c  te <typename T1,
-00003ef0: 2074 7970 656e 616d 6520 5432 2c20 7479   typename T2, ty
-00003f00: 7065 6e61 6d65 2054 333e 0a73 7472 7563  pename T3>.struc
-00003f10: 7420 7061 636b 6574 5f63 6f6e 6469 7469  t packet_conditi
-00003f20: 6f6e 616c 3c47 4542 5050 6163 6b65 7446  onal<GEBPPacketF
-00003f30: 756c 6c2c 2054 312c 2054 322c 2054 333e  ull, T1, T2, T3>
-00003f40: 207b 2074 7970 6564 6566 2054 3120 7479   { typedef T1 ty
-00003f50: 7065 3b20 7d3b 0a0a 7465 6d70 6c61 7465  pe; };..template
-00003f60: 203c 7479 7065 6e61 6d65 2054 312c 2074   <typename T1, t
-00003f70: 7970 656e 616d 6520 5432 2c20 7479 7065  ypename T2, type
-00003f80: 6e61 6d65 2054 333e 0a73 7472 7563 7420  name T3>.struct 
-00003f90: 7061 636b 6574 5f63 6f6e 6469 7469 6f6e  packet_condition
-00003fa0: 616c 3c47 4542 5050 6163 6b65 7448 616c  al<GEBPPacketHal
-00003fb0: 662c 2054 312c 2054 322c 2054 333e 207b  f, T1, T2, T3> {
-00003fc0: 2074 7970 6564 6566 2054 3220 7479 7065   typedef T2 type
-00003fd0: 3b20 7d3b 0a0a 2364 6566 696e 6520 5041  ; };..#define PA
-00003fe0: 434b 4554 5f44 4543 4c5f 434f 4e44 5f50  CKET_DECL_COND_P
-00003ff0: 5245 4649 5828 7072 6566 6978 2c20 6e61  REFIX(prefix, na
-00004000: 6d65 2c20 7061 636b 6574 5f73 697a 6529  me, packet_size)
-00004010: 2020 2020 2020 2020 205c 0a20 2074 7970           \.  typ
-00004020: 6564 6566 2074 7970 656e 616d 6520 7061  edef typename pa
-00004030: 636b 6574 5f63 6f6e 6469 7469 6f6e 616c  cket_conditional
-00004040: 3c70 6163 6b65 745f 7369 7a65 2c20 2020  <packet_size,   
-00004050: 2020 2020 2020 2020 2020 2020 2020 5c0a                \.
-00004060: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004070: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004080: 2020 2020 2020 7479 7065 6e61 6d65 2070        typename p
-00004090: 6163 6b65 745f 7472 6169 7473 3c6e 616d  acket_traits<nam
-000040a0: 6520 2323 2053 6361 6c61 723e 3a3a 7479  e ## Scalar>::ty
-000040b0: 7065 2c20 5c0a 2020 2020 2020 2020 2020  pe, \.          
+000005a0: 7661 6c29 2045 4947 454e 5f44 4546 4155  val) EIGEN_DEFAU
+000005b0: 4c54 5f4c 335f 4341 4348 455f 5349 5a45  LT_L3_CACHE_SIZE
+000005c0: 0a23 656c 7365 0a23 6465 6669 6e65 2045  .#else.#define E
+000005d0: 4947 454e 5f53 4554 5f44 4546 4155 4c54  IGEN_SET_DEFAULT
+000005e0: 5f4c 335f 4341 4348 455f 5349 5a45 2876  _L3_CACHE_SIZE(v
+000005f0: 616c 2920 7661 6c0a 2365 6e64 6966 202f  al) val.#endif /
+00000600: 2f20 6465 6669 6e65 6428 4549 4745 4e5f  / defined(EIGEN_
+00000610: 4445 4641 554c 545f 4c33 5f43 4143 4845  DEFAULT_L3_CACHE
+00000620: 5f53 495a 4529 0a20 200a 2369 6620 4549  _SIZE).  .#if EI
+00000630: 4745 4e5f 4152 4348 5f69 3338 365f 4f52  GEN_ARCH_i386_OR
+00000640: 5f78 3836 5f36 340a 636f 6e73 7420 7374  _x86_64.const st
+00000650: 643a 3a70 7472 6469 6666 5f74 2064 6566  d::ptrdiff_t def
+00000660: 6175 6c74 4c31 4361 6368 6553 697a 6520  aultL1CacheSize 
+00000670: 3d20 4549 4745 4e5f 5345 545f 4445 4641  = EIGEN_SET_DEFA
+00000680: 554c 545f 4c31 5f43 4143 4845 5f53 495a  ULT_L1_CACHE_SIZ
+00000690: 4528 3332 2a31 3032 3429 3b0a 636f 6e73  E(32*1024);.cons
+000006a0: 7420 7374 643a 3a70 7472 6469 6666 5f74  t std::ptrdiff_t
+000006b0: 2064 6566 6175 6c74 4c32 4361 6368 6553   defaultL2CacheS
+000006c0: 697a 6520 3d20 4549 4745 4e5f 5345 545f  ize = EIGEN_SET_
+000006d0: 4445 4641 554c 545f 4c32 5f43 4143 4845  DEFAULT_L2_CACHE
+000006e0: 5f53 495a 4528 3235 362a 3130 3234 293b  _SIZE(256*1024);
+000006f0: 0a63 6f6e 7374 2073 7464 3a3a 7074 7264  .const std::ptrd
+00000700: 6966 665f 7420 6465 6661 756c 744c 3343  iff_t defaultL3C
+00000710: 6163 6865 5369 7a65 203d 2045 4947 454e  acheSize = EIGEN
+00000720: 5f53 4554 5f44 4546 4155 4c54 5f4c 335f  _SET_DEFAULT_L3_
+00000730: 4341 4348 455f 5349 5a45 2832 2a31 3032  CACHE_SIZE(2*102
+00000740: 342a 3130 3234 293b 0a23 656c 6966 2045  4*1024);.#elif E
+00000750: 4947 454e 5f41 5243 485f 5050 430a 636f  IGEN_ARCH_PPC.co
+00000760: 6e73 7420 7374 643a 3a70 7472 6469 6666  nst std::ptrdiff
+00000770: 5f74 2064 6566 6175 6c74 4c31 4361 6368  _t defaultL1Cach
+00000780: 6553 697a 6520 3d20 4549 4745 4e5f 5345  eSize = EIGEN_SE
+00000790: 545f 4445 4641 554c 545f 4c31 5f43 4143  T_DEFAULT_L1_CAC
+000007a0: 4845 5f53 495a 4528 3634 2a31 3032 3429  HE_SIZE(64*1024)
+000007b0: 3b0a 636f 6e73 7420 7374 643a 3a70 7472  ;.const std::ptr
+000007c0: 6469 6666 5f74 2064 6566 6175 6c74 4c32  diff_t defaultL2
+000007d0: 4361 6368 6553 697a 6520 3d20 4549 4745  CacheSize = EIGE
+000007e0: 4e5f 5345 545f 4445 4641 554c 545f 4c32  N_SET_DEFAULT_L2
+000007f0: 5f43 4143 4845 5f53 495a 4528 3531 322a  _CACHE_SIZE(512*
+00000800: 3130 3234 293b 0a63 6f6e 7374 2073 7464  1024);.const std
+00000810: 3a3a 7074 7264 6966 665f 7420 6465 6661  ::ptrdiff_t defa
+00000820: 756c 744c 3343 6163 6865 5369 7a65 203d  ultL3CacheSize =
+00000830: 2045 4947 454e 5f53 4554 5f44 4546 4155   EIGEN_SET_DEFAU
+00000840: 4c54 5f4c 335f 4341 4348 455f 5349 5a45  LT_L3_CACHE_SIZE
+00000850: 2834 2a31 3032 342a 3130 3234 293b 0a23  (4*1024*1024);.#
+00000860: 656c 7365 0a63 6f6e 7374 2073 7464 3a3a  else.const std::
+00000870: 7074 7264 6966 665f 7420 6465 6661 756c  ptrdiff_t defaul
+00000880: 744c 3143 6163 6865 5369 7a65 203d 2045  tL1CacheSize = E
+00000890: 4947 454e 5f53 4554 5f44 4546 4155 4c54  IGEN_SET_DEFAULT
+000008a0: 5f4c 315f 4341 4348 455f 5349 5a45 2831  _L1_CACHE_SIZE(1
+000008b0: 362a 3130 3234 293b 0a63 6f6e 7374 2073  6*1024);.const s
+000008c0: 7464 3a3a 7074 7264 6966 665f 7420 6465  td::ptrdiff_t de
+000008d0: 6661 756c 744c 3243 6163 6865 5369 7a65  faultL2CacheSize
+000008e0: 203d 2045 4947 454e 5f53 4554 5f44 4546   = EIGEN_SET_DEF
+000008f0: 4155 4c54 5f4c 325f 4341 4348 455f 5349  AULT_L2_CACHE_SI
+00000900: 5a45 2835 3132 2a31 3032 3429 3b0a 636f  ZE(512*1024);.co
+00000910: 6e73 7420 7374 643a 3a70 7472 6469 6666  nst std::ptrdiff
+00000920: 5f74 2064 6566 6175 6c74 4c33 4361 6368  _t defaultL3Cach
+00000930: 6553 697a 6520 3d20 4549 4745 4e5f 5345  eSize = EIGEN_SE
+00000940: 545f 4445 4641 554c 545f 4c33 5f43 4143  T_DEFAULT_L3_CAC
+00000950: 4845 5f53 495a 4528 3531 322a 3130 3234  HE_SIZE(512*1024
+00000960: 293b 0a23 656e 6469 660a 0a23 756e 6465  );.#endif..#unde
+00000970: 6620 4549 4745 4e5f 5345 545f 4445 4641  f EIGEN_SET_DEFA
+00000980: 554c 545f 4c31 5f43 4143 4845 5f53 495a  ULT_L1_CACHE_SIZ
+00000990: 450a 2375 6e64 6566 2045 4947 454e 5f53  E.#undef EIGEN_S
+000009a0: 4554 5f44 4546 4155 4c54 5f4c 325f 4341  ET_DEFAULT_L2_CA
+000009b0: 4348 455f 5349 5a45 0a23 756e 6465 6620  CHE_SIZE.#undef 
+000009c0: 4549 4745 4e5f 5345 545f 4445 4641 554c  EIGEN_SET_DEFAUL
+000009d0: 545f 4c33 5f43 4143 4845 5f53 495a 450a  T_L3_CACHE_SIZE.
+000009e0: 0a2f 2a2a 205c 696e 7465 726e 616c 202a  ./** \internal *
+000009f0: 2f0a 7374 7275 6374 2043 6163 6865 5369  /.struct CacheSi
+00000a00: 7a65 7320 7b0a 2020 4361 6368 6553 697a  zes {.  CacheSiz
+00000a10: 6573 2829 3a20 6d5f 6c31 282d 3129 2c6d  es(): m_l1(-1),m
+00000a20: 5f6c 3228 2d31 292c 6d5f 6c33 282d 3129  _l2(-1),m_l3(-1)
+00000a30: 207b 0a20 2020 2069 6e74 206c 3143 6163   {.    int l1Cac
+00000a40: 6865 5369 7a65 2c20 6c32 4361 6368 6553  heSize, l2CacheS
+00000a50: 697a 652c 206c 3343 6163 6865 5369 7a65  ize, l3CacheSize
+00000a60: 3b0a 2020 2020 7175 6572 7943 6163 6865  ;.    queryCache
+00000a70: 5369 7a65 7328 6c31 4361 6368 6553 697a  Sizes(l1CacheSiz
+00000a80: 652c 206c 3243 6163 6865 5369 7a65 2c20  e, l2CacheSize, 
+00000a90: 6c33 4361 6368 6553 697a 6529 3b0a 2020  l3CacheSize);.  
+00000aa0: 2020 6d5f 6c31 203d 206d 616e 6167 655f    m_l1 = manage_
+00000ab0: 6361 6368 696e 675f 7369 7a65 735f 6865  caching_sizes_he
+00000ac0: 6c70 6572 286c 3143 6163 6865 5369 7a65  lper(l1CacheSize
+00000ad0: 2c20 6465 6661 756c 744c 3143 6163 6865  , defaultL1Cache
+00000ae0: 5369 7a65 293b 0a20 2020 206d 5f6c 3220  Size);.    m_l2 
+00000af0: 3d20 6d61 6e61 6765 5f63 6163 6869 6e67  = manage_caching
+00000b00: 5f73 697a 6573 5f68 656c 7065 7228 6c32  _sizes_helper(l2
+00000b10: 4361 6368 6553 697a 652c 2064 6566 6175  CacheSize, defau
+00000b20: 6c74 4c32 4361 6368 6553 697a 6529 3b0a  ltL2CacheSize);.
+00000b30: 2020 2020 6d5f 6c33 203d 206d 616e 6167      m_l3 = manag
+00000b40: 655f 6361 6368 696e 675f 7369 7a65 735f  e_caching_sizes_
+00000b50: 6865 6c70 6572 286c 3343 6163 6865 5369  helper(l3CacheSi
+00000b60: 7a65 2c20 6465 6661 756c 744c 3343 6163  ze, defaultL3Cac
+00000b70: 6865 5369 7a65 293b 0a20 207d 0a0a 2020  heSize);.  }..  
+00000b80: 7374 643a 3a70 7472 6469 6666 5f74 206d  std::ptrdiff_t m
+00000b90: 5f6c 313b 0a20 2073 7464 3a3a 7074 7264  _l1;.  std::ptrd
+00000ba0: 6966 665f 7420 6d5f 6c32 3b0a 2020 7374  iff_t m_l2;.  st
+00000bb0: 643a 3a70 7472 6469 6666 5f74 206d 5f6c  d::ptrdiff_t m_l
+00000bc0: 333b 0a7d 3b0a 0a2f 2a2a 205c 696e 7465  3;.};../** \inte
+00000bd0: 726e 616c 202a 2f0a 696e 6c69 6e65 2076  rnal */.inline v
+00000be0: 6f69 6420 6d61 6e61 6765 5f63 6163 6869  oid manage_cachi
+00000bf0: 6e67 5f73 697a 6573 2841 6374 696f 6e20  ng_sizes(Action 
+00000c00: 6163 7469 6f6e 2c20 7374 643a 3a70 7472  action, std::ptr
+00000c10: 6469 6666 5f74 2a20 6c31 2c20 7374 643a  diff_t* l1, std:
+00000c20: 3a70 7472 6469 6666 5f74 2a20 6c32 2c20  :ptrdiff_t* l2, 
+00000c30: 7374 643a 3a70 7472 6469 6666 5f74 2a20  std::ptrdiff_t* 
+00000c40: 6c33 290a 7b0a 2020 7374 6174 6963 2043  l3).{.  static C
+00000c50: 6163 6865 5369 7a65 7320 6d5f 6361 6368  acheSizes m_cach
+00000c60: 6553 697a 6573 3b0a 0a20 2069 6628 6163  eSizes;..  if(ac
+00000c70: 7469 6f6e 3d3d 5365 7441 6374 696f 6e29  tion==SetAction)
+00000c80: 0a20 207b 0a20 2020 202f 2f20 7365 7420  .  {.    // set 
+00000c90: 7468 6520 6370 7520 6361 6368 6520 7369  the cpu cache si
+00000ca0: 7a65 2061 6e64 2063 6163 6865 2061 6c6c  ze and cache all
+00000cb0: 2062 6c6f 636b 2073 697a 6573 2066 726f   block sizes fro
+00000cc0: 6d20 6120 676c 6f62 616c 2063 6163 6865  m a global cache
+00000cd0: 2073 697a 6520 696e 2062 7974 650a 2020   size in byte.  
+00000ce0: 2020 6569 6765 6e5f 696e 7465 726e 616c    eigen_internal
+00000cf0: 5f61 7373 6572 7428 6c31 213d 3020 2626  _assert(l1!=0 &&
+00000d00: 206c 3221 3d30 293b 0a20 2020 206d 5f63   l2!=0);.    m_c
+00000d10: 6163 6865 5369 7a65 732e 6d5f 6c31 203d  acheSizes.m_l1 =
+00000d20: 202a 6c31 3b0a 2020 2020 6d5f 6361 6368   *l1;.    m_cach
+00000d30: 6553 697a 6573 2e6d 5f6c 3220 3d20 2a6c  eSizes.m_l2 = *l
+00000d40: 323b 0a20 2020 206d 5f63 6163 6865 5369  2;.    m_cacheSi
+00000d50: 7a65 732e 6d5f 6c33 203d 202a 6c33 3b0a  zes.m_l3 = *l3;.
+00000d60: 2020 7d0a 2020 656c 7365 2069 6628 6163    }.  else if(ac
+00000d70: 7469 6f6e 3d3d 4765 7441 6374 696f 6e29  tion==GetAction)
+00000d80: 0a20 207b 0a20 2020 2065 6967 656e 5f69  .  {.    eigen_i
+00000d90: 6e74 6572 6e61 6c5f 6173 7365 7274 286c  nternal_assert(l
+00000da0: 3121 3d30 2026 2620 6c32 213d 3029 3b0a  1!=0 && l2!=0);.
+00000db0: 2020 2020 2a6c 3120 3d20 6d5f 6361 6368      *l1 = m_cach
+00000dc0: 6553 697a 6573 2e6d 5f6c 313b 0a20 2020  eSizes.m_l1;.   
+00000dd0: 202a 6c32 203d 206d 5f63 6163 6865 5369   *l2 = m_cacheSi
+00000de0: 7a65 732e 6d5f 6c32 3b0a 2020 2020 2a6c  zes.m_l2;.    *l
+00000df0: 3320 3d20 6d5f 6361 6368 6553 697a 6573  3 = m_cacheSizes
+00000e00: 2e6d 5f6c 333b 0a20 207d 0a20 2065 6c73  .m_l3;.  }.  els
+00000e10: 650a 2020 7b0a 2020 2020 6569 6765 6e5f  e.  {.    eigen_
+00000e20: 696e 7465 726e 616c 5f61 7373 6572 7428  internal_assert(
+00000e30: 6661 6c73 6529 3b0a 2020 7d0a 7d0a 0a2f  false);.  }.}../
+00000e40: 2a20 4865 6c70 6572 2066 6f72 2063 6f6d  * Helper for com
+00000e50: 7075 7465 5072 6f64 7563 7442 6c6f 636b  puteProductBlock
+00000e60: 696e 6753 697a 6573 2e0a 202a 0a20 2a20  ingSizes.. *. * 
+00000e70: 4769 7665 6e20 6120 6d20 7820 6b20 7469  Given a m x k ti
+00000e80: 6d65 7320 6b20 7820 6e20 6d61 7472 6978  mes k x n matrix
+00000e90: 2070 726f 6475 6374 206f 6620 7363 616c   product of scal
+00000ea0: 6172 2074 7970 6573 205c 6320 4c68 7353  ar types \c LhsS
+00000eb0: 6361 6c61 7220 616e 6420 5c63 2052 6873  calar and \c Rhs
+00000ec0: 5363 616c 6172 2c0a 202a 2074 6869 7320  Scalar,. * this 
+00000ed0: 6675 6e63 7469 6f6e 2063 6f6d 7075 7465  function compute
+00000ee0: 7320 7468 6520 626c 6f63 6b69 6e67 2073  s the blocking s
+00000ef0: 697a 6520 7061 7261 6d65 7465 7273 2061  ize parameters a
+00000f00: 6c6f 6e67 2074 6865 2072 6573 7065 6374  long the respect
+00000f10: 6976 6520 6469 6d65 6e73 696f 6e73 0a20  ive dimensions. 
+00000f20: 2a20 666f 7220 6d61 7472 6978 2070 726f  * for matrix pro
+00000f30: 6475 6374 7320 616e 6420 7265 6c61 7465  ducts and relate
+00000f40: 6420 616c 676f 7269 7468 6d73 2e20 5468  d algorithms. Th
+00000f50: 6520 626c 6f63 6b69 6e67 2073 697a 6573  e blocking sizes
+00000f60: 2064 6570 656e 6473 206f 6e20 7661 7269   depends on vari
+00000f70: 6f75 730a 202a 2070 6172 616d 6574 6572  ous. * parameter
+00000f80: 733a 0a20 2a20 2d20 7468 6520 4c31 2061  s:. * - the L1 a
+00000f90: 6e64 204c 3220 6361 6368 6520 7369 7a65  nd L2 cache size
+00000fa0: 732c 0a20 2a20 2d20 7468 6520 7265 6769  s,. * - the regi
+00000fb0: 7374 6572 206c 6576 656c 2062 6c6f 636b  ster level block
+00000fc0: 696e 6720 7369 7a65 7320 6465 6669 6e65  ing sizes define
+00000fd0: 6420 6279 2067 6562 705f 7472 6169 7473  d by gebp_traits
+00000fe0: 2c0a 202a 202d 2074 6865 206e 756d 6265  ,. * - the numbe
+00000ff0: 7220 6f66 2073 6361 6c61 7273 2074 6861  r of scalars tha
+00001000: 7420 6669 7420 696e 746f 2061 2070 6163  t fit into a pac
+00001010: 6b65 7420 2877 6865 6e20 7665 6374 6f72  ket (when vector
+00001020: 697a 6174 696f 6e20 6973 2065 6e61 626c  ization is enabl
+00001030: 6564 292e 0a20 2a0a 202a 205c 7361 2073  ed).. *. * \sa s
+00001040: 6574 4370 7543 6163 6865 5369 7a65 7320  etCpuCacheSizes 
+00001050: 2a2f 0a0a 7465 6d70 6c61 7465 3c74 7970  */..template<typ
+00001060: 656e 616d 6520 4c68 7353 6361 6c61 722c  ename LhsScalar,
+00001070: 2074 7970 656e 616d 6520 5268 7353 6361   typename RhsSca
+00001080: 6c61 722c 2069 6e74 204b 6346 6163 746f  lar, int KcFacto
+00001090: 722c 2074 7970 656e 616d 6520 496e 6465  r, typename Inde
+000010a0: 783e 0a76 6f69 6420 6576 616c 7561 7465  x>.void evaluate
+000010b0: 5072 6f64 7563 7442 6c6f 636b 696e 6753  ProductBlockingS
+000010c0: 697a 6573 4865 7572 6973 7469 6328 496e  izesHeuristic(In
+000010d0: 6465 7826 206b 2c20 496e 6465 7826 206d  dex& k, Index& m
+000010e0: 2c20 496e 6465 7826 206e 2c20 496e 6465  , Index& n, Inde
+000010f0: 7820 6e75 6d5f 7468 7265 6164 7320 3d20  x num_threads = 
+00001100: 3129 0a7b 0a20 2074 7970 6564 6566 2067  1).{.  typedef g
+00001110: 6562 705f 7472 6169 7473 3c4c 6873 5363  ebp_traits<LhsSc
+00001120: 616c 6172 2c52 6873 5363 616c 6172 3e20  alar,RhsScalar> 
+00001130: 5472 6169 7473 3b0a 0a20 202f 2f20 4578  Traits;..  // Ex
+00001140: 706c 616e 6174 696f 6e73 3a0a 2020 2f2f  planations:.  //
+00001150: 204c 6574 2773 2072 6563 616c 6c20 7468   Let's recall th
+00001160: 6174 2074 6865 2070 726f 6475 6374 2061  at the product a
+00001170: 6c67 6f72 6974 686d 7320 666f 726d 206d  lgorithms form m
+00001180: 6320 7820 6b63 2076 6572 7469 6361 6c20  c x kc vertical 
+00001190: 7061 6e65 6c73 2041 2720 6f6e 2074 6865  panels A' on the
+000011a0: 206c 6873 2061 6e64 0a20 202f 2f20 6b63   lhs and.  // kc
+000011b0: 2078 206e 6320 626c 6f63 6b73 2042 2720   x nc blocks B' 
+000011c0: 6f6e 2074 6865 2072 6873 2e20 4227 2068  on the rhs. B' h
+000011d0: 6173 2074 6f20 6669 7420 696e 746f 204c  as to fit into L
+000011e0: 322f 4c33 2063 6163 6865 2e20 4d6f 7265  2/L3 cache. More
+000011f0: 6f76 6572 2c20 4127 2069 7320 7072 6f63  over, A' is proc
+00001200: 6573 7365 640a 2020 2f2f 2070 6572 206d  essed.  // per m
+00001210: 7220 7820 6b63 2068 6f72 697a 6f6e 7461  r x kc horizonta
+00001220: 6c20 736d 616c 6c20 7061 6e65 6c73 2077  l small panels w
+00001230: 6865 7265 206d 7220 6973 2074 6865 2062  here mr is the b
+00001240: 6c6f 636b 696e 6720 7369 7a65 2061 6c6f  locking size alo
+00001250: 6e67 2074 6865 206d 2064 696d 656e 7369  ng the m dimensi
+00001260: 6f6e 0a20 202f 2f20 6174 2074 6865 2072  on.  // at the r
+00001270: 6567 6973 7465 7220 6c65 7665 6c2e 2054  egister level. T
+00001280: 6869 7320 736d 616c 6c20 686f 7269 7a6f  his small horizo
+00001290: 6e74 616c 2070 616e 656c 2068 6173 2074  ntal panel has t
+000012a0: 6f20 7374 6179 2077 6974 6869 6e20 4c31  o stay within L1
+000012b0: 2063 6163 6865 2e0a 2020 7374 643a 3a70   cache..  std::p
+000012c0: 7472 6469 6666 5f74 206c 312c 206c 322c  trdiff_t l1, l2,
+000012d0: 206c 333b 0a20 206d 616e 6167 655f 6361   l3;.  manage_ca
+000012e0: 6368 696e 675f 7369 7a65 7328 4765 7441  ching_sizes(GetA
+000012f0: 6374 696f 6e2c 2026 6c31 2c20 266c 322c  ction, &l1, &l2,
+00001300: 2026 6c33 293b 0a20 2023 6966 6465 6620   &l3);.  #ifdef 
+00001310: 4549 4745 4e5f 5645 4354 4f52 495a 455f  EIGEN_VECTORIZE_
+00001320: 4156 5835 3132 0a20 202f 2f20 5765 206e  AVX512.  // We n
+00001330: 6565 6420 746f 2066 696e 6420 6120 7261  eed to find a ra
+00001340: 7469 6f6e 616c 6520 666f 7220 7468 6174  tionale for that
+00001350: 2c20 6275 7420 7769 7468 6f75 7420 7468  , but without th
+00001360: 6973 2061 646a 7573 746d 656e 742c 0a20  is adjustment,. 
+00001370: 202f 2f20 7065 7266 6f72 6d61 6e63 6520   // performance 
+00001380: 7769 7468 2041 5658 3531 3220 6973 2070  with AVX512 is p
+00001390: 7265 7474 7920 6261 642c 206c 696b 6520  retty bad, like 
+000013a0: 2d32 3025 2073 6c6f 7765 722e 0a20 202f  -20% slower..  /
+000013b0: 2f20 4f6e 6520 7265 6173 6f6e 2069 7320  / One reason is 
+000013c0: 7468 6174 2077 6974 6820 696e 6372 6561  that with increa
+000013d0: 7369 6e67 2070 6163 6b65 742d 7369 7a65  sing packet-size
+000013e0: 2c20 7468 6520 626c 6f63 6b69 6e67 2073  , the blocking s
+000013f0: 697a 6520 6b0a 2020 2f2f 2068 6173 2074  ize k.  // has t
+00001400: 6f20 6265 636f 6d65 2070 7265 7474 7920  o become pretty 
+00001410: 736d 616c 6c20 6966 2077 6520 7761 6e74  small if we want
+00001420: 2074 6861 7420 3120 6c68 7320 7061 6e65   that 1 lhs pane
+00001430: 6c20 6669 7420 7769 7468 696e 204c 312e  l fit within L1.
+00001440: 0a20 202f 2f20 466f 7220 696e 7374 616e  .  // For instan
+00001450: 6365 2c20 7769 7468 2074 6865 2033 7058  ce, with the 3pX
+00001460: 3420 6b65 726e 656c 2061 6e64 2064 6f75  4 kernel and dou
+00001470: 626c 652c 2074 6865 2073 697a 6520 6f66  ble, the size of
+00001480: 2074 6865 206c 6873 2b72 6873 2070 616e   the lhs+rhs pan
+00001490: 656c 7320 6172 653a 0a20 202f 2f20 2020  els are:.  //   
+000014a0: 6b2a 2833 2a36 3420 2b20 342a 3829 2042  k*(3*64 + 4*8) B
+000014b0: 7974 6573 2c20 7769 7468 206c 313d 3332  ytes, with l1=32
+000014c0: 6b42 7974 6573 2c20 616e 6420 6b25 383d  kBytes, and k%8=
+000014d0: 302c 2077 6520 6861 7665 206b 3d31 3434  0, we have k=144
+000014e0: 2e0a 2020 2f2f 2054 6869 7320 6973 2071  ..  // This is q
+000014f0: 7569 7465 2073 6d61 6c6c 2066 6f72 2061  uite small for a
+00001500: 2067 6f6f 6420 7265 7573 6520 6f66 2074   good reuse of t
+00001510: 6865 2061 6363 756d 756c 6174 696f 6e20  he accumulation 
+00001520: 7265 6769 7374 6572 732e 0a20 206c 3120  registers..  l1 
+00001530: 2a3d 2034 3b0a 2020 2365 6e64 6966 0a0a  *= 4;.  #endif..
+00001540: 2020 6966 2028 6e75 6d5f 7468 7265 6164    if (num_thread
+00001550: 7320 3e20 3129 207b 0a20 2020 2074 7970  s > 1) {.    typ
+00001560: 6564 6566 2074 7970 656e 616d 6520 5472  edef typename Tr
+00001570: 6169 7473 3a3a 5265 7353 6361 6c61 7220  aits::ResScalar 
+00001580: 5265 7353 6361 6c61 723b 0a20 2020 2065  ResScalar;.    e
+00001590: 6e75 6d20 7b0a 2020 2020 2020 6b64 6976  num {.      kdiv
+000015a0: 203d 204b 6346 6163 746f 7220 2a20 2854   = KcFactor * (T
+000015b0: 7261 6974 733a 3a6d 7220 2a20 7369 7a65  raits::mr * size
+000015c0: 6f66 284c 6873 5363 616c 6172 2920 2b20  of(LhsScalar) + 
+000015d0: 5472 6169 7473 3a3a 6e72 202a 2073 697a  Traits::nr * siz
+000015e0: 656f 6628 5268 7353 6361 6c61 7229 292c  eof(RhsScalar)),
+000015f0: 0a20 2020 2020 206b 7375 6220 3d20 5472  .      ksub = Tr
+00001600: 6169 7473 3a3a 6d72 202a 2054 7261 6974  aits::mr * Trait
+00001610: 733a 3a6e 7220 2a20 7369 7a65 6f66 2852  s::nr * sizeof(R
+00001620: 6573 5363 616c 6172 292c 0a20 2020 2020  esScalar),.     
+00001630: 206b 7220 3d20 382c 0a20 2020 2020 206d   kr = 8,.      m
+00001640: 7220 3d20 5472 6169 7473 3a3a 6d72 2c0a  r = Traits::mr,.
+00001650: 2020 2020 2020 6e72 203d 2054 7261 6974        nr = Trait
+00001660: 733a 3a6e 720a 2020 2020 7d3b 0a20 2020  s::nr.    };.   
+00001670: 202f 2f20 496e 6372 6561 7369 6e67 206b   // Increasing k
+00001680: 2067 6976 6573 2075 7320 6d6f 7265 2074   gives us more t
+00001690: 696d 6520 746f 2070 7265 6665 7463 6820  ime to prefetch 
+000016a0: 7468 6520 636f 6e74 656e 7420 6f66 2074  the content of t
+000016b0: 6865 2022 4322 0a20 2020 202f 2f20 7265  he "C".    // re
+000016c0: 6769 7374 6572 732e 2048 6f77 6576 6572  gisters. However
+000016d0: 206f 6e63 6520 7468 6520 6c61 7465 6e63   once the latenc
+000016e0: 7920 6973 2068 6964 6465 6e20 7468 6572  y is hidden ther
+000016f0: 6520 6973 206e 6f20 706f 696e 7420 696e  e is no point in
+00001700: 0a20 2020 202f 2f20 696e 6372 6561 7369  .    // increasi
+00001710: 6e67 2074 6865 2076 616c 7565 206f 6620  ng the value of 
+00001720: 6b2c 2073 6f20 7765 276c 6c20 6361 7020  k, so we'll cap 
+00001730: 6974 2061 7420 3332 3020 2876 616c 7565  it at 320 (value
+00001740: 2064 6574 6572 6d69 6e65 640a 2020 2020   determined.    
+00001750: 2f2f 2065 7870 6572 696d 656e 7461 6c6c  // experimentall
+00001760: 7929 2e0a 2020 2020 2f2f 2054 6f20 6176  y)..    // To av
+00001770: 6f69 6420 7468 6174 206b 2076 616e 6973  oid that k vanis
+00001780: 6865 732c 2077 6520 6d61 6b65 206b 5f63  hes, we make k_c
+00001790: 6163 6865 2061 7420 6c65 6173 7420 6173  ache at least as
+000017a0: 2062 6967 2061 7320 6b72 0a20 2020 2063   big as kr.    c
+000017b0: 6f6e 7374 2049 6e64 6578 206b 5f63 6163  onst Index k_cac
+000017c0: 6865 203d 206e 756d 6578 743a 3a6d 6178  he = numext::max
+000017d0: 693c 496e 6465 783e 286b 722c 2028 6e75  i<Index>(kr, (nu
+000017e0: 6d65 7874 3a3a 6d69 6e69 3c49 6e64 6578  mext::mini<Index
+000017f0: 3e29 2828 6c31 2d6b 7375 6229 2f6b 6469  >)((l1-ksub)/kdi
+00001800: 762c 2033 3230 2929 3b0a 2020 2020 6966  v, 320));.    if
+00001810: 2028 6b5f 6361 6368 6520 3c20 6b29 207b   (k_cache < k) {
+00001820: 0a20 2020 2020 206b 203d 206b 5f63 6163  .      k = k_cac
+00001830: 6865 202d 2028 6b5f 6361 6368 6520 2520  he - (k_cache % 
+00001840: 6b72 293b 0a20 2020 2020 2065 6967 656e  kr);.      eigen
+00001850: 5f69 6e74 6572 6e61 6c5f 6173 7365 7274  _internal_assert
+00001860: 286b 203e 2030 293b 0a20 2020 207d 0a0a  (k > 0);.    }..
+00001870: 2020 2020 636f 6e73 7420 496e 6465 7820      const Index 
+00001880: 6e5f 6361 6368 6520 3d20 286c 322d 6c31  n_cache = (l2-l1
+00001890: 2920 2f20 286e 7220 2a20 7369 7a65 6f66  ) / (nr * sizeof
+000018a0: 2852 6873 5363 616c 6172 2920 2a20 6b29  (RhsScalar) * k)
+000018b0: 3b0a 2020 2020 636f 6e73 7420 496e 6465  ;.    const Inde
+000018c0: 7820 6e5f 7065 725f 7468 7265 6164 203d  x n_per_thread =
+000018d0: 206e 756d 6578 743a 3a64 6976 5f63 6569   numext::div_cei
+000018e0: 6c28 6e2c 206e 756d 5f74 6872 6561 6473  l(n, num_threads
+000018f0: 293b 0a20 2020 2069 6620 286e 5f63 6163  );.    if (n_cac
+00001900: 6865 203c 3d20 6e5f 7065 725f 7468 7265  he <= n_per_thre
+00001910: 6164 2920 7b0a 2020 2020 2020 2f2f 2044  ad) {.      // D
+00001920: 6f6e 2774 2065 7863 6565 6420 7468 6520  on't exceed the 
+00001930: 6361 7061 6369 7479 206f 6620 7468 6520  capacity of the 
+00001940: 6c32 2063 6163 6865 2e0a 2020 2020 2020  l2 cache..      
+00001950: 6569 6765 6e5f 696e 7465 726e 616c 5f61  eigen_internal_a
+00001960: 7373 6572 7428 6e5f 6361 6368 6520 3e3d  ssert(n_cache >=
+00001970: 2073 7461 7469 635f 6361 7374 3c49 6e64   static_cast<Ind
+00001980: 6578 3e28 6e72 2929 3b0a 2020 2020 2020  ex>(nr));.      
+00001990: 6e20 3d20 6e5f 6361 6368 6520 2d20 286e  n = n_cache - (n
+000019a0: 5f63 6163 6865 2025 206e 7229 3b0a 2020  _cache % nr);.  
+000019b0: 2020 2020 6569 6765 6e5f 696e 7465 726e      eigen_intern
+000019c0: 616c 5f61 7373 6572 7428 6e20 3e20 3029  al_assert(n > 0)
+000019d0: 3b0a 2020 2020 7d20 656c 7365 207b 0a20  ;.    } else {. 
+000019e0: 2020 2020 206e 203d 2028 6e75 6d65 7874       n = (numext
+000019f0: 3a3a 6d69 6e69 3c49 6e64 6578 3e29 286e  ::mini<Index>)(n
+00001a00: 2c20 286e 5f70 6572 5f74 6872 6561 6420  , (n_per_thread 
+00001a10: 2b20 6e72 202d 2031 2920 2d20 2828 6e5f  + nr - 1) - ((n_
+00001a20: 7065 725f 7468 7265 6164 202b 206e 7220  per_thread + nr 
+00001a30: 2d20 3129 2025 206e 7229 293b 0a20 2020  - 1) % nr));.   
+00001a40: 207d 0a0a 2020 2020 6966 2028 6c33 203e   }..    if (l3 >
+00001a50: 206c 3229 207b 0a20 2020 2020 202f 2f20   l2) {.      // 
+00001a60: 6c33 2069 7320 7368 6172 6564 2062 6574  l3 is shared bet
+00001a70: 7765 656e 2061 6c6c 2063 6f72 6573 2c20  ween all cores, 
+00001a80: 736f 2077 6527 6c6c 2067 6976 6520 6561  so we'll give ea
+00001a90: 6368 2074 6872 6561 6420 6974 7320 6f77  ch thread its ow
+00001aa0: 6e20 6368 756e 6b20 6f66 206c 332e 0a20  n chunk of l3.. 
+00001ab0: 2020 2020 2063 6f6e 7374 2049 6e64 6578       const Index
+00001ac0: 206d 5f63 6163 6865 203d 2028 6c33 2d6c   m_cache = (l3-l
+00001ad0: 3229 202f 2028 7369 7a65 6f66 284c 6873  2) / (sizeof(Lhs
+00001ae0: 5363 616c 6172 2920 2a20 6b20 2a20 6e75  Scalar) * k * nu
+00001af0: 6d5f 7468 7265 6164 7329 3b0a 2020 2020  m_threads);.    
+00001b00: 2020 636f 6e73 7420 496e 6465 7820 6d5f    const Index m_
+00001b10: 7065 725f 7468 7265 6164 203d 206e 756d  per_thread = num
+00001b20: 6578 743a 3a64 6976 5f63 6569 6c28 6d2c  ext::div_ceil(m,
+00001b30: 206e 756d 5f74 6872 6561 6473 293b 0a20   num_threads);. 
+00001b40: 2020 2020 2069 6628 6d5f 6361 6368 6520       if(m_cache 
+00001b50: 3c20 6d5f 7065 725f 7468 7265 6164 2026  < m_per_thread &
+00001b60: 2620 6d5f 6361 6368 6520 3e3d 2073 7461  & m_cache >= sta
+00001b70: 7469 635f 6361 7374 3c49 6e64 6578 3e28  tic_cast<Index>(
+00001b80: 6d72 2929 207b 0a20 2020 2020 2020 206d  mr)) {.        m
+00001b90: 203d 206d 5f63 6163 6865 202d 2028 6d5f   = m_cache - (m_
+00001ba0: 6361 6368 6520 2520 6d72 293b 0a20 2020  cache % mr);.   
+00001bb0: 2020 2020 2065 6967 656e 5f69 6e74 6572       eigen_inter
+00001bc0: 6e61 6c5f 6173 7365 7274 286d 203e 2030  nal_assert(m > 0
+00001bd0: 293b 0a20 2020 2020 207d 2065 6c73 6520  );.      } else 
+00001be0: 7b0a 2020 2020 2020 2020 6d20 3d20 286e  {.        m = (n
+00001bf0: 756d 6578 743a 3a6d 696e 693c 496e 6465  umext::mini<Inde
+00001c00: 783e 2928 6d2c 2028 6d5f 7065 725f 7468  x>)(m, (m_per_th
+00001c10: 7265 6164 202b 206d 7220 2d20 3129 202d  read + mr - 1) -
+00001c20: 2028 286d 5f70 6572 5f74 6872 6561 6420   ((m_per_thread 
+00001c30: 2b20 6d72 202d 2031 2920 2520 6d72 2929  + mr - 1) % mr))
+00001c40: 3b0a 2020 2020 2020 7d0a 2020 2020 7d0a  ;.      }.    }.
+00001c50: 2020 7d0a 2020 656c 7365 207b 0a20 2020    }.  else {.   
+00001c60: 202f 2f20 496e 2075 6e69 7420 7465 7374   // In unit test
+00001c70: 7320 7765 2064 6f20 6e6f 7420 7761 6e74  s we do not want
+00001c80: 2074 6f20 7573 6520 6578 7472 6120 6c61   to use extra la
+00001c90: 7267 6520 6d61 7472 6963 6573 2c0a 2020  rge matrices,.  
+00001ca0: 2020 2f2f 2073 6f20 7765 2072 6564 7563    // so we reduc
+00001cb0: 6520 7468 6520 6361 6368 6520 7369 7a65  e the cache size
+00001cc0: 2074 6f20 6368 6563 6b20 7468 6520 626c   to check the bl
+00001cd0: 6f63 6b69 6e67 2073 7472 6174 6567 7920  ocking strategy 
+00001ce0: 6973 206e 6f74 2066 6c61 7765 640a 2369  is not flawed.#i
+00001cf0: 6664 6566 2045 4947 454e 5f44 4542 5547  fdef EIGEN_DEBUG
+00001d00: 5f53 4d41 4c4c 5f50 524f 4455 4354 5f42  _SMALL_PRODUCT_B
+00001d10: 4c4f 434b 530a 2020 2020 6c31 203d 2039  LOCKS.    l1 = 9
+00001d20: 2a31 3032 343b 0a20 2020 206c 3220 3d20  *1024;.    l2 = 
+00001d30: 3332 2a31 3032 343b 0a20 2020 206c 3320  32*1024;.    l3 
+00001d40: 3d20 3531 322a 3130 3234 3b0a 2365 6e64  = 512*1024;.#end
+00001d50: 6966 0a0a 2020 2020 2f2f 2045 6172 6c79  if..    // Early
+00001d60: 2072 6574 7572 6e20 666f 7220 736d 616c   return for smal
+00001d70: 6c20 7072 6f62 6c65 6d73 2062 6563 6175  l problems becau
+00001d80: 7365 2074 6865 2063 6f6d 7075 7461 7469  se the computati
+00001d90: 6f6e 2062 656c 6f77 2061 7265 2074 696d  on below are tim
+00001da0: 6520 636f 6e73 756d 696e 6720 666f 7220  e consuming for 
+00001db0: 736d 616c 6c20 7072 6f62 6c65 6d73 2e0a  small problems..
+00001dc0: 2020 2020 2f2f 2050 6572 6861 7073 2069      // Perhaps i
+00001dd0: 7420 776f 756c 6420 6d61 6b65 206d 6f72  t would make mor
+00001de0: 6520 7365 6e73 6520 746f 2063 6f6e 7369  e sense to consi
+00001df0: 6465 7220 6b2a 6e2a 6d3f 3f0a 2020 2020  der k*n*m??.    
+00001e00: 2f2f 204e 6f74 6520 7468 6174 2066 6f72  // Note that for
+00001e10: 2076 6572 7920 7469 6e79 2070 726f 626c   very tiny probl
+00001e20: 656d 2c20 7468 6973 2066 756e 6374 696f  em, this functio
+00001e30: 6e20 7368 6f75 6c64 2062 6520 6279 7061  n should be bypa
+00001e40: 7373 6564 2061 6e79 7761 790a 2020 2020  ssed anyway.    
+00001e50: 2f2f 2062 6563 6175 7365 2077 6520 7573  // because we us
+00001e60: 6520 7468 6520 636f 6566 6669 6369 656e  e the coefficien
+00001e70: 742d 6261 7365 6420 696d 706c 656d 656e  t-based implemen
+00001e80: 7461 7469 6f6e 2066 6f72 2074 6865 6d2e  tation for them.
+00001e90: 0a20 2020 2069 6628 286e 756d 6578 743a  .    if((numext:
+00001ea0: 3a6d 6178 6929 286b 2c28 6e75 6d65 7874  :maxi)(k,(numext
+00001eb0: 3a3a 6d61 7869 2928 6d2c 6e29 293c 3438  ::maxi)(m,n))<48
+00001ec0: 290a 2020 2020 2020 7265 7475 726e 3b0a  ).      return;.
+00001ed0: 0a20 2020 2074 7970 6564 6566 2074 7970  .    typedef typ
+00001ee0: 656e 616d 6520 5472 6169 7473 3a3a 5265  ename Traits::Re
+00001ef0: 7353 6361 6c61 7220 5265 7353 6361 6c61  sScalar ResScala
+00001f00: 723b 0a20 2020 2065 6e75 6d20 7b0a 2020  r;.    enum {.  
+00001f10: 2020 2020 6b5f 7065 656c 696e 6720 3d20      k_peeling = 
+00001f20: 382c 0a20 2020 2020 206b 5f64 6976 203d  8,.      k_div =
+00001f30: 204b 6346 6163 746f 7220 2a20 2854 7261   KcFactor * (Tra
+00001f40: 6974 733a 3a6d 7220 2a20 7369 7a65 6f66  its::mr * sizeof
+00001f50: 284c 6873 5363 616c 6172 2920 2b20 5472  (LhsScalar) + Tr
+00001f60: 6169 7473 3a3a 6e72 202a 2073 697a 656f  aits::nr * sizeo
+00001f70: 6628 5268 7353 6361 6c61 7229 292c 0a20  f(RhsScalar)),. 
+00001f80: 2020 2020 206b 5f73 7562 203d 2054 7261       k_sub = Tra
+00001f90: 6974 733a 3a6d 7220 2a20 5472 6169 7473  its::mr * Traits
+00001fa0: 3a3a 6e72 202a 2073 697a 656f 6628 5265  ::nr * sizeof(Re
+00001fb0: 7353 6361 6c61 7229 0a20 2020 207d 3b0a  sScalar).    };.
+00001fc0: 0a20 2020 202f 2f20 2d2d 2d2d 2031 7374  .    // ---- 1st
+00001fd0: 206c 6576 656c 206f 6620 626c 6f63 6b69   level of blocki
+00001fe0: 6e67 206f 6e20 4c31 2c20 7969 656c 6473  ng on L1, yields
+00001ff0: 206b 6320 2d2d 2d2d 0a0a 2020 2020 2f2f   kc ----..    //
+00002000: 2042 6c6f 636b 696e 6720 6f6e 2074 6865   Blocking on the
+00002010: 2074 6869 7264 2064 696d 656e 7369 6f6e   third dimension
+00002020: 2028 692e 652e 2c20 6b29 2069 7320 6368   (i.e., k) is ch
+00002030: 6f73 656e 2073 6f20 7468 6174 2061 6e20  osen so that an 
+00002040: 686f 7269 7a6f 6e74 616c 2070 616e 656c  horizontal panel
+00002050: 0a20 2020 202f 2f20 6f66 2073 697a 6520  .    // of size 
+00002060: 6d72 2078 206b 6320 6f66 2074 6865 206c  mr x kc of the l
+00002070: 6873 2070 6c75 7320 6120 7665 7274 6963  hs plus a vertic
+00002080: 616c 2070 616e 656c 206f 6620 6b63 2078  al panel of kc x
+00002090: 206e 7220 6f66 2074 6865 2072 6873 2062   nr of the rhs b
+000020a0: 6f74 6820 6669 7473 2077 6974 6869 6e20  oth fits within 
+000020b0: 4c31 2063 6163 6865 2e0a 2020 2020 2f2f  L1 cache..    //
+000020c0: 2057 6520 616c 736f 2069 6e63 6c75 6465   We also include
+000020d0: 2061 2072 6567 6973 7465 722d 6c65 7665   a register-leve
+000020e0: 6c20 626c 6f63 6b20 6f66 2074 6865 2072  l block of the r
+000020f0: 6573 756c 7420 286d 7820 7820 6e72 292e  esult (mx x nr).
+00002100: 0a20 2020 202f 2f20 2849 6e20 616e 2069  .    // (In an i
+00002110: 6465 616c 2077 6f72 6c64 206f 6e6c 7920  deal world only 
+00002120: 7468 6520 6c68 7320 7061 6e65 6c20 776f  the lhs panel wo
+00002130: 756c 6420 7374 6179 2069 6e20 4c31 290a  uld stay in L1).
+00002140: 2020 2020 2f2f 204d 6f72 656f 7665 722c      // Moreover,
+00002150: 206b 6320 6861 7320 746f 2062 6520 6120   kc has to be a 
+00002160: 6d75 6c74 6970 6c65 206f 6620 3820 746f  multiple of 8 to
+00002170: 2062 6520 636f 6d70 6174 6962 6c65 2077   be compatible w
+00002180: 6974 6820 6c6f 6f70 2070 6565 6c69 6e67  ith loop peeling
+00002190: 2c20 6c65 6164 696e 6720 746f 2061 206d  , leading to a m
+000021a0: 6178 696d 756d 2062 6c6f 636b 696e 6720  aximum blocking 
+000021b0: 7369 7a65 206f 663a 0a20 2020 2063 6f6e  size of:.    con
+000021c0: 7374 2049 6e64 6578 206d 6178 5f6b 6320  st Index max_kc 
+000021d0: 3d20 6e75 6d65 7874 3a3a 6d61 7869 3c49  = numext::maxi<I
+000021e0: 6e64 6578 3e28 2828 6c31 2d6b 5f73 7562  ndex>(((l1-k_sub
+000021f0: 292f 6b5f 6469 7629 2026 2028 7e28 6b5f  )/k_div) & (~(k_
+00002200: 7065 656c 696e 672d 3129 292c 3129 3b0a  peeling-1)),1);.
+00002210: 2020 2020 636f 6e73 7420 496e 6465 7820      const Index 
+00002220: 6f6c 645f 6b20 3d20 6b3b 0a20 2020 2069  old_k = k;.    i
+00002230: 6628 6b3e 6d61 785f 6b63 290a 2020 2020  f(k>max_kc).    
+00002240: 7b0a 2020 2020 2020 2f2f 2057 6520 6172  {.      // We ar
+00002250: 6520 7265 616c 6c79 2062 6c6f 636b 696e  e really blockin
+00002260: 6720 6f6e 2074 6865 2074 6869 7264 2064  g on the third d
+00002270: 696d 656e 7369 6f6e 3a0a 2020 2020 2020  imension:.      
+00002280: 2f2f 202d 3e20 7265 6475 6365 2062 6c6f  // -> reduce blo
+00002290: 636b 696e 6720 7369 7a65 2074 6f20 6d61  cking size to ma
+000022a0: 6b65 2073 7572 6520 7468 6520 6c61 7374  ke sure the last
+000022b0: 2062 6c6f 636b 2069 7320 6173 206c 6172   block is as lar
+000022c0: 6765 2061 7320 706f 7373 6962 6c65 0a20  ge as possible. 
+000022d0: 2020 2020 202f 2f20 2020 2077 6869 6c65       //    while
+000022e0: 206b 6565 7069 6e67 2074 6865 2073 616d   keeping the sam
+000022f0: 6520 6e75 6d62 6572 206f 6620 7377 6565  e number of swee
+00002300: 7073 206f 7665 7220 7468 6520 7265 7375  ps over the resu
+00002310: 6c74 2e0a 2020 2020 2020 6b20 3d20 286b  lt..      k = (k
+00002320: 256d 6178 5f6b 6329 3d3d 3020 3f20 6d61  %max_kc)==0 ? ma
+00002330: 785f 6b63 0a20 2020 2020 2020 2020 2020  x_kc.           
+00002340: 2020 2020 2020 2020 2020 2020 203a 206d               : m
+00002350: 6178 5f6b 6320 2d20 6b5f 7065 656c 696e  ax_kc - k_peelin
+00002360: 6720 2a20 2828 6d61 785f 6b63 2d31 2d28  g * ((max_kc-1-(
+00002370: 6b25 6d61 785f 6b63 2929 2f28 6b5f 7065  k%max_kc))/(k_pe
+00002380: 656c 696e 672a 286b 2f6d 6178 5f6b 632b  eling*(k/max_kc+
+00002390: 3129 2929 3b0a 0a20 2020 2020 2065 6967  1)));..      eig
+000023a0: 656e 5f69 6e74 6572 6e61 6c5f 6173 7365  en_internal_asse
+000023b0: 7274 2828 286f 6c64 5f6b 2f6b 2920 3d3d  rt(((old_k/k) ==
+000023c0: 2028 6f6c 645f 6b2f 6d61 785f 6b63 2929   (old_k/max_kc))
+000023d0: 2026 2620 2274 6865 206e 756d 6265 7220   && "the number 
+000023e0: 6f66 2073 7765 6570 7320 6861 7320 746f  of sweeps has to
+000023f0: 2072 656d 6169 6e20 7468 6520 7361 6d65   remain the same
+00002400: 2229 3b0a 2020 2020 7d0a 0a20 2020 202f  ");.    }..    /
+00002410: 2f20 2d2d 2d2d 2032 6e64 206c 6576 656c  / ---- 2nd level
+00002420: 206f 6620 626c 6f63 6b69 6e67 206f 6e20   of blocking on 
+00002430: 6d61 7828 4c32 2c4c 3329 2c20 7969 656c  max(L2,L3), yiel
+00002440: 6473 206e 6320 2d2d 2d2d 0a0a 2020 2020  ds nc ----..    
+00002450: 2f2f 2054 4f44 4f20 6669 6e64 2061 2072  // TODO find a r
+00002460: 656c 6961 626c 6520 7761 7920 746f 2067  eliable way to g
+00002470: 6574 2074 6865 2061 6374 7561 6c20 616d  et the actual am
+00002480: 6f75 6e74 206f 6620 6361 6368 6520 7065  ount of cache pe
+00002490: 7220 636f 7265 2074 6f20 7573 6520 666f  r core to use fo
+000024a0: 7220 326e 6420 6c65 7665 6c20 626c 6f63  r 2nd level bloc
+000024b0: 6b69 6e67 2c20 7468 6174 2069 733a 0a20  king, that is:. 
+000024c0: 2020 202f 2f20 2020 2020 2061 6374 7561     //      actua
+000024d0: 6c5f 6c32 203d 206d 6178 286c 322c 206c  l_l2 = max(l2, l
+000024e0: 332f 6e62 5f63 6f72 655f 7368 6172 696e  3/nb_core_sharin
+000024f0: 675f 6c33 290a 2020 2020 2f2f 2054 6865  g_l3).    // The
+00002500: 206e 756d 6265 7220 6265 6c6f 7720 6973   number below is
+00002510: 2071 7569 7465 2063 6f6e 7365 7276 6174   quite conservat
+00002520: 6976 653a 2069 7420 6973 2062 6574 7465  ive: it is bette
+00002530: 7220 746f 2075 6e64 6572 6573 7469 6d61  r to underestima
+00002540: 7465 2074 6865 2063 6163 6865 2073 697a  te the cache siz
+00002550: 6520 7261 7468 6572 2074 6861 6e20 6f76  e rather than ov
+00002560: 6572 6573 7469 6d61 7469 6e67 2069 7429  erestimating it)
+00002570: 0a20 2020 202f 2f20 466f 7220 696e 7374  .    // For inst
+00002580: 616e 6365 2c20 6974 2063 6f72 7265 7370  ance, it corresp
+00002590: 6f6e 6473 2074 6f20 364d 4220 6f66 204c  onds to 6MB of L
+000025a0: 3320 7368 6172 6564 2061 6d6f 6e67 2034  3 shared among 4
+000025b0: 2063 6f72 6573 2e0a 2020 2020 2369 6664   cores..    #ifd
+000025c0: 6566 2045 4947 454e 5f44 4542 5547 5f53  ef EIGEN_DEBUG_S
+000025d0: 4d41 4c4c 5f50 524f 4455 4354 5f42 4c4f  MALL_PRODUCT_BLO
+000025e0: 434b 530a 2020 2020 636f 6e73 7420 496e  CKS.    const In
+000025f0: 6465 7820 6163 7475 616c 5f6c 3220 3d20  dex actual_l2 = 
+00002600: 6c33 3b0a 2020 2020 2365 6c73 650a 2020  l3;.    #else.  
+00002610: 2020 636f 6e73 7420 496e 6465 7820 6163    const Index ac
+00002620: 7475 616c 5f6c 3220 3d20 3135 3732 3836  tual_l2 = 157286
+00002630: 343b 202f 2f20 3d3d 2031 2e35 204d 420a  4; // == 1.5 MB.
+00002640: 2020 2020 2365 6e64 6966 0a0a 2020 2020      #endif..    
+00002650: 2f2f 2048 6572 652c 206e 6320 6973 2063  // Here, nc is c
+00002660: 686f 7365 6e20 7375 6368 2074 6861 7420  hosen such that 
+00002670: 6120 626c 6f63 6b20 6f66 206b 6320 7820  a block of kc x 
+00002680: 6e63 206f 6620 7468 6520 7268 7320 6669  nc of the rhs fi
+00002690: 7420 7769 7468 696e 2068 616c 6620 6f66  t within half of
+000026a0: 204c 322e 0a20 2020 202f 2f20 5468 6520   L2..    // The 
+000026b0: 7365 636f 6e64 2068 616c 6620 6973 2069  second half is i
+000026c0: 6d70 6c69 6369 746c 7920 7265 7365 7276  mplicitly reserv
+000026d0: 6564 2074 6f20 6163 6365 7373 2074 6865  ed to access the
+000026e0: 2072 6573 756c 7420 616e 6420 6c68 7320   result and lhs 
+000026f0: 636f 6566 6669 6369 656e 7473 2e0a 2020  coefficients..  
+00002700: 2020 2f2f 2057 6865 6e20 6b3c 6d61 785f    // When k<max_
+00002710: 6b63 2c20 7468 656e 206e 6320 6361 6e20  kc, then nc can 
+00002720: 6172 6269 7472 6172 696c 7920 6772 6f77  arbitrarily grow
+00002730: 7468 2e20 496e 2070 7261 6374 6963 652c  th. In practice,
+00002740: 2069 7420 7365 656d 7320 746f 2062 6520   it seems to be 
+00002750: 6672 7569 7466 756c 0a20 2020 202f 2f20  fruitful.    // 
+00002760: 746f 206c 696d 6974 2074 6869 7320 6772  to limit this gr
+00002770: 6f77 7468 3a20 7765 2062 6f75 6e64 206e  owth: we bound n
+00002780: 6320 746f 2067 726f 7774 6820 6279 2061  c to growth by a
+00002790: 2066 6163 746f 7220 7831 2e35 2e0a 2020   factor x1.5..  
+000027a0: 2020 2f2f 2048 6f77 6576 6572 2c20 6966    // However, if
+000027b0: 2074 6865 2065 6e74 6972 6520 6c68 7320   the entire lhs 
+000027c0: 626c 6f63 6b20 6669 7420 7769 7468 696e  block fit within
+000027d0: 204c 312c 2074 6865 6e20 7765 2061 7265   L1, then we are
+000027e0: 206e 6f74 2067 6f69 6e67 2074 6f20 626c   not going to bl
+000027f0: 6f63 6b20 6f6e 2074 6865 2072 6f77 7320  ock on the rows 
+00002800: 6174 2061 6c6c 2c0a 2020 2020 2f2f 2061  at all,.    // a
+00002810: 6e64 2069 7420 6265 636f 6d65 7320 6672  nd it becomes fr
+00002820: 7569 7466 756c 2074 6f20 6b65 6570 2074  uitful to keep t
+00002830: 6865 2070 6163 6b65 6420 7268 7320 626c  he packed rhs bl
+00002840: 6f63 6b73 2069 6e20 4c31 2069 6620 7468  ocks in L1 if th
+00002850: 6572 6520 6973 2065 6e6f 7567 6820 7265  ere is enough re
+00002860: 6d61 696e 696e 6720 7370 6163 652e 0a20  maining space.. 
+00002870: 2020 2049 6e64 6578 206d 6178 5f6e 633b     Index max_nc;
+00002880: 0a20 2020 2063 6f6e 7374 2049 6e64 6578  .    const Index
+00002890: 206c 6873 5f62 7974 6573 203d 206d 202a   lhs_bytes = m *
+000028a0: 206b 202a 2073 697a 656f 6628 4c68 7353   k * sizeof(LhsS
+000028b0: 6361 6c61 7229 3b0a 2020 2020 636f 6e73  calar);.    cons
+000028c0: 7420 496e 6465 7820 7265 6d61 696e 696e  t Index remainin
+000028d0: 675f 6c31 203d 206c 312d 206b 5f73 7562  g_l1 = l1- k_sub
+000028e0: 202d 206c 6873 5f62 7974 6573 3b0a 2020   - lhs_bytes;.  
+000028f0: 2020 6966 2872 656d 6169 6e69 6e67 5f6c    if(remaining_l
+00002900: 3120 3e3d 2049 6e64 6578 2854 7261 6974  1 >= Index(Trait
+00002910: 733a 3a6e 722a 7369 7a65 6f66 2852 6873  s::nr*sizeof(Rhs
+00002920: 5363 616c 6172 2929 2a6b 290a 2020 2020  Scalar))*k).    
+00002930: 7b0a 2020 2020 2020 2f2f 204c 3120 626c  {.      // L1 bl
+00002940: 6f63 6b69 6e67 0a20 2020 2020 206d 6178  ocking.      max
+00002950: 5f6e 6320 3d20 7265 6d61 696e 696e 675f  _nc = remaining_
+00002960: 6c31 202f 2028 6b2a 7369 7a65 6f66 2852  l1 / (k*sizeof(R
+00002970: 6873 5363 616c 6172 2929 3b0a 2020 2020  hsScalar));.    
+00002980: 7d0a 2020 2020 656c 7365 0a20 2020 207b  }.    else.    {
+00002990: 0a20 2020 2020 202f 2f20 4c32 2062 6c6f  .      // L2 blo
+000029a0: 636b 696e 670a 2020 2020 2020 6d61 785f  cking.      max_
+000029b0: 6e63 203d 2028 332a 6163 7475 616c 5f6c  nc = (3*actual_l
+000029c0: 3229 2f28 322a 322a 6d61 785f 6b63 2a73  2)/(2*2*max_kc*s
+000029d0: 697a 656f 6628 5268 7353 6361 6c61 7229  izeof(RhsScalar)
+000029e0: 293b 0a20 2020 207d 0a20 2020 202f 2f20  );.    }.    // 
+000029f0: 5741 524e 494e 4720 4265 6c6f 772c 2077  WARNING Below, w
+00002a00: 6520 6173 7375 6d65 2074 6861 7420 5472  e assume that Tr
+00002a10: 6169 7473 3a3a 6e72 2069 7320 6120 706f  aits::nr is a po
+00002a20: 7765 7220 6f66 2074 776f 2e0a 2020 2020  wer of two..    
+00002a30: 496e 6465 7820 6e63 203d 206e 756d 6578  Index nc = numex
+00002a40: 743a 3a6d 696e 693c 496e 6465 783e 2861  t::mini<Index>(a
+00002a50: 6374 7561 6c5f 6c32 2f28 322a 6b2a 7369  ctual_l2/(2*k*si
+00002a60: 7a65 6f66 2852 6873 5363 616c 6172 2929  zeof(RhsScalar))
+00002a70: 2c20 6d61 785f 6e63 2920 2620 287e 2854  , max_nc) & (~(T
+00002a80: 7261 6974 733a 3a6e 722d 3129 293b 0a20  raits::nr-1));. 
+00002a90: 2020 2069 6628 6e3e 6e63 290a 2020 2020     if(n>nc).    
+00002aa0: 7b0a 2020 2020 2020 2f2f 2057 6520 6172  {.      // We ar
+00002ab0: 6520 7265 616c 6c79 2062 6c6f 636b 696e  e really blockin
+00002ac0: 6720 6f76 6572 2074 6865 2063 6f6c 756d  g over the colum
+00002ad0: 6e73 3a0a 2020 2020 2020 2f2f 202d 3e20  ns:.      // -> 
+00002ae0: 7265 6475 6365 2062 6c6f 636b 696e 6720  reduce blocking 
+00002af0: 7369 7a65 2074 6f20 6d61 6b65 2073 7572  size to make sur
+00002b00: 6520 7468 6520 6c61 7374 2062 6c6f 636b  e the last block
+00002b10: 2069 7320 6173 206c 6172 6765 2061 7320   is as large as 
+00002b20: 706f 7373 6962 6c65 0a20 2020 2020 202f  possible.      /
+00002b30: 2f20 2020 2077 6869 6c65 206b 6565 7069  /    while keepi
+00002b40: 6e67 2074 6865 2073 616d 6520 6e75 6d62  ng the same numb
+00002b50: 6572 206f 6620 7377 6565 7073 206f 7665  er of sweeps ove
+00002b60: 7220 7468 6520 7061 636b 6564 206c 6873  r the packed lhs
+00002b70: 2e0a 2020 2020 2020 2f2f 2020 2020 4865  ..      //    He
+00002b80: 7265 2077 6520 616c 6c6f 7720 6f6e 6520  re we allow one 
+00002b90: 6d6f 7265 2073 7765 6570 2069 6620 7468  more sweep if th
+00002ba0: 6973 2067 6976 6573 2075 7320 6120 7065  is gives us a pe
+00002bb0: 7266 6563 7420 6d61 7463 682c 2074 6875  rfect match, thu
+00002bc0: 7320 7468 6520 636f 6d6d 656e 7465 6420  s the commented 
+00002bd0: 222d 3122 0a20 2020 2020 206e 203d 2028  "-1".      n = (
+00002be0: 6e25 6e63 293d 3d30 203f 206e 630a 2020  n%nc)==0 ? nc.  
+00002bf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002c00: 2020 3a20 286e 6320 2d20 5472 6169 7473    : (nc - Traits
+00002c10: 3a3a 6e72 202a 2028 286e 632f 2a2d 312a  ::nr * ((nc/*-1*
+00002c20: 2f2d 286e 256e 6329 292f 2854 7261 6974  /-(n%nc))/(Trait
+00002c30: 733a 3a6e 722a 286e 2f6e 632b 3129 2929  s::nr*(n/nc+1)))
+00002c40: 293b 0a20 2020 207d 0a20 2020 2065 6c73  );.    }.    els
+00002c50: 6520 6966 286f 6c64 5f6b 3d3d 6b29 0a20  e if(old_k==k). 
+00002c60: 2020 207b 0a20 2020 2020 202f 2f20 536f     {.      // So
+00002c70: 2066 6172 2c20 6e6f 2062 6c6f 636b 696e   far, no blockin
+00002c80: 6720 6174 2061 6c6c 2c20 692e 652e 2c20  g at all, i.e., 
+00002c90: 6b63 3d3d 6b2c 2061 6e64 206e 633d 3d6e  kc==k, and nc==n
+00002ca0: 2e0a 2020 2020 2020 2f2f 2049 6e20 7468  ..      // In th
+00002cb0: 6973 2063 6173 652c 206c 6574 2773 2070  is case, let's p
+00002cc0: 6572 666f 726d 2061 2062 6c6f 636b 696e  erform a blockin
+00002cd0: 6720 6f76 6572 2074 6865 2072 6f77 7320  g over the rows 
+00002ce0: 7375 6368 2074 6861 7420 7468 6520 7061  such that the pa
+00002cf0: 636b 6564 206c 6873 2064 6174 6120 6973  cked lhs data is
+00002d00: 206b 6570 7420 696e 2063 6163 6865 204c   kept in cache L
+00002d10: 312f 4c32 0a20 2020 2020 202f 2f20 544f  1/L2.      // TO
+00002d20: 444f 3a20 7061 7274 206f 6620 7468 6973  DO: part of this
+00002d30: 2062 6c6f 636b 696e 6720 7374 7261 7465   blocking strate
+00002d40: 6779 2069 7320 6e6f 7720 696d 706c 656d  gy is now implem
+00002d50: 656e 7465 6420 7769 7468 696e 2074 6865  ented within the
+00002d60: 206b 6572 6e65 6c20 6974 7365 6c66 2c20   kernel itself, 
+00002d70: 736f 2074 6865 204c 312d 6261 7365 6420  so the L1-based 
+00002d80: 6865 7572 6973 7469 6320 6865 7265 2073  heuristic here s
+00002d90: 686f 756c 6420 6265 206f 6273 6f6c 6574  hould be obsolet
+00002da0: 652e 0a20 2020 2020 2049 6e64 6578 2070  e..      Index p
+00002db0: 726f 626c 656d 5f73 697a 6520 3d20 6b2a  roblem_size = k*
+00002dc0: 6e2a 7369 7a65 6f66 284c 6873 5363 616c  n*sizeof(LhsScal
+00002dd0: 6172 293b 0a20 2020 2020 2049 6e64 6578  ar);.      Index
+00002de0: 2061 6374 7561 6c5f 6c6d 203d 2061 6374   actual_lm = act
+00002df0: 7561 6c5f 6c32 3b0a 2020 2020 2020 496e  ual_l2;.      In
+00002e00: 6465 7820 6d61 785f 6d63 203d 206d 3b0a  dex max_mc = m;.
+00002e10: 2020 2020 2020 6966 2870 726f 626c 656d        if(problem
+00002e20: 5f73 697a 653c 3d31 3032 3429 0a20 2020  _size<=1024).   
+00002e30: 2020 207b 0a20 2020 2020 2020 202f 2f20     {.        // 
+00002e40: 7072 6f62 6c65 6d20 6973 2073 6d61 6c6c  problem is small
+00002e50: 2065 6e6f 7567 6820 746f 206b 6565 7020   enough to keep 
+00002e60: 696e 204c 310a 2020 2020 2020 2020 2f2f  in L1.        //
+00002e70: 204c 6574 2773 2063 686f 6f73 6520 6d20   Let's choose m 
+00002e80: 7375 6368 2074 6861 7420 6c68 7327 7320  such that lhs's 
+00002e90: 626c 6f63 6b20 6669 7420 696e 2031 2f33  block fit in 1/3
+00002ea0: 206f 6620 4c31 0a20 2020 2020 2020 2061   of L1.        a
+00002eb0: 6374 7561 6c5f 6c6d 203d 206c 313b 0a20  ctual_lm = l1;. 
+00002ec0: 2020 2020 207d 0a20 2020 2020 2065 6c73       }.      els
+00002ed0: 6520 6966 286c 3321 3d30 2026 2620 7072  e if(l3!=0 && pr
+00002ee0: 6f62 6c65 6d5f 7369 7a65 3c3d 3332 3736  oblem_size<=3276
+00002ef0: 3829 0a20 2020 2020 207b 0a20 2020 2020  8).      {.     
+00002f00: 2020 202f 2f20 7765 2068 6176 6520 626f     // we have bo
+00002f10: 7468 204c 3220 616e 6420 4c33 2c20 616e  th L2 and L3, an
+00002f20: 6420 7072 6f62 6c65 6d20 6973 2073 6d61  d problem is sma
+00002f30: 6c6c 2065 6e6f 7567 6820 746f 2062 6520  ll enough to be 
+00002f40: 6b65 7074 2069 6e20 4c32 0a20 2020 2020  kept in L2.     
+00002f50: 2020 202f 2f20 4c65 7427 7320 6368 6f6f     // Let's choo
+00002f60: 7365 206d 2073 7563 6820 7468 6174 206c  se m such that l
+00002f70: 6873 2773 2062 6c6f 636b 2066 6974 2069  hs's block fit i
+00002f80: 6e20 312f 3320 6f66 204c 320a 2020 2020  n 1/3 of L2.    
+00002f90: 2020 2020 6163 7475 616c 5f6c 6d20 3d20      actual_lm = 
+00002fa0: 6c32 3b0a 2020 2020 2020 2020 6d61 785f  l2;.        max_
+00002fb0: 6d63 203d 2028 6e75 6d65 7874 3a3a 6d69  mc = (numext::mi
+00002fc0: 6e69 3c49 6e64 6578 3e29 2835 3736 2c6d  ni<Index>)(576,m
+00002fd0: 6178 5f6d 6329 3b0a 2020 2020 2020 7d0a  ax_mc);.      }.
+00002fe0: 2020 2020 2020 496e 6465 7820 6d63 203d        Index mc =
+00002ff0: 2028 6e75 6d65 7874 3a3a 6d69 6e69 3c49   (numext::mini<I
+00003000: 6e64 6578 3e29 2861 6374 7561 6c5f 6c6d  ndex>)(actual_lm
+00003010: 2f28 332a 6b2a 7369 7a65 6f66 284c 6873  /(3*k*sizeof(Lhs
+00003020: 5363 616c 6172 2929 2c20 6d61 785f 6d63  Scalar)), max_mc
+00003030: 293b 0a20 2020 2020 2069 6620 286d 6320  );.      if (mc 
+00003040: 3e20 5472 6169 7473 3a3a 6d72 2920 6d63  > Traits::mr) mc
+00003050: 202d 3d20 6d63 2025 2054 7261 6974 733a   -= mc % Traits:
+00003060: 3a6d 723b 0a20 2020 2020 2065 6c73 6520  :mr;.      else 
+00003070: 6966 2028 6d63 3d3d 3029 2072 6574 7572  if (mc==0) retur
+00003080: 6e3b 0a20 2020 2020 206d 203d 2028 6d25  n;.      m = (m%
+00003090: 6d63 293d 3d30 203f 206d 630a 2020 2020  mc)==0 ? mc.    
+000030a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000030b0: 3a20 286d 6320 2d20 5472 6169 7473 3a3a  : (mc - Traits::
+000030c0: 6d72 202a 2028 286d 632f 2a2d 312a 2f2d  mr * ((mc/*-1*/-
+000030d0: 286d 256d 6329 292f 2854 7261 6974 733a  (m%mc))/(Traits:
+000030e0: 3a6d 722a 286d 2f6d 632b 3129 2929 293b  :mr*(m/mc+1))));
+000030f0: 0a20 2020 207d 0a20 207d 0a7d 0a0a 7465  .    }.  }.}..te
+00003100: 6d70 6c61 7465 203c 7479 7065 6e61 6d65  mplate <typename
+00003110: 2049 6e64 6578 3e0a 696e 6c69 6e65 2062   Index>.inline b
+00003120: 6f6f 6c20 7573 6553 7065 6369 6669 6342  ool useSpecificB
+00003130: 6c6f 636b 696e 6753 697a 6573 2849 6e64  lockingSizes(Ind
+00003140: 6578 2620 6b2c 2049 6e64 6578 2620 6d2c  ex& k, Index& m,
+00003150: 2049 6e64 6578 2620 6e29 0a7b 0a23 6966   Index& n).{.#if
+00003160: 6465 6620 4549 4745 4e5f 5445 5354 5f53  def EIGEN_TEST_S
+00003170: 5045 4349 4649 435f 424c 4f43 4b49 4e47  PECIFIC_BLOCKING
+00003180: 5f53 495a 4553 0a20 2069 6620 2845 4947  _SIZES.  if (EIG
+00003190: 454e 5f54 4553 545f 5350 4543 4946 4943  EN_TEST_SPECIFIC
+000031a0: 5f42 4c4f 434b 494e 475f 5349 5a45 5329  _BLOCKING_SIZES)
+000031b0: 207b 0a20 2020 206b 203d 206e 756d 6578   {.    k = numex
+000031c0: 743a 3a6d 696e 693c 496e 6465 783e 286b  t::mini<Index>(k
+000031d0: 2c20 4549 4745 4e5f 5445 5354 5f53 5045  , EIGEN_TEST_SPE
+000031e0: 4349 4649 435f 424c 4f43 4b49 4e47 5f53  CIFIC_BLOCKING_S
+000031f0: 495a 455f 4b29 3b0a 2020 2020 6d20 3d20  IZE_K);.    m = 
+00003200: 6e75 6d65 7874 3a3a 6d69 6e69 3c49 6e64  numext::mini<Ind
+00003210: 6578 3e28 6d2c 2045 4947 454e 5f54 4553  ex>(m, EIGEN_TES
+00003220: 545f 5350 4543 4946 4943 5f42 4c4f 434b  T_SPECIFIC_BLOCK
+00003230: 494e 475f 5349 5a45 5f4d 293b 0a20 2020  ING_SIZE_M);.   
+00003240: 206e 203d 206e 756d 6578 743a 3a6d 696e   n = numext::min
+00003250: 693c 496e 6465 783e 286e 2c20 4549 4745  i<Index>(n, EIGE
+00003260: 4e5f 5445 5354 5f53 5045 4349 4649 435f  N_TEST_SPECIFIC_
+00003270: 424c 4f43 4b49 4e47 5f53 495a 455f 4e29  BLOCKING_SIZE_N)
+00003280: 3b0a 2020 2020 7265 7475 726e 2074 7275  ;.    return tru
+00003290: 653b 0a20 207d 0a23 656c 7365 0a20 2045  e;.  }.#else.  E
+000032a0: 4947 454e 5f55 4e55 5345 445f 5641 5249  IGEN_UNUSED_VARI
+000032b0: 4142 4c45 286b 290a 2020 4549 4745 4e5f  ABLE(k).  EIGEN_
+000032c0: 554e 5553 4544 5f56 4152 4941 424c 4528  UNUSED_VARIABLE(
+000032d0: 6d29 0a20 2045 4947 454e 5f55 4e55 5345  m).  EIGEN_UNUSE
+000032e0: 445f 5641 5249 4142 4c45 286e 290a 2365  D_VARIABLE(n).#e
+000032f0: 6e64 6966 0a20 2072 6574 7572 6e20 6661  ndif.  return fa
+00003300: 6c73 653b 0a7d 0a0a 2f2a 2a20 5c62 7269  lse;.}../** \bri
+00003310: 6566 2043 6f6d 7075 7465 7320 7468 6520  ef Computes the 
+00003320: 626c 6f63 6b69 6e67 2070 6172 616d 6574  blocking paramet
+00003330: 6572 7320 666f 7220 6120 6d20 7820 6b20  ers for a m x k 
+00003340: 7469 6d65 7320 6b20 7820 6e20 6d61 7472  times k x n matr
+00003350: 6978 2070 726f 6475 6374 0a20 202a 0a20  ix product.  *. 
+00003360: 202a 205c 7061 7261 6d5b 696e 2c6f 7574   * \param[in,out
+00003370: 5d20 6b20 496e 7075 743a 2074 6865 2074  ] k Input: the t
+00003380: 6869 7264 2064 696d 656e 7369 6f6e 206f  hird dimension o
+00003390: 6620 7468 6520 7072 6f64 7563 742e 204f  f the product. O
+000033a0: 7574 7075 743a 2074 6865 2062 6c6f 636b  utput: the block
+000033b0: 696e 6720 7369 7a65 2061 6c6f 6e67 2074  ing size along t
+000033c0: 6865 2073 616d 6520 6469 6d65 6e73 696f  he same dimensio
+000033d0: 6e2e 0a20 202a 205c 7061 7261 6d5b 696e  n..  * \param[in
+000033e0: 2c6f 7574 5d20 6d20 496e 7075 743a 2074  ,out] m Input: t
+000033f0: 6865 206e 756d 6265 7220 6f66 2072 6f77  he number of row
+00003400: 7320 6f66 2074 6865 206c 6566 7420 6861  s of the left ha
+00003410: 6e64 2073 6964 652e 204f 7574 7075 743a  nd side. Output:
+00003420: 2074 6865 2062 6c6f 636b 696e 6720 7369   the blocking si
+00003430: 7a65 2061 6c6f 6e67 2074 6865 2073 616d  ze along the sam
+00003440: 6520 6469 6d65 6e73 696f 6e2e 0a20 202a  e dimension..  *
+00003450: 205c 7061 7261 6d5b 696e 2c6f 7574 5d20   \param[in,out] 
+00003460: 6e20 496e 7075 743a 2074 6865 206e 756d  n Input: the num
+00003470: 6265 7220 6f66 2063 6f6c 756d 6e73 206f  ber of columns o
+00003480: 6620 7468 6520 7269 6768 7420 6861 6e64  f the right hand
+00003490: 2073 6964 652e 204f 7574 7075 743a 2074   side. Output: t
+000034a0: 6865 2062 6c6f 636b 696e 6720 7369 7a65  he blocking size
+000034b0: 2061 6c6f 6e67 2074 6865 2073 616d 6520   along the same 
+000034c0: 6469 6d65 6e73 696f 6e2e 0a20 202a 0a20  dimension..  *. 
+000034d0: 202a 2047 6976 656e 2061 206d 2078 206b   * Given a m x k
+000034e0: 2074 696d 6573 206b 2078 206e 206d 6174   times k x n mat
+000034f0: 7269 7820 7072 6f64 7563 7420 6f66 2073  rix product of s
+00003500: 6361 6c61 7220 7479 7065 7320 5c63 204c  calar types \c L
+00003510: 6873 5363 616c 6172 2061 6e64 205c 6320  hsScalar and \c 
+00003520: 5268 7353 6361 6c61 722c 0a20 202a 2074  RhsScalar,.  * t
+00003530: 6869 7320 6675 6e63 7469 6f6e 2063 6f6d  his function com
+00003540: 7075 7465 7320 7468 6520 626c 6f63 6b69  putes the blocki
+00003550: 6e67 2073 697a 6520 7061 7261 6d65 7465  ng size paramete
+00003560: 7273 2061 6c6f 6e67 2074 6865 2072 6573  rs along the res
+00003570: 7065 6374 6976 6520 6469 6d65 6e73 696f  pective dimensio
+00003580: 6e73 0a20 202a 2066 6f72 206d 6174 7269  ns.  * for matri
+00003590: 7820 7072 6f64 7563 7473 2061 6e64 2072  x products and r
+000035a0: 656c 6174 6564 2061 6c67 6f72 6974 686d  elated algorithm
+000035b0: 732e 0a20 202a 0a20 202a 2054 6865 2062  s..  *.  * The b
+000035c0: 6c6f 636b 696e 6720 7369 7a65 2070 6172  locking size par
+000035d0: 616d 6574 6572 7320 6d61 7920 6265 2065  ameters may be e
+000035e0: 7661 6c75 6174 6564 3a0a 2020 2a20 2020  valuated:.  *   
+000035f0: 2d20 6569 7468 6572 2062 7920 6120 6865  - either by a he
+00003600: 7572 6973 7469 6320 6261 7365 6420 6f6e  uristic based on
+00003610: 2063 6163 6865 2073 697a 6573 3b0a 2020   cache sizes;.  
+00003620: 2a20 2020 2d20 6f72 2075 7369 6e67 2066  *   - or using f
+00003630: 6978 6564 2070 7265 7363 7269 6265 6420  ixed prescribed 
+00003640: 7661 6c75 6573 2028 666f 7220 7465 7374  values (for test
+00003650: 696e 6720 7075 7270 6f73 6573 292e 0a20  ing purposes).. 
+00003660: 202a 0a20 202a 205c 7361 2073 6574 4370   *.  * \sa setCp
+00003670: 7543 6163 6865 5369 7a65 7320 2a2f 0a0a  uCacheSizes */..
+00003680: 7465 6d70 6c61 7465 3c74 7970 656e 616d  template<typenam
+00003690: 6520 4c68 7353 6361 6c61 722c 2074 7970  e LhsScalar, typ
+000036a0: 656e 616d 6520 5268 7353 6361 6c61 722c  ename RhsScalar,
+000036b0: 2069 6e74 204b 6346 6163 746f 722c 2074   int KcFactor, t
+000036c0: 7970 656e 616d 6520 496e 6465 783e 0a76  ypename Index>.v
+000036d0: 6f69 6420 636f 6d70 7574 6550 726f 6475  oid computeProdu
+000036e0: 6374 426c 6f63 6b69 6e67 5369 7a65 7328  ctBlockingSizes(
+000036f0: 496e 6465 7826 206b 2c20 496e 6465 7826  Index& k, Index&
+00003700: 206d 2c20 496e 6465 7826 206e 2c20 496e   m, Index& n, In
+00003710: 6465 7820 6e75 6d5f 7468 7265 6164 7320  dex num_threads 
+00003720: 3d20 3129 0a7b 0a20 2069 6620 2821 7573  = 1).{.  if (!us
+00003730: 6553 7065 6369 6669 6342 6c6f 636b 696e  eSpecificBlockin
+00003740: 6753 697a 6573 286b 2c20 6d2c 206e 2929  gSizes(k, m, n))
+00003750: 207b 0a20 2020 2065 7661 6c75 6174 6550   {.    evaluateP
+00003760: 726f 6475 6374 426c 6f63 6b69 6e67 5369  roductBlockingSi
+00003770: 7a65 7348 6575 7269 7374 6963 3c4c 6873  zesHeuristic<Lhs
+00003780: 5363 616c 6172 2c20 5268 7353 6361 6c61  Scalar, RhsScala
+00003790: 722c 204b 6346 6163 746f 722c 2049 6e64  r, KcFactor, Ind
+000037a0: 6578 3e28 6b2c 206d 2c20 6e2c 206e 756d  ex>(k, m, n, num
+000037b0: 5f74 6872 6561 6473 293b 0a20 207d 0a7d  _threads);.  }.}
+000037c0: 0a0a 7465 6d70 6c61 7465 3c74 7970 656e  ..template<typen
+000037d0: 616d 6520 4c68 7353 6361 6c61 722c 2074  ame LhsScalar, t
+000037e0: 7970 656e 616d 6520 5268 7353 6361 6c61  ypename RhsScala
+000037f0: 722c 2074 7970 656e 616d 6520 496e 6465  r, typename Inde
+00003800: 783e 0a69 6e6c 696e 6520 766f 6964 2063  x>.inline void c
+00003810: 6f6d 7075 7465 5072 6f64 7563 7442 6c6f  omputeProductBlo
+00003820: 636b 696e 6753 697a 6573 2849 6e64 6578  ckingSizes(Index
+00003830: 2620 6b2c 2049 6e64 6578 2620 6d2c 2049  & k, Index& m, I
+00003840: 6e64 6578 2620 6e2c 2049 6e64 6578 206e  ndex& n, Index n
+00003850: 756d 5f74 6872 6561 6473 203d 2031 290a  um_threads = 1).
+00003860: 7b0a 2020 636f 6d70 7574 6550 726f 6475  {.  computeProdu
+00003870: 6374 426c 6f63 6b69 6e67 5369 7a65 733c  ctBlockingSizes<
+00003880: 4c68 7353 6361 6c61 722c 5268 7353 6361  LhsScalar,RhsSca
+00003890: 6c61 722c 312c 496e 6465 783e 286b 2c20  lar,1,Index>(k, 
+000038a0: 6d2c 206e 2c20 6e75 6d5f 7468 7265 6164  m, n, num_thread
+000038b0: 7329 3b0a 7d0a 0a74 656d 706c 6174 6520  s);.}..template 
+000038c0: 3c74 7970 656e 616d 6520 5268 7350 6163  <typename RhsPac
+000038d0: 6b65 742c 2074 7970 656e 616d 6520 5268  ket, typename Rh
+000038e0: 7350 6163 6b65 7478 342c 2069 6e74 2072  sPacketx4, int r
+000038f0: 6567 6973 7465 7273 5f74 616b 656e 3e0a  egisters_taken>.
+00003900: 7374 7275 6374 2052 6873 5061 6e65 6c48  struct RhsPanelH
+00003910: 656c 7065 7220 7b0a 2070 7269 7661 7465  elper {. private
+00003920: 3a0a 2020 7374 6174 6963 2063 6f6e 7374  :.  static const
+00003930: 2069 6e74 2072 656d 6169 6e69 6e67 5f72   int remaining_r
+00003940: 6567 6973 7465 7273 203d 2045 4947 454e  egisters = EIGEN
+00003950: 5f41 5243 485f 4445 4641 554c 545f 4e55  _ARCH_DEFAULT_NU
+00003960: 4d42 4552 5f4f 465f 5245 4749 5354 4552  MBER_OF_REGISTER
+00003970: 5320 2d20 7265 6769 7374 6572 735f 7461  S - registers_ta
+00003980: 6b65 6e3b 0a20 7075 626c 6963 3a0a 2020  ken;. public:.  
+00003990: 7479 7065 6465 6620 7479 7065 6e61 6d65  typedef typename
+000039a0: 2063 6f6e 6469 7469 6f6e 616c 3c72 656d   conditional<rem
+000039b0: 6169 6e69 6e67 5f72 6567 6973 7465 7273  aining_registers
+000039c0: 3e3d 342c 2052 6873 5061 636b 6574 7834  >=4, RhsPacketx4
+000039d0: 2c20 5268 7350 6163 6b65 743e 3a3a 7479  , RhsPacket>::ty
+000039e0: 7065 2074 7970 653b 0a7d 3b0a 0a74 656d  pe type;.};..tem
+000039f0: 706c 6174 6520 3c74 7970 656e 616d 6520  plate <typename 
+00003a00: 5061 636b 6574 3e0a 7374 7275 6374 2051  Packet>.struct Q
+00003a10: 7561 6450 6163 6b65 740a 7b0a 2020 5061  uadPacket.{.  Pa
+00003a20: 636b 6574 2042 5f30 2c20 4231 2c20 4232  cket B_0, B1, B2
+00003a30: 2c20 4233 3b0a 2020 636f 6e73 7420 5061  , B3;.  const Pa
+00003a40: 636b 6574 2620 6765 7428 636f 6e73 7420  cket& get(const 
+00003a50: 4669 7865 6449 6e74 3c30 3e26 2920 636f  FixedInt<0>&) co
+00003a60: 6e73 7420 7b20 7265 7475 726e 2042 5f30  nst { return B_0
+00003a70: 3b20 7d0a 2020 636f 6e73 7420 5061 636b  ; }.  const Pack
+00003a80: 6574 2620 6765 7428 636f 6e73 7420 4669  et& get(const Fi
+00003a90: 7865 6449 6e74 3c31 3e26 2920 636f 6e73  xedInt<1>&) cons
+00003aa0: 7420 7b20 7265 7475 726e 2042 313b 207d  t { return B1; }
+00003ab0: 0a20 2063 6f6e 7374 2050 6163 6b65 7426  .  const Packet&
+00003ac0: 2067 6574 2863 6f6e 7374 2046 6978 6564   get(const Fixed
+00003ad0: 496e 743c 323e 2629 2063 6f6e 7374 207b  Int<2>&) const {
+00003ae0: 2072 6574 7572 6e20 4232 3b20 7d0a 2020   return B2; }.  
+00003af0: 636f 6e73 7420 5061 636b 6574 2620 6765  const Packet& ge
+00003b00: 7428 636f 6e73 7420 4669 7865 6449 6e74  t(const FixedInt
+00003b10: 3c33 3e26 2920 636f 6e73 7420 7b20 7265  <3>&) const { re
+00003b20: 7475 726e 2042 333b 207d 0a7d 3b0a 0a74  turn B3; }.};..t
+00003b30: 656d 706c 6174 6520 3c69 6e74 204e 2c20  emplate <int N, 
+00003b40: 7479 7065 6e61 6d65 2054 312c 2074 7970  typename T1, typ
+00003b50: 656e 616d 6520 5432 2c20 7479 7065 6e61  ename T2, typena
+00003b60: 6d65 2054 333e 0a73 7472 7563 7420 7061  me T3>.struct pa
+00003b70: 636b 6574 5f63 6f6e 6469 7469 6f6e 616c  cket_conditional
+00003b80: 207b 2074 7970 6564 6566 2054 3320 7479   { typedef T3 ty
+00003b90: 7065 3b20 7d3b 0a0a 7465 6d70 6c61 7465  pe; };..template
+00003ba0: 203c 7479 7065 6e61 6d65 2054 312c 2074   <typename T1, t
+00003bb0: 7970 656e 616d 6520 5432 2c20 7479 7065  ypename T2, type
+00003bc0: 6e61 6d65 2054 333e 0a73 7472 7563 7420  name T3>.struct 
+00003bd0: 7061 636b 6574 5f63 6f6e 6469 7469 6f6e  packet_condition
+00003be0: 616c 3c47 4542 5050 6163 6b65 7446 756c  al<GEBPPacketFul
+00003bf0: 6c2c 2054 312c 2054 322c 2054 333e 207b  l, T1, T2, T3> {
+00003c00: 2074 7970 6564 6566 2054 3120 7479 7065   typedef T1 type
+00003c10: 3b20 7d3b 0a0a 7465 6d70 6c61 7465 203c  ; };..template <
+00003c20: 7479 7065 6e61 6d65 2054 312c 2074 7970  typename T1, typ
+00003c30: 656e 616d 6520 5432 2c20 7479 7065 6e61  ename T2, typena
+00003c40: 6d65 2054 333e 0a73 7472 7563 7420 7061  me T3>.struct pa
+00003c50: 636b 6574 5f63 6f6e 6469 7469 6f6e 616c  cket_conditional
+00003c60: 3c47 4542 5050 6163 6b65 7448 616c 662c  <GEBPPacketHalf,
+00003c70: 2054 312c 2054 322c 2054 333e 207b 2074   T1, T2, T3> { t
+00003c80: 7970 6564 6566 2054 3220 7479 7065 3b20  ypedef T2 type; 
+00003c90: 7d3b 0a0a 2364 6566 696e 6520 5041 434b  };..#define PACK
+00003ca0: 4554 5f44 4543 4c5f 434f 4e44 5f50 5245  ET_DECL_COND_PRE
+00003cb0: 4649 5828 7072 6566 6978 2c20 6e61 6d65  FIX(prefix, name
+00003cc0: 2c20 7061 636b 6574 5f73 697a 6529 2020  , packet_size)  
+00003cd0: 2020 2020 2020 205c 0a20 2074 7970 6564         \.  typed
+00003ce0: 6566 2074 7970 656e 616d 6520 7061 636b  ef typename pack
+00003cf0: 6574 5f63 6f6e 6469 7469 6f6e 616c 3c70  et_conditional<p
+00003d00: 6163 6b65 745f 7369 7a65 2c20 2020 2020  acket_size,     
+00003d10: 2020 2020 2020 2020 2020 2020 5c0a 2020              \.  
+00003d20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003d30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003d40: 2020 2020 7479 7065 6e61 6d65 2070 6163      typename pac
+00003d50: 6b65 745f 7472 6169 7473 3c6e 616d 6520  ket_traits<name 
+00003d60: 2323 2053 6361 6c61 723e 3a3a 7479 7065  ## Scalar>::type
+00003d70: 2c20 5c0a 2020 2020 2020 2020 2020 2020  , \.            
+00003d80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003d90: 2020 2020 2020 2020 2020 7479 7065 6e61            typena
+00003da0: 6d65 2070 6163 6b65 745f 7472 6169 7473  me packet_traits
+00003db0: 3c6e 616d 6520 2323 2053 6361 6c61 723e  <name ## Scalar>
+00003dc0: 3a3a 6861 6c66 2c20 5c0a 2020 2020 2020  ::half, \.      
+00003dd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003de0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003df0: 7479 7065 6e61 6d65 2075 6e70 6163 6b65  typename unpacke
+00003e00: 745f 7472 6169 7473 3c74 7970 656e 616d  t_traits<typenam
+00003e10: 6520 7061 636b 6574 5f74 7261 6974 733c  e packet_traits<
+00003e20: 6e61 6d65 2023 2320 5363 616c 6172 3e3a  name ## Scalar>:
+00003e30: 3a68 616c 663e 3a3a 6861 6c66 3e3a 3a74  :half>::half>::t
+00003e40: 7970 6520 5c0a 2020 7072 6566 6978 2023  ype \.  prefix #
+00003e50: 2320 6e61 6d65 2023 2320 5061 636b 6574  # name ## Packet
+00003e60: 0a0a 2364 6566 696e 6520 5041 434b 4554  ..#define PACKET
+00003e70: 5f44 4543 4c5f 434f 4e44 286e 616d 652c  _DECL_COND(name,
+00003e80: 2070 6163 6b65 745f 7369 7a65 2920 2020   packet_size)   
+00003e90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003ea0: 2020 2020 205c 0a20 2074 7970 6564 6566       \.  typedef
+00003eb0: 2074 7970 656e 616d 6520 7061 636b 6574   typename packet
+00003ec0: 5f63 6f6e 6469 7469 6f6e 616c 3c70 6163  _conditional<pac
+00003ed0: 6b65 745f 7369 7a65 2c20 2020 2020 2020  ket_size,       
+00003ee0: 2020 2020 2020 2020 2020 5c0a 2020 2020            \.    
+00003ef0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003f00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003f10: 2020 7479 7065 6e61 6d65 2070 6163 6b65    typename packe
+00003f20: 745f 7472 6169 7473 3c6e 616d 6520 2323  t_traits<name ##
+00003f30: 2053 6361 6c61 723e 3a3a 7479 7065 2c20   Scalar>::type, 
+00003f40: 5c0a 2020 2020 2020 2020 2020 2020 2020  \.              
+00003f50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003f60: 2020 2020 2020 2020 7479 7065 6e61 6d65          typename
+00003f70: 2070 6163 6b65 745f 7472 6169 7473 3c6e   packet_traits<n
+00003f80: 616d 6520 2323 2053 6361 6c61 723e 3a3a  ame ## Scalar>::
+00003f90: 6861 6c66 2c20 5c0a 2020 2020 2020 2020  half, \.        
+00003fa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003fb0: 2020 2020 2020 2020 2020 2020 2020 7479                ty
+00003fc0: 7065 6e61 6d65 2075 6e70 6163 6b65 745f  pename unpacket_
+00003fd0: 7472 6169 7473 3c74 7970 656e 616d 6520  traits<typename 
+00003fe0: 7061 636b 6574 5f74 7261 6974 733c 6e61  packet_traits<na
+00003ff0: 6d65 2023 2320 5363 616c 6172 3e3a 3a68  me ## Scalar>::h
+00004000: 616c 663e 3a3a 6861 6c66 3e3a 3a74 7970  alf>::half>::typ
+00004010: 6520 5c0a 2020 6e61 6d65 2023 2320 5061  e \.  name ## Pa
+00004020: 636b 6574 0a0a 2364 6566 696e 6520 5041  cket..#define PA
+00004030: 434b 4554 5f44 4543 4c5f 434f 4e44 5f53  CKET_DECL_COND_S
+00004040: 4341 4c41 525f 5052 4546 4958 2870 7265  CALAR_PREFIX(pre
+00004050: 6669 782c 2070 6163 6b65 745f 7369 7a65  fix, packet_size
+00004060: 2920 2020 2020 2020 205c 0a20 2074 7970  )        \.  typ
+00004070: 6564 6566 2074 7970 656e 616d 6520 7061  edef typename pa
+00004080: 636b 6574 5f63 6f6e 6469 7469 6f6e 616c  cket_conditional
+00004090: 3c70 6163 6b65 745f 7369 7a65 2c20 2020  <packet_size,   
+000040a0: 2020 2020 2020 2020 2020 2020 2020 5c0a                \.
+000040b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
 000040c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000040d0: 2020 2020 2020 2020 2020 2020 7479 7065              type
-000040e0: 6e61 6d65 2070 6163 6b65 745f 7472 6169  name packet_trai
-000040f0: 7473 3c6e 616d 6520 2323 2053 6361 6c61  ts<name ## Scala
-00004100: 723e 3a3a 6861 6c66 2c20 5c0a 2020 2020  r>::half, \.    
+000040d0: 2020 2020 2020 7479 7065 6e61 6d65 2070        typename p
+000040e0: 6163 6b65 745f 7472 6169 7473 3c53 6361  acket_traits<Sca
+000040f0: 6c61 723e 3a3a 7479 7065 2c20 5c0a 2020  lar>::type, \.  
+00004100: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00004110: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004120: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004130: 2020 7479 7065 6e61 6d65 2075 6e70 6163    typename unpac
-00004140: 6b65 745f 7472 6169 7473 3c74 7970 656e  ket_traits<typen
-00004150: 616d 6520 7061 636b 6574 5f74 7261 6974  ame packet_trait
-00004160: 733c 6e61 6d65 2023 2320 5363 616c 6172  s<name ## Scalar
-00004170: 3e3a 3a68 616c 663e 3a3a 6861 6c66 3e3a  >::half>::half>:
-00004180: 3a74 7970 6520 5c0a 2020 7072 6566 6978  :type \.  prefix
-00004190: 2023 2320 6e61 6d65 2023 2320 5061 636b   ## name ## Pack
-000041a0: 6574 0a0a 2364 6566 696e 6520 5041 434b  et..#define PACK
-000041b0: 4554 5f44 4543 4c5f 434f 4e44 286e 616d  ET_DECL_COND(nam
-000041c0: 652c 2070 6163 6b65 745f 7369 7a65 2920  e, packet_size) 
-000041d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000041e0: 2020 2020 2020 205c 0a20 2074 7970 6564         \.  typed
-000041f0: 6566 2074 7970 656e 616d 6520 7061 636b  ef typename pack
-00004200: 6574 5f63 6f6e 6469 7469 6f6e 616c 3c70  et_conditional<p
-00004210: 6163 6b65 745f 7369 7a65 2c20 2020 2020  acket_size,     
-00004220: 2020 2020 2020 2020 2020 2020 5c0a 2020              \.  
-00004230: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004240: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004250: 2020 2020 7479 7065 6e61 6d65 2070 6163      typename pac
-00004260: 6b65 745f 7472 6169 7473 3c6e 616d 6520  ket_traits<name 
-00004270: 2323 2053 6361 6c61 723e 3a3a 7479 7065  ## Scalar>::type
-00004280: 2c20 5c0a 2020 2020 2020 2020 2020 2020  , \.            
-00004290: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000042a0: 2020 2020 2020 2020 2020 7479 7065 6e61            typena
-000042b0: 6d65 2070 6163 6b65 745f 7472 6169 7473  me packet_traits
-000042c0: 3c6e 616d 6520 2323 2053 6361 6c61 723e  <name ## Scalar>
-000042d0: 3a3a 6861 6c66 2c20 5c0a 2020 2020 2020  ::half, \.      
-000042e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000042f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004300: 7479 7065 6e61 6d65 2075 6e70 6163 6b65  typename unpacke
-00004310: 745f 7472 6169 7473 3c74 7970 656e 616d  t_traits<typenam
-00004320: 6520 7061 636b 6574 5f74 7261 6974 733c  e packet_traits<
-00004330: 6e61 6d65 2023 2320 5363 616c 6172 3e3a  name ## Scalar>:
-00004340: 3a68 616c 663e 3a3a 6861 6c66 3e3a 3a74  :half>::half>::t
-00004350: 7970 6520 5c0a 2020 6e61 6d65 2023 2320  ype \.  name ## 
-00004360: 5061 636b 6574 0a0a 2364 6566 696e 6520  Packet..#define 
-00004370: 5041 434b 4554 5f44 4543 4c5f 434f 4e44  PACKET_DECL_COND
-00004380: 5f53 4341 4c41 525f 5052 4546 4958 2870  _SCALAR_PREFIX(p
-00004390: 7265 6669 782c 2070 6163 6b65 745f 7369  refix, packet_si
-000043a0: 7a65 2920 2020 2020 2020 205c 0a20 2074  ze)        \.  t
-000043b0: 7970 6564 6566 2074 7970 656e 616d 6520  ypedef typename 
-000043c0: 7061 636b 6574 5f63 6f6e 6469 7469 6f6e  packet_condition
-000043d0: 616c 3c70 6163 6b65 745f 7369 7a65 2c20  al<packet_size, 
-000043e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000043f0: 5c0a 2020 2020 2020 2020 2020 2020 2020  \.              
-00004400: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004410: 2020 2020 2020 2020 7479 7065 6e61 6d65          typename
-00004420: 2070 6163 6b65 745f 7472 6169 7473 3c53   packet_traits<S
-00004430: 6361 6c61 723e 3a3a 7479 7065 2c20 5c0a  calar>::type, \.
-00004440: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004450: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004460: 2020 2020 2020 7479 7065 6e61 6d65 2070        typename p
-00004470: 6163 6b65 745f 7472 6169 7473 3c53 6361  acket_traits<Sca
-00004480: 6c61 723e 3a3a 6861 6c66 2c20 5c0a 2020  lar>::half, \.  
-00004490: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000044a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000044b0: 2020 2020 7479 7065 6e61 6d65 2075 6e70      typename unp
-000044c0: 6163 6b65 745f 7472 6169 7473 3c74 7970  acket_traits<typ
-000044d0: 656e 616d 6520 7061 636b 6574 5f74 7261  ename packet_tra
-000044e0: 6974 733c 5363 616c 6172 3e3a 3a68 616c  its<Scalar>::hal
-000044f0: 663e 3a3a 6861 6c66 3e3a 3a74 7970 6520  f>::half>::type 
-00004500: 5c0a 2020 7072 6566 6978 2023 2320 5363  \.  prefix ## Sc
-00004510: 616c 6172 5061 636b 6574 0a0a 2364 6566  alarPacket..#def
-00004520: 696e 6520 5041 434b 4554 5f44 4543 4c5f  ine PACKET_DECL_
-00004530: 434f 4e44 5f53 4341 4c41 5228 7061 636b  COND_SCALAR(pack
-00004540: 6574 5f73 697a 6529 2020 2020 2020 2020  et_size)        
-00004550: 2020 2020 2020 2020 2020 2020 2020 205c                 \
-00004560: 0a20 2074 7970 6564 6566 2074 7970 656e  .  typedef typen
-00004570: 616d 6520 7061 636b 6574 5f63 6f6e 6469  ame packet_condi
-00004580: 7469 6f6e 616c 3c70 6163 6b65 745f 7369  tional<packet_si
-00004590: 7a65 2c20 2020 2020 2020 2020 2020 2020  ze,             
-000045a0: 2020 2020 5c0a 2020 2020 2020 2020 2020      \.          
-000045b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000045c0: 2020 2020 2020 2020 2020 2020 7479 7065              type
-000045d0: 6e61 6d65 2070 6163 6b65 745f 7472 6169  name packet_trai
-000045e0: 7473 3c53 6361 6c61 723e 3a3a 7479 7065  ts<Scalar>::type
-000045f0: 2c20 5c0a 2020 2020 2020 2020 2020 2020  , \.            
-00004600: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004610: 2020 2020 2020 2020 2020 7479 7065 6e61            typena
-00004620: 6d65 2070 6163 6b65 745f 7472 6169 7473  me packet_traits
-00004630: 3c53 6361 6c61 723e 3a3a 6861 6c66 2c20  <Scalar>::half, 
-00004640: 5c0a 2020 2020 2020 2020 2020 2020 2020  \.              
-00004650: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004660: 2020 2020 2020 2020 7479 7065 6e61 6d65          typename
-00004670: 2075 6e70 6163 6b65 745f 7472 6169 7473   unpacket_traits
-00004680: 3c74 7970 656e 616d 6520 7061 636b 6574  <typename packet
-00004690: 5f74 7261 6974 733c 5363 616c 6172 3e3a  _traits<Scalar>:
-000046a0: 3a68 616c 663e 3a3a 6861 6c66 3e3a 3a74  :half>::half>::t
-000046b0: 7970 6520 5c0a 2020 5363 616c 6172 5061  ype \.  ScalarPa
-000046c0: 636b 6574 0a0a 2f2a 2056 6563 746f 7269  cket../* Vectori
-000046d0: 7a61 7469 6f6e 206c 6f67 6963 0a20 2a20  zation logic. * 
-000046e0: 2072 6561 6c2a 7265 616c 3a20 756e 7061   real*real: unpa
-000046f0: 636b 2072 6873 2074 6f20 636f 6e73 7461  ck rhs to consta
-00004700: 6e74 2070 6163 6b65 7473 2c20 2e2e 2e0a  nt packets, ....
-00004710: 202a 200a 202a 2020 6364 2a63 6420 3a20   * . *  cd*cd : 
-00004720: 756e 7061 636b 2072 6873 2074 6f20 2862  unpack rhs to (b
-00004730: 5f72 2c62 5f72 292c 2028 625f 692c 625f  _r,b_r), (b_i,b_
-00004740: 6929 2c20 6d75 6c20 746f 2067 6574 2028  i), mul to get (
-00004750: 615f 7220 625f 722c 615f 6920 625f 7229  a_r b_r,a_i b_r)
-00004760: 2028 615f 7220 625f 692c 615f 6920 625f   (a_r b_i,a_i b_
-00004770: 6929 2c0a 202a 2020 2020 2020 2020 2020  i),. *          
-00004780: 7374 6f72 696e 6720 6561 6368 2072 6573  storing each res
-00004790: 2070 6163 6b65 7420 696e 746f 2074 776f   packet into two
-000047a0: 2070 6163 6b65 7473 2028 3278 3229 2c0a   packets (2x2),.
-000047b0: 202a 2020 2020 2020 2020 2020 6174 2074   *          at t
-000047c0: 6865 2065 6e64 2063 6f6d 6269 6e65 2074  he end combine t
-000047d0: 6865 6d3a 2073 7761 7020 7468 6520 7365  hem: swap the se
-000047e0: 636f 6e64 2061 6e64 2061 6464 7375 6220  cond and addsub 
-000047f0: 7468 656d 200a 202a 2020 6366 2a63 6620  them . *  cf*cf 
-00004800: 3a20 7361 6d65 2062 7574 2077 6974 6820  : same but with 
-00004810: 3278 3420 626c 6f63 6b73 0a20 2a20 2063  2x4 blocks. *  c
-00004820: 706c 782a 7265 616c 203a 2075 6e70 6163  plx*real : unpac
-00004830: 6b20 7268 7320 746f 2063 6f6e 7374 616e  k rhs to constan
-00004840: 7420 7061 636b 6574 732c 202e 2e2e 0a20  t packets, .... 
-00004850: 2a20 2072 6561 6c2a 6370 6c78 203a 206c  *  real*cplx : l
-00004860: 6f61 6420 6c68 7320 6173 2028 6130 2c61  oad lhs as (a0,a
-00004870: 302c 6131 2c61 3129 2c20 616e 6420 6d75  0,a1,a1), and mu
-00004880: 6c20 6173 2075 7375 616c 0a20 2a2f 0a74  l as usual. */.t
-00004890: 656d 706c 6174 653c 7479 7065 6e61 6d65  emplate<typename
-000048a0: 205f 4c68 7353 6361 6c61 722c 2074 7970   _LhsScalar, typ
-000048b0: 656e 616d 6520 5f52 6873 5363 616c 6172  ename _RhsScalar
-000048c0: 2c20 626f 6f6c 205f 436f 6e6a 4c68 732c  , bool _ConjLhs,
-000048d0: 2062 6f6f 6c20 5f43 6f6e 6a52 6873 2c20   bool _ConjRhs, 
-000048e0: 696e 7420 4172 6368 2c20 696e 7420 5f50  int Arch, int _P
-000048f0: 6163 6b65 7453 697a 653e 0a63 6c61 7373  acketSize>.class
-00004900: 2067 6562 705f 7472 6169 7473 0a7b 0a70   gebp_traits.{.p
-00004910: 7562 6c69 633a 0a20 2074 7970 6564 6566  ublic:.  typedef
-00004920: 205f 4c68 7353 6361 6c61 7220 4c68 7353   _LhsScalar LhsS
-00004930: 6361 6c61 723b 0a20 2074 7970 6564 6566  calar;.  typedef
-00004940: 205f 5268 7353 6361 6c61 7220 5268 7353   _RhsScalar RhsS
-00004950: 6361 6c61 723b 0a20 2074 7970 6564 6566  calar;.  typedef
-00004960: 2074 7970 656e 616d 6520 5363 616c 6172   typename Scalar
-00004970: 4269 6e61 7279 4f70 5472 6169 7473 3c4c  BinaryOpTraits<L
-00004980: 6873 5363 616c 6172 2c20 5268 7353 6361  hsScalar, RhsSca
-00004990: 6c61 723e 3a3a 5265 7475 726e 5479 7065  lar>::ReturnType
-000049a0: 2052 6573 5363 616c 6172 3b0a 0a20 2050   ResScalar;..  P
-000049b0: 4143 4b45 545f 4445 434c 5f43 4f4e 445f  ACKET_DECL_COND_
-000049c0: 5052 4546 4958 285f 2c20 4c68 732c 205f  PREFIX(_, Lhs, _
-000049d0: 5061 636b 6574 5369 7a65 293b 0a20 2050  PacketSize);.  P
-000049e0: 4143 4b45 545f 4445 434c 5f43 4f4e 445f  ACKET_DECL_COND_
-000049f0: 5052 4546 4958 285f 2c20 5268 732c 205f  PREFIX(_, Rhs, _
-00004a00: 5061 636b 6574 5369 7a65 293b 0a20 2050  PacketSize);.  P
-00004a10: 4143 4b45 545f 4445 434c 5f43 4f4e 445f  ACKET_DECL_COND_
-00004a20: 5052 4546 4958 285f 2c20 5265 732c 205f  PREFIX(_, Res, _
-00004a30: 5061 636b 6574 5369 7a65 293b 0a0a 2020  PacketSize);..  
-00004a40: 656e 756d 207b 0a20 2020 2043 6f6e 6a4c  enum {.    ConjL
-00004a50: 6873 203d 205f 436f 6e6a 4c68 732c 0a20  hs = _ConjLhs,. 
-00004a60: 2020 2043 6f6e 6a52 6873 203d 205f 436f     ConjRhs = _Co
-00004a70: 6e6a 5268 732c 0a20 2020 2056 6563 746f  njRhs,.    Vecto
-00004a80: 7269 7a61 626c 6520 3d20 756e 7061 636b  rizable = unpack
-00004a90: 6574 5f74 7261 6974 733c 5f4c 6873 5061  et_traits<_LhsPa
-00004aa0: 636b 6574 3e3a 3a76 6563 746f 7269 7a61  cket>::vectoriza
-00004ab0: 626c 6520 2626 2075 6e70 6163 6b65 745f  ble && unpacket_
-00004ac0: 7472 6169 7473 3c5f 5268 7350 6163 6b65  traits<_RhsPacke
-00004ad0: 743e 3a3a 7665 6374 6f72 697a 6162 6c65  t>::vectorizable
-00004ae0: 2c0a 2020 2020 4c68 7350 6163 6b65 7453  ,.    LhsPacketS
-00004af0: 697a 6520 3d20 5665 6374 6f72 697a 6162  ize = Vectorizab
-00004b00: 6c65 203f 2075 6e70 6163 6b65 745f 7472  le ? unpacket_tr
-00004b10: 6169 7473 3c5f 4c68 7350 6163 6b65 743e  aits<_LhsPacket>
-00004b20: 3a3a 7369 7a65 203a 2031 2c0a 2020 2020  ::size : 1,.    
-00004b30: 5268 7350 6163 6b65 7453 697a 6520 3d20  RhsPacketSize = 
-00004b40: 5665 6374 6f72 697a 6162 6c65 203f 2075  Vectorizable ? u
-00004b50: 6e70 6163 6b65 745f 7472 6169 7473 3c5f  npacket_traits<_
-00004b60: 5268 7350 6163 6b65 743e 3a3a 7369 7a65  RhsPacket>::size
-00004b70: 203a 2031 2c0a 2020 2020 5265 7350 6163   : 1,.    ResPac
-00004b80: 6b65 7453 697a 6520 3d20 5665 6374 6f72  ketSize = Vector
-00004b90: 697a 6162 6c65 203f 2075 6e70 6163 6b65  izable ? unpacke
-00004ba0: 745f 7472 6169 7473 3c5f 5265 7350 6163  t_traits<_ResPac
-00004bb0: 6b65 743e 3a3a 7369 7a65 203a 2031 2c0a  ket>::size : 1,.
-00004bc0: 2020 2020 0a20 2020 204e 756d 6265 724f      .    NumberO
-00004bd0: 6652 6567 6973 7465 7273 203d 2045 4947  fRegisters = EIG
-00004be0: 454e 5f41 5243 485f 4445 4641 554c 545f  EN_ARCH_DEFAULT_
-00004bf0: 4e55 4d42 4552 5f4f 465f 5245 4749 5354  NUMBER_OF_REGIST
-00004c00: 4552 532c 0a0a 2020 2020 2f2f 2072 6567  ERS,..    // reg
-00004c10: 6973 7465 7220 626c 6f63 6b20 7369 7a65  ister block size
-00004c20: 2061 6c6f 6e67 2074 6865 204e 2064 6972   along the N dir
-00004c30: 6563 7469 6f6e 206d 7573 7420 6265 2031  ection must be 1
-00004c40: 206f 7220 340a 2020 2020 6e72 203d 2034   or 4.    nr = 4
-00004c50: 2c0a 0a20 2020 202f 2f20 7265 6769 7374  ,..    // regist
-00004c60: 6572 2062 6c6f 636b 2073 697a 6520 616c  er block size al
-00004c70: 6f6e 6720 7468 6520 4d20 6469 7265 6374  ong the M direct
-00004c80: 696f 6e20 2863 7572 7265 6e74 6c79 2c20  ion (currently, 
-00004c90: 7468 6973 206f 6e65 2063 616e 6e6f 7420  this one cannot 
-00004ca0: 6265 206d 6f64 6966 6965 6429 0a20 2020  be modified).   
-00004cb0: 2064 6566 6175 6c74 5f6d 7220 3d20 2845   default_mr = (E
-00004cc0: 4947 454e 5f50 4c41 494e 5f45 4e55 4d5f  IGEN_PLAIN_ENUM_
-00004cd0: 4d49 4e28 3136 2c4e 756d 6265 724f 6652  MIN(16,NumberOfR
-00004ce0: 6567 6973 7465 7273 292f 322f 6e72 292a  egisters)/2/nr)*
-00004cf0: 4c68 7350 6163 6b65 7453 697a 652c 0a23  LhsPacketSize,.#
-00004d00: 6966 2064 6566 696e 6564 2845 4947 454e  if defined(EIGEN
-00004d10: 5f48 4153 5f53 494e 474c 455f 494e 5354  _HAS_SINGLE_INST
-00004d20: 5255 4354 494f 4e5f 4d41 4444 2920 2626  RUCTION_MADD) &&
-00004d30: 2021 6465 6669 6e65 6428 4549 4745 4e5f   !defined(EIGEN_
-00004d40: 5645 4354 4f52 495a 455f 414c 5449 5645  VECTORIZE_ALTIVE
-00004d50: 4329 2026 2620 2164 6566 696e 6564 2845  C) && !defined(E
-00004d60: 4947 454e 5f56 4543 544f 5249 5a45 5f56  IGEN_VECTORIZE_V
-00004d70: 5358 2920 5c0a 2020 2020 2626 2028 2821  SX) \.    && ((!
-00004d80: 4549 4745 4e5f 434f 4d50 5f4d 5356 4329  EIGEN_COMP_MSVC)
-00004d90: 207c 7c20 2845 4947 454e 5f43 4f4d 505f   || (EIGEN_COMP_
-00004da0: 4d53 5643 3e3d 3139 3134 2929 0a20 2020  MSVC>=1914)).   
-00004db0: 202f 2f20 7765 2061 7373 756d 6520 3136   // we assume 16
-00004dc0: 2072 6567 6973 7465 7273 206f 7220 6d6f   registers or mo
-00004dd0: 7265 0a20 2020 202f 2f20 5365 6520 6275  re.    // See bu
-00004de0: 6720 3939 322c 2069 6620 7468 6520 7363  g 992, if the sc
-00004df0: 616c 6172 2074 7970 6520 6973 206e 6f74  alar type is not
-00004e00: 2076 6563 746f 7269 7a61 626c 6520 6275   vectorizable bu
-00004e10: 7420 7468 6174 2045 4947 454e 5f48 4153  t that EIGEN_HAS
-00004e20: 5f53 494e 474c 455f 494e 5354 5255 4354  _SINGLE_INSTRUCT
-00004e30: 494f 4e5f 4d41 4444 2069 7320 6465 6669  ION_MADD is defi
-00004e40: 6e65 642c 0a20 2020 202f 2f20 7468 656e  ned,.    // then
-00004e50: 2075 7369 6e67 2033 2a4c 6873 5061 636b   using 3*LhsPack
-00004e60: 6574 5369 7a65 2074 7269 6767 6572 7320  etSize triggers 
-00004e70: 6e6f 6e2d 696d 706c 656d 656e 7465 6420  non-implemented 
-00004e80: 7061 7468 7320 696e 2073 7972 6b2e 0a20  paths in syrk.. 
-00004e90: 2020 202f 2f20 4275 6720 3135 3135 3a20     // Bug 1515: 
-00004ea0: 4d53 5643 2070 7269 6f72 2074 6f20 7631  MSVC prior to v1
-00004eb0: 392e 3134 2079 6965 6c64 7320 746f 2072  9.14 yields to r
-00004ec0: 6567 6973 7465 7220 7370 696c 6c69 6e67  egister spilling
-00004ed0: 2e0a 2020 2020 6d72 203d 2056 6563 746f  ..    mr = Vecto
-00004ee0: 7269 7a61 626c 6520 3f20 332a 4c68 7350  rizable ? 3*LhsP
-00004ef0: 6163 6b65 7453 697a 6520 3a20 6465 6661  acketSize : defa
-00004f00: 756c 745f 6d72 2c0a 2365 6c73 650a 2020  ult_mr,.#else.  
-00004f10: 2020 6d72 203d 2064 6566 6175 6c74 5f6d    mr = default_m
-00004f20: 722c 0a23 656e 6469 660a 2020 2020 0a20  r,.#endif.    . 
-00004f30: 2020 204c 6873 5072 6f67 7265 7373 203d     LhsProgress =
-00004f40: 204c 6873 5061 636b 6574 5369 7a65 2c0a   LhsPacketSize,.
-00004f50: 2020 2020 5268 7350 726f 6772 6573 7320      RhsProgress 
-00004f60: 3d20 310a 2020 7d3b 0a0a 0a20 2074 7970  = 1.  };...  typ
-00004f70: 6564 6566 2074 7970 656e 616d 6520 636f  edef typename co
-00004f80: 6e64 6974 696f 6e61 6c3c 5665 6374 6f72  nditional<Vector
-00004f90: 697a 6162 6c65 2c5f 4c68 7350 6163 6b65  izable,_LhsPacke
-00004fa0: 742c 4c68 7353 6361 6c61 723e 3a3a 7479  t,LhsScalar>::ty
-00004fb0: 7065 204c 6873 5061 636b 6574 3b0a 2020  pe LhsPacket;.  
-00004fc0: 7479 7065 6465 6620 7479 7065 6e61 6d65  typedef typename
-00004fd0: 2063 6f6e 6469 7469 6f6e 616c 3c56 6563   conditional<Vec
-00004fe0: 746f 7269 7a61 626c 652c 5f52 6873 5061  torizable,_RhsPa
-00004ff0: 636b 6574 2c52 6873 5363 616c 6172 3e3a  cket,RhsScalar>:
-00005000: 3a74 7970 6520 5268 7350 6163 6b65 743b  :type RhsPacket;
-00005010: 0a20 2074 7970 6564 6566 2074 7970 656e  .  typedef typen
-00005020: 616d 6520 636f 6e64 6974 696f 6e61 6c3c  ame conditional<
-00005030: 5665 6374 6f72 697a 6162 6c65 2c5f 5265  Vectorizable,_Re
-00005040: 7350 6163 6b65 742c 5265 7353 6361 6c61  sPacket,ResScala
-00005050: 723e 3a3a 7479 7065 2052 6573 5061 636b  r>::type ResPack
-00005060: 6574 3b0a 2020 7479 7065 6465 6620 4c68  et;.  typedef Lh
-00005070: 7350 6163 6b65 7420 4c68 7350 6163 6b65  sPacket LhsPacke
-00005080: 7434 5061 636b 696e 673b 0a0a 2020 7479  t4Packing;..  ty
-00005090: 7065 6465 6620 5175 6164 5061 636b 6574  pedef QuadPacket
-000050a0: 3c52 6873 5061 636b 6574 3e20 5268 7350  <RhsPacket> RhsP
-000050b0: 6163 6b65 7478 343b 0a20 2074 7970 6564  acketx4;.  typed
-000050c0: 6566 2052 6573 5061 636b 6574 2041 6363  ef ResPacket Acc
-000050d0: 5061 636b 6574 3b0a 2020 0a20 2045 4947  Packet;.  .  EIG
-000050e0: 454e 5f53 5452 4f4e 475f 494e 4c49 4e45  EN_STRONG_INLINE
-000050f0: 2076 6f69 6420 696e 6974 4163 6328 4163   void initAcc(Ac
-00005100: 6350 6163 6b65 7426 2070 290a 2020 7b0a  cPacket& p).  {.
-00005110: 2020 2020 7020 3d20 7073 6574 313c 5265      p = pset1<Re
-00005120: 7350 6163 6b65 743e 2852 6573 5363 616c  sPacket>(ResScal
-00005130: 6172 2830 2929 3b0a 2020 7d0a 0a20 2074  ar(0));.  }..  t
-00005140: 656d 706c 6174 653c 7479 7065 6e61 6d65  emplate<typename
-00005150: 2052 6873 5061 636b 6574 5479 7065 3e0a   RhsPacketType>.
-00005160: 2020 4549 4745 4e5f 5354 524f 4e47 5f49    EIGEN_STRONG_I
-00005170: 4e4c 494e 4520 766f 6964 206c 6f61 6452  NLINE void loadR
-00005180: 6873 2863 6f6e 7374 2052 6873 5363 616c  hs(const RhsScal
-00005190: 6172 2a20 622c 2052 6873 5061 636b 6574  ar* b, RhsPacket
-000051a0: 5479 7065 2620 6465 7374 2920 636f 6e73  Type& dest) cons
-000051b0: 740a 2020 7b0a 2020 2020 6465 7374 203d  t.  {.    dest =
-000051c0: 2070 7365 7431 3c52 6873 5061 636b 6574   pset1<RhsPacket
-000051d0: 5479 7065 3e28 2a62 293b 0a20 207d 0a0a  Type>(*b);.  }..
-000051e0: 2020 4549 4745 4e5f 5354 524f 4e47 5f49    EIGEN_STRONG_I
-000051f0: 4e4c 494e 4520 766f 6964 206c 6f61 6452  NLINE void loadR
-00005200: 6873 2863 6f6e 7374 2052 6873 5363 616c  hs(const RhsScal
-00005210: 6172 2a20 622c 2052 6873 5061 636b 6574  ar* b, RhsPacket
-00005220: 7834 2620 6465 7374 2920 636f 6e73 740a  x4& dest) const.
-00005230: 2020 7b0a 2020 2020 7062 726f 6164 6361    {.    pbroadca
-00005240: 7374 3428 622c 2064 6573 742e 425f 302c  st4(b, dest.B_0,
-00005250: 2064 6573 742e 4231 2c20 6465 7374 2e42   dest.B1, dest.B
-00005260: 322c 2064 6573 742e 4233 293b 0a20 207d  2, dest.B3);.  }
-00005270: 0a0a 2020 7465 6d70 6c61 7465 3c74 7970  ..  template<typ
-00005280: 656e 616d 6520 5268 7350 6163 6b65 7454  ename RhsPacketT
-00005290: 7970 653e 0a20 2045 4947 454e 5f53 5452  ype>.  EIGEN_STR
-000052a0: 4f4e 475f 494e 4c49 4e45 2076 6f69 6420  ONG_INLINE void 
-000052b0: 7570 6461 7465 5268 7328 636f 6e73 7420  updateRhs(const 
-000052c0: 5268 7353 6361 6c61 722a 2062 2c20 5268  RhsScalar* b, Rh
-000052d0: 7350 6163 6b65 7454 7970 6526 2064 6573  sPacketType& des
-000052e0: 7429 2063 6f6e 7374 0a20 207b 0a20 2020  t) const.  {.   
-000052f0: 206c 6f61 6452 6873 2862 2c20 6465 7374   loadRhs(b, dest
-00005300: 293b 0a20 207d 0a0a 2020 4549 4745 4e5f  );.  }..  EIGEN_
-00005310: 5354 524f 4e47 5f49 4e4c 494e 4520 766f  STRONG_INLINE vo
-00005320: 6964 2075 7064 6174 6552 6873 2863 6f6e  id updateRhs(con
-00005330: 7374 2052 6873 5363 616c 6172 2a2c 2052  st RhsScalar*, R
-00005340: 6873 5061 636b 6574 7834 2629 2063 6f6e  hsPacketx4&) con
-00005350: 7374 0a20 207b 0a20 207d 0a0a 2020 4549  st.  {.  }..  EI
-00005360: 4745 4e5f 5354 524f 4e47 5f49 4e4c 494e  GEN_STRONG_INLIN
-00005370: 4520 766f 6964 206c 6f61 6452 6873 5175  E void loadRhsQu
-00005380: 6164 2863 6f6e 7374 2052 6873 5363 616c  ad(const RhsScal
-00005390: 6172 2a20 622c 2052 6873 5061 636b 6574  ar* b, RhsPacket
-000053a0: 2620 6465 7374 2920 636f 6e73 740a 2020  & dest) const.  
-000053b0: 7b0a 2020 2020 6465 7374 203d 2070 6c6f  {.    dest = plo
-000053c0: 6164 7175 6164 3c52 6873 5061 636b 6574  adquad<RhsPacket
-000053d0: 3e28 6229 3b0a 2020 7d0a 0a20 2074 656d  >(b);.  }..  tem
-000053e0: 706c 6174 653c 7479 7065 6e61 6d65 204c  plate<typename L
-000053f0: 6873 5061 636b 6574 5479 7065 3e0a 2020  hsPacketType>.  
-00005400: 4549 4745 4e5f 5354 524f 4e47 5f49 4e4c  EIGEN_STRONG_INL
-00005410: 494e 4520 766f 6964 206c 6f61 644c 6873  INE void loadLhs
-00005420: 2863 6f6e 7374 204c 6873 5363 616c 6172  (const LhsScalar
-00005430: 2a20 612c 204c 6873 5061 636b 6574 5479  * a, LhsPacketTy
-00005440: 7065 2620 6465 7374 2920 636f 6e73 740a  pe& dest) const.
-00005450: 2020 7b0a 2020 2020 6465 7374 203d 2070    {.    dest = p
-00005460: 6c6f 6164 3c4c 6873 5061 636b 6574 5479  load<LhsPacketTy
-00005470: 7065 3e28 6129 3b0a 2020 7d0a 0a20 2074  pe>(a);.  }..  t
-00005480: 656d 706c 6174 653c 7479 7065 6e61 6d65  emplate<typename
-00005490: 204c 6873 5061 636b 6574 5479 7065 3e0a   LhsPacketType>.
-000054a0: 2020 4549 4745 4e5f 5354 524f 4e47 5f49    EIGEN_STRONG_I
-000054b0: 4e4c 494e 4520 766f 6964 206c 6f61 644c  NLINE void loadL
-000054c0: 6873 556e 616c 6967 6e65 6428 636f 6e73  hsUnaligned(cons
-000054d0: 7420 4c68 7353 6361 6c61 722a 2061 2c20  t LhsScalar* a, 
-000054e0: 4c68 7350 6163 6b65 7454 7970 6526 2064  LhsPacketType& d
-000054f0: 6573 7429 2063 6f6e 7374 0a20 207b 0a20  est) const.  {. 
-00005500: 2020 2064 6573 7420 3d20 706c 6f61 6475     dest = ploadu
-00005510: 3c4c 6873 5061 636b 6574 5479 7065 3e28  <LhsPacketType>(
-00005520: 6129 3b0a 2020 7d0a 0a20 2074 656d 706c  a);.  }..  templ
-00005530: 6174 653c 7479 7065 6e61 6d65 204c 6873  ate<typename Lhs
-00005540: 5061 636b 6574 5479 7065 2c20 7479 7065  PacketType, type
-00005550: 6e61 6d65 2052 6873 5061 636b 6574 5479  name RhsPacketTy
-00005560: 7065 2c20 7479 7065 6e61 6d65 2041 6363  pe, typename Acc
-00005570: 5061 636b 6574 5479 7065 2c20 7479 7065  PacketType, type
-00005580: 6e61 6d65 204c 616e 6549 6454 7970 653e  name LaneIdType>
-00005590: 0a20 2045 4947 454e 5f53 5452 4f4e 475f  .  EIGEN_STRONG_
-000055a0: 494e 4c49 4e45 2076 6f69 6420 6d61 6464  INLINE void madd
-000055b0: 2863 6f6e 7374 204c 6873 5061 636b 6574  (const LhsPacket
-000055c0: 5479 7065 2620 612c 2063 6f6e 7374 2052  Type& a, const R
-000055d0: 6873 5061 636b 6574 5479 7065 2620 622c  hsPacketType& b,
-000055e0: 2041 6363 5061 636b 6574 5479 7065 2620   AccPacketType& 
-000055f0: 632c 2052 6873 5061 636b 6574 5479 7065  c, RhsPacketType
-00005600: 2620 746d 702c 2063 6f6e 7374 204c 616e  & tmp, const Lan
-00005610: 6549 6454 7970 6526 2920 636f 6e73 740a  eIdType&) const.
-00005620: 2020 7b0a 2020 2020 636f 6e6a 5f68 656c    {.    conj_hel
-00005630: 7065 723c 4c68 7350 6163 6b65 7454 7970  per<LhsPacketTyp
-00005640: 652c 5268 7350 6163 6b65 7454 7970 652c  e,RhsPacketType,
-00005650: 436f 6e6a 4c68 732c 436f 6e6a 5268 733e  ConjLhs,ConjRhs>
-00005660: 2063 6a3b 0a20 2020 202f 2f20 4974 2077   cj;.    // It w
-00005670: 6f75 6c64 2062 6520 6120 6c6f 7420 636c  ould be a lot cl
-00005680: 6561 6e65 7220 746f 2063 616c 6c20 706d  eaner to call pm
-00005690: 6164 6420 616c 6c20 7468 6520 7469 6d65  add all the time
-000056a0: 2e20 556e 666f 7274 756e 6174 656c 7920  . Unfortunately 
-000056b0: 6966 2077 650a 2020 2020 2f2f 206c 6574  if we.    // let
-000056c0: 2067 6363 2061 6c6c 6f63 6174 6520 7468   gcc allocate th
-000056d0: 6520 7265 6769 7374 6572 2069 6e20 7768  e register in wh
-000056e0: 6963 6820 746f 2073 746f 7265 2074 6865  ich to store the
-000056f0: 2072 6573 756c 7420 6f66 2074 6865 2070   result of the p
-00005700: 6d75 6c0a 2020 2020 2f2f 2028 696e 2074  mul.    // (in t
-00005710: 6865 2063 6173 6520 7768 6572 6520 7468  he case where th
-00005720: 6572 6520 6973 206e 6f20 464d 4129 2067  ere is no FMA) g
-00005730: 6363 2066 6169 6c73 2074 6f20 6669 6775  cc fails to figu
-00005740: 7265 206f 7574 2068 6f77 2074 6f20 6176  re out how to av
-00005750: 6f69 640a 2020 2020 2f2f 2073 7069 6c6c  oid.    // spill
-00005760: 696e 6720 7265 6769 7374 6572 2e0a 2369  ing register..#i
-00005770: 6664 6566 2045 4947 454e 5f48 4153 5f53  fdef EIGEN_HAS_S
-00005780: 494e 474c 455f 494e 5354 5255 4354 494f  INGLE_INSTRUCTIO
-00005790: 4e5f 4d41 4444 0a20 2020 2045 4947 454e  N_MADD.    EIGEN
-000057a0: 5f55 4e55 5345 445f 5641 5249 4142 4c45  _UNUSED_VARIABLE
-000057b0: 2874 6d70 293b 0a20 2020 2063 203d 2063  (tmp);.    c = c
-000057c0: 6a2e 706d 6164 6428 612c 622c 6329 3b0a  j.pmadd(a,b,c);.
-000057d0: 2365 6c73 650a 2020 2020 746d 7020 3d20  #else.    tmp = 
-000057e0: 623b 2074 6d70 203d 2063 6a2e 706d 756c  b; tmp = cj.pmul
-000057f0: 2861 2c74 6d70 293b 2063 203d 2070 6164  (a,tmp); c = pad
-00005800: 6428 632c 746d 7029 3b0a 2365 6e64 6966  d(c,tmp);.#endif
-00005810: 0a20 207d 0a0a 2020 7465 6d70 6c61 7465  .  }..  template
-00005820: 3c74 7970 656e 616d 6520 4c68 7350 6163  <typename LhsPac
-00005830: 6b65 7454 7970 652c 2074 7970 656e 616d  ketType, typenam
-00005840: 6520 4163 6350 6163 6b65 7454 7970 652c  e AccPacketType,
-00005850: 2074 7970 656e 616d 6520 4c61 6e65 4964   typename LaneId
-00005860: 5479 7065 3e0a 2020 4549 4745 4e5f 5354  Type>.  EIGEN_ST
-00005870: 524f 4e47 5f49 4e4c 494e 4520 766f 6964  RONG_INLINE void
-00005880: 206d 6164 6428 636f 6e73 7420 4c68 7350   madd(const LhsP
-00005890: 6163 6b65 7454 7970 6526 2061 2c20 636f  acketType& a, co
-000058a0: 6e73 7420 5268 7350 6163 6b65 7478 3426  nst RhsPacketx4&
-000058b0: 2062 2c20 4163 6350 6163 6b65 7454 7970   b, AccPacketTyp
-000058c0: 6526 2063 2c20 5268 7350 6163 6b65 7426  e& c, RhsPacket&
-000058d0: 2074 6d70 2c20 636f 6e73 7420 4c61 6e65   tmp, const Lane
-000058e0: 4964 5479 7065 2620 6c61 6e65 2920 636f  IdType& lane) co
-000058f0: 6e73 740a 2020 7b0a 2020 2020 6d61 6464  nst.  {.    madd
-00005900: 2861 2c20 622e 6765 7428 6c61 6e65 292c  (a, b.get(lane),
-00005910: 2063 2c20 746d 702c 206c 616e 6529 3b0a   c, tmp, lane);.
-00005920: 2020 7d0a 0a20 2045 4947 454e 5f53 5452    }..  EIGEN_STR
-00005930: 4f4e 475f 494e 4c49 4e45 2076 6f69 6420  ONG_INLINE void 
-00005940: 6163 6328 636f 6e73 7420 4163 6350 6163  acc(const AccPac
-00005950: 6b65 7426 2063 2c20 636f 6e73 7420 5265  ket& c, const Re
-00005960: 7350 6163 6b65 7426 2061 6c70 6861 2c20  sPacket& alpha, 
-00005970: 5265 7350 6163 6b65 7426 2072 2920 636f  ResPacket& r) co
-00005980: 6e73 740a 2020 7b0a 2020 2020 7220 3d20  nst.  {.    r = 
-00005990: 706d 6164 6428 632c 616c 7068 612c 7229  pmadd(c,alpha,r)
-000059a0: 3b0a 2020 7d0a 2020 0a20 2074 656d 706c  ;.  }.  .  templ
-000059b0: 6174 653c 7479 7065 6e61 6d65 2052 6573  ate<typename Res
-000059c0: 5061 636b 6574 4861 6c66 3e0a 2020 4549  PacketHalf>.  EI
-000059d0: 4745 4e5f 5354 524f 4e47 5f49 4e4c 494e  GEN_STRONG_INLIN
-000059e0: 4520 766f 6964 2061 6363 2863 6f6e 7374  E void acc(const
-000059f0: 2052 6573 5061 636b 6574 4861 6c66 2620   ResPacketHalf& 
-00005a00: 632c 2063 6f6e 7374 2052 6573 5061 636b  c, const ResPack
-00005a10: 6574 4861 6c66 2620 616c 7068 612c 2052  etHalf& alpha, R
-00005a20: 6573 5061 636b 6574 4861 6c66 2620 7229  esPacketHalf& r)
-00005a30: 2063 6f6e 7374 0a20 207b 0a20 2020 2072   const.  {.    r
-00005a40: 203d 2070 6d61 6464 2863 2c61 6c70 6861   = pmadd(c,alpha
-00005a50: 2c72 293b 0a20 207d 0a0a 7d3b 0a0a 7465  ,r);.  }..};..te
-00005a60: 6d70 6c61 7465 3c74 7970 656e 616d 6520  mplate<typename 
-00005a70: 5265 616c 5363 616c 6172 2c20 626f 6f6c  RealScalar, bool
-00005a80: 205f 436f 6e6a 4c68 732c 2069 6e74 2041   _ConjLhs, int A
-00005a90: 7263 682c 2069 6e74 205f 5061 636b 6574  rch, int _Packet
-00005aa0: 5369 7a65 3e0a 636c 6173 7320 6765 6270  Size>.class gebp
-00005ab0: 5f74 7261 6974 733c 7374 643a 3a63 6f6d  _traits<std::com
-00005ac0: 706c 6578 3c52 6561 6c53 6361 6c61 723e  plex<RealScalar>
-00005ad0: 2c20 5265 616c 5363 616c 6172 2c20 5f43  , RealScalar, _C
-00005ae0: 6f6e 6a4c 6873 2c20 6661 6c73 652c 2041  onjLhs, false, A
-00005af0: 7263 682c 205f 5061 636b 6574 5369 7a65  rch, _PacketSize
-00005b00: 3e0a 7b0a 7075 626c 6963 3a0a 2020 7479  >.{.public:.  ty
-00005b10: 7065 6465 6620 7374 643a 3a63 6f6d 706c  pedef std::compl
-00005b20: 6578 3c52 6561 6c53 6361 6c61 723e 204c  ex<RealScalar> L
-00005b30: 6873 5363 616c 6172 3b0a 2020 7479 7065  hsScalar;.  type
-00005b40: 6465 6620 5265 616c 5363 616c 6172 2052  def RealScalar R
-00005b50: 6873 5363 616c 6172 3b0a 2020 7479 7065  hsScalar;.  type
-00005b60: 6465 6620 7479 7065 6e61 6d65 2053 6361  def typename Sca
-00005b70: 6c61 7242 696e 6172 794f 7054 7261 6974  larBinaryOpTrait
-00005b80: 733c 4c68 7353 6361 6c61 722c 2052 6873  s<LhsScalar, Rhs
-00005b90: 5363 616c 6172 3e3a 3a52 6574 7572 6e54  Scalar>::ReturnT
-00005ba0: 7970 6520 5265 7353 6361 6c61 723b 0a0a  ype ResScalar;..
-00005bb0: 2020 5041 434b 4554 5f44 4543 4c5f 434f    PACKET_DECL_CO
-00005bc0: 4e44 5f50 5245 4649 5828 5f2c 204c 6873  ND_PREFIX(_, Lhs
-00005bd0: 2c20 5f50 6163 6b65 7453 697a 6529 3b0a  , _PacketSize);.
-00005be0: 2020 5041 434b 4554 5f44 4543 4c5f 434f    PACKET_DECL_CO
-00005bf0: 4e44 5f50 5245 4649 5828 5f2c 2052 6873  ND_PREFIX(_, Rhs
-00005c00: 2c20 5f50 6163 6b65 7453 697a 6529 3b0a  , _PacketSize);.
-00005c10: 2020 5041 434b 4554 5f44 4543 4c5f 434f    PACKET_DECL_CO
-00005c20: 4e44 5f50 5245 4649 5828 5f2c 2052 6573  ND_PREFIX(_, Res
-00005c30: 2c20 5f50 6163 6b65 7453 697a 6529 3b0a  , _PacketSize);.
-00005c40: 0a20 2065 6e75 6d20 7b0a 2020 2020 436f  .  enum {.    Co
-00005c50: 6e6a 4c68 7320 3d20 5f43 6f6e 6a4c 6873  njLhs = _ConjLhs
-00005c60: 2c0a 2020 2020 436f 6e6a 5268 7320 3d20  ,.    ConjRhs = 
-00005c70: 6661 6c73 652c 0a20 2020 2056 6563 746f  false,.    Vecto
-00005c80: 7269 7a61 626c 6520 3d20 756e 7061 636b  rizable = unpack
-00005c90: 6574 5f74 7261 6974 733c 5f4c 6873 5061  et_traits<_LhsPa
-00005ca0: 636b 6574 3e3a 3a76 6563 746f 7269 7a61  cket>::vectoriza
-00005cb0: 626c 6520 2626 2075 6e70 6163 6b65 745f  ble && unpacket_
-00005cc0: 7472 6169 7473 3c5f 5268 7350 6163 6b65  traits<_RhsPacke
-00005cd0: 743e 3a3a 7665 6374 6f72 697a 6162 6c65  t>::vectorizable
-00005ce0: 2c0a 2020 2020 4c68 7350 6163 6b65 7453  ,.    LhsPacketS
-00005cf0: 697a 6520 3d20 5665 6374 6f72 697a 6162  ize = Vectorizab
-00005d00: 6c65 203f 2075 6e70 6163 6b65 745f 7472  le ? unpacket_tr
-00005d10: 6169 7473 3c5f 4c68 7350 6163 6b65 743e  aits<_LhsPacket>
-00005d20: 3a3a 7369 7a65 203a 2031 2c0a 2020 2020  ::size : 1,.    
-00005d30: 5268 7350 6163 6b65 7453 697a 6520 3d20  RhsPacketSize = 
-00005d40: 5665 6374 6f72 697a 6162 6c65 203f 2075  Vectorizable ? u
-00005d50: 6e70 6163 6b65 745f 7472 6169 7473 3c5f  npacket_traits<_
-00005d60: 5268 7350 6163 6b65 743e 3a3a 7369 7a65  RhsPacket>::size
-00005d70: 203a 2031 2c0a 2020 2020 5265 7350 6163   : 1,.    ResPac
-00005d80: 6b65 7453 697a 6520 3d20 5665 6374 6f72  ketSize = Vector
-00005d90: 697a 6162 6c65 203f 2075 6e70 6163 6b65  izable ? unpacke
-00005da0: 745f 7472 6169 7473 3c5f 5265 7350 6163  t_traits<_ResPac
-00005db0: 6b65 743e 3a3a 7369 7a65 203a 2031 2c0a  ket>::size : 1,.
-00005dc0: 2020 2020 0a20 2020 204e 756d 6265 724f      .    NumberO
-00005dd0: 6652 6567 6973 7465 7273 203d 2045 4947  fRegisters = EIG
-00005de0: 454e 5f41 5243 485f 4445 4641 554c 545f  EN_ARCH_DEFAULT_
-00005df0: 4e55 4d42 4552 5f4f 465f 5245 4749 5354  NUMBER_OF_REGIST
-00005e00: 4552 532c 0a20 2020 206e 7220 3d20 342c  ERS,.    nr = 4,
-00005e10: 0a23 6966 2064 6566 696e 6564 2845 4947  .#if defined(EIG
-00005e20: 454e 5f48 4153 5f53 494e 474c 455f 494e  EN_HAS_SINGLE_IN
-00005e30: 5354 5255 4354 494f 4e5f 4d41 4444 2920  STRUCTION_MADD) 
-00005e40: 2626 2021 6465 6669 6e65 6428 4549 4745  && !defined(EIGE
-00005e50: 4e5f 5645 4354 4f52 495a 455f 414c 5449  N_VECTORIZE_ALTI
-00005e60: 5645 4329 2026 2620 2164 6566 696e 6564  VEC) && !defined
-00005e70: 2845 4947 454e 5f56 4543 544f 5249 5a45  (EIGEN_VECTORIZE
-00005e80: 5f56 5358 290a 2020 2020 2f2f 2077 6520  _VSX).    // we 
-00005e90: 6173 7375 6d65 2031 3620 7265 6769 7374  assume 16 regist
-00005ea0: 6572 730a 2020 2020 6d72 203d 2033 2a4c  ers.    mr = 3*L
-00005eb0: 6873 5061 636b 6574 5369 7a65 2c0a 2365  hsPacketSize,.#e
-00005ec0: 6c73 650a 2020 2020 6d72 203d 2028 4549  lse.    mr = (EI
-00005ed0: 4745 4e5f 504c 4149 4e5f 454e 554d 5f4d  GEN_PLAIN_ENUM_M
-00005ee0: 494e 2831 362c 4e75 6d62 6572 4f66 5265  IN(16,NumberOfRe
-00005ef0: 6769 7374 6572 7329 2f32 2f6e 7229 2a4c  gisters)/2/nr)*L
-00005f00: 6873 5061 636b 6574 5369 7a65 2c0a 2365  hsPacketSize,.#e
-00005f10: 6e64 6966 0a0a 2020 2020 4c68 7350 726f  ndif..    LhsPro
-00005f20: 6772 6573 7320 3d20 4c68 7350 6163 6b65  gress = LhsPacke
-00005f30: 7453 697a 652c 0a20 2020 2052 6873 5072  tSize,.    RhsPr
-00005f40: 6f67 7265 7373 203d 2031 0a20 207d 3b0a  ogress = 1.  };.
-00005f50: 0a20 2074 7970 6564 6566 2074 7970 656e  .  typedef typen
-00005f60: 616d 6520 636f 6e64 6974 696f 6e61 6c3c  ame conditional<
-00005f70: 5665 6374 6f72 697a 6162 6c65 2c5f 4c68  Vectorizable,_Lh
-00005f80: 7350 6163 6b65 742c 4c68 7353 6361 6c61  sPacket,LhsScala
-00005f90: 723e 3a3a 7479 7065 204c 6873 5061 636b  r>::type LhsPack
-00005fa0: 6574 3b0a 2020 7479 7065 6465 6620 7479  et;.  typedef ty
-00005fb0: 7065 6e61 6d65 2063 6f6e 6469 7469 6f6e  pename condition
-00005fc0: 616c 3c56 6563 746f 7269 7a61 626c 652c  al<Vectorizable,
-00005fd0: 5f52 6873 5061 636b 6574 2c52 6873 5363  _RhsPacket,RhsSc
-00005fe0: 616c 6172 3e3a 3a74 7970 6520 5268 7350  alar>::type RhsP
-00005ff0: 6163 6b65 743b 0a20 2074 7970 6564 6566  acket;.  typedef
-00006000: 2074 7970 656e 616d 6520 636f 6e64 6974   typename condit
-00006010: 696f 6e61 6c3c 5665 6374 6f72 697a 6162  ional<Vectorizab
-00006020: 6c65 2c5f 5265 7350 6163 6b65 742c 5265  le,_ResPacket,Re
-00006030: 7353 6361 6c61 723e 3a3a 7479 7065 2052  sScalar>::type R
-00006040: 6573 5061 636b 6574 3b0a 2020 7479 7065  esPacket;.  type
-00006050: 6465 6620 4c68 7350 6163 6b65 7420 4c68  def LhsPacket Lh
-00006060: 7350 6163 6b65 7434 5061 636b 696e 673b  sPacket4Packing;
-00006070: 0a0a 2020 7479 7065 6465 6620 5175 6164  ..  typedef Quad
-00006080: 5061 636b 6574 3c52 6873 5061 636b 6574  Packet<RhsPacket
-00006090: 3e20 5268 7350 6163 6b65 7478 343b 0a0a  > RhsPacketx4;..
-000060a0: 2020 7479 7065 6465 6620 5265 7350 6163    typedef ResPac
-000060b0: 6b65 7420 4163 6350 6163 6b65 743b 0a0a  ket AccPacket;..
-000060c0: 2020 4549 4745 4e5f 5354 524f 4e47 5f49    EIGEN_STRONG_I
-000060d0: 4e4c 494e 4520 766f 6964 2069 6e69 7441  NLINE void initA
-000060e0: 6363 2841 6363 5061 636b 6574 2620 7029  cc(AccPacket& p)
-000060f0: 0a20 207b 0a20 2020 2070 203d 2070 7365  .  {.    p = pse
-00006100: 7431 3c52 6573 5061 636b 6574 3e28 5265  t1<ResPacket>(Re
-00006110: 7353 6361 6c61 7228 3029 293b 0a20 207d  sScalar(0));.  }
-00006120: 0a0a 2020 7465 6d70 6c61 7465 3c74 7970  ..  template<typ
-00006130: 656e 616d 6520 5268 7350 6163 6b65 7454  ename RhsPacketT
-00006140: 7970 653e 0a20 2045 4947 454e 5f53 5452  ype>.  EIGEN_STR
-00006150: 4f4e 475f 494e 4c49 4e45 2076 6f69 6420  ONG_INLINE void 
-00006160: 6c6f 6164 5268 7328 636f 6e73 7420 5268  loadRhs(const Rh
-00006170: 7353 6361 6c61 722a 2062 2c20 5268 7350  sScalar* b, RhsP
-00006180: 6163 6b65 7454 7970 6526 2064 6573 7429  acketType& dest)
-00006190: 2063 6f6e 7374 0a20 207b 0a20 2020 2064   const.  {.    d
-000061a0: 6573 7420 3d20 7073 6574 313c 5268 7350  est = pset1<RhsP
-000061b0: 6163 6b65 7454 7970 653e 282a 6229 3b0a  acketType>(*b);.
-000061c0: 2020 7d0a 0a20 2045 4947 454e 5f53 5452    }..  EIGEN_STR
-000061d0: 4f4e 475f 494e 4c49 4e45 2076 6f69 6420  ONG_INLINE void 
-000061e0: 6c6f 6164 5268 7328 636f 6e73 7420 5268  loadRhs(const Rh
-000061f0: 7353 6361 6c61 722a 2062 2c20 5268 7350  sScalar* b, RhsP
-00006200: 6163 6b65 7478 3426 2064 6573 7429 2063  acketx4& dest) c
-00006210: 6f6e 7374 0a20 207b 0a20 2020 2070 6272  onst.  {.    pbr
-00006220: 6f61 6463 6173 7434 2862 2c20 6465 7374  oadcast4(b, dest
-00006230: 2e42 5f30 2c20 6465 7374 2e42 312c 2064  .B_0, dest.B1, d
-00006240: 6573 742e 4232 2c20 6465 7374 2e42 3329  est.B2, dest.B3)
-00006250: 3b0a 2020 7d0a 0a20 2074 656d 706c 6174  ;.  }..  templat
-00006260: 653c 7479 7065 6e61 6d65 2052 6873 5061  e<typename RhsPa
-00006270: 636b 6574 5479 7065 3e0a 2020 4549 4745  cketType>.  EIGE
-00006280: 4e5f 5354 524f 4e47 5f49 4e4c 494e 4520  N_STRONG_INLINE 
-00006290: 766f 6964 2075 7064 6174 6552 6873 2863  void updateRhs(c
-000062a0: 6f6e 7374 2052 6873 5363 616c 6172 2a20  onst RhsScalar* 
-000062b0: 622c 2052 6873 5061 636b 6574 5479 7065  b, RhsPacketType
-000062c0: 2620 6465 7374 2920 636f 6e73 740a 2020  & dest) const.  
-000062d0: 7b0a 2020 2020 6c6f 6164 5268 7328 622c  {.    loadRhs(b,
-000062e0: 2064 6573 7429 3b0a 2020 7d0a 0a20 2045   dest);.  }..  E
-000062f0: 4947 454e 5f53 5452 4f4e 475f 494e 4c49  IGEN_STRONG_INLI
-00006300: 4e45 2076 6f69 6420 7570 6461 7465 5268  NE void updateRh
-00006310: 7328 636f 6e73 7420 5268 7353 6361 6c61  s(const RhsScala
-00006320: 722a 2c20 5268 7350 6163 6b65 7478 3426  r*, RhsPacketx4&
-00006330: 2920 636f 6e73 740a 2020 7b7d 0a20 200a  ) const.  {}.  .
-00006340: 2020 4549 4745 4e5f 5354 524f 4e47 5f49    EIGEN_STRONG_I
-00006350: 4e4c 494e 4520 766f 6964 206c 6f61 6452  NLINE void loadR
-00006360: 6873 5175 6164 2863 6f6e 7374 2052 6873  hsQuad(const Rhs
-00006370: 5363 616c 6172 2a20 622c 2052 6873 5061  Scalar* b, RhsPa
-00006380: 636b 6574 2620 6465 7374 2920 636f 6e73  cket& dest) cons
-00006390: 740a 2020 7b0a 2020 2020 6c6f 6164 5268  t.  {.    loadRh
-000063a0: 7351 7561 645f 696d 706c 2862 2c64 6573  sQuad_impl(b,des
-000063b0: 742c 2074 7970 656e 616d 6520 636f 6e64  t, typename cond
-000063c0: 6974 696f 6e61 6c3c 5268 7350 6163 6b65  itional<RhsPacke
-000063d0: 7453 697a 653d 3d31 362c 7472 7565 5f74  tSize==16,true_t
-000063e0: 7970 652c 6661 6c73 655f 7479 7065 3e3a  ype,false_type>:
-000063f0: 3a74 7970 6528 2929 3b0a 2020 7d0a 0a20  :type());.  }.. 
-00006400: 2045 4947 454e 5f53 5452 4f4e 475f 494e   EIGEN_STRONG_IN
-00006410: 4c49 4e45 2076 6f69 6420 6c6f 6164 5268  LINE void loadRh
-00006420: 7351 7561 645f 696d 706c 2863 6f6e 7374  sQuad_impl(const
-00006430: 2052 6873 5363 616c 6172 2a20 622c 2052   RhsScalar* b, R
-00006440: 6873 5061 636b 6574 2620 6465 7374 2c20  hsPacket& dest, 
-00006450: 636f 6e73 7420 7472 7565 5f74 7970 6526  const true_type&
-00006460: 2920 636f 6e73 740a 2020 7b0a 2020 2020  ) const.  {.    
-00006470: 2f2f 2046 4958 4d45 2077 6520 6361 6e20  // FIXME we can 
-00006480: 646f 2062 6574 7465 7221 0a20 2020 202f  do better!.    /
-00006490: 2f20 7768 6174 2077 6520 7761 6e74 2068  / what we want h
-000064a0: 6572 6520 6973 2061 2070 6c6f 6164 6865  ere is a ploadhe
-000064b0: 6967 6874 0a20 2020 2052 6873 5363 616c  ight.    RhsScal
-000064c0: 6172 2074 6d70 5b34 5d20 3d20 7b62 5b30  ar tmp[4] = {b[0
-000064d0: 5d2c 625b 305d 2c62 5b31 5d2c 625b 315d  ],b[0],b[1],b[1]
-000064e0: 7d3b 0a20 2020 2064 6573 7420 3d20 706c  };.    dest = pl
-000064f0: 6f61 6471 7561 643c 5268 7350 6163 6b65  oadquad<RhsPacke
-00006500: 743e 2874 6d70 293b 0a20 207d 0a0a 2020  t>(tmp);.  }..  
-00006510: 4549 4745 4e5f 5354 524f 4e47 5f49 4e4c  EIGEN_STRONG_INL
-00006520: 494e 4520 766f 6964 206c 6f61 6452 6873  INE void loadRhs
-00006530: 5175 6164 5f69 6d70 6c28 636f 6e73 7420  Quad_impl(const 
-00006540: 5268 7353 6361 6c61 722a 2062 2c20 5268  RhsScalar* b, Rh
-00006550: 7350 6163 6b65 7426 2064 6573 742c 2063  sPacket& dest, c
-00006560: 6f6e 7374 2066 616c 7365 5f74 7970 6526  onst false_type&
-00006570: 2920 636f 6e73 740a 2020 7b0a 2020 2020  ) const.  {.    
-00006580: 6569 6765 6e5f 696e 7465 726e 616c 5f61  eigen_internal_a
-00006590: 7373 6572 7428 5268 7350 6163 6b65 7453  ssert(RhsPacketS
-000065a0: 697a 653c 3d38 293b 0a20 2020 2064 6573  ize<=8);.    des
-000065b0: 7420 3d20 7073 6574 313c 5268 7350 6163  t = pset1<RhsPac
-000065c0: 6b65 743e 282a 6229 3b0a 2020 7d0a 0a20  ket>(*b);.  }.. 
-000065d0: 2045 4947 454e 5f53 5452 4f4e 475f 494e   EIGEN_STRONG_IN
-000065e0: 4c49 4e45 2076 6f69 6420 6c6f 6164 4c68  LINE void loadLh
-000065f0: 7328 636f 6e73 7420 4c68 7353 6361 6c61  s(const LhsScala
-00006600: 722a 2061 2c20 4c68 7350 6163 6b65 7426  r* a, LhsPacket&
-00006610: 2064 6573 7429 2063 6f6e 7374 0a20 207b   dest) const.  {
-00006620: 0a20 2020 2064 6573 7420 3d20 706c 6f61  .    dest = ploa
-00006630: 643c 4c68 7350 6163 6b65 743e 2861 293b  d<LhsPacket>(a);
-00006640: 0a20 207d 0a0a 2020 7465 6d70 6c61 7465  .  }..  template
-00006650: 3c74 7970 656e 616d 6520 4c68 7350 6163  <typename LhsPac
-00006660: 6b65 7454 7970 653e 0a20 2045 4947 454e  ketType>.  EIGEN
-00006670: 5f53 5452 4f4e 475f 494e 4c49 4e45 2076  _STRONG_INLINE v
-00006680: 6f69 6420 6c6f 6164 4c68 7355 6e61 6c69  oid loadLhsUnali
-00006690: 676e 6564 2863 6f6e 7374 204c 6873 5363  gned(const LhsSc
-000066a0: 616c 6172 2a20 612c 204c 6873 5061 636b  alar* a, LhsPack
-000066b0: 6574 5479 7065 2620 6465 7374 2920 636f  etType& dest) co
-000066c0: 6e73 740a 2020 7b0a 2020 2020 6465 7374  nst.  {.    dest
-000066d0: 203d 2070 6c6f 6164 753c 4c68 7350 6163   = ploadu<LhsPac
-000066e0: 6b65 7454 7970 653e 2861 293b 0a20 207d  ketType>(a);.  }
-000066f0: 0a0a 2020 7465 6d70 6c61 7465 203c 7479  ..  template <ty
-00006700: 7065 6e61 6d65 204c 6873 5061 636b 6574  pename LhsPacket
-00006710: 5479 7065 2c20 7479 7065 6e61 6d65 2052  Type, typename R
-00006720: 6873 5061 636b 6574 5479 7065 2c20 7479  hsPacketType, ty
-00006730: 7065 6e61 6d65 2041 6363 5061 636b 6574  pename AccPacket
-00006740: 5479 7065 2c20 7479 7065 6e61 6d65 204c  Type, typename L
-00006750: 616e 6549 6454 7970 653e 0a20 2045 4947  aneIdType>.  EIG
-00006760: 454e 5f53 5452 4f4e 475f 494e 4c49 4e45  EN_STRONG_INLINE
-00006770: 2076 6f69 6420 6d61 6464 2863 6f6e 7374   void madd(const
-00006780: 204c 6873 5061 636b 6574 5479 7065 2620   LhsPacketType& 
-00006790: 612c 2063 6f6e 7374 2052 6873 5061 636b  a, const RhsPack
-000067a0: 6574 5479 7065 2620 622c 2041 6363 5061  etType& b, AccPa
-000067b0: 636b 6574 5479 7065 2620 632c 2052 6873  cketType& c, Rhs
-000067c0: 5061 636b 6574 5479 7065 2620 746d 702c  PacketType& tmp,
-000067d0: 2063 6f6e 7374 204c 616e 6549 6454 7970   const LaneIdTyp
-000067e0: 6526 2920 636f 6e73 740a 2020 7b0a 2020  e&) const.  {.  
-000067f0: 2020 6d61 6464 5f69 6d70 6c28 612c 2062    madd_impl(a, b
-00006800: 2c20 632c 2074 6d70 2c20 7479 7065 6e61  , c, tmp, typena
-00006810: 6d65 2063 6f6e 6469 7469 6f6e 616c 3c56  me conditional<V
-00006820: 6563 746f 7269 7a61 626c 652c 7472 7565  ectorizable,true
-00006830: 5f74 7970 652c 6661 6c73 655f 7479 7065  _type,false_type
-00006840: 3e3a 3a74 7970 6528 2929 3b0a 2020 7d0a  >::type());.  }.
-00006850: 0a20 2074 656d 706c 6174 6520 3c74 7970  .  template <typ
-00006860: 656e 616d 6520 4c68 7350 6163 6b65 7454  ename LhsPacketT
-00006870: 7970 652c 2074 7970 656e 616d 6520 5268  ype, typename Rh
-00006880: 7350 6163 6b65 7454 7970 652c 2074 7970  sPacketType, typ
-00006890: 656e 616d 6520 4163 6350 6163 6b65 7454  ename AccPacketT
-000068a0: 7970 653e 0a20 2045 4947 454e 5f53 5452  ype>.  EIGEN_STR
-000068b0: 4f4e 475f 494e 4c49 4e45 2076 6f69 6420  ONG_INLINE void 
-000068c0: 6d61 6464 5f69 6d70 6c28 636f 6e73 7420  madd_impl(const 
-000068d0: 4c68 7350 6163 6b65 7454 7970 6526 2061  LhsPacketType& a
-000068e0: 2c20 636f 6e73 7420 5268 7350 6163 6b65  , const RhsPacke
-000068f0: 7454 7970 6526 2062 2c20 4163 6350 6163  tType& b, AccPac
-00006900: 6b65 7454 7970 6526 2063 2c20 5268 7350  ketType& c, RhsP
-00006910: 6163 6b65 7454 7970 6526 2074 6d70 2c20  acketType& tmp, 
-00006920: 636f 6e73 7420 7472 7565 5f74 7970 6526  const true_type&
-00006930: 2920 636f 6e73 740a 2020 7b0a 2369 6664  ) const.  {.#ifd
-00006940: 6566 2045 4947 454e 5f48 4153 5f53 494e  ef EIGEN_HAS_SIN
-00006950: 474c 455f 494e 5354 5255 4354 494f 4e5f  GLE_INSTRUCTION_
-00006960: 4d41 4444 0a20 2020 2045 4947 454e 5f55  MADD.    EIGEN_U
-00006970: 4e55 5345 445f 5641 5249 4142 4c45 2874  NUSED_VARIABLE(t
-00006980: 6d70 293b 0a20 2020 2063 2e76 203d 2070  mp);.    c.v = p
-00006990: 6d61 6464 2861 2e76 2c62 2c63 2e76 293b  madd(a.v,b,c.v);
-000069a0: 0a23 656c 7365 0a20 2020 2074 6d70 203d  .#else.    tmp =
-000069b0: 2062 3b20 746d 7020 3d20 706d 756c 2861   b; tmp = pmul(a
-000069c0: 2e76 2c74 6d70 293b 2063 2e76 203d 2070  .v,tmp); c.v = p
-000069d0: 6164 6428 632e 762c 746d 7029 3b0a 2365  add(c.v,tmp);.#e
-000069e0: 6e64 6966 0a20 207d 0a0a 2020 4549 4745  ndif.  }..  EIGE
-000069f0: 4e5f 5354 524f 4e47 5f49 4e4c 494e 4520  N_STRONG_INLINE 
-00006a00: 766f 6964 206d 6164 645f 696d 706c 2863  void madd_impl(c
-00006a10: 6f6e 7374 204c 6873 5363 616c 6172 2620  onst LhsScalar& 
-00006a20: 612c 2063 6f6e 7374 2052 6873 5363 616c  a, const RhsScal
-00006a30: 6172 2620 622c 2052 6573 5363 616c 6172  ar& b, ResScalar
-00006a40: 2620 632c 2052 6873 5363 616c 6172 2620  & c, RhsScalar& 
-00006a50: 2f2a 746d 702a 2f2c 2063 6f6e 7374 2066  /*tmp*/, const f
-00006a60: 616c 7365 5f74 7970 6526 2920 636f 6e73  alse_type&) cons
-00006a70: 740a 2020 7b0a 2020 2020 6320 2b3d 2061  t.  {.    c += a
-00006a80: 202a 2062 3b0a 2020 7d0a 0a20 2074 656d   * b;.  }..  tem
-00006a90: 706c 6174 653c 7479 7065 6e61 6d65 204c  plate<typename L
-00006aa0: 6873 5061 636b 6574 5479 7065 2c20 7479  hsPacketType, ty
-00006ab0: 7065 6e61 6d65 2041 6363 5061 636b 6574  pename AccPacket
-00006ac0: 5479 7065 2c20 7479 7065 6e61 6d65 204c  Type, typename L
-00006ad0: 616e 6549 6454 7970 653e 0a20 2045 4947  aneIdType>.  EIG
-00006ae0: 454e 5f53 5452 4f4e 475f 494e 4c49 4e45  EN_STRONG_INLINE
-00006af0: 2076 6f69 6420 6d61 6464 2863 6f6e 7374   void madd(const
-00006b00: 204c 6873 5061 636b 6574 5479 7065 2620   LhsPacketType& 
-00006b10: 612c 2063 6f6e 7374 2052 6873 5061 636b  a, const RhsPack
-00006b20: 6574 7834 2620 622c 2041 6363 5061 636b  etx4& b, AccPack
-00006b30: 6574 5479 7065 2620 632c 2052 6873 5061  etType& c, RhsPa
-00006b40: 636b 6574 2620 746d 702c 2063 6f6e 7374  cket& tmp, const
-00006b50: 204c 616e 6549 6454 7970 6526 206c 616e   LaneIdType& lan
-00006b60: 6529 2063 6f6e 7374 0a20 207b 0a20 2020  e) const.  {.   
-00006b70: 206d 6164 6428 612c 2062 2e67 6574 286c   madd(a, b.get(l
-00006b80: 616e 6529 2c20 632c 2074 6d70 2c20 6c61  ane), c, tmp, la
-00006b90: 6e65 293b 0a20 207d 0a0a 2020 7465 6d70  ne);.  }..  temp
-00006ba0: 6c61 7465 203c 7479 7065 6e61 6d65 2052  late <typename R
-00006bb0: 6573 5061 636b 6574 5479 7065 2c20 7479  esPacketType, ty
-00006bc0: 7065 6e61 6d65 2041 6363 5061 636b 6574  pename AccPacket
-00006bd0: 5479 7065 3e0a 2020 4549 4745 4e5f 5354  Type>.  EIGEN_ST
-00006be0: 524f 4e47 5f49 4e4c 494e 4520 766f 6964  RONG_INLINE void
-00006bf0: 2061 6363 2863 6f6e 7374 2041 6363 5061   acc(const AccPa
-00006c00: 636b 6574 5479 7065 2620 632c 2063 6f6e  cketType& c, con
-00006c10: 7374 2052 6573 5061 636b 6574 5479 7065  st ResPacketType
-00006c20: 2620 616c 7068 612c 2052 6573 5061 636b  & alpha, ResPack
-00006c30: 6574 5479 7065 2620 7229 2063 6f6e 7374  etType& r) const
-00006c40: 0a20 207b 0a20 2020 2063 6f6e 6a5f 6865  .  {.    conj_he
-00006c50: 6c70 6572 3c52 6573 5061 636b 6574 5479  lper<ResPacketTy
-00006c60: 7065 2c52 6573 5061 636b 6574 5479 7065  pe,ResPacketType
-00006c70: 2c43 6f6e 6a4c 6873 2c66 616c 7365 3e20  ,ConjLhs,false> 
-00006c80: 636a 3b0a 2020 2020 7220 3d20 636a 2e70  cj;.    r = cj.p
-00006c90: 6d61 6464 2863 2c61 6c70 6861 2c72 293b  madd(c,alpha,r);
-00006ca0: 0a20 207d 0a0a 7072 6f74 6563 7465 643a  .  }..protected:
-00006cb0: 0a7d 3b0a 0a74 656d 706c 6174 653c 7479  .};..template<ty
-00006cc0: 7065 6e61 6d65 2050 6163 6b65 743e 0a73  pename Packet>.s
-00006cd0: 7472 7563 7420 446f 7562 6c65 5061 636b  truct DoublePack
-00006ce0: 6574 0a7b 0a20 2050 6163 6b65 7420 6669  et.{.  Packet fi
-00006cf0: 7273 743b 0a20 2050 6163 6b65 7420 7365  rst;.  Packet se
-00006d00: 636f 6e64 3b0a 7d3b 0a0a 7465 6d70 6c61  cond;.};..templa
-00006d10: 7465 3c74 7970 656e 616d 6520 5061 636b  te<typename Pack
-00006d20: 6574 3e0a 446f 7562 6c65 5061 636b 6574  et>.DoublePacket
-00006d30: 3c50 6163 6b65 743e 2070 6164 6428 636f  <Packet> padd(co
-00006d40: 6e73 7420 446f 7562 6c65 5061 636b 6574  nst DoublePacket
-00006d50: 3c50 6163 6b65 743e 2026 612c 2063 6f6e  <Packet> &a, con
-00006d60: 7374 2044 6f75 626c 6550 6163 6b65 743c  st DoublePacket<
-00006d70: 5061 636b 6574 3e20 2662 290a 7b0a 2020  Packet> &b).{.  
-00006d80: 446f 7562 6c65 5061 636b 6574 3c50 6163  DoublePacket<Pac
-00006d90: 6b65 743e 2072 6573 3b0a 2020 7265 732e  ket> res;.  res.
-00006da0: 6669 7273 7420 203d 2070 6164 6428 612e  first  = padd(a.
-00006db0: 6669 7273 742c 2062 2e66 6972 7374 293b  first, b.first);
-00006dc0: 0a20 2072 6573 2e73 6563 6f6e 6420 3d20  .  res.second = 
-00006dd0: 7061 6464 2861 2e73 6563 6f6e 642c 622e  padd(a.second,b.
-00006de0: 7365 636f 6e64 293b 0a20 2072 6574 7572  second);.  retur
-00006df0: 6e20 7265 733b 0a7d 0a0a 2f2f 206e 6f74  n res;.}..// not
-00006e00: 6520 7468 6174 2066 6f72 2044 6f75 626c  e that for Doubl
-00006e10: 6550 6163 6b65 743c 5265 616c 5061 636b  ePacket<RealPack
-00006e20: 6574 3e20 7468 6520 2234 2220 696e 2022  et> the "4" in "
-00006e30: 646f 776e 746f 3422 0a2f 2f20 636f 7272  downto4".// corr
-00006e40: 6573 706f 6e64 7320 746f 2074 6865 206e  esponds to the n
-00006e50: 756d 6265 7220 6f66 2063 6f6d 706c 6578  umber of complex
-00006e60: 6573 2c20 736f 2069 7420 6d65 616e 7320  es, so it means 
-00006e70: 2238 220a 2f2f 2069 7420 7465 726d 7320  "8".// it terms 
-00006e80: 6f66 2072 6561 6c20 636f 6566 6669 6369  of real coeffici
-00006e90: 656e 7473 2e0a 0a74 656d 706c 6174 653c  ents...template<
-00006ea0: 7479 7065 6e61 6d65 2050 6163 6b65 743e  typename Packet>
-00006eb0: 0a63 6f6e 7374 2044 6f75 626c 6550 6163  .const DoublePac
-00006ec0: 6b65 743c 5061 636b 6574 3e26 0a70 7265  ket<Packet>&.pre
-00006ed0: 6475 785f 6861 6c66 5f64 6f77 746f 3428  dux_half_dowto4(
-00006ee0: 636f 6e73 7420 446f 7562 6c65 5061 636b  const DoublePack
-00006ef0: 6574 3c50 6163 6b65 743e 2026 612c 0a20  et<Packet> &a,. 
-00006f00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006f10: 2020 7479 7065 6e61 6d65 2065 6e61 626c    typename enabl
-00006f20: 655f 6966 3c75 6e70 6163 6b65 745f 7472  e_if<unpacket_tr
-00006f30: 6169 7473 3c50 6163 6b65 743e 3a3a 7369  aits<Packet>::si
-00006f40: 7a65 3c3d 383e 3a3a 7479 7065 2a20 3d20  ze<=8>::type* = 
-00006f50: 3029 0a7b 0a20 2072 6574 7572 6e20 613b  0).{.  return a;
-00006f60: 0a7d 0a0a 7465 6d70 6c61 7465 3c74 7970  .}..template<typ
-00006f70: 656e 616d 6520 5061 636b 6574 3e0a 446f  ename Packet>.Do
-00006f80: 7562 6c65 5061 636b 6574 3c74 7970 656e  ublePacket<typen
-00006f90: 616d 6520 756e 7061 636b 6574 5f74 7261  ame unpacket_tra
-00006fa0: 6974 733c 5061 636b 6574 3e3a 3a68 616c  its<Packet>::hal
-00006fb0: 663e 0a70 7265 6475 785f 6861 6c66 5f64  f>.predux_half_d
-00006fc0: 6f77 746f 3428 636f 6e73 7420 446f 7562  owto4(const Doub
-00006fd0: 6c65 5061 636b 6574 3c50 6163 6b65 743e  lePacket<Packet>
-00006fe0: 2026 612c 0a20 2020 2020 2020 2020 2020   &a,.           
-00006ff0: 2020 2020 2020 2020 7479 7065 6e61 6d65          typename
-00007000: 2065 6e61 626c 655f 6966 3c75 6e70 6163   enable_if<unpac
-00007010: 6b65 745f 7472 6169 7473 3c50 6163 6b65  ket_traits<Packe
-00007020: 743e 3a3a 7369 7a65 3d3d 3136 3e3a 3a74  t>::size==16>::t
-00007030: 7970 652a 203d 2030 290a 7b0a 2020 2f2f  ype* = 0).{.  //
-00007040: 2079 6573 2c20 7468 6174 2773 2070 7265   yes, that's pre
-00007050: 7474 7920 6861 636b 6973 6820 3a28 0a20  tty hackish :(. 
-00007060: 2044 6f75 626c 6550 6163 6b65 743c 7479   DoublePacket<ty
-00007070: 7065 6e61 6d65 2075 6e70 6163 6b65 745f  pename unpacket_
-00007080: 7472 6169 7473 3c50 6163 6b65 743e 3a3a  traits<Packet>::
-00007090: 6861 6c66 3e20 7265 733b 0a20 2074 7970  half> res;.  typ
-000070a0: 6564 6566 2073 7464 3a3a 636f 6d70 6c65  edef std::comple
-000070b0: 783c 7479 7065 6e61 6d65 2075 6e70 6163  x<typename unpac
-000070c0: 6b65 745f 7472 6169 7473 3c50 6163 6b65  ket_traits<Packe
-000070d0: 743e 3a3a 7479 7065 3e20 4370 6c78 3b0a  t>::type> Cplx;.
-000070e0: 2020 7479 7065 6465 6620 7479 7065 6e61    typedef typena
-000070f0: 6d65 2070 6163 6b65 745f 7472 6169 7473  me packet_traits
-00007100: 3c43 706c 783e 3a3a 7479 7065 2043 706c  <Cplx>::type Cpl
-00007110: 7850 6163 6b65 743b 0a20 2072 6573 2e66  xPacket;.  res.f
-00007120: 6972 7374 2020 3d20 7072 6564 7578 5f68  irst  = predux_h
-00007130: 616c 665f 646f 7774 6f34 2843 706c 7850  alf_dowto4(CplxP
-00007140: 6163 6b65 7428 612e 6669 7273 7429 292e  acket(a.first)).
-00007150: 763b 0a20 2072 6573 2e73 6563 6f6e 6420  v;.  res.second 
-00007160: 3d20 7072 6564 7578 5f68 616c 665f 646f  = predux_half_do
-00007170: 7774 6f34 2843 706c 7850 6163 6b65 7428  wto4(CplxPacket(
-00007180: 612e 7365 636f 6e64 2929 2e76 3b0a 2020  a.second)).v;.  
-00007190: 7265 7475 726e 2072 6573 3b0a 7d0a 0a2f  return res;.}../
-000071a0: 2f20 7361 6d65 2068 6572 652c 2022 7175  / same here, "qu
-000071b0: 6164 2220 6163 7475 616c 6c79 206d 6561  ad" actually mea
-000071c0: 6e73 2022 3822 2069 6e20 7465 726d 7320  ns "8" in terms 
-000071d0: 6f66 2072 6561 6c20 636f 6566 6669 6369  of real coeffici
-000071e0: 656e 7473 0a74 656d 706c 6174 653c 7479  ents.template<ty
-000071f0: 7065 6e61 6d65 2053 6361 6c61 722c 2074  pename Scalar, t
-00007200: 7970 656e 616d 6520 5265 616c 5061 636b  ypename RealPack
-00007210: 6574 3e0a 766f 6964 206c 6f61 6451 7561  et>.void loadQua
-00007220: 6454 6f44 6f75 626c 6550 6163 6b65 7428  dToDoublePacket(
-00007230: 636f 6e73 7420 5363 616c 6172 2a20 622c  const Scalar* b,
-00007240: 2044 6f75 626c 6550 6163 6b65 743c 5265   DoublePacket<Re
-00007250: 616c 5061 636b 6574 3e26 2064 6573 742c  alPacket>& dest,
-00007260: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00007270: 2020 2020 2020 2020 2020 2020 2074 7970               typ
-00007280: 656e 616d 6520 656e 6162 6c65 5f69 663c  ename enable_if<
-00007290: 756e 7061 636b 6574 5f74 7261 6974 733c  unpacket_traits<
-000072a0: 5265 616c 5061 636b 6574 3e3a 3a73 697a  RealPacket>::siz
-000072b0: 653c 3d38 3e3a 3a74 7970 652a 203d 2030  e<=8>::type* = 0
-000072c0: 290a 7b0a 2020 6465 7374 2e66 6972 7374  ).{.  dest.first
-000072d0: 2020 3d20 7073 6574 313c 5265 616c 5061    = pset1<RealPa
-000072e0: 636b 6574 3e28 6e75 6d65 7874 3a3a 7265  cket>(numext::re
-000072f0: 616c 282a 6229 293b 0a20 2064 6573 742e  al(*b));.  dest.
-00007300: 7365 636f 6e64 203d 2070 7365 7431 3c52  second = pset1<R
-00007310: 6561 6c50 6163 6b65 743e 286e 756d 6578  ealPacket>(numex
-00007320: 743a 3a69 6d61 6728 2a62 2929 3b0a 7d0a  t::imag(*b));.}.
-00007330: 0a74 656d 706c 6174 653c 7479 7065 6e61  .template<typena
-00007340: 6d65 2053 6361 6c61 722c 2074 7970 656e  me Scalar, typen
-00007350: 616d 6520 5265 616c 5061 636b 6574 3e0a  ame RealPacket>.
-00007360: 766f 6964 206c 6f61 6451 7561 6454 6f44  void loadQuadToD
-00007370: 6f75 626c 6550 6163 6b65 7428 636f 6e73  oublePacket(cons
-00007380: 7420 5363 616c 6172 2a20 622c 2044 6f75  t Scalar* b, Dou
-00007390: 626c 6550 6163 6b65 743c 5265 616c 5061  blePacket<RealPa
-000073a0: 636b 6574 3e26 2064 6573 742c 0a20 2020  cket>& dest,.   
-000073b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000073c0: 2020 2020 2020 2020 2074 7970 656e 616d           typenam
-000073d0: 6520 656e 6162 6c65 5f69 663c 756e 7061  e enable_if<unpa
-000073e0: 636b 6574 5f74 7261 6974 733c 5265 616c  cket_traits<Real
-000073f0: 5061 636b 6574 3e3a 3a73 697a 653d 3d31  Packet>::size==1
-00007400: 363e 3a3a 7479 7065 2a20 3d20 3029 0a7b  6>::type* = 0).{
-00007410: 0a20 202f 2f20 7965 732c 2074 6861 7427  .  // yes, that'
-00007420: 7320 7072 6574 7479 2068 6163 6b69 7368  s pretty hackish
-00007430: 2074 6f6f 203a 280a 2020 7479 7065 6465   too :(.  typede
-00007440: 6620 7479 7065 6e61 6d65 204e 756d 5472  f typename NumTr
-00007450: 6169 7473 3c53 6361 6c61 723e 3a3a 5265  aits<Scalar>::Re
-00007460: 616c 2052 6561 6c53 6361 6c61 723b 0a20  al RealScalar;. 
-00007470: 2052 6561 6c53 6361 6c61 7220 725b 345d   RealScalar r[4]
-00007480: 203d 207b 6e75 6d65 7874 3a3a 7265 616c   = {numext::real
-00007490: 2862 5b30 5d29 2c20 6e75 6d65 7874 3a3a  (b[0]), numext::
-000074a0: 7265 616c 2862 5b30 5d29 2c20 6e75 6d65  real(b[0]), nume
-000074b0: 7874 3a3a 7265 616c 2862 5b31 5d29 2c20  xt::real(b[1]), 
-000074c0: 6e75 6d65 7874 3a3a 7265 616c 2862 5b31  numext::real(b[1
-000074d0: 5d29 7d3b 0a20 2052 6561 6c53 6361 6c61  ])};.  RealScala
-000074e0: 7220 695b 345d 203d 207b 6e75 6d65 7874  r i[4] = {numext
-000074f0: 3a3a 696d 6167 2862 5b30 5d29 2c20 6e75  ::imag(b[0]), nu
-00007500: 6d65 7874 3a3a 696d 6167 2862 5b30 5d29  mext::imag(b[0])
-00007510: 2c20 6e75 6d65 7874 3a3a 696d 6167 2862  , numext::imag(b
-00007520: 5b31 5d29 2c20 6e75 6d65 7874 3a3a 696d  [1]), numext::im
-00007530: 6167 2862 5b31 5d29 7d3b 0a20 2064 6573  ag(b[1])};.  des
-00007540: 742e 6669 7273 7420 203d 2070 6c6f 6164  t.first  = pload
-00007550: 7175 6164 3c52 6561 6c50 6163 6b65 743e  quad<RealPacket>
-00007560: 2872 293b 0a20 2064 6573 742e 7365 636f  (r);.  dest.seco
-00007570: 6e64 203d 2070 6c6f 6164 7175 6164 3c52  nd = ploadquad<R
-00007580: 6561 6c50 6163 6b65 743e 2869 293b 0a7d  ealPacket>(i);.}
-00007590: 0a0a 0a74 656d 706c 6174 653c 7479 7065  ...template<type
-000075a0: 6e61 6d65 2050 6163 6b65 743e 2073 7472  name Packet> str
-000075b0: 7563 7420 756e 7061 636b 6574 5f74 7261  uct unpacket_tra
-000075c0: 6974 733c 446f 7562 6c65 5061 636b 6574  its<DoublePacket
-000075d0: 3c50 6163 6b65 743e 203e 207b 0a20 2074  <Packet> > {.  t
-000075e0: 7970 6564 6566 2044 6f75 626c 6550 6163  ypedef DoublePac
-000075f0: 6b65 743c 7479 7065 6e61 6d65 2075 6e70  ket<typename unp
-00007600: 6163 6b65 745f 7472 6169 7473 3c50 6163  acket_traits<Pac
-00007610: 6b65 743e 3a3a 6861 6c66 3e20 6861 6c66  ket>::half> half
-00007620: 3b0a 7d3b 0a2f 2f20 7465 6d70 6c61 7465  ;.};.// template
-00007630: 3c74 7970 656e 616d 6520 5061 636b 6574  <typename Packet
-00007640: 3e0a 2f2f 2044 6f75 626c 6550 6163 6b65  >.// DoublePacke
-00007650: 743c 5061 636b 6574 3e20 706d 6164 6428  t<Packet> pmadd(
-00007660: 636f 6e73 7420 446f 7562 6c65 5061 636b  const DoublePack
-00007670: 6574 3c50 6163 6b65 743e 2026 612c 2063  et<Packet> &a, c
-00007680: 6f6e 7374 2044 6f75 626c 6550 6163 6b65  onst DoublePacke
-00007690: 743c 5061 636b 6574 3e20 2662 290a 2f2f  t<Packet> &b).//
-000076a0: 207b 0a2f 2f20 2020 446f 7562 6c65 5061   {.//   DoublePa
-000076b0: 636b 6574 3c50 6163 6b65 743e 2072 6573  cket<Packet> res
-000076c0: 3b0a 2f2f 2020 2072 6573 2e66 6972 7374  ;.//   res.first
-000076d0: 2020 3d20 7061 6464 2861 2e66 6972 7374    = padd(a.first
-000076e0: 2c20 622e 6669 7273 7429 3b0a 2f2f 2020  , b.first);.//  
-000076f0: 2072 6573 2e73 6563 6f6e 6420 3d20 7061   res.second = pa
-00007700: 6464 2861 2e73 6563 6f6e 642c 622e 7365  dd(a.second,b.se
-00007710: 636f 6e64 293b 0a2f 2f20 2020 7265 7475  cond);.//   retu
-00007720: 726e 2072 6573 3b0a 2f2f 207d 0a0a 7465  rn res;.// }..te
-00007730: 6d70 6c61 7465 3c74 7970 656e 616d 6520  mplate<typename 
-00007740: 5265 616c 5363 616c 6172 2c20 626f 6f6c  RealScalar, bool
-00007750: 205f 436f 6e6a 4c68 732c 2062 6f6f 6c20   _ConjLhs, bool 
-00007760: 5f43 6f6e 6a52 6873 2c20 696e 7420 4172  _ConjRhs, int Ar
-00007770: 6368 2c20 696e 7420 5f50 6163 6b65 7453  ch, int _PacketS
-00007780: 697a 653e 0a63 6c61 7373 2067 6562 705f  ize>.class gebp_
-00007790: 7472 6169 7473 3c73 7464 3a3a 636f 6d70  traits<std::comp
-000077a0: 6c65 783c 5265 616c 5363 616c 6172 3e2c  lex<RealScalar>,
-000077b0: 2073 7464 3a3a 636f 6d70 6c65 783c 5265   std::complex<Re
-000077c0: 616c 5363 616c 6172 3e2c 205f 436f 6e6a  alScalar>, _Conj
-000077d0: 4c68 732c 205f 436f 6e6a 5268 732c 2041  Lhs, _ConjRhs, A
-000077e0: 7263 682c 205f 5061 636b 6574 5369 7a65  rch, _PacketSize
-000077f0: 203e 0a7b 0a70 7562 6c69 633a 0a20 2074   >.{.public:.  t
-00007800: 7970 6564 6566 2073 7464 3a3a 636f 6d70  ypedef std::comp
-00007810: 6c65 783c 5265 616c 5363 616c 6172 3e20  lex<RealScalar> 
-00007820: 2053 6361 6c61 723b 0a20 2074 7970 6564   Scalar;.  typed
-00007830: 6566 2073 7464 3a3a 636f 6d70 6c65 783c  ef std::complex<
-00007840: 5265 616c 5363 616c 6172 3e20 204c 6873  RealScalar>  Lhs
-00007850: 5363 616c 6172 3b0a 2020 7479 7065 6465  Scalar;.  typede
-00007860: 6620 7374 643a 3a63 6f6d 706c 6578 3c52  f std::complex<R
-00007870: 6561 6c53 6361 6c61 723e 2020 5268 7353  ealScalar>  RhsS
-00007880: 6361 6c61 723b 0a20 2074 7970 6564 6566  calar;.  typedef
-00007890: 2073 7464 3a3a 636f 6d70 6c65 783c 5265   std::complex<Re
-000078a0: 616c 5363 616c 6172 3e20 2052 6573 5363  alScalar>  ResSc
-000078b0: 616c 6172 3b0a 2020 0a20 2050 4143 4b45  alar;.  .  PACKE
-000078c0: 545f 4445 434c 5f43 4f4e 445f 5052 4546  T_DECL_COND_PREF
-000078d0: 4958 285f 2c20 4c68 732c 205f 5061 636b  IX(_, Lhs, _Pack
-000078e0: 6574 5369 7a65 293b 0a20 2050 4143 4b45  etSize);.  PACKE
-000078f0: 545f 4445 434c 5f43 4f4e 445f 5052 4546  T_DECL_COND_PREF
-00007900: 4958 285f 2c20 5268 732c 205f 5061 636b  IX(_, Rhs, _Pack
-00007910: 6574 5369 7a65 293b 0a20 2050 4143 4b45  etSize);.  PACKE
-00007920: 545f 4445 434c 5f43 4f4e 445f 5052 4546  T_DECL_COND_PREF
-00007930: 4958 285f 2c20 5265 732c 205f 5061 636b  IX(_, Res, _Pack
-00007940: 6574 5369 7a65 293b 0a20 2050 4143 4b45  etSize);.  PACKE
-00007950: 545f 4445 434c 5f43 4f4e 4428 5265 616c  T_DECL_COND(Real
-00007960: 2c20 5f50 6163 6b65 7453 697a 6529 3b0a  , _PacketSize);.
-00007970: 2020 5041 434b 4554 5f44 4543 4c5f 434f    PACKET_DECL_CO
-00007980: 4e44 5f53 4341 4c41 5228 5f50 6163 6b65  ND_SCALAR(_Packe
-00007990: 7453 697a 6529 3b0a 0a20 2065 6e75 6d20  tSize);..  enum 
-000079a0: 7b0a 2020 2020 436f 6e6a 4c68 7320 3d20  {.    ConjLhs = 
-000079b0: 5f43 6f6e 6a4c 6873 2c0a 2020 2020 436f  _ConjLhs,.    Co
-000079c0: 6e6a 5268 7320 3d20 5f43 6f6e 6a52 6873  njRhs = _ConjRhs
-000079d0: 2c0a 2020 2020 5665 6374 6f72 697a 6162  ,.    Vectorizab
-000079e0: 6c65 203d 2075 6e70 6163 6b65 745f 7472  le = unpacket_tr
-000079f0: 6169 7473 3c52 6561 6c50 6163 6b65 743e  aits<RealPacket>
-00007a00: 3a3a 7665 6374 6f72 697a 6162 6c65 0a20  ::vectorizable. 
-00007a10: 2020 2020 2020 2020 2020 2020 2020 2026                 &
-00007a20: 2620 756e 7061 636b 6574 5f74 7261 6974  & unpacket_trait
-00007a30: 733c 5363 616c 6172 5061 636b 6574 3e3a  s<ScalarPacket>:
-00007a40: 3a76 6563 746f 7269 7a61 626c 652c 0a20  :vectorizable,. 
-00007a50: 2020 2052 6573 5061 636b 6574 5369 7a65     ResPacketSize
-00007a60: 2020 203d 2056 6563 746f 7269 7a61 626c     = Vectorizabl
-00007a70: 6520 3f20 756e 7061 636b 6574 5f74 7261  e ? unpacket_tra
-00007a80: 6974 733c 5f52 6573 5061 636b 6574 3e3a  its<_ResPacket>:
-00007a90: 3a73 697a 6520 3a20 312c 0a20 2020 204c  :size : 1,.    L
-00007aa0: 6873 5061 636b 6574 5369 7a65 203d 2056  hsPacketSize = V
-00007ab0: 6563 746f 7269 7a61 626c 6520 3f20 756e  ectorizable ? un
-00007ac0: 7061 636b 6574 5f74 7261 6974 733c 5f4c  packet_traits<_L
-00007ad0: 6873 5061 636b 6574 3e3a 3a73 697a 6520  hsPacket>::size 
-00007ae0: 3a20 312c 0a20 2020 2052 6873 5061 636b  : 1,.    RhsPack
-00007af0: 6574 5369 7a65 203d 2056 6563 746f 7269  etSize = Vectori
-00007b00: 7a61 626c 6520 3f20 756e 7061 636b 6574  zable ? unpacket
-00007b10: 5f74 7261 6974 733c 5268 7353 6361 6c61  _traits<RhsScala
-00007b20: 723e 3a3a 7369 7a65 203a 2031 2c0a 2020  r>::size : 1,.  
-00007b30: 2020 5265 616c 5061 636b 6574 5369 7a65    RealPacketSize
-00007b40: 2020 3d20 5665 6374 6f72 697a 6162 6c65    = Vectorizable
-00007b50: 203f 2075 6e70 6163 6b65 745f 7472 6169   ? unpacket_trai
-00007b60: 7473 3c52 6561 6c50 6163 6b65 743e 3a3a  ts<RealPacket>::
-00007b70: 7369 7a65 203a 2031 2c0a 0a20 2020 202f  size : 1,..    /
-00007b80: 2f20 4649 584d 453a 2073 686f 756c 6420  / FIXME: should 
-00007b90: 6465 7065 6e64 206f 6e20 4e75 6d62 6572  depend on Number
-00007ba0: 4f66 5265 6769 7374 6572 730a 2020 2020  OfRegisters.    
-00007bb0: 6e72 203d 2034 2c0a 2020 2020 6d72 203d  nr = 4,.    mr =
-00007bc0: 2052 6573 5061 636b 6574 5369 7a65 2c0a   ResPacketSize,.
-00007bd0: 0a20 2020 204c 6873 5072 6f67 7265 7373  .    LhsProgress
-00007be0: 203d 2052 6573 5061 636b 6574 5369 7a65   = ResPacketSize
-00007bf0: 2c0a 2020 2020 5268 7350 726f 6772 6573  ,.    RhsProgres
-00007c00: 7320 3d20 310a 2020 7d3b 0a20 200a 2020  s = 1.  };.  .  
-00007c10: 7479 7065 6465 6620 446f 7562 6c65 5061  typedef DoublePa
-00007c20: 636b 6574 3c52 6561 6c50 6163 6b65 743e  cket<RealPacket>
-00007c30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00007c40: 2044 6f75 626c 6550 6163 6b65 7454 7970   DoublePacketTyp
-00007c50: 653b 0a0a 2020 7479 7065 6465 6620 7479  e;..  typedef ty
-00007c60: 7065 6e61 6d65 2063 6f6e 6469 7469 6f6e  pename condition
-00007c70: 616c 3c56 6563 746f 7269 7a61 626c 652c  al<Vectorizable,
-00007c80: 5363 616c 6172 5061 636b 6574 2c53 6361  ScalarPacket,Sca
-00007c90: 6c61 723e 3a3a 7479 7065 204c 6873 5061  lar>::type LhsPa
-00007ca0: 636b 6574 3450 6163 6b69 6e67 3b0a 2020  cket4Packing;.  
-00007cb0: 7479 7065 6465 6620 7479 7065 6e61 6d65  typedef typename
-00007cc0: 2063 6f6e 6469 7469 6f6e 616c 3c56 6563   conditional<Vec
-00007cd0: 746f 7269 7a61 626c 652c 5265 616c 5061  torizable,RealPa
-00007ce0: 636b 6574 2c20 2053 6361 6c61 723e 3a3a  cket,  Scalar>::
-00007cf0: 7479 7065 204c 6873 5061 636b 6574 3b0a  type LhsPacket;.
-00007d00: 2020 7479 7065 6465 6620 7479 7065 6e61    typedef typena
-00007d10: 6d65 2063 6f6e 6469 7469 6f6e 616c 3c56  me conditional<V
-00007d20: 6563 746f 7269 7a61 626c 652c 446f 7562  ectorizable,Doub
-00007d30: 6c65 5061 636b 6574 5479 7065 2c53 6361  lePacketType,Sca
-00007d40: 6c61 723e 3a3a 7479 7065 2052 6873 5061  lar>::type RhsPa
-00007d50: 636b 6574 3b0a 2020 7479 7065 6465 6620  cket;.  typedef 
-00007d60: 7479 7065 6e61 6d65 2063 6f6e 6469 7469  typename conditi
-00007d70: 6f6e 616c 3c56 6563 746f 7269 7a61 626c  onal<Vectorizabl
-00007d80: 652c 5363 616c 6172 5061 636b 6574 2c53  e,ScalarPacket,S
-00007d90: 6361 6c61 723e 3a3a 7479 7065 2052 6573  calar>::type Res
-00007da0: 5061 636b 6574 3b0a 2020 7479 7065 6465  Packet;.  typede
-00007db0: 6620 7479 7065 6e61 6d65 2063 6f6e 6469  f typename condi
-00007dc0: 7469 6f6e 616c 3c56 6563 746f 7269 7a61  tional<Vectoriza
-00007dd0: 626c 652c 446f 7562 6c65 5061 636b 6574  ble,DoublePacket
-00007de0: 5479 7065 2c53 6361 6c61 723e 3a3a 7479  Type,Scalar>::ty
-00007df0: 7065 2041 6363 5061 636b 6574 3b0a 0a20  pe AccPacket;.. 
-00007e00: 202f 2f20 7468 6973 2061 6374 7561 6c79   // this actualy
-00007e10: 2068 6f6c 6473 2038 2070 6163 6b65 7473   holds 8 packets
-00007e20: 210a 2020 7479 7065 6465 6620 5175 6164  !.  typedef Quad
-00007e30: 5061 636b 6574 3c52 6873 5061 636b 6574  Packet<RhsPacket
-00007e40: 3e20 5268 7350 6163 6b65 7478 343b 0a20  > RhsPacketx4;. 
-00007e50: 200a 2020 4549 4745 4e5f 5354 524f 4e47   .  EIGEN_STRONG
-00007e60: 5f49 4e4c 494e 4520 766f 6964 2069 6e69  _INLINE void ini
-00007e70: 7441 6363 2853 6361 6c61 7226 2070 2920  tAcc(Scalar& p) 
-00007e80: 7b20 7020 3d20 5363 616c 6172 2830 293b  { p = Scalar(0);
-00007e90: 207d 0a0a 2020 4549 4745 4e5f 5354 524f   }..  EIGEN_STRO
-00007ea0: 4e47 5f49 4e4c 494e 4520 766f 6964 2069  NG_INLINE void i
-00007eb0: 6e69 7441 6363 2844 6f75 626c 6550 6163  nitAcc(DoublePac
-00007ec0: 6b65 7454 7970 6526 2070 290a 2020 7b0a  ketType& p).  {.
-00007ed0: 2020 2020 702e 6669 7273 7420 2020 3d20      p.first   = 
-00007ee0: 7073 6574 313c 5265 616c 5061 636b 6574  pset1<RealPacket
-00007ef0: 3e28 5265 616c 5363 616c 6172 2830 2929  >(RealScalar(0))
-00007f00: 3b0a 2020 2020 702e 7365 636f 6e64 2020  ;.    p.second  
-00007f10: 3d20 7073 6574 313c 5265 616c 5061 636b  = pset1<RealPack
-00007f20: 6574 3e28 5265 616c 5363 616c 6172 2830  et>(RealScalar(0
-00007f30: 2929 3b0a 2020 7d0a 0a20 202f 2f20 5363  ));.  }..  // Sc
-00007f40: 616c 6172 2070 6174 680a 2020 4549 4745  alar path.  EIGE
-00007f50: 4e5f 5354 524f 4e47 5f49 4e4c 494e 4520  N_STRONG_INLINE 
-00007f60: 766f 6964 206c 6f61 6452 6873 2863 6f6e  void loadRhs(con
-00007f70: 7374 2052 6873 5363 616c 6172 2a20 622c  st RhsScalar* b,
-00007f80: 2053 6361 6c61 7250 6163 6b65 7426 2064   ScalarPacket& d
-00007f90: 6573 7429 2063 6f6e 7374 0a20 207b 0a20  est) const.  {. 
-00007fa0: 2020 2064 6573 7420 3d20 7073 6574 313c     dest = pset1<
-00007fb0: 5363 616c 6172 5061 636b 6574 3e28 2a62  ScalarPacket>(*b
-00007fc0: 293b 0a20 207d 0a0a 2020 2f2f 2056 6563  );.  }..  // Vec
-00007fd0: 746f 7269 7a65 6420 7061 7468 0a20 2074  torized path.  t
-00007fe0: 656d 706c 6174 653c 7479 7065 6e61 6d65  emplate<typename
-00007ff0: 2052 6561 6c50 6163 6b65 7454 7970 653e   RealPacketType>
-00008000: 0a20 2045 4947 454e 5f53 5452 4f4e 475f  .  EIGEN_STRONG_
-00008010: 494e 4c49 4e45 2076 6f69 6420 6c6f 6164  INLINE void load
-00008020: 5268 7328 636f 6e73 7420 5268 7353 6361  Rhs(const RhsSca
-00008030: 6c61 722a 2062 2c20 446f 7562 6c65 5061  lar* b, DoublePa
-00008040: 636b 6574 3c52 6561 6c50 6163 6b65 7454  cket<RealPacketT
-00008050: 7970 653e 2620 6465 7374 2920 636f 6e73  ype>& dest) cons
-00008060: 740a 2020 7b0a 2020 2020 6465 7374 2e66  t.  {.    dest.f
-00008070: 6972 7374 2020 3d20 7073 6574 313c 5265  irst  = pset1<Re
-00008080: 616c 5061 636b 6574 5479 7065 3e28 6e75  alPacketType>(nu
-00008090: 6d65 7874 3a3a 7265 616c 282a 6229 293b  mext::real(*b));
-000080a0: 0a20 2020 2064 6573 742e 7365 636f 6e64  .    dest.second
-000080b0: 203d 2070 7365 7431 3c52 6561 6c50 6163   = pset1<RealPac
-000080c0: 6b65 7454 7970 653e 286e 756d 6578 743a  ketType>(numext:
-000080d0: 3a69 6d61 6728 2a62 2929 3b0a 2020 7d0a  :imag(*b));.  }.
-000080e0: 0a20 2045 4947 454e 5f53 5452 4f4e 475f  .  EIGEN_STRONG_
-000080f0: 494e 4c49 4e45 2076 6f69 6420 6c6f 6164  INLINE void load
-00008100: 5268 7328 636f 6e73 7420 5268 7353 6361  Rhs(const RhsSca
-00008110: 6c61 722a 2062 2c20 5268 7350 6163 6b65  lar* b, RhsPacke
-00008120: 7478 3426 2064 6573 7429 2063 6f6e 7374  tx4& dest) const
-00008130: 0a20 207b 0a20 2020 206c 6f61 6452 6873  .  {.    loadRhs
-00008140: 2862 2c20 6465 7374 2e42 5f30 293b 0a20  (b, dest.B_0);. 
-00008150: 2020 206c 6f61 6452 6873 2862 202b 2031     loadRhs(b + 1
-00008160: 2c20 6465 7374 2e42 3129 3b0a 2020 2020  , dest.B1);.    
-00008170: 6c6f 6164 5268 7328 6220 2b20 322c 2064  loadRhs(b + 2, d
-00008180: 6573 742e 4232 293b 0a20 2020 206c 6f61  est.B2);.    loa
-00008190: 6452 6873 2862 202b 2033 2c20 6465 7374  dRhs(b + 3, dest
-000081a0: 2e42 3329 3b0a 2020 7d0a 0a20 202f 2f20  .B3);.  }..  // 
-000081b0: 5363 616c 6172 2070 6174 680a 2020 4549  Scalar path.  EI
-000081c0: 4745 4e5f 5354 524f 4e47 5f49 4e4c 494e  GEN_STRONG_INLIN
-000081d0: 4520 766f 6964 2075 7064 6174 6552 6873  E void updateRhs
-000081e0: 2863 6f6e 7374 2052 6873 5363 616c 6172  (const RhsScalar
-000081f0: 2a20 622c 2053 6361 6c61 7250 6163 6b65  * b, ScalarPacke
-00008200: 7426 2064 6573 7429 2063 6f6e 7374 0a20  t& dest) const. 
-00008210: 207b 0a20 2020 206c 6f61 6452 6873 2862   {.    loadRhs(b
-00008220: 2c20 6465 7374 293b 0a20 207d 0a0a 2020  , dest);.  }..  
-00008230: 2f2f 2056 6563 746f 7269 7a65 6420 7061  // Vectorized pa
-00008240: 7468 0a20 2074 656d 706c 6174 653c 7479  th.  template<ty
-00008250: 7065 6e61 6d65 2052 6561 6c50 6163 6b65  pename RealPacke
-00008260: 7454 7970 653e 0a20 2045 4947 454e 5f53  tType>.  EIGEN_S
-00008270: 5452 4f4e 475f 494e 4c49 4e45 2076 6f69  TRONG_INLINE voi
-00008280: 6420 7570 6461 7465 5268 7328 636f 6e73  d updateRhs(cons
-00008290: 7420 5268 7353 6361 6c61 722a 2062 2c20  t RhsScalar* b, 
-000082a0: 446f 7562 6c65 5061 636b 6574 3c52 6561  DoublePacket<Rea
-000082b0: 6c50 6163 6b65 7454 7970 653e 2620 6465  lPacketType>& de
-000082c0: 7374 2920 636f 6e73 740a 2020 7b0a 2020  st) const.  {.  
-000082d0: 2020 6c6f 6164 5268 7328 622c 2064 6573    loadRhs(b, des
-000082e0: 7429 3b0a 2020 7d0a 0a20 2045 4947 454e  t);.  }..  EIGEN
-000082f0: 5f53 5452 4f4e 475f 494e 4c49 4e45 2076  _STRONG_INLINE v
-00008300: 6f69 6420 7570 6461 7465 5268 7328 636f  oid updateRhs(co
-00008310: 6e73 7420 5268 7353 6361 6c61 722a 2c20  nst RhsScalar*, 
-00008320: 5268 7350 6163 6b65 7478 3426 2920 636f  RhsPacketx4&) co
-00008330: 6e73 7420 7b7d 0a20 200a 2020 4549 4745  nst {}.  .  EIGE
-00008340: 4e5f 5354 524f 4e47 5f49 4e4c 494e 4520  N_STRONG_INLINE 
-00008350: 766f 6964 206c 6f61 6452 6873 5175 6164  void loadRhsQuad
-00008360: 2863 6f6e 7374 2052 6873 5363 616c 6172  (const RhsScalar
-00008370: 2a20 622c 2052 6573 5061 636b 6574 2620  * b, ResPacket& 
-00008380: 6465 7374 2920 636f 6e73 740a 2020 7b0a  dest) const.  {.
-00008390: 2020 2020 6c6f 6164 5268 7328 622c 6465      loadRhs(b,de
-000083a0: 7374 293b 0a20 207d 0a20 2045 4947 454e  st);.  }.  EIGEN
-000083b0: 5f53 5452 4f4e 475f 494e 4c49 4e45 2076  _STRONG_INLINE v
-000083c0: 6f69 6420 6c6f 6164 5268 7351 7561 6428  oid loadRhsQuad(
-000083d0: 636f 6e73 7420 5268 7353 6361 6c61 722a  const RhsScalar*
-000083e0: 2062 2c20 446f 7562 6c65 5061 636b 6574   b, DoublePacket
-000083f0: 5479 7065 2620 6465 7374 2920 636f 6e73  Type& dest) cons
-00008400: 740a 2020 7b0a 2020 2020 6c6f 6164 5175  t.  {.    loadQu
-00008410: 6164 546f 446f 7562 6c65 5061 636b 6574  adToDoublePacket
-00008420: 2862 2c64 6573 7429 3b0a 2020 7d0a 0a20  (b,dest);.  }.. 
-00008430: 202f 2f20 6e6f 7468 696e 6720 7370 6563   // nothing spec
-00008440: 6961 6c20 6865 7265 0a20 2045 4947 454e  ial here.  EIGEN
-00008450: 5f53 5452 4f4e 475f 494e 4c49 4e45 2076  _STRONG_INLINE v
-00008460: 6f69 6420 6c6f 6164 4c68 7328 636f 6e73  oid loadLhs(cons
-00008470: 7420 4c68 7353 6361 6c61 722a 2061 2c20  t LhsScalar* a, 
-00008480: 4c68 7350 6163 6b65 7426 2064 6573 7429  LhsPacket& dest)
-00008490: 2063 6f6e 7374 0a20 207b 0a20 2020 2064   const.  {.    d
-000084a0: 6573 7420 3d20 706c 6f61 643c 4c68 7350  est = pload<LhsP
-000084b0: 6163 6b65 743e 2828 636f 6e73 7420 7479  acket>((const ty
-000084c0: 7065 6e61 6d65 2075 6e70 6163 6b65 745f  pename unpacket_
-000084d0: 7472 6169 7473 3c4c 6873 5061 636b 6574  traits<LhsPacket
-000084e0: 3e3a 3a74 7970 652a 2928 6129 293b 0a20  >::type*)(a));. 
-000084f0: 207d 0a0a 2020 7465 6d70 6c61 7465 3c74   }..  template<t
-00008500: 7970 656e 616d 6520 4c68 7350 6163 6b65  ypename LhsPacke
-00008510: 7454 7970 653e 0a20 2045 4947 454e 5f53  tType>.  EIGEN_S
-00008520: 5452 4f4e 475f 494e 4c49 4e45 2076 6f69  TRONG_INLINE voi
-00008530: 6420 6c6f 6164 4c68 7355 6e61 6c69 676e  d loadLhsUnalign
-00008540: 6564 2863 6f6e 7374 204c 6873 5363 616c  ed(const LhsScal
-00008550: 6172 2a20 612c 204c 6873 5061 636b 6574  ar* a, LhsPacket
-00008560: 5479 7065 2620 6465 7374 2920 636f 6e73  Type& dest) cons
-00008570: 740a 2020 7b0a 2020 2020 6465 7374 203d  t.  {.    dest =
-00008580: 2070 6c6f 6164 753c 4c68 7350 6163 6b65   ploadu<LhsPacke
-00008590: 7454 7970 653e 2828 636f 6e73 7420 7479  tType>((const ty
-000085a0: 7065 6e61 6d65 2075 6e70 6163 6b65 745f  pename unpacket_
-000085b0: 7472 6169 7473 3c4c 6873 5061 636b 6574  traits<LhsPacket
-000085c0: 5479 7065 3e3a 3a74 7970 652a 2928 6129  Type>::type*)(a)
-000085d0: 293b 0a20 207d 0a0a 2020 7465 6d70 6c61  );.  }..  templa
-000085e0: 7465 3c74 7970 656e 616d 6520 4c68 7350  te<typename LhsP
-000085f0: 6163 6b65 7454 7970 652c 2074 7970 656e  acketType, typen
-00008600: 616d 6520 5268 7350 6163 6b65 7454 7970  ame RhsPacketTyp
-00008610: 652c 2074 7970 656e 616d 6520 5265 7350  e, typename ResP
-00008620: 6163 6b65 7454 7970 652c 2074 7970 656e  acketType, typen
-00008630: 616d 6520 546d 7054 7970 652c 2074 7970  ame TmpType, typ
-00008640: 656e 616d 6520 4c61 6e65 4964 5479 7065  ename LaneIdType
-00008650: 3e0a 2020 4549 4745 4e5f 5354 524f 4e47  >.  EIGEN_STRONG
-00008660: 5f49 4e4c 494e 450a 2020 7479 7065 6e61  _INLINE.  typena
-00008670: 6d65 2065 6e61 626c 655f 6966 3c21 6973  me enable_if<!is
-00008680: 5f73 616d 653c 5268 7350 6163 6b65 7454  _same<RhsPacketT
-00008690: 7970 652c 5268 7350 6163 6b65 7478 343e  ype,RhsPacketx4>
-000086a0: 3a3a 7661 6c75 653e 3a3a 7479 7065 0a20  ::value>::type. 
-000086b0: 206d 6164 6428 636f 6e73 7420 4c68 7350   madd(const LhsP
-000086c0: 6163 6b65 7454 7970 6526 2061 2c20 636f  acketType& a, co
-000086d0: 6e73 7420 5268 7350 6163 6b65 7454 7970  nst RhsPacketTyp
-000086e0: 6526 2062 2c20 446f 7562 6c65 5061 636b  e& b, DoublePack
-000086f0: 6574 3c52 6573 5061 636b 6574 5479 7065  et<ResPacketType
-00008700: 3e26 2063 2c20 546d 7054 7970 6526 202f  >& c, TmpType& /
-00008710: 2a74 6d70 2a2f 2c20 636f 6e73 7420 4c61  *tmp*/, const La
-00008720: 6e65 4964 5479 7065 2629 2063 6f6e 7374  neIdType&) const
-00008730: 0a20 207b 0a20 2020 2063 2e66 6972 7374  .  {.    c.first
-00008740: 2020 203d 2070 6164 6428 706d 756c 2861     = padd(pmul(a
-00008750: 2c62 2e66 6972 7374 292c 2063 2e66 6972  ,b.first), c.fir
-00008760: 7374 293b 0a20 2020 2063 2e73 6563 6f6e  st);.    c.secon
-00008770: 6420 203d 2070 6164 6428 706d 756c 2861  d  = padd(pmul(a
-00008780: 2c62 2e73 6563 6f6e 6429 2c63 2e73 6563  ,b.second),c.sec
-00008790: 6f6e 6429 3b0a 2020 7d0a 0a20 2074 656d  ond);.  }..  tem
-000087a0: 706c 6174 653c 7479 7065 6e61 6d65 204c  plate<typename L
-000087b0: 616e 6549 6454 7970 653e 0a20 2045 4947  aneIdType>.  EIG
-000087c0: 454e 5f53 5452 4f4e 475f 494e 4c49 4e45  EN_STRONG_INLINE
-000087d0: 2076 6f69 6420 6d61 6464 2863 6f6e 7374   void madd(const
-000087e0: 204c 6873 5061 636b 6574 2620 612c 2063   LhsPacket& a, c
-000087f0: 6f6e 7374 2052 6873 5061 636b 6574 2620  onst RhsPacket& 
-00008800: 622c 2052 6573 5061 636b 6574 2620 632c  b, ResPacket& c,
-00008810: 2052 6873 5061 636b 6574 2620 2f2a 746d   RhsPacket& /*tm
-00008820: 702a 2f2c 2063 6f6e 7374 204c 616e 6549  p*/, const LaneI
-00008830: 6454 7970 6526 2920 636f 6e73 740a 2020  dType&) const.  
-00008840: 7b0a 2020 2020 6320 3d20 636a 2e70 6d61  {.    c = cj.pma
-00008850: 6464 2861 2c62 2c63 293b 0a20 207d 0a0a  dd(a,b,c);.  }..
-00008860: 2020 7465 6d70 6c61 7465 3c74 7970 656e    template<typen
-00008870: 616d 6520 4c68 7350 6163 6b65 7454 7970  ame LhsPacketTyp
-00008880: 652c 2074 7970 656e 616d 6520 4163 6350  e, typename AccP
-00008890: 6163 6b65 7454 7970 652c 2074 7970 656e  acketType, typen
-000088a0: 616d 6520 4c61 6e65 4964 5479 7065 3e0a  ame LaneIdType>.
-000088b0: 2020 4549 4745 4e5f 5354 524f 4e47 5f49    EIGEN_STRONG_I
-000088c0: 4e4c 494e 4520 766f 6964 206d 6164 6428  NLINE void madd(
-000088d0: 636f 6e73 7420 4c68 7350 6163 6b65 7454  const LhsPacketT
-000088e0: 7970 6526 2061 2c20 636f 6e73 7420 5268  ype& a, const Rh
-000088f0: 7350 6163 6b65 7478 3426 2062 2c20 4163  sPacketx4& b, Ac
-00008900: 6350 6163 6b65 7454 7970 6526 2063 2c20  cPacketType& c, 
-00008910: 5268 7350 6163 6b65 7426 2074 6d70 2c20  RhsPacket& tmp, 
-00008920: 636f 6e73 7420 4c61 6e65 4964 5479 7065  const LaneIdType
-00008930: 2620 6c61 6e65 2920 636f 6e73 740a 2020  & lane) const.  
-00008940: 7b0a 2020 2020 6d61 6464 2861 2c20 622e  {.    madd(a, b.
-00008950: 6765 7428 6c61 6e65 292c 2063 2c20 746d  get(lane), c, tm
-00008960: 702c 206c 616e 6529 3b0a 2020 7d0a 2020  p, lane);.  }.  
-00008970: 0a20 2045 4947 454e 5f53 5452 4f4e 475f  .  EIGEN_STRONG_
-00008980: 494e 4c49 4e45 2076 6f69 6420 6163 6328  INLINE void acc(
-00008990: 636f 6e73 7420 5363 616c 6172 2620 632c  const Scalar& c,
-000089a0: 2063 6f6e 7374 2053 6361 6c61 7226 2061   const Scalar& a
-000089b0: 6c70 6861 2c20 5363 616c 6172 2620 7229  lpha, Scalar& r)
-000089c0: 2063 6f6e 7374 207b 2072 202b 3d20 616c   const { r += al
-000089d0: 7068 6120 2a20 633b 207d 0a20 200a 2020  pha * c; }.  .  
-000089e0: 7465 6d70 6c61 7465 3c74 7970 656e 616d  template<typenam
-000089f0: 6520 5265 616c 5061 636b 6574 5479 7065  e RealPacketType
-00008a00: 2c20 7479 7065 6e61 6d65 2052 6573 5061  , typename ResPa
-00008a10: 636b 6574 5479 7065 3e0a 2020 4549 4745  cketType>.  EIGE
-00008a20: 4e5f 5354 524f 4e47 5f49 4e4c 494e 4520  N_STRONG_INLINE 
-00008a30: 766f 6964 2061 6363 2863 6f6e 7374 2044  void acc(const D
-00008a40: 6f75 626c 6550 6163 6b65 743c 5265 616c  oublePacket<Real
-00008a50: 5061 636b 6574 5479 7065 3e26 2063 2c20  PacketType>& c, 
-00008a60: 636f 6e73 7420 5265 7350 6163 6b65 7454  const ResPacketT
-00008a70: 7970 6526 2061 6c70 6861 2c20 5265 7350  ype& alpha, ResP
-00008a80: 6163 6b65 7454 7970 6526 2072 2920 636f  acketType& r) co
-00008a90: 6e73 740a 2020 7b0a 2020 2020 2f2f 2061  nst.  {.    // a
-00008aa0: 7373 656d 626c 6520 630a 2020 2020 5265  ssemble c.    Re
-00008ab0: 7350 6163 6b65 7454 7970 6520 746d 703b  sPacketType tmp;
-00008ac0: 0a20 2020 2069 6628 2821 436f 6e6a 4c68  .    if((!ConjLh
-00008ad0: 7329 2626 2821 436f 6e6a 5268 7329 290a  s)&&(!ConjRhs)).
-00008ae0: 2020 2020 7b0a 2020 2020 2020 746d 7020      {.      tmp 
-00008af0: 3d20 7063 706c 7866 6c69 7028 7063 6f6e  = pcplxflip(pcon
-00008b00: 6a28 5265 7350 6163 6b65 7454 7970 6528  j(ResPacketType(
-00008b10: 632e 7365 636f 6e64 2929 293b 0a20 2020  c.second)));.   
-00008b20: 2020 2074 6d70 203d 2070 6164 6428 5265     tmp = padd(Re
-00008b30: 7350 6163 6b65 7454 7970 6528 632e 6669  sPacketType(c.fi
-00008b40: 7273 7429 2c74 6d70 293b 0a20 2020 207d  rst),tmp);.    }
-00008b50: 0a20 2020 2065 6c73 6520 6966 2828 2143  .    else if((!C
-00008b60: 6f6e 6a4c 6873 2926 2628 436f 6e6a 5268  onjLhs)&&(ConjRh
-00008b70: 7329 290a 2020 2020 7b0a 2020 2020 2020  s)).    {.      
-00008b80: 746d 7020 3d20 7063 6f6e 6a28 7063 706c  tmp = pconj(pcpl
-00008b90: 7866 6c69 7028 5265 7350 6163 6b65 7454  xflip(ResPacketT
-00008ba0: 7970 6528 632e 7365 636f 6e64 2929 293b  ype(c.second)));
-00008bb0: 0a20 2020 2020 2074 6d70 203d 2070 6164  .      tmp = pad
-00008bc0: 6428 5265 7350 6163 6b65 7454 7970 6528  d(ResPacketType(
-00008bd0: 632e 6669 7273 7429 2c74 6d70 293b 0a20  c.first),tmp);. 
-00008be0: 2020 207d 0a20 2020 2065 6c73 6520 6966     }.    else if
-00008bf0: 2828 436f 6e6a 4c68 7329 2626 2821 436f  ((ConjLhs)&&(!Co
-00008c00: 6e6a 5268 7329 290a 2020 2020 7b0a 2020  njRhs)).    {.  
-00008c10: 2020 2020 746d 7020 3d20 7063 706c 7866      tmp = pcplxf
-00008c20: 6c69 7028 5265 7350 6163 6b65 7454 7970  lip(ResPacketTyp
-00008c30: 6528 632e 7365 636f 6e64 2929 3b0a 2020  e(c.second));.  
-00008c40: 2020 2020 746d 7020 3d20 7061 6464 2870      tmp = padd(p
-00008c50: 636f 6e6a 2852 6573 5061 636b 6574 5479  conj(ResPacketTy
-00008c60: 7065 2863 2e66 6972 7374 2929 2c74 6d70  pe(c.first)),tmp
-00008c70: 293b 0a20 2020 207d 0a20 2020 2065 6c73  );.    }.    els
-00008c80: 6520 6966 2828 436f 6e6a 4c68 7329 2626  e if((ConjLhs)&&
-00008c90: 2843 6f6e 6a52 6873 2929 0a20 2020 207b  (ConjRhs)).    {
-00008ca0: 0a20 2020 2020 2074 6d70 203d 2070 6370  .      tmp = pcp
-00008cb0: 6c78 666c 6970 2852 6573 5061 636b 6574  lxflip(ResPacket
-00008cc0: 5479 7065 2863 2e73 6563 6f6e 6429 293b  Type(c.second));
-00008cd0: 0a20 2020 2020 2074 6d70 203d 2070 7375  .      tmp = psu
-00008ce0: 6228 7063 6f6e 6a28 5265 7350 6163 6b65  b(pconj(ResPacke
-00008cf0: 7454 7970 6528 632e 6669 7273 7429 292c  tType(c.first)),
-00008d00: 746d 7029 3b0a 2020 2020 7d0a 2020 2020  tmp);.    }.    
-00008d10: 0a20 2020 2072 203d 2070 6d61 6464 2874  .    r = pmadd(t
-00008d20: 6d70 2c61 6c70 6861 2c72 293b 0a20 207d  mp,alpha,r);.  }
-00008d30: 0a0a 7072 6f74 6563 7465 643a 0a20 2063  ..protected:.  c
-00008d40: 6f6e 6a5f 6865 6c70 6572 3c4c 6873 5363  onj_helper<LhsSc
-00008d50: 616c 6172 2c52 6873 5363 616c 6172 2c43  alar,RhsScalar,C
-00008d60: 6f6e 6a4c 6873 2c43 6f6e 6a52 6873 3e20  onjLhs,ConjRhs> 
-00008d70: 636a 3b0a 7d3b 0a0a 7465 6d70 6c61 7465  cj;.};..template
-00008d80: 3c74 7970 656e 616d 6520 5265 616c 5363  <typename RealSc
-00008d90: 616c 6172 2c20 626f 6f6c 205f 436f 6e6a  alar, bool _Conj
-00008da0: 5268 732c 2069 6e74 2041 7263 682c 2069  Rhs, int Arch, i
-00008db0: 6e74 205f 5061 636b 6574 5369 7a65 3e0a  nt _PacketSize>.
-00008dc0: 636c 6173 7320 6765 6270 5f74 7261 6974  class gebp_trait
-00008dd0: 733c 5265 616c 5363 616c 6172 2c20 7374  s<RealScalar, st
-00008de0: 643a 3a63 6f6d 706c 6578 3c52 6561 6c53  d::complex<RealS
-00008df0: 6361 6c61 723e 2c20 6661 6c73 652c 205f  calar>, false, _
-00008e00: 436f 6e6a 5268 732c 2041 7263 682c 205f  ConjRhs, Arch, _
-00008e10: 5061 636b 6574 5369 7a65 203e 0a7b 0a70  PacketSize >.{.p
-00008e20: 7562 6c69 633a 0a20 2074 7970 6564 6566  ublic:.  typedef
-00008e30: 2073 7464 3a3a 636f 6d70 6c65 783c 5265   std::complex<Re
-00008e40: 616c 5363 616c 6172 3e20 2053 6361 6c61  alScalar>  Scala
-00008e50: 723b 0a20 2074 7970 6564 6566 2052 6561  r;.  typedef Rea
-00008e60: 6c53 6361 6c61 7220 204c 6873 5363 616c  lScalar  LhsScal
-00008e70: 6172 3b0a 2020 7479 7065 6465 6620 5363  ar;.  typedef Sc
-00008e80: 616c 6172 2020 2020 2020 5268 7353 6361  alar      RhsSca
-00008e90: 6c61 723b 0a20 2074 7970 6564 6566 2053  lar;.  typedef S
-00008ea0: 6361 6c61 7220 2020 2020 2052 6573 5363  calar      ResSc
-00008eb0: 616c 6172 3b0a 0a20 2050 4143 4b45 545f  alar;..  PACKET_
-00008ec0: 4445 434c 5f43 4f4e 445f 5052 4546 4958  DECL_COND_PREFIX
-00008ed0: 285f 2c20 4c68 732c 205f 5061 636b 6574  (_, Lhs, _Packet
-00008ee0: 5369 7a65 293b 0a20 2050 4143 4b45 545f  Size);.  PACKET_
-00008ef0: 4445 434c 5f43 4f4e 445f 5052 4546 4958  DECL_COND_PREFIX
-00008f00: 285f 2c20 5268 732c 205f 5061 636b 6574  (_, Rhs, _Packet
-00008f10: 5369 7a65 293b 0a20 2050 4143 4b45 545f  Size);.  PACKET_
-00008f20: 4445 434c 5f43 4f4e 445f 5052 4546 4958  DECL_COND_PREFIX
-00008f30: 285f 2c20 5265 732c 205f 5061 636b 6574  (_, Res, _Packet
-00008f40: 5369 7a65 293b 0a20 2050 4143 4b45 545f  Size);.  PACKET_
-00008f50: 4445 434c 5f43 4f4e 445f 5052 4546 4958  DECL_COND_PREFIX
-00008f60: 285f 2c20 5265 616c 2c20 5f50 6163 6b65  (_, Real, _Packe
-00008f70: 7453 697a 6529 3b0a 2020 5041 434b 4554  tSize);.  PACKET
-00008f80: 5f44 4543 4c5f 434f 4e44 5f53 4341 4c41  _DECL_COND_SCALA
-00008f90: 525f 5052 4546 4958 285f 2c20 5f50 6163  R_PREFIX(_, _Pac
-00008fa0: 6b65 7453 697a 6529 3b0a 0a23 756e 6465  ketSize);..#unde
-00008fb0: 6620 5041 434b 4554 5f44 4543 4c5f 434f  f PACKET_DECL_CO
-00008fc0: 4e44 5f53 4341 4c41 525f 5052 4546 4958  ND_SCALAR_PREFIX
-00008fd0: 0a23 756e 6465 6620 5041 434b 4554 5f44  .#undef PACKET_D
-00008fe0: 4543 4c5f 434f 4e44 5f50 5245 4649 580a  ECL_COND_PREFIX.
-00008ff0: 2375 6e64 6566 2050 4143 4b45 545f 4445  #undef PACKET_DE
-00009000: 434c 5f43 4f4e 445f 5343 414c 4152 0a23  CL_COND_SCALAR.#
-00009010: 756e 6465 6620 5041 434b 4554 5f44 4543  undef PACKET_DEC
-00009020: 4c5f 434f 4e44 0a0a 2020 656e 756d 207b  L_COND..  enum {
-00009030: 0a20 2020 2043 6f6e 6a4c 6873 203d 2066  .    ConjLhs = f
-00009040: 616c 7365 2c0a 2020 2020 436f 6e6a 5268  alse,.    ConjRh
-00009050: 7320 3d20 5f43 6f6e 6a52 6873 2c0a 2020  s = _ConjRhs,.  
-00009060: 2020 5665 6374 6f72 697a 6162 6c65 203d    Vectorizable =
-00009070: 2075 6e70 6163 6b65 745f 7472 6169 7473   unpacket_traits
-00009080: 3c5f 5265 616c 5061 636b 6574 3e3a 3a76  <_RealPacket>::v
-00009090: 6563 746f 7269 7a61 626c 650a 2020 2020  ectorizable.    
-000090a0: 2020 2020 2020 2020 2020 2020 2626 2075              && u
-000090b0: 6e70 6163 6b65 745f 7472 6169 7473 3c5f  npacket_traits<_
-000090c0: 5363 616c 6172 5061 636b 6574 3e3a 3a76  ScalarPacket>::v
-000090d0: 6563 746f 7269 7a61 626c 652c 0a20 2020  ectorizable,.   
-000090e0: 204c 6873 5061 636b 6574 5369 7a65 203d   LhsPacketSize =
-000090f0: 2056 6563 746f 7269 7a61 626c 6520 3f20   Vectorizable ? 
-00009100: 756e 7061 636b 6574 5f74 7261 6974 733c  unpacket_traits<
-00009110: 5f4c 6873 5061 636b 6574 3e3a 3a73 697a  _LhsPacket>::siz
-00009120: 6520 3a20 312c 0a20 2020 2052 6873 5061  e : 1,.    RhsPa
-00009130: 636b 6574 5369 7a65 203d 2056 6563 746f  cketSize = Vecto
-00009140: 7269 7a61 626c 6520 3f20 756e 7061 636b  rizable ? unpack
-00009150: 6574 5f74 7261 6974 733c 5f52 6873 5061  et_traits<_RhsPa
-00009160: 636b 6574 3e3a 3a73 697a 6520 3a20 312c  cket>::size : 1,
-00009170: 0a20 2020 2052 6573 5061 636b 6574 5369  .    ResPacketSi
-00009180: 7a65 203d 2056 6563 746f 7269 7a61 626c  ze = Vectorizabl
-00009190: 6520 3f20 756e 7061 636b 6574 5f74 7261  e ? unpacket_tra
-000091a0: 6974 733c 5f52 6573 5061 636b 6574 3e3a  its<_ResPacket>:
-000091b0: 3a73 697a 6520 3a20 312c 0a20 2020 200a  :size : 1,.    .
-000091c0: 2020 2020 4e75 6d62 6572 4f66 5265 6769      NumberOfRegi
-000091d0: 7374 6572 7320 3d20 4549 4745 4e5f 4152  sters = EIGEN_AR
-000091e0: 4348 5f44 4546 4155 4c54 5f4e 554d 4245  CH_DEFAULT_NUMBE
-000091f0: 525f 4f46 5f52 4547 4953 5445 5253 2c0a  R_OF_REGISTERS,.
-00009200: 2020 2020 2f2f 2046 4958 4d45 3a20 7368      // FIXME: sh
-00009210: 6f75 6c64 2064 6570 656e 6420 6f6e 204e  ould depend on N
-00009220: 756d 6265 724f 6652 6567 6973 7465 7273  umberOfRegisters
-00009230: 0a20 2020 206e 7220 3d20 342c 0a20 2020  .    nr = 4,.   
-00009240: 206d 7220 3d20 2845 4947 454e 5f50 4c41   mr = (EIGEN_PLA
-00009250: 494e 5f45 4e55 4d5f 4d49 4e28 3136 2c4e  IN_ENUM_MIN(16,N
-00009260: 756d 6265 724f 6652 6567 6973 7465 7273  umberOfRegisters
-00009270: 292f 322f 6e72 292a 5265 7350 6163 6b65  )/2/nr)*ResPacke
-00009280: 7453 697a 652c 0a0a 2020 2020 4c68 7350  tSize,..    LhsP
-00009290: 726f 6772 6573 7320 3d20 5265 7350 6163  rogress = ResPac
-000092a0: 6b65 7453 697a 652c 0a20 2020 2052 6873  ketSize,.    Rhs
-000092b0: 5072 6f67 7265 7373 203d 2031 0a20 207d  Progress = 1.  }
-000092c0: 3b0a 0a20 2074 7970 6564 6566 2074 7970  ;..  typedef typ
-000092d0: 656e 616d 6520 636f 6e64 6974 696f 6e61  ename conditiona
-000092e0: 6c3c 5665 6374 6f72 697a 6162 6c65 2c5f  l<Vectorizable,_
-000092f0: 4c68 7350 6163 6b65 742c 4c68 7353 6361  LhsPacket,LhsSca
-00009300: 6c61 723e 3a3a 7479 7065 204c 6873 5061  lar>::type LhsPa
-00009310: 636b 6574 3b0a 2020 7479 7065 6465 6620  cket;.  typedef 
-00009320: 7479 7065 6e61 6d65 2063 6f6e 6469 7469  typename conditi
-00009330: 6f6e 616c 3c56 6563 746f 7269 7a61 626c  onal<Vectorizabl
-00009340: 652c 5f52 6873 5061 636b 6574 2c52 6873  e,_RhsPacket,Rhs
-00009350: 5363 616c 6172 3e3a 3a74 7970 6520 5268  Scalar>::type Rh
-00009360: 7350 6163 6b65 743b 0a20 2074 7970 6564  sPacket;.  typed
-00009370: 6566 2074 7970 656e 616d 6520 636f 6e64  ef typename cond
-00009380: 6974 696f 6e61 6c3c 5665 6374 6f72 697a  itional<Vectoriz
-00009390: 6162 6c65 2c5f 5265 7350 6163 6b65 742c  able,_ResPacket,
-000093a0: 5265 7353 6361 6c61 723e 3a3a 7479 7065  ResScalar>::type
-000093b0: 2052 6573 5061 636b 6574 3b0a 2020 7479   ResPacket;.  ty
-000093c0: 7065 6465 6620 4c68 7350 6163 6b65 7420  pedef LhsPacket 
-000093d0: 4c68 7350 6163 6b65 7434 5061 636b 696e  LhsPacket4Packin
-000093e0: 673b 0a20 2074 7970 6564 6566 2051 7561  g;.  typedef Qua
-000093f0: 6450 6163 6b65 743c 5268 7350 6163 6b65  dPacket<RhsPacke
-00009400: 743e 2052 6873 5061 636b 6574 7834 3b0a  t> RhsPacketx4;.
-00009410: 2020 7479 7065 6465 6620 5265 7350 6163    typedef ResPac
-00009420: 6b65 7420 4163 6350 6163 6b65 743b 0a0a  ket AccPacket;..
-00009430: 2020 4549 4745 4e5f 5354 524f 4e47 5f49    EIGEN_STRONG_I
-00009440: 4e4c 494e 4520 766f 6964 2069 6e69 7441  NLINE void initA
-00009450: 6363 2841 6363 5061 636b 6574 2620 7029  cc(AccPacket& p)
-00009460: 0a20 207b 0a20 2020 2070 203d 2070 7365  .  {.    p = pse
-00009470: 7431 3c52 6573 5061 636b 6574 3e28 5265  t1<ResPacket>(Re
-00009480: 7353 6361 6c61 7228 3029 293b 0a20 207d  sScalar(0));.  }
-00009490: 0a0a 2020 7465 6d70 6c61 7465 3c74 7970  ..  template<typ
-000094a0: 656e 616d 6520 5268 7350 6163 6b65 7454  ename RhsPacketT
-000094b0: 7970 653e 0a20 2045 4947 454e 5f53 5452  ype>.  EIGEN_STR
-000094c0: 4f4e 475f 494e 4c49 4e45 2076 6f69 6420  ONG_INLINE void 
-000094d0: 6c6f 6164 5268 7328 636f 6e73 7420 5268  loadRhs(const Rh
-000094e0: 7353 6361 6c61 722a 2062 2c20 5268 7350  sScalar* b, RhsP
-000094f0: 6163 6b65 7454 7970 6526 2064 6573 7429  acketType& dest)
-00009500: 2063 6f6e 7374 0a20 207b 0a20 2020 2064   const.  {.    d
-00009510: 6573 7420 3d20 7073 6574 313c 5268 7350  est = pset1<RhsP
-00009520: 6163 6b65 7454 7970 653e 282a 6229 3b0a  acketType>(*b);.
-00009530: 2020 7d0a 0a20 2045 4947 454e 5f53 5452    }..  EIGEN_STR
-00009540: 4f4e 475f 494e 4c49 4e45 2076 6f69 6420  ONG_INLINE void 
-00009550: 6c6f 6164 5268 7328 636f 6e73 7420 5268  loadRhs(const Rh
-00009560: 7353 6361 6c61 722a 2062 2c20 5268 7350  sScalar* b, RhsP
-00009570: 6163 6b65 7478 3426 2064 6573 7429 2063  acketx4& dest) c
-00009580: 6f6e 7374 0a20 207b 0a20 2020 2070 6272  onst.  {.    pbr
-00009590: 6f61 6463 6173 7434 2862 2c20 6465 7374  oadcast4(b, dest
-000095a0: 2e42 5f30 2c20 6465 7374 2e42 312c 2064  .B_0, dest.B1, d
-000095b0: 6573 742e 4232 2c20 6465 7374 2e42 3329  est.B2, dest.B3)
-000095c0: 3b0a 2020 7d0a 0a20 2074 656d 706c 6174  ;.  }..  templat
-000095d0: 653c 7479 7065 6e61 6d65 2052 6873 5061  e<typename RhsPa
-000095e0: 636b 6574 5479 7065 3e0a 2020 4549 4745  cketType>.  EIGE
-000095f0: 4e5f 5354 524f 4e47 5f49 4e4c 494e 4520  N_STRONG_INLINE 
-00009600: 766f 6964 2075 7064 6174 6552 6873 2863  void updateRhs(c
-00009610: 6f6e 7374 2052 6873 5363 616c 6172 2a20  onst RhsScalar* 
-00009620: 622c 2052 6873 5061 636b 6574 5479 7065  b, RhsPacketType
-00009630: 2620 6465 7374 2920 636f 6e73 740a 2020  & dest) const.  
-00009640: 7b0a 2020 2020 6c6f 6164 5268 7328 622c  {.    loadRhs(b,
-00009650: 2064 6573 7429 3b0a 2020 7d0a 0a20 2045   dest);.  }..  E
-00009660: 4947 454e 5f53 5452 4f4e 475f 494e 4c49  IGEN_STRONG_INLI
-00009670: 4e45 2076 6f69 6420 7570 6461 7465 5268  NE void updateRh
-00009680: 7328 636f 6e73 7420 5268 7353 6361 6c61  s(const RhsScala
-00009690: 722a 2c20 5268 7350 6163 6b65 7478 3426  r*, RhsPacketx4&
-000096a0: 2920 636f 6e73 740a 2020 7b7d 0a0a 2020  ) const.  {}..  
-000096b0: 4549 4745 4e5f 5354 524f 4e47 5f49 4e4c  EIGEN_STRONG_INL
-000096c0: 494e 4520 766f 6964 206c 6f61 644c 6873  INE void loadLhs
-000096d0: 2863 6f6e 7374 204c 6873 5363 616c 6172  (const LhsScalar
-000096e0: 2a20 612c 204c 6873 5061 636b 6574 2620  * a, LhsPacket& 
-000096f0: 6465 7374 2920 636f 6e73 740a 2020 7b0a  dest) const.  {.
-00009700: 2020 2020 6465 7374 203d 2070 6c6f 6164      dest = pload
-00009710: 6475 703c 4c68 7350 6163 6b65 743e 2861  dup<LhsPacket>(a
-00009720: 293b 0a20 207d 0a20 200a 2020 4549 4745  );.  }.  .  EIGE
-00009730: 4e5f 5354 524f 4e47 5f49 4e4c 494e 4520  N_STRONG_INLINE 
-00009740: 766f 6964 206c 6f61 6452 6873 5175 6164  void loadRhsQuad
-00009750: 2863 6f6e 7374 2052 6873 5363 616c 6172  (const RhsScalar
-00009760: 2a20 622c 2052 6873 5061 636b 6574 2620  * b, RhsPacket& 
-00009770: 6465 7374 2920 636f 6e73 740a 2020 7b0a  dest) const.  {.
-00009780: 2020 2020 6465 7374 203d 2070 6c6f 6164      dest = pload
-00009790: 7175 6164 3c52 6873 5061 636b 6574 3e28  quad<RhsPacket>(
-000097a0: 6229 3b0a 2020 7d0a 0a20 2074 656d 706c  b);.  }..  templ
-000097b0: 6174 653c 7479 7065 6e61 6d65 204c 6873  ate<typename Lhs
-000097c0: 5061 636b 6574 5479 7065 3e0a 2020 4549  PacketType>.  EI
-000097d0: 4745 4e5f 5354 524f 4e47 5f49 4e4c 494e  GEN_STRONG_INLIN
-000097e0: 4520 766f 6964 206c 6f61 644c 6873 556e  E void loadLhsUn
-000097f0: 616c 6967 6e65 6428 636f 6e73 7420 4c68  aligned(const Lh
-00009800: 7353 6361 6c61 722a 2061 2c20 4c68 7350  sScalar* a, LhsP
-00009810: 6163 6b65 7454 7970 6526 2064 6573 7429  acketType& dest)
-00009820: 2063 6f6e 7374 0a20 207b 0a20 2020 2064   const.  {.    d
-00009830: 6573 7420 3d20 706c 6f61 6464 7570 3c4c  est = ploaddup<L
-00009840: 6873 5061 636b 6574 5479 7065 3e28 6129  hsPacketType>(a)
-00009850: 3b0a 2020 7d0a 0a20 2074 656d 706c 6174  ;.  }..  templat
-00009860: 6520 3c74 7970 656e 616d 6520 4c68 7350  e <typename LhsP
-00009870: 6163 6b65 7454 7970 652c 2074 7970 656e  acketType, typen
-00009880: 616d 6520 5268 7350 6163 6b65 7454 7970  ame RhsPacketTyp
-00009890: 652c 2074 7970 656e 616d 6520 4163 6350  e, typename AccP
-000098a0: 6163 6b65 7454 7970 652c 2074 7970 656e  acketType, typen
-000098b0: 616d 6520 4c61 6e65 4964 5479 7065 3e0a  ame LaneIdType>.
-000098c0: 2020 4549 4745 4e5f 5354 524f 4e47 5f49    EIGEN_STRONG_I
-000098d0: 4e4c 494e 4520 766f 6964 206d 6164 6428  NLINE void madd(
-000098e0: 636f 6e73 7420 4c68 7350 6163 6b65 7454  const LhsPacketT
-000098f0: 7970 6526 2061 2c20 636f 6e73 7420 5268  ype& a, const Rh
-00009900: 7350 6163 6b65 7454 7970 6526 2062 2c20  sPacketType& b, 
-00009910: 4163 6350 6163 6b65 7454 7970 6526 2063  AccPacketType& c
-00009920: 2c20 5268 7350 6163 6b65 7454 7970 6526  , RhsPacketType&
-00009930: 2074 6d70 2c20 636f 6e73 7420 4c61 6e65   tmp, const Lane
-00009940: 4964 5479 7065 2629 2063 6f6e 7374 0a20  IdType&) const. 
-00009950: 207b 0a20 2020 206d 6164 645f 696d 706c   {.    madd_impl
-00009960: 2861 2c20 622c 2063 2c20 746d 702c 2074  (a, b, c, tmp, t
-00009970: 7970 656e 616d 6520 636f 6e64 6974 696f  ypename conditio
-00009980: 6e61 6c3c 5665 6374 6f72 697a 6162 6c65  nal<Vectorizable
-00009990: 2c74 7275 655f 7479 7065 2c66 616c 7365  ,true_type,false
-000099a0: 5f74 7970 653e 3a3a 7479 7065 2829 293b  _type>::type());
-000099b0: 0a20 207d 0a0a 2020 7465 6d70 6c61 7465  .  }..  template
-000099c0: 203c 7479 7065 6e61 6d65 204c 6873 5061   <typename LhsPa
-000099d0: 636b 6574 5479 7065 2c20 7479 7065 6e61  cketType, typena
-000099e0: 6d65 2052 6873 5061 636b 6574 5479 7065  me RhsPacketType
-000099f0: 2c20 7479 7065 6e61 6d65 2041 6363 5061  , typename AccPa
-00009a00: 636b 6574 5479 7065 3e0a 2020 4549 4745  cketType>.  EIGE
-00009a10: 4e5f 5354 524f 4e47 5f49 4e4c 494e 4520  N_STRONG_INLINE 
-00009a20: 766f 6964 206d 6164 645f 696d 706c 2863  void madd_impl(c
-00009a30: 6f6e 7374 204c 6873 5061 636b 6574 5479  onst LhsPacketTy
-00009a40: 7065 2620 612c 2063 6f6e 7374 2052 6873  pe& a, const Rhs
-00009a50: 5061 636b 6574 5479 7065 2620 622c 2041  PacketType& b, A
-00009a60: 6363 5061 636b 6574 5479 7065 2620 632c  ccPacketType& c,
-00009a70: 2052 6873 5061 636b 6574 5479 7065 2620   RhsPacketType& 
-00009a80: 746d 702c 2063 6f6e 7374 2074 7275 655f  tmp, const true_
-00009a90: 7479 7065 2629 2063 6f6e 7374 0a20 207b  type&) const.  {
-00009aa0: 0a23 6966 6465 6620 4549 4745 4e5f 4841  .#ifdef EIGEN_HA
-00009ab0: 535f 5349 4e47 4c45 5f49 4e53 5452 5543  S_SINGLE_INSTRUC
-00009ac0: 5449 4f4e 5f4d 4144 440a 2020 2020 4549  TION_MADD.    EI
-00009ad0: 4745 4e5f 554e 5553 4544 5f56 4152 4941  GEN_UNUSED_VARIA
-00009ae0: 424c 4528 746d 7029 3b0a 2020 2020 632e  BLE(tmp);.    c.
-00009af0: 7620 3d20 706d 6164 6428 612c 622e 762c  v = pmadd(a,b.v,
-00009b00: 632e 7629 3b0a 2365 6c73 650a 2020 2020  c.v);.#else.    
-00009b10: 746d 7020 3d20 623b 2074 6d70 2e76 203d  tmp = b; tmp.v =
-00009b20: 2070 6d75 6c28 612c 746d 702e 7629 3b20   pmul(a,tmp.v); 
-00009b30: 6320 3d20 7061 6464 2863 2c74 6d70 293b  c = padd(c,tmp);
-00009b40: 0a23 656e 6469 660a 2020 2020 0a20 207d  .#endif.    .  }
-00009b50: 0a0a 2020 4549 4745 4e5f 5354 524f 4e47  ..  EIGEN_STRONG
-00009b60: 5f49 4e4c 494e 4520 766f 6964 206d 6164  _INLINE void mad
-00009b70: 645f 696d 706c 2863 6f6e 7374 204c 6873  d_impl(const Lhs
-00009b80: 5363 616c 6172 2620 612c 2063 6f6e 7374  Scalar& a, const
-00009b90: 2052 6873 5363 616c 6172 2620 622c 2052   RhsScalar& b, R
-00009ba0: 6573 5363 616c 6172 2620 632c 2052 6873  esScalar& c, Rhs
-00009bb0: 5363 616c 6172 2620 2f2a 746d 702a 2f2c  Scalar& /*tmp*/,
-00009bc0: 2063 6f6e 7374 2066 616c 7365 5f74 7970   const false_typ
-00009bd0: 6526 2920 636f 6e73 740a 2020 7b0a 2020  e&) const.  {.  
-00009be0: 2020 6320 2b3d 2061 202a 2062 3b0a 2020    c += a * b;.  
-00009bf0: 7d0a 0a20 2074 656d 706c 6174 653c 7479  }..  template<ty
-00009c00: 7065 6e61 6d65 204c 6873 5061 636b 6574  pename LhsPacket
-00009c10: 5479 7065 2c20 7479 7065 6e61 6d65 2041  Type, typename A
-00009c20: 6363 5061 636b 6574 5479 7065 2c20 7479  ccPacketType, ty
-00009c30: 7065 6e61 6d65 204c 616e 6549 6454 7970  pename LaneIdTyp
-00009c40: 653e 0a20 2045 4947 454e 5f53 5452 4f4e  e>.  EIGEN_STRON
-00009c50: 475f 494e 4c49 4e45 2076 6f69 6420 6d61  G_INLINE void ma
-00009c60: 6464 2863 6f6e 7374 204c 6873 5061 636b  dd(const LhsPack
-00009c70: 6574 5479 7065 2620 612c 2063 6f6e 7374  etType& a, const
-00009c80: 2052 6873 5061 636b 6574 7834 2620 622c   RhsPacketx4& b,
-00009c90: 2041 6363 5061 636b 6574 5479 7065 2620   AccPacketType& 
-00009ca0: 632c 2052 6873 5061 636b 6574 2620 746d  c, RhsPacket& tm
-00009cb0: 702c 2063 6f6e 7374 204c 616e 6549 6454  p, const LaneIdT
-00009cc0: 7970 6526 206c 616e 6529 2063 6f6e 7374  ype& lane) const
-00009cd0: 0a20 207b 0a20 2020 206d 6164 6428 612c  .  {.    madd(a,
-00009ce0: 2062 2e67 6574 286c 616e 6529 2c20 632c   b.get(lane), c,
-00009cf0: 2074 6d70 2c20 6c61 6e65 293b 0a20 207d   tmp, lane);.  }
-00009d00: 0a0a 2020 7465 6d70 6c61 7465 203c 7479  ..  template <ty
-00009d10: 7065 6e61 6d65 2052 6573 5061 636b 6574  pename ResPacket
-00009d20: 5479 7065 2c20 7479 7065 6e61 6d65 2041  Type, typename A
-00009d30: 6363 5061 636b 6574 5479 7065 3e0a 2020  ccPacketType>.  
-00009d40: 4549 4745 4e5f 5354 524f 4e47 5f49 4e4c  EIGEN_STRONG_INL
-00009d50: 494e 4520 766f 6964 2061 6363 2863 6f6e  INE void acc(con
-00009d60: 7374 2041 6363 5061 636b 6574 5479 7065  st AccPacketType
-00009d70: 2620 632c 2063 6f6e 7374 2052 6573 5061  & c, const ResPa
-00009d80: 636b 6574 5479 7065 2620 616c 7068 612c  cketType& alpha,
-00009d90: 2052 6573 5061 636b 6574 5479 7065 2620   ResPacketType& 
-00009da0: 7229 2063 6f6e 7374 0a20 207b 0a20 2020  r) const.  {.   
-00009db0: 2063 6f6e 6a5f 6865 6c70 6572 3c52 6573   conj_helper<Res
-00009dc0: 5061 636b 6574 5479 7065 2c52 6573 5061  PacketType,ResPa
-00009dd0: 636b 6574 5479 7065 2c66 616c 7365 2c43  cketType,false,C
-00009de0: 6f6e 6a52 6873 3e20 636a 3b0a 2020 2020  onjRhs> cj;.    
-00009df0: 7220 3d20 636a 2e70 6d61 6464 2861 6c70  r = cj.pmadd(alp
-00009e00: 6861 2c63 2c72 293b 0a20 207d 0a0a 7072  ha,c,r);.  }..pr
-00009e10: 6f74 6563 7465 643a 0a0a 7d3b 0a0a 0a23  otected:..};...#
-00009e20: 6966 2045 4947 454e 5f41 5243 485f 4152  if EIGEN_ARCH_AR
-00009e30: 4d36 3420 2626 2064 6566 696e 6564 2045  M64 && defined E
-00009e40: 4947 454e 5f56 4543 544f 5249 5a45 5f4e  IGEN_VECTORIZE_N
-00009e50: 454f 4e0a 0a74 656d 706c 6174 653c 3e0a  EON..template<>.
-00009e60: 7374 7275 6374 2067 6562 705f 7472 6169  struct gebp_trai
-00009e70: 7473 203c 666c 6f61 742c 2066 6c6f 6174  ts <float, float
-00009e80: 2c20 6661 6c73 652c 2066 616c 7365 2c41  , false, false,A
-00009e90: 7263 6869 7465 6374 7572 653a 3a4e 454f  rchitecture::NEO
-00009ea0: 4e2c 4745 4250 5061 636b 6574 4675 6c6c  N,GEBPPacketFull
-00009eb0: 3e0a 203a 2067 6562 705f 7472 6169 7473  >. : gebp_traits
-00009ec0: 3c66 6c6f 6174 2c66 6c6f 6174 2c66 616c  <float,float,fal
-00009ed0: 7365 2c66 616c 7365 2c41 7263 6869 7465  se,false,Archite
-00009ee0: 6374 7572 653a 3a47 656e 6572 6963 2c47  cture::Generic,G
-00009ef0: 4542 5050 6163 6b65 7446 756c 6c3e 0a7b  EBPPacketFull>.{
-00009f00: 0a20 2074 7970 6564 6566 2066 6c6f 6174  .  typedef float
-00009f10: 2052 6873 5061 636b 6574 3b0a 0a20 2074   RhsPacket;..  t
-00009f20: 7970 6564 6566 2066 6c6f 6174 3332 7834  ypedef float32x4
-00009f30: 5f74 2052 6873 5061 636b 6574 7834 3b0a  _t RhsPacketx4;.
-00009f40: 0a20 2045 4947 454e 5f53 5452 4f4e 475f  .  EIGEN_STRONG_
-00009f50: 494e 4c49 4e45 2076 6f69 6420 6c6f 6164  INLINE void load
-00009f60: 5268 7328 636f 6e73 7420 5268 7353 6361  Rhs(const RhsSca
-00009f70: 6c61 722a 2062 2c20 5268 7350 6163 6b65  lar* b, RhsPacke
-00009f80: 7426 2064 6573 7429 2063 6f6e 7374 0a20  t& dest) const. 
-00009f90: 207b 0a20 2020 2064 6573 7420 3d20 2a62   {.    dest = *b
-00009fa0: 3b0a 2020 7d0a 0a20 2045 4947 454e 5f53  ;.  }..  EIGEN_S
-00009fb0: 5452 4f4e 475f 494e 4c49 4e45 2076 6f69  TRONG_INLINE voi
-00009fc0: 6420 6c6f 6164 5268 7328 636f 6e73 7420  d loadRhs(const 
-00009fd0: 5268 7353 6361 6c61 722a 2062 2c20 5268  RhsScalar* b, Rh
-00009fe0: 7350 6163 6b65 7478 3426 2064 6573 7429  sPacketx4& dest)
-00009ff0: 2063 6f6e 7374 0a20 207b 0a20 2020 2064   const.  {.    d
-0000a000: 6573 7420 3d20 766c 6431 715f 6633 3228  est = vld1q_f32(
-0000a010: 6229 3b0a 2020 7d0a 0a20 2045 4947 454e  b);.  }..  EIGEN
-0000a020: 5f53 5452 4f4e 475f 494e 4c49 4e45 2076  _STRONG_INLINE v
-0000a030: 6f69 6420 7570 6461 7465 5268 7328 636f  oid updateRhs(co
-0000a040: 6e73 7420 5268 7353 6361 6c61 722a 2062  nst RhsScalar* b
-0000a050: 2c20 5268 7350 6163 6b65 7426 2064 6573  , RhsPacket& des
-0000a060: 7429 2063 6f6e 7374 0a20 207b 0a20 2020  t) const.  {.   
-0000a070: 2064 6573 7420 3d20 2a62 3b0a 2020 7d0a   dest = *b;.  }.
-0000a080: 0a20 2045 4947 454e 5f53 5452 4f4e 475f  .  EIGEN_STRONG_
-0000a090: 494e 4c49 4e45 2076 6f69 6420 7570 6461  INLINE void upda
-0000a0a0: 7465 5268 7328 636f 6e73 7420 5268 7353  teRhs(const RhsS
-0000a0b0: 6361 6c61 722a 2c20 5268 7350 6163 6b65  calar*, RhsPacke
-0000a0c0: 7478 3426 2920 636f 6e73 740a 2020 7b7d  tx4&) const.  {}
-0000a0d0: 0a0a 2020 4549 4745 4e5f 5354 524f 4e47  ..  EIGEN_STRONG
-0000a0e0: 5f49 4e4c 494e 4520 766f 6964 206c 6f61  _INLINE void loa
-0000a0f0: 6452 6873 5175 6164 2863 6f6e 7374 2052  dRhsQuad(const R
-0000a100: 6873 5363 616c 6172 2a20 622c 2052 6873  hsScalar* b, Rhs
-0000a110: 5061 636b 6574 2620 6465 7374 2920 636f  Packet& dest) co
-0000a120: 6e73 740a 2020 7b0a 2020 2020 6c6f 6164  nst.  {.    load
-0000a130: 5268 7328 622c 6465 7374 293b 0a20 207d  Rhs(b,dest);.  }
-0000a140: 0a0a 2020 4549 4745 4e5f 5354 524f 4e47  ..  EIGEN_STRONG
-0000a150: 5f49 4e4c 494e 4520 766f 6964 206d 6164  _INLINE void mad
-0000a160: 6428 636f 6e73 7420 4c68 7350 6163 6b65  d(const LhsPacke
-0000a170: 7426 2061 2c20 636f 6e73 7420 5268 7350  t& a, const RhsP
-0000a180: 6163 6b65 7426 2062 2c20 4163 6350 6163  acket& b, AccPac
-0000a190: 6b65 7426 2063 2c20 5268 7350 6163 6b65  ket& c, RhsPacke
-0000a1a0: 7426 202f 2a74 6d70 2a2f 2c20 636f 6e73  t& /*tmp*/, cons
-0000a1b0: 7420 4669 7865 6449 6e74 3c30 3e26 2920  t FixedInt<0>&) 
-0000a1c0: 636f 6e73 740a 2020 7b0a 2020 2020 6320  const.  {.    c 
-0000a1d0: 3d20 7666 6d61 715f 6e5f 6633 3228 632c  = vfmaq_n_f32(c,
-0000a1e0: 2061 2c20 6229 3b0a 2020 7d0a 0a20 202f   a, b);.  }..  /
-0000a1f0: 2f20 4e4f 5445 3a20 5465 6d70 6c61 7465  / NOTE: Template
-0000a200: 2070 6172 616d 6574 6572 2069 6e66 6572   parameter infer
-0000a210: 656e 6365 2066 6169 6c65 6420 7768 656e  ence failed when
-0000a220: 2063 6f6d 7069 6c65 6420 7769 7468 2041   compiled with A
-0000a230: 6e64 726f 6964 204e 444b 3a0a 2020 2f2f  ndroid NDK:.  //
-0000a240: 2022 6361 6e64 6964 6174 6520 7465 6d70   "candidate temp
-0000a250: 6c61 7465 2069 676e 6f72 6564 3a20 636f  late ignored: co
-0000a260: 756c 6420 6e6f 7420 6d61 7463 6820 2746  uld not match 'F
-0000a270: 6978 6564 496e 743c 4e3e 2720 6167 6169  ixedInt<N>' agai
-0000a280: 6e73 7420 2745 6967 656e 3a3a 696e 7465  nst 'Eigen::inte
-0000a290: 726e 616c 3a3a 4669 7865 6449 6e74 3c30  rnal::FixedInt<0
-0000a2a0: 3e22 2e0a 0a20 2045 4947 454e 5f53 5452  >"...  EIGEN_STR
-0000a2b0: 4f4e 475f 494e 4c49 4e45 2076 6f69 6420  ONG_INLINE void 
-0000a2c0: 6d61 6464 2863 6f6e 7374 204c 6873 5061  madd(const LhsPa
-0000a2d0: 636b 6574 2620 612c 2063 6f6e 7374 2052  cket& a, const R
-0000a2e0: 6873 5061 636b 6574 7834 2620 622c 2041  hsPacketx4& b, A
-0000a2f0: 6363 5061 636b 6574 2620 632c 2052 6873  ccPacket& c, Rhs
-0000a300: 5061 636b 6574 2620 2f2a 746d 702a 2f2c  Packet& /*tmp*/,
-0000a310: 2063 6f6e 7374 2046 6978 6564 496e 743c   const FixedInt<
-0000a320: 303e 2629 2063 6f6e 7374 0a20 207b 206d  0>&) const.  { m
-0000a330: 6164 645f 6865 6c70 6572 3c30 3e28 612c  add_helper<0>(a,
-0000a340: 2062 2c20 6329 3b20 7d0a 2020 4549 4745   b, c); }.  EIGE
-0000a350: 4e5f 5354 524f 4e47 5f49 4e4c 494e 4520  N_STRONG_INLINE 
-0000a360: 766f 6964 206d 6164 6428 636f 6e73 7420  void madd(const 
-0000a370: 4c68 7350 6163 6b65 7426 2061 2c20 636f  LhsPacket& a, co
-0000a380: 6e73 7420 5268 7350 6163 6b65 7478 3426  nst RhsPacketx4&
-0000a390: 2062 2c20 4163 6350 6163 6b65 7426 2063   b, AccPacket& c
-0000a3a0: 2c20 5268 7350 6163 6b65 7426 202f 2a74  , RhsPacket& /*t
-0000a3b0: 6d70 2a2f 2c20 636f 6e73 7420 4669 7865  mp*/, const Fixe
-0000a3c0: 6449 6e74 3c31 3e26 2920 636f 6e73 740a  dInt<1>&) const.
-0000a3d0: 2020 7b20 6d61 6464 5f68 656c 7065 723c    { madd_helper<
-0000a3e0: 313e 2861 2c20 622c 2063 293b 207d 0a20  1>(a, b, c); }. 
-0000a3f0: 2045 4947 454e 5f53 5452 4f4e 475f 494e   EIGEN_STRONG_IN
-0000a400: 4c49 4e45 2076 6f69 6420 6d61 6464 2863  LINE void madd(c
-0000a410: 6f6e 7374 204c 6873 5061 636b 6574 2620  onst LhsPacket& 
-0000a420: 612c 2063 6f6e 7374 2052 6873 5061 636b  a, const RhsPack
-0000a430: 6574 7834 2620 622c 2041 6363 5061 636b  etx4& b, AccPack
-0000a440: 6574 2620 632c 2052 6873 5061 636b 6574  et& c, RhsPacket
-0000a450: 2620 2f2a 746d 702a 2f2c 2063 6f6e 7374  & /*tmp*/, const
-0000a460: 2046 6978 6564 496e 743c 323e 2629 2063   FixedInt<2>&) c
-0000a470: 6f6e 7374 0a20 207b 206d 6164 645f 6865  onst.  { madd_he
-0000a480: 6c70 6572 3c32 3e28 612c 2062 2c20 6329  lper<2>(a, b, c)
-0000a490: 3b20 7d0a 2020 4549 4745 4e5f 5354 524f  ; }.  EIGEN_STRO
-0000a4a0: 4e47 5f49 4e4c 494e 4520 766f 6964 206d  NG_INLINE void m
-0000a4b0: 6164 6428 636f 6e73 7420 4c68 7350 6163  add(const LhsPac
-0000a4c0: 6b65 7426 2061 2c20 636f 6e73 7420 5268  ket& a, const Rh
-0000a4d0: 7350 6163 6b65 7478 3426 2062 2c20 4163  sPacketx4& b, Ac
-0000a4e0: 6350 6163 6b65 7426 2063 2c20 5268 7350  cPacket& c, RhsP
-0000a4f0: 6163 6b65 7426 202f 2a74 6d70 2a2f 2c20  acket& /*tmp*/, 
-0000a500: 636f 6e73 7420 4669 7865 6449 6e74 3c33  const FixedInt<3
-0000a510: 3e26 2920 636f 6e73 740a 2020 7b20 6d61  >&) const.  { ma
-0000a520: 6464 5f68 656c 7065 723c 333e 2861 2c20  dd_helper<3>(a, 
-0000a530: 622c 2063 293b 207d 0a0a 2070 7269 7661  b, c); }.. priva
-0000a540: 7465 3a0a 2020 7465 6d70 6c61 7465 3c69  te:.  template<i
-0000a550: 6e74 204c 616e 6549 443e 0a20 2045 4947  nt LaneID>.  EIG
-0000a560: 454e 5f53 5452 4f4e 475f 494e 4c49 4e45  EN_STRONG_INLINE
-0000a570: 2076 6f69 6420 6d61 6464 5f68 656c 7065   void madd_helpe
-0000a580: 7228 636f 6e73 7420 4c68 7350 6163 6b65  r(const LhsPacke
-0000a590: 7426 2061 2c20 636f 6e73 7420 5268 7350  t& a, const RhsP
-0000a5a0: 6163 6b65 7478 3426 2062 2c20 4163 6350  acketx4& b, AccP
-0000a5b0: 6163 6b65 7426 2063 2920 636f 6e73 740a  acket& c) const.
-0000a5c0: 2020 7b0a 2020 2020 2369 6620 4549 4745    {.    #if EIGE
-0000a5d0: 4e5f 434f 4d50 5f47 4e55 435f 5354 5249  N_COMP_GNUC_STRI
-0000a5e0: 4354 2026 2620 2128 4549 4745 4e5f 474e  CT && !(EIGEN_GN
-0000a5f0: 5543 5f41 545f 4c45 4153 5428 392c 3029  UC_AT_LEAST(9,0)
-0000a600: 290a 2020 2020 2f2f 2077 6f72 6b61 726f  ).    // workaro
-0000a610: 756e 6420 6763 6320 6973 7375 6520 6874  und gcc issue ht
-0000a620: 7470 733a 2f2f 6763 632e 676e 752e 6f72  tps://gcc.gnu.or
-0000a630: 672f 6275 677a 696c 6c61 2f73 686f 775f  g/bugzilla/show_
-0000a640: 6275 672e 6367 693f 6964 3d38 3931 3031  bug.cgi?id=89101
-0000a650: 0a20 2020 202f 2f20 7666 6d61 715f 6c61  .    // vfmaq_la
-0000a660: 6e65 715f 6633 3220 6973 2069 6d70 6c65  neq_f32 is imple
-0000a670: 6d65 6e74 6564 2074 6872 6f75 6768 2061  mented through a
-0000a680: 2063 6f73 746c 7920 6475 700a 2020 2020   costly dup.    
-0000a690: 2020 2020 2069 6628 4c61 6e65 4944 3d3d       if(LaneID==
-0000a6a0: 3029 2020 6173 6d28 2266 6d6c 6120 2530  0)  asm("fmla %0
-0000a6b0: 2e34 732c 2025 312e 3473 2c20 2532 2e73  .4s, %1.4s, %2.s
-0000a6c0: 5b30 5d5c 6e22 203a 2022 2b77 2220 2863  [0]\n" : "+w" (c
-0000a6d0: 2920 3a20 2277 2220 2861 292c 2022 7722  ) : "w" (a), "w"
-0000a6e0: 2028 6229 203a 2020 293b 0a20 2020 2065   (b) :  );.    e
-0000a6f0: 6c73 6520 6966 284c 616e 6549 443d 3d31  lse if(LaneID==1
-0000a700: 2920 2061 736d 2822 666d 6c61 2025 302e  )  asm("fmla %0.
-0000a710: 3473 2c20 2531 2e34 732c 2025 322e 735b  4s, %1.4s, %2.s[
-0000a720: 315d 5c6e 2220 3a20 222b 7722 2028 6329  1]\n" : "+w" (c)
-0000a730: 203a 2022 7722 2028 6129 2c20 2277 2220   : "w" (a), "w" 
-0000a740: 2862 2920 3a20 2029 3b0a 2020 2020 656c  (b) :  );.    el
-0000a750: 7365 2069 6628 4c61 6e65 4944 3d3d 3229  se if(LaneID==2)
-0000a760: 2020 6173 6d28 2266 6d6c 6120 2530 2e34    asm("fmla %0.4
-0000a770: 732c 2025 312e 3473 2c20 2532 2e73 5b32  s, %1.4s, %2.s[2
-0000a780: 5d5c 6e22 203a 2022 2b77 2220 2863 2920  ]\n" : "+w" (c) 
-0000a790: 3a20 2277 2220 2861 292c 2022 7722 2028  : "w" (a), "w" (
-0000a7a0: 6229 203a 2020 293b 0a20 2020 2065 6c73  b) :  );.    els
-0000a7b0: 6520 6966 284c 616e 6549 443d 3d33 2920  e if(LaneID==3) 
-0000a7c0: 2061 736d 2822 666d 6c61 2025 302e 3473   asm("fmla %0.4s
-0000a7d0: 2c20 2531 2e34 732c 2025 322e 735b 335d  , %1.4s, %2.s[3]
-0000a7e0: 5c6e 2220 3a20 222b 7722 2028 6329 203a  \n" : "+w" (c) :
-0000a7f0: 2022 7722 2028 6129 2c20 2277 2220 2862   "w" (a), "w" (b
-0000a800: 2920 3a20 2029 3b0a 2020 2020 2365 6c73  ) :  );.    #els
-0000a810: 650a 2020 2020 6320 3d20 7666 6d61 715f  e.    c = vfmaq_
-0000a820: 6c61 6e65 715f 6633 3228 632c 2061 2c20  laneq_f32(c, a, 
-0000a830: 622c 204c 616e 6549 4429 3b0a 2020 2020  b, LaneID);.    
-0000a840: 2365 6e64 6966 0a20 207d 0a7d 3b0a 0a0a  #endif.  }.};...
-0000a850: 7465 6d70 6c61 7465 3c3e 0a73 7472 7563  template<>.struc
-0000a860: 7420 6765 6270 5f74 7261 6974 7320 3c64  t gebp_traits <d
-0000a870: 6f75 626c 652c 2064 6f75 626c 652c 2066  ouble, double, f
-0000a880: 616c 7365 2c20 6661 6c73 652c 4172 6368  alse, false,Arch
-0000a890: 6974 6563 7475 7265 3a3a 4e45 4f4e 3e0a  itecture::NEON>.
-0000a8a0: 203a 2067 6562 705f 7472 6169 7473 3c64   : gebp_traits<d
-0000a8b0: 6f75 626c 652c 646f 7562 6c65 2c66 616c  ouble,double,fal
-0000a8c0: 7365 2c66 616c 7365 2c41 7263 6869 7465  se,false,Archite
-0000a8d0: 6374 7572 653a 3a47 656e 6572 6963 3e0a  cture::Generic>.
-0000a8e0: 7b0a 2020 7479 7065 6465 6620 646f 7562  {.  typedef doub
-0000a8f0: 6c65 2052 6873 5061 636b 6574 3b0a 0a20  le RhsPacket;.. 
-0000a900: 2073 7472 7563 7420 5268 7350 6163 6b65   struct RhsPacke
-0000a910: 7478 3420 7b0a 2020 2020 666c 6f61 7436  tx4 {.    float6
-0000a920: 3478 325f 7420 425f 302c 2042 5f31 3b0a  4x2_t B_0, B_1;.
-0000a930: 2020 7d3b 0a0a 2020 4549 4745 4e5f 5354    };..  EIGEN_ST
-0000a940: 524f 4e47 5f49 4e4c 494e 4520 766f 6964  RONG_INLINE void
-0000a950: 206c 6f61 6452 6873 2863 6f6e 7374 2052   loadRhs(const R
-0000a960: 6873 5363 616c 6172 2a20 622c 2052 6873  hsScalar* b, Rhs
-0000a970: 5061 636b 6574 2620 6465 7374 2920 636f  Packet& dest) co
-0000a980: 6e73 740a 2020 7b0a 2020 2020 6465 7374  nst.  {.    dest
-0000a990: 203d 202a 623b 0a20 207d 0a0a 2020 4549   = *b;.  }..  EI
-0000a9a0: 4745 4e5f 5354 524f 4e47 5f49 4e4c 494e  GEN_STRONG_INLIN
-0000a9b0: 4520 766f 6964 206c 6f61 6452 6873 2863  E void loadRhs(c
-0000a9c0: 6f6e 7374 2052 6873 5363 616c 6172 2a20  onst RhsScalar* 
-0000a9d0: 622c 2052 6873 5061 636b 6574 7834 2620  b, RhsPacketx4& 
-0000a9e0: 6465 7374 2920 636f 6e73 740a 2020 7b0a  dest) const.  {.
-0000a9f0: 2020 2020 6465 7374 2e42 5f30 203d 2076      dest.B_0 = v
-0000aa00: 6c64 3171 5f66 3634 2862 293b 0a20 2020  ld1q_f64(b);.   
-0000aa10: 2064 6573 742e 425f 3120 3d20 766c 6431   dest.B_1 = vld1
-0000aa20: 715f 6636 3428 622b 3229 3b0a 2020 7d0a  q_f64(b+2);.  }.
-0000aa30: 0a20 2045 4947 454e 5f53 5452 4f4e 475f  .  EIGEN_STRONG_
-0000aa40: 494e 4c49 4e45 2076 6f69 6420 7570 6461  INLINE void upda
-0000aa50: 7465 5268 7328 636f 6e73 7420 5268 7353  teRhs(const RhsS
-0000aa60: 6361 6c61 722a 2062 2c20 5268 7350 6163  calar* b, RhsPac
-0000aa70: 6b65 7426 2064 6573 7429 2063 6f6e 7374  ket& dest) const
-0000aa80: 0a20 207b 0a20 2020 206c 6f61 6452 6873  .  {.    loadRhs
-0000aa90: 2862 2c64 6573 7429 3b0a 2020 7d0a 0a20  (b,dest);.  }.. 
-0000aaa0: 2045 4947 454e 5f53 5452 4f4e 475f 494e   EIGEN_STRONG_IN
-0000aab0: 4c49 4e45 2076 6f69 6420 7570 6461 7465  LINE void update
-0000aac0: 5268 7328 636f 6e73 7420 5268 7353 6361  Rhs(const RhsSca
-0000aad0: 6c61 722a 2c20 5268 7350 6163 6b65 7478  lar*, RhsPacketx
-0000aae0: 3426 2920 636f 6e73 740a 2020 7b7d 0a0a  4&) const.  {}..
-0000aaf0: 2020 4549 4745 4e5f 5354 524f 4e47 5f49    EIGEN_STRONG_I
-0000ab00: 4e4c 494e 4520 766f 6964 206c 6f61 6452  NLINE void loadR
-0000ab10: 6873 5175 6164 2863 6f6e 7374 2052 6873  hsQuad(const Rhs
-0000ab20: 5363 616c 6172 2a20 622c 2052 6873 5061  Scalar* b, RhsPa
-0000ab30: 636b 6574 2620 6465 7374 2920 636f 6e73  cket& dest) cons
-0000ab40: 740a 2020 7b0a 2020 2020 6c6f 6164 5268  t.  {.    loadRh
-0000ab50: 7328 622c 6465 7374 293b 0a20 207d 0a0a  s(b,dest);.  }..
-0000ab60: 2020 4549 4745 4e5f 5354 524f 4e47 5f49    EIGEN_STRONG_I
-0000ab70: 4e4c 494e 4520 766f 6964 206d 6164 6428  NLINE void madd(
-0000ab80: 636f 6e73 7420 4c68 7350 6163 6b65 7426  const LhsPacket&
-0000ab90: 2061 2c20 636f 6e73 7420 5268 7350 6163   a, const RhsPac
-0000aba0: 6b65 7426 2062 2c20 4163 6350 6163 6b65  ket& b, AccPacke
-0000abb0: 7426 2063 2c20 5268 7350 6163 6b65 7426  t& c, RhsPacket&
-0000abc0: 202f 2a74 6d70 2a2f 2c20 636f 6e73 7420   /*tmp*/, const 
-0000abd0: 4669 7865 6449 6e74 3c30 3e26 2920 636f  FixedInt<0>&) co
-0000abe0: 6e73 740a 2020 7b0a 2020 2020 6320 3d20  nst.  {.    c = 
-0000abf0: 7666 6d61 715f 6e5f 6636 3428 632c 2061  vfmaq_n_f64(c, a
-0000ac00: 2c20 6229 3b0a 2020 7d0a 0a20 202f 2f20  , b);.  }..  // 
-0000ac10: 4e4f 5445 3a20 5465 6d70 6c61 7465 2070  NOTE: Template p
-0000ac20: 6172 616d 6574 6572 2069 6e66 6572 656e  arameter inferen
-0000ac30: 6365 2066 6169 6c65 6420 7768 656e 2063  ce failed when c
-0000ac40: 6f6d 7069 6c65 6420 7769 7468 2041 6e64  ompiled with And
-0000ac50: 726f 6964 204e 444b 3a0a 2020 2f2f 2022  roid NDK:.  // "
-0000ac60: 6361 6e64 6964 6174 6520 7465 6d70 6c61  candidate templa
-0000ac70: 7465 2069 676e 6f72 6564 3a20 636f 756c  te ignored: coul
-0000ac80: 6420 6e6f 7420 6d61 7463 6820 2746 6978  d not match 'Fix
-0000ac90: 6564 496e 743c 4e3e 2720 6167 6169 6e73  edInt<N>' agains
-0000aca0: 7420 2745 6967 656e 3a3a 696e 7465 726e  t 'Eigen::intern
-0000acb0: 616c 3a3a 4669 7865 6449 6e74 3c30 3e22  al::FixedInt<0>"
-0000acc0: 2e0a 0a20 2045 4947 454e 5f53 5452 4f4e  ...  EIGEN_STRON
-0000acd0: 475f 494e 4c49 4e45 2076 6f69 6420 6d61  G_INLINE void ma
-0000ace0: 6464 2863 6f6e 7374 204c 6873 5061 636b  dd(const LhsPack
-0000acf0: 6574 2620 612c 2063 6f6e 7374 2052 6873  et& a, const Rhs
-0000ad00: 5061 636b 6574 7834 2620 622c 2041 6363  Packetx4& b, Acc
-0000ad10: 5061 636b 6574 2620 632c 2052 6873 5061  Packet& c, RhsPa
-0000ad20: 636b 6574 2620 2f2a 746d 702a 2f2c 2063  cket& /*tmp*/, c
-0000ad30: 6f6e 7374 2046 6978 6564 496e 743c 303e  onst FixedInt<0>
-0000ad40: 2629 2063 6f6e 7374 0a20 207b 206d 6164  &) const.  { mad
-0000ad50: 645f 6865 6c70 6572 3c30 3e28 612c 2062  d_helper<0>(a, b
-0000ad60: 2c20 6329 3b20 7d0a 2020 4549 4745 4e5f  , c); }.  EIGEN_
-0000ad70: 5354 524f 4e47 5f49 4e4c 494e 4520 766f  STRONG_INLINE vo
-0000ad80: 6964 206d 6164 6428 636f 6e73 7420 4c68  id madd(const Lh
-0000ad90: 7350 6163 6b65 7426 2061 2c20 636f 6e73  sPacket& a, cons
-0000ada0: 7420 5268 7350 6163 6b65 7478 3426 2062  t RhsPacketx4& b
-0000adb0: 2c20 4163 6350 6163 6b65 7426 2063 2c20  , AccPacket& c, 
-0000adc0: 5268 7350 6163 6b65 7426 202f 2a74 6d70  RhsPacket& /*tmp
-0000add0: 2a2f 2c20 636f 6e73 7420 4669 7865 6449  */, const FixedI
-0000ade0: 6e74 3c31 3e26 2920 636f 6e73 740a 2020  nt<1>&) const.  
-0000adf0: 7b20 6d61 6464 5f68 656c 7065 723c 313e  { madd_helper<1>
-0000ae00: 2861 2c20 622c 2063 293b 207d 0a20 2045  (a, b, c); }.  E
-0000ae10: 4947 454e 5f53 5452 4f4e 475f 494e 4c49  IGEN_STRONG_INLI
-0000ae20: 4e45 2076 6f69 6420 6d61 6464 2863 6f6e  NE void madd(con
-0000ae30: 7374 204c 6873 5061 636b 6574 2620 612c  st LhsPacket& a,
-0000ae40: 2063 6f6e 7374 2052 6873 5061 636b 6574   const RhsPacket
-0000ae50: 7834 2620 622c 2041 6363 5061 636b 6574  x4& b, AccPacket
-0000ae60: 2620 632c 2052 6873 5061 636b 6574 2620  & c, RhsPacket& 
-0000ae70: 2f2a 746d 702a 2f2c 2063 6f6e 7374 2046  /*tmp*/, const F
-0000ae80: 6978 6564 496e 743c 323e 2629 2063 6f6e  ixedInt<2>&) con
-0000ae90: 7374 0a20 207b 206d 6164 645f 6865 6c70  st.  { madd_help
-0000aea0: 6572 3c32 3e28 612c 2062 2c20 6329 3b20  er<2>(a, b, c); 
-0000aeb0: 7d0a 2020 4549 4745 4e5f 5354 524f 4e47  }.  EIGEN_STRONG
-0000aec0: 5f49 4e4c 494e 4520 766f 6964 206d 6164  _INLINE void mad
-0000aed0: 6428 636f 6e73 7420 4c68 7350 6163 6b65  d(const LhsPacke
-0000aee0: 7426 2061 2c20 636f 6e73 7420 5268 7350  t& a, const RhsP
-0000aef0: 6163 6b65 7478 3426 2062 2c20 4163 6350  acketx4& b, AccP
-0000af00: 6163 6b65 7426 2063 2c20 5268 7350 6163  acket& c, RhsPac
-0000af10: 6b65 7426 202f 2a74 6d70 2a2f 2c20 636f  ket& /*tmp*/, co
-0000af20: 6e73 7420 4669 7865 6449 6e74 3c33 3e26  nst FixedInt<3>&
-0000af30: 2920 636f 6e73 740a 2020 7b20 6d61 6464  ) const.  { madd
-0000af40: 5f68 656c 7065 723c 333e 2861 2c20 622c  _helper<3>(a, b,
-0000af50: 2063 293b 207d 0a0a 2070 7269 7661 7465   c); }.. private
-0000af60: 3a0a 2020 7465 6d70 6c61 7465 203c 696e  :.  template <in
-0000af70: 7420 4c61 6e65 4944 3e0a 2020 4549 4745  t LaneID>.  EIGE
-0000af80: 4e5f 5354 524f 4e47 5f49 4e4c 494e 4520  N_STRONG_INLINE 
-0000af90: 766f 6964 206d 6164 645f 6865 6c70 6572  void madd_helper
-0000afa0: 2863 6f6e 7374 204c 6873 5061 636b 6574  (const LhsPacket
-0000afb0: 2620 612c 2063 6f6e 7374 2052 6873 5061  & a, const RhsPa
-0000afc0: 636b 6574 7834 2620 622c 2041 6363 5061  cketx4& b, AccPa
-0000afd0: 636b 6574 2620 6329 2063 6f6e 7374 0a20  cket& c) const. 
-0000afe0: 207b 0a20 2020 2023 6966 2045 4947 454e   {.    #if EIGEN
-0000aff0: 5f43 4f4d 505f 474e 5543 5f53 5452 4943  _COMP_GNUC_STRIC
-0000b000: 5420 2626 2021 2845 4947 454e 5f47 4e55  T && !(EIGEN_GNU
-0000b010: 435f 4154 5f4c 4541 5354 2839 2c30 2929  C_AT_LEAST(9,0))
-0000b020: 0a20 2020 202f 2f20 776f 726b 6172 6f75  .    // workarou
-0000b030: 6e64 2067 6363 2069 7373 7565 2068 7474  nd gcc issue htt
-0000b040: 7073 3a2f 2f67 6363 2e67 6e75 2e6f 7267  ps://gcc.gnu.org
-0000b050: 2f62 7567 7a69 6c6c 612f 7368 6f77 5f62  /bugzilla/show_b
-0000b060: 7567 2e63 6769 3f69 643d 3839 3130 310a  ug.cgi?id=89101.
-0000b070: 2020 2020 2f2f 2076 666d 6171 5f6c 616e      // vfmaq_lan
-0000b080: 6571 5f66 3634 2069 7320 696d 706c 656d  eq_f64 is implem
-0000b090: 656e 7465 6420 7468 726f 7567 6820 6120  ented through a 
-0000b0a0: 636f 7374 6c79 2064 7570 0a20 2020 2020  costly dup.     
-0000b0b0: 2020 2020 6966 284c 616e 6549 443d 3d30      if(LaneID==0
-0000b0c0: 2920 2061 736d 2822 666d 6c61 2025 302e  )  asm("fmla %0.
-0000b0d0: 3264 2c20 2531 2e32 642c 2025 322e 645b  2d, %1.2d, %2.d[
-0000b0e0: 305d 5c6e 2220 3a20 222b 7722 2028 6329  0]\n" : "+w" (c)
-0000b0f0: 203a 2022 7722 2028 6129 2c20 2277 2220   : "w" (a), "w" 
-0000b100: 2862 2e42 5f30 2920 3a20 2029 3b0a 2020  (b.B_0) :  );.  
-0000b110: 2020 656c 7365 2069 6628 4c61 6e65 4944    else if(LaneID
-0000b120: 3d3d 3129 2020 6173 6d28 2266 6d6c 6120  ==1)  asm("fmla 
-0000b130: 2530 2e32 642c 2025 312e 3264 2c20 2532  %0.2d, %1.2d, %2
-0000b140: 2e64 5b31 5d5c 6e22 203a 2022 2b77 2220  .d[1]\n" : "+w" 
-0000b150: 2863 2920 3a20 2277 2220 2861 292c 2022  (c) : "w" (a), "
-0000b160: 7722 2028 622e 425f 3029 203a 2020 293b  w" (b.B_0) :  );
-0000b170: 0a20 2020 2065 6c73 6520 6966 284c 616e  .    else if(Lan
-0000b180: 6549 443d 3d32 2920 2061 736d 2822 666d  eID==2)  asm("fm
-0000b190: 6c61 2025 302e 3264 2c20 2531 2e32 642c  la %0.2d, %1.2d,
-0000b1a0: 2025 322e 645b 305d 5c6e 2220 3a20 222b   %2.d[0]\n" : "+
-0000b1b0: 7722 2028 6329 203a 2022 7722 2028 6129  w" (c) : "w" (a)
-0000b1c0: 2c20 2277 2220 2862 2e42 5f31 2920 3a20  , "w" (b.B_1) : 
-0000b1d0: 2029 3b0a 2020 2020 656c 7365 2069 6628   );.    else if(
-0000b1e0: 4c61 6e65 4944 3d3d 3329 2020 6173 6d28  LaneID==3)  asm(
-0000b1f0: 2266 6d6c 6120 2530 2e32 642c 2025 312e  "fmla %0.2d, %1.
-0000b200: 3264 2c20 2532 2e64 5b31 5d5c 6e22 203a  2d, %2.d[1]\n" :
-0000b210: 2022 2b77 2220 2863 2920 3a20 2277 2220   "+w" (c) : "w" 
-0000b220: 2861 292c 2022 7722 2028 622e 425f 3129  (a), "w" (b.B_1)
-0000b230: 203a 2020 293b 0a20 2020 2023 656c 7365   :  );.    #else
-0000b240: 0a20 2020 2020 2020 2020 6966 284c 616e  .         if(Lan
-0000b250: 6549 443d 3d30 2920 6320 3d20 7666 6d61  eID==0) c = vfma
-0000b260: 715f 6c61 6e65 715f 6636 3428 632c 2061  q_laneq_f64(c, a
-0000b270: 2c20 622e 425f 302c 2030 293b 0a20 2020  , b.B_0, 0);.   
-0000b280: 2065 6c73 6520 6966 284c 616e 6549 443d   else if(LaneID=
-0000b290: 3d31 2920 6320 3d20 7666 6d61 715f 6c61  =1) c = vfmaq_la
-0000b2a0: 6e65 715f 6636 3428 632c 2061 2c20 622e  neq_f64(c, a, b.
-0000b2b0: 425f 302c 2031 293b 0a20 2020 2065 6c73  B_0, 1);.    els
-0000b2c0: 6520 6966 284c 616e 6549 443d 3d32 2920  e if(LaneID==2) 
-0000b2d0: 6320 3d20 7666 6d61 715f 6c61 6e65 715f  c = vfmaq_laneq_
-0000b2e0: 6636 3428 632c 2061 2c20 622e 425f 312c  f64(c, a, b.B_1,
-0000b2f0: 2030 293b 0a20 2020 2065 6c73 6520 6966   0);.    else if
-0000b300: 284c 616e 6549 443d 3d33 2920 6320 3d20  (LaneID==3) c = 
-0000b310: 7666 6d61 715f 6c61 6e65 715f 6636 3428  vfmaq_laneq_f64(
-0000b320: 632c 2061 2c20 622e 425f 312c 2031 293b  c, a, b.B_1, 1);
-0000b330: 0a20 2020 2023 656e 6469 660a 2020 7d0a  .    #endif.  }.
-0000b340: 7d3b 0a0a 2365 6e64 6966 0a0a 2f2a 206f  };..#endif../* o
-0000b350: 7074 696d 697a 6564 2047 656e 6572 616c  ptimized General
-0000b360: 2070 6163 6b65 6420 426c 6f63 6b20 2a20   packed Block * 
-0000b370: 7061 636b 6564 2050 616e 656c 2070 726f  packed Panel pro
-0000b380: 6475 6374 206b 6572 6e65 6c0a 202a 0a20  duct kernel. *. 
-0000b390: 2a20 4d69 7869 6e67 2074 7970 6520 6c6f  * Mixing type lo
-0000b3a0: 6769 633a 2043 202b 3d20 4120 2a20 420a  gic: C += A * B.
-0000b3b0: 202a 2020 7c20 2041 2020 7c20 2042 2020   *  |  A  |  B  
-0000b3c0: 7c20 636f 6d6d 656e 7473 0a20 2a20 207c  | comments. *  |
-0000b3d0: 7265 616c 207c 6370 6c78 207c 206e 6f20  real |cplx | no 
-0000b3e0: 7665 6374 6f72 697a 6174 696f 6e20 7965  vectorization ye
-0000b3f0: 742c 2077 6f75 6c64 2072 6571 7569 7265  t, would require
-0000b400: 2074 6f20 7061 636b 2041 2077 6974 6820   to pack A with 
-0000b410: 6475 706c 6963 6174 696f 6e0a 202a 2020  duplication. *  
-0000b420: 7c63 706c 7820 7c72 6561 6c20 7c20 6561  |cplx |real | ea
-0000b430: 7379 2076 6563 746f 7269 7a61 7469 6f6e  sy vectorization
-0000b440: 0a20 2a2f 0a74 656d 706c 6174 653c 7479  . */.template<ty
-0000b450: 7065 6e61 6d65 204c 6873 5363 616c 6172  pename LhsScalar
-0000b460: 2c20 7479 7065 6e61 6d65 2052 6873 5363  , typename RhsSc
-0000b470: 616c 6172 2c20 7479 7065 6e61 6d65 2049  alar, typename I
-0000b480: 6e64 6578 2c20 7479 7065 6e61 6d65 2044  ndex, typename D
-0000b490: 6174 614d 6170 7065 722c 2069 6e74 206d  ataMapper, int m
-0000b4a0: 722c 2069 6e74 206e 722c 2062 6f6f 6c20  r, int nr, bool 
-0000b4b0: 436f 6e6a 7567 6174 654c 6873 2c20 626f  ConjugateLhs, bo
-0000b4c0: 6f6c 2043 6f6e 6a75 6761 7465 5268 733e  ol ConjugateRhs>
-0000b4d0: 0a73 7472 7563 7420 6765 6270 5f6b 6572  .struct gebp_ker
-0000b4e0: 6e65 6c0a 7b0a 2020 7479 7065 6465 6620  nel.{.  typedef 
-0000b4f0: 6765 6270 5f74 7261 6974 733c 4c68 7353  gebp_traits<LhsS
-0000b500: 6361 6c61 722c 5268 7353 6361 6c61 722c  calar,RhsScalar,
-0000b510: 436f 6e6a 7567 6174 654c 6873 2c43 6f6e  ConjugateLhs,Con
-0000b520: 6a75 6761 7465 5268 732c 4172 6368 6974  jugateRhs,Archit
-0000b530: 6563 7475 7265 3a3a 5461 7267 6574 3e20  ecture::Target> 
-0000b540: 5472 6169 7473 3b0a 2020 7479 7065 6465  Traits;.  typede
-0000b550: 6620 6765 6270 5f74 7261 6974 733c 4c68  f gebp_traits<Lh
-0000b560: 7353 6361 6c61 722c 5268 7353 6361 6c61  sScalar,RhsScala
-0000b570: 722c 436f 6e6a 7567 6174 654c 6873 2c43  r,ConjugateLhs,C
-0000b580: 6f6e 6a75 6761 7465 5268 732c 4172 6368  onjugateRhs,Arch
-0000b590: 6974 6563 7475 7265 3a3a 5461 7267 6574  itecture::Target
-0000b5a0: 2c47 4542 5050 6163 6b65 7448 616c 663e  ,GEBPPacketHalf>
-0000b5b0: 2048 616c 6654 7261 6974 733b 0a20 2074   HalfTraits;.  t
-0000b5c0: 7970 6564 6566 2067 6562 705f 7472 6169  ypedef gebp_trai
-0000b5d0: 7473 3c4c 6873 5363 616c 6172 2c52 6873  ts<LhsScalar,Rhs
-0000b5e0: 5363 616c 6172 2c43 6f6e 6a75 6761 7465  Scalar,Conjugate
-0000b5f0: 4c68 732c 436f 6e6a 7567 6174 6552 6873  Lhs,ConjugateRhs
-0000b600: 2c41 7263 6869 7465 6374 7572 653a 3a54  ,Architecture::T
-0000b610: 6172 6765 742c 4745 4250 5061 636b 6574  arget,GEBPPacket
-0000b620: 5175 6172 7465 723e 2051 7561 7274 6572  Quarter> Quarter
-0000b630: 5472 6169 7473 3b0a 2020 0a20 2074 7970  Traits;.  .  typ
-0000b640: 6564 6566 2074 7970 656e 616d 6520 5472  edef typename Tr
-0000b650: 6169 7473 3a3a 5265 7353 6361 6c61 7220  aits::ResScalar 
-0000b660: 5265 7353 6361 6c61 723b 0a20 2074 7970  ResScalar;.  typ
-0000b670: 6564 6566 2074 7970 656e 616d 6520 5472  edef typename Tr
-0000b680: 6169 7473 3a3a 4c68 7350 6163 6b65 7420  aits::LhsPacket 
-0000b690: 4c68 7350 6163 6b65 743b 0a20 2074 7970  LhsPacket;.  typ
-0000b6a0: 6564 6566 2074 7970 656e 616d 6520 5472  edef typename Tr
-0000b6b0: 6169 7473 3a3a 5268 7350 6163 6b65 7420  aits::RhsPacket 
-0000b6c0: 5268 7350 6163 6b65 743b 0a20 2074 7970  RhsPacket;.  typ
-0000b6d0: 6564 6566 2074 7970 656e 616d 6520 5472  edef typename Tr
-0000b6e0: 6169 7473 3a3a 5265 7350 6163 6b65 7420  aits::ResPacket 
-0000b6f0: 5265 7350 6163 6b65 743b 0a20 2074 7970  ResPacket;.  typ
-0000b700: 6564 6566 2074 7970 656e 616d 6520 5472  edef typename Tr
-0000b710: 6169 7473 3a3a 4163 6350 6163 6b65 7420  aits::AccPacket 
-0000b720: 4163 6350 6163 6b65 743b 0a20 2074 7970  AccPacket;.  typ
-0000b730: 6564 6566 2074 7970 656e 616d 6520 5472  edef typename Tr
-0000b740: 6169 7473 3a3a 5268 7350 6163 6b65 7478  aits::RhsPacketx
-0000b750: 3420 5268 7350 6163 6b65 7478 343b 0a0a  4 RhsPacketx4;..
-0000b760: 2020 7479 7065 6465 6620 7479 7065 6e61    typedef typena
-0000b770: 6d65 2052 6873 5061 6e65 6c48 656c 7065  me RhsPanelHelpe
-0000b780: 723c 5268 7350 6163 6b65 742c 2052 6873  r<RhsPacket, Rhs
-0000b790: 5061 636b 6574 7834 2c20 3135 3e3a 3a74  Packetx4, 15>::t
-0000b7a0: 7970 6520 5268 7350 616e 656c 3135 3b0a  ype RhsPanel15;.
-0000b7b0: 0a20 2074 7970 6564 6566 2067 6562 705f  .  typedef gebp_
-0000b7c0: 7472 6169 7473 3c52 6873 5363 616c 6172  traits<RhsScalar
-0000b7d0: 2c4c 6873 5363 616c 6172 2c43 6f6e 6a75  ,LhsScalar,Conju
-0000b7e0: 6761 7465 5268 732c 436f 6e6a 7567 6174  gateRhs,Conjugat
-0000b7f0: 654c 6873 2c41 7263 6869 7465 6374 7572  eLhs,Architectur
-0000b800: 653a 3a54 6172 6765 743e 2053 7761 7070  e::Target> Swapp
-0000b810: 6564 5472 6169 7473 3b0a 0a20 2074 7970  edTraits;..  typ
-0000b820: 6564 6566 2074 7970 656e 616d 6520 5377  edef typename Sw
-0000b830: 6170 7065 6454 7261 6974 733a 3a52 6573  appedTraits::Res
-0000b840: 5363 616c 6172 2053 5265 7353 6361 6c61  Scalar SResScala
-0000b850: 723b 0a20 2074 7970 6564 6566 2074 7970  r;.  typedef typ
-0000b860: 656e 616d 6520 5377 6170 7065 6454 7261  ename SwappedTra
-0000b870: 6974 733a 3a4c 6873 5061 636b 6574 2053  its::LhsPacket S
-0000b880: 4c68 7350 6163 6b65 743b 0a20 2074 7970  LhsPacket;.  typ
-0000b890: 6564 6566 2074 7970 656e 616d 6520 5377  edef typename Sw
-0000b8a0: 6170 7065 6454 7261 6974 733a 3a52 6873  appedTraits::Rhs
-0000b8b0: 5061 636b 6574 2053 5268 7350 6163 6b65  Packet SRhsPacke
-0000b8c0: 743b 0a20 2074 7970 6564 6566 2074 7970  t;.  typedef typ
-0000b8d0: 656e 616d 6520 5377 6170 7065 6454 7261  ename SwappedTra
-0000b8e0: 6974 733a 3a52 6573 5061 636b 6574 2053  its::ResPacket S
-0000b8f0: 5265 7350 6163 6b65 743b 0a20 2074 7970  ResPacket;.  typ
-0000b900: 6564 6566 2074 7970 656e 616d 6520 5377  edef typename Sw
-0000b910: 6170 7065 6454 7261 6974 733a 3a41 6363  appedTraits::Acc
-0000b920: 5061 636b 6574 2053 4163 6350 6163 6b65  Packet SAccPacke
-0000b930: 743b 0a0a 2020 7479 7065 6465 6620 7479  t;..  typedef ty
-0000b940: 7065 6e61 6d65 2048 616c 6654 7261 6974  pename HalfTrait
-0000b950: 733a 3a4c 6873 5061 636b 6574 204c 6873  s::LhsPacket Lhs
-0000b960: 5061 636b 6574 4861 6c66 3b0a 2020 7479  PacketHalf;.  ty
-0000b970: 7065 6465 6620 7479 7065 6e61 6d65 2048  pedef typename H
-0000b980: 616c 6654 7261 6974 733a 3a52 6873 5061  alfTraits::RhsPa
-0000b990: 636b 6574 2052 6873 5061 636b 6574 4861  cket RhsPacketHa
-0000b9a0: 6c66 3b0a 2020 7479 7065 6465 6620 7479  lf;.  typedef ty
-0000b9b0: 7065 6e61 6d65 2048 616c 6654 7261 6974  pename HalfTrait
-0000b9c0: 733a 3a52 6573 5061 636b 6574 2052 6573  s::ResPacket Res
-0000b9d0: 5061 636b 6574 4861 6c66 3b0a 2020 7479  PacketHalf;.  ty
-0000b9e0: 7065 6465 6620 7479 7065 6e61 6d65 2048  pedef typename H
-0000b9f0: 616c 6654 7261 6974 733a 3a41 6363 5061  alfTraits::AccPa
-0000ba00: 636b 6574 2041 6363 5061 636b 6574 4861  cket AccPacketHa
-0000ba10: 6c66 3b0a 0a20 2074 7970 6564 6566 2074  lf;..  typedef t
-0000ba20: 7970 656e 616d 6520 5175 6172 7465 7254  ypename QuarterT
-0000ba30: 7261 6974 733a 3a4c 6873 5061 636b 6574  raits::LhsPacket
-0000ba40: 204c 6873 5061 636b 6574 5175 6172 7465   LhsPacketQuarte
-0000ba50: 723b 0a20 2074 7970 6564 6566 2074 7970  r;.  typedef typ
-0000ba60: 656e 616d 6520 5175 6172 7465 7254 7261  ename QuarterTra
-0000ba70: 6974 733a 3a52 6873 5061 636b 6574 2052  its::RhsPacket R
-0000ba80: 6873 5061 636b 6574 5175 6172 7465 723b  hsPacketQuarter;
-0000ba90: 0a20 2074 7970 6564 6566 2074 7970 656e  .  typedef typen
-0000baa0: 616d 6520 5175 6172 7465 7254 7261 6974  ame QuarterTrait
-0000bab0: 733a 3a52 6573 5061 636b 6574 2052 6573  s::ResPacket Res
-0000bac0: 5061 636b 6574 5175 6172 7465 723b 0a20  PacketQuarter;. 
-0000bad0: 2074 7970 6564 6566 2074 7970 656e 616d   typedef typenam
-0000bae0: 6520 5175 6172 7465 7254 7261 6974 733a  e QuarterTraits:
-0000baf0: 3a41 6363 5061 636b 6574 2041 6363 5061  :AccPacket AccPa
-0000bb00: 636b 6574 5175 6172 7465 723b 0a0a 2020  cketQuarter;..  
-0000bb10: 7479 7065 6465 6620 7479 7065 6e61 6d65  typedef typename
-0000bb20: 2044 6174 614d 6170 7065 723a 3a4c 696e   DataMapper::Lin
-0000bb30: 6561 724d 6170 7065 7220 4c69 6e65 6172  earMapper Linear
-0000bb40: 4d61 7070 6572 3b0a 0a20 2065 6e75 6d20  Mapper;..  enum 
-0000bb50: 7b0a 2020 2020 5665 6374 6f72 697a 6162  {.    Vectorizab
-0000bb60: 6c65 2020 3d20 5472 6169 7473 3a3a 5665  le  = Traits::Ve
-0000bb70: 6374 6f72 697a 6162 6c65 2c0a 2020 2020  ctorizable,.    
-0000bb80: 4c68 7350 726f 6772 6573 7320 2020 3d20  LhsProgress   = 
-0000bb90: 5472 6169 7473 3a3a 4c68 7350 726f 6772  Traits::LhsProgr
-0000bba0: 6573 732c 0a20 2020 204c 6873 5072 6f67  ess,.    LhsProg
-0000bbb0: 7265 7373 4861 6c66 2020 2020 2020 3d20  ressHalf      = 
-0000bbc0: 4861 6c66 5472 6169 7473 3a3a 4c68 7350  HalfTraits::LhsP
-0000bbd0: 726f 6772 6573 732c 0a20 2020 204c 6873  rogress,.    Lhs
-0000bbe0: 5072 6f67 7265 7373 5175 6172 7465 7220  ProgressQuarter 
-0000bbf0: 2020 3d20 5175 6172 7465 7254 7261 6974    = QuarterTrait
-0000bc00: 733a 3a4c 6873 5072 6f67 7265 7373 2c0a  s::LhsProgress,.
-0000bc10: 2020 2020 5268 7350 726f 6772 6573 7320      RhsProgress 
-0000bc20: 2020 3d20 5472 6169 7473 3a3a 5268 7350    = Traits::RhsP
-0000bc30: 726f 6772 6573 732c 0a20 2020 2052 6873  rogress,.    Rhs
-0000bc40: 5072 6f67 7265 7373 4861 6c66 2020 2020  ProgressHalf    
-0000bc50: 2020 3d20 4861 6c66 5472 6169 7473 3a3a    = HalfTraits::
-0000bc60: 5268 7350 726f 6772 6573 732c 0a20 2020  RhsProgress,.   
-0000bc70: 2052 6873 5072 6f67 7265 7373 5175 6172   RhsProgressQuar
-0000bc80: 7465 7220 2020 3d20 5175 6172 7465 7254  ter   = QuarterT
-0000bc90: 7261 6974 733a 3a52 6873 5072 6f67 7265  raits::RhsProgre
-0000bca0: 7373 2c0a 2020 2020 5265 7350 6163 6b65  ss,.    ResPacke
-0000bcb0: 7453 697a 6520 3d20 5472 6169 7473 3a3a  tSize = Traits::
-0000bcc0: 5265 7350 6163 6b65 7453 697a 650a 2020  ResPacketSize.  
-0000bcd0: 7d3b 0a0a 2020 4549 4745 4e5f 444f 4e54  };..  EIGEN_DONT
-0000bce0: 5f49 4e4c 494e 450a 2020 766f 6964 206f  _INLINE.  void o
-0000bcf0: 7065 7261 746f 7228 2928 636f 6e73 7420  perator()(const 
-0000bd00: 4461 7461 4d61 7070 6572 2620 7265 732c  DataMapper& res,
-0000bd10: 2063 6f6e 7374 204c 6873 5363 616c 6172   const LhsScalar
-0000bd20: 2a20 626c 6f63 6b41 2c20 636f 6e73 7420  * blockA, const 
-0000bd30: 5268 7353 6361 6c61 722a 2062 6c6f 636b  RhsScalar* block
-0000bd40: 422c 0a20 2020 2020 2020 2020 2020 2020  B,.             
-0000bd50: 2020 2020 2049 6e64 6578 2072 6f77 732c       Index rows,
-0000bd60: 2049 6e64 6578 2064 6570 7468 2c20 496e   Index depth, In
-0000bd70: 6465 7820 636f 6c73 2c20 5265 7353 6361  dex cols, ResSca
-0000bd80: 6c61 7220 616c 7068 612c 0a20 2020 2020  lar alpha,.     
-0000bd90: 2020 2020 2020 2020 2020 2020 2049 6e64               Ind
-0000bda0: 6578 2073 7472 6964 6541 3d2d 312c 2049  ex strideA=-1, I
-0000bdb0: 6e64 6578 2073 7472 6964 6542 3d2d 312c  ndex strideB=-1,
-0000bdc0: 2049 6e64 6578 206f 6666 7365 7441 3d30   Index offsetA=0
-0000bdd0: 2c20 496e 6465 7820 6f66 6673 6574 423d  , Index offsetB=
-0000bde0: 3029 3b0a 7d3b 0a0a 7465 6d70 6c61 7465  0);.};..template
-0000bdf0: 3c74 7970 656e 616d 6520 4c68 7353 6361  <typename LhsSca
-0000be00: 6c61 722c 2074 7970 656e 616d 6520 5268  lar, typename Rh
-0000be10: 7353 6361 6c61 722c 2074 7970 656e 616d  sScalar, typenam
-0000be20: 6520 496e 6465 782c 2074 7970 656e 616d  e Index, typenam
-0000be30: 6520 4461 7461 4d61 7070 6572 2c20 696e  e DataMapper, in
-0000be40: 7420 6d72 2c20 696e 7420 6e72 2c20 626f  t mr, int nr, bo
-0000be50: 6f6c 2043 6f6e 6a75 6761 7465 4c68 732c  ol ConjugateLhs,
-0000be60: 2062 6f6f 6c20 436f 6e6a 7567 6174 6552   bool ConjugateR
-0000be70: 6873 2c0a 696e 7420 5377 6170 7065 644c  hs,.int SwappedL
-0000be80: 6873 5072 6f67 7265 7373 203d 2067 6562  hsProgress = geb
-0000be90: 705f 7472 6169 7473 3c52 6873 5363 616c  p_traits<RhsScal
-0000bea0: 6172 2c4c 6873 5363 616c 6172 2c43 6f6e  ar,LhsScalar,Con
-0000beb0: 6a75 6761 7465 5268 732c 436f 6e6a 7567  jugateRhs,Conjug
-0000bec0: 6174 654c 6873 2c41 7263 6869 7465 6374  ateLhs,Architect
-0000bed0: 7572 653a 3a54 6172 6765 743e 3a3a 4c68  ure::Target>::Lh
-0000bee0: 7350 726f 6772 6573 733e 0a73 7472 7563  sProgress>.struc
-0000bef0: 7420 6c61 7374 5f72 6f77 5f70 726f 6365  t last_row_proce
-0000bf00: 7373 5f31 365f 7061 636b 6574 730a 7b0a  ss_16_packets.{.
-0000bf10: 2020 7479 7065 6465 6620 6765 6270 5f74    typedef gebp_t
-0000bf20: 7261 6974 733c 4c68 7353 6361 6c61 722c  raits<LhsScalar,
-0000bf30: 5268 7353 6361 6c61 722c 436f 6e6a 7567  RhsScalar,Conjug
-0000bf40: 6174 654c 6873 2c43 6f6e 6a75 6761 7465  ateLhs,Conjugate
-0000bf50: 5268 732c 4172 6368 6974 6563 7475 7265  Rhs,Architecture
-0000bf60: 3a3a 5461 7267 6574 3e20 5472 6169 7473  ::Target> Traits
-0000bf70: 3b0a 2020 7479 7065 6465 6620 6765 6270  ;.  typedef gebp
-0000bf80: 5f74 7261 6974 733c 5268 7353 6361 6c61  _traits<RhsScala
-0000bf90: 722c 4c68 7353 6361 6c61 722c 436f 6e6a  r,LhsScalar,Conj
-0000bfa0: 7567 6174 6552 6873 2c43 6f6e 6a75 6761  ugateRhs,Conjuga
-0000bfb0: 7465 4c68 732c 4172 6368 6974 6563 7475  teLhs,Architectu
-0000bfc0: 7265 3a3a 5461 7267 6574 3e20 5377 6170  re::Target> Swap
-0000bfd0: 7065 6454 7261 6974 733b 0a0a 2020 7479  pedTraits;..  ty
-0000bfe0: 7065 6465 6620 7479 7065 6e61 6d65 2054  pedef typename T
-0000bff0: 7261 6974 733a 3a52 6573 5363 616c 6172  raits::ResScalar
-0000c000: 2052 6573 5363 616c 6172 3b0a 2020 7479   ResScalar;.  ty
-0000c010: 7065 6465 6620 7479 7065 6e61 6d65 2053  pedef typename S
-0000c020: 7761 7070 6564 5472 6169 7473 3a3a 4c68  wappedTraits::Lh
-0000c030: 7350 6163 6b65 7420 534c 6873 5061 636b  sPacket SLhsPack
-0000c040: 6574 3b0a 2020 7479 7065 6465 6620 7479  et;.  typedef ty
-0000c050: 7065 6e61 6d65 2053 7761 7070 6564 5472  pename SwappedTr
-0000c060: 6169 7473 3a3a 5268 7350 6163 6b65 7420  aits::RhsPacket 
-0000c070: 5352 6873 5061 636b 6574 3b0a 2020 7479  SRhsPacket;.  ty
-0000c080: 7065 6465 6620 7479 7065 6e61 6d65 2053  pedef typename S
-0000c090: 7761 7070 6564 5472 6169 7473 3a3a 5265  wappedTraits::Re
-0000c0a0: 7350 6163 6b65 7420 5352 6573 5061 636b  sPacket SResPack
-0000c0b0: 6574 3b0a 2020 7479 7065 6465 6620 7479  et;.  typedef ty
-0000c0c0: 7065 6e61 6d65 2053 7761 7070 6564 5472  pename SwappedTr
-0000c0d0: 6169 7473 3a3a 4163 6350 6163 6b65 7420  aits::AccPacket 
-0000c0e0: 5341 6363 5061 636b 6574 3b0a 0a20 2045  SAccPacket;..  E
-0000c0f0: 4947 454e 5f53 5452 4f4e 475f 494e 4c49  IGEN_STRONG_INLI
-0000c100: 4e45 2076 6f69 6420 6f70 6572 6174 6f72  NE void operator
-0000c110: 2829 2863 6f6e 7374 2044 6174 614d 6170  ()(const DataMap
-0000c120: 7065 7226 2072 6573 2c20 5377 6170 7065  per& res, Swappe
-0000c130: 6454 7261 6974 7320 2673 7472 6169 7473  dTraits &straits
-0000c140: 2c20 636f 6e73 7420 4c68 7353 6361 6c61  , const LhsScala
-0000c150: 722a 2062 6c41 2c0a 2020 2020 2020 2020  r* blA,.        
-0000c160: 2020 2020 2020 2020 2020 636f 6e73 7420            const 
-0000c170: 5268 7353 6361 6c61 722a 2062 6c42 2c20  RhsScalar* blB, 
-0000c180: 496e 6465 7820 6465 7074 682c 2063 6f6e  Index depth, con
-0000c190: 7374 2049 6e64 6578 2065 6e64 6b2c 2049  st Index endk, I
-0000c1a0: 6e64 6578 2069 2c20 496e 6465 7820 6a32  ndex i, Index j2
-0000c1b0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-0000c1c0: 2020 2020 5265 7353 6361 6c61 7220 616c      ResScalar al
-0000c1d0: 7068 612c 2053 4163 6350 6163 6b65 7420  pha, SAccPacket 
-0000c1e0: 2643 3029 0a20 2020 207b 0a20 2020 2020  &C0).    {.     
-0000c1f0: 2045 4947 454e 5f55 4e55 5345 445f 5641   EIGEN_UNUSED_VA
-0000c200: 5249 4142 4c45 2872 6573 293b 0a20 2020  RIABLE(res);.   
-0000c210: 2020 2045 4947 454e 5f55 4e55 5345 445f     EIGEN_UNUSED_
-0000c220: 5641 5249 4142 4c45 2873 7472 6169 7473  VARIABLE(straits
-0000c230: 293b 0a20 2020 2020 2045 4947 454e 5f55  );.      EIGEN_U
-0000c240: 4e55 5345 445f 5641 5249 4142 4c45 2862  NUSED_VARIABLE(b
-0000c250: 6c41 293b 0a20 2020 2020 2045 4947 454e  lA);.      EIGEN
-0000c260: 5f55 4e55 5345 445f 5641 5249 4142 4c45  _UNUSED_VARIABLE
-0000c270: 2862 6c42 293b 0a20 2020 2020 2045 4947  (blB);.      EIG
-0000c280: 454e 5f55 4e55 5345 445f 5641 5249 4142  EN_UNUSED_VARIAB
-0000c290: 4c45 2864 6570 7468 293b 0a20 2020 2020  LE(depth);.     
-0000c2a0: 2045 4947 454e 5f55 4e55 5345 445f 5641   EIGEN_UNUSED_VA
-0000c2b0: 5249 4142 4c45 2865 6e64 6b29 3b0a 2020  RIABLE(endk);.  
-0000c2c0: 2020 2020 4549 4745 4e5f 554e 5553 4544      EIGEN_UNUSED
-0000c2d0: 5f56 4152 4941 424c 4528 6929 3b0a 2020  _VARIABLE(i);.  
-0000c2e0: 2020 2020 4549 4745 4e5f 554e 5553 4544      EIGEN_UNUSED
-0000c2f0: 5f56 4152 4941 424c 4528 6a32 293b 0a20  _VARIABLE(j2);. 
-0000c300: 2020 2020 2045 4947 454e 5f55 4e55 5345       EIGEN_UNUSE
-0000c310: 445f 5641 5249 4142 4c45 2861 6c70 6861  D_VARIABLE(alpha
-0000c320: 293b 0a20 2020 2020 2045 4947 454e 5f55  );.      EIGEN_U
-0000c330: 4e55 5345 445f 5641 5249 4142 4c45 2843  NUSED_VARIABLE(C
-0000c340: 3029 3b0a 2020 2020 7d0a 7d3b 0a0a 0a74  0);.    }.};...t
-0000c350: 656d 706c 6174 653c 7479 7065 6e61 6d65  emplate<typename
-0000c360: 204c 6873 5363 616c 6172 2c20 7479 7065   LhsScalar, type
-0000c370: 6e61 6d65 2052 6873 5363 616c 6172 2c20  name RhsScalar, 
-0000c380: 7479 7065 6e61 6d65 2049 6e64 6578 2c20  typename Index, 
-0000c390: 7479 7065 6e61 6d65 2044 6174 614d 6170  typename DataMap
-0000c3a0: 7065 722c 2069 6e74 206d 722c 2069 6e74  per, int mr, int
-0000c3b0: 206e 722c 2062 6f6f 6c20 436f 6e6a 7567   nr, bool Conjug
-0000c3c0: 6174 654c 6873 2c20 626f 6f6c 2043 6f6e  ateLhs, bool Con
-0000c3d0: 6a75 6761 7465 5268 733e 0a73 7472 7563  jugateRhs>.struc
-0000c3e0: 7420 6c61 7374 5f72 6f77 5f70 726f 6365  t last_row_proce
-0000c3f0: 7373 5f31 365f 7061 636b 6574 733c 4c68  ss_16_packets<Lh
-0000c400: 7353 6361 6c61 722c 2052 6873 5363 616c  sScalar, RhsScal
-0000c410: 6172 2c20 496e 6465 782c 2044 6174 614d  ar, Index, DataM
-0000c420: 6170 7065 722c 2020 6d72 2c20 206e 722c  apper,  mr,  nr,
-0000c430: 2043 6f6e 6a75 6761 7465 4c68 732c 2020   ConjugateLhs,  
-0000c440: 436f 6e6a 7567 6174 6552 6873 2c20 3136  ConjugateRhs, 16
-0000c450: 3e20 7b0a 2020 7479 7065 6465 6620 6765  > {.  typedef ge
-0000c460: 6270 5f74 7261 6974 733c 4c68 7353 6361  bp_traits<LhsSca
-0000c470: 6c61 722c 5268 7353 6361 6c61 722c 436f  lar,RhsScalar,Co
-0000c480: 6e6a 7567 6174 654c 6873 2c43 6f6e 6a75  njugateLhs,Conju
-0000c490: 6761 7465 5268 732c 4172 6368 6974 6563  gateRhs,Architec
-0000c4a0: 7475 7265 3a3a 5461 7267 6574 3e20 5472  ture::Target> Tr
-0000c4b0: 6169 7473 3b0a 2020 7479 7065 6465 6620  aits;.  typedef 
-0000c4c0: 6765 6270 5f74 7261 6974 733c 5268 7353  gebp_traits<RhsS
-0000c4d0: 6361 6c61 722c 4c68 7353 6361 6c61 722c  calar,LhsScalar,
-0000c4e0: 436f 6e6a 7567 6174 6552 6873 2c43 6f6e  ConjugateRhs,Con
-0000c4f0: 6a75 6761 7465 4c68 732c 4172 6368 6974  jugateLhs,Archit
-0000c500: 6563 7475 7265 3a3a 5461 7267 6574 3e20  ecture::Target> 
-0000c510: 5377 6170 7065 6454 7261 6974 733b 0a0a  SwappedTraits;..
-0000c520: 2020 7479 7065 6465 6620 7479 7065 6e61    typedef typena
-0000c530: 6d65 2054 7261 6974 733a 3a52 6573 5363  me Traits::ResSc
-0000c540: 616c 6172 2052 6573 5363 616c 6172 3b0a  alar ResScalar;.
-0000c550: 2020 7479 7065 6465 6620 7479 7065 6e61    typedef typena
-0000c560: 6d65 2053 7761 7070 6564 5472 6169 7473  me SwappedTraits
-0000c570: 3a3a 4c68 7350 6163 6b65 7420 534c 6873  ::LhsPacket SLhs
-0000c580: 5061 636b 6574 3b0a 2020 7479 7065 6465  Packet;.  typede
-0000c590: 6620 7479 7065 6e61 6d65 2053 7761 7070  f typename Swapp
-0000c5a0: 6564 5472 6169 7473 3a3a 5268 7350 6163  edTraits::RhsPac
-0000c5b0: 6b65 7420 5352 6873 5061 636b 6574 3b0a  ket SRhsPacket;.
-0000c5c0: 2020 7479 7065 6465 6620 7479 7065 6e61    typedef typena
-0000c5d0: 6d65 2053 7761 7070 6564 5472 6169 7473  me SwappedTraits
-0000c5e0: 3a3a 5265 7350 6163 6b65 7420 5352 6573  ::ResPacket SRes
-0000c5f0: 5061 636b 6574 3b0a 2020 7479 7065 6465  Packet;.  typede
-0000c600: 6620 7479 7065 6e61 6d65 2053 7761 7070  f typename Swapp
-0000c610: 6564 5472 6169 7473 3a3a 4163 6350 6163  edTraits::AccPac
-0000c620: 6b65 7420 5341 6363 5061 636b 6574 3b0a  ket SAccPacket;.
-0000c630: 0a20 2045 4947 454e 5f53 5452 4f4e 475f  .  EIGEN_STRONG_
-0000c640: 494e 4c49 4e45 2076 6f69 6420 6f70 6572  INLINE void oper
-0000c650: 6174 6f72 2829 2863 6f6e 7374 2044 6174  ator()(const Dat
-0000c660: 614d 6170 7065 7226 2072 6573 2c20 5377  aMapper& res, Sw
-0000c670: 6170 7065 6454 7261 6974 7320 2673 7472  appedTraits &str
-0000c680: 6169 7473 2c20 636f 6e73 7420 4c68 7353  aits, const LhsS
-0000c690: 6361 6c61 722a 2062 6c41 2c0a 2020 2020  calar* blA,.    
-0000c6a0: 2020 2020 2020 2020 2020 2020 2020 636f                co
-0000c6b0: 6e73 7420 5268 7353 6361 6c61 722a 2062  nst RhsScalar* b
-0000c6c0: 6c42 2c20 496e 6465 7820 6465 7074 682c  lB, Index depth,
-0000c6d0: 2063 6f6e 7374 2049 6e64 6578 2065 6e64   const Index end
-0000c6e0: 6b2c 2049 6e64 6578 2069 2c20 496e 6465  k, Index i, Inde
-0000c6f0: 7820 6a32 2c0a 2020 2020 2020 2020 2020  x j2,.          
-0000c700: 2020 2020 2020 2020 5265 7353 6361 6c61          ResScala
-0000c710: 7220 616c 7068 612c 2053 4163 6350 6163  r alpha, SAccPac
-0000c720: 6b65 7420 2643 3029 0a20 207b 0a20 2020  ket &C0).  {.   
-0000c730: 2074 7970 6564 6566 2074 7970 656e 616d   typedef typenam
-0000c740: 6520 756e 7061 636b 6574 5f74 7261 6974  e unpacket_trait
-0000c750: 733c 7479 7065 6e61 6d65 2075 6e70 6163  s<typename unpac
-0000c760: 6b65 745f 7472 6169 7473 3c53 5265 7350  ket_traits<SResP
-0000c770: 6163 6b65 743e 3a3a 6861 6c66 3e3a 3a68  acket>::half>::h
-0000c780: 616c 6620 5352 6573 5061 636b 6574 5175  alf SResPacketQu
-0000c790: 6172 7465 723b 0a20 2020 2074 7970 6564  arter;.    typed
-0000c7a0: 6566 2074 7970 656e 616d 6520 756e 7061  ef typename unpa
-0000c7b0: 636b 6574 5f74 7261 6974 733c 7479 7065  cket_traits<type
-0000c7c0: 6e61 6d65 2075 6e70 6163 6b65 745f 7472  name unpacket_tr
-0000c7d0: 6169 7473 3c53 4c68 7350 6163 6b65 743e  aits<SLhsPacket>
-0000c7e0: 3a3a 6861 6c66 3e3a 3a68 616c 6620 534c  ::half>::half SL
-0000c7f0: 6873 5061 636b 6574 5175 6172 7465 723b  hsPacketQuarter;
-0000c800: 0a20 2020 2074 7970 6564 6566 2074 7970  .    typedef typ
-0000c810: 656e 616d 6520 756e 7061 636b 6574 5f74  ename unpacket_t
-0000c820: 7261 6974 733c 7479 7065 6e61 6d65 2075  raits<typename u
-0000c830: 6e70 6163 6b65 745f 7472 6169 7473 3c53  npacket_traits<S
-0000c840: 5268 7350 6163 6b65 743e 3a3a 6861 6c66  RhsPacket>::half
-0000c850: 3e3a 3a68 616c 6620 5352 6873 5061 636b  >::half SRhsPack
-0000c860: 6574 5175 6172 7465 723b 0a20 2020 2074  etQuarter;.    t
-0000c870: 7970 6564 6566 2074 7970 656e 616d 6520  ypedef typename 
-0000c880: 756e 7061 636b 6574 5f74 7261 6974 733c  unpacket_traits<
-0000c890: 7479 7065 6e61 6d65 2075 6e70 6163 6b65  typename unpacke
-0000c8a0: 745f 7472 6169 7473 3c53 4163 6350 6163  t_traits<SAccPac
-0000c8b0: 6b65 743e 3a3a 6861 6c66 3e3a 3a68 616c  ket>::half>::hal
-0000c8c0: 6620 5341 6363 5061 636b 6574 5175 6172  f SAccPacketQuar
-0000c8d0: 7465 723b 0a0a 2020 2020 5352 6573 5061  ter;..    SResPa
-0000c8e0: 636b 6574 5175 6172 7465 7220 5220 3d20  cketQuarter R = 
-0000c8f0: 7265 732e 7465 6d70 6c61 7465 2067 6174  res.template gat
-0000c900: 6865 7250 6163 6b65 743c 5352 6573 5061  herPacket<SResPa
-0000c910: 636b 6574 5175 6172 7465 723e 2869 2c20  cketQuarter>(i, 
-0000c920: 6a32 293b 0a20 2020 2053 5265 7350 6163  j2);.    SResPac
-0000c930: 6b65 7451 7561 7274 6572 2061 6c70 6861  ketQuarter alpha
-0000c940: 7620 3d20 7073 6574 313c 5352 6573 5061  v = pset1<SResPa
-0000c950: 636b 6574 5175 6172 7465 723e 2861 6c70  cketQuarter>(alp
-0000c960: 6861 293b 0a0a 2020 2020 6966 2028 6465  ha);..    if (de
-0000c970: 7074 6820 2d20 656e 646b 203e 2030 290a  pth - endk > 0).
-0000c980: 2020 2020 2020 7b0a 092f 2f20 5765 2068        {..// We h
-0000c990: 6176 6520 746f 2068 616e 646c 6520 7468  ave to handle th
-0000c9a0: 6520 6c61 7374 2072 6f77 2873 2920 6f66  e last row(s) of
-0000c9b0: 2074 6865 2072 6873 2c20 7768 6963 680a   the rhs, which.
-0000c9c0: 092f 2f20 636f 7272 6573 706f 6e64 2074  .// correspond t
-0000c9d0: 6f20 6120 6861 6c66 2d70 6163 6b65 740a  o a half-packet.
-0000c9e0: 0953 4163 6350 6163 6b65 7451 7561 7274  .SAccPacketQuart
-0000c9f0: 6572 2063 3020 3d20 7072 6564 7578 5f68  er c0 = predux_h
-0000ca00: 616c 665f 646f 7774 6f34 2870 7265 6475  alf_dowto4(predu
-0000ca10: 785f 6861 6c66 5f64 6f77 746f 3428 4330  x_half_dowto4(C0
-0000ca20: 2929 3b0a 0a09 666f 7220 2849 6e64 6578  ));...for (Index
-0000ca30: 206b 6b20 3d20 656e 646b 3b20 6b6b 203c   kk = endk; kk <
-0000ca40: 2064 6570 7468 3b20 6b6b 2b2b 290a 0920   depth; kk++).. 
-0000ca50: 207b 0a09 2020 2020 534c 6873 5061 636b   {..    SLhsPack
-0000ca60: 6574 5175 6172 7465 7220 6130 3b0a 0920  etQuarter a0;.. 
-0000ca70: 2020 2053 5268 7350 6163 6b65 7451 7561     SRhsPacketQua
-0000ca80: 7274 6572 2062 303b 0a09 2020 2020 7374  rter b0;..    st
-0000ca90: 7261 6974 732e 6c6f 6164 4c68 7355 6e61  raits.loadLhsUna
-0000caa0: 6c69 676e 6564 2862 6c42 2c20 6130 293b  ligned(blB, a0);
-0000cab0: 0a09 2020 2020 7374 7261 6974 732e 6c6f  ..    straits.lo
-0000cac0: 6164 5268 7328 626c 412c 2062 3029 3b0a  adRhs(blA, b0);.
-0000cad0: 0920 2020 2073 7472 6169 7473 2e6d 6164  .    straits.mad
-0000cae0: 6428 6130 2c62 302c 6330 2c62 302c 2066  d(a0,b0,c0,b0, f
-0000caf0: 6978 3c30 3e29 3b0a 0920 2020 2062 6c42  ix<0>);..    blB
-0000cb00: 202b 3d20 5377 6170 7065 6454 7261 6974   += SwappedTrait
-0000cb10: 733a 3a4c 6873 5072 6f67 7265 7373 2f34  s::LhsProgress/4
-0000cb20: 3b0a 0920 2020 2062 6c41 202b 3d20 313b  ;..    blA += 1;
-0000cb30: 0a09 2020 7d0a 0973 7472 6169 7473 2e61  ..  }..straits.a
-0000cb40: 6363 2863 302c 2061 6c70 6861 762c 2052  cc(c0, alphav, R
-0000cb50: 293b 0a20 2020 2020 207d 0a20 2020 2065  );.      }.    e
-0000cb60: 6c73 650a 2020 2020 2020 7b0a 0973 7472  lse.      {..str
-0000cb70: 6169 7473 2e61 6363 2870 7265 6475 785f  aits.acc(predux_
-0000cb80: 6861 6c66 5f64 6f77 746f 3428 7072 6564  half_dowto4(pred
-0000cb90: 7578 5f68 616c 665f 646f 7774 6f34 2843  ux_half_dowto4(C
-0000cba0: 3029 292c 2061 6c70 6861 762c 2052 293b  0)), alphav, R);
-0000cbb0: 0a20 2020 2020 207d 0a20 2020 2072 6573  .      }.    res
-0000cbc0: 2e73 6361 7474 6572 5061 636b 6574 2869  .scatterPacket(i
-0000cbd0: 2c20 6a32 2c20 5229 3b0a 2020 7d0a 7d3b  , j2, R);.  }.};
-0000cbe0: 0a0a 7465 6d70 6c61 7465 3c69 6e74 206e  ..template<int n
-0000cbf0: 722c 2049 6e64 6578 204c 6873 5072 6f67  r, Index LhsProg
-0000cc00: 7265 7373 2c20 496e 6465 7820 5268 7350  ress, Index RhsP
-0000cc10: 726f 6772 6573 732c 2074 7970 656e 616d  rogress, typenam
-0000cc20: 6520 4c68 7353 6361 6c61 722c 2074 7970  e LhsScalar, typ
-0000cc30: 656e 616d 6520 5268 7353 6361 6c61 722c  ename RhsScalar,
-0000cc40: 2074 7970 656e 616d 6520 5265 7353 6361   typename ResSca
-0000cc50: 6c61 722c 2074 7970 656e 616d 6520 4163  lar, typename Ac
-0000cc60: 6350 6163 6b65 742c 2074 7970 656e 616d  cPacket, typenam
-0000cc70: 6520 4c68 7350 6163 6b65 742c 2074 7970  e LhsPacket, typ
-0000cc80: 656e 616d 6520 5268 7350 6163 6b65 742c  ename RhsPacket,
-0000cc90: 2074 7970 656e 616d 6520 5265 7350 6163   typename ResPac
-0000cca0: 6b65 742c 2074 7970 656e 616d 6520 4745  ket, typename GE
-0000ccb0: 4250 5472 6169 7473 2c20 7479 7065 6e61  BPTraits, typena
-0000ccc0: 6d65 204c 696e 6561 724d 6170 7065 722c  me LinearMapper,
-0000ccd0: 2074 7970 656e 616d 6520 4461 7461 4d61   typename DataMa
-0000cce0: 7070 6572 3e0a 7374 7275 6374 206c 6873  pper>.struct lhs
-0000ccf0: 5f70 726f 6365 7373 5f6f 6e65 5f70 6163  _process_one_pac
-0000cd00: 6b65 740a 7b0a 2020 7479 7065 6465 6620  ket.{.  typedef 
-0000cd10: 7479 7065 6e61 6d65 2047 4542 5054 7261  typename GEBPTra
-0000cd20: 6974 733a 3a52 6873 5061 636b 6574 7834  its::RhsPacketx4
-0000cd30: 2052 6873 5061 636b 6574 7834 3b0a 0a20   RhsPacketx4;.. 
-0000cd40: 2045 4947 454e 5f53 5452 4f4e 475f 494e   EIGEN_STRONG_IN
-0000cd50: 4c49 4e45 2076 6f69 6420 7065 656c 6564  LINE void peeled
-0000cd60: 5f6b 635f 6f6e 6573 7465 7028 496e 6465  _kc_onestep(Inde
-0000cd70: 7820 4b2c 2063 6f6e 7374 204c 6873 5363  x K, const LhsSc
-0000cd80: 616c 6172 2a20 626c 412c 2063 6f6e 7374  alar* blA, const
-0000cd90: 2052 6873 5363 616c 6172 2a20 626c 422c   RhsScalar* blB,
-0000cda0: 2047 4542 5054 7261 6974 7320 7472 6169   GEBPTraits trai
-0000cdb0: 7473 2c20 4c68 7350 6163 6b65 7420 2a41  ts, LhsPacket *A
-0000cdc0: 302c 2052 6873 5061 636b 6574 7834 202a  0, RhsPacketx4 *
-0000cdd0: 7268 735f 7061 6e65 6c2c 2052 6873 5061  rhs_panel, RhsPa
-0000cde0: 636b 6574 202a 5430 2c20 4163 6350 6163  cket *T0, AccPac
-0000cdf0: 6b65 7420 2a43 302c 2041 6363 5061 636b  ket *C0, AccPack
-0000ce00: 6574 202a 4331 2c20 4163 6350 6163 6b65  et *C1, AccPacke
-0000ce10: 7420 2a43 322c 2041 6363 5061 636b 6574  t *C2, AccPacket
-0000ce20: 202a 4333 290a 2020 7b0a 2020 2020 4549   *C3).  {.    EI
-0000ce30: 4745 4e5f 4153 4d5f 434f 4d4d 454e 5428  GEN_ASM_COMMENT(
-0000ce40: 2262 6567 696e 2073 7465 7020 6f66 2067  "begin step of g
-0000ce50: 6562 7020 6d69 6372 6f20 6b65 726e 656c  ebp micro kernel
-0000ce60: 2031 5834 2229 3b0a 2020 2020 4549 4745   1X4");.    EIGE
-0000ce70: 4e5f 4153 4d5f 434f 4d4d 454e 5428 224e  N_ASM_COMMENT("N
-0000ce80: 6f74 653a 2074 6865 7365 2061 736d 2063  ote: these asm c
-0000ce90: 6f6d 6d65 6e74 7320 776f 726b 2061 726f  omments work aro
-0000cea0: 756e 6420 6275 6720 3933 3521 2229 3b0a  und bug 935!");.
-0000ceb0: 2020 2020 7472 6169 7473 2e6c 6f61 644c      traits.loadL
-0000cec0: 6873 2826 626c 415b 2830 2b31 2a4b 292a  hs(&blA[(0+1*K)*
-0000ced0: 4c68 7350 726f 6772 6573 735d 2c20 2a41  LhsProgress], *A
-0000cee0: 3029 3b0a 2020 2020 7472 6169 7473 2e6c  0);.    traits.l
-0000cef0: 6f61 6452 6873 2826 626c 425b 2830 2b34  oadRhs(&blB[(0+4
-0000cf00: 2a4b 292a 5268 7350 726f 6772 6573 735d  *K)*RhsProgress]
-0000cf10: 2c20 2a72 6873 5f70 616e 656c 293b 0a20  , *rhs_panel);. 
-0000cf20: 2020 2074 7261 6974 732e 6d61 6464 282a     traits.madd(*
-0000cf30: 4130 2c20 2a72 6873 5f70 616e 656c 2c20  A0, *rhs_panel, 
-0000cf40: 2a43 302c 202a 5430 2c20 6669 783c 303e  *C0, *T0, fix<0>
-0000cf50: 293b 0a20 2020 2074 7261 6974 732e 6d61  );.    traits.ma
-0000cf60: 6464 282a 4130 2c20 2a72 6873 5f70 616e  dd(*A0, *rhs_pan
-0000cf70: 656c 2c20 2a43 312c 202a 5430 2c20 6669  el, *C1, *T0, fi
-0000cf80: 783c 313e 293b 0a20 2020 2074 7261 6974  x<1>);.    trait
-0000cf90: 732e 6d61 6464 282a 4130 2c20 2a72 6873  s.madd(*A0, *rhs
-0000cfa0: 5f70 616e 656c 2c20 2a43 322c 202a 5430  _panel, *C2, *T0
-0000cfb0: 2c20 6669 783c 323e 293b 0a20 2020 2074  , fix<2>);.    t
-0000cfc0: 7261 6974 732e 6d61 6464 282a 4130 2c20  raits.madd(*A0, 
-0000cfd0: 2a72 6873 5f70 616e 656c 2c20 2a43 332c  *rhs_panel, *C3,
-0000cfe0: 202a 5430 2c20 6669 783c 333e 293b 0a20   *T0, fix<3>);. 
-0000cff0: 2020 2023 6966 2045 4947 454e 5f47 4e55     #if EIGEN_GNU
-0000d000: 435f 4154 5f4c 4541 5354 2836 2c30 2920  C_AT_LEAST(6,0) 
-0000d010: 2626 2064 6566 696e 6564 2845 4947 454e  && defined(EIGEN
-0000d020: 5f56 4543 544f 5249 5a45 5f53 5345 290a  _VECTORIZE_SSE).
-0000d030: 2020 2020 5f5f 6173 6d5f 5f20 2028 2222      __asm__  (""
-0000d040: 203a 2022 2b78 2c6d 2220 282a 4130 2929   : "+x,m" (*A0))
-0000d050: 3b0a 2020 2020 2365 6e64 6966 0a20 2020  ;.    #endif.   
-0000d060: 2045 4947 454e 5f41 534d 5f43 4f4d 4d45   EIGEN_ASM_COMME
-0000d070: 4e54 2822 656e 6420 7374 6570 206f 6620  NT("end step of 
-0000d080: 6765 6270 206d 6963 726f 206b 6572 6e65  gebp micro kerne
-0000d090: 6c20 3158 3422 293b 0a20 207d 0a0a 2020  l 1X4");.  }..  
-0000d0a0: 4549 4745 4e5f 5354 524f 4e47 5f49 4e4c  EIGEN_STRONG_INL
-0000d0b0: 494e 4520 766f 6964 206f 7065 7261 746f  INE void operato
-0000d0c0: 7228 2928 0a20 2020 2063 6f6e 7374 2044  r()(.    const D
-0000d0d0: 6174 614d 6170 7065 7226 2072 6573 2c20  ataMapper& res, 
-0000d0e0: 636f 6e73 7420 4c68 7353 6361 6c61 722a  const LhsScalar*
-0000d0f0: 2062 6c6f 636b 412c 2063 6f6e 7374 2052   blockA, const R
-0000d100: 6873 5363 616c 6172 2a20 626c 6f63 6b42  hsScalar* blockB
-0000d110: 2c20 5265 7353 6361 6c61 7220 616c 7068  , ResScalar alph
-0000d120: 612c 0a20 2020 2049 6e64 6578 2070 6565  a,.    Index pee
-0000d130: 6c53 7461 7274 2c20 496e 6465 7820 7065  lStart, Index pe
-0000d140: 656c 456e 642c 2049 6e64 6578 2073 7472  elEnd, Index str
-0000d150: 6964 6541 2c20 496e 6465 7820 7374 7269  ideA, Index stri
-0000d160: 6465 422c 2049 6e64 6578 206f 6666 7365  deB, Index offse
-0000d170: 7441 2c20 496e 6465 7820 6f66 6673 6574  tA, Index offset
-0000d180: 422c 0a20 2020 2069 6e74 2070 7265 6665  B,.    int prefe
-0000d190: 7463 685f 7265 735f 6f66 6673 6574 2c20  tch_res_offset, 
-0000d1a0: 496e 6465 7820 7065 656c 6564 5f6b 632c  Index peeled_kc,
-0000d1b0: 2049 6e64 6578 2070 6b2c 2049 6e64 6578   Index pk, Index
-0000d1c0: 2063 6f6c 732c 2049 6e64 6578 2064 6570   cols, Index dep
-0000d1d0: 7468 2c20 496e 6465 7820 7061 636b 6574  th, Index packet
-0000d1e0: 5f63 6f6c 7334 290a 2020 7b0a 2020 2020  _cols4).  {.    
-0000d1f0: 4745 4250 5472 6169 7473 2074 7261 6974  GEBPTraits trait
-0000d200: 733b 0a0a 2020 2020 2f2f 206c 6f6f 7073  s;..    // loops
-0000d210: 206f 6e20 6561 6368 206c 6172 6765 7374   on each largest
-0000d220: 206d 6963 726f 2068 6f72 697a 6f6e 7461   micro horizonta
-0000d230: 6c20 7061 6e65 6c20 6f66 206c 6873 0a20  l panel of lhs. 
-0000d240: 2020 202f 2f20 284c 6873 5072 6f67 7265     // (LhsProgre
-0000d250: 7373 2078 2064 6570 7468 290a 2020 2020  ss x depth).    
-0000d260: 666f 7228 496e 6465 7820 693d 7065 656c  for(Index i=peel
-0000d270: 5374 6172 743b 2069 3c70 6565 6c45 6e64  Start; i<peelEnd
-0000d280: 3b20 692b 3d4c 6873 5072 6f67 7265 7373  ; i+=LhsProgress
-0000d290: 290a 2020 2020 7b0a 2020 2020 2020 2f2f  ).    {.      //
-0000d2a0: 206c 6f6f 7073 206f 6e20 6561 6368 206c   loops on each l
-0000d2b0: 6172 6765 7374 206d 6963 726f 2076 6572  argest micro ver
-0000d2c0: 7469 6361 6c20 7061 6e65 6c20 6f66 2072  tical panel of r
-0000d2d0: 6873 2028 6465 7074 6820 2a20 6e72 290a  hs (depth * nr).
-0000d2e0: 2020 2020 2020 666f 7228 496e 6465 7820        for(Index 
-0000d2f0: 6a32 3d30 3b20 6a32 3c70 6163 6b65 745f  j2=0; j2<packet_
-0000d300: 636f 6c73 343b 206a 322b 3d6e 7229 0a20  cols4; j2+=nr). 
-0000d310: 2020 2020 207b 0a20 2020 2020 2020 202f       {.        /
-0000d320: 2f20 5765 2073 656c 6563 7420 6120 4c68  / We select a Lh
-0000d330: 7350 726f 6772 6573 7320 7820 6e72 206d  sProgress x nr m
-0000d340: 6963 726f 2062 6c6f 636b 206f 6620 7265  icro block of re
-0000d350: 730a 2020 2020 2020 2020 2f2f 2077 6869  s.        // whi
-0000d360: 6368 2069 7320 656e 7469 7265 6c79 2073  ch is entirely s
-0000d370: 746f 7265 6420 696e 746f 2031 2078 206e  tored into 1 x n
-0000d380: 7220 7265 6769 7374 6572 732e 0a0a 2020  r registers...  
-0000d390: 2020 2020 2020 636f 6e73 7420 4c68 7353        const LhsS
-0000d3a0: 6361 6c61 722a 2062 6c41 203d 2026 626c  calar* blA = &bl
-0000d3b0: 6f63 6b41 5b69 2a73 7472 6964 6541 2b6f  ockA[i*strideA+o
-0000d3c0: 6666 7365 7441 2a28 4c68 7350 726f 6772  ffsetA*(LhsProgr
-0000d3d0: 6573 7329 5d3b 0a20 2020 2020 2020 2070  ess)];.        p
-0000d3e0: 7265 6665 7463 6828 2662 6c41 5b30 5d29  refetch(&blA[0])
-0000d3f0: 3b0a 0a20 2020 2020 2020 202f 2f20 6765  ;..        // ge
-0000d400: 7473 2072 6573 2062 6c6f 636b 2061 7320  ts res block as 
-0000d410: 7265 6769 7374 6572 0a20 2020 2020 2020  register.       
-0000d420: 2041 6363 5061 636b 6574 2043 302c 2043   AccPacket C0, C
-0000d430: 312c 2043 322c 2043 333b 0a20 2020 2020  1, C2, C3;.     
-0000d440: 2020 2074 7261 6974 732e 696e 6974 4163     traits.initAc
-0000d450: 6328 4330 293b 0a20 2020 2020 2020 2074  c(C0);.        t
-0000d460: 7261 6974 732e 696e 6974 4163 6328 4331  raits.initAcc(C1
-0000d470: 293b 0a20 2020 2020 2020 2074 7261 6974  );.        trait
-0000d480: 732e 696e 6974 4163 6328 4332 293b 0a20  s.initAcc(C2);. 
-0000d490: 2020 2020 2020 2074 7261 6974 732e 696e         traits.in
-0000d4a0: 6974 4163 6328 4333 293b 0a20 2020 2020  itAcc(C3);.     
-0000d4b0: 2020 202f 2f20 546f 2069 6d70 726f 7665     // To improve
-0000d4c0: 2069 6e73 7472 7563 7469 6f6e 2070 6970   instruction pip
-0000d4d0: 656c 696e 696e 672c 206c 6574 2773 2064  elining, let's d
-0000d4e0: 6f75 626c 6520 7468 6520 6163 6375 6d75  ouble the accumu
-0000d4f0: 6c61 7469 6f6e 2072 6567 6973 7465 7273  lation registers
-0000d500: 3a0a 2020 2020 2020 2020 2f2f 2020 6576  :.        //  ev
-0000d510: 656e 206b 2077 696c 6c20 6163 6375 6d75  en k will accumu
-0000d520: 6c61 7465 2069 6e20 432a 2c20 7768 696c  late in C*, whil
-0000d530: 6520 6f64 6420 6b20 7769 6c6c 2061 6363  e odd k will acc
-0000d540: 756d 756c 6174 6520 696e 2044 2a2e 0a20  umulate in D*.. 
-0000d550: 2020 2020 2020 202f 2f20 5468 6973 2074         // This t
-0000d560: 7269 636b 2069 7320 6372 7574 6961 6c20  rick is crutial 
-0000d570: 746f 2067 6574 2067 6f6f 6420 7065 7266  to get good perf
-0000d580: 6f72 6d61 6e63 6520 7769 7468 2046 4d41  ormance with FMA
-0000d590: 2c20 6f74 6865 7277 6973 6520 6974 2069  , otherwise it i
-0000d5a0: 7320 0a20 2020 2020 2020 202f 2f20 6163  s .        // ac
-0000d5b0: 7475 616c 6c79 2066 6173 7465 7220 746f  tually faster to
-0000d5c0: 2070 6572 666f 726d 2073 6570 6172 6174   perform separat
-0000d5d0: 6564 204d 554c 2b41 4444 2062 6563 6175  ed MUL+ADD becau
-0000d5e0: 7365 206f 6620 6120 6e61 7475 7261 6c6c  se of a naturall
-0000d5f0: 790a 2020 2020 2020 2020 2f2f 2062 6574  y.        // bet
-0000d600: 7465 7220 696e 7374 7275 6374 696f 6e2d  ter instruction-
-0000d610: 6c65 7665 6c20 7061 7261 6c6c 656c 6973  level parallelis
-0000d620: 6d2e 0a20 2020 2020 2020 2041 6363 5061  m..        AccPa
-0000d630: 636b 6574 2044 302c 2044 312c 2044 322c  cket D0, D1, D2,
-0000d640: 2044 333b 0a20 2020 2020 2020 2074 7261   D3;.        tra
-0000d650: 6974 732e 696e 6974 4163 6328 4430 293b  its.initAcc(D0);
-0000d660: 0a20 2020 2020 2020 2074 7261 6974 732e  .        traits.
-0000d670: 696e 6974 4163 6328 4431 293b 0a20 2020  initAcc(D1);.   
-0000d680: 2020 2020 2074 7261 6974 732e 696e 6974       traits.init
-0000d690: 4163 6328 4432 293b 0a20 2020 2020 2020  Acc(D2);.       
-0000d6a0: 2074 7261 6974 732e 696e 6974 4163 6328   traits.initAcc(
-0000d6b0: 4433 293b 0a0a 2020 2020 2020 2020 4c69  D3);..        Li
-0000d6c0: 6e65 6172 4d61 7070 6572 2072 3020 3d20  nearMapper r0 = 
-0000d6d0: 7265 732e 6765 744c 696e 6561 724d 6170  res.getLinearMap
-0000d6e0: 7065 7228 692c 206a 3220 2b20 3029 3b0a  per(i, j2 + 0);.
-0000d6f0: 2020 2020 2020 2020 4c69 6e65 6172 4d61          LinearMa
-0000d700: 7070 6572 2072 3120 3d20 7265 732e 6765  pper r1 = res.ge
-0000d710: 744c 696e 6561 724d 6170 7065 7228 692c  tLinearMapper(i,
-0000d720: 206a 3220 2b20 3129 3b0a 2020 2020 2020   j2 + 1);.      
-0000d730: 2020 4c69 6e65 6172 4d61 7070 6572 2072    LinearMapper r
-0000d740: 3220 3d20 7265 732e 6765 744c 696e 6561  2 = res.getLinea
-0000d750: 724d 6170 7065 7228 692c 206a 3220 2b20  rMapper(i, j2 + 
-0000d760: 3229 3b0a 2020 2020 2020 2020 4c69 6e65  2);.        Line
-0000d770: 6172 4d61 7070 6572 2072 3320 3d20 7265  arMapper r3 = re
-0000d780: 732e 6765 744c 696e 6561 724d 6170 7065  s.getLinearMappe
-0000d790: 7228 692c 206a 3220 2b20 3329 3b0a 0a20  r(i, j2 + 3);.. 
-0000d7a0: 2020 2020 2020 2072 302e 7072 6566 6574         r0.prefet
-0000d7b0: 6368 2870 7265 6665 7463 685f 7265 735f  ch(prefetch_res_
-0000d7c0: 6f66 6673 6574 293b 0a20 2020 2020 2020  offset);.       
-0000d7d0: 2072 312e 7072 6566 6574 6368 2870 7265   r1.prefetch(pre
-0000d7e0: 6665 7463 685f 7265 735f 6f66 6673 6574  fetch_res_offset
-0000d7f0: 293b 0a20 2020 2020 2020 2072 322e 7072  );.        r2.pr
-0000d800: 6566 6574 6368 2870 7265 6665 7463 685f  efetch(prefetch_
-0000d810: 7265 735f 6f66 6673 6574 293b 0a20 2020  res_offset);.   
-0000d820: 2020 2020 2072 332e 7072 6566 6574 6368       r3.prefetch
-0000d830: 2870 7265 6665 7463 685f 7265 735f 6f66  (prefetch_res_of
-0000d840: 6673 6574 293b 0a0a 2020 2020 2020 2020  fset);..        
-0000d850: 2f2f 2070 6572 666f 726d 7320 2269 6e6e  // performs "inn
-0000d860: 6572 2220 7072 6f64 7563 7473 0a20 2020  er" products.   
-0000d870: 2020 2020 2063 6f6e 7374 2052 6873 5363       const RhsSc
-0000d880: 616c 6172 2a20 626c 4220 3d20 2662 6c6f  alar* blB = &blo
-0000d890: 636b 425b 6a32 2a73 7472 6964 6542 2b6f  ckB[j2*strideB+o
-0000d8a0: 6666 7365 7442 2a6e 725d 3b0a 2020 2020  ffsetB*nr];.    
-0000d8b0: 2020 2020 7072 6566 6574 6368 2826 626c      prefetch(&bl
-0000d8c0: 425b 305d 293b 0a20 2020 2020 2020 204c  B[0]);.        L
-0000d8d0: 6873 5061 636b 6574 2041 302c 2041 313b  hsPacket A0, A1;
-0000d8e0: 0a0a 2020 2020 2020 2020 666f 7228 496e  ..        for(In
-0000d8f0: 6465 7820 6b3d 303b 206b 3c70 6565 6c65  dex k=0; k<peele
-0000d900: 645f 6b63 3b20 6b2b 3d70 6b29 0a20 2020  d_kc; k+=pk).   
-0000d910: 2020 2020 207b 0a20 2020 2020 2020 2020       {.         
-0000d920: 2045 4947 454e 5f41 534d 5f43 4f4d 4d45   EIGEN_ASM_COMME
-0000d930: 4e54 2822 6265 6769 6e20 6765 6270 206d  NT("begin gebp m
-0000d940: 6963 726f 206b 6572 6e65 6c20 312f 6861  icro kernel 1/ha
-0000d950: 6c66 2f71 7561 7274 6572 5834 2229 3b0a  lf/quarterX4");.
-0000d960: 2020 2020 2020 2020 2020 5268 7350 6163            RhsPac
-0000d970: 6b65 7478 3420 7268 735f 7061 6e65 6c3b  ketx4 rhs_panel;
-0000d980: 0a20 2020 2020 2020 2020 2052 6873 5061  .          RhsPa
-0000d990: 636b 6574 2054 303b 0a0a 2020 2020 2020  cket T0;..      
-0000d9a0: 2020 2020 696e 7465 726e 616c 3a3a 7072      internal::pr
-0000d9b0: 6566 6574 6368 2862 6c42 2b28 3438 2b30  efetch(blB+(48+0
-0000d9c0: 2929 3b0a 2020 2020 2020 2020 2020 7065  ));.          pe
-0000d9d0: 656c 6564 5f6b 635f 6f6e 6573 7465 7028  eled_kc_onestep(
-0000d9e0: 302c 2062 6c41 2c20 626c 422c 2074 7261  0, blA, blB, tra
-0000d9f0: 6974 732c 2026 4130 2c20 2672 6873 5f70  its, &A0, &rhs_p
-0000da00: 616e 656c 2c20 2654 302c 2026 4330 2c20  anel, &T0, &C0, 
-0000da10: 2643 312c 2026 4332 2c20 2643 3329 3b0a  &C1, &C2, &C3);.
-0000da20: 2020 2020 2020 2020 2020 7065 656c 6564            peeled
-0000da30: 5f6b 635f 6f6e 6573 7465 7028 312c 2062  _kc_onestep(1, b
-0000da40: 6c41 2c20 626c 422c 2074 7261 6974 732c  lA, blB, traits,
-0000da50: 2026 4131 2c20 2672 6873 5f70 616e 656c   &A1, &rhs_panel
-0000da60: 2c20 2654 302c 2026 4430 2c20 2644 312c  , &T0, &D0, &D1,
-0000da70: 2026 4432 2c20 2644 3329 3b0a 2020 2020   &D2, &D3);.    
-0000da80: 2020 2020 2020 7065 656c 6564 5f6b 635f        peeled_kc_
-0000da90: 6f6e 6573 7465 7028 322c 2062 6c41 2c20  onestep(2, blA, 
-0000daa0: 626c 422c 2074 7261 6974 732c 2026 4130  blB, traits, &A0
-0000dab0: 2c20 2672 6873 5f70 616e 656c 2c20 2654  , &rhs_panel, &T
-0000dac0: 302c 2026 4330 2c20 2643 312c 2026 4332  0, &C0, &C1, &C2
-0000dad0: 2c20 2643 3329 3b0a 2020 2020 2020 2020  , &C3);.        
-0000dae0: 2020 7065 656c 6564 5f6b 635f 6f6e 6573    peeled_kc_ones
-0000daf0: 7465 7028 332c 2062 6c41 2c20 626c 422c  tep(3, blA, blB,
-0000db00: 2074 7261 6974 732c 2026 4131 2c20 2672   traits, &A1, &r
-0000db10: 6873 5f70 616e 656c 2c20 2654 302c 2026  hs_panel, &T0, &
-0000db20: 4430 2c20 2644 312c 2026 4432 2c20 2644  D0, &D1, &D2, &D
-0000db30: 3329 3b0a 2020 2020 2020 2020 2020 696e  3);.          in
-0000db40: 7465 726e 616c 3a3a 7072 6566 6574 6368  ternal::prefetch
-0000db50: 2862 6c42 2b28 3438 2b31 3629 293b 0a20  (blB+(48+16));. 
-0000db60: 2020 2020 2020 2020 2070 6565 6c65 645f           peeled_
-0000db70: 6b63 5f6f 6e65 7374 6570 2834 2c20 626c  kc_onestep(4, bl
-0000db80: 412c 2062 6c42 2c20 7472 6169 7473 2c20  A, blB, traits, 
-0000db90: 2641 302c 2026 7268 735f 7061 6e65 6c2c  &A0, &rhs_panel,
-0000dba0: 2026 5430 2c20 2643 302c 2026 4331 2c20   &T0, &C0, &C1, 
-0000dbb0: 2643 322c 2026 4333 293b 0a20 2020 2020  &C2, &C3);.     
-0000dbc0: 2020 2020 2070 6565 6c65 645f 6b63 5f6f       peeled_kc_o
-0000dbd0: 6e65 7374 6570 2835 2c20 626c 412c 2062  nestep(5, blA, b
-0000dbe0: 6c42 2c20 7472 6169 7473 2c20 2641 312c  lB, traits, &A1,
-0000dbf0: 2026 7268 735f 7061 6e65 6c2c 2026 5430   &rhs_panel, &T0
-0000dc00: 2c20 2644 302c 2026 4431 2c20 2644 322c  , &D0, &D1, &D2,
-0000dc10: 2026 4433 293b 0a20 2020 2020 2020 2020   &D3);.         
-0000dc20: 2070 6565 6c65 645f 6b63 5f6f 6e65 7374   peeled_kc_onest
-0000dc30: 6570 2836 2c20 626c 412c 2062 6c42 2c20  ep(6, blA, blB, 
-0000dc40: 7472 6169 7473 2c20 2641 302c 2026 7268  traits, &A0, &rh
-0000dc50: 735f 7061 6e65 6c2c 2026 5430 2c20 2643  s_panel, &T0, &C
-0000dc60: 302c 2026 4331 2c20 2643 322c 2026 4333  0, &C1, &C2, &C3
-0000dc70: 293b 0a20 2020 2020 2020 2020 2070 6565  );.          pee
-0000dc80: 6c65 645f 6b63 5f6f 6e65 7374 6570 2837  led_kc_onestep(7
-0000dc90: 2c20 626c 412c 2062 6c42 2c20 7472 6169  , blA, blB, trai
-0000dca0: 7473 2c20 2641 312c 2026 7268 735f 7061  ts, &A1, &rhs_pa
-0000dcb0: 6e65 6c2c 2026 5430 2c20 2644 302c 2026  nel, &T0, &D0, &
-0000dcc0: 4431 2c20 2644 322c 2026 4433 293b 0a0a  D1, &D2, &D3);..
-0000dcd0: 2020 2020 2020 2020 2020 626c 4220 2b3d            blB +=
-0000dce0: 2070 6b2a 342a 5268 7350 726f 6772 6573   pk*4*RhsProgres
-0000dcf0: 733b 0a20 2020 2020 2020 2020 2062 6c41  s;.          blA
-0000dd00: 202b 3d20 706b 2a4c 6873 5072 6f67 7265   += pk*LhsProgre
-0000dd10: 7373 3b0a 0a20 2020 2020 2020 2020 2045  ss;..          E
-0000dd20: 4947 454e 5f41 534d 5f43 4f4d 4d45 4e54  IGEN_ASM_COMMENT
-0000dd30: 2822 656e 6420 6765 6270 206d 6963 726f  ("end gebp micro
-0000dd40: 206b 6572 6e65 6c20 312f 6861 6c66 2f71   kernel 1/half/q
-0000dd50: 7561 7274 6572 5834 2229 3b0a 2020 2020  uarterX4");.    
-0000dd60: 2020 2020 7d0a 2020 2020 2020 2020 4330      }.        C0
-0000dd70: 203d 2070 6164 6428 4330 2c44 3029 3b0a   = padd(C0,D0);.
-0000dd80: 2020 2020 2020 2020 4331 203d 2070 6164          C1 = pad
-0000dd90: 6428 4331 2c44 3129 3b0a 2020 2020 2020  d(C1,D1);.      
-0000dda0: 2020 4332 203d 2070 6164 6428 4332 2c44    C2 = padd(C2,D
-0000ddb0: 3229 3b0a 2020 2020 2020 2020 4333 203d  2);.        C3 =
-0000ddc0: 2070 6164 6428 4333 2c44 3329 3b0a 0a20   padd(C3,D3);.. 
-0000ddd0: 2020 2020 2020 202f 2f20 7072 6f63 6573         // proces
-0000dde0: 7320 7265 6d61 696e 696e 6720 7065 656c  s remaining peel
-0000ddf0: 6564 206c 6f6f 700a 2020 2020 2020 2020  ed loop.        
-0000de00: 666f 7228 496e 6465 7820 6b3d 7065 656c  for(Index k=peel
-0000de10: 6564 5f6b 633b 206b 3c64 6570 7468 3b20  ed_kc; k<depth; 
-0000de20: 6b2b 2b29 0a20 2020 2020 2020 207b 0a20  k++).        {. 
-0000de30: 2020 2020 2020 2020 2052 6873 5061 636b           RhsPack
-0000de40: 6574 7834 2072 6873 5f70 616e 656c 3b0a  etx4 rhs_panel;.
-0000de50: 2020 2020 2020 2020 2020 5268 7350 6163            RhsPac
-0000de60: 6b65 7420 5430 3b0a 2020 2020 2020 2020  ket T0;.        
-0000de70: 2020 7065 656c 6564 5f6b 635f 6f6e 6573    peeled_kc_ones
-0000de80: 7465 7028 302c 2062 6c41 2c20 626c 422c  tep(0, blA, blB,
-0000de90: 2074 7261 6974 732c 2026 4130 2c20 2672   traits, &A0, &r
-0000dea0: 6873 5f70 616e 656c 2c20 2654 302c 2026  hs_panel, &T0, &
-0000deb0: 4330 2c20 2643 312c 2026 4332 2c20 2643  C0, &C1, &C2, &C
-0000dec0: 3329 3b0a 2020 2020 2020 2020 2020 626c  3);.          bl
-0000ded0: 4220 2b3d 2034 2a52 6873 5072 6f67 7265  B += 4*RhsProgre
-0000dee0: 7373 3b0a 2020 2020 2020 2020 2020 626c  ss;.          bl
-0000def0: 4120 2b3d 204c 6873 5072 6f67 7265 7373  A += LhsProgress
-0000df00: 3b0a 2020 2020 2020 2020 7d0a 0a20 2020  ;.        }..   
-0000df10: 2020 2020 2052 6573 5061 636b 6574 2052       ResPacket R
-0000df20: 302c 2052 313b 0a20 2020 2020 2020 2052  0, R1;.        R
-0000df30: 6573 5061 636b 6574 2061 6c70 6861 7620  esPacket alphav 
-0000df40: 3d20 7073 6574 313c 5265 7350 6163 6b65  = pset1<ResPacke
-0000df50: 743e 2861 6c70 6861 293b 0a0a 2020 2020  t>(alpha);..    
-0000df60: 2020 2020 5230 203d 2072 302e 7465 6d70      R0 = r0.temp
-0000df70: 6c61 7465 206c 6f61 6450 6163 6b65 743c  late loadPacket<
-0000df80: 5265 7350 6163 6b65 743e 2830 293b 0a20  ResPacket>(0);. 
-0000df90: 2020 2020 2020 2052 3120 3d20 7231 2e74         R1 = r1.t
-0000dfa0: 656d 706c 6174 6520 6c6f 6164 5061 636b  emplate loadPack
-0000dfb0: 6574 3c52 6573 5061 636b 6574 3e28 3029  et<ResPacket>(0)
-0000dfc0: 3b0a 2020 2020 2020 2020 7472 6169 7473  ;.        traits
-0000dfd0: 2e61 6363 2843 302c 2061 6c70 6861 762c  .acc(C0, alphav,
-0000dfe0: 2052 3029 3b0a 2020 2020 2020 2020 7472   R0);.        tr
-0000dff0: 6169 7473 2e61 6363 2843 312c 2020 616c  aits.acc(C1,  al
-0000e000: 7068 6176 2c20 5231 293b 0a20 2020 2020  phav, R1);.     
-0000e010: 2020 2072 302e 7374 6f72 6550 6163 6b65     r0.storePacke
-0000e020: 7428 302c 2052 3029 3b0a 2020 2020 2020  t(0, R0);.      
-0000e030: 2020 7231 2e73 746f 7265 5061 636b 6574    r1.storePacket
-0000e040: 2830 2c20 5231 293b 0a0a 2020 2020 2020  (0, R1);..      
-0000e050: 2020 5230 203d 2072 322e 7465 6d70 6c61    R0 = r2.templa
-0000e060: 7465 206c 6f61 6450 6163 6b65 743c 5265  te loadPacket<Re
-0000e070: 7350 6163 6b65 743e 2830 293b 0a20 2020  sPacket>(0);.   
-0000e080: 2020 2020 2052 3120 3d20 7233 2e74 656d       R1 = r3.tem
-0000e090: 706c 6174 6520 6c6f 6164 5061 636b 6574  plate loadPacket
-0000e0a0: 3c52 6573 5061 636b 6574 3e28 3029 3b0a  <ResPacket>(0);.
-0000e0b0: 2020 2020 2020 2020 7472 6169 7473 2e61          traits.a
-0000e0c0: 6363 2843 322c 2020 616c 7068 6176 2c20  cc(C2,  alphav, 
-0000e0d0: 5230 293b 0a20 2020 2020 2020 2074 7261  R0);.        tra
-0000e0e0: 6974 732e 6163 6328 4333 2c20 2061 6c70  its.acc(C3,  alp
-0000e0f0: 6861 762c 2052 3129 3b0a 2020 2020 2020  hav, R1);.      
-0000e100: 2020 7232 2e73 746f 7265 5061 636b 6574    r2.storePacket
-0000e110: 2830 2c20 5230 293b 0a20 2020 2020 2020  (0, R0);.       
-0000e120: 2072 332e 7374 6f72 6550 6163 6b65 7428   r3.storePacket(
-0000e130: 302c 2052 3129 3b0a 2020 2020 2020 7d0a  0, R1);.      }.
-0000e140: 0a20 2020 2020 202f 2f20 4465 616c 2077  .      // Deal w
-0000e150: 6974 6820 7265 6d61 696e 696e 6720 636f  ith remaining co
-0000e160: 6c75 6d6e 7320 6f66 2074 6865 2072 6873  lumns of the rhs
-0000e170: 0a20 2020 2020 2066 6f72 2849 6e64 6578  .      for(Index
-0000e180: 206a 323d 7061 636b 6574 5f63 6f6c 7334   j2=packet_cols4
-0000e190: 3b20 6a32 3c63 6f6c 733b 206a 322b 2b29  ; j2<cols; j2++)
-0000e1a0: 0a20 2020 2020 207b 0a20 2020 2020 2020  .      {.       
-0000e1b0: 202f 2f20 4f6e 6520 636f 6c75 6d6e 2061   // One column a
-0000e1c0: 7420 6120 7469 6d65 0a20 2020 2020 2020  t a time.       
-0000e1d0: 2063 6f6e 7374 204c 6873 5363 616c 6172   const LhsScalar
-0000e1e0: 2a20 626c 4120 3d20 2662 6c6f 636b 415b  * blA = &blockA[
-0000e1f0: 692a 7374 7269 6465 412b 6f66 6673 6574  i*strideA+offset
-0000e200: 412a 284c 6873 5072 6f67 7265 7373 295d  A*(LhsProgress)]
-0000e210: 3b0a 2020 2020 2020 2020 7072 6566 6574  ;.        prefet
-0000e220: 6368 2826 626c 415b 305d 293b 0a0a 2020  ch(&blA[0]);..  
-0000e230: 2020 2020 2020 2f2f 2067 6574 7320 7265        // gets re
-0000e240: 7320 626c 6f63 6b20 6173 2072 6567 6973  s block as regis
-0000e250: 7465 720a 2020 2020 2020 2020 4163 6350  ter.        AccP
-0000e260: 6163 6b65 7420 4330 3b0a 2020 2020 2020  acket C0;.      
-0000e270: 2020 7472 6169 7473 2e69 6e69 7441 6363    traits.initAcc
-0000e280: 2843 3029 3b0a 0a20 2020 2020 2020 204c  (C0);..        L
-0000e290: 696e 6561 724d 6170 7065 7220 7230 203d  inearMapper r0 =
-0000e2a0: 2072 6573 2e67 6574 4c69 6e65 6172 4d61   res.getLinearMa
-0000e2b0: 7070 6572 2869 2c20 6a32 293b 0a0a 2020  pper(i, j2);..  
-0000e2c0: 2020 2020 2020 2f2f 2070 6572 666f 726d        // perform
-0000e2d0: 7320 2269 6e6e 6572 2220 7072 6f64 7563  s "inner" produc
-0000e2e0: 7473 0a20 2020 2020 2020 2063 6f6e 7374  ts.        const
-0000e2f0: 2052 6873 5363 616c 6172 2a20 626c 4220   RhsScalar* blB 
-0000e300: 3d20 2662 6c6f 636b 425b 6a32 2a73 7472  = &blockB[j2*str
-0000e310: 6964 6542 2b6f 6666 7365 7442 5d3b 0a20  ideB+offsetB];. 
-0000e320: 2020 2020 2020 204c 6873 5061 636b 6574         LhsPacket
-0000e330: 2041 303b 0a0a 2020 2020 2020 2020 666f   A0;..        fo
-0000e340: 7228 496e 6465 7820 6b3d 2030 3b20 6b3c  r(Index k= 0; k<
-0000e350: 7065 656c 6564 5f6b 633b 206b 2b3d 706b  peeled_kc; k+=pk
-0000e360: 290a 2020 2020 2020 2020 7b0a 2020 2020  ).        {.    
-0000e370: 2020 2020 2020 4549 4745 4e5f 4153 4d5f        EIGEN_ASM_
-0000e380: 434f 4d4d 454e 5428 2262 6567 696e 2067  COMMENT("begin g
-0000e390: 6562 7020 6d69 6372 6f20 6b65 726e 656c  ebp micro kernel
-0000e3a0: 2031 2f68 616c 662f 7175 6172 7465 7258   1/half/quarterX
-0000e3b0: 3122 293b 0a20 2020 2020 2020 2020 2052  1");.          R
-0000e3c0: 6873 5061 636b 6574 2042 5f30 3b0a 0a23  hsPacket B_0;..#
-0000e3d0: 6465 6669 6e65 2045 4947 454e 5f47 4542  define EIGEN_GEB
-0000e3e0: 4750 5f4f 4e45 5354 4550 284b 2920 2020  GP_ONESTEP(K)   
+00004120: 2020 2020 7479 7065 6e61 6d65 2070 6163      typename pac
+00004130: 6b65 745f 7472 6169 7473 3c53 6361 6c61  ket_traits<Scala
+00004140: 723e 3a3a 6861 6c66 2c20 5c0a 2020 2020  r>::half, \.    
+00004150: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004160: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004170: 2020 7479 7065 6e61 6d65 2075 6e70 6163    typename unpac
+00004180: 6b65 745f 7472 6169 7473 3c74 7970 656e  ket_traits<typen
+00004190: 616d 6520 7061 636b 6574 5f74 7261 6974  ame packet_trait
+000041a0: 733c 5363 616c 6172 3e3a 3a68 616c 663e  s<Scalar>::half>
+000041b0: 3a3a 6861 6c66 3e3a 3a74 7970 6520 5c0a  ::half>::type \.
+000041c0: 2020 7072 6566 6978 2023 2320 5363 616c    prefix ## Scal
+000041d0: 6172 5061 636b 6574 0a0a 2364 6566 696e  arPacket..#defin
+000041e0: 6520 5041 434b 4554 5f44 4543 4c5f 434f  e PACKET_DECL_CO
+000041f0: 4e44 5f53 4341 4c41 5228 7061 636b 6574  ND_SCALAR(packet
+00004200: 5f73 697a 6529 2020 2020 2020 2020 2020  _size)          
+00004210: 2020 2020 2020 2020 2020 2020 205c 0a20               \. 
+00004220: 2074 7970 6564 6566 2074 7970 656e 616d   typedef typenam
+00004230: 6520 7061 636b 6574 5f63 6f6e 6469 7469  e packet_conditi
+00004240: 6f6e 616c 3c70 6163 6b65 745f 7369 7a65  onal<packet_size
+00004250: 2c20 2020 2020 2020 2020 2020 2020 2020  ,               
+00004260: 2020 5c0a 2020 2020 2020 2020 2020 2020    \.            
+00004270: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004280: 2020 2020 2020 2020 2020 7479 7065 6e61            typena
+00004290: 6d65 2070 6163 6b65 745f 7472 6169 7473  me packet_traits
+000042a0: 3c53 6361 6c61 723e 3a3a 7479 7065 2c20  <Scalar>::type, 
+000042b0: 5c0a 2020 2020 2020 2020 2020 2020 2020  \.              
+000042c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000042d0: 2020 2020 2020 2020 7479 7065 6e61 6d65          typename
+000042e0: 2070 6163 6b65 745f 7472 6169 7473 3c53   packet_traits<S
+000042f0: 6361 6c61 723e 3a3a 6861 6c66 2c20 5c0a  calar>::half, \.
+00004300: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004310: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004320: 2020 2020 2020 7479 7065 6e61 6d65 2075        typename u
+00004330: 6e70 6163 6b65 745f 7472 6169 7473 3c74  npacket_traits<t
+00004340: 7970 656e 616d 6520 7061 636b 6574 5f74  ypename packet_t
+00004350: 7261 6974 733c 5363 616c 6172 3e3a 3a68  raits<Scalar>::h
+00004360: 616c 663e 3a3a 6861 6c66 3e3a 3a74 7970  alf>::half>::typ
+00004370: 6520 5c0a 2020 5363 616c 6172 5061 636b  e \.  ScalarPack
+00004380: 6574 0a0a 2f2a 2056 6563 746f 7269 7a61  et../* Vectoriza
+00004390: 7469 6f6e 206c 6f67 6963 0a20 2a20 2072  tion logic. *  r
+000043a0: 6561 6c2a 7265 616c 3a20 756e 7061 636b  eal*real: unpack
+000043b0: 2072 6873 2074 6f20 636f 6e73 7461 6e74   rhs to constant
+000043c0: 2070 6163 6b65 7473 2c20 2e2e 2e0a 202a   packets, .... *
+000043d0: 200a 202a 2020 6364 2a63 6420 3a20 756e   . *  cd*cd : un
+000043e0: 7061 636b 2072 6873 2074 6f20 2862 5f72  pack rhs to (b_r
+000043f0: 2c62 5f72 292c 2028 625f 692c 625f 6929  ,b_r), (b_i,b_i)
+00004400: 2c20 6d75 6c20 746f 2067 6574 2028 615f  , mul to get (a_
+00004410: 7220 625f 722c 615f 6920 625f 7229 2028  r b_r,a_i b_r) (
+00004420: 615f 7220 625f 692c 615f 6920 625f 6929  a_r b_i,a_i b_i)
+00004430: 2c0a 202a 2020 2020 2020 2020 2020 7374  ,. *          st
+00004440: 6f72 696e 6720 6561 6368 2072 6573 2070  oring each res p
+00004450: 6163 6b65 7420 696e 746f 2074 776f 2070  acket into two p
+00004460: 6163 6b65 7473 2028 3278 3229 2c0a 202a  ackets (2x2),. *
+00004470: 2020 2020 2020 2020 2020 6174 2074 6865            at the
+00004480: 2065 6e64 2063 6f6d 6269 6e65 2074 6865   end combine the
+00004490: 6d3a 2073 7761 7020 7468 6520 7365 636f  m: swap the seco
+000044a0: 6e64 2061 6e64 2061 6464 7375 6220 7468  nd and addsub th
+000044b0: 656d 200a 202a 2020 6366 2a63 6620 3a20  em . *  cf*cf : 
+000044c0: 7361 6d65 2062 7574 2077 6974 6820 3278  same but with 2x
+000044d0: 3420 626c 6f63 6b73 0a20 2a20 2063 706c  4 blocks. *  cpl
+000044e0: 782a 7265 616c 203a 2075 6e70 6163 6b20  x*real : unpack 
+000044f0: 7268 7320 746f 2063 6f6e 7374 616e 7420  rhs to constant 
+00004500: 7061 636b 6574 732c 202e 2e2e 0a20 2a20  packets, .... * 
+00004510: 2072 6561 6c2a 6370 6c78 203a 206c 6f61   real*cplx : loa
+00004520: 6420 6c68 7320 6173 2028 6130 2c61 302c  d lhs as (a0,a0,
+00004530: 6131 2c61 3129 2c20 616e 6420 6d75 6c20  a1,a1), and mul 
+00004540: 6173 2075 7375 616c 0a20 2a2f 0a74 656d  as usual. */.tem
+00004550: 706c 6174 653c 7479 7065 6e61 6d65 205f  plate<typename _
+00004560: 4c68 7353 6361 6c61 722c 2074 7970 656e  LhsScalar, typen
+00004570: 616d 6520 5f52 6873 5363 616c 6172 2c20  ame _RhsScalar, 
+00004580: 626f 6f6c 205f 436f 6e6a 4c68 732c 2062  bool _ConjLhs, b
+00004590: 6f6f 6c20 5f43 6f6e 6a52 6873 2c20 696e  ool _ConjRhs, in
+000045a0: 7420 4172 6368 2c20 696e 7420 5f50 6163  t Arch, int _Pac
+000045b0: 6b65 7453 697a 653e 0a63 6c61 7373 2067  ketSize>.class g
+000045c0: 6562 705f 7472 6169 7473 0a7b 0a70 7562  ebp_traits.{.pub
+000045d0: 6c69 633a 0a20 2074 7970 6564 6566 205f  lic:.  typedef _
+000045e0: 4c68 7353 6361 6c61 7220 4c68 7353 6361  LhsScalar LhsSca
+000045f0: 6c61 723b 0a20 2074 7970 6564 6566 205f  lar;.  typedef _
+00004600: 5268 7353 6361 6c61 7220 5268 7353 6361  RhsScalar RhsSca
+00004610: 6c61 723b 0a20 2074 7970 6564 6566 2074  lar;.  typedef t
+00004620: 7970 656e 616d 6520 5363 616c 6172 4269  ypename ScalarBi
+00004630: 6e61 7279 4f70 5472 6169 7473 3c4c 6873  naryOpTraits<Lhs
+00004640: 5363 616c 6172 2c20 5268 7353 6361 6c61  Scalar, RhsScala
+00004650: 723e 3a3a 5265 7475 726e 5479 7065 2052  r>::ReturnType R
+00004660: 6573 5363 616c 6172 3b0a 0a20 2050 4143  esScalar;..  PAC
+00004670: 4b45 545f 4445 434c 5f43 4f4e 445f 5052  KET_DECL_COND_PR
+00004680: 4546 4958 285f 2c20 4c68 732c 205f 5061  EFIX(_, Lhs, _Pa
+00004690: 636b 6574 5369 7a65 293b 0a20 2050 4143  cketSize);.  PAC
+000046a0: 4b45 545f 4445 434c 5f43 4f4e 445f 5052  KET_DECL_COND_PR
+000046b0: 4546 4958 285f 2c20 5268 732c 205f 5061  EFIX(_, Rhs, _Pa
+000046c0: 636b 6574 5369 7a65 293b 0a20 2050 4143  cketSize);.  PAC
+000046d0: 4b45 545f 4445 434c 5f43 4f4e 445f 5052  KET_DECL_COND_PR
+000046e0: 4546 4958 285f 2c20 5265 732c 205f 5061  EFIX(_, Res, _Pa
+000046f0: 636b 6574 5369 7a65 293b 0a0a 2020 656e  cketSize);..  en
+00004700: 756d 207b 0a20 2020 2043 6f6e 6a4c 6873  um {.    ConjLhs
+00004710: 203d 205f 436f 6e6a 4c68 732c 0a20 2020   = _ConjLhs,.   
+00004720: 2043 6f6e 6a52 6873 203d 205f 436f 6e6a   ConjRhs = _Conj
+00004730: 5268 732c 0a20 2020 2056 6563 746f 7269  Rhs,.    Vectori
+00004740: 7a61 626c 6520 3d20 756e 7061 636b 6574  zable = unpacket
+00004750: 5f74 7261 6974 733c 5f4c 6873 5061 636b  _traits<_LhsPack
+00004760: 6574 3e3a 3a76 6563 746f 7269 7a61 626c  et>::vectorizabl
+00004770: 6520 2626 2075 6e70 6163 6b65 745f 7472  e && unpacket_tr
+00004780: 6169 7473 3c5f 5268 7350 6163 6b65 743e  aits<_RhsPacket>
+00004790: 3a3a 7665 6374 6f72 697a 6162 6c65 2c0a  ::vectorizable,.
+000047a0: 2020 2020 4c68 7350 6163 6b65 7453 697a      LhsPacketSiz
+000047b0: 6520 3d20 5665 6374 6f72 697a 6162 6c65  e = Vectorizable
+000047c0: 203f 2075 6e70 6163 6b65 745f 7472 6169   ? unpacket_trai
+000047d0: 7473 3c5f 4c68 7350 6163 6b65 743e 3a3a  ts<_LhsPacket>::
+000047e0: 7369 7a65 203a 2031 2c0a 2020 2020 5268  size : 1,.    Rh
+000047f0: 7350 6163 6b65 7453 697a 6520 3d20 5665  sPacketSize = Ve
+00004800: 6374 6f72 697a 6162 6c65 203f 2075 6e70  ctorizable ? unp
+00004810: 6163 6b65 745f 7472 6169 7473 3c5f 5268  acket_traits<_Rh
+00004820: 7350 6163 6b65 743e 3a3a 7369 7a65 203a  sPacket>::size :
+00004830: 2031 2c0a 2020 2020 5265 7350 6163 6b65   1,.    ResPacke
+00004840: 7453 697a 6520 3d20 5665 6374 6f72 697a  tSize = Vectoriz
+00004850: 6162 6c65 203f 2075 6e70 6163 6b65 745f  able ? unpacket_
+00004860: 7472 6169 7473 3c5f 5265 7350 6163 6b65  traits<_ResPacke
+00004870: 743e 3a3a 7369 7a65 203a 2031 2c0a 2020  t>::size : 1,.  
+00004880: 2020 0a20 2020 204e 756d 6265 724f 6652    .    NumberOfR
+00004890: 6567 6973 7465 7273 203d 2045 4947 454e  egisters = EIGEN
+000048a0: 5f41 5243 485f 4445 4641 554c 545f 4e55  _ARCH_DEFAULT_NU
+000048b0: 4d42 4552 5f4f 465f 5245 4749 5354 4552  MBER_OF_REGISTER
+000048c0: 532c 0a0a 2020 2020 2f2f 2072 6567 6973  S,..    // regis
+000048d0: 7465 7220 626c 6f63 6b20 7369 7a65 2061  ter block size a
+000048e0: 6c6f 6e67 2074 6865 204e 2064 6972 6563  long the N direc
+000048f0: 7469 6f6e 206d 7573 7420 6265 2031 206f  tion must be 1 o
+00004900: 7220 340a 2020 2020 6e72 203d 2034 2c0a  r 4.    nr = 4,.
+00004910: 0a20 2020 202f 2f20 7265 6769 7374 6572  .    // register
+00004920: 2062 6c6f 636b 2073 697a 6520 616c 6f6e   block size alon
+00004930: 6720 7468 6520 4d20 6469 7265 6374 696f  g the M directio
+00004940: 6e20 2863 7572 7265 6e74 6c79 2c20 7468  n (currently, th
+00004950: 6973 206f 6e65 2063 616e 6e6f 7420 6265  is one cannot be
+00004960: 206d 6f64 6966 6965 6429 0a20 2020 2064   modified).    d
+00004970: 6566 6175 6c74 5f6d 7220 3d20 2845 4947  efault_mr = (EIG
+00004980: 454e 5f50 4c41 494e 5f45 4e55 4d5f 4d49  EN_PLAIN_ENUM_MI
+00004990: 4e28 3136 2c4e 756d 6265 724f 6652 6567  N(16,NumberOfReg
+000049a0: 6973 7465 7273 292f 322f 6e72 292a 4c68  isters)/2/nr)*Lh
+000049b0: 7350 6163 6b65 7453 697a 652c 0a23 6966  sPacketSize,.#if
+000049c0: 2064 6566 696e 6564 2845 4947 454e 5f48   defined(EIGEN_H
+000049d0: 4153 5f53 494e 474c 455f 494e 5354 5255  AS_SINGLE_INSTRU
+000049e0: 4354 494f 4e5f 4d41 4444 2920 2626 2021  CTION_MADD) && !
+000049f0: 6465 6669 6e65 6428 4549 4745 4e5f 5645  defined(EIGEN_VE
+00004a00: 4354 4f52 495a 455f 414c 5449 5645 4329  CTORIZE_ALTIVEC)
+00004a10: 2026 2620 2164 6566 696e 6564 2845 4947   && !defined(EIG
+00004a20: 454e 5f56 4543 544f 5249 5a45 5f56 5358  EN_VECTORIZE_VSX
+00004a30: 2920 5c0a 2020 2020 2626 2028 2821 4549  ) \.    && ((!EI
+00004a40: 4745 4e5f 434f 4d50 5f4d 5356 4329 207c  GEN_COMP_MSVC) |
+00004a50: 7c20 2845 4947 454e 5f43 4f4d 505f 4d53  | (EIGEN_COMP_MS
+00004a60: 5643 3e3d 3139 3134 2929 0a20 2020 202f  VC>=1914)).    /
+00004a70: 2f20 7765 2061 7373 756d 6520 3136 2072  / we assume 16 r
+00004a80: 6567 6973 7465 7273 206f 7220 6d6f 7265  egisters or more
+00004a90: 0a20 2020 202f 2f20 5365 6520 6275 6720  .    // See bug 
+00004aa0: 3939 322c 2069 6620 7468 6520 7363 616c  992, if the scal
+00004ab0: 6172 2074 7970 6520 6973 206e 6f74 2076  ar type is not v
+00004ac0: 6563 746f 7269 7a61 626c 6520 6275 7420  ectorizable but 
+00004ad0: 7468 6174 2045 4947 454e 5f48 4153 5f53  that EIGEN_HAS_S
+00004ae0: 494e 474c 455f 494e 5354 5255 4354 494f  INGLE_INSTRUCTIO
+00004af0: 4e5f 4d41 4444 2069 7320 6465 6669 6e65  N_MADD is define
+00004b00: 642c 0a20 2020 202f 2f20 7468 656e 2075  d,.    // then u
+00004b10: 7369 6e67 2033 2a4c 6873 5061 636b 6574  sing 3*LhsPacket
+00004b20: 5369 7a65 2074 7269 6767 6572 7320 6e6f  Size triggers no
+00004b30: 6e2d 696d 706c 656d 656e 7465 6420 7061  n-implemented pa
+00004b40: 7468 7320 696e 2073 7972 6b2e 0a20 2020  ths in syrk..   
+00004b50: 202f 2f20 4275 6720 3135 3135 3a20 4d53   // Bug 1515: MS
+00004b60: 5643 2070 7269 6f72 2074 6f20 7631 392e  VC prior to v19.
+00004b70: 3134 2079 6965 6c64 7320 746f 2072 6567  14 yields to reg
+00004b80: 6973 7465 7220 7370 696c 6c69 6e67 2e0a  ister spilling..
+00004b90: 2020 2020 6d72 203d 2056 6563 746f 7269      mr = Vectori
+00004ba0: 7a61 626c 6520 3f20 332a 4c68 7350 6163  zable ? 3*LhsPac
+00004bb0: 6b65 7453 697a 6520 3a20 6465 6661 756c  ketSize : defaul
+00004bc0: 745f 6d72 2c0a 2365 6c73 650a 2020 2020  t_mr,.#else.    
+00004bd0: 6d72 203d 2064 6566 6175 6c74 5f6d 722c  mr = default_mr,
+00004be0: 0a23 656e 6469 660a 2020 2020 0a20 2020  .#endif.    .   
+00004bf0: 204c 6873 5072 6f67 7265 7373 203d 204c   LhsProgress = L
+00004c00: 6873 5061 636b 6574 5369 7a65 2c0a 2020  hsPacketSize,.  
+00004c10: 2020 5268 7350 726f 6772 6573 7320 3d20    RhsProgress = 
+00004c20: 310a 2020 7d3b 0a0a 0a20 2074 7970 6564  1.  };...  typed
+00004c30: 6566 2074 7970 656e 616d 6520 636f 6e64  ef typename cond
+00004c40: 6974 696f 6e61 6c3c 5665 6374 6f72 697a  itional<Vectoriz
+00004c50: 6162 6c65 2c5f 4c68 7350 6163 6b65 742c  able,_LhsPacket,
+00004c60: 4c68 7353 6361 6c61 723e 3a3a 7479 7065  LhsScalar>::type
+00004c70: 204c 6873 5061 636b 6574 3b0a 2020 7479   LhsPacket;.  ty
+00004c80: 7065 6465 6620 7479 7065 6e61 6d65 2063  pedef typename c
+00004c90: 6f6e 6469 7469 6f6e 616c 3c56 6563 746f  onditional<Vecto
+00004ca0: 7269 7a61 626c 652c 5f52 6873 5061 636b  rizable,_RhsPack
+00004cb0: 6574 2c52 6873 5363 616c 6172 3e3a 3a74  et,RhsScalar>::t
+00004cc0: 7970 6520 5268 7350 6163 6b65 743b 0a20  ype RhsPacket;. 
+00004cd0: 2074 7970 6564 6566 2074 7970 656e 616d   typedef typenam
+00004ce0: 6520 636f 6e64 6974 696f 6e61 6c3c 5665  e conditional<Ve
+00004cf0: 6374 6f72 697a 6162 6c65 2c5f 5265 7350  ctorizable,_ResP
+00004d00: 6163 6b65 742c 5265 7353 6361 6c61 723e  acket,ResScalar>
+00004d10: 3a3a 7479 7065 2052 6573 5061 636b 6574  ::type ResPacket
+00004d20: 3b0a 2020 7479 7065 6465 6620 4c68 7350  ;.  typedef LhsP
+00004d30: 6163 6b65 7420 4c68 7350 6163 6b65 7434  acket LhsPacket4
+00004d40: 5061 636b 696e 673b 0a0a 2020 7479 7065  Packing;..  type
+00004d50: 6465 6620 5175 6164 5061 636b 6574 3c52  def QuadPacket<R
+00004d60: 6873 5061 636b 6574 3e20 5268 7350 6163  hsPacket> RhsPac
+00004d70: 6b65 7478 343b 0a20 2074 7970 6564 6566  ketx4;.  typedef
+00004d80: 2052 6573 5061 636b 6574 2041 6363 5061   ResPacket AccPa
+00004d90: 636b 6574 3b0a 2020 0a20 2045 4947 454e  cket;.  .  EIGEN
+00004da0: 5f53 5452 4f4e 475f 494e 4c49 4e45 2076  _STRONG_INLINE v
+00004db0: 6f69 6420 696e 6974 4163 6328 4163 6350  oid initAcc(AccP
+00004dc0: 6163 6b65 7426 2070 290a 2020 7b0a 2020  acket& p).  {.  
+00004dd0: 2020 7020 3d20 7073 6574 313c 5265 7350    p = pset1<ResP
+00004de0: 6163 6b65 743e 2852 6573 5363 616c 6172  acket>(ResScalar
+00004df0: 2830 2929 3b0a 2020 7d0a 0a20 2074 656d  (0));.  }..  tem
+00004e00: 706c 6174 653c 7479 7065 6e61 6d65 2052  plate<typename R
+00004e10: 6873 5061 636b 6574 5479 7065 3e0a 2020  hsPacketType>.  
+00004e20: 4549 4745 4e5f 5354 524f 4e47 5f49 4e4c  EIGEN_STRONG_INL
+00004e30: 494e 4520 766f 6964 206c 6f61 6452 6873  INE void loadRhs
+00004e40: 2863 6f6e 7374 2052 6873 5363 616c 6172  (const RhsScalar
+00004e50: 2a20 622c 2052 6873 5061 636b 6574 5479  * b, RhsPacketTy
+00004e60: 7065 2620 6465 7374 2920 636f 6e73 740a  pe& dest) const.
+00004e70: 2020 7b0a 2020 2020 6465 7374 203d 2070    {.    dest = p
+00004e80: 7365 7431 3c52 6873 5061 636b 6574 5479  set1<RhsPacketTy
+00004e90: 7065 3e28 2a62 293b 0a20 207d 0a0a 2020  pe>(*b);.  }..  
+00004ea0: 4549 4745 4e5f 5354 524f 4e47 5f49 4e4c  EIGEN_STRONG_INL
+00004eb0: 494e 4520 766f 6964 206c 6f61 6452 6873  INE void loadRhs
+00004ec0: 2863 6f6e 7374 2052 6873 5363 616c 6172  (const RhsScalar
+00004ed0: 2a20 622c 2052 6873 5061 636b 6574 7834  * b, RhsPacketx4
+00004ee0: 2620 6465 7374 2920 636f 6e73 740a 2020  & dest) const.  
+00004ef0: 7b0a 2020 2020 7062 726f 6164 6361 7374  {.    pbroadcast
+00004f00: 3428 622c 2064 6573 742e 425f 302c 2064  4(b, dest.B_0, d
+00004f10: 6573 742e 4231 2c20 6465 7374 2e42 322c  est.B1, dest.B2,
+00004f20: 2064 6573 742e 4233 293b 0a20 207d 0a0a   dest.B3);.  }..
+00004f30: 2020 7465 6d70 6c61 7465 3c74 7970 656e    template<typen
+00004f40: 616d 6520 5268 7350 6163 6b65 7454 7970  ame RhsPacketTyp
+00004f50: 653e 0a20 2045 4947 454e 5f53 5452 4f4e  e>.  EIGEN_STRON
+00004f60: 475f 494e 4c49 4e45 2076 6f69 6420 7570  G_INLINE void up
+00004f70: 6461 7465 5268 7328 636f 6e73 7420 5268  dateRhs(const Rh
+00004f80: 7353 6361 6c61 722a 2062 2c20 5268 7350  sScalar* b, RhsP
+00004f90: 6163 6b65 7454 7970 6526 2064 6573 7429  acketType& dest)
+00004fa0: 2063 6f6e 7374 0a20 207b 0a20 2020 206c   const.  {.    l
+00004fb0: 6f61 6452 6873 2862 2c20 6465 7374 293b  oadRhs(b, dest);
+00004fc0: 0a20 207d 0a0a 2020 4549 4745 4e5f 5354  .  }..  EIGEN_ST
+00004fd0: 524f 4e47 5f49 4e4c 494e 4520 766f 6964  RONG_INLINE void
+00004fe0: 2075 7064 6174 6552 6873 2863 6f6e 7374   updateRhs(const
+00004ff0: 2052 6873 5363 616c 6172 2a2c 2052 6873   RhsScalar*, Rhs
+00005000: 5061 636b 6574 7834 2629 2063 6f6e 7374  Packetx4&) const
+00005010: 0a20 207b 0a20 207d 0a0a 2020 4549 4745  .  {.  }..  EIGE
+00005020: 4e5f 5354 524f 4e47 5f49 4e4c 494e 4520  N_STRONG_INLINE 
+00005030: 766f 6964 206c 6f61 6452 6873 5175 6164  void loadRhsQuad
+00005040: 2863 6f6e 7374 2052 6873 5363 616c 6172  (const RhsScalar
+00005050: 2a20 622c 2052 6873 5061 636b 6574 2620  * b, RhsPacket& 
+00005060: 6465 7374 2920 636f 6e73 740a 2020 7b0a  dest) const.  {.
+00005070: 2020 2020 6465 7374 203d 2070 6c6f 6164      dest = pload
+00005080: 7175 6164 3c52 6873 5061 636b 6574 3e28  quad<RhsPacket>(
+00005090: 6229 3b0a 2020 7d0a 0a20 2074 656d 706c  b);.  }..  templ
+000050a0: 6174 653c 7479 7065 6e61 6d65 204c 6873  ate<typename Lhs
+000050b0: 5061 636b 6574 5479 7065 3e0a 2020 4549  PacketType>.  EI
+000050c0: 4745 4e5f 5354 524f 4e47 5f49 4e4c 494e  GEN_STRONG_INLIN
+000050d0: 4520 766f 6964 206c 6f61 644c 6873 2863  E void loadLhs(c
+000050e0: 6f6e 7374 204c 6873 5363 616c 6172 2a20  onst LhsScalar* 
+000050f0: 612c 204c 6873 5061 636b 6574 5479 7065  a, LhsPacketType
+00005100: 2620 6465 7374 2920 636f 6e73 740a 2020  & dest) const.  
+00005110: 7b0a 2020 2020 6465 7374 203d 2070 6c6f  {.    dest = plo
+00005120: 6164 3c4c 6873 5061 636b 6574 5479 7065  ad<LhsPacketType
+00005130: 3e28 6129 3b0a 2020 7d0a 0a20 2074 656d  >(a);.  }..  tem
+00005140: 706c 6174 653c 7479 7065 6e61 6d65 204c  plate<typename L
+00005150: 6873 5061 636b 6574 5479 7065 3e0a 2020  hsPacketType>.  
+00005160: 4549 4745 4e5f 5354 524f 4e47 5f49 4e4c  EIGEN_STRONG_INL
+00005170: 494e 4520 766f 6964 206c 6f61 644c 6873  INE void loadLhs
+00005180: 556e 616c 6967 6e65 6428 636f 6e73 7420  Unaligned(const 
+00005190: 4c68 7353 6361 6c61 722a 2061 2c20 4c68  LhsScalar* a, Lh
+000051a0: 7350 6163 6b65 7454 7970 6526 2064 6573  sPacketType& des
+000051b0: 7429 2063 6f6e 7374 0a20 207b 0a20 2020  t) const.  {.   
+000051c0: 2064 6573 7420 3d20 706c 6f61 6475 3c4c   dest = ploadu<L
+000051d0: 6873 5061 636b 6574 5479 7065 3e28 6129  hsPacketType>(a)
+000051e0: 3b0a 2020 7d0a 0a20 2074 656d 706c 6174  ;.  }..  templat
+000051f0: 653c 7479 7065 6e61 6d65 204c 6873 5061  e<typename LhsPa
+00005200: 636b 6574 5479 7065 2c20 7479 7065 6e61  cketType, typena
+00005210: 6d65 2052 6873 5061 636b 6574 5479 7065  me RhsPacketType
+00005220: 2c20 7479 7065 6e61 6d65 2041 6363 5061  , typename AccPa
+00005230: 636b 6574 5479 7065 2c20 7479 7065 6e61  cketType, typena
+00005240: 6d65 204c 616e 6549 6454 7970 653e 0a20  me LaneIdType>. 
+00005250: 2045 4947 454e 5f53 5452 4f4e 475f 494e   EIGEN_STRONG_IN
+00005260: 4c49 4e45 2076 6f69 6420 6d61 6464 2863  LINE void madd(c
+00005270: 6f6e 7374 204c 6873 5061 636b 6574 5479  onst LhsPacketTy
+00005280: 7065 2620 612c 2063 6f6e 7374 2052 6873  pe& a, const Rhs
+00005290: 5061 636b 6574 5479 7065 2620 622c 2041  PacketType& b, A
+000052a0: 6363 5061 636b 6574 5479 7065 2620 632c  ccPacketType& c,
+000052b0: 2052 6873 5061 636b 6574 5479 7065 2620   RhsPacketType& 
+000052c0: 746d 702c 2063 6f6e 7374 204c 616e 6549  tmp, const LaneI
+000052d0: 6454 7970 6526 2920 636f 6e73 740a 2020  dType&) const.  
+000052e0: 7b0a 2020 2020 636f 6e6a 5f68 656c 7065  {.    conj_helpe
+000052f0: 723c 4c68 7350 6163 6b65 7454 7970 652c  r<LhsPacketType,
+00005300: 5268 7350 6163 6b65 7454 7970 652c 436f  RhsPacketType,Co
+00005310: 6e6a 4c68 732c 436f 6e6a 5268 733e 2063  njLhs,ConjRhs> c
+00005320: 6a3b 0a20 2020 202f 2f20 4974 2077 6f75  j;.    // It wou
+00005330: 6c64 2062 6520 6120 6c6f 7420 636c 6561  ld be a lot clea
+00005340: 6e65 7220 746f 2063 616c 6c20 706d 6164  ner to call pmad
+00005350: 6420 616c 6c20 7468 6520 7469 6d65 2e20  d all the time. 
+00005360: 556e 666f 7274 756e 6174 656c 7920 6966  Unfortunately if
+00005370: 2077 650a 2020 2020 2f2f 206c 6574 2067   we.    // let g
+00005380: 6363 2061 6c6c 6f63 6174 6520 7468 6520  cc allocate the 
+00005390: 7265 6769 7374 6572 2069 6e20 7768 6963  register in whic
+000053a0: 6820 746f 2073 746f 7265 2074 6865 2072  h to store the r
+000053b0: 6573 756c 7420 6f66 2074 6865 2070 6d75  esult of the pmu
+000053c0: 6c0a 2020 2020 2f2f 2028 696e 2074 6865  l.    // (in the
+000053d0: 2063 6173 6520 7768 6572 6520 7468 6572   case where ther
+000053e0: 6520 6973 206e 6f20 464d 4129 2067 6363  e is no FMA) gcc
+000053f0: 2066 6169 6c73 2074 6f20 6669 6775 7265   fails to figure
+00005400: 206f 7574 2068 6f77 2074 6f20 6176 6f69   out how to avoi
+00005410: 640a 2020 2020 2f2f 2073 7069 6c6c 696e  d.    // spillin
+00005420: 6720 7265 6769 7374 6572 2e0a 2369 6664  g register..#ifd
+00005430: 6566 2045 4947 454e 5f48 4153 5f53 494e  ef EIGEN_HAS_SIN
+00005440: 474c 455f 494e 5354 5255 4354 494f 4e5f  GLE_INSTRUCTION_
+00005450: 4d41 4444 0a20 2020 2045 4947 454e 5f55  MADD.    EIGEN_U
+00005460: 4e55 5345 445f 5641 5249 4142 4c45 2874  NUSED_VARIABLE(t
+00005470: 6d70 293b 0a20 2020 2063 203d 2063 6a2e  mp);.    c = cj.
+00005480: 706d 6164 6428 612c 622c 6329 3b0a 2365  pmadd(a,b,c);.#e
+00005490: 6c73 650a 2020 2020 746d 7020 3d20 623b  lse.    tmp = b;
+000054a0: 2074 6d70 203d 2063 6a2e 706d 756c 2861   tmp = cj.pmul(a
+000054b0: 2c74 6d70 293b 2063 203d 2070 6164 6428  ,tmp); c = padd(
+000054c0: 632c 746d 7029 3b0a 2365 6e64 6966 0a20  c,tmp);.#endif. 
+000054d0: 207d 0a0a 2020 7465 6d70 6c61 7465 3c74   }..  template<t
+000054e0: 7970 656e 616d 6520 4c68 7350 6163 6b65  ypename LhsPacke
+000054f0: 7454 7970 652c 2074 7970 656e 616d 6520  tType, typename 
+00005500: 4163 6350 6163 6b65 7454 7970 652c 2074  AccPacketType, t
+00005510: 7970 656e 616d 6520 4c61 6e65 4964 5479  ypename LaneIdTy
+00005520: 7065 3e0a 2020 4549 4745 4e5f 5354 524f  pe>.  EIGEN_STRO
+00005530: 4e47 5f49 4e4c 494e 4520 766f 6964 206d  NG_INLINE void m
+00005540: 6164 6428 636f 6e73 7420 4c68 7350 6163  add(const LhsPac
+00005550: 6b65 7454 7970 6526 2061 2c20 636f 6e73  ketType& a, cons
+00005560: 7420 5268 7350 6163 6b65 7478 3426 2062  t RhsPacketx4& b
+00005570: 2c20 4163 6350 6163 6b65 7454 7970 6526  , AccPacketType&
+00005580: 2063 2c20 5268 7350 6163 6b65 7426 2074   c, RhsPacket& t
+00005590: 6d70 2c20 636f 6e73 7420 4c61 6e65 4964  mp, const LaneId
+000055a0: 5479 7065 2620 6c61 6e65 2920 636f 6e73  Type& lane) cons
+000055b0: 740a 2020 7b0a 2020 2020 6d61 6464 2861  t.  {.    madd(a
+000055c0: 2c20 622e 6765 7428 6c61 6e65 292c 2063  , b.get(lane), c
+000055d0: 2c20 746d 702c 206c 616e 6529 3b0a 2020  , tmp, lane);.  
+000055e0: 7d0a 0a20 2045 4947 454e 5f53 5452 4f4e  }..  EIGEN_STRON
+000055f0: 475f 494e 4c49 4e45 2076 6f69 6420 6163  G_INLINE void ac
+00005600: 6328 636f 6e73 7420 4163 6350 6163 6b65  c(const AccPacke
+00005610: 7426 2063 2c20 636f 6e73 7420 5265 7350  t& c, const ResP
+00005620: 6163 6b65 7426 2061 6c70 6861 2c20 5265  acket& alpha, Re
+00005630: 7350 6163 6b65 7426 2072 2920 636f 6e73  sPacket& r) cons
+00005640: 740a 2020 7b0a 2020 2020 7220 3d20 706d  t.  {.    r = pm
+00005650: 6164 6428 632c 616c 7068 612c 7229 3b0a  add(c,alpha,r);.
+00005660: 2020 7d0a 2020 0a20 2074 656d 706c 6174    }.  .  templat
+00005670: 653c 7479 7065 6e61 6d65 2052 6573 5061  e<typename ResPa
+00005680: 636b 6574 4861 6c66 3e0a 2020 4549 4745  cketHalf>.  EIGE
+00005690: 4e5f 5354 524f 4e47 5f49 4e4c 494e 4520  N_STRONG_INLINE 
+000056a0: 766f 6964 2061 6363 2863 6f6e 7374 2052  void acc(const R
+000056b0: 6573 5061 636b 6574 4861 6c66 2620 632c  esPacketHalf& c,
+000056c0: 2063 6f6e 7374 2052 6573 5061 636b 6574   const ResPacket
+000056d0: 4861 6c66 2620 616c 7068 612c 2052 6573  Half& alpha, Res
+000056e0: 5061 636b 6574 4861 6c66 2620 7229 2063  PacketHalf& r) c
+000056f0: 6f6e 7374 0a20 207b 0a20 2020 2072 203d  onst.  {.    r =
+00005700: 2070 6d61 6464 2863 2c61 6c70 6861 2c72   pmadd(c,alpha,r
+00005710: 293b 0a20 207d 0a0a 7d3b 0a0a 7465 6d70  );.  }..};..temp
+00005720: 6c61 7465 3c74 7970 656e 616d 6520 5265  late<typename Re
+00005730: 616c 5363 616c 6172 2c20 626f 6f6c 205f  alScalar, bool _
+00005740: 436f 6e6a 4c68 732c 2069 6e74 2041 7263  ConjLhs, int Arc
+00005750: 682c 2069 6e74 205f 5061 636b 6574 5369  h, int _PacketSi
+00005760: 7a65 3e0a 636c 6173 7320 6765 6270 5f74  ze>.class gebp_t
+00005770: 7261 6974 733c 7374 643a 3a63 6f6d 706c  raits<std::compl
+00005780: 6578 3c52 6561 6c53 6361 6c61 723e 2c20  ex<RealScalar>, 
+00005790: 5265 616c 5363 616c 6172 2c20 5f43 6f6e  RealScalar, _Con
+000057a0: 6a4c 6873 2c20 6661 6c73 652c 2041 7263  jLhs, false, Arc
+000057b0: 682c 205f 5061 636b 6574 5369 7a65 3e0a  h, _PacketSize>.
+000057c0: 7b0a 7075 626c 6963 3a0a 2020 7479 7065  {.public:.  type
+000057d0: 6465 6620 7374 643a 3a63 6f6d 706c 6578  def std::complex
+000057e0: 3c52 6561 6c53 6361 6c61 723e 204c 6873  <RealScalar> Lhs
+000057f0: 5363 616c 6172 3b0a 2020 7479 7065 6465  Scalar;.  typede
+00005800: 6620 5265 616c 5363 616c 6172 2052 6873  f RealScalar Rhs
+00005810: 5363 616c 6172 3b0a 2020 7479 7065 6465  Scalar;.  typede
+00005820: 6620 7479 7065 6e61 6d65 2053 6361 6c61  f typename Scala
+00005830: 7242 696e 6172 794f 7054 7261 6974 733c  rBinaryOpTraits<
+00005840: 4c68 7353 6361 6c61 722c 2052 6873 5363  LhsScalar, RhsSc
+00005850: 616c 6172 3e3a 3a52 6574 7572 6e54 7970  alar>::ReturnTyp
+00005860: 6520 5265 7353 6361 6c61 723b 0a0a 2020  e ResScalar;..  
+00005870: 5041 434b 4554 5f44 4543 4c5f 434f 4e44  PACKET_DECL_COND
+00005880: 5f50 5245 4649 5828 5f2c 204c 6873 2c20  _PREFIX(_, Lhs, 
+00005890: 5f50 6163 6b65 7453 697a 6529 3b0a 2020  _PacketSize);.  
+000058a0: 5041 434b 4554 5f44 4543 4c5f 434f 4e44  PACKET_DECL_COND
+000058b0: 5f50 5245 4649 5828 5f2c 2052 6873 2c20  _PREFIX(_, Rhs, 
+000058c0: 5f50 6163 6b65 7453 697a 6529 3b0a 2020  _PacketSize);.  
+000058d0: 5041 434b 4554 5f44 4543 4c5f 434f 4e44  PACKET_DECL_COND
+000058e0: 5f50 5245 4649 5828 5f2c 2052 6573 2c20  _PREFIX(_, Res, 
+000058f0: 5f50 6163 6b65 7453 697a 6529 3b0a 0a20  _PacketSize);.. 
+00005900: 2065 6e75 6d20 7b0a 2020 2020 436f 6e6a   enum {.    Conj
+00005910: 4c68 7320 3d20 5f43 6f6e 6a4c 6873 2c0a  Lhs = _ConjLhs,.
+00005920: 2020 2020 436f 6e6a 5268 7320 3d20 6661      ConjRhs = fa
+00005930: 6c73 652c 0a20 2020 2056 6563 746f 7269  lse,.    Vectori
+00005940: 7a61 626c 6520 3d20 756e 7061 636b 6574  zable = unpacket
+00005950: 5f74 7261 6974 733c 5f4c 6873 5061 636b  _traits<_LhsPack
+00005960: 6574 3e3a 3a76 6563 746f 7269 7a61 626c  et>::vectorizabl
+00005970: 6520 2626 2075 6e70 6163 6b65 745f 7472  e && unpacket_tr
+00005980: 6169 7473 3c5f 5268 7350 6163 6b65 743e  aits<_RhsPacket>
+00005990: 3a3a 7665 6374 6f72 697a 6162 6c65 2c0a  ::vectorizable,.
+000059a0: 2020 2020 4c68 7350 6163 6b65 7453 697a      LhsPacketSiz
+000059b0: 6520 3d20 5665 6374 6f72 697a 6162 6c65  e = Vectorizable
+000059c0: 203f 2075 6e70 6163 6b65 745f 7472 6169   ? unpacket_trai
+000059d0: 7473 3c5f 4c68 7350 6163 6b65 743e 3a3a  ts<_LhsPacket>::
+000059e0: 7369 7a65 203a 2031 2c0a 2020 2020 5268  size : 1,.    Rh
+000059f0: 7350 6163 6b65 7453 697a 6520 3d20 5665  sPacketSize = Ve
+00005a00: 6374 6f72 697a 6162 6c65 203f 2075 6e70  ctorizable ? unp
+00005a10: 6163 6b65 745f 7472 6169 7473 3c5f 5268  acket_traits<_Rh
+00005a20: 7350 6163 6b65 743e 3a3a 7369 7a65 203a  sPacket>::size :
+00005a30: 2031 2c0a 2020 2020 5265 7350 6163 6b65   1,.    ResPacke
+00005a40: 7453 697a 6520 3d20 5665 6374 6f72 697a  tSize = Vectoriz
+00005a50: 6162 6c65 203f 2075 6e70 6163 6b65 745f  able ? unpacket_
+00005a60: 7472 6169 7473 3c5f 5265 7350 6163 6b65  traits<_ResPacke
+00005a70: 743e 3a3a 7369 7a65 203a 2031 2c0a 2020  t>::size : 1,.  
+00005a80: 2020 0a20 2020 204e 756d 6265 724f 6652    .    NumberOfR
+00005a90: 6567 6973 7465 7273 203d 2045 4947 454e  egisters = EIGEN
+00005aa0: 5f41 5243 485f 4445 4641 554c 545f 4e55  _ARCH_DEFAULT_NU
+00005ab0: 4d42 4552 5f4f 465f 5245 4749 5354 4552  MBER_OF_REGISTER
+00005ac0: 532c 0a20 2020 206e 7220 3d20 342c 0a23  S,.    nr = 4,.#
+00005ad0: 6966 2064 6566 696e 6564 2845 4947 454e  if defined(EIGEN
+00005ae0: 5f48 4153 5f53 494e 474c 455f 494e 5354  _HAS_SINGLE_INST
+00005af0: 5255 4354 494f 4e5f 4d41 4444 2920 2626  RUCTION_MADD) &&
+00005b00: 2021 6465 6669 6e65 6428 4549 4745 4e5f   !defined(EIGEN_
+00005b10: 5645 4354 4f52 495a 455f 414c 5449 5645  VECTORIZE_ALTIVE
+00005b20: 4329 2026 2620 2164 6566 696e 6564 2845  C) && !defined(E
+00005b30: 4947 454e 5f56 4543 544f 5249 5a45 5f56  IGEN_VECTORIZE_V
+00005b40: 5358 290a 2020 2020 2f2f 2077 6520 6173  SX).    // we as
+00005b50: 7375 6d65 2031 3620 7265 6769 7374 6572  sume 16 register
+00005b60: 730a 2020 2020 6d72 203d 2033 2a4c 6873  s.    mr = 3*Lhs
+00005b70: 5061 636b 6574 5369 7a65 2c0a 2365 6c73  PacketSize,.#els
+00005b80: 650a 2020 2020 6d72 203d 2028 4549 4745  e.    mr = (EIGE
+00005b90: 4e5f 504c 4149 4e5f 454e 554d 5f4d 494e  N_PLAIN_ENUM_MIN
+00005ba0: 2831 362c 4e75 6d62 6572 4f66 5265 6769  (16,NumberOfRegi
+00005bb0: 7374 6572 7329 2f32 2f6e 7229 2a4c 6873  sters)/2/nr)*Lhs
+00005bc0: 5061 636b 6574 5369 7a65 2c0a 2365 6e64  PacketSize,.#end
+00005bd0: 6966 0a0a 2020 2020 4c68 7350 726f 6772  if..    LhsProgr
+00005be0: 6573 7320 3d20 4c68 7350 6163 6b65 7453  ess = LhsPacketS
+00005bf0: 697a 652c 0a20 2020 2052 6873 5072 6f67  ize,.    RhsProg
+00005c00: 7265 7373 203d 2031 0a20 207d 3b0a 0a20  ress = 1.  };.. 
+00005c10: 2074 7970 6564 6566 2074 7970 656e 616d   typedef typenam
+00005c20: 6520 636f 6e64 6974 696f 6e61 6c3c 5665  e conditional<Ve
+00005c30: 6374 6f72 697a 6162 6c65 2c5f 4c68 7350  ctorizable,_LhsP
+00005c40: 6163 6b65 742c 4c68 7353 6361 6c61 723e  acket,LhsScalar>
+00005c50: 3a3a 7479 7065 204c 6873 5061 636b 6574  ::type LhsPacket
+00005c60: 3b0a 2020 7479 7065 6465 6620 7479 7065  ;.  typedef type
+00005c70: 6e61 6d65 2063 6f6e 6469 7469 6f6e 616c  name conditional
+00005c80: 3c56 6563 746f 7269 7a61 626c 652c 5f52  <Vectorizable,_R
+00005c90: 6873 5061 636b 6574 2c52 6873 5363 616c  hsPacket,RhsScal
+00005ca0: 6172 3e3a 3a74 7970 6520 5268 7350 6163  ar>::type RhsPac
+00005cb0: 6b65 743b 0a20 2074 7970 6564 6566 2074  ket;.  typedef t
+00005cc0: 7970 656e 616d 6520 636f 6e64 6974 696f  ypename conditio
+00005cd0: 6e61 6c3c 5665 6374 6f72 697a 6162 6c65  nal<Vectorizable
+00005ce0: 2c5f 5265 7350 6163 6b65 742c 5265 7353  ,_ResPacket,ResS
+00005cf0: 6361 6c61 723e 3a3a 7479 7065 2052 6573  calar>::type Res
+00005d00: 5061 636b 6574 3b0a 2020 7479 7065 6465  Packet;.  typede
+00005d10: 6620 4c68 7350 6163 6b65 7420 4c68 7350  f LhsPacket LhsP
+00005d20: 6163 6b65 7434 5061 636b 696e 673b 0a0a  acket4Packing;..
+00005d30: 2020 7479 7065 6465 6620 5175 6164 5061    typedef QuadPa
+00005d40: 636b 6574 3c52 6873 5061 636b 6574 3e20  cket<RhsPacket> 
+00005d50: 5268 7350 6163 6b65 7478 343b 0a0a 2020  RhsPacketx4;..  
+00005d60: 7479 7065 6465 6620 5265 7350 6163 6b65  typedef ResPacke
+00005d70: 7420 4163 6350 6163 6b65 743b 0a0a 2020  t AccPacket;..  
+00005d80: 4549 4745 4e5f 5354 524f 4e47 5f49 4e4c  EIGEN_STRONG_INL
+00005d90: 494e 4520 766f 6964 2069 6e69 7441 6363  INE void initAcc
+00005da0: 2841 6363 5061 636b 6574 2620 7029 0a20  (AccPacket& p). 
+00005db0: 207b 0a20 2020 2070 203d 2070 7365 7431   {.    p = pset1
+00005dc0: 3c52 6573 5061 636b 6574 3e28 5265 7353  <ResPacket>(ResS
+00005dd0: 6361 6c61 7228 3029 293b 0a20 207d 0a0a  calar(0));.  }..
+00005de0: 2020 7465 6d70 6c61 7465 3c74 7970 656e    template<typen
+00005df0: 616d 6520 5268 7350 6163 6b65 7454 7970  ame RhsPacketTyp
+00005e00: 653e 0a20 2045 4947 454e 5f53 5452 4f4e  e>.  EIGEN_STRON
+00005e10: 475f 494e 4c49 4e45 2076 6f69 6420 6c6f  G_INLINE void lo
+00005e20: 6164 5268 7328 636f 6e73 7420 5268 7353  adRhs(const RhsS
+00005e30: 6361 6c61 722a 2062 2c20 5268 7350 6163  calar* b, RhsPac
+00005e40: 6b65 7454 7970 6526 2064 6573 7429 2063  ketType& dest) c
+00005e50: 6f6e 7374 0a20 207b 0a20 2020 2064 6573  onst.  {.    des
+00005e60: 7420 3d20 7073 6574 313c 5268 7350 6163  t = pset1<RhsPac
+00005e70: 6b65 7454 7970 653e 282a 6229 3b0a 2020  ketType>(*b);.  
+00005e80: 7d0a 0a20 2045 4947 454e 5f53 5452 4f4e  }..  EIGEN_STRON
+00005e90: 475f 494e 4c49 4e45 2076 6f69 6420 6c6f  G_INLINE void lo
+00005ea0: 6164 5268 7328 636f 6e73 7420 5268 7353  adRhs(const RhsS
+00005eb0: 6361 6c61 722a 2062 2c20 5268 7350 6163  calar* b, RhsPac
+00005ec0: 6b65 7478 3426 2064 6573 7429 2063 6f6e  ketx4& dest) con
+00005ed0: 7374 0a20 207b 0a20 2020 2070 6272 6f61  st.  {.    pbroa
+00005ee0: 6463 6173 7434 2862 2c20 6465 7374 2e42  dcast4(b, dest.B
+00005ef0: 5f30 2c20 6465 7374 2e42 312c 2064 6573  _0, dest.B1, des
+00005f00: 742e 4232 2c20 6465 7374 2e42 3329 3b0a  t.B2, dest.B3);.
+00005f10: 2020 7d0a 0a20 2074 656d 706c 6174 653c    }..  template<
+00005f20: 7479 7065 6e61 6d65 2052 6873 5061 636b  typename RhsPack
+00005f30: 6574 5479 7065 3e0a 2020 4549 4745 4e5f  etType>.  EIGEN_
+00005f40: 5354 524f 4e47 5f49 4e4c 494e 4520 766f  STRONG_INLINE vo
+00005f50: 6964 2075 7064 6174 6552 6873 2863 6f6e  id updateRhs(con
+00005f60: 7374 2052 6873 5363 616c 6172 2a20 622c  st RhsScalar* b,
+00005f70: 2052 6873 5061 636b 6574 5479 7065 2620   RhsPacketType& 
+00005f80: 6465 7374 2920 636f 6e73 740a 2020 7b0a  dest) const.  {.
+00005f90: 2020 2020 6c6f 6164 5268 7328 622c 2064      loadRhs(b, d
+00005fa0: 6573 7429 3b0a 2020 7d0a 0a20 2045 4947  est);.  }..  EIG
+00005fb0: 454e 5f53 5452 4f4e 475f 494e 4c49 4e45  EN_STRONG_INLINE
+00005fc0: 2076 6f69 6420 7570 6461 7465 5268 7328   void updateRhs(
+00005fd0: 636f 6e73 7420 5268 7353 6361 6c61 722a  const RhsScalar*
+00005fe0: 2c20 5268 7350 6163 6b65 7478 3426 2920  , RhsPacketx4&) 
+00005ff0: 636f 6e73 740a 2020 7b7d 0a20 200a 2020  const.  {}.  .  
+00006000: 4549 4745 4e5f 5354 524f 4e47 5f49 4e4c  EIGEN_STRONG_INL
+00006010: 494e 4520 766f 6964 206c 6f61 6452 6873  INE void loadRhs
+00006020: 5175 6164 2863 6f6e 7374 2052 6873 5363  Quad(const RhsSc
+00006030: 616c 6172 2a20 622c 2052 6873 5061 636b  alar* b, RhsPack
+00006040: 6574 2620 6465 7374 2920 636f 6e73 740a  et& dest) const.
+00006050: 2020 7b0a 2020 2020 6c6f 6164 5268 7351    {.    loadRhsQ
+00006060: 7561 645f 696d 706c 2862 2c64 6573 742c  uad_impl(b,dest,
+00006070: 2074 7970 656e 616d 6520 636f 6e64 6974   typename condit
+00006080: 696f 6e61 6c3c 5268 7350 6163 6b65 7453  ional<RhsPacketS
+00006090: 697a 653d 3d31 362c 7472 7565 5f74 7970  ize==16,true_typ
+000060a0: 652c 6661 6c73 655f 7479 7065 3e3a 3a74  e,false_type>::t
+000060b0: 7970 6528 2929 3b0a 2020 7d0a 0a20 2045  ype());.  }..  E
+000060c0: 4947 454e 5f53 5452 4f4e 475f 494e 4c49  IGEN_STRONG_INLI
+000060d0: 4e45 2076 6f69 6420 6c6f 6164 5268 7351  NE void loadRhsQ
+000060e0: 7561 645f 696d 706c 2863 6f6e 7374 2052  uad_impl(const R
+000060f0: 6873 5363 616c 6172 2a20 622c 2052 6873  hsScalar* b, Rhs
+00006100: 5061 636b 6574 2620 6465 7374 2c20 636f  Packet& dest, co
+00006110: 6e73 7420 7472 7565 5f74 7970 6526 2920  nst true_type&) 
+00006120: 636f 6e73 740a 2020 7b0a 2020 2020 2f2f  const.  {.    //
+00006130: 2046 4958 4d45 2077 6520 6361 6e20 646f   FIXME we can do
+00006140: 2062 6574 7465 7221 0a20 2020 202f 2f20   better!.    // 
+00006150: 7768 6174 2077 6520 7761 6e74 2068 6572  what we want her
+00006160: 6520 6973 2061 2070 6c6f 6164 6865 6967  e is a ploadheig
+00006170: 6874 0a20 2020 2052 6873 5363 616c 6172  ht.    RhsScalar
+00006180: 2074 6d70 5b34 5d20 3d20 7b62 5b30 5d2c   tmp[4] = {b[0],
+00006190: 625b 305d 2c62 5b31 5d2c 625b 315d 7d3b  b[0],b[1],b[1]};
+000061a0: 0a20 2020 2064 6573 7420 3d20 706c 6f61  .    dest = ploa
+000061b0: 6471 7561 643c 5268 7350 6163 6b65 743e  dquad<RhsPacket>
+000061c0: 2874 6d70 293b 0a20 207d 0a0a 2020 4549  (tmp);.  }..  EI
+000061d0: 4745 4e5f 5354 524f 4e47 5f49 4e4c 494e  GEN_STRONG_INLIN
+000061e0: 4520 766f 6964 206c 6f61 6452 6873 5175  E void loadRhsQu
+000061f0: 6164 5f69 6d70 6c28 636f 6e73 7420 5268  ad_impl(const Rh
+00006200: 7353 6361 6c61 722a 2062 2c20 5268 7350  sScalar* b, RhsP
+00006210: 6163 6b65 7426 2064 6573 742c 2063 6f6e  acket& dest, con
+00006220: 7374 2066 616c 7365 5f74 7970 6526 2920  st false_type&) 
+00006230: 636f 6e73 740a 2020 7b0a 2020 2020 6569  const.  {.    ei
+00006240: 6765 6e5f 696e 7465 726e 616c 5f61 7373  gen_internal_ass
+00006250: 6572 7428 5268 7350 6163 6b65 7453 697a  ert(RhsPacketSiz
+00006260: 653c 3d38 293b 0a20 2020 2064 6573 7420  e<=8);.    dest 
+00006270: 3d20 7073 6574 313c 5268 7350 6163 6b65  = pset1<RhsPacke
+00006280: 743e 282a 6229 3b0a 2020 7d0a 0a20 2045  t>(*b);.  }..  E
+00006290: 4947 454e 5f53 5452 4f4e 475f 494e 4c49  IGEN_STRONG_INLI
+000062a0: 4e45 2076 6f69 6420 6c6f 6164 4c68 7328  NE void loadLhs(
+000062b0: 636f 6e73 7420 4c68 7353 6361 6c61 722a  const LhsScalar*
+000062c0: 2061 2c20 4c68 7350 6163 6b65 7426 2064   a, LhsPacket& d
+000062d0: 6573 7429 2063 6f6e 7374 0a20 207b 0a20  est) const.  {. 
+000062e0: 2020 2064 6573 7420 3d20 706c 6f61 643c     dest = pload<
+000062f0: 4c68 7350 6163 6b65 743e 2861 293b 0a20  LhsPacket>(a);. 
+00006300: 207d 0a0a 2020 7465 6d70 6c61 7465 3c74   }..  template<t
+00006310: 7970 656e 616d 6520 4c68 7350 6163 6b65  ypename LhsPacke
+00006320: 7454 7970 653e 0a20 2045 4947 454e 5f53  tType>.  EIGEN_S
+00006330: 5452 4f4e 475f 494e 4c49 4e45 2076 6f69  TRONG_INLINE voi
+00006340: 6420 6c6f 6164 4c68 7355 6e61 6c69 676e  d loadLhsUnalign
+00006350: 6564 2863 6f6e 7374 204c 6873 5363 616c  ed(const LhsScal
+00006360: 6172 2a20 612c 204c 6873 5061 636b 6574  ar* a, LhsPacket
+00006370: 5479 7065 2620 6465 7374 2920 636f 6e73  Type& dest) cons
+00006380: 740a 2020 7b0a 2020 2020 6465 7374 203d  t.  {.    dest =
+00006390: 2070 6c6f 6164 753c 4c68 7350 6163 6b65   ploadu<LhsPacke
+000063a0: 7454 7970 653e 2861 293b 0a20 207d 0a0a  tType>(a);.  }..
+000063b0: 2020 7465 6d70 6c61 7465 203c 7479 7065    template <type
+000063c0: 6e61 6d65 204c 6873 5061 636b 6574 5479  name LhsPacketTy
+000063d0: 7065 2c20 7479 7065 6e61 6d65 2052 6873  pe, typename Rhs
+000063e0: 5061 636b 6574 5479 7065 2c20 7479 7065  PacketType, type
+000063f0: 6e61 6d65 2041 6363 5061 636b 6574 5479  name AccPacketTy
+00006400: 7065 2c20 7479 7065 6e61 6d65 204c 616e  pe, typename Lan
+00006410: 6549 6454 7970 653e 0a20 2045 4947 454e  eIdType>.  EIGEN
+00006420: 5f53 5452 4f4e 475f 494e 4c49 4e45 2076  _STRONG_INLINE v
+00006430: 6f69 6420 6d61 6464 2863 6f6e 7374 204c  oid madd(const L
+00006440: 6873 5061 636b 6574 5479 7065 2620 612c  hsPacketType& a,
+00006450: 2063 6f6e 7374 2052 6873 5061 636b 6574   const RhsPacket
+00006460: 5479 7065 2620 622c 2041 6363 5061 636b  Type& b, AccPack
+00006470: 6574 5479 7065 2620 632c 2052 6873 5061  etType& c, RhsPa
+00006480: 636b 6574 5479 7065 2620 746d 702c 2063  cketType& tmp, c
+00006490: 6f6e 7374 204c 616e 6549 6454 7970 6526  onst LaneIdType&
+000064a0: 2920 636f 6e73 740a 2020 7b0a 2020 2020  ) const.  {.    
+000064b0: 6d61 6464 5f69 6d70 6c28 612c 2062 2c20  madd_impl(a, b, 
+000064c0: 632c 2074 6d70 2c20 7479 7065 6e61 6d65  c, tmp, typename
+000064d0: 2063 6f6e 6469 7469 6f6e 616c 3c56 6563   conditional<Vec
+000064e0: 746f 7269 7a61 626c 652c 7472 7565 5f74  torizable,true_t
+000064f0: 7970 652c 6661 6c73 655f 7479 7065 3e3a  ype,false_type>:
+00006500: 3a74 7970 6528 2929 3b0a 2020 7d0a 0a20  :type());.  }.. 
+00006510: 2074 656d 706c 6174 6520 3c74 7970 656e   template <typen
+00006520: 616d 6520 4c68 7350 6163 6b65 7454 7970  ame LhsPacketTyp
+00006530: 652c 2074 7970 656e 616d 6520 5268 7350  e, typename RhsP
+00006540: 6163 6b65 7454 7970 652c 2074 7970 656e  acketType, typen
+00006550: 616d 6520 4163 6350 6163 6b65 7454 7970  ame AccPacketTyp
+00006560: 653e 0a20 2045 4947 454e 5f53 5452 4f4e  e>.  EIGEN_STRON
+00006570: 475f 494e 4c49 4e45 2076 6f69 6420 6d61  G_INLINE void ma
+00006580: 6464 5f69 6d70 6c28 636f 6e73 7420 4c68  dd_impl(const Lh
+00006590: 7350 6163 6b65 7454 7970 6526 2061 2c20  sPacketType& a, 
+000065a0: 636f 6e73 7420 5268 7350 6163 6b65 7454  const RhsPacketT
+000065b0: 7970 6526 2062 2c20 4163 6350 6163 6b65  ype& b, AccPacke
+000065c0: 7454 7970 6526 2063 2c20 5268 7350 6163  tType& c, RhsPac
+000065d0: 6b65 7454 7970 6526 2074 6d70 2c20 636f  ketType& tmp, co
+000065e0: 6e73 7420 7472 7565 5f74 7970 6526 2920  nst true_type&) 
+000065f0: 636f 6e73 740a 2020 7b0a 2369 6664 6566  const.  {.#ifdef
+00006600: 2045 4947 454e 5f48 4153 5f53 494e 474c   EIGEN_HAS_SINGL
+00006610: 455f 494e 5354 5255 4354 494f 4e5f 4d41  E_INSTRUCTION_MA
+00006620: 4444 0a20 2020 2045 4947 454e 5f55 4e55  DD.    EIGEN_UNU
+00006630: 5345 445f 5641 5249 4142 4c45 2874 6d70  SED_VARIABLE(tmp
+00006640: 293b 0a20 2020 2063 2e76 203d 2070 6d61  );.    c.v = pma
+00006650: 6464 2861 2e76 2c62 2c63 2e76 293b 0a23  dd(a.v,b,c.v);.#
+00006660: 656c 7365 0a20 2020 2074 6d70 203d 2062  else.    tmp = b
+00006670: 3b20 746d 7020 3d20 706d 756c 2861 2e76  ; tmp = pmul(a.v
+00006680: 2c74 6d70 293b 2063 2e76 203d 2070 6164  ,tmp); c.v = pad
+00006690: 6428 632e 762c 746d 7029 3b0a 2365 6e64  d(c.v,tmp);.#end
+000066a0: 6966 0a20 207d 0a0a 2020 4549 4745 4e5f  if.  }..  EIGEN_
+000066b0: 5354 524f 4e47 5f49 4e4c 494e 4520 766f  STRONG_INLINE vo
+000066c0: 6964 206d 6164 645f 696d 706c 2863 6f6e  id madd_impl(con
+000066d0: 7374 204c 6873 5363 616c 6172 2620 612c  st LhsScalar& a,
+000066e0: 2063 6f6e 7374 2052 6873 5363 616c 6172   const RhsScalar
+000066f0: 2620 622c 2052 6573 5363 616c 6172 2620  & b, ResScalar& 
+00006700: 632c 2052 6873 5363 616c 6172 2620 2f2a  c, RhsScalar& /*
+00006710: 746d 702a 2f2c 2063 6f6e 7374 2066 616c  tmp*/, const fal
+00006720: 7365 5f74 7970 6526 2920 636f 6e73 740a  se_type&) const.
+00006730: 2020 7b0a 2020 2020 6320 2b3d 2061 202a    {.    c += a *
+00006740: 2062 3b0a 2020 7d0a 0a20 2074 656d 706c   b;.  }..  templ
+00006750: 6174 653c 7479 7065 6e61 6d65 204c 6873  ate<typename Lhs
+00006760: 5061 636b 6574 5479 7065 2c20 7479 7065  PacketType, type
+00006770: 6e61 6d65 2041 6363 5061 636b 6574 5479  name AccPacketTy
+00006780: 7065 2c20 7479 7065 6e61 6d65 204c 616e  pe, typename Lan
+00006790: 6549 6454 7970 653e 0a20 2045 4947 454e  eIdType>.  EIGEN
+000067a0: 5f53 5452 4f4e 475f 494e 4c49 4e45 2076  _STRONG_INLINE v
+000067b0: 6f69 6420 6d61 6464 2863 6f6e 7374 204c  oid madd(const L
+000067c0: 6873 5061 636b 6574 5479 7065 2620 612c  hsPacketType& a,
+000067d0: 2063 6f6e 7374 2052 6873 5061 636b 6574   const RhsPacket
+000067e0: 7834 2620 622c 2041 6363 5061 636b 6574  x4& b, AccPacket
+000067f0: 5479 7065 2620 632c 2052 6873 5061 636b  Type& c, RhsPack
+00006800: 6574 2620 746d 702c 2063 6f6e 7374 204c  et& tmp, const L
+00006810: 616e 6549 6454 7970 6526 206c 616e 6529  aneIdType& lane)
+00006820: 2063 6f6e 7374 0a20 207b 0a20 2020 206d   const.  {.    m
+00006830: 6164 6428 612c 2062 2e67 6574 286c 616e  add(a, b.get(lan
+00006840: 6529 2c20 632c 2074 6d70 2c20 6c61 6e65  e), c, tmp, lane
+00006850: 293b 0a20 207d 0a0a 2020 7465 6d70 6c61  );.  }..  templa
+00006860: 7465 203c 7479 7065 6e61 6d65 2052 6573  te <typename Res
+00006870: 5061 636b 6574 5479 7065 2c20 7479 7065  PacketType, type
+00006880: 6e61 6d65 2041 6363 5061 636b 6574 5479  name AccPacketTy
+00006890: 7065 3e0a 2020 4549 4745 4e5f 5354 524f  pe>.  EIGEN_STRO
+000068a0: 4e47 5f49 4e4c 494e 4520 766f 6964 2061  NG_INLINE void a
+000068b0: 6363 2863 6f6e 7374 2041 6363 5061 636b  cc(const AccPack
+000068c0: 6574 5479 7065 2620 632c 2063 6f6e 7374  etType& c, const
+000068d0: 2052 6573 5061 636b 6574 5479 7065 2620   ResPacketType& 
+000068e0: 616c 7068 612c 2052 6573 5061 636b 6574  alpha, ResPacket
+000068f0: 5479 7065 2620 7229 2063 6f6e 7374 0a20  Type& r) const. 
+00006900: 207b 0a20 2020 2063 6f6e 6a5f 6865 6c70   {.    conj_help
+00006910: 6572 3c52 6573 5061 636b 6574 5479 7065  er<ResPacketType
+00006920: 2c52 6573 5061 636b 6574 5479 7065 2c43  ,ResPacketType,C
+00006930: 6f6e 6a4c 6873 2c66 616c 7365 3e20 636a  onjLhs,false> cj
+00006940: 3b0a 2020 2020 7220 3d20 636a 2e70 6d61  ;.    r = cj.pma
+00006950: 6464 2863 2c61 6c70 6861 2c72 293b 0a20  dd(c,alpha,r);. 
+00006960: 207d 0a0a 7072 6f74 6563 7465 643a 0a7d   }..protected:.}
+00006970: 3b0a 0a74 656d 706c 6174 653c 7479 7065  ;..template<type
+00006980: 6e61 6d65 2050 6163 6b65 743e 0a73 7472  name Packet>.str
+00006990: 7563 7420 446f 7562 6c65 5061 636b 6574  uct DoublePacket
+000069a0: 0a7b 0a20 2050 6163 6b65 7420 6669 7273  .{.  Packet firs
+000069b0: 743b 0a20 2050 6163 6b65 7420 7365 636f  t;.  Packet seco
+000069c0: 6e64 3b0a 7d3b 0a0a 7465 6d70 6c61 7465  nd;.};..template
+000069d0: 3c74 7970 656e 616d 6520 5061 636b 6574  <typename Packet
+000069e0: 3e0a 446f 7562 6c65 5061 636b 6574 3c50  >.DoublePacket<P
+000069f0: 6163 6b65 743e 2070 6164 6428 636f 6e73  acket> padd(cons
+00006a00: 7420 446f 7562 6c65 5061 636b 6574 3c50  t DoublePacket<P
+00006a10: 6163 6b65 743e 2026 612c 2063 6f6e 7374  acket> &a, const
+00006a20: 2044 6f75 626c 6550 6163 6b65 743c 5061   DoublePacket<Pa
+00006a30: 636b 6574 3e20 2662 290a 7b0a 2020 446f  cket> &b).{.  Do
+00006a40: 7562 6c65 5061 636b 6574 3c50 6163 6b65  ublePacket<Packe
+00006a50: 743e 2072 6573 3b0a 2020 7265 732e 6669  t> res;.  res.fi
+00006a60: 7273 7420 203d 2070 6164 6428 612e 6669  rst  = padd(a.fi
+00006a70: 7273 742c 2062 2e66 6972 7374 293b 0a20  rst, b.first);. 
+00006a80: 2072 6573 2e73 6563 6f6e 6420 3d20 7061   res.second = pa
+00006a90: 6464 2861 2e73 6563 6f6e 642c 622e 7365  dd(a.second,b.se
+00006aa0: 636f 6e64 293b 0a20 2072 6574 7572 6e20  cond);.  return 
+00006ab0: 7265 733b 0a7d 0a0a 2f2f 206e 6f74 6520  res;.}..// note 
+00006ac0: 7468 6174 2066 6f72 2044 6f75 626c 6550  that for DoubleP
+00006ad0: 6163 6b65 743c 5265 616c 5061 636b 6574  acket<RealPacket
+00006ae0: 3e20 7468 6520 2234 2220 696e 2022 646f  > the "4" in "do
+00006af0: 776e 746f 3422 0a2f 2f20 636f 7272 6573  wnto4".// corres
+00006b00: 706f 6e64 7320 746f 2074 6865 206e 756d  ponds to the num
+00006b10: 6265 7220 6f66 2063 6f6d 706c 6578 6573  ber of complexes
+00006b20: 2c20 736f 2069 7420 6d65 616e 7320 2238  , so it means "8
+00006b30: 220a 2f2f 2069 7420 7465 726d 7320 6f66  ".// it terms of
+00006b40: 2072 6561 6c20 636f 6566 6669 6369 656e   real coefficien
+00006b50: 7473 2e0a 0a74 656d 706c 6174 653c 7479  ts...template<ty
+00006b60: 7065 6e61 6d65 2050 6163 6b65 743e 0a63  pename Packet>.c
+00006b70: 6f6e 7374 2044 6f75 626c 6550 6163 6b65  onst DoublePacke
+00006b80: 743c 5061 636b 6574 3e26 0a70 7265 6475  t<Packet>&.predu
+00006b90: 785f 6861 6c66 5f64 6f77 746f 3428 636f  x_half_dowto4(co
+00006ba0: 6e73 7420 446f 7562 6c65 5061 636b 6574  nst DoublePacket
+00006bb0: 3c50 6163 6b65 743e 2026 612c 0a20 2020  <Packet> &a,.   
+00006bc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006bd0: 7479 7065 6e61 6d65 2065 6e61 626c 655f  typename enable_
+00006be0: 6966 3c75 6e70 6163 6b65 745f 7472 6169  if<unpacket_trai
+00006bf0: 7473 3c50 6163 6b65 743e 3a3a 7369 7a65  ts<Packet>::size
+00006c00: 3c3d 383e 3a3a 7479 7065 2a20 3d20 3029  <=8>::type* = 0)
+00006c10: 0a7b 0a20 2072 6574 7572 6e20 613b 0a7d  .{.  return a;.}
+00006c20: 0a0a 7465 6d70 6c61 7465 3c74 7970 656e  ..template<typen
+00006c30: 616d 6520 5061 636b 6574 3e0a 446f 7562  ame Packet>.Doub
+00006c40: 6c65 5061 636b 6574 3c74 7970 656e 616d  lePacket<typenam
+00006c50: 6520 756e 7061 636b 6574 5f74 7261 6974  e unpacket_trait
+00006c60: 733c 5061 636b 6574 3e3a 3a68 616c 663e  s<Packet>::half>
+00006c70: 0a70 7265 6475 785f 6861 6c66 5f64 6f77  .predux_half_dow
+00006c80: 746f 3428 636f 6e73 7420 446f 7562 6c65  to4(const Double
+00006c90: 5061 636b 6574 3c50 6163 6b65 743e 2026  Packet<Packet> &
+00006ca0: 612c 0a20 2020 2020 2020 2020 2020 2020  a,.             
+00006cb0: 2020 2020 2020 7479 7065 6e61 6d65 2065        typename e
+00006cc0: 6e61 626c 655f 6966 3c75 6e70 6163 6b65  nable_if<unpacke
+00006cd0: 745f 7472 6169 7473 3c50 6163 6b65 743e  t_traits<Packet>
+00006ce0: 3a3a 7369 7a65 3d3d 3136 3e3a 3a74 7970  ::size==16>::typ
+00006cf0: 652a 203d 2030 290a 7b0a 2020 2f2f 2079  e* = 0).{.  // y
+00006d00: 6573 2c20 7468 6174 2773 2070 7265 7474  es, that's prett
+00006d10: 7920 6861 636b 6973 6820 3a28 0a20 2044  y hackish :(.  D
+00006d20: 6f75 626c 6550 6163 6b65 743c 7479 7065  oublePacket<type
+00006d30: 6e61 6d65 2075 6e70 6163 6b65 745f 7472  name unpacket_tr
+00006d40: 6169 7473 3c50 6163 6b65 743e 3a3a 6861  aits<Packet>::ha
+00006d50: 6c66 3e20 7265 733b 0a20 2074 7970 6564  lf> res;.  typed
+00006d60: 6566 2073 7464 3a3a 636f 6d70 6c65 783c  ef std::complex<
+00006d70: 7479 7065 6e61 6d65 2075 6e70 6163 6b65  typename unpacke
+00006d80: 745f 7472 6169 7473 3c50 6163 6b65 743e  t_traits<Packet>
+00006d90: 3a3a 7479 7065 3e20 4370 6c78 3b0a 2020  ::type> Cplx;.  
+00006da0: 7479 7065 6465 6620 7479 7065 6e61 6d65  typedef typename
+00006db0: 2070 6163 6b65 745f 7472 6169 7473 3c43   packet_traits<C
+00006dc0: 706c 783e 3a3a 7479 7065 2043 706c 7850  plx>::type CplxP
+00006dd0: 6163 6b65 743b 0a20 2072 6573 2e66 6972  acket;.  res.fir
+00006de0: 7374 2020 3d20 7072 6564 7578 5f68 616c  st  = predux_hal
+00006df0: 665f 646f 7774 6f34 2843 706c 7850 6163  f_dowto4(CplxPac
+00006e00: 6b65 7428 612e 6669 7273 7429 292e 763b  ket(a.first)).v;
+00006e10: 0a20 2072 6573 2e73 6563 6f6e 6420 3d20  .  res.second = 
+00006e20: 7072 6564 7578 5f68 616c 665f 646f 7774  predux_half_dowt
+00006e30: 6f34 2843 706c 7850 6163 6b65 7428 612e  o4(CplxPacket(a.
+00006e40: 7365 636f 6e64 2929 2e76 3b0a 2020 7265  second)).v;.  re
+00006e50: 7475 726e 2072 6573 3b0a 7d0a 0a2f 2f20  turn res;.}..// 
+00006e60: 7361 6d65 2068 6572 652c 2022 7175 6164  same here, "quad
+00006e70: 2220 6163 7475 616c 6c79 206d 6561 6e73  " actually means
+00006e80: 2022 3822 2069 6e20 7465 726d 7320 6f66   "8" in terms of
+00006e90: 2072 6561 6c20 636f 6566 6669 6369 656e   real coefficien
+00006ea0: 7473 0a74 656d 706c 6174 653c 7479 7065  ts.template<type
+00006eb0: 6e61 6d65 2053 6361 6c61 722c 2074 7970  name Scalar, typ
+00006ec0: 656e 616d 6520 5265 616c 5061 636b 6574  ename RealPacket
+00006ed0: 3e0a 766f 6964 206c 6f61 6451 7561 6454  >.void loadQuadT
+00006ee0: 6f44 6f75 626c 6550 6163 6b65 7428 636f  oDoublePacket(co
+00006ef0: 6e73 7420 5363 616c 6172 2a20 622c 2044  nst Scalar* b, D
+00006f00: 6f75 626c 6550 6163 6b65 743c 5265 616c  oublePacket<Real
+00006f10: 5061 636b 6574 3e26 2064 6573 742c 0a20  Packet>& dest,. 
+00006f20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006f30: 2020 2020 2020 2020 2020 2074 7970 656e             typen
+00006f40: 616d 6520 656e 6162 6c65 5f69 663c 756e  ame enable_if<un
+00006f50: 7061 636b 6574 5f74 7261 6974 733c 5265  packet_traits<Re
+00006f60: 616c 5061 636b 6574 3e3a 3a73 697a 653c  alPacket>::size<
+00006f70: 3d38 3e3a 3a74 7970 652a 203d 2030 290a  =8>::type* = 0).
+00006f80: 7b0a 2020 6465 7374 2e66 6972 7374 2020  {.  dest.first  
+00006f90: 3d20 7073 6574 313c 5265 616c 5061 636b  = pset1<RealPack
+00006fa0: 6574 3e28 6e75 6d65 7874 3a3a 7265 616c  et>(numext::real
+00006fb0: 282a 6229 293b 0a20 2064 6573 742e 7365  (*b));.  dest.se
+00006fc0: 636f 6e64 203d 2070 7365 7431 3c52 6561  cond = pset1<Rea
+00006fd0: 6c50 6163 6b65 743e 286e 756d 6578 743a  lPacket>(numext:
+00006fe0: 3a69 6d61 6728 2a62 2929 3b0a 7d0a 0a74  :imag(*b));.}..t
+00006ff0: 656d 706c 6174 653c 7479 7065 6e61 6d65  emplate<typename
+00007000: 2053 6361 6c61 722c 2074 7970 656e 616d   Scalar, typenam
+00007010: 6520 5265 616c 5061 636b 6574 3e0a 766f  e RealPacket>.vo
+00007020: 6964 206c 6f61 6451 7561 6454 6f44 6f75  id loadQuadToDou
+00007030: 626c 6550 6163 6b65 7428 636f 6e73 7420  blePacket(const 
+00007040: 5363 616c 6172 2a20 622c 2044 6f75 626c  Scalar* b, Doubl
+00007050: 6550 6163 6b65 743c 5265 616c 5061 636b  ePacket<RealPack
+00007060: 6574 3e26 2064 6573 742c 0a20 2020 2020  et>& dest,.     
+00007070: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007080: 2020 2020 2020 2074 7970 656e 616d 6520         typename 
+00007090: 656e 6162 6c65 5f69 663c 756e 7061 636b  enable_if<unpack
+000070a0: 6574 5f74 7261 6974 733c 5265 616c 5061  et_traits<RealPa
+000070b0: 636b 6574 3e3a 3a73 697a 653d 3d31 363e  cket>::size==16>
+000070c0: 3a3a 7479 7065 2a20 3d20 3029 0a7b 0a20  ::type* = 0).{. 
+000070d0: 202f 2f20 7965 732c 2074 6861 7427 7320   // yes, that's 
+000070e0: 7072 6574 7479 2068 6163 6b69 7368 2074  pretty hackish t
+000070f0: 6f6f 203a 280a 2020 7479 7065 6465 6620  oo :(.  typedef 
+00007100: 7479 7065 6e61 6d65 204e 756d 5472 6169  typename NumTrai
+00007110: 7473 3c53 6361 6c61 723e 3a3a 5265 616c  ts<Scalar>::Real
+00007120: 2052 6561 6c53 6361 6c61 723b 0a20 2052   RealScalar;.  R
+00007130: 6561 6c53 6361 6c61 7220 725b 345d 203d  ealScalar r[4] =
+00007140: 207b 6e75 6d65 7874 3a3a 7265 616c 2862   {numext::real(b
+00007150: 5b30 5d29 2c20 6e75 6d65 7874 3a3a 7265  [0]), numext::re
+00007160: 616c 2862 5b30 5d29 2c20 6e75 6d65 7874  al(b[0]), numext
+00007170: 3a3a 7265 616c 2862 5b31 5d29 2c20 6e75  ::real(b[1]), nu
+00007180: 6d65 7874 3a3a 7265 616c 2862 5b31 5d29  mext::real(b[1])
+00007190: 7d3b 0a20 2052 6561 6c53 6361 6c61 7220  };.  RealScalar 
+000071a0: 695b 345d 203d 207b 6e75 6d65 7874 3a3a  i[4] = {numext::
+000071b0: 696d 6167 2862 5b30 5d29 2c20 6e75 6d65  imag(b[0]), nume
+000071c0: 7874 3a3a 696d 6167 2862 5b30 5d29 2c20  xt::imag(b[0]), 
+000071d0: 6e75 6d65 7874 3a3a 696d 6167 2862 5b31  numext::imag(b[1
+000071e0: 5d29 2c20 6e75 6d65 7874 3a3a 696d 6167  ]), numext::imag
+000071f0: 2862 5b31 5d29 7d3b 0a20 2064 6573 742e  (b[1])};.  dest.
+00007200: 6669 7273 7420 203d 2070 6c6f 6164 7175  first  = ploadqu
+00007210: 6164 3c52 6561 6c50 6163 6b65 743e 2872  ad<RealPacket>(r
+00007220: 293b 0a20 2064 6573 742e 7365 636f 6e64  );.  dest.second
+00007230: 203d 2070 6c6f 6164 7175 6164 3c52 6561   = ploadquad<Rea
+00007240: 6c50 6163 6b65 743e 2869 293b 0a7d 0a0a  lPacket>(i);.}..
+00007250: 0a74 656d 706c 6174 653c 7479 7065 6e61  .template<typena
+00007260: 6d65 2050 6163 6b65 743e 2073 7472 7563  me Packet> struc
+00007270: 7420 756e 7061 636b 6574 5f74 7261 6974  t unpacket_trait
+00007280: 733c 446f 7562 6c65 5061 636b 6574 3c50  s<DoublePacket<P
+00007290: 6163 6b65 743e 203e 207b 0a20 2074 7970  acket> > {.  typ
+000072a0: 6564 6566 2044 6f75 626c 6550 6163 6b65  edef DoublePacke
+000072b0: 743c 7479 7065 6e61 6d65 2075 6e70 6163  t<typename unpac
+000072c0: 6b65 745f 7472 6169 7473 3c50 6163 6b65  ket_traits<Packe
+000072d0: 743e 3a3a 6861 6c66 3e20 6861 6c66 3b0a  t>::half> half;.
+000072e0: 7d3b 0a2f 2f20 7465 6d70 6c61 7465 3c74  };.// template<t
+000072f0: 7970 656e 616d 6520 5061 636b 6574 3e0a  ypename Packet>.
+00007300: 2f2f 2044 6f75 626c 6550 6163 6b65 743c  // DoublePacket<
+00007310: 5061 636b 6574 3e20 706d 6164 6428 636f  Packet> pmadd(co
+00007320: 6e73 7420 446f 7562 6c65 5061 636b 6574  nst DoublePacket
+00007330: 3c50 6163 6b65 743e 2026 612c 2063 6f6e  <Packet> &a, con
+00007340: 7374 2044 6f75 626c 6550 6163 6b65 743c  st DoublePacket<
+00007350: 5061 636b 6574 3e20 2662 290a 2f2f 207b  Packet> &b).// {
+00007360: 0a2f 2f20 2020 446f 7562 6c65 5061 636b  .//   DoublePack
+00007370: 6574 3c50 6163 6b65 743e 2072 6573 3b0a  et<Packet> res;.
+00007380: 2f2f 2020 2072 6573 2e66 6972 7374 2020  //   res.first  
+00007390: 3d20 7061 6464 2861 2e66 6972 7374 2c20  = padd(a.first, 
+000073a0: 622e 6669 7273 7429 3b0a 2f2f 2020 2072  b.first);.//   r
+000073b0: 6573 2e73 6563 6f6e 6420 3d20 7061 6464  es.second = padd
+000073c0: 2861 2e73 6563 6f6e 642c 622e 7365 636f  (a.second,b.seco
+000073d0: 6e64 293b 0a2f 2f20 2020 7265 7475 726e  nd);.//   return
+000073e0: 2072 6573 3b0a 2f2f 207d 0a0a 7465 6d70   res;.// }..temp
+000073f0: 6c61 7465 3c74 7970 656e 616d 6520 5265  late<typename Re
+00007400: 616c 5363 616c 6172 2c20 626f 6f6c 205f  alScalar, bool _
+00007410: 436f 6e6a 4c68 732c 2062 6f6f 6c20 5f43  ConjLhs, bool _C
+00007420: 6f6e 6a52 6873 2c20 696e 7420 4172 6368  onjRhs, int Arch
+00007430: 2c20 696e 7420 5f50 6163 6b65 7453 697a  , int _PacketSiz
+00007440: 653e 0a63 6c61 7373 2067 6562 705f 7472  e>.class gebp_tr
+00007450: 6169 7473 3c73 7464 3a3a 636f 6d70 6c65  aits<std::comple
+00007460: 783c 5265 616c 5363 616c 6172 3e2c 2073  x<RealScalar>, s
+00007470: 7464 3a3a 636f 6d70 6c65 783c 5265 616c  td::complex<Real
+00007480: 5363 616c 6172 3e2c 205f 436f 6e6a 4c68  Scalar>, _ConjLh
+00007490: 732c 205f 436f 6e6a 5268 732c 2041 7263  s, _ConjRhs, Arc
+000074a0: 682c 205f 5061 636b 6574 5369 7a65 203e  h, _PacketSize >
+000074b0: 0a7b 0a70 7562 6c69 633a 0a20 2074 7970  .{.public:.  typ
+000074c0: 6564 6566 2073 7464 3a3a 636f 6d70 6c65  edef std::comple
+000074d0: 783c 5265 616c 5363 616c 6172 3e20 2053  x<RealScalar>  S
+000074e0: 6361 6c61 723b 0a20 2074 7970 6564 6566  calar;.  typedef
+000074f0: 2073 7464 3a3a 636f 6d70 6c65 783c 5265   std::complex<Re
+00007500: 616c 5363 616c 6172 3e20 204c 6873 5363  alScalar>  LhsSc
+00007510: 616c 6172 3b0a 2020 7479 7065 6465 6620  alar;.  typedef 
+00007520: 7374 643a 3a63 6f6d 706c 6578 3c52 6561  std::complex<Rea
+00007530: 6c53 6361 6c61 723e 2020 5268 7353 6361  lScalar>  RhsSca
+00007540: 6c61 723b 0a20 2074 7970 6564 6566 2073  lar;.  typedef s
+00007550: 7464 3a3a 636f 6d70 6c65 783c 5265 616c  td::complex<Real
+00007560: 5363 616c 6172 3e20 2052 6573 5363 616c  Scalar>  ResScal
+00007570: 6172 3b0a 2020 0a20 2050 4143 4b45 545f  ar;.  .  PACKET_
+00007580: 4445 434c 5f43 4f4e 445f 5052 4546 4958  DECL_COND_PREFIX
+00007590: 285f 2c20 4c68 732c 205f 5061 636b 6574  (_, Lhs, _Packet
+000075a0: 5369 7a65 293b 0a20 2050 4143 4b45 545f  Size);.  PACKET_
+000075b0: 4445 434c 5f43 4f4e 445f 5052 4546 4958  DECL_COND_PREFIX
+000075c0: 285f 2c20 5268 732c 205f 5061 636b 6574  (_, Rhs, _Packet
+000075d0: 5369 7a65 293b 0a20 2050 4143 4b45 545f  Size);.  PACKET_
+000075e0: 4445 434c 5f43 4f4e 445f 5052 4546 4958  DECL_COND_PREFIX
+000075f0: 285f 2c20 5265 732c 205f 5061 636b 6574  (_, Res, _Packet
+00007600: 5369 7a65 293b 0a20 2050 4143 4b45 545f  Size);.  PACKET_
+00007610: 4445 434c 5f43 4f4e 4428 5265 616c 2c20  DECL_COND(Real, 
+00007620: 5f50 6163 6b65 7453 697a 6529 3b0a 2020  _PacketSize);.  
+00007630: 5041 434b 4554 5f44 4543 4c5f 434f 4e44  PACKET_DECL_COND
+00007640: 5f53 4341 4c41 5228 5f50 6163 6b65 7453  _SCALAR(_PacketS
+00007650: 697a 6529 3b0a 0a20 2065 6e75 6d20 7b0a  ize);..  enum {.
+00007660: 2020 2020 436f 6e6a 4c68 7320 3d20 5f43      ConjLhs = _C
+00007670: 6f6e 6a4c 6873 2c0a 2020 2020 436f 6e6a  onjLhs,.    Conj
+00007680: 5268 7320 3d20 5f43 6f6e 6a52 6873 2c0a  Rhs = _ConjRhs,.
+00007690: 2020 2020 5665 6374 6f72 697a 6162 6c65      Vectorizable
+000076a0: 203d 2075 6e70 6163 6b65 745f 7472 6169   = unpacket_trai
+000076b0: 7473 3c52 6561 6c50 6163 6b65 743e 3a3a  ts<RealPacket>::
+000076c0: 7665 6374 6f72 697a 6162 6c65 0a20 2020  vectorizable.   
+000076d0: 2020 2020 2020 2020 2020 2020 2026 2620               && 
+000076e0: 756e 7061 636b 6574 5f74 7261 6974 733c  unpacket_traits<
+000076f0: 5363 616c 6172 5061 636b 6574 3e3a 3a76  ScalarPacket>::v
+00007700: 6563 746f 7269 7a61 626c 652c 0a20 2020  ectorizable,.   
+00007710: 2052 6573 5061 636b 6574 5369 7a65 2020   ResPacketSize  
+00007720: 203d 2056 6563 746f 7269 7a61 626c 6520   = Vectorizable 
+00007730: 3f20 756e 7061 636b 6574 5f74 7261 6974  ? unpacket_trait
+00007740: 733c 5f52 6573 5061 636b 6574 3e3a 3a73  s<_ResPacket>::s
+00007750: 697a 6520 3a20 312c 0a20 2020 204c 6873  ize : 1,.    Lhs
+00007760: 5061 636b 6574 5369 7a65 203d 2056 6563  PacketSize = Vec
+00007770: 746f 7269 7a61 626c 6520 3f20 756e 7061  torizable ? unpa
+00007780: 636b 6574 5f74 7261 6974 733c 5f4c 6873  cket_traits<_Lhs
+00007790: 5061 636b 6574 3e3a 3a73 697a 6520 3a20  Packet>::size : 
+000077a0: 312c 0a20 2020 2052 6873 5061 636b 6574  1,.    RhsPacket
+000077b0: 5369 7a65 203d 2056 6563 746f 7269 7a61  Size = Vectoriza
+000077c0: 626c 6520 3f20 756e 7061 636b 6574 5f74  ble ? unpacket_t
+000077d0: 7261 6974 733c 5268 7353 6361 6c61 723e  raits<RhsScalar>
+000077e0: 3a3a 7369 7a65 203a 2031 2c0a 2020 2020  ::size : 1,.    
+000077f0: 5265 616c 5061 636b 6574 5369 7a65 2020  RealPacketSize  
+00007800: 3d20 5665 6374 6f72 697a 6162 6c65 203f  = Vectorizable ?
+00007810: 2075 6e70 6163 6b65 745f 7472 6169 7473   unpacket_traits
+00007820: 3c52 6561 6c50 6163 6b65 743e 3a3a 7369  <RealPacket>::si
+00007830: 7a65 203a 2031 2c0a 0a20 2020 202f 2f20  ze : 1,..    // 
+00007840: 4649 584d 453a 2073 686f 756c 6420 6465  FIXME: should de
+00007850: 7065 6e64 206f 6e20 4e75 6d62 6572 4f66  pend on NumberOf
+00007860: 5265 6769 7374 6572 730a 2020 2020 6e72  Registers.    nr
+00007870: 203d 2034 2c0a 2020 2020 6d72 203d 2052   = 4,.    mr = R
+00007880: 6573 5061 636b 6574 5369 7a65 2c0a 0a20  esPacketSize,.. 
+00007890: 2020 204c 6873 5072 6f67 7265 7373 203d     LhsProgress =
+000078a0: 2052 6573 5061 636b 6574 5369 7a65 2c0a   ResPacketSize,.
+000078b0: 2020 2020 5268 7350 726f 6772 6573 7320      RhsProgress 
+000078c0: 3d20 310a 2020 7d3b 0a20 200a 2020 7479  = 1.  };.  .  ty
+000078d0: 7065 6465 6620 446f 7562 6c65 5061 636b  pedef DoublePack
+000078e0: 6574 3c52 6561 6c50 6163 6b65 743e 2020  et<RealPacket>  
+000078f0: 2020 2020 2020 2020 2020 2020 2020 2044                 D
+00007900: 6f75 626c 6550 6163 6b65 7454 7970 653b  oublePacketType;
+00007910: 0a0a 2020 7479 7065 6465 6620 7479 7065  ..  typedef type
+00007920: 6e61 6d65 2063 6f6e 6469 7469 6f6e 616c  name conditional
+00007930: 3c56 6563 746f 7269 7a61 626c 652c 5363  <Vectorizable,Sc
+00007940: 616c 6172 5061 636b 6574 2c53 6361 6c61  alarPacket,Scala
+00007950: 723e 3a3a 7479 7065 204c 6873 5061 636b  r>::type LhsPack
+00007960: 6574 3450 6163 6b69 6e67 3b0a 2020 7479  et4Packing;.  ty
+00007970: 7065 6465 6620 7479 7065 6e61 6d65 2063  pedef typename c
+00007980: 6f6e 6469 7469 6f6e 616c 3c56 6563 746f  onditional<Vecto
+00007990: 7269 7a61 626c 652c 5265 616c 5061 636b  rizable,RealPack
+000079a0: 6574 2c20 2053 6361 6c61 723e 3a3a 7479  et,  Scalar>::ty
+000079b0: 7065 204c 6873 5061 636b 6574 3b0a 2020  pe LhsPacket;.  
+000079c0: 7479 7065 6465 6620 7479 7065 6e61 6d65  typedef typename
+000079d0: 2063 6f6e 6469 7469 6f6e 616c 3c56 6563   conditional<Vec
+000079e0: 746f 7269 7a61 626c 652c 446f 7562 6c65  torizable,Double
+000079f0: 5061 636b 6574 5479 7065 2c53 6361 6c61  PacketType,Scala
+00007a00: 723e 3a3a 7479 7065 2052 6873 5061 636b  r>::type RhsPack
+00007a10: 6574 3b0a 2020 7479 7065 6465 6620 7479  et;.  typedef ty
+00007a20: 7065 6e61 6d65 2063 6f6e 6469 7469 6f6e  pename condition
+00007a30: 616c 3c56 6563 746f 7269 7a61 626c 652c  al<Vectorizable,
+00007a40: 5363 616c 6172 5061 636b 6574 2c53 6361  ScalarPacket,Sca
+00007a50: 6c61 723e 3a3a 7479 7065 2052 6573 5061  lar>::type ResPa
+00007a60: 636b 6574 3b0a 2020 7479 7065 6465 6620  cket;.  typedef 
+00007a70: 7479 7065 6e61 6d65 2063 6f6e 6469 7469  typename conditi
+00007a80: 6f6e 616c 3c56 6563 746f 7269 7a61 626c  onal<Vectorizabl
+00007a90: 652c 446f 7562 6c65 5061 636b 6574 5479  e,DoublePacketTy
+00007aa0: 7065 2c53 6361 6c61 723e 3a3a 7479 7065  pe,Scalar>::type
+00007ab0: 2041 6363 5061 636b 6574 3b0a 0a20 202f   AccPacket;..  /
+00007ac0: 2f20 7468 6973 2061 6374 7561 6c79 2068  / this actualy h
+00007ad0: 6f6c 6473 2038 2070 6163 6b65 7473 210a  olds 8 packets!.
+00007ae0: 2020 7479 7065 6465 6620 5175 6164 5061    typedef QuadPa
+00007af0: 636b 6574 3c52 6873 5061 636b 6574 3e20  cket<RhsPacket> 
+00007b00: 5268 7350 6163 6b65 7478 343b 0a20 200a  RhsPacketx4;.  .
+00007b10: 2020 4549 4745 4e5f 5354 524f 4e47 5f49    EIGEN_STRONG_I
+00007b20: 4e4c 494e 4520 766f 6964 2069 6e69 7441  NLINE void initA
+00007b30: 6363 2853 6361 6c61 7226 2070 2920 7b20  cc(Scalar& p) { 
+00007b40: 7020 3d20 5363 616c 6172 2830 293b 207d  p = Scalar(0); }
+00007b50: 0a0a 2020 4549 4745 4e5f 5354 524f 4e47  ..  EIGEN_STRONG
+00007b60: 5f49 4e4c 494e 4520 766f 6964 2069 6e69  _INLINE void ini
+00007b70: 7441 6363 2844 6f75 626c 6550 6163 6b65  tAcc(DoublePacke
+00007b80: 7454 7970 6526 2070 290a 2020 7b0a 2020  tType& p).  {.  
+00007b90: 2020 702e 6669 7273 7420 2020 3d20 7073    p.first   = ps
+00007ba0: 6574 313c 5265 616c 5061 636b 6574 3e28  et1<RealPacket>(
+00007bb0: 5265 616c 5363 616c 6172 2830 2929 3b0a  RealScalar(0));.
+00007bc0: 2020 2020 702e 7365 636f 6e64 2020 3d20      p.second  = 
+00007bd0: 7073 6574 313c 5265 616c 5061 636b 6574  pset1<RealPacket
+00007be0: 3e28 5265 616c 5363 616c 6172 2830 2929  >(RealScalar(0))
+00007bf0: 3b0a 2020 7d0a 0a20 202f 2f20 5363 616c  ;.  }..  // Scal
+00007c00: 6172 2070 6174 680a 2020 4549 4745 4e5f  ar path.  EIGEN_
+00007c10: 5354 524f 4e47 5f49 4e4c 494e 4520 766f  STRONG_INLINE vo
+00007c20: 6964 206c 6f61 6452 6873 2863 6f6e 7374  id loadRhs(const
+00007c30: 2052 6873 5363 616c 6172 2a20 622c 2053   RhsScalar* b, S
+00007c40: 6361 6c61 7250 6163 6b65 7426 2064 6573  calarPacket& des
+00007c50: 7429 2063 6f6e 7374 0a20 207b 0a20 2020  t) const.  {.   
+00007c60: 2064 6573 7420 3d20 7073 6574 313c 5363   dest = pset1<Sc
+00007c70: 616c 6172 5061 636b 6574 3e28 2a62 293b  alarPacket>(*b);
+00007c80: 0a20 207d 0a0a 2020 2f2f 2056 6563 746f  .  }..  // Vecto
+00007c90: 7269 7a65 6420 7061 7468 0a20 2074 656d  rized path.  tem
+00007ca0: 706c 6174 653c 7479 7065 6e61 6d65 2052  plate<typename R
+00007cb0: 6561 6c50 6163 6b65 7454 7970 653e 0a20  ealPacketType>. 
+00007cc0: 2045 4947 454e 5f53 5452 4f4e 475f 494e   EIGEN_STRONG_IN
+00007cd0: 4c49 4e45 2076 6f69 6420 6c6f 6164 5268  LINE void loadRh
+00007ce0: 7328 636f 6e73 7420 5268 7353 6361 6c61  s(const RhsScala
+00007cf0: 722a 2062 2c20 446f 7562 6c65 5061 636b  r* b, DoublePack
+00007d00: 6574 3c52 6561 6c50 6163 6b65 7454 7970  et<RealPacketTyp
+00007d10: 653e 2620 6465 7374 2920 636f 6e73 740a  e>& dest) const.
+00007d20: 2020 7b0a 2020 2020 6465 7374 2e66 6972    {.    dest.fir
+00007d30: 7374 2020 3d20 7073 6574 313c 5265 616c  st  = pset1<Real
+00007d40: 5061 636b 6574 5479 7065 3e28 6e75 6d65  PacketType>(nume
+00007d50: 7874 3a3a 7265 616c 282a 6229 293b 0a20  xt::real(*b));. 
+00007d60: 2020 2064 6573 742e 7365 636f 6e64 203d     dest.second =
+00007d70: 2070 7365 7431 3c52 6561 6c50 6163 6b65   pset1<RealPacke
+00007d80: 7454 7970 653e 286e 756d 6578 743a 3a69  tType>(numext::i
+00007d90: 6d61 6728 2a62 2929 3b0a 2020 7d0a 0a20  mag(*b));.  }.. 
+00007da0: 2045 4947 454e 5f53 5452 4f4e 475f 494e   EIGEN_STRONG_IN
+00007db0: 4c49 4e45 2076 6f69 6420 6c6f 6164 5268  LINE void loadRh
+00007dc0: 7328 636f 6e73 7420 5268 7353 6361 6c61  s(const RhsScala
+00007dd0: 722a 2062 2c20 5268 7350 6163 6b65 7478  r* b, RhsPacketx
+00007de0: 3426 2064 6573 7429 2063 6f6e 7374 0a20  4& dest) const. 
+00007df0: 207b 0a20 2020 206c 6f61 6452 6873 2862   {.    loadRhs(b
+00007e00: 2c20 6465 7374 2e42 5f30 293b 0a20 2020  , dest.B_0);.   
+00007e10: 206c 6f61 6452 6873 2862 202b 2031 2c20   loadRhs(b + 1, 
+00007e20: 6465 7374 2e42 3129 3b0a 2020 2020 6c6f  dest.B1);.    lo
+00007e30: 6164 5268 7328 6220 2b20 322c 2064 6573  adRhs(b + 2, des
+00007e40: 742e 4232 293b 0a20 2020 206c 6f61 6452  t.B2);.    loadR
+00007e50: 6873 2862 202b 2033 2c20 6465 7374 2e42  hs(b + 3, dest.B
+00007e60: 3329 3b0a 2020 7d0a 0a20 202f 2f20 5363  3);.  }..  // Sc
+00007e70: 616c 6172 2070 6174 680a 2020 4549 4745  alar path.  EIGE
+00007e80: 4e5f 5354 524f 4e47 5f49 4e4c 494e 4520  N_STRONG_INLINE 
+00007e90: 766f 6964 2075 7064 6174 6552 6873 2863  void updateRhs(c
+00007ea0: 6f6e 7374 2052 6873 5363 616c 6172 2a20  onst RhsScalar* 
+00007eb0: 622c 2053 6361 6c61 7250 6163 6b65 7426  b, ScalarPacket&
+00007ec0: 2064 6573 7429 2063 6f6e 7374 0a20 207b   dest) const.  {
+00007ed0: 0a20 2020 206c 6f61 6452 6873 2862 2c20  .    loadRhs(b, 
+00007ee0: 6465 7374 293b 0a20 207d 0a0a 2020 2f2f  dest);.  }..  //
+00007ef0: 2056 6563 746f 7269 7a65 6420 7061 7468   Vectorized path
+00007f00: 0a20 2074 656d 706c 6174 653c 7479 7065  .  template<type
+00007f10: 6e61 6d65 2052 6561 6c50 6163 6b65 7454  name RealPacketT
+00007f20: 7970 653e 0a20 2045 4947 454e 5f53 5452  ype>.  EIGEN_STR
+00007f30: 4f4e 475f 494e 4c49 4e45 2076 6f69 6420  ONG_INLINE void 
+00007f40: 7570 6461 7465 5268 7328 636f 6e73 7420  updateRhs(const 
+00007f50: 5268 7353 6361 6c61 722a 2062 2c20 446f  RhsScalar* b, Do
+00007f60: 7562 6c65 5061 636b 6574 3c52 6561 6c50  ublePacket<RealP
+00007f70: 6163 6b65 7454 7970 653e 2620 6465 7374  acketType>& dest
+00007f80: 2920 636f 6e73 740a 2020 7b0a 2020 2020  ) const.  {.    
+00007f90: 6c6f 6164 5268 7328 622c 2064 6573 7429  loadRhs(b, dest)
+00007fa0: 3b0a 2020 7d0a 0a20 2045 4947 454e 5f53  ;.  }..  EIGEN_S
+00007fb0: 5452 4f4e 475f 494e 4c49 4e45 2076 6f69  TRONG_INLINE voi
+00007fc0: 6420 7570 6461 7465 5268 7328 636f 6e73  d updateRhs(cons
+00007fd0: 7420 5268 7353 6361 6c61 722a 2c20 5268  t RhsScalar*, Rh
+00007fe0: 7350 6163 6b65 7478 3426 2920 636f 6e73  sPacketx4&) cons
+00007ff0: 7420 7b7d 0a20 200a 2020 4549 4745 4e5f  t {}.  .  EIGEN_
+00008000: 5354 524f 4e47 5f49 4e4c 494e 4520 766f  STRONG_INLINE vo
+00008010: 6964 206c 6f61 6452 6873 5175 6164 2863  id loadRhsQuad(c
+00008020: 6f6e 7374 2052 6873 5363 616c 6172 2a20  onst RhsScalar* 
+00008030: 622c 2052 6573 5061 636b 6574 2620 6465  b, ResPacket& de
+00008040: 7374 2920 636f 6e73 740a 2020 7b0a 2020  st) const.  {.  
+00008050: 2020 6c6f 6164 5268 7328 622c 6465 7374    loadRhs(b,dest
+00008060: 293b 0a20 207d 0a20 2045 4947 454e 5f53  );.  }.  EIGEN_S
+00008070: 5452 4f4e 475f 494e 4c49 4e45 2076 6f69  TRONG_INLINE voi
+00008080: 6420 6c6f 6164 5268 7351 7561 6428 636f  d loadRhsQuad(co
+00008090: 6e73 7420 5268 7353 6361 6c61 722a 2062  nst RhsScalar* b
+000080a0: 2c20 446f 7562 6c65 5061 636b 6574 5479  , DoublePacketTy
+000080b0: 7065 2620 6465 7374 2920 636f 6e73 740a  pe& dest) const.
+000080c0: 2020 7b0a 2020 2020 6c6f 6164 5175 6164    {.    loadQuad
+000080d0: 546f 446f 7562 6c65 5061 636b 6574 2862  ToDoublePacket(b
+000080e0: 2c64 6573 7429 3b0a 2020 7d0a 0a20 202f  ,dest);.  }..  /
+000080f0: 2f20 6e6f 7468 696e 6720 7370 6563 6961  / nothing specia
+00008100: 6c20 6865 7265 0a20 2045 4947 454e 5f53  l here.  EIGEN_S
+00008110: 5452 4f4e 475f 494e 4c49 4e45 2076 6f69  TRONG_INLINE voi
+00008120: 6420 6c6f 6164 4c68 7328 636f 6e73 7420  d loadLhs(const 
+00008130: 4c68 7353 6361 6c61 722a 2061 2c20 4c68  LhsScalar* a, Lh
+00008140: 7350 6163 6b65 7426 2064 6573 7429 2063  sPacket& dest) c
+00008150: 6f6e 7374 0a20 207b 0a20 2020 2064 6573  onst.  {.    des
+00008160: 7420 3d20 706c 6f61 643c 4c68 7350 6163  t = pload<LhsPac
+00008170: 6b65 743e 2828 636f 6e73 7420 7479 7065  ket>((const type
+00008180: 6e61 6d65 2075 6e70 6163 6b65 745f 7472  name unpacket_tr
+00008190: 6169 7473 3c4c 6873 5061 636b 6574 3e3a  aits<LhsPacket>:
+000081a0: 3a74 7970 652a 2928 6129 293b 0a20 207d  :type*)(a));.  }
+000081b0: 0a0a 2020 7465 6d70 6c61 7465 3c74 7970  ..  template<typ
+000081c0: 656e 616d 6520 4c68 7350 6163 6b65 7454  ename LhsPacketT
+000081d0: 7970 653e 0a20 2045 4947 454e 5f53 5452  ype>.  EIGEN_STR
+000081e0: 4f4e 475f 494e 4c49 4e45 2076 6f69 6420  ONG_INLINE void 
+000081f0: 6c6f 6164 4c68 7355 6e61 6c69 676e 6564  loadLhsUnaligned
+00008200: 2863 6f6e 7374 204c 6873 5363 616c 6172  (const LhsScalar
+00008210: 2a20 612c 204c 6873 5061 636b 6574 5479  * a, LhsPacketTy
+00008220: 7065 2620 6465 7374 2920 636f 6e73 740a  pe& dest) const.
+00008230: 2020 7b0a 2020 2020 6465 7374 203d 2070    {.    dest = p
+00008240: 6c6f 6164 753c 4c68 7350 6163 6b65 7454  loadu<LhsPacketT
+00008250: 7970 653e 2828 636f 6e73 7420 7479 7065  ype>((const type
+00008260: 6e61 6d65 2075 6e70 6163 6b65 745f 7472  name unpacket_tr
+00008270: 6169 7473 3c4c 6873 5061 636b 6574 5479  aits<LhsPacketTy
+00008280: 7065 3e3a 3a74 7970 652a 2928 6129 293b  pe>::type*)(a));
+00008290: 0a20 207d 0a0a 2020 7465 6d70 6c61 7465  .  }..  template
+000082a0: 3c74 7970 656e 616d 6520 4c68 7350 6163  <typename LhsPac
+000082b0: 6b65 7454 7970 652c 2074 7970 656e 616d  ketType, typenam
+000082c0: 6520 5268 7350 6163 6b65 7454 7970 652c  e RhsPacketType,
+000082d0: 2074 7970 656e 616d 6520 5265 7350 6163   typename ResPac
+000082e0: 6b65 7454 7970 652c 2074 7970 656e 616d  ketType, typenam
+000082f0: 6520 546d 7054 7970 652c 2074 7970 656e  e TmpType, typen
+00008300: 616d 6520 4c61 6e65 4964 5479 7065 3e0a  ame LaneIdType>.
+00008310: 2020 4549 4745 4e5f 5354 524f 4e47 5f49    EIGEN_STRONG_I
+00008320: 4e4c 494e 450a 2020 7479 7065 6e61 6d65  NLINE.  typename
+00008330: 2065 6e61 626c 655f 6966 3c21 6973 5f73   enable_if<!is_s
+00008340: 616d 653c 5268 7350 6163 6b65 7454 7970  ame<RhsPacketTyp
+00008350: 652c 5268 7350 6163 6b65 7478 343e 3a3a  e,RhsPacketx4>::
+00008360: 7661 6c75 653e 3a3a 7479 7065 0a20 206d  value>::type.  m
+00008370: 6164 6428 636f 6e73 7420 4c68 7350 6163  add(const LhsPac
+00008380: 6b65 7454 7970 6526 2061 2c20 636f 6e73  ketType& a, cons
+00008390: 7420 5268 7350 6163 6b65 7454 7970 6526  t RhsPacketType&
+000083a0: 2062 2c20 446f 7562 6c65 5061 636b 6574   b, DoublePacket
+000083b0: 3c52 6573 5061 636b 6574 5479 7065 3e26  <ResPacketType>&
+000083c0: 2063 2c20 546d 7054 7970 6526 202f 2a74   c, TmpType& /*t
+000083d0: 6d70 2a2f 2c20 636f 6e73 7420 4c61 6e65  mp*/, const Lane
+000083e0: 4964 5479 7065 2629 2063 6f6e 7374 0a20  IdType&) const. 
+000083f0: 207b 0a20 2020 2063 2e66 6972 7374 2020   {.    c.first  
+00008400: 203d 2070 6164 6428 706d 756c 2861 2c62   = padd(pmul(a,b
+00008410: 2e66 6972 7374 292c 2063 2e66 6972 7374  .first), c.first
+00008420: 293b 0a20 2020 2063 2e73 6563 6f6e 6420  );.    c.second 
+00008430: 203d 2070 6164 6428 706d 756c 2861 2c62   = padd(pmul(a,b
+00008440: 2e73 6563 6f6e 6429 2c63 2e73 6563 6f6e  .second),c.secon
+00008450: 6429 3b0a 2020 7d0a 0a20 2074 656d 706c  d);.  }..  templ
+00008460: 6174 653c 7479 7065 6e61 6d65 204c 616e  ate<typename Lan
+00008470: 6549 6454 7970 653e 0a20 2045 4947 454e  eIdType>.  EIGEN
+00008480: 5f53 5452 4f4e 475f 494e 4c49 4e45 2076  _STRONG_INLINE v
+00008490: 6f69 6420 6d61 6464 2863 6f6e 7374 204c  oid madd(const L
+000084a0: 6873 5061 636b 6574 2620 612c 2063 6f6e  hsPacket& a, con
+000084b0: 7374 2052 6873 5061 636b 6574 2620 622c  st RhsPacket& b,
+000084c0: 2052 6573 5061 636b 6574 2620 632c 2052   ResPacket& c, R
+000084d0: 6873 5061 636b 6574 2620 2f2a 746d 702a  hsPacket& /*tmp*
+000084e0: 2f2c 2063 6f6e 7374 204c 616e 6549 6454  /, const LaneIdT
+000084f0: 7970 6526 2920 636f 6e73 740a 2020 7b0a  ype&) const.  {.
+00008500: 2020 2020 6320 3d20 636a 2e70 6d61 6464      c = cj.pmadd
+00008510: 2861 2c62 2c63 293b 0a20 207d 0a0a 2020  (a,b,c);.  }..  
+00008520: 7465 6d70 6c61 7465 3c74 7970 656e 616d  template<typenam
+00008530: 6520 4c68 7350 6163 6b65 7454 7970 652c  e LhsPacketType,
+00008540: 2074 7970 656e 616d 6520 4163 6350 6163   typename AccPac
+00008550: 6b65 7454 7970 652c 2074 7970 656e 616d  ketType, typenam
+00008560: 6520 4c61 6e65 4964 5479 7065 3e0a 2020  e LaneIdType>.  
+00008570: 4549 4745 4e5f 5354 524f 4e47 5f49 4e4c  EIGEN_STRONG_INL
+00008580: 494e 4520 766f 6964 206d 6164 6428 636f  INE void madd(co
+00008590: 6e73 7420 4c68 7350 6163 6b65 7454 7970  nst LhsPacketTyp
+000085a0: 6526 2061 2c20 636f 6e73 7420 5268 7350  e& a, const RhsP
+000085b0: 6163 6b65 7478 3426 2062 2c20 4163 6350  acketx4& b, AccP
+000085c0: 6163 6b65 7454 7970 6526 2063 2c20 5268  acketType& c, Rh
+000085d0: 7350 6163 6b65 7426 2074 6d70 2c20 636f  sPacket& tmp, co
+000085e0: 6e73 7420 4c61 6e65 4964 5479 7065 2620  nst LaneIdType& 
+000085f0: 6c61 6e65 2920 636f 6e73 740a 2020 7b0a  lane) const.  {.
+00008600: 2020 2020 6d61 6464 2861 2c20 622e 6765      madd(a, b.ge
+00008610: 7428 6c61 6e65 292c 2063 2c20 746d 702c  t(lane), c, tmp,
+00008620: 206c 616e 6529 3b0a 2020 7d0a 2020 0a20   lane);.  }.  . 
+00008630: 2045 4947 454e 5f53 5452 4f4e 475f 494e   EIGEN_STRONG_IN
+00008640: 4c49 4e45 2076 6f69 6420 6163 6328 636f  LINE void acc(co
+00008650: 6e73 7420 5363 616c 6172 2620 632c 2063  nst Scalar& c, c
+00008660: 6f6e 7374 2053 6361 6c61 7226 2061 6c70  onst Scalar& alp
+00008670: 6861 2c20 5363 616c 6172 2620 7229 2063  ha, Scalar& r) c
+00008680: 6f6e 7374 207b 2072 202b 3d20 616c 7068  onst { r += alph
+00008690: 6120 2a20 633b 207d 0a20 200a 2020 7465  a * c; }.  .  te
+000086a0: 6d70 6c61 7465 3c74 7970 656e 616d 6520  mplate<typename 
+000086b0: 5265 616c 5061 636b 6574 5479 7065 2c20  RealPacketType, 
+000086c0: 7479 7065 6e61 6d65 2052 6573 5061 636b  typename ResPack
+000086d0: 6574 5479 7065 3e0a 2020 4549 4745 4e5f  etType>.  EIGEN_
+000086e0: 5354 524f 4e47 5f49 4e4c 494e 4520 766f  STRONG_INLINE vo
+000086f0: 6964 2061 6363 2863 6f6e 7374 2044 6f75  id acc(const Dou
+00008700: 626c 6550 6163 6b65 743c 5265 616c 5061  blePacket<RealPa
+00008710: 636b 6574 5479 7065 3e26 2063 2c20 636f  cketType>& c, co
+00008720: 6e73 7420 5265 7350 6163 6b65 7454 7970  nst ResPacketTyp
+00008730: 6526 2061 6c70 6861 2c20 5265 7350 6163  e& alpha, ResPac
+00008740: 6b65 7454 7970 6526 2072 2920 636f 6e73  ketType& r) cons
+00008750: 740a 2020 7b0a 2020 2020 2f2f 2061 7373  t.  {.    // ass
+00008760: 656d 626c 6520 630a 2020 2020 5265 7350  emble c.    ResP
+00008770: 6163 6b65 7454 7970 6520 746d 703b 0a20  acketType tmp;. 
+00008780: 2020 2069 6628 2821 436f 6e6a 4c68 7329     if((!ConjLhs)
+00008790: 2626 2821 436f 6e6a 5268 7329 290a 2020  &&(!ConjRhs)).  
+000087a0: 2020 7b0a 2020 2020 2020 746d 7020 3d20    {.      tmp = 
+000087b0: 7063 706c 7866 6c69 7028 7063 6f6e 6a28  pcplxflip(pconj(
+000087c0: 5265 7350 6163 6b65 7454 7970 6528 632e  ResPacketType(c.
+000087d0: 7365 636f 6e64 2929 293b 0a20 2020 2020  second)));.     
+000087e0: 2074 6d70 203d 2070 6164 6428 5265 7350   tmp = padd(ResP
+000087f0: 6163 6b65 7454 7970 6528 632e 6669 7273  acketType(c.firs
+00008800: 7429 2c74 6d70 293b 0a20 2020 207d 0a20  t),tmp);.    }. 
+00008810: 2020 2065 6c73 6520 6966 2828 2143 6f6e     else if((!Con
+00008820: 6a4c 6873 2926 2628 436f 6e6a 5268 7329  jLhs)&&(ConjRhs)
+00008830: 290a 2020 2020 7b0a 2020 2020 2020 746d  ).    {.      tm
+00008840: 7020 3d20 7063 6f6e 6a28 7063 706c 7866  p = pconj(pcplxf
+00008850: 6c69 7028 5265 7350 6163 6b65 7454 7970  lip(ResPacketTyp
+00008860: 6528 632e 7365 636f 6e64 2929 293b 0a20  e(c.second)));. 
+00008870: 2020 2020 2074 6d70 203d 2070 6164 6428       tmp = padd(
+00008880: 5265 7350 6163 6b65 7454 7970 6528 632e  ResPacketType(c.
+00008890: 6669 7273 7429 2c74 6d70 293b 0a20 2020  first),tmp);.   
+000088a0: 207d 0a20 2020 2065 6c73 6520 6966 2828   }.    else if((
+000088b0: 436f 6e6a 4c68 7329 2626 2821 436f 6e6a  ConjLhs)&&(!Conj
+000088c0: 5268 7329 290a 2020 2020 7b0a 2020 2020  Rhs)).    {.    
+000088d0: 2020 746d 7020 3d20 7063 706c 7866 6c69    tmp = pcplxfli
+000088e0: 7028 5265 7350 6163 6b65 7454 7970 6528  p(ResPacketType(
+000088f0: 632e 7365 636f 6e64 2929 3b0a 2020 2020  c.second));.    
+00008900: 2020 746d 7020 3d20 7061 6464 2870 636f    tmp = padd(pco
+00008910: 6e6a 2852 6573 5061 636b 6574 5479 7065  nj(ResPacketType
+00008920: 2863 2e66 6972 7374 2929 2c74 6d70 293b  (c.first)),tmp);
+00008930: 0a20 2020 207d 0a20 2020 2065 6c73 6520  .    }.    else 
+00008940: 6966 2828 436f 6e6a 4c68 7329 2626 2843  if((ConjLhs)&&(C
+00008950: 6f6e 6a52 6873 2929 0a20 2020 207b 0a20  onjRhs)).    {. 
+00008960: 2020 2020 2074 6d70 203d 2070 6370 6c78       tmp = pcplx
+00008970: 666c 6970 2852 6573 5061 636b 6574 5479  flip(ResPacketTy
+00008980: 7065 2863 2e73 6563 6f6e 6429 293b 0a20  pe(c.second));. 
+00008990: 2020 2020 2074 6d70 203d 2070 7375 6228       tmp = psub(
+000089a0: 7063 6f6e 6a28 5265 7350 6163 6b65 7454  pconj(ResPacketT
+000089b0: 7970 6528 632e 6669 7273 7429 292c 746d  ype(c.first)),tm
+000089c0: 7029 3b0a 2020 2020 7d0a 2020 2020 0a20  p);.    }.    . 
+000089d0: 2020 2072 203d 2070 6d61 6464 2874 6d70     r = pmadd(tmp
+000089e0: 2c61 6c70 6861 2c72 293b 0a20 207d 0a0a  ,alpha,r);.  }..
+000089f0: 7072 6f74 6563 7465 643a 0a20 2063 6f6e  protected:.  con
+00008a00: 6a5f 6865 6c70 6572 3c4c 6873 5363 616c  j_helper<LhsScal
+00008a10: 6172 2c52 6873 5363 616c 6172 2c43 6f6e  ar,RhsScalar,Con
+00008a20: 6a4c 6873 2c43 6f6e 6a52 6873 3e20 636a  jLhs,ConjRhs> cj
+00008a30: 3b0a 7d3b 0a0a 7465 6d70 6c61 7465 3c74  ;.};..template<t
+00008a40: 7970 656e 616d 6520 5265 616c 5363 616c  ypename RealScal
+00008a50: 6172 2c20 626f 6f6c 205f 436f 6e6a 5268  ar, bool _ConjRh
+00008a60: 732c 2069 6e74 2041 7263 682c 2069 6e74  s, int Arch, int
+00008a70: 205f 5061 636b 6574 5369 7a65 3e0a 636c   _PacketSize>.cl
+00008a80: 6173 7320 6765 6270 5f74 7261 6974 733c  ass gebp_traits<
+00008a90: 5265 616c 5363 616c 6172 2c20 7374 643a  RealScalar, std:
+00008aa0: 3a63 6f6d 706c 6578 3c52 6561 6c53 6361  :complex<RealSca
+00008ab0: 6c61 723e 2c20 6661 6c73 652c 205f 436f  lar>, false, _Co
+00008ac0: 6e6a 5268 732c 2041 7263 682c 205f 5061  njRhs, Arch, _Pa
+00008ad0: 636b 6574 5369 7a65 203e 0a7b 0a70 7562  cketSize >.{.pub
+00008ae0: 6c69 633a 0a20 2074 7970 6564 6566 2073  lic:.  typedef s
+00008af0: 7464 3a3a 636f 6d70 6c65 783c 5265 616c  td::complex<Real
+00008b00: 5363 616c 6172 3e20 2053 6361 6c61 723b  Scalar>  Scalar;
+00008b10: 0a20 2074 7970 6564 6566 2052 6561 6c53  .  typedef RealS
+00008b20: 6361 6c61 7220 204c 6873 5363 616c 6172  calar  LhsScalar
+00008b30: 3b0a 2020 7479 7065 6465 6620 5363 616c  ;.  typedef Scal
+00008b40: 6172 2020 2020 2020 5268 7353 6361 6c61  ar      RhsScala
+00008b50: 723b 0a20 2074 7970 6564 6566 2053 6361  r;.  typedef Sca
+00008b60: 6c61 7220 2020 2020 2052 6573 5363 616c  lar      ResScal
+00008b70: 6172 3b0a 0a20 2050 4143 4b45 545f 4445  ar;..  PACKET_DE
+00008b80: 434c 5f43 4f4e 445f 5052 4546 4958 285f  CL_COND_PREFIX(_
+00008b90: 2c20 4c68 732c 205f 5061 636b 6574 5369  , Lhs, _PacketSi
+00008ba0: 7a65 293b 0a20 2050 4143 4b45 545f 4445  ze);.  PACKET_DE
+00008bb0: 434c 5f43 4f4e 445f 5052 4546 4958 285f  CL_COND_PREFIX(_
+00008bc0: 2c20 5268 732c 205f 5061 636b 6574 5369  , Rhs, _PacketSi
+00008bd0: 7a65 293b 0a20 2050 4143 4b45 545f 4445  ze);.  PACKET_DE
+00008be0: 434c 5f43 4f4e 445f 5052 4546 4958 285f  CL_COND_PREFIX(_
+00008bf0: 2c20 5265 732c 205f 5061 636b 6574 5369  , Res, _PacketSi
+00008c00: 7a65 293b 0a20 2050 4143 4b45 545f 4445  ze);.  PACKET_DE
+00008c10: 434c 5f43 4f4e 445f 5052 4546 4958 285f  CL_COND_PREFIX(_
+00008c20: 2c20 5265 616c 2c20 5f50 6163 6b65 7453  , Real, _PacketS
+00008c30: 697a 6529 3b0a 2020 5041 434b 4554 5f44  ize);.  PACKET_D
+00008c40: 4543 4c5f 434f 4e44 5f53 4341 4c41 525f  ECL_COND_SCALAR_
+00008c50: 5052 4546 4958 285f 2c20 5f50 6163 6b65  PREFIX(_, _Packe
+00008c60: 7453 697a 6529 3b0a 0a23 756e 6465 6620  tSize);..#undef 
+00008c70: 5041 434b 4554 5f44 4543 4c5f 434f 4e44  PACKET_DECL_COND
+00008c80: 5f53 4341 4c41 525f 5052 4546 4958 0a23  _SCALAR_PREFIX.#
+00008c90: 756e 6465 6620 5041 434b 4554 5f44 4543  undef PACKET_DEC
+00008ca0: 4c5f 434f 4e44 5f50 5245 4649 580a 2375  L_COND_PREFIX.#u
+00008cb0: 6e64 6566 2050 4143 4b45 545f 4445 434c  ndef PACKET_DECL
+00008cc0: 5f43 4f4e 445f 5343 414c 4152 0a23 756e  _COND_SCALAR.#un
+00008cd0: 6465 6620 5041 434b 4554 5f44 4543 4c5f  def PACKET_DECL_
+00008ce0: 434f 4e44 0a0a 2020 656e 756d 207b 0a20  COND..  enum {. 
+00008cf0: 2020 2043 6f6e 6a4c 6873 203d 2066 616c     ConjLhs = fal
+00008d00: 7365 2c0a 2020 2020 436f 6e6a 5268 7320  se,.    ConjRhs 
+00008d10: 3d20 5f43 6f6e 6a52 6873 2c0a 2020 2020  = _ConjRhs,.    
+00008d20: 5665 6374 6f72 697a 6162 6c65 203d 2075  Vectorizable = u
+00008d30: 6e70 6163 6b65 745f 7472 6169 7473 3c5f  npacket_traits<_
+00008d40: 5265 616c 5061 636b 6574 3e3a 3a76 6563  RealPacket>::vec
+00008d50: 746f 7269 7a61 626c 650a 2020 2020 2020  torizable.      
+00008d60: 2020 2020 2020 2020 2020 2626 2075 6e70            && unp
+00008d70: 6163 6b65 745f 7472 6169 7473 3c5f 5363  acket_traits<_Sc
+00008d80: 616c 6172 5061 636b 6574 3e3a 3a76 6563  alarPacket>::vec
+00008d90: 746f 7269 7a61 626c 652c 0a20 2020 204c  torizable,.    L
+00008da0: 6873 5061 636b 6574 5369 7a65 203d 2056  hsPacketSize = V
+00008db0: 6563 746f 7269 7a61 626c 6520 3f20 756e  ectorizable ? un
+00008dc0: 7061 636b 6574 5f74 7261 6974 733c 5f4c  packet_traits<_L
+00008dd0: 6873 5061 636b 6574 3e3a 3a73 697a 6520  hsPacket>::size 
+00008de0: 3a20 312c 0a20 2020 2052 6873 5061 636b  : 1,.    RhsPack
+00008df0: 6574 5369 7a65 203d 2056 6563 746f 7269  etSize = Vectori
+00008e00: 7a61 626c 6520 3f20 756e 7061 636b 6574  zable ? unpacket
+00008e10: 5f74 7261 6974 733c 5f52 6873 5061 636b  _traits<_RhsPack
+00008e20: 6574 3e3a 3a73 697a 6520 3a20 312c 0a20  et>::size : 1,. 
+00008e30: 2020 2052 6573 5061 636b 6574 5369 7a65     ResPacketSize
+00008e40: 203d 2056 6563 746f 7269 7a61 626c 6520   = Vectorizable 
+00008e50: 3f20 756e 7061 636b 6574 5f74 7261 6974  ? unpacket_trait
+00008e60: 733c 5f52 6573 5061 636b 6574 3e3a 3a73  s<_ResPacket>::s
+00008e70: 697a 6520 3a20 312c 0a20 2020 200a 2020  ize : 1,.    .  
+00008e80: 2020 4e75 6d62 6572 4f66 5265 6769 7374    NumberOfRegist
+00008e90: 6572 7320 3d20 4549 4745 4e5f 4152 4348  ers = EIGEN_ARCH
+00008ea0: 5f44 4546 4155 4c54 5f4e 554d 4245 525f  _DEFAULT_NUMBER_
+00008eb0: 4f46 5f52 4547 4953 5445 5253 2c0a 2020  OF_REGISTERS,.  
+00008ec0: 2020 2f2f 2046 4958 4d45 3a20 7368 6f75    // FIXME: shou
+00008ed0: 6c64 2064 6570 656e 6420 6f6e 204e 756d  ld depend on Num
+00008ee0: 6265 724f 6652 6567 6973 7465 7273 0a20  berOfRegisters. 
+00008ef0: 2020 206e 7220 3d20 342c 0a20 2020 206d     nr = 4,.    m
+00008f00: 7220 3d20 2845 4947 454e 5f50 4c41 494e  r = (EIGEN_PLAIN
+00008f10: 5f45 4e55 4d5f 4d49 4e28 3136 2c4e 756d  _ENUM_MIN(16,Num
+00008f20: 6265 724f 6652 6567 6973 7465 7273 292f  berOfRegisters)/
+00008f30: 322f 6e72 292a 5265 7350 6163 6b65 7453  2/nr)*ResPacketS
+00008f40: 697a 652c 0a0a 2020 2020 4c68 7350 726f  ize,..    LhsPro
+00008f50: 6772 6573 7320 3d20 5265 7350 6163 6b65  gress = ResPacke
+00008f60: 7453 697a 652c 0a20 2020 2052 6873 5072  tSize,.    RhsPr
+00008f70: 6f67 7265 7373 203d 2031 0a20 207d 3b0a  ogress = 1.  };.
+00008f80: 0a20 2074 7970 6564 6566 2074 7970 656e  .  typedef typen
+00008f90: 616d 6520 636f 6e64 6974 696f 6e61 6c3c  ame conditional<
+00008fa0: 5665 6374 6f72 697a 6162 6c65 2c5f 4c68  Vectorizable,_Lh
+00008fb0: 7350 6163 6b65 742c 4c68 7353 6361 6c61  sPacket,LhsScala
+00008fc0: 723e 3a3a 7479 7065 204c 6873 5061 636b  r>::type LhsPack
+00008fd0: 6574 3b0a 2020 7479 7065 6465 6620 7479  et;.  typedef ty
+00008fe0: 7065 6e61 6d65 2063 6f6e 6469 7469 6f6e  pename condition
+00008ff0: 616c 3c56 6563 746f 7269 7a61 626c 652c  al<Vectorizable,
+00009000: 5f52 6873 5061 636b 6574 2c52 6873 5363  _RhsPacket,RhsSc
+00009010: 616c 6172 3e3a 3a74 7970 6520 5268 7350  alar>::type RhsP
+00009020: 6163 6b65 743b 0a20 2074 7970 6564 6566  acket;.  typedef
+00009030: 2074 7970 656e 616d 6520 636f 6e64 6974   typename condit
+00009040: 696f 6e61 6c3c 5665 6374 6f72 697a 6162  ional<Vectorizab
+00009050: 6c65 2c5f 5265 7350 6163 6b65 742c 5265  le,_ResPacket,Re
+00009060: 7353 6361 6c61 723e 3a3a 7479 7065 2052  sScalar>::type R
+00009070: 6573 5061 636b 6574 3b0a 2020 7479 7065  esPacket;.  type
+00009080: 6465 6620 4c68 7350 6163 6b65 7420 4c68  def LhsPacket Lh
+00009090: 7350 6163 6b65 7434 5061 636b 696e 673b  sPacket4Packing;
+000090a0: 0a20 2074 7970 6564 6566 2051 7561 6450  .  typedef QuadP
+000090b0: 6163 6b65 743c 5268 7350 6163 6b65 743e  acket<RhsPacket>
+000090c0: 2052 6873 5061 636b 6574 7834 3b0a 2020   RhsPacketx4;.  
+000090d0: 7479 7065 6465 6620 5265 7350 6163 6b65  typedef ResPacke
+000090e0: 7420 4163 6350 6163 6b65 743b 0a0a 2020  t AccPacket;..  
+000090f0: 4549 4745 4e5f 5354 524f 4e47 5f49 4e4c  EIGEN_STRONG_INL
+00009100: 494e 4520 766f 6964 2069 6e69 7441 6363  INE void initAcc
+00009110: 2841 6363 5061 636b 6574 2620 7029 0a20  (AccPacket& p). 
+00009120: 207b 0a20 2020 2070 203d 2070 7365 7431   {.    p = pset1
+00009130: 3c52 6573 5061 636b 6574 3e28 5265 7353  <ResPacket>(ResS
+00009140: 6361 6c61 7228 3029 293b 0a20 207d 0a0a  calar(0));.  }..
+00009150: 2020 7465 6d70 6c61 7465 3c74 7970 656e    template<typen
+00009160: 616d 6520 5268 7350 6163 6b65 7454 7970  ame RhsPacketTyp
+00009170: 653e 0a20 2045 4947 454e 5f53 5452 4f4e  e>.  EIGEN_STRON
+00009180: 475f 494e 4c49 4e45 2076 6f69 6420 6c6f  G_INLINE void lo
+00009190: 6164 5268 7328 636f 6e73 7420 5268 7353  adRhs(const RhsS
+000091a0: 6361 6c61 722a 2062 2c20 5268 7350 6163  calar* b, RhsPac
+000091b0: 6b65 7454 7970 6526 2064 6573 7429 2063  ketType& dest) c
+000091c0: 6f6e 7374 0a20 207b 0a20 2020 2064 6573  onst.  {.    des
+000091d0: 7420 3d20 7073 6574 313c 5268 7350 6163  t = pset1<RhsPac
+000091e0: 6b65 7454 7970 653e 282a 6229 3b0a 2020  ketType>(*b);.  
+000091f0: 7d0a 0a20 2045 4947 454e 5f53 5452 4f4e  }..  EIGEN_STRON
+00009200: 475f 494e 4c49 4e45 2076 6f69 6420 6c6f  G_INLINE void lo
+00009210: 6164 5268 7328 636f 6e73 7420 5268 7353  adRhs(const RhsS
+00009220: 6361 6c61 722a 2062 2c20 5268 7350 6163  calar* b, RhsPac
+00009230: 6b65 7478 3426 2064 6573 7429 2063 6f6e  ketx4& dest) con
+00009240: 7374 0a20 207b 0a20 2020 2070 6272 6f61  st.  {.    pbroa
+00009250: 6463 6173 7434 2862 2c20 6465 7374 2e42  dcast4(b, dest.B
+00009260: 5f30 2c20 6465 7374 2e42 312c 2064 6573  _0, dest.B1, des
+00009270: 742e 4232 2c20 6465 7374 2e42 3329 3b0a  t.B2, dest.B3);.
+00009280: 2020 7d0a 0a20 2074 656d 706c 6174 653c    }..  template<
+00009290: 7479 7065 6e61 6d65 2052 6873 5061 636b  typename RhsPack
+000092a0: 6574 5479 7065 3e0a 2020 4549 4745 4e5f  etType>.  EIGEN_
+000092b0: 5354 524f 4e47 5f49 4e4c 494e 4520 766f  STRONG_INLINE vo
+000092c0: 6964 2075 7064 6174 6552 6873 2863 6f6e  id updateRhs(con
+000092d0: 7374 2052 6873 5363 616c 6172 2a20 622c  st RhsScalar* b,
+000092e0: 2052 6873 5061 636b 6574 5479 7065 2620   RhsPacketType& 
+000092f0: 6465 7374 2920 636f 6e73 740a 2020 7b0a  dest) const.  {.
+00009300: 2020 2020 6c6f 6164 5268 7328 622c 2064      loadRhs(b, d
+00009310: 6573 7429 3b0a 2020 7d0a 0a20 2045 4947  est);.  }..  EIG
+00009320: 454e 5f53 5452 4f4e 475f 494e 4c49 4e45  EN_STRONG_INLINE
+00009330: 2076 6f69 6420 7570 6461 7465 5268 7328   void updateRhs(
+00009340: 636f 6e73 7420 5268 7353 6361 6c61 722a  const RhsScalar*
+00009350: 2c20 5268 7350 6163 6b65 7478 3426 2920  , RhsPacketx4&) 
+00009360: 636f 6e73 740a 2020 7b7d 0a0a 2020 4549  const.  {}..  EI
+00009370: 4745 4e5f 5354 524f 4e47 5f49 4e4c 494e  GEN_STRONG_INLIN
+00009380: 4520 766f 6964 206c 6f61 644c 6873 2863  E void loadLhs(c
+00009390: 6f6e 7374 204c 6873 5363 616c 6172 2a20  onst LhsScalar* 
+000093a0: 612c 204c 6873 5061 636b 6574 2620 6465  a, LhsPacket& de
+000093b0: 7374 2920 636f 6e73 740a 2020 7b0a 2020  st) const.  {.  
+000093c0: 2020 6465 7374 203d 2070 6c6f 6164 6475    dest = ploaddu
+000093d0: 703c 4c68 7350 6163 6b65 743e 2861 293b  p<LhsPacket>(a);
+000093e0: 0a20 207d 0a20 200a 2020 4549 4745 4e5f  .  }.  .  EIGEN_
+000093f0: 5354 524f 4e47 5f49 4e4c 494e 4520 766f  STRONG_INLINE vo
+00009400: 6964 206c 6f61 6452 6873 5175 6164 2863  id loadRhsQuad(c
+00009410: 6f6e 7374 2052 6873 5363 616c 6172 2a20  onst RhsScalar* 
+00009420: 622c 2052 6873 5061 636b 6574 2620 6465  b, RhsPacket& de
+00009430: 7374 2920 636f 6e73 740a 2020 7b0a 2020  st) const.  {.  
+00009440: 2020 6465 7374 203d 2070 6c6f 6164 7175    dest = ploadqu
+00009450: 6164 3c52 6873 5061 636b 6574 3e28 6229  ad<RhsPacket>(b)
+00009460: 3b0a 2020 7d0a 0a20 2074 656d 706c 6174  ;.  }..  templat
+00009470: 653c 7479 7065 6e61 6d65 204c 6873 5061  e<typename LhsPa
+00009480: 636b 6574 5479 7065 3e0a 2020 4549 4745  cketType>.  EIGE
+00009490: 4e5f 5354 524f 4e47 5f49 4e4c 494e 4520  N_STRONG_INLINE 
+000094a0: 766f 6964 206c 6f61 644c 6873 556e 616c  void loadLhsUnal
+000094b0: 6967 6e65 6428 636f 6e73 7420 4c68 7353  igned(const LhsS
+000094c0: 6361 6c61 722a 2061 2c20 4c68 7350 6163  calar* a, LhsPac
+000094d0: 6b65 7454 7970 6526 2064 6573 7429 2063  ketType& dest) c
+000094e0: 6f6e 7374 0a20 207b 0a20 2020 2064 6573  onst.  {.    des
+000094f0: 7420 3d20 706c 6f61 6464 7570 3c4c 6873  t = ploaddup<Lhs
+00009500: 5061 636b 6574 5479 7065 3e28 6129 3b0a  PacketType>(a);.
+00009510: 2020 7d0a 0a20 2074 656d 706c 6174 6520    }..  template 
+00009520: 3c74 7970 656e 616d 6520 4c68 7350 6163  <typename LhsPac
+00009530: 6b65 7454 7970 652c 2074 7970 656e 616d  ketType, typenam
+00009540: 6520 5268 7350 6163 6b65 7454 7970 652c  e RhsPacketType,
+00009550: 2074 7970 656e 616d 6520 4163 6350 6163   typename AccPac
+00009560: 6b65 7454 7970 652c 2074 7970 656e 616d  ketType, typenam
+00009570: 6520 4c61 6e65 4964 5479 7065 3e0a 2020  e LaneIdType>.  
+00009580: 4549 4745 4e5f 5354 524f 4e47 5f49 4e4c  EIGEN_STRONG_INL
+00009590: 494e 4520 766f 6964 206d 6164 6428 636f  INE void madd(co
+000095a0: 6e73 7420 4c68 7350 6163 6b65 7454 7970  nst LhsPacketTyp
+000095b0: 6526 2061 2c20 636f 6e73 7420 5268 7350  e& a, const RhsP
+000095c0: 6163 6b65 7454 7970 6526 2062 2c20 4163  acketType& b, Ac
+000095d0: 6350 6163 6b65 7454 7970 6526 2063 2c20  cPacketType& c, 
+000095e0: 5268 7350 6163 6b65 7454 7970 6526 2074  RhsPacketType& t
+000095f0: 6d70 2c20 636f 6e73 7420 4c61 6e65 4964  mp, const LaneId
+00009600: 5479 7065 2629 2063 6f6e 7374 0a20 207b  Type&) const.  {
+00009610: 0a20 2020 206d 6164 645f 696d 706c 2861  .    madd_impl(a
+00009620: 2c20 622c 2063 2c20 746d 702c 2074 7970  , b, c, tmp, typ
+00009630: 656e 616d 6520 636f 6e64 6974 696f 6e61  ename conditiona
+00009640: 6c3c 5665 6374 6f72 697a 6162 6c65 2c74  l<Vectorizable,t
+00009650: 7275 655f 7479 7065 2c66 616c 7365 5f74  rue_type,false_t
+00009660: 7970 653e 3a3a 7479 7065 2829 293b 0a20  ype>::type());. 
+00009670: 207d 0a0a 2020 7465 6d70 6c61 7465 203c   }..  template <
+00009680: 7479 7065 6e61 6d65 204c 6873 5061 636b  typename LhsPack
+00009690: 6574 5479 7065 2c20 7479 7065 6e61 6d65  etType, typename
+000096a0: 2052 6873 5061 636b 6574 5479 7065 2c20   RhsPacketType, 
+000096b0: 7479 7065 6e61 6d65 2041 6363 5061 636b  typename AccPack
+000096c0: 6574 5479 7065 3e0a 2020 4549 4745 4e5f  etType>.  EIGEN_
+000096d0: 5354 524f 4e47 5f49 4e4c 494e 4520 766f  STRONG_INLINE vo
+000096e0: 6964 206d 6164 645f 696d 706c 2863 6f6e  id madd_impl(con
+000096f0: 7374 204c 6873 5061 636b 6574 5479 7065  st LhsPacketType
+00009700: 2620 612c 2063 6f6e 7374 2052 6873 5061  & a, const RhsPa
+00009710: 636b 6574 5479 7065 2620 622c 2041 6363  cketType& b, Acc
+00009720: 5061 636b 6574 5479 7065 2620 632c 2052  PacketType& c, R
+00009730: 6873 5061 636b 6574 5479 7065 2620 746d  hsPacketType& tm
+00009740: 702c 2063 6f6e 7374 2074 7275 655f 7479  p, const true_ty
+00009750: 7065 2629 2063 6f6e 7374 0a20 207b 0a23  pe&) const.  {.#
+00009760: 6966 6465 6620 4549 4745 4e5f 4841 535f  ifdef EIGEN_HAS_
+00009770: 5349 4e47 4c45 5f49 4e53 5452 5543 5449  SINGLE_INSTRUCTI
+00009780: 4f4e 5f4d 4144 440a 2020 2020 4549 4745  ON_MADD.    EIGE
+00009790: 4e5f 554e 5553 4544 5f56 4152 4941 424c  N_UNUSED_VARIABL
+000097a0: 4528 746d 7029 3b0a 2020 2020 632e 7620  E(tmp);.    c.v 
+000097b0: 3d20 706d 6164 6428 612c 622e 762c 632e  = pmadd(a,b.v,c.
+000097c0: 7629 3b0a 2365 6c73 650a 2020 2020 746d  v);.#else.    tm
+000097d0: 7020 3d20 623b 2074 6d70 2e76 203d 2070  p = b; tmp.v = p
+000097e0: 6d75 6c28 612c 746d 702e 7629 3b20 6320  mul(a,tmp.v); c 
+000097f0: 3d20 7061 6464 2863 2c74 6d70 293b 0a23  = padd(c,tmp);.#
+00009800: 656e 6469 660a 2020 2020 0a20 207d 0a0a  endif.    .  }..
+00009810: 2020 4549 4745 4e5f 5354 524f 4e47 5f49    EIGEN_STRONG_I
+00009820: 4e4c 494e 4520 766f 6964 206d 6164 645f  NLINE void madd_
+00009830: 696d 706c 2863 6f6e 7374 204c 6873 5363  impl(const LhsSc
+00009840: 616c 6172 2620 612c 2063 6f6e 7374 2052  alar& a, const R
+00009850: 6873 5363 616c 6172 2620 622c 2052 6573  hsScalar& b, Res
+00009860: 5363 616c 6172 2620 632c 2052 6873 5363  Scalar& c, RhsSc
+00009870: 616c 6172 2620 2f2a 746d 702a 2f2c 2063  alar& /*tmp*/, c
+00009880: 6f6e 7374 2066 616c 7365 5f74 7970 6526  onst false_type&
+00009890: 2920 636f 6e73 740a 2020 7b0a 2020 2020  ) const.  {.    
+000098a0: 6320 2b3d 2061 202a 2062 3b0a 2020 7d0a  c += a * b;.  }.
+000098b0: 0a20 2074 656d 706c 6174 653c 7479 7065  .  template<type
+000098c0: 6e61 6d65 204c 6873 5061 636b 6574 5479  name LhsPacketTy
+000098d0: 7065 2c20 7479 7065 6e61 6d65 2041 6363  pe, typename Acc
+000098e0: 5061 636b 6574 5479 7065 2c20 7479 7065  PacketType, type
+000098f0: 6e61 6d65 204c 616e 6549 6454 7970 653e  name LaneIdType>
+00009900: 0a20 2045 4947 454e 5f53 5452 4f4e 475f  .  EIGEN_STRONG_
+00009910: 494e 4c49 4e45 2076 6f69 6420 6d61 6464  INLINE void madd
+00009920: 2863 6f6e 7374 204c 6873 5061 636b 6574  (const LhsPacket
+00009930: 5479 7065 2620 612c 2063 6f6e 7374 2052  Type& a, const R
+00009940: 6873 5061 636b 6574 7834 2620 622c 2041  hsPacketx4& b, A
+00009950: 6363 5061 636b 6574 5479 7065 2620 632c  ccPacketType& c,
+00009960: 2052 6873 5061 636b 6574 2620 746d 702c   RhsPacket& tmp,
+00009970: 2063 6f6e 7374 204c 616e 6549 6454 7970   const LaneIdTyp
+00009980: 6526 206c 616e 6529 2063 6f6e 7374 0a20  e& lane) const. 
+00009990: 207b 0a20 2020 206d 6164 6428 612c 2062   {.    madd(a, b
+000099a0: 2e67 6574 286c 616e 6529 2c20 632c 2074  .get(lane), c, t
+000099b0: 6d70 2c20 6c61 6e65 293b 0a20 207d 0a0a  mp, lane);.  }..
+000099c0: 2020 7465 6d70 6c61 7465 203c 7479 7065    template <type
+000099d0: 6e61 6d65 2052 6573 5061 636b 6574 5479  name ResPacketTy
+000099e0: 7065 2c20 7479 7065 6e61 6d65 2041 6363  pe, typename Acc
+000099f0: 5061 636b 6574 5479 7065 3e0a 2020 4549  PacketType>.  EI
+00009a00: 4745 4e5f 5354 524f 4e47 5f49 4e4c 494e  GEN_STRONG_INLIN
+00009a10: 4520 766f 6964 2061 6363 2863 6f6e 7374  E void acc(const
+00009a20: 2041 6363 5061 636b 6574 5479 7065 2620   AccPacketType& 
+00009a30: 632c 2063 6f6e 7374 2052 6573 5061 636b  c, const ResPack
+00009a40: 6574 5479 7065 2620 616c 7068 612c 2052  etType& alpha, R
+00009a50: 6573 5061 636b 6574 5479 7065 2620 7229  esPacketType& r)
+00009a60: 2063 6f6e 7374 0a20 207b 0a20 2020 2063   const.  {.    c
+00009a70: 6f6e 6a5f 6865 6c70 6572 3c52 6573 5061  onj_helper<ResPa
+00009a80: 636b 6574 5479 7065 2c52 6573 5061 636b  cketType,ResPack
+00009a90: 6574 5479 7065 2c66 616c 7365 2c43 6f6e  etType,false,Con
+00009aa0: 6a52 6873 3e20 636a 3b0a 2020 2020 7220  jRhs> cj;.    r 
+00009ab0: 3d20 636a 2e70 6d61 6464 2861 6c70 6861  = cj.pmadd(alpha
+00009ac0: 2c63 2c72 293b 0a20 207d 0a0a 7072 6f74  ,c,r);.  }..prot
+00009ad0: 6563 7465 643a 0a0a 7d3b 0a0a 2f2a 206f  ected:..};../* o
+00009ae0: 7074 696d 697a 6564 2047 656e 6572 616c  ptimized General
+00009af0: 2070 6163 6b65 6420 426c 6f63 6b20 2a20   packed Block * 
+00009b00: 7061 636b 6564 2050 616e 656c 2070 726f  packed Panel pro
+00009b10: 6475 6374 206b 6572 6e65 6c0a 202a 0a20  duct kernel. *. 
+00009b20: 2a20 4d69 7869 6e67 2074 7970 6520 6c6f  * Mixing type lo
+00009b30: 6769 633a 2043 202b 3d20 4120 2a20 420a  gic: C += A * B.
+00009b40: 202a 2020 7c20 2041 2020 7c20 2042 2020   *  |  A  |  B  
+00009b50: 7c20 636f 6d6d 656e 7473 0a20 2a20 207c  | comments. *  |
+00009b60: 7265 616c 207c 6370 6c78 207c 206e 6f20  real |cplx | no 
+00009b70: 7665 6374 6f72 697a 6174 696f 6e20 7965  vectorization ye
+00009b80: 742c 2077 6f75 6c64 2072 6571 7569 7265  t, would require
+00009b90: 2074 6f20 7061 636b 2041 2077 6974 6820   to pack A with 
+00009ba0: 6475 706c 6963 6174 696f 6e0a 202a 2020  duplication. *  
+00009bb0: 7c63 706c 7820 7c72 6561 6c20 7c20 6561  |cplx |real | ea
+00009bc0: 7379 2076 6563 746f 7269 7a61 7469 6f6e  sy vectorization
+00009bd0: 0a20 2a2f 0a74 656d 706c 6174 653c 7479  . */.template<ty
+00009be0: 7065 6e61 6d65 204c 6873 5363 616c 6172  pename LhsScalar
+00009bf0: 2c20 7479 7065 6e61 6d65 2052 6873 5363  , typename RhsSc
+00009c00: 616c 6172 2c20 7479 7065 6e61 6d65 2049  alar, typename I
+00009c10: 6e64 6578 2c20 7479 7065 6e61 6d65 2044  ndex, typename D
+00009c20: 6174 614d 6170 7065 722c 2069 6e74 206d  ataMapper, int m
+00009c30: 722c 2069 6e74 206e 722c 2062 6f6f 6c20  r, int nr, bool 
+00009c40: 436f 6e6a 7567 6174 654c 6873 2c20 626f  ConjugateLhs, bo
+00009c50: 6f6c 2043 6f6e 6a75 6761 7465 5268 733e  ol ConjugateRhs>
+00009c60: 0a73 7472 7563 7420 6765 6270 5f6b 6572  .struct gebp_ker
+00009c70: 6e65 6c0a 7b0a 2020 7479 7065 6465 6620  nel.{.  typedef 
+00009c80: 6765 6270 5f74 7261 6974 733c 4c68 7353  gebp_traits<LhsS
+00009c90: 6361 6c61 722c 5268 7353 6361 6c61 722c  calar,RhsScalar,
+00009ca0: 436f 6e6a 7567 6174 654c 6873 2c43 6f6e  ConjugateLhs,Con
+00009cb0: 6a75 6761 7465 5268 732c 4172 6368 6974  jugateRhs,Archit
+00009cc0: 6563 7475 7265 3a3a 5461 7267 6574 3e20  ecture::Target> 
+00009cd0: 5472 6169 7473 3b0a 2020 7479 7065 6465  Traits;.  typede
+00009ce0: 6620 6765 6270 5f74 7261 6974 733c 4c68  f gebp_traits<Lh
+00009cf0: 7353 6361 6c61 722c 5268 7353 6361 6c61  sScalar,RhsScala
+00009d00: 722c 436f 6e6a 7567 6174 654c 6873 2c43  r,ConjugateLhs,C
+00009d10: 6f6e 6a75 6761 7465 5268 732c 4172 6368  onjugateRhs,Arch
+00009d20: 6974 6563 7475 7265 3a3a 5461 7267 6574  itecture::Target
+00009d30: 2c47 4542 5050 6163 6b65 7448 616c 663e  ,GEBPPacketHalf>
+00009d40: 2048 616c 6654 7261 6974 733b 0a20 2074   HalfTraits;.  t
+00009d50: 7970 6564 6566 2067 6562 705f 7472 6169  ypedef gebp_trai
+00009d60: 7473 3c4c 6873 5363 616c 6172 2c52 6873  ts<LhsScalar,Rhs
+00009d70: 5363 616c 6172 2c43 6f6e 6a75 6761 7465  Scalar,Conjugate
+00009d80: 4c68 732c 436f 6e6a 7567 6174 6552 6873  Lhs,ConjugateRhs
+00009d90: 2c41 7263 6869 7465 6374 7572 653a 3a54  ,Architecture::T
+00009da0: 6172 6765 742c 4745 4250 5061 636b 6574  arget,GEBPPacket
+00009db0: 5175 6172 7465 723e 2051 7561 7274 6572  Quarter> Quarter
+00009dc0: 5472 6169 7473 3b0a 2020 0a20 2074 7970  Traits;.  .  typ
+00009dd0: 6564 6566 2074 7970 656e 616d 6520 5472  edef typename Tr
+00009de0: 6169 7473 3a3a 5265 7353 6361 6c61 7220  aits::ResScalar 
+00009df0: 5265 7353 6361 6c61 723b 0a20 2074 7970  ResScalar;.  typ
+00009e00: 6564 6566 2074 7970 656e 616d 6520 5472  edef typename Tr
+00009e10: 6169 7473 3a3a 4c68 7350 6163 6b65 7420  aits::LhsPacket 
+00009e20: 4c68 7350 6163 6b65 743b 0a20 2074 7970  LhsPacket;.  typ
+00009e30: 6564 6566 2074 7970 656e 616d 6520 5472  edef typename Tr
+00009e40: 6169 7473 3a3a 5268 7350 6163 6b65 7420  aits::RhsPacket 
+00009e50: 5268 7350 6163 6b65 743b 0a20 2074 7970  RhsPacket;.  typ
+00009e60: 6564 6566 2074 7970 656e 616d 6520 5472  edef typename Tr
+00009e70: 6169 7473 3a3a 5265 7350 6163 6b65 7420  aits::ResPacket 
+00009e80: 5265 7350 6163 6b65 743b 0a20 2074 7970  ResPacket;.  typ
+00009e90: 6564 6566 2074 7970 656e 616d 6520 5472  edef typename Tr
+00009ea0: 6169 7473 3a3a 4163 6350 6163 6b65 7420  aits::AccPacket 
+00009eb0: 4163 6350 6163 6b65 743b 0a20 2074 7970  AccPacket;.  typ
+00009ec0: 6564 6566 2074 7970 656e 616d 6520 5472  edef typename Tr
+00009ed0: 6169 7473 3a3a 5268 7350 6163 6b65 7478  aits::RhsPacketx
+00009ee0: 3420 5268 7350 6163 6b65 7478 343b 0a0a  4 RhsPacketx4;..
+00009ef0: 2020 7479 7065 6465 6620 7479 7065 6e61    typedef typena
+00009f00: 6d65 2052 6873 5061 6e65 6c48 656c 7065  me RhsPanelHelpe
+00009f10: 723c 5268 7350 6163 6b65 742c 2052 6873  r<RhsPacket, Rhs
+00009f20: 5061 636b 6574 7834 2c20 3135 3e3a 3a74  Packetx4, 15>::t
+00009f30: 7970 6520 5268 7350 616e 656c 3135 3b0a  ype RhsPanel15;.
+00009f40: 0a20 2074 7970 6564 6566 2067 6562 705f  .  typedef gebp_
+00009f50: 7472 6169 7473 3c52 6873 5363 616c 6172  traits<RhsScalar
+00009f60: 2c4c 6873 5363 616c 6172 2c43 6f6e 6a75  ,LhsScalar,Conju
+00009f70: 6761 7465 5268 732c 436f 6e6a 7567 6174  gateRhs,Conjugat
+00009f80: 654c 6873 2c41 7263 6869 7465 6374 7572  eLhs,Architectur
+00009f90: 653a 3a54 6172 6765 743e 2053 7761 7070  e::Target> Swapp
+00009fa0: 6564 5472 6169 7473 3b0a 0a20 2074 7970  edTraits;..  typ
+00009fb0: 6564 6566 2074 7970 656e 616d 6520 5377  edef typename Sw
+00009fc0: 6170 7065 6454 7261 6974 733a 3a52 6573  appedTraits::Res
+00009fd0: 5363 616c 6172 2053 5265 7353 6361 6c61  Scalar SResScala
+00009fe0: 723b 0a20 2074 7970 6564 6566 2074 7970  r;.  typedef typ
+00009ff0: 656e 616d 6520 5377 6170 7065 6454 7261  ename SwappedTra
+0000a000: 6974 733a 3a4c 6873 5061 636b 6574 2053  its::LhsPacket S
+0000a010: 4c68 7350 6163 6b65 743b 0a20 2074 7970  LhsPacket;.  typ
+0000a020: 6564 6566 2074 7970 656e 616d 6520 5377  edef typename Sw
+0000a030: 6170 7065 6454 7261 6974 733a 3a52 6873  appedTraits::Rhs
+0000a040: 5061 636b 6574 2053 5268 7350 6163 6b65  Packet SRhsPacke
+0000a050: 743b 0a20 2074 7970 6564 6566 2074 7970  t;.  typedef typ
+0000a060: 656e 616d 6520 5377 6170 7065 6454 7261  ename SwappedTra
+0000a070: 6974 733a 3a52 6573 5061 636b 6574 2053  its::ResPacket S
+0000a080: 5265 7350 6163 6b65 743b 0a20 2074 7970  ResPacket;.  typ
+0000a090: 6564 6566 2074 7970 656e 616d 6520 5377  edef typename Sw
+0000a0a0: 6170 7065 6454 7261 6974 733a 3a41 6363  appedTraits::Acc
+0000a0b0: 5061 636b 6574 2053 4163 6350 6163 6b65  Packet SAccPacke
+0000a0c0: 743b 0a0a 2020 7479 7065 6465 6620 7479  t;..  typedef ty
+0000a0d0: 7065 6e61 6d65 2048 616c 6654 7261 6974  pename HalfTrait
+0000a0e0: 733a 3a4c 6873 5061 636b 6574 204c 6873  s::LhsPacket Lhs
+0000a0f0: 5061 636b 6574 4861 6c66 3b0a 2020 7479  PacketHalf;.  ty
+0000a100: 7065 6465 6620 7479 7065 6e61 6d65 2048  pedef typename H
+0000a110: 616c 6654 7261 6974 733a 3a52 6873 5061  alfTraits::RhsPa
+0000a120: 636b 6574 2052 6873 5061 636b 6574 4861  cket RhsPacketHa
+0000a130: 6c66 3b0a 2020 7479 7065 6465 6620 7479  lf;.  typedef ty
+0000a140: 7065 6e61 6d65 2048 616c 6654 7261 6974  pename HalfTrait
+0000a150: 733a 3a52 6573 5061 636b 6574 2052 6573  s::ResPacket Res
+0000a160: 5061 636b 6574 4861 6c66 3b0a 2020 7479  PacketHalf;.  ty
+0000a170: 7065 6465 6620 7479 7065 6e61 6d65 2048  pedef typename H
+0000a180: 616c 6654 7261 6974 733a 3a41 6363 5061  alfTraits::AccPa
+0000a190: 636b 6574 2041 6363 5061 636b 6574 4861  cket AccPacketHa
+0000a1a0: 6c66 3b0a 0a20 2074 7970 6564 6566 2074  lf;..  typedef t
+0000a1b0: 7970 656e 616d 6520 5175 6172 7465 7254  ypename QuarterT
+0000a1c0: 7261 6974 733a 3a4c 6873 5061 636b 6574  raits::LhsPacket
+0000a1d0: 204c 6873 5061 636b 6574 5175 6172 7465   LhsPacketQuarte
+0000a1e0: 723b 0a20 2074 7970 6564 6566 2074 7970  r;.  typedef typ
+0000a1f0: 656e 616d 6520 5175 6172 7465 7254 7261  ename QuarterTra
+0000a200: 6974 733a 3a52 6873 5061 636b 6574 2052  its::RhsPacket R
+0000a210: 6873 5061 636b 6574 5175 6172 7465 723b  hsPacketQuarter;
+0000a220: 0a20 2074 7970 6564 6566 2074 7970 656e  .  typedef typen
+0000a230: 616d 6520 5175 6172 7465 7254 7261 6974  ame QuarterTrait
+0000a240: 733a 3a52 6573 5061 636b 6574 2052 6573  s::ResPacket Res
+0000a250: 5061 636b 6574 5175 6172 7465 723b 0a20  PacketQuarter;. 
+0000a260: 2074 7970 6564 6566 2074 7970 656e 616d   typedef typenam
+0000a270: 6520 5175 6172 7465 7254 7261 6974 733a  e QuarterTraits:
+0000a280: 3a41 6363 5061 636b 6574 2041 6363 5061  :AccPacket AccPa
+0000a290: 636b 6574 5175 6172 7465 723b 0a0a 2020  cketQuarter;..  
+0000a2a0: 7479 7065 6465 6620 7479 7065 6e61 6d65  typedef typename
+0000a2b0: 2044 6174 614d 6170 7065 723a 3a4c 696e   DataMapper::Lin
+0000a2c0: 6561 724d 6170 7065 7220 4c69 6e65 6172  earMapper Linear
+0000a2d0: 4d61 7070 6572 3b0a 0a20 2065 6e75 6d20  Mapper;..  enum 
+0000a2e0: 7b0a 2020 2020 5665 6374 6f72 697a 6162  {.    Vectorizab
+0000a2f0: 6c65 2020 3d20 5472 6169 7473 3a3a 5665  le  = Traits::Ve
+0000a300: 6374 6f72 697a 6162 6c65 2c0a 2020 2020  ctorizable,.    
+0000a310: 4c68 7350 726f 6772 6573 7320 2020 3d20  LhsProgress   = 
+0000a320: 5472 6169 7473 3a3a 4c68 7350 726f 6772  Traits::LhsProgr
+0000a330: 6573 732c 0a20 2020 204c 6873 5072 6f67  ess,.    LhsProg
+0000a340: 7265 7373 4861 6c66 2020 2020 2020 3d20  ressHalf      = 
+0000a350: 4861 6c66 5472 6169 7473 3a3a 4c68 7350  HalfTraits::LhsP
+0000a360: 726f 6772 6573 732c 0a20 2020 204c 6873  rogress,.    Lhs
+0000a370: 5072 6f67 7265 7373 5175 6172 7465 7220  ProgressQuarter 
+0000a380: 2020 3d20 5175 6172 7465 7254 7261 6974    = QuarterTrait
+0000a390: 733a 3a4c 6873 5072 6f67 7265 7373 2c0a  s::LhsProgress,.
+0000a3a0: 2020 2020 5268 7350 726f 6772 6573 7320      RhsProgress 
+0000a3b0: 2020 3d20 5472 6169 7473 3a3a 5268 7350    = Traits::RhsP
+0000a3c0: 726f 6772 6573 732c 0a20 2020 2052 6873  rogress,.    Rhs
+0000a3d0: 5072 6f67 7265 7373 4861 6c66 2020 2020  ProgressHalf    
+0000a3e0: 2020 3d20 4861 6c66 5472 6169 7473 3a3a    = HalfTraits::
+0000a3f0: 5268 7350 726f 6772 6573 732c 0a20 2020  RhsProgress,.   
+0000a400: 2052 6873 5072 6f67 7265 7373 5175 6172   RhsProgressQuar
+0000a410: 7465 7220 2020 3d20 5175 6172 7465 7254  ter   = QuarterT
+0000a420: 7261 6974 733a 3a52 6873 5072 6f67 7265  raits::RhsProgre
+0000a430: 7373 2c0a 2020 2020 5265 7350 6163 6b65  ss,.    ResPacke
+0000a440: 7453 697a 6520 3d20 5472 6169 7473 3a3a  tSize = Traits::
+0000a450: 5265 7350 6163 6b65 7453 697a 650a 2020  ResPacketSize.  
+0000a460: 7d3b 0a0a 2020 4549 4745 4e5f 444f 4e54  };..  EIGEN_DONT
+0000a470: 5f49 4e4c 494e 450a 2020 766f 6964 206f  _INLINE.  void o
+0000a480: 7065 7261 746f 7228 2928 636f 6e73 7420  perator()(const 
+0000a490: 4461 7461 4d61 7070 6572 2620 7265 732c  DataMapper& res,
+0000a4a0: 2063 6f6e 7374 204c 6873 5363 616c 6172   const LhsScalar
+0000a4b0: 2a20 626c 6f63 6b41 2c20 636f 6e73 7420  * blockA, const 
+0000a4c0: 5268 7353 6361 6c61 722a 2062 6c6f 636b  RhsScalar* block
+0000a4d0: 422c 0a20 2020 2020 2020 2020 2020 2020  B,.             
+0000a4e0: 2020 2020 2049 6e64 6578 2072 6f77 732c       Index rows,
+0000a4f0: 2049 6e64 6578 2064 6570 7468 2c20 496e   Index depth, In
+0000a500: 6465 7820 636f 6c73 2c20 5265 7353 6361  dex cols, ResSca
+0000a510: 6c61 7220 616c 7068 612c 0a20 2020 2020  lar alpha,.     
+0000a520: 2020 2020 2020 2020 2020 2020 2049 6e64               Ind
+0000a530: 6578 2073 7472 6964 6541 3d2d 312c 2049  ex strideA=-1, I
+0000a540: 6e64 6578 2073 7472 6964 6542 3d2d 312c  ndex strideB=-1,
+0000a550: 2049 6e64 6578 206f 6666 7365 7441 3d30   Index offsetA=0
+0000a560: 2c20 496e 6465 7820 6f66 6673 6574 423d  , Index offsetB=
+0000a570: 3029 3b0a 7d3b 0a0a 7465 6d70 6c61 7465  0);.};..template
+0000a580: 3c74 7970 656e 616d 6520 4c68 7353 6361  <typename LhsSca
+0000a590: 6c61 722c 2074 7970 656e 616d 6520 5268  lar, typename Rh
+0000a5a0: 7353 6361 6c61 722c 2074 7970 656e 616d  sScalar, typenam
+0000a5b0: 6520 496e 6465 782c 2074 7970 656e 616d  e Index, typenam
+0000a5c0: 6520 4461 7461 4d61 7070 6572 2c20 696e  e DataMapper, in
+0000a5d0: 7420 6d72 2c20 696e 7420 6e72 2c20 626f  t mr, int nr, bo
+0000a5e0: 6f6c 2043 6f6e 6a75 6761 7465 4c68 732c  ol ConjugateLhs,
+0000a5f0: 2062 6f6f 6c20 436f 6e6a 7567 6174 6552   bool ConjugateR
+0000a600: 6873 2c0a 696e 7420 5377 6170 7065 644c  hs,.int SwappedL
+0000a610: 6873 5072 6f67 7265 7373 203d 2067 6562  hsProgress = geb
+0000a620: 705f 7472 6169 7473 3c52 6873 5363 616c  p_traits<RhsScal
+0000a630: 6172 2c4c 6873 5363 616c 6172 2c43 6f6e  ar,LhsScalar,Con
+0000a640: 6a75 6761 7465 5268 732c 436f 6e6a 7567  jugateRhs,Conjug
+0000a650: 6174 654c 6873 2c41 7263 6869 7465 6374  ateLhs,Architect
+0000a660: 7572 653a 3a54 6172 6765 743e 3a3a 4c68  ure::Target>::Lh
+0000a670: 7350 726f 6772 6573 733e 0a73 7472 7563  sProgress>.struc
+0000a680: 7420 6c61 7374 5f72 6f77 5f70 726f 6365  t last_row_proce
+0000a690: 7373 5f31 365f 7061 636b 6574 730a 7b0a  ss_16_packets.{.
+0000a6a0: 2020 7479 7065 6465 6620 6765 6270 5f74    typedef gebp_t
+0000a6b0: 7261 6974 733c 4c68 7353 6361 6c61 722c  raits<LhsScalar,
+0000a6c0: 5268 7353 6361 6c61 722c 436f 6e6a 7567  RhsScalar,Conjug
+0000a6d0: 6174 654c 6873 2c43 6f6e 6a75 6761 7465  ateLhs,Conjugate
+0000a6e0: 5268 732c 4172 6368 6974 6563 7475 7265  Rhs,Architecture
+0000a6f0: 3a3a 5461 7267 6574 3e20 5472 6169 7473  ::Target> Traits
+0000a700: 3b0a 2020 7479 7065 6465 6620 6765 6270  ;.  typedef gebp
+0000a710: 5f74 7261 6974 733c 5268 7353 6361 6c61  _traits<RhsScala
+0000a720: 722c 4c68 7353 6361 6c61 722c 436f 6e6a  r,LhsScalar,Conj
+0000a730: 7567 6174 6552 6873 2c43 6f6e 6a75 6761  ugateRhs,Conjuga
+0000a740: 7465 4c68 732c 4172 6368 6974 6563 7475  teLhs,Architectu
+0000a750: 7265 3a3a 5461 7267 6574 3e20 5377 6170  re::Target> Swap
+0000a760: 7065 6454 7261 6974 733b 0a0a 2020 7479  pedTraits;..  ty
+0000a770: 7065 6465 6620 7479 7065 6e61 6d65 2054  pedef typename T
+0000a780: 7261 6974 733a 3a52 6573 5363 616c 6172  raits::ResScalar
+0000a790: 2052 6573 5363 616c 6172 3b0a 2020 7479   ResScalar;.  ty
+0000a7a0: 7065 6465 6620 7479 7065 6e61 6d65 2053  pedef typename S
+0000a7b0: 7761 7070 6564 5472 6169 7473 3a3a 4c68  wappedTraits::Lh
+0000a7c0: 7350 6163 6b65 7420 534c 6873 5061 636b  sPacket SLhsPack
+0000a7d0: 6574 3b0a 2020 7479 7065 6465 6620 7479  et;.  typedef ty
+0000a7e0: 7065 6e61 6d65 2053 7761 7070 6564 5472  pename SwappedTr
+0000a7f0: 6169 7473 3a3a 5268 7350 6163 6b65 7420  aits::RhsPacket 
+0000a800: 5352 6873 5061 636b 6574 3b0a 2020 7479  SRhsPacket;.  ty
+0000a810: 7065 6465 6620 7479 7065 6e61 6d65 2053  pedef typename S
+0000a820: 7761 7070 6564 5472 6169 7473 3a3a 5265  wappedTraits::Re
+0000a830: 7350 6163 6b65 7420 5352 6573 5061 636b  sPacket SResPack
+0000a840: 6574 3b0a 2020 7479 7065 6465 6620 7479  et;.  typedef ty
+0000a850: 7065 6e61 6d65 2053 7761 7070 6564 5472  pename SwappedTr
+0000a860: 6169 7473 3a3a 4163 6350 6163 6b65 7420  aits::AccPacket 
+0000a870: 5341 6363 5061 636b 6574 3b0a 0a20 2045  SAccPacket;..  E
+0000a880: 4947 454e 5f53 5452 4f4e 475f 494e 4c49  IGEN_STRONG_INLI
+0000a890: 4e45 2076 6f69 6420 6f70 6572 6174 6f72  NE void operator
+0000a8a0: 2829 2863 6f6e 7374 2044 6174 614d 6170  ()(const DataMap
+0000a8b0: 7065 7226 2072 6573 2c20 5377 6170 7065  per& res, Swappe
+0000a8c0: 6454 7261 6974 7320 2673 7472 6169 7473  dTraits &straits
+0000a8d0: 2c20 636f 6e73 7420 4c68 7353 6361 6c61  , const LhsScala
+0000a8e0: 722a 2062 6c41 2c0a 2020 2020 2020 2020  r* blA,.        
+0000a8f0: 2020 2020 2020 2020 2020 636f 6e73 7420            const 
+0000a900: 5268 7353 6361 6c61 722a 2062 6c42 2c20  RhsScalar* blB, 
+0000a910: 496e 6465 7820 6465 7074 682c 2063 6f6e  Index depth, con
+0000a920: 7374 2049 6e64 6578 2065 6e64 6b2c 2049  st Index endk, I
+0000a930: 6e64 6578 2069 2c20 496e 6465 7820 6a32  ndex i, Index j2
+0000a940: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+0000a950: 2020 2020 5265 7353 6361 6c61 7220 616c      ResScalar al
+0000a960: 7068 612c 2053 4163 6350 6163 6b65 7420  pha, SAccPacket 
+0000a970: 2643 3029 0a20 2020 207b 0a20 2020 2020  &C0).    {.     
+0000a980: 2045 4947 454e 5f55 4e55 5345 445f 5641   EIGEN_UNUSED_VA
+0000a990: 5249 4142 4c45 2872 6573 293b 0a20 2020  RIABLE(res);.   
+0000a9a0: 2020 2045 4947 454e 5f55 4e55 5345 445f     EIGEN_UNUSED_
+0000a9b0: 5641 5249 4142 4c45 2873 7472 6169 7473  VARIABLE(straits
+0000a9c0: 293b 0a20 2020 2020 2045 4947 454e 5f55  );.      EIGEN_U
+0000a9d0: 4e55 5345 445f 5641 5249 4142 4c45 2862  NUSED_VARIABLE(b
+0000a9e0: 6c41 293b 0a20 2020 2020 2045 4947 454e  lA);.      EIGEN
+0000a9f0: 5f55 4e55 5345 445f 5641 5249 4142 4c45  _UNUSED_VARIABLE
+0000aa00: 2862 6c42 293b 0a20 2020 2020 2045 4947  (blB);.      EIG
+0000aa10: 454e 5f55 4e55 5345 445f 5641 5249 4142  EN_UNUSED_VARIAB
+0000aa20: 4c45 2864 6570 7468 293b 0a20 2020 2020  LE(depth);.     
+0000aa30: 2045 4947 454e 5f55 4e55 5345 445f 5641   EIGEN_UNUSED_VA
+0000aa40: 5249 4142 4c45 2865 6e64 6b29 3b0a 2020  RIABLE(endk);.  
+0000aa50: 2020 2020 4549 4745 4e5f 554e 5553 4544      EIGEN_UNUSED
+0000aa60: 5f56 4152 4941 424c 4528 6929 3b0a 2020  _VARIABLE(i);.  
+0000aa70: 2020 2020 4549 4745 4e5f 554e 5553 4544      EIGEN_UNUSED
+0000aa80: 5f56 4152 4941 424c 4528 6a32 293b 0a20  _VARIABLE(j2);. 
+0000aa90: 2020 2020 2045 4947 454e 5f55 4e55 5345       EIGEN_UNUSE
+0000aaa0: 445f 5641 5249 4142 4c45 2861 6c70 6861  D_VARIABLE(alpha
+0000aab0: 293b 0a20 2020 2020 2045 4947 454e 5f55  );.      EIGEN_U
+0000aac0: 4e55 5345 445f 5641 5249 4142 4c45 2843  NUSED_VARIABLE(C
+0000aad0: 3029 3b0a 2020 2020 7d0a 7d3b 0a0a 0a74  0);.    }.};...t
+0000aae0: 656d 706c 6174 653c 7479 7065 6e61 6d65  emplate<typename
+0000aaf0: 204c 6873 5363 616c 6172 2c20 7479 7065   LhsScalar, type
+0000ab00: 6e61 6d65 2052 6873 5363 616c 6172 2c20  name RhsScalar, 
+0000ab10: 7479 7065 6e61 6d65 2049 6e64 6578 2c20  typename Index, 
+0000ab20: 7479 7065 6e61 6d65 2044 6174 614d 6170  typename DataMap
+0000ab30: 7065 722c 2069 6e74 206d 722c 2069 6e74  per, int mr, int
+0000ab40: 206e 722c 2062 6f6f 6c20 436f 6e6a 7567   nr, bool Conjug
+0000ab50: 6174 654c 6873 2c20 626f 6f6c 2043 6f6e  ateLhs, bool Con
+0000ab60: 6a75 6761 7465 5268 733e 0a73 7472 7563  jugateRhs>.struc
+0000ab70: 7420 6c61 7374 5f72 6f77 5f70 726f 6365  t last_row_proce
+0000ab80: 7373 5f31 365f 7061 636b 6574 733c 4c68  ss_16_packets<Lh
+0000ab90: 7353 6361 6c61 722c 2052 6873 5363 616c  sScalar, RhsScal
+0000aba0: 6172 2c20 496e 6465 782c 2044 6174 614d  ar, Index, DataM
+0000abb0: 6170 7065 722c 2020 6d72 2c20 206e 722c  apper,  mr,  nr,
+0000abc0: 2043 6f6e 6a75 6761 7465 4c68 732c 2020   ConjugateLhs,  
+0000abd0: 436f 6e6a 7567 6174 6552 6873 2c20 3136  ConjugateRhs, 16
+0000abe0: 3e20 7b0a 2020 7479 7065 6465 6620 6765  > {.  typedef ge
+0000abf0: 6270 5f74 7261 6974 733c 4c68 7353 6361  bp_traits<LhsSca
+0000ac00: 6c61 722c 5268 7353 6361 6c61 722c 436f  lar,RhsScalar,Co
+0000ac10: 6e6a 7567 6174 654c 6873 2c43 6f6e 6a75  njugateLhs,Conju
+0000ac20: 6761 7465 5268 732c 4172 6368 6974 6563  gateRhs,Architec
+0000ac30: 7475 7265 3a3a 5461 7267 6574 3e20 5472  ture::Target> Tr
+0000ac40: 6169 7473 3b0a 2020 7479 7065 6465 6620  aits;.  typedef 
+0000ac50: 6765 6270 5f74 7261 6974 733c 5268 7353  gebp_traits<RhsS
+0000ac60: 6361 6c61 722c 4c68 7353 6361 6c61 722c  calar,LhsScalar,
+0000ac70: 436f 6e6a 7567 6174 6552 6873 2c43 6f6e  ConjugateRhs,Con
+0000ac80: 6a75 6761 7465 4c68 732c 4172 6368 6974  jugateLhs,Archit
+0000ac90: 6563 7475 7265 3a3a 5461 7267 6574 3e20  ecture::Target> 
+0000aca0: 5377 6170 7065 6454 7261 6974 733b 0a0a  SwappedTraits;..
+0000acb0: 2020 7479 7065 6465 6620 7479 7065 6e61    typedef typena
+0000acc0: 6d65 2054 7261 6974 733a 3a52 6573 5363  me Traits::ResSc
+0000acd0: 616c 6172 2052 6573 5363 616c 6172 3b0a  alar ResScalar;.
+0000ace0: 2020 7479 7065 6465 6620 7479 7065 6e61    typedef typena
+0000acf0: 6d65 2053 7761 7070 6564 5472 6169 7473  me SwappedTraits
+0000ad00: 3a3a 4c68 7350 6163 6b65 7420 534c 6873  ::LhsPacket SLhs
+0000ad10: 5061 636b 6574 3b0a 2020 7479 7065 6465  Packet;.  typede
+0000ad20: 6620 7479 7065 6e61 6d65 2053 7761 7070  f typename Swapp
+0000ad30: 6564 5472 6169 7473 3a3a 5268 7350 6163  edTraits::RhsPac
+0000ad40: 6b65 7420 5352 6873 5061 636b 6574 3b0a  ket SRhsPacket;.
+0000ad50: 2020 7479 7065 6465 6620 7479 7065 6e61    typedef typena
+0000ad60: 6d65 2053 7761 7070 6564 5472 6169 7473  me SwappedTraits
+0000ad70: 3a3a 5265 7350 6163 6b65 7420 5352 6573  ::ResPacket SRes
+0000ad80: 5061 636b 6574 3b0a 2020 7479 7065 6465  Packet;.  typede
+0000ad90: 6620 7479 7065 6e61 6d65 2053 7761 7070  f typename Swapp
+0000ada0: 6564 5472 6169 7473 3a3a 4163 6350 6163  edTraits::AccPac
+0000adb0: 6b65 7420 5341 6363 5061 636b 6574 3b0a  ket SAccPacket;.
+0000adc0: 0a20 2045 4947 454e 5f53 5452 4f4e 475f  .  EIGEN_STRONG_
+0000add0: 494e 4c49 4e45 2076 6f69 6420 6f70 6572  INLINE void oper
+0000ade0: 6174 6f72 2829 2863 6f6e 7374 2044 6174  ator()(const Dat
+0000adf0: 614d 6170 7065 7226 2072 6573 2c20 5377  aMapper& res, Sw
+0000ae00: 6170 7065 6454 7261 6974 7320 2673 7472  appedTraits &str
+0000ae10: 6169 7473 2c20 636f 6e73 7420 4c68 7353  aits, const LhsS
+0000ae20: 6361 6c61 722a 2062 6c41 2c0a 2020 2020  calar* blA,.    
+0000ae30: 2020 2020 2020 2020 2020 2020 2020 636f                co
+0000ae40: 6e73 7420 5268 7353 6361 6c61 722a 2062  nst RhsScalar* b
+0000ae50: 6c42 2c20 496e 6465 7820 6465 7074 682c  lB, Index depth,
+0000ae60: 2063 6f6e 7374 2049 6e64 6578 2065 6e64   const Index end
+0000ae70: 6b2c 2049 6e64 6578 2069 2c20 496e 6465  k, Index i, Inde
+0000ae80: 7820 6a32 2c0a 2020 2020 2020 2020 2020  x j2,.          
+0000ae90: 2020 2020 2020 2020 5265 7353 6361 6c61          ResScala
+0000aea0: 7220 616c 7068 612c 2053 4163 6350 6163  r alpha, SAccPac
+0000aeb0: 6b65 7420 2643 3029 0a20 207b 0a20 2020  ket &C0).  {.   
+0000aec0: 2074 7970 6564 6566 2074 7970 656e 616d   typedef typenam
+0000aed0: 6520 756e 7061 636b 6574 5f74 7261 6974  e unpacket_trait
+0000aee0: 733c 7479 7065 6e61 6d65 2075 6e70 6163  s<typename unpac
+0000aef0: 6b65 745f 7472 6169 7473 3c53 5265 7350  ket_traits<SResP
+0000af00: 6163 6b65 743e 3a3a 6861 6c66 3e3a 3a68  acket>::half>::h
+0000af10: 616c 6620 5352 6573 5061 636b 6574 5175  alf SResPacketQu
+0000af20: 6172 7465 723b 0a20 2020 2074 7970 6564  arter;.    typed
+0000af30: 6566 2074 7970 656e 616d 6520 756e 7061  ef typename unpa
+0000af40: 636b 6574 5f74 7261 6974 733c 7479 7065  cket_traits<type
+0000af50: 6e61 6d65 2075 6e70 6163 6b65 745f 7472  name unpacket_tr
+0000af60: 6169 7473 3c53 4c68 7350 6163 6b65 743e  aits<SLhsPacket>
+0000af70: 3a3a 6861 6c66 3e3a 3a68 616c 6620 534c  ::half>::half SL
+0000af80: 6873 5061 636b 6574 5175 6172 7465 723b  hsPacketQuarter;
+0000af90: 0a20 2020 2074 7970 6564 6566 2074 7970  .    typedef typ
+0000afa0: 656e 616d 6520 756e 7061 636b 6574 5f74  ename unpacket_t
+0000afb0: 7261 6974 733c 7479 7065 6e61 6d65 2075  raits<typename u
+0000afc0: 6e70 6163 6b65 745f 7472 6169 7473 3c53  npacket_traits<S
+0000afd0: 5268 7350 6163 6b65 743e 3a3a 6861 6c66  RhsPacket>::half
+0000afe0: 3e3a 3a68 616c 6620 5352 6873 5061 636b  >::half SRhsPack
+0000aff0: 6574 5175 6172 7465 723b 0a20 2020 2074  etQuarter;.    t
+0000b000: 7970 6564 6566 2074 7970 656e 616d 6520  ypedef typename 
+0000b010: 756e 7061 636b 6574 5f74 7261 6974 733c  unpacket_traits<
+0000b020: 7479 7065 6e61 6d65 2075 6e70 6163 6b65  typename unpacke
+0000b030: 745f 7472 6169 7473 3c53 4163 6350 6163  t_traits<SAccPac
+0000b040: 6b65 743e 3a3a 6861 6c66 3e3a 3a68 616c  ket>::half>::hal
+0000b050: 6620 5341 6363 5061 636b 6574 5175 6172  f SAccPacketQuar
+0000b060: 7465 723b 0a0a 2020 2020 5352 6573 5061  ter;..    SResPa
+0000b070: 636b 6574 5175 6172 7465 7220 5220 3d20  cketQuarter R = 
+0000b080: 7265 732e 7465 6d70 6c61 7465 2067 6174  res.template gat
+0000b090: 6865 7250 6163 6b65 743c 5352 6573 5061  herPacket<SResPa
+0000b0a0: 636b 6574 5175 6172 7465 723e 2869 2c20  cketQuarter>(i, 
+0000b0b0: 6a32 293b 0a20 2020 2053 5265 7350 6163  j2);.    SResPac
+0000b0c0: 6b65 7451 7561 7274 6572 2061 6c70 6861  ketQuarter alpha
+0000b0d0: 7620 3d20 7073 6574 313c 5352 6573 5061  v = pset1<SResPa
+0000b0e0: 636b 6574 5175 6172 7465 723e 2861 6c70  cketQuarter>(alp
+0000b0f0: 6861 293b 0a0a 2020 2020 6966 2028 6465  ha);..    if (de
+0000b100: 7074 6820 2d20 656e 646b 203e 2030 290a  pth - endk > 0).
+0000b110: 2020 2020 2020 7b0a 092f 2f20 5765 2068        {..// We h
+0000b120: 6176 6520 746f 2068 616e 646c 6520 7468  ave to handle th
+0000b130: 6520 6c61 7374 2072 6f77 2873 2920 6f66  e last row(s) of
+0000b140: 2074 6865 2072 6873 2c20 7768 6963 680a   the rhs, which.
+0000b150: 092f 2f20 636f 7272 6573 706f 6e64 2074  .// correspond t
+0000b160: 6f20 6120 6861 6c66 2d70 6163 6b65 740a  o a half-packet.
+0000b170: 0953 4163 6350 6163 6b65 7451 7561 7274  .SAccPacketQuart
+0000b180: 6572 2063 3020 3d20 7072 6564 7578 5f68  er c0 = predux_h
+0000b190: 616c 665f 646f 7774 6f34 2870 7265 6475  alf_dowto4(predu
+0000b1a0: 785f 6861 6c66 5f64 6f77 746f 3428 4330  x_half_dowto4(C0
+0000b1b0: 2929 3b0a 0a09 666f 7220 2849 6e64 6578  ));...for (Index
+0000b1c0: 206b 6b20 3d20 656e 646b 3b20 6b6b 203c   kk = endk; kk <
+0000b1d0: 2064 6570 7468 3b20 6b6b 2b2b 290a 0920   depth; kk++).. 
+0000b1e0: 207b 0a09 2020 2020 534c 6873 5061 636b   {..    SLhsPack
+0000b1f0: 6574 5175 6172 7465 7220 6130 3b0a 0920  etQuarter a0;.. 
+0000b200: 2020 2053 5268 7350 6163 6b65 7451 7561     SRhsPacketQua
+0000b210: 7274 6572 2062 303b 0a09 2020 2020 7374  rter b0;..    st
+0000b220: 7261 6974 732e 6c6f 6164 4c68 7355 6e61  raits.loadLhsUna
+0000b230: 6c69 676e 6564 2862 6c42 2c20 6130 293b  ligned(blB, a0);
+0000b240: 0a09 2020 2020 7374 7261 6974 732e 6c6f  ..    straits.lo
+0000b250: 6164 5268 7328 626c 412c 2062 3029 3b0a  adRhs(blA, b0);.
+0000b260: 0920 2020 2073 7472 6169 7473 2e6d 6164  .    straits.mad
+0000b270: 6428 6130 2c62 302c 6330 2c62 302c 2066  d(a0,b0,c0,b0, f
+0000b280: 6978 3c30 3e29 3b0a 0920 2020 2062 6c42  ix<0>);..    blB
+0000b290: 202b 3d20 5377 6170 7065 6454 7261 6974   += SwappedTrait
+0000b2a0: 733a 3a4c 6873 5072 6f67 7265 7373 2f34  s::LhsProgress/4
+0000b2b0: 3b0a 0920 2020 2062 6c41 202b 3d20 313b  ;..    blA += 1;
+0000b2c0: 0a09 2020 7d0a 0973 7472 6169 7473 2e61  ..  }..straits.a
+0000b2d0: 6363 2863 302c 2061 6c70 6861 762c 2052  cc(c0, alphav, R
+0000b2e0: 293b 0a20 2020 2020 207d 0a20 2020 2065  );.      }.    e
+0000b2f0: 6c73 650a 2020 2020 2020 7b0a 0973 7472  lse.      {..str
+0000b300: 6169 7473 2e61 6363 2870 7265 6475 785f  aits.acc(predux_
+0000b310: 6861 6c66 5f64 6f77 746f 3428 7072 6564  half_dowto4(pred
+0000b320: 7578 5f68 616c 665f 646f 7774 6f34 2843  ux_half_dowto4(C
+0000b330: 3029 292c 2061 6c70 6861 762c 2052 293b  0)), alphav, R);
+0000b340: 0a20 2020 2020 207d 0a20 2020 2072 6573  .      }.    res
+0000b350: 2e73 6361 7474 6572 5061 636b 6574 2869  .scatterPacket(i
+0000b360: 2c20 6a32 2c20 5229 3b0a 2020 7d0a 7d3b  , j2, R);.  }.};
+0000b370: 0a0a 7465 6d70 6c61 7465 3c69 6e74 206e  ..template<int n
+0000b380: 722c 2049 6e64 6578 204c 6873 5072 6f67  r, Index LhsProg
+0000b390: 7265 7373 2c20 496e 6465 7820 5268 7350  ress, Index RhsP
+0000b3a0: 726f 6772 6573 732c 2074 7970 656e 616d  rogress, typenam
+0000b3b0: 6520 4c68 7353 6361 6c61 722c 2074 7970  e LhsScalar, typ
+0000b3c0: 656e 616d 6520 5268 7353 6361 6c61 722c  ename RhsScalar,
+0000b3d0: 2074 7970 656e 616d 6520 5265 7353 6361   typename ResSca
+0000b3e0: 6c61 722c 2074 7970 656e 616d 6520 4163  lar, typename Ac
+0000b3f0: 6350 6163 6b65 742c 2074 7970 656e 616d  cPacket, typenam
+0000b400: 6520 4c68 7350 6163 6b65 742c 2074 7970  e LhsPacket, typ
+0000b410: 656e 616d 6520 5268 7350 6163 6b65 742c  ename RhsPacket,
+0000b420: 2074 7970 656e 616d 6520 5265 7350 6163   typename ResPac
+0000b430: 6b65 742c 2074 7970 656e 616d 6520 4745  ket, typename GE
+0000b440: 4250 5472 6169 7473 2c20 7479 7065 6e61  BPTraits, typena
+0000b450: 6d65 204c 696e 6561 724d 6170 7065 722c  me LinearMapper,
+0000b460: 2074 7970 656e 616d 6520 4461 7461 4d61   typename DataMa
+0000b470: 7070 6572 3e0a 7374 7275 6374 206c 6873  pper>.struct lhs
+0000b480: 5f70 726f 6365 7373 5f6f 6e65 5f70 6163  _process_one_pac
+0000b490: 6b65 740a 7b0a 2020 7479 7065 6465 6620  ket.{.  typedef 
+0000b4a0: 7479 7065 6e61 6d65 2047 4542 5054 7261  typename GEBPTra
+0000b4b0: 6974 733a 3a52 6873 5061 636b 6574 7834  its::RhsPacketx4
+0000b4c0: 2052 6873 5061 636b 6574 7834 3b0a 0a20   RhsPacketx4;.. 
+0000b4d0: 2045 4947 454e 5f53 5452 4f4e 475f 494e   EIGEN_STRONG_IN
+0000b4e0: 4c49 4e45 2076 6f69 6420 7065 656c 6564  LINE void peeled
+0000b4f0: 5f6b 635f 6f6e 6573 7465 7028 496e 6465  _kc_onestep(Inde
+0000b500: 7820 4b2c 2063 6f6e 7374 204c 6873 5363  x K, const LhsSc
+0000b510: 616c 6172 2a20 626c 412c 2063 6f6e 7374  alar* blA, const
+0000b520: 2052 6873 5363 616c 6172 2a20 626c 422c   RhsScalar* blB,
+0000b530: 2047 4542 5054 7261 6974 7320 7472 6169   GEBPTraits trai
+0000b540: 7473 2c20 4c68 7350 6163 6b65 7420 2a41  ts, LhsPacket *A
+0000b550: 302c 2052 6873 5061 636b 6574 7834 202a  0, RhsPacketx4 *
+0000b560: 7268 735f 7061 6e65 6c2c 2052 6873 5061  rhs_panel, RhsPa
+0000b570: 636b 6574 202a 5430 2c20 4163 6350 6163  cket *T0, AccPac
+0000b580: 6b65 7420 2a43 302c 2041 6363 5061 636b  ket *C0, AccPack
+0000b590: 6574 202a 4331 2c20 4163 6350 6163 6b65  et *C1, AccPacke
+0000b5a0: 7420 2a43 322c 2041 6363 5061 636b 6574  t *C2, AccPacket
+0000b5b0: 202a 4333 290a 2020 7b0a 2020 2020 4549   *C3).  {.    EI
+0000b5c0: 4745 4e5f 4153 4d5f 434f 4d4d 454e 5428  GEN_ASM_COMMENT(
+0000b5d0: 2262 6567 696e 2073 7465 7020 6f66 2067  "begin step of g
+0000b5e0: 6562 7020 6d69 6372 6f20 6b65 726e 656c  ebp micro kernel
+0000b5f0: 2031 5834 2229 3b0a 2020 2020 4549 4745   1X4");.    EIGE
+0000b600: 4e5f 4153 4d5f 434f 4d4d 454e 5428 224e  N_ASM_COMMENT("N
+0000b610: 6f74 653a 2074 6865 7365 2061 736d 2063  ote: these asm c
+0000b620: 6f6d 6d65 6e74 7320 776f 726b 2061 726f  omments work aro
+0000b630: 756e 6420 6275 6720 3933 3521 2229 3b0a  und bug 935!");.
+0000b640: 2020 2020 7472 6169 7473 2e6c 6f61 644c      traits.loadL
+0000b650: 6873 2826 626c 415b 2830 2b31 2a4b 292a  hs(&blA[(0+1*K)*
+0000b660: 4c68 7350 726f 6772 6573 735d 2c20 2a41  LhsProgress], *A
+0000b670: 3029 3b0a 2020 2020 7472 6169 7473 2e6c  0);.    traits.l
+0000b680: 6f61 6452 6873 2826 626c 425b 2830 2b34  oadRhs(&blB[(0+4
+0000b690: 2a4b 292a 5268 7350 726f 6772 6573 735d  *K)*RhsProgress]
+0000b6a0: 2c20 2a72 6873 5f70 616e 656c 293b 0a20  , *rhs_panel);. 
+0000b6b0: 2020 2074 7261 6974 732e 6d61 6464 282a     traits.madd(*
+0000b6c0: 4130 2c20 2a72 6873 5f70 616e 656c 2c20  A0, *rhs_panel, 
+0000b6d0: 2a43 302c 202a 5430 2c20 6669 783c 303e  *C0, *T0, fix<0>
+0000b6e0: 293b 0a20 2020 2074 7261 6974 732e 6d61  );.    traits.ma
+0000b6f0: 6464 282a 4130 2c20 2a72 6873 5f70 616e  dd(*A0, *rhs_pan
+0000b700: 656c 2c20 2a43 312c 202a 5430 2c20 6669  el, *C1, *T0, fi
+0000b710: 783c 313e 293b 0a20 2020 2074 7261 6974  x<1>);.    trait
+0000b720: 732e 6d61 6464 282a 4130 2c20 2a72 6873  s.madd(*A0, *rhs
+0000b730: 5f70 616e 656c 2c20 2a43 322c 202a 5430  _panel, *C2, *T0
+0000b740: 2c20 6669 783c 323e 293b 0a20 2020 2074  , fix<2>);.    t
+0000b750: 7261 6974 732e 6d61 6464 282a 4130 2c20  raits.madd(*A0, 
+0000b760: 2a72 6873 5f70 616e 656c 2c20 2a43 332c  *rhs_panel, *C3,
+0000b770: 202a 5430 2c20 6669 783c 333e 293b 0a20   *T0, fix<3>);. 
+0000b780: 2020 2023 6966 2045 4947 454e 5f47 4e55     #if EIGEN_GNU
+0000b790: 435f 4154 5f4c 4541 5354 2836 2c30 2920  C_AT_LEAST(6,0) 
+0000b7a0: 2626 2064 6566 696e 6564 2845 4947 454e  && defined(EIGEN
+0000b7b0: 5f56 4543 544f 5249 5a45 5f53 5345 290a  _VECTORIZE_SSE).
+0000b7c0: 2020 2020 5f5f 6173 6d5f 5f20 2028 2222      __asm__  (""
+0000b7d0: 203a 2022 2b78 2c6d 2220 282a 4130 2929   : "+x,m" (*A0))
+0000b7e0: 3b0a 2020 2020 2365 6e64 6966 0a20 2020  ;.    #endif.   
+0000b7f0: 2045 4947 454e 5f41 534d 5f43 4f4d 4d45   EIGEN_ASM_COMME
+0000b800: 4e54 2822 656e 6420 7374 6570 206f 6620  NT("end step of 
+0000b810: 6765 6270 206d 6963 726f 206b 6572 6e65  gebp micro kerne
+0000b820: 6c20 3158 3422 293b 0a20 207d 0a0a 2020  l 1X4");.  }..  
+0000b830: 4549 4745 4e5f 5354 524f 4e47 5f49 4e4c  EIGEN_STRONG_INL
+0000b840: 494e 4520 766f 6964 206f 7065 7261 746f  INE void operato
+0000b850: 7228 2928 0a20 2020 2063 6f6e 7374 2044  r()(.    const D
+0000b860: 6174 614d 6170 7065 7226 2072 6573 2c20  ataMapper& res, 
+0000b870: 636f 6e73 7420 4c68 7353 6361 6c61 722a  const LhsScalar*
+0000b880: 2062 6c6f 636b 412c 2063 6f6e 7374 2052   blockA, const R
+0000b890: 6873 5363 616c 6172 2a20 626c 6f63 6b42  hsScalar* blockB
+0000b8a0: 2c20 5265 7353 6361 6c61 7220 616c 7068  , ResScalar alph
+0000b8b0: 612c 0a20 2020 2049 6e64 6578 2070 6565  a,.    Index pee
+0000b8c0: 6c53 7461 7274 2c20 496e 6465 7820 7065  lStart, Index pe
+0000b8d0: 656c 456e 642c 2049 6e64 6578 2073 7472  elEnd, Index str
+0000b8e0: 6964 6541 2c20 496e 6465 7820 7374 7269  ideA, Index stri
+0000b8f0: 6465 422c 2049 6e64 6578 206f 6666 7365  deB, Index offse
+0000b900: 7441 2c20 496e 6465 7820 6f66 6673 6574  tA, Index offset
+0000b910: 422c 0a20 2020 2069 6e74 2070 7265 6665  B,.    int prefe
+0000b920: 7463 685f 7265 735f 6f66 6673 6574 2c20  tch_res_offset, 
+0000b930: 496e 6465 7820 7065 656c 6564 5f6b 632c  Index peeled_kc,
+0000b940: 2049 6e64 6578 2070 6b2c 2049 6e64 6578   Index pk, Index
+0000b950: 2063 6f6c 732c 2049 6e64 6578 2064 6570   cols, Index dep
+0000b960: 7468 2c20 496e 6465 7820 7061 636b 6574  th, Index packet
+0000b970: 5f63 6f6c 7334 290a 2020 7b0a 2020 2020  _cols4).  {.    
+0000b980: 4745 4250 5472 6169 7473 2074 7261 6974  GEBPTraits trait
+0000b990: 733b 0a0a 2020 2020 2f2f 206c 6f6f 7073  s;..    // loops
+0000b9a0: 206f 6e20 6561 6368 206c 6172 6765 7374   on each largest
+0000b9b0: 206d 6963 726f 2068 6f72 697a 6f6e 7461   micro horizonta
+0000b9c0: 6c20 7061 6e65 6c20 6f66 206c 6873 0a20  l panel of lhs. 
+0000b9d0: 2020 202f 2f20 284c 6873 5072 6f67 7265     // (LhsProgre
+0000b9e0: 7373 2078 2064 6570 7468 290a 2020 2020  ss x depth).    
+0000b9f0: 666f 7228 496e 6465 7820 693d 7065 656c  for(Index i=peel
+0000ba00: 5374 6172 743b 2069 3c70 6565 6c45 6e64  Start; i<peelEnd
+0000ba10: 3b20 692b 3d4c 6873 5072 6f67 7265 7373  ; i+=LhsProgress
+0000ba20: 290a 2020 2020 7b0a 2020 2020 2020 2f2f  ).    {.      //
+0000ba30: 206c 6f6f 7073 206f 6e20 6561 6368 206c   loops on each l
+0000ba40: 6172 6765 7374 206d 6963 726f 2076 6572  argest micro ver
+0000ba50: 7469 6361 6c20 7061 6e65 6c20 6f66 2072  tical panel of r
+0000ba60: 6873 2028 6465 7074 6820 2a20 6e72 290a  hs (depth * nr).
+0000ba70: 2020 2020 2020 666f 7228 496e 6465 7820        for(Index 
+0000ba80: 6a32 3d30 3b20 6a32 3c70 6163 6b65 745f  j2=0; j2<packet_
+0000ba90: 636f 6c73 343b 206a 322b 3d6e 7229 0a20  cols4; j2+=nr). 
+0000baa0: 2020 2020 207b 0a20 2020 2020 2020 202f       {.        /
+0000bab0: 2f20 5765 2073 656c 6563 7420 6120 4c68  / We select a Lh
+0000bac0: 7350 726f 6772 6573 7320 7820 6e72 206d  sProgress x nr m
+0000bad0: 6963 726f 2062 6c6f 636b 206f 6620 7265  icro block of re
+0000bae0: 730a 2020 2020 2020 2020 2f2f 2077 6869  s.        // whi
+0000baf0: 6368 2069 7320 656e 7469 7265 6c79 2073  ch is entirely s
+0000bb00: 746f 7265 6420 696e 746f 2031 2078 206e  tored into 1 x n
+0000bb10: 7220 7265 6769 7374 6572 732e 0a0a 2020  r registers...  
+0000bb20: 2020 2020 2020 636f 6e73 7420 4c68 7353        const LhsS
+0000bb30: 6361 6c61 722a 2062 6c41 203d 2026 626c  calar* blA = &bl
+0000bb40: 6f63 6b41 5b69 2a73 7472 6964 6541 2b6f  ockA[i*strideA+o
+0000bb50: 6666 7365 7441 2a28 4c68 7350 726f 6772  ffsetA*(LhsProgr
+0000bb60: 6573 7329 5d3b 0a20 2020 2020 2020 2070  ess)];.        p
+0000bb70: 7265 6665 7463 6828 2662 6c41 5b30 5d29  refetch(&blA[0])
+0000bb80: 3b0a 0a20 2020 2020 2020 202f 2f20 6765  ;..        // ge
+0000bb90: 7473 2072 6573 2062 6c6f 636b 2061 7320  ts res block as 
+0000bba0: 7265 6769 7374 6572 0a20 2020 2020 2020  register.       
+0000bbb0: 2041 6363 5061 636b 6574 2043 302c 2043   AccPacket C0, C
+0000bbc0: 312c 2043 322c 2043 333b 0a20 2020 2020  1, C2, C3;.     
+0000bbd0: 2020 2074 7261 6974 732e 696e 6974 4163     traits.initAc
+0000bbe0: 6328 4330 293b 0a20 2020 2020 2020 2074  c(C0);.        t
+0000bbf0: 7261 6974 732e 696e 6974 4163 6328 4331  raits.initAcc(C1
+0000bc00: 293b 0a20 2020 2020 2020 2074 7261 6974  );.        trait
+0000bc10: 732e 696e 6974 4163 6328 4332 293b 0a20  s.initAcc(C2);. 
+0000bc20: 2020 2020 2020 2074 7261 6974 732e 696e         traits.in
+0000bc30: 6974 4163 6328 4333 293b 0a20 2020 2020  itAcc(C3);.     
+0000bc40: 2020 202f 2f20 546f 2069 6d70 726f 7665     // To improve
+0000bc50: 2069 6e73 7472 7563 7469 6f6e 2070 6970   instruction pip
+0000bc60: 656c 696e 696e 672c 206c 6574 2773 2064  elining, let's d
+0000bc70: 6f75 626c 6520 7468 6520 6163 6375 6d75  ouble the accumu
+0000bc80: 6c61 7469 6f6e 2072 6567 6973 7465 7273  lation registers
+0000bc90: 3a0a 2020 2020 2020 2020 2f2f 2020 6576  :.        //  ev
+0000bca0: 656e 206b 2077 696c 6c20 6163 6375 6d75  en k will accumu
+0000bcb0: 6c61 7465 2069 6e20 432a 2c20 7768 696c  late in C*, whil
+0000bcc0: 6520 6f64 6420 6b20 7769 6c6c 2061 6363  e odd k will acc
+0000bcd0: 756d 756c 6174 6520 696e 2044 2a2e 0a20  umulate in D*.. 
+0000bce0: 2020 2020 2020 202f 2f20 5468 6973 2074         // This t
+0000bcf0: 7269 636b 2069 7320 6372 7574 6961 6c20  rick is crutial 
+0000bd00: 746f 2067 6574 2067 6f6f 6420 7065 7266  to get good perf
+0000bd10: 6f72 6d61 6e63 6520 7769 7468 2046 4d41  ormance with FMA
+0000bd20: 2c20 6f74 6865 7277 6973 6520 6974 2069  , otherwise it i
+0000bd30: 7320 0a20 2020 2020 2020 202f 2f20 6163  s .        // ac
+0000bd40: 7475 616c 6c79 2066 6173 7465 7220 746f  tually faster to
+0000bd50: 2070 6572 666f 726d 2073 6570 6172 6174   perform separat
+0000bd60: 6564 204d 554c 2b41 4444 2062 6563 6175  ed MUL+ADD becau
+0000bd70: 7365 206f 6620 6120 6e61 7475 7261 6c6c  se of a naturall
+0000bd80: 790a 2020 2020 2020 2020 2f2f 2062 6574  y.        // bet
+0000bd90: 7465 7220 696e 7374 7275 6374 696f 6e2d  ter instruction-
+0000bda0: 6c65 7665 6c20 7061 7261 6c6c 656c 6973  level parallelis
+0000bdb0: 6d2e 0a20 2020 2020 2020 2041 6363 5061  m..        AccPa
+0000bdc0: 636b 6574 2044 302c 2044 312c 2044 322c  cket D0, D1, D2,
+0000bdd0: 2044 333b 0a20 2020 2020 2020 2074 7261   D3;.        tra
+0000bde0: 6974 732e 696e 6974 4163 6328 4430 293b  its.initAcc(D0);
+0000bdf0: 0a20 2020 2020 2020 2074 7261 6974 732e  .        traits.
+0000be00: 696e 6974 4163 6328 4431 293b 0a20 2020  initAcc(D1);.   
+0000be10: 2020 2020 2074 7261 6974 732e 696e 6974       traits.init
+0000be20: 4163 6328 4432 293b 0a20 2020 2020 2020  Acc(D2);.       
+0000be30: 2074 7261 6974 732e 696e 6974 4163 6328   traits.initAcc(
+0000be40: 4433 293b 0a0a 2020 2020 2020 2020 4c69  D3);..        Li
+0000be50: 6e65 6172 4d61 7070 6572 2072 3020 3d20  nearMapper r0 = 
+0000be60: 7265 732e 6765 744c 696e 6561 724d 6170  res.getLinearMap
+0000be70: 7065 7228 692c 206a 3220 2b20 3029 3b0a  per(i, j2 + 0);.
+0000be80: 2020 2020 2020 2020 4c69 6e65 6172 4d61          LinearMa
+0000be90: 7070 6572 2072 3120 3d20 7265 732e 6765  pper r1 = res.ge
+0000bea0: 744c 696e 6561 724d 6170 7065 7228 692c  tLinearMapper(i,
+0000beb0: 206a 3220 2b20 3129 3b0a 2020 2020 2020   j2 + 1);.      
+0000bec0: 2020 4c69 6e65 6172 4d61 7070 6572 2072    LinearMapper r
+0000bed0: 3220 3d20 7265 732e 6765 744c 696e 6561  2 = res.getLinea
+0000bee0: 724d 6170 7065 7228 692c 206a 3220 2b20  rMapper(i, j2 + 
+0000bef0: 3229 3b0a 2020 2020 2020 2020 4c69 6e65  2);.        Line
+0000bf00: 6172 4d61 7070 6572 2072 3320 3d20 7265  arMapper r3 = re
+0000bf10: 732e 6765 744c 696e 6561 724d 6170 7065  s.getLinearMappe
+0000bf20: 7228 692c 206a 3220 2b20 3329 3b0a 0a20  r(i, j2 + 3);.. 
+0000bf30: 2020 2020 2020 2072 302e 7072 6566 6574         r0.prefet
+0000bf40: 6368 2870 7265 6665 7463 685f 7265 735f  ch(prefetch_res_
+0000bf50: 6f66 6673 6574 293b 0a20 2020 2020 2020  offset);.       
+0000bf60: 2072 312e 7072 6566 6574 6368 2870 7265   r1.prefetch(pre
+0000bf70: 6665 7463 685f 7265 735f 6f66 6673 6574  fetch_res_offset
+0000bf80: 293b 0a20 2020 2020 2020 2072 322e 7072  );.        r2.pr
+0000bf90: 6566 6574 6368 2870 7265 6665 7463 685f  efetch(prefetch_
+0000bfa0: 7265 735f 6f66 6673 6574 293b 0a20 2020  res_offset);.   
+0000bfb0: 2020 2020 2072 332e 7072 6566 6574 6368       r3.prefetch
+0000bfc0: 2870 7265 6665 7463 685f 7265 735f 6f66  (prefetch_res_of
+0000bfd0: 6673 6574 293b 0a0a 2020 2020 2020 2020  fset);..        
+0000bfe0: 2f2f 2070 6572 666f 726d 7320 2269 6e6e  // performs "inn
+0000bff0: 6572 2220 7072 6f64 7563 7473 0a20 2020  er" products.   
+0000c000: 2020 2020 2063 6f6e 7374 2052 6873 5363       const RhsSc
+0000c010: 616c 6172 2a20 626c 4220 3d20 2662 6c6f  alar* blB = &blo
+0000c020: 636b 425b 6a32 2a73 7472 6964 6542 2b6f  ckB[j2*strideB+o
+0000c030: 6666 7365 7442 2a6e 725d 3b0a 2020 2020  ffsetB*nr];.    
+0000c040: 2020 2020 7072 6566 6574 6368 2826 626c      prefetch(&bl
+0000c050: 425b 305d 293b 0a20 2020 2020 2020 204c  B[0]);.        L
+0000c060: 6873 5061 636b 6574 2041 302c 2041 313b  hsPacket A0, A1;
+0000c070: 0a0a 2020 2020 2020 2020 666f 7228 496e  ..        for(In
+0000c080: 6465 7820 6b3d 303b 206b 3c70 6565 6c65  dex k=0; k<peele
+0000c090: 645f 6b63 3b20 6b2b 3d70 6b29 0a20 2020  d_kc; k+=pk).   
+0000c0a0: 2020 2020 207b 0a20 2020 2020 2020 2020       {.         
+0000c0b0: 2045 4947 454e 5f41 534d 5f43 4f4d 4d45   EIGEN_ASM_COMME
+0000c0c0: 4e54 2822 6265 6769 6e20 6765 6270 206d  NT("begin gebp m
+0000c0d0: 6963 726f 206b 6572 6e65 6c20 312f 6861  icro kernel 1/ha
+0000c0e0: 6c66 2f71 7561 7274 6572 5834 2229 3b0a  lf/quarterX4");.
+0000c0f0: 2020 2020 2020 2020 2020 5268 7350 6163            RhsPac
+0000c100: 6b65 7478 3420 7268 735f 7061 6e65 6c3b  ketx4 rhs_panel;
+0000c110: 0a20 2020 2020 2020 2020 2052 6873 5061  .          RhsPa
+0000c120: 636b 6574 2054 303b 0a0a 2020 2020 2020  cket T0;..      
+0000c130: 2020 2020 696e 7465 726e 616c 3a3a 7072      internal::pr
+0000c140: 6566 6574 6368 2862 6c42 2b28 3438 2b30  efetch(blB+(48+0
+0000c150: 2929 3b0a 2020 2020 2020 2020 2020 7065  ));.          pe
+0000c160: 656c 6564 5f6b 635f 6f6e 6573 7465 7028  eled_kc_onestep(
+0000c170: 302c 2062 6c41 2c20 626c 422c 2074 7261  0, blA, blB, tra
+0000c180: 6974 732c 2026 4130 2c20 2672 6873 5f70  its, &A0, &rhs_p
+0000c190: 616e 656c 2c20 2654 302c 2026 4330 2c20  anel, &T0, &C0, 
+0000c1a0: 2643 312c 2026 4332 2c20 2643 3329 3b0a  &C1, &C2, &C3);.
+0000c1b0: 2020 2020 2020 2020 2020 7065 656c 6564            peeled
+0000c1c0: 5f6b 635f 6f6e 6573 7465 7028 312c 2062  _kc_onestep(1, b
+0000c1d0: 6c41 2c20 626c 422c 2074 7261 6974 732c  lA, blB, traits,
+0000c1e0: 2026 4131 2c20 2672 6873 5f70 616e 656c   &A1, &rhs_panel
+0000c1f0: 2c20 2654 302c 2026 4430 2c20 2644 312c  , &T0, &D0, &D1,
+0000c200: 2026 4432 2c20 2644 3329 3b0a 2020 2020   &D2, &D3);.    
+0000c210: 2020 2020 2020 7065 656c 6564 5f6b 635f        peeled_kc_
+0000c220: 6f6e 6573 7465 7028 322c 2062 6c41 2c20  onestep(2, blA, 
+0000c230: 626c 422c 2074 7261 6974 732c 2026 4130  blB, traits, &A0
+0000c240: 2c20 2672 6873 5f70 616e 656c 2c20 2654  , &rhs_panel, &T
+0000c250: 302c 2026 4330 2c20 2643 312c 2026 4332  0, &C0, &C1, &C2
+0000c260: 2c20 2643 3329 3b0a 2020 2020 2020 2020  , &C3);.        
+0000c270: 2020 7065 656c 6564 5f6b 635f 6f6e 6573    peeled_kc_ones
+0000c280: 7465 7028 332c 2062 6c41 2c20 626c 422c  tep(3, blA, blB,
+0000c290: 2074 7261 6974 732c 2026 4131 2c20 2672   traits, &A1, &r
+0000c2a0: 6873 5f70 616e 656c 2c20 2654 302c 2026  hs_panel, &T0, &
+0000c2b0: 4430 2c20 2644 312c 2026 4432 2c20 2644  D0, &D1, &D2, &D
+0000c2c0: 3329 3b0a 2020 2020 2020 2020 2020 696e  3);.          in
+0000c2d0: 7465 726e 616c 3a3a 7072 6566 6574 6368  ternal::prefetch
+0000c2e0: 2862 6c42 2b28 3438 2b31 3629 293b 0a20  (blB+(48+16));. 
+0000c2f0: 2020 2020 2020 2020 2070 6565 6c65 645f           peeled_
+0000c300: 6b63 5f6f 6e65 7374 6570 2834 2c20 626c  kc_onestep(4, bl
+0000c310: 412c 2062 6c42 2c20 7472 6169 7473 2c20  A, blB, traits, 
+0000c320: 2641 302c 2026 7268 735f 7061 6e65 6c2c  &A0, &rhs_panel,
+0000c330: 2026 5430 2c20 2643 302c 2026 4331 2c20   &T0, &C0, &C1, 
+0000c340: 2643 322c 2026 4333 293b 0a20 2020 2020  &C2, &C3);.     
+0000c350: 2020 2020 2070 6565 6c65 645f 6b63 5f6f       peeled_kc_o
+0000c360: 6e65 7374 6570 2835 2c20 626c 412c 2062  nestep(5, blA, b
+0000c370: 6c42 2c20 7472 6169 7473 2c20 2641 312c  lB, traits, &A1,
+0000c380: 2026 7268 735f 7061 6e65 6c2c 2026 5430   &rhs_panel, &T0
+0000c390: 2c20 2644 302c 2026 4431 2c20 2644 322c  , &D0, &D1, &D2,
+0000c3a0: 2026 4433 293b 0a20 2020 2020 2020 2020   &D3);.         
+0000c3b0: 2070 6565 6c65 645f 6b63 5f6f 6e65 7374   peeled_kc_onest
+0000c3c0: 6570 2836 2c20 626c 412c 2062 6c42 2c20  ep(6, blA, blB, 
+0000c3d0: 7472 6169 7473 2c20 2641 302c 2026 7268  traits, &A0, &rh
+0000c3e0: 735f 7061 6e65 6c2c 2026 5430 2c20 2643  s_panel, &T0, &C
+0000c3f0: 302c 2026 4331 2c20 2643 322c 2026 4333  0, &C1, &C2, &C3
+0000c400: 293b 0a20 2020 2020 2020 2020 2070 6565  );.          pee
+0000c410: 6c65 645f 6b63 5f6f 6e65 7374 6570 2837  led_kc_onestep(7
+0000c420: 2c20 626c 412c 2062 6c42 2c20 7472 6169  , blA, blB, trai
+0000c430: 7473 2c20 2641 312c 2026 7268 735f 7061  ts, &A1, &rhs_pa
+0000c440: 6e65 6c2c 2026 5430 2c20 2644 302c 2026  nel, &T0, &D0, &
+0000c450: 4431 2c20 2644 322c 2026 4433 293b 0a0a  D1, &D2, &D3);..
+0000c460: 2020 2020 2020 2020 2020 626c 4220 2b3d            blB +=
+0000c470: 2070 6b2a 342a 5268 7350 726f 6772 6573   pk*4*RhsProgres
+0000c480: 733b 0a20 2020 2020 2020 2020 2062 6c41  s;.          blA
+0000c490: 202b 3d20 706b 2a4c 6873 5072 6f67 7265   += pk*LhsProgre
+0000c4a0: 7373 3b0a 0a20 2020 2020 2020 2020 2045  ss;..          E
+0000c4b0: 4947 454e 5f41 534d 5f43 4f4d 4d45 4e54  IGEN_ASM_COMMENT
+0000c4c0: 2822 656e 6420 6765 6270 206d 6963 726f  ("end gebp micro
+0000c4d0: 206b 6572 6e65 6c20 312f 6861 6c66 2f71   kernel 1/half/q
+0000c4e0: 7561 7274 6572 5834 2229 3b0a 2020 2020  uarterX4");.    
+0000c4f0: 2020 2020 7d0a 2020 2020 2020 2020 4330      }.        C0
+0000c500: 203d 2070 6164 6428 4330 2c44 3029 3b0a   = padd(C0,D0);.
+0000c510: 2020 2020 2020 2020 4331 203d 2070 6164          C1 = pad
+0000c520: 6428 4331 2c44 3129 3b0a 2020 2020 2020  d(C1,D1);.      
+0000c530: 2020 4332 203d 2070 6164 6428 4332 2c44    C2 = padd(C2,D
+0000c540: 3229 3b0a 2020 2020 2020 2020 4333 203d  2);.        C3 =
+0000c550: 2070 6164 6428 4333 2c44 3329 3b0a 0a20   padd(C3,D3);.. 
+0000c560: 2020 2020 2020 202f 2f20 7072 6f63 6573         // proces
+0000c570: 7320 7265 6d61 696e 696e 6720 7065 656c  s remaining peel
+0000c580: 6564 206c 6f6f 700a 2020 2020 2020 2020  ed loop.        
+0000c590: 666f 7228 496e 6465 7820 6b3d 7065 656c  for(Index k=peel
+0000c5a0: 6564 5f6b 633b 206b 3c64 6570 7468 3b20  ed_kc; k<depth; 
+0000c5b0: 6b2b 2b29 0a20 2020 2020 2020 207b 0a20  k++).        {. 
+0000c5c0: 2020 2020 2020 2020 2052 6873 5061 636b           RhsPack
+0000c5d0: 6574 7834 2072 6873 5f70 616e 656c 3b0a  etx4 rhs_panel;.
+0000c5e0: 2020 2020 2020 2020 2020 5268 7350 6163            RhsPac
+0000c5f0: 6b65 7420 5430 3b0a 2020 2020 2020 2020  ket T0;.        
+0000c600: 2020 7065 656c 6564 5f6b 635f 6f6e 6573    peeled_kc_ones
+0000c610: 7465 7028 302c 2062 6c41 2c20 626c 422c  tep(0, blA, blB,
+0000c620: 2074 7261 6974 732c 2026 4130 2c20 2672   traits, &A0, &r
+0000c630: 6873 5f70 616e 656c 2c20 2654 302c 2026  hs_panel, &T0, &
+0000c640: 4330 2c20 2643 312c 2026 4332 2c20 2643  C0, &C1, &C2, &C
+0000c650: 3329 3b0a 2020 2020 2020 2020 2020 626c  3);.          bl
+0000c660: 4220 2b3d 2034 2a52 6873 5072 6f67 7265  B += 4*RhsProgre
+0000c670: 7373 3b0a 2020 2020 2020 2020 2020 626c  ss;.          bl
+0000c680: 4120 2b3d 204c 6873 5072 6f67 7265 7373  A += LhsProgress
+0000c690: 3b0a 2020 2020 2020 2020 7d0a 0a20 2020  ;.        }..   
+0000c6a0: 2020 2020 2052 6573 5061 636b 6574 2052       ResPacket R
+0000c6b0: 302c 2052 313b 0a20 2020 2020 2020 2052  0, R1;.        R
+0000c6c0: 6573 5061 636b 6574 2061 6c70 6861 7620  esPacket alphav 
+0000c6d0: 3d20 7073 6574 313c 5265 7350 6163 6b65  = pset1<ResPacke
+0000c6e0: 743e 2861 6c70 6861 293b 0a0a 2020 2020  t>(alpha);..    
+0000c6f0: 2020 2020 5230 203d 2072 302e 7465 6d70      R0 = r0.temp
+0000c700: 6c61 7465 206c 6f61 6450 6163 6b65 743c  late loadPacket<
+0000c710: 5265 7350 6163 6b65 743e 2830 293b 0a20  ResPacket>(0);. 
+0000c720: 2020 2020 2020 2052 3120 3d20 7231 2e74         R1 = r1.t
+0000c730: 656d 706c 6174 6520 6c6f 6164 5061 636b  emplate loadPack
+0000c740: 6574 3c52 6573 5061 636b 6574 3e28 3029  et<ResPacket>(0)
+0000c750: 3b0a 2020 2020 2020 2020 7472 6169 7473  ;.        traits
+0000c760: 2e61 6363 2843 302c 2061 6c70 6861 762c  .acc(C0, alphav,
+0000c770: 2052 3029 3b0a 2020 2020 2020 2020 7472   R0);.        tr
+0000c780: 6169 7473 2e61 6363 2843 312c 2020 616c  aits.acc(C1,  al
+0000c790: 7068 6176 2c20 5231 293b 0a20 2020 2020  phav, R1);.     
+0000c7a0: 2020 2072 302e 7374 6f72 6550 6163 6b65     r0.storePacke
+0000c7b0: 7428 302c 2052 3029 3b0a 2020 2020 2020  t(0, R0);.      
+0000c7c0: 2020 7231 2e73 746f 7265 5061 636b 6574    r1.storePacket
+0000c7d0: 2830 2c20 5231 293b 0a0a 2020 2020 2020  (0, R1);..      
+0000c7e0: 2020 5230 203d 2072 322e 7465 6d70 6c61    R0 = r2.templa
+0000c7f0: 7465 206c 6f61 6450 6163 6b65 743c 5265  te loadPacket<Re
+0000c800: 7350 6163 6b65 743e 2830 293b 0a20 2020  sPacket>(0);.   
+0000c810: 2020 2020 2052 3120 3d20 7233 2e74 656d       R1 = r3.tem
+0000c820: 706c 6174 6520 6c6f 6164 5061 636b 6574  plate loadPacket
+0000c830: 3c52 6573 5061 636b 6574 3e28 3029 3b0a  <ResPacket>(0);.
+0000c840: 2020 2020 2020 2020 7472 6169 7473 2e61          traits.a
+0000c850: 6363 2843 322c 2020 616c 7068 6176 2c20  cc(C2,  alphav, 
+0000c860: 5230 293b 0a20 2020 2020 2020 2074 7261  R0);.        tra
+0000c870: 6974 732e 6163 6328 4333 2c20 2061 6c70  its.acc(C3,  alp
+0000c880: 6861 762c 2052 3129 3b0a 2020 2020 2020  hav, R1);.      
+0000c890: 2020 7232 2e73 746f 7265 5061 636b 6574    r2.storePacket
+0000c8a0: 2830 2c20 5230 293b 0a20 2020 2020 2020  (0, R0);.       
+0000c8b0: 2072 332e 7374 6f72 6550 6163 6b65 7428   r3.storePacket(
+0000c8c0: 302c 2052 3129 3b0a 2020 2020 2020 7d0a  0, R1);.      }.
+0000c8d0: 0a20 2020 2020 202f 2f20 4465 616c 2077  .      // Deal w
+0000c8e0: 6974 6820 7265 6d61 696e 696e 6720 636f  ith remaining co
+0000c8f0: 6c75 6d6e 7320 6f66 2074 6865 2072 6873  lumns of the rhs
+0000c900: 0a20 2020 2020 2066 6f72 2849 6e64 6578  .      for(Index
+0000c910: 206a 323d 7061 636b 6574 5f63 6f6c 7334   j2=packet_cols4
+0000c920: 3b20 6a32 3c63 6f6c 733b 206a 322b 2b29  ; j2<cols; j2++)
+0000c930: 0a20 2020 2020 207b 0a20 2020 2020 2020  .      {.       
+0000c940: 202f 2f20 4f6e 6520 636f 6c75 6d6e 2061   // One column a
+0000c950: 7420 6120 7469 6d65 0a20 2020 2020 2020  t a time.       
+0000c960: 2063 6f6e 7374 204c 6873 5363 616c 6172   const LhsScalar
+0000c970: 2a20 626c 4120 3d20 2662 6c6f 636b 415b  * blA = &blockA[
+0000c980: 692a 7374 7269 6465 412b 6f66 6673 6574  i*strideA+offset
+0000c990: 412a 284c 6873 5072 6f67 7265 7373 295d  A*(LhsProgress)]
+0000c9a0: 3b0a 2020 2020 2020 2020 7072 6566 6574  ;.        prefet
+0000c9b0: 6368 2826 626c 415b 305d 293b 0a0a 2020  ch(&blA[0]);..  
+0000c9c0: 2020 2020 2020 2f2f 2067 6574 7320 7265        // gets re
+0000c9d0: 7320 626c 6f63 6b20 6173 2072 6567 6973  s block as regis
+0000c9e0: 7465 720a 2020 2020 2020 2020 4163 6350  ter.        AccP
+0000c9f0: 6163 6b65 7420 4330 3b0a 2020 2020 2020  acket C0;.      
+0000ca00: 2020 7472 6169 7473 2e69 6e69 7441 6363    traits.initAcc
+0000ca10: 2843 3029 3b0a 0a20 2020 2020 2020 204c  (C0);..        L
+0000ca20: 696e 6561 724d 6170 7065 7220 7230 203d  inearMapper r0 =
+0000ca30: 2072 6573 2e67 6574 4c69 6e65 6172 4d61   res.getLinearMa
+0000ca40: 7070 6572 2869 2c20 6a32 293b 0a0a 2020  pper(i, j2);..  
+0000ca50: 2020 2020 2020 2f2f 2070 6572 666f 726d        // perform
+0000ca60: 7320 2269 6e6e 6572 2220 7072 6f64 7563  s "inner" produc
+0000ca70: 7473 0a20 2020 2020 2020 2063 6f6e 7374  ts.        const
+0000ca80: 2052 6873 5363 616c 6172 2a20 626c 4220   RhsScalar* blB 
+0000ca90: 3d20 2662 6c6f 636b 425b 6a32 2a73 7472  = &blockB[j2*str
+0000caa0: 6964 6542 2b6f 6666 7365 7442 5d3b 0a20  ideB+offsetB];. 
+0000cab0: 2020 2020 2020 204c 6873 5061 636b 6574         LhsPacket
+0000cac0: 2041 303b 0a0a 2020 2020 2020 2020 666f   A0;..        fo
+0000cad0: 7228 496e 6465 7820 6b3d 2030 3b20 6b3c  r(Index k= 0; k<
+0000cae0: 7065 656c 6564 5f6b 633b 206b 2b3d 706b  peeled_kc; k+=pk
+0000caf0: 290a 2020 2020 2020 2020 7b0a 2020 2020  ).        {.    
+0000cb00: 2020 2020 2020 4549 4745 4e5f 4153 4d5f        EIGEN_ASM_
+0000cb10: 434f 4d4d 454e 5428 2262 6567 696e 2067  COMMENT("begin g
+0000cb20: 6562 7020 6d69 6372 6f20 6b65 726e 656c  ebp micro kernel
+0000cb30: 2031 2f68 616c 662f 7175 6172 7465 7258   1/half/quarterX
+0000cb40: 3122 293b 0a20 2020 2020 2020 2020 2052  1");.          R
+0000cb50: 6873 5061 636b 6574 2042 5f30 3b0a 0a23  hsPacket B_0;..#
+0000cb60: 6465 6669 6e65 2045 4947 454e 5f47 4542  define EIGEN_GEB
+0000cb70: 4750 5f4f 4e45 5354 4550 284b 2920 2020  GP_ONESTEP(K)   
+0000cb80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cb90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cba0: 2020 2020 2020 205c 0a09 2020 2020 2020         \..      
+0000cbb0: 646f 207b 2020 2020 2020 2020 2020 2020  do {            
+0000cbc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cbd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cbe0: 2020 2020 2020 2020 2020 5c0a 0909 4549            \...EI
+0000cbf0: 4745 4e5f 4153 4d5f 434f 4d4d 454e 5428  GEN_ASM_COMMENT(
+0000cc00: 2262 6567 696e 2073 7465 7020 6f66 2067  "begin step of g
+0000cc10: 6562 7020 6d69 6372 6f20 6b65 726e 656c  ebp micro kernel
+0000cc20: 2031 2f68 616c 662f 7175 6172 7465 7258   1/half/quarterX
+0000cc30: 3122 293b 205c 0a09 0945 4947 454e 5f41  1"); \...EIGEN_A
+0000cc40: 534d 5f43 4f4d 4d45 4e54 2822 4e6f 7465  SM_COMMENT("Note
+0000cc50: 3a20 7468 6573 6520 6173 6d20 636f 6d6d  : these asm comm
+0000cc60: 656e 7473 2077 6f72 6b20 6172 6f75 6e64  ents work around
+0000cc70: 2062 7567 2039 3335 2122 293b 205c 0a20   bug 935!"); \. 
+0000cc80: 2020 202f 2a20 4649 584d 453a 2077 6879     /* FIXME: why
+0000cc90: 2075 6e61 6c69 676e 6564 3f3f 3f3f 202a   unaligned???? *
+0000cca0: 2f20 5c0a 0909 7472 6169 7473 2e6c 6f61  / \...traits.loa
+0000ccb0: 644c 6873 556e 616c 6967 6e65 6428 2662  dLhsUnaligned(&b
+0000ccc0: 6c41 5b28 302b 312a 4b29 2a4c 6873 5072  lA[(0+1*K)*LhsPr
+0000ccd0: 6f67 7265 7373 5d2c 2041 3029 3b20 5c0a  ogress], A0); \.
+0000cce0: 0909 7472 6169 7473 2e6c 6f61 6452 6873  ..traits.loadRhs
+0000ccf0: 2826 626c 425b 2830 2b4b 292a 5268 7350  (&blB[(0+K)*RhsP
+0000cd00: 726f 6772 6573 735d 2c20 425f 3029 3b09  rogress], B_0);.
+0000cd10: 095c 0a09 0974 7261 6974 732e 6d61 6464  .\...traits.madd
+0000cd20: 2841 302c 2042 5f30 2c20 4330 2c20 425f  (A0, B_0, C0, B_
+0000cd30: 302c 2066 6978 3c30 3e29 3b09 0909 095c  0, fix<0>);....\
+0000cd40: 0a09 0945 4947 454e 5f41 534d 5f43 4f4d  ...EIGEN_ASM_COM
+0000cd50: 4d45 4e54 2822 656e 6420 7374 6570 206f  MENT("end step o
+0000cd60: 6620 6765 6270 206d 6963 726f 206b 6572  f gebp micro ker
+0000cd70: 6e65 6c20 312f 6861 6c66 2f71 7561 7274  nel 1/half/quart
+0000cd80: 6572 5831 2229 3b20 5c0a 0920 2020 2020  erX1"); \..     
+0000cd90: 207d 2077 6869 6c65 2866 616c 7365 293b   } while(false);
+0000cda0: 0a0a 2020 2020 2020 2020 2020 4549 4745  ..          EIGE
+0000cdb0: 4e5f 4745 4247 505f 4f4e 4553 5445 5028  N_GEBGP_ONESTEP(
+0000cdc0: 3029 3b0a 2020 2020 2020 2020 2020 4549  0);.          EI
+0000cdd0: 4745 4e5f 4745 4247 505f 4f4e 4553 5445  GEN_GEBGP_ONESTE
+0000cde0: 5028 3129 3b0a 2020 2020 2020 2020 2020  P(1);.          
+0000cdf0: 4549 4745 4e5f 4745 4247 505f 4f4e 4553  EIGEN_GEBGP_ONES
+0000ce00: 5445 5028 3229 3b0a 2020 2020 2020 2020  TEP(2);.        
+0000ce10: 2020 4549 4745 4e5f 4745 4247 505f 4f4e    EIGEN_GEBGP_ON
+0000ce20: 4553 5445 5028 3329 3b0a 2020 2020 2020  ESTEP(3);.      
+0000ce30: 2020 2020 4549 4745 4e5f 4745 4247 505f      EIGEN_GEBGP_
+0000ce40: 4f4e 4553 5445 5028 3429 3b0a 2020 2020  ONESTEP(4);.    
+0000ce50: 2020 2020 2020 4549 4745 4e5f 4745 4247        EIGEN_GEBG
+0000ce60: 505f 4f4e 4553 5445 5028 3529 3b0a 2020  P_ONESTEP(5);.  
+0000ce70: 2020 2020 2020 2020 4549 4745 4e5f 4745          EIGEN_GE
+0000ce80: 4247 505f 4f4e 4553 5445 5028 3629 3b0a  BGP_ONESTEP(6);.
+0000ce90: 2020 2020 2020 2020 2020 4549 4745 4e5f            EIGEN_
+0000cea0: 4745 4247 505f 4f4e 4553 5445 5028 3729  GEBGP_ONESTEP(7)
+0000ceb0: 3b0a 0a20 2020 2020 2020 2020 2062 6c42  ;..          blB
+0000cec0: 202b 3d20 706b 2a52 6873 5072 6f67 7265   += pk*RhsProgre
+0000ced0: 7373 3b0a 2020 2020 2020 2020 2020 626c  ss;.          bl
+0000cee0: 4120 2b3d 2070 6b2a 4c68 7350 726f 6772  A += pk*LhsProgr
+0000cef0: 6573 733b 0a0a 2020 2020 2020 2020 2020  ess;..          
+0000cf00: 4549 4745 4e5f 4153 4d5f 434f 4d4d 454e  EIGEN_ASM_COMMEN
+0000cf10: 5428 2265 6e64 2067 6562 7020 6d69 6372  T("end gebp micr
+0000cf20: 6f20 6b65 726e 656c 2031 2f68 616c 662f  o kernel 1/half/
+0000cf30: 7175 6172 7465 7258 3122 293b 0a20 2020  quarterX1");.   
+0000cf40: 2020 2020 207d 0a0a 2020 2020 2020 2020       }..        
+0000cf50: 2f2f 2070 726f 6365 7373 2072 656d 6169  // process remai
+0000cf60: 6e69 6e67 2070 6565 6c65 6420 6c6f 6f70  ning peeled loop
+0000cf70: 0a20 2020 2020 2020 2066 6f72 2849 6e64  .        for(Ind
+0000cf80: 6578 206b 3d70 6565 6c65 645f 6b63 3b20  ex k=peeled_kc; 
+0000cf90: 6b3c 6465 7074 683b 206b 2b2b 290a 2020  k<depth; k++).  
+0000cfa0: 2020 2020 2020 7b0a 2020 2020 2020 2020        {.        
+0000cfb0: 2020 5268 7350 6163 6b65 7420 425f 303b    RhsPacket B_0;
+0000cfc0: 0a20 2020 2020 2020 2020 2045 4947 454e  .          EIGEN
+0000cfd0: 5f47 4542 4750 5f4f 4e45 5354 4550 2830  _GEBGP_ONESTEP(0
+0000cfe0: 293b 0a20 2020 2020 2020 2020 2062 6c42  );.          blB
+0000cff0: 202b 3d20 5268 7350 726f 6772 6573 733b   += RhsProgress;
+0000d000: 0a20 2020 2020 2020 2020 2062 6c41 202b  .          blA +
+0000d010: 3d20 4c68 7350 726f 6772 6573 733b 0a20  = LhsProgress;. 
+0000d020: 2020 2020 2020 207d 0a23 756e 6465 6620         }.#undef 
+0000d030: 4549 4745 4e5f 4745 4247 505f 4f4e 4553  EIGEN_GEBGP_ONES
+0000d040: 5445 500a 2020 2020 2020 2020 5265 7350  TEP.        ResP
+0000d050: 6163 6b65 7420 5230 3b0a 2020 2020 2020  acket R0;.      
+0000d060: 2020 5265 7350 6163 6b65 7420 616c 7068    ResPacket alph
+0000d070: 6176 203d 2070 7365 7431 3c52 6573 5061  av = pset1<ResPa
+0000d080: 636b 6574 3e28 616c 7068 6129 3b0a 2020  cket>(alpha);.  
+0000d090: 2020 2020 2020 5230 203d 2072 302e 7465        R0 = r0.te
+0000d0a0: 6d70 6c61 7465 206c 6f61 6450 6163 6b65  mplate loadPacke
+0000d0b0: 743c 5265 7350 6163 6b65 743e 2830 293b  t<ResPacket>(0);
+0000d0c0: 0a20 2020 2020 2020 2074 7261 6974 732e  .        traits.
+0000d0d0: 6163 6328 4330 2c20 616c 7068 6176 2c20  acc(C0, alphav, 
+0000d0e0: 5230 293b 0a20 2020 2020 2020 2072 302e  R0);.        r0.
+0000d0f0: 7374 6f72 6550 6163 6b65 7428 302c 2052  storePacket(0, R
+0000d100: 3029 3b0a 2020 2020 2020 7d0a 2020 2020  0);.      }.    
+0000d110: 7d0a 2020 7d0a 7d3b 0a0a 7465 6d70 6c61  }.  }.};..templa
+0000d120: 7465 3c69 6e74 206e 722c 2049 6e64 6578  te<int nr, Index
+0000d130: 204c 6873 5072 6f67 7265 7373 2c20 496e   LhsProgress, In
+0000d140: 6465 7820 5268 7350 726f 6772 6573 732c  dex RhsProgress,
+0000d150: 2074 7970 656e 616d 6520 4c68 7353 6361   typename LhsSca
+0000d160: 6c61 722c 2074 7970 656e 616d 6520 5268  lar, typename Rh
+0000d170: 7353 6361 6c61 722c 2074 7970 656e 616d  sScalar, typenam
+0000d180: 6520 5265 7353 6361 6c61 722c 2074 7970  e ResScalar, typ
+0000d190: 656e 616d 6520 4163 6350 6163 6b65 742c  ename AccPacket,
+0000d1a0: 2074 7970 656e 616d 6520 4c68 7350 6163   typename LhsPac
+0000d1b0: 6b65 742c 2074 7970 656e 616d 6520 5268  ket, typename Rh
+0000d1c0: 7350 6163 6b65 742c 2074 7970 656e 616d  sPacket, typenam
+0000d1d0: 6520 5265 7350 6163 6b65 742c 2074 7970  e ResPacket, typ
+0000d1e0: 656e 616d 6520 4745 4250 5472 6169 7473  ename GEBPTraits
+0000d1f0: 2c20 7479 7065 6e61 6d65 204c 696e 6561  , typename Linea
+0000d200: 724d 6170 7065 722c 2074 7970 656e 616d  rMapper, typenam
+0000d210: 6520 4461 7461 4d61 7070 6572 3e0a 7374  e DataMapper>.st
+0000d220: 7275 6374 206c 6873 5f70 726f 6365 7373  ruct lhs_process
+0000d230: 5f66 7261 6374 696f 6e5f 6f66 5f70 6163  _fraction_of_pac
+0000d240: 6b65 7420 3a20 6c68 735f 7072 6f63 6573  ket : lhs_proces
+0000d250: 735f 6f6e 655f 7061 636b 6574 3c6e 722c  s_one_packet<nr,
+0000d260: 204c 6873 5072 6f67 7265 7373 2c20 5268   LhsProgress, Rh
+0000d270: 7350 726f 6772 6573 732c 204c 6873 5363  sProgress, LhsSc
+0000d280: 616c 6172 2c20 5268 7353 6361 6c61 722c  alar, RhsScalar,
+0000d290: 2052 6573 5363 616c 6172 2c20 4163 6350   ResScalar, AccP
+0000d2a0: 6163 6b65 742c 204c 6873 5061 636b 6574  acket, LhsPacket
+0000d2b0: 2c20 5268 7350 6163 6b65 742c 2052 6573  , RhsPacket, Res
+0000d2c0: 5061 636b 6574 2c20 4745 4250 5472 6169  Packet, GEBPTrai
+0000d2d0: 7473 2c20 4c69 6e65 6172 4d61 7070 6572  ts, LinearMapper
+0000d2e0: 2c20 4461 7461 4d61 7070 6572 3e0a 7b0a  , DataMapper>.{.
+0000d2f0: 0a45 4947 454e 5f53 5452 4f4e 475f 494e  .EIGEN_STRONG_IN
+0000d300: 4c49 4e45 2076 6f69 6420 7065 656c 6564  LINE void peeled
+0000d310: 5f6b 635f 6f6e 6573 7465 7028 496e 6465  _kc_onestep(Inde
+0000d320: 7820 4b2c 2063 6f6e 7374 204c 6873 5363  x K, const LhsSc
+0000d330: 616c 6172 2a20 626c 412c 2063 6f6e 7374  alar* blA, const
+0000d340: 2052 6873 5363 616c 6172 2a20 626c 422c   RhsScalar* blB,
+0000d350: 2047 4542 5054 7261 6974 7320 7472 6169   GEBPTraits trai
+0000d360: 7473 2c20 4c68 7350 6163 6b65 7420 2a41  ts, LhsPacket *A
+0000d370: 302c 2052 6873 5061 636b 6574 202a 425f  0, RhsPacket *B_
+0000d380: 302c 2052 6873 5061 636b 6574 202a 4231  0, RhsPacket *B1
+0000d390: 2c20 5268 7350 6163 6b65 7420 2a42 322c  , RhsPacket *B2,
+0000d3a0: 2052 6873 5061 636b 6574 202a 4233 2c20   RhsPacket *B3, 
+0000d3b0: 4163 6350 6163 6b65 7420 2a43 302c 2041  AccPacket *C0, A
+0000d3c0: 6363 5061 636b 6574 202a 4331 2c20 4163  ccPacket *C1, Ac
+0000d3d0: 6350 6163 6b65 7420 2a43 322c 2041 6363  cPacket *C2, Acc
+0000d3e0: 5061 636b 6574 202a 4333 290a 2020 7b0a  Packet *C3).  {.
+0000d3f0: 2020 2020 2020 2020 4549 4745 4e5f 4153          EIGEN_AS
+0000d400: 4d5f 434f 4d4d 454e 5428 2262 6567 696e  M_COMMENT("begin
+0000d410: 2073 7465 7020 6f66 2067 6562 7020 6d69   step of gebp mi
+0000d420: 6372 6f20 6b65 726e 656c 2031 5834 2229  cro kernel 1X4")
+0000d430: 3b0a 2020 2020 2020 2020 4549 4745 4e5f  ;.        EIGEN_
+0000d440: 4153 4d5f 434f 4d4d 454e 5428 224e 6f74  ASM_COMMENT("Not
+0000d450: 653a 2074 6865 7365 2061 736d 2063 6f6d  e: these asm com
+0000d460: 6d65 6e74 7320 776f 726b 2061 726f 756e  ments work aroun
+0000d470: 6420 6275 6720 3933 3521 2229 3b0a 2020  d bug 935!");.  
+0000d480: 2020 2020 2020 7472 6169 7473 2e6c 6f61        traits.loa
+0000d490: 644c 6873 556e 616c 6967 6e65 6428 2662  dLhsUnaligned(&b
+0000d4a0: 6c41 5b28 302b 312a 4b29 2a28 4c68 7350  lA[(0+1*K)*(LhsP
+0000d4b0: 726f 6772 6573 7329 5d2c 202a 4130 293b  rogress)], *A0);
+0000d4c0: 0a20 2020 2020 2020 2074 7261 6974 732e  .        traits.
+0000d4d0: 6272 6f61 6463 6173 7452 6873 2826 626c  broadcastRhs(&bl
+0000d4e0: 425b 2830 2b34 2a4b 292a 5268 7350 726f  B[(0+4*K)*RhsPro
+0000d4f0: 6772 6573 735d 2c20 2a42 5f30 2c20 2a42  gress], *B_0, *B
+0000d500: 312c 202a 4232 2c20 2a42 3329 3b0a 2020  1, *B2, *B3);.  
+0000d510: 2020 2020 2020 7472 6169 7473 2e6d 6164        traits.mad
+0000d520: 6428 2a41 302c 202a 425f 302c 202a 4330  d(*A0, *B_0, *C0
+0000d530: 2c20 2a42 5f30 293b 0a20 2020 2020 2020  , *B_0);.       
+0000d540: 2074 7261 6974 732e 6d61 6464 282a 4130   traits.madd(*A0
+0000d550: 2c20 2a42 312c 2020 2a43 312c 202a 4231  , *B1,  *C1, *B1
+0000d560: 293b 0a20 2020 2020 2020 2074 7261 6974  );.        trait
+0000d570: 732e 6d61 6464 282a 4130 2c20 2a42 322c  s.madd(*A0, *B2,
+0000d580: 2020 2a43 322c 202a 4232 293b 0a20 2020    *C2, *B2);.   
+0000d590: 2020 2020 2074 7261 6974 732e 6d61 6464       traits.madd
+0000d5a0: 282a 4130 2c20 2a42 332c 2020 2a43 332c  (*A0, *B3,  *C3,
+0000d5b0: 202a 4233 293b 0a20 2020 2020 2020 2045   *B3);.        E
+0000d5c0: 4947 454e 5f41 534d 5f43 4f4d 4d45 4e54  IGEN_ASM_COMMENT
+0000d5d0: 2822 656e 6420 7374 6570 206f 6620 6765  ("end step of ge
+0000d5e0: 6270 206d 6963 726f 206b 6572 6e65 6c20  bp micro kernel 
+0000d5f0: 3158 3422 293b 0a20 207d 0a7d 3b0a 0a74  1X4");.  }.};..t
+0000d600: 656d 706c 6174 653c 7479 7065 6e61 6d65  emplate<typename
+0000d610: 204c 6873 5363 616c 6172 2c20 7479 7065   LhsScalar, type
+0000d620: 6e61 6d65 2052 6873 5363 616c 6172 2c20  name RhsScalar, 
+0000d630: 7479 7065 6e61 6d65 2049 6e64 6578 2c20  typename Index, 
+0000d640: 7479 7065 6e61 6d65 2044 6174 614d 6170  typename DataMap
+0000d650: 7065 722c 2069 6e74 206d 722c 2069 6e74  per, int mr, int
+0000d660: 206e 722c 2062 6f6f 6c20 436f 6e6a 7567   nr, bool Conjug
+0000d670: 6174 654c 6873 2c20 626f 6f6c 2043 6f6e  ateLhs, bool Con
+0000d680: 6a75 6761 7465 5268 733e 0a45 4947 454e  jugateRhs>.EIGEN
+0000d690: 5f44 4f4e 545f 494e 4c49 4e45 0a76 6f69  _DONT_INLINE.voi
+0000d6a0: 6420 6765 6270 5f6b 6572 6e65 6c3c 4c68  d gebp_kernel<Lh
+0000d6b0: 7353 6361 6c61 722c 5268 7353 6361 6c61  sScalar,RhsScala
+0000d6c0: 722c 496e 6465 782c 4461 7461 4d61 7070  r,Index,DataMapp
+0000d6d0: 6572 2c6d 722c 6e72 2c43 6f6e 6a75 6761  er,mr,nr,Conjuga
+0000d6e0: 7465 4c68 732c 436f 6e6a 7567 6174 6552  teLhs,ConjugateR
+0000d6f0: 6873 3e0a 2020 3a3a 6f70 6572 6174 6f72  hs>.  ::operator
+0000d700: 2829 2863 6f6e 7374 2044 6174 614d 6170  ()(const DataMap
+0000d710: 7065 7226 2072 6573 2c20 636f 6e73 7420  per& res, const 
+0000d720: 4c68 7353 6361 6c61 722a 2062 6c6f 636b  LhsScalar* block
+0000d730: 412c 2063 6f6e 7374 2052 6873 5363 616c  A, const RhsScal
+0000d740: 6172 2a20 626c 6f63 6b42 2c0a 2020 2020  ar* blockB,.    
+0000d750: 2020 2020 2020 2020 2020 2049 6e64 6578             Index
+0000d760: 2072 6f77 732c 2049 6e64 6578 2064 6570   rows, Index dep
+0000d770: 7468 2c20 496e 6465 7820 636f 6c73 2c20  th, Index cols, 
+0000d780: 5265 7353 6361 6c61 7220 616c 7068 612c  ResScalar alpha,
+0000d790: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000d7a0: 496e 6465 7820 7374 7269 6465 412c 2049  Index strideA, I
+0000d7b0: 6e64 6578 2073 7472 6964 6542 2c20 496e  ndex strideB, In
+0000d7c0: 6465 7820 6f66 6673 6574 412c 2049 6e64  dex offsetA, Ind
+0000d7d0: 6578 206f 6666 7365 7442 290a 2020 7b0a  ex offsetB).  {.
+0000d7e0: 2020 2020 5472 6169 7473 2074 7261 6974      Traits trait
+0000d7f0: 733b 0a20 2020 2053 7761 7070 6564 5472  s;.    SwappedTr
+0000d800: 6169 7473 2073 7472 6169 7473 3b0a 2020  aits straits;.  
+0000d810: 2020 0a20 2020 2069 6628 7374 7269 6465    .    if(stride
+0000d820: 413d 3d2d 3129 2073 7472 6964 6541 203d  A==-1) strideA =
+0000d830: 2064 6570 7468 3b0a 2020 2020 6966 2873   depth;.    if(s
+0000d840: 7472 6964 6542 3d3d 2d31 2920 7374 7269  trideB==-1) stri
+0000d850: 6465 4220 3d20 6465 7074 683b 0a20 2020  deB = depth;.   
+0000d860: 2063 6f6e 6a5f 6865 6c70 6572 3c4c 6873   conj_helper<Lhs
+0000d870: 5363 616c 6172 2c52 6873 5363 616c 6172  Scalar,RhsScalar
+0000d880: 2c43 6f6e 6a75 6761 7465 4c68 732c 436f  ,ConjugateLhs,Co
+0000d890: 6e6a 7567 6174 6552 6873 3e20 636a 3b0a  njugateRhs> cj;.
+0000d8a0: 2020 2020 496e 6465 7820 7061 636b 6574      Index packet
+0000d8b0: 5f63 6f6c 7334 203d 206e 723e 3d34 203f  _cols4 = nr>=4 ?
+0000d8c0: 2028 636f 6c73 2f34 2920 2a20 3420 3a20   (cols/4) * 4 : 
+0000d8d0: 303b 0a20 2020 2063 6f6e 7374 2049 6e64  0;.    const Ind
+0000d8e0: 6578 2070 6565 6c65 645f 6d63 3320 3d20  ex peeled_mc3 = 
+0000d8f0: 6d72 3e3d 332a 5472 6169 7473 3a3a 4c68  mr>=3*Traits::Lh
+0000d900: 7350 726f 6772 6573 7320 3f20 2872 6f77  sProgress ? (row
+0000d910: 732f 2833 2a4c 6873 5072 6f67 7265 7373  s/(3*LhsProgress
+0000d920: 2929 2a28 332a 4c68 7350 726f 6772 6573  ))*(3*LhsProgres
+0000d930: 7329 203a 2030 3b0a 2020 2020 636f 6e73  s) : 0;.    cons
+0000d940: 7420 496e 6465 7820 7065 656c 6564 5f6d  t Index peeled_m
+0000d950: 6332 203d 206d 723e 3d32 2a54 7261 6974  c2 = mr>=2*Trait
+0000d960: 733a 3a4c 6873 5072 6f67 7265 7373 203f  s::LhsProgress ?
+0000d970: 2070 6565 6c65 645f 6d63 332b 2828 726f   peeled_mc3+((ro
+0000d980: 7773 2d70 6565 6c65 645f 6d63 3329 2f28  ws-peeled_mc3)/(
+0000d990: 322a 4c68 7350 726f 6772 6573 7329 292a  2*LhsProgress))*
+0000d9a0: 2832 2a4c 6873 5072 6f67 7265 7373 2920  (2*LhsProgress) 
+0000d9b0: 3a20 303b 0a20 2020 2063 6f6e 7374 2049  : 0;.    const I
+0000d9c0: 6e64 6578 2070 6565 6c65 645f 6d63 3120  ndex peeled_mc1 
+0000d9d0: 3d20 6d72 3e3d 312a 5472 6169 7473 3a3a  = mr>=1*Traits::
+0000d9e0: 4c68 7350 726f 6772 6573 7320 3f20 7065  LhsProgress ? pe
+0000d9f0: 656c 6564 5f6d 6332 2b28 2872 6f77 732d  eled_mc2+((rows-
+0000da00: 7065 656c 6564 5f6d 6332 292f 2831 2a4c  peeled_mc2)/(1*L
+0000da10: 6873 5072 6f67 7265 7373 2929 2a28 312a  hsProgress))*(1*
+0000da20: 4c68 7350 726f 6772 6573 7329 203a 2030  LhsProgress) : 0
+0000da30: 3b0a 2020 2020 636f 6e73 7420 496e 6465  ;.    const Inde
+0000da40: 7820 7065 656c 6564 5f6d 635f 6861 6c66  x peeled_mc_half
+0000da50: 203d 206d 723e 3d4c 6873 5072 6f67 7265   = mr>=LhsProgre
+0000da60: 7373 4861 6c66 203f 2070 6565 6c65 645f  ssHalf ? peeled_
+0000da70: 6d63 312b 2828 726f 7773 2d70 6565 6c65  mc1+((rows-peele
+0000da80: 645f 6d63 3129 2f28 4c68 7350 726f 6772  d_mc1)/(LhsProgr
+0000da90: 6573 7348 616c 6629 292a 284c 6873 5072  essHalf))*(LhsPr
+0000daa0: 6f67 7265 7373 4861 6c66 2920 3a20 303b  ogressHalf) : 0;
+0000dab0: 0a20 2020 2063 6f6e 7374 2049 6e64 6578  .    const Index
+0000dac0: 2070 6565 6c65 645f 6d63 5f71 7561 7274   peeled_mc_quart
+0000dad0: 6572 203d 206d 723e 3d4c 6873 5072 6f67  er = mr>=LhsProg
+0000dae0: 7265 7373 5175 6172 7465 7220 3f20 7065  ressQuarter ? pe
+0000daf0: 656c 6564 5f6d 635f 6861 6c66 2b28 2872  eled_mc_half+((r
+0000db00: 6f77 732d 7065 656c 6564 5f6d 635f 6861  ows-peeled_mc_ha
+0000db10: 6c66 292f 284c 6873 5072 6f67 7265 7373  lf)/(LhsProgress
+0000db20: 5175 6172 7465 7229 292a 284c 6873 5072  Quarter))*(LhsPr
+0000db30: 6f67 7265 7373 5175 6172 7465 7229 203a  ogressQuarter) :
+0000db40: 2030 3b0a 2020 2020 656e 756d 207b 2070   0;.    enum { p
+0000db50: 6b20 3d20 3820 7d3b 202f 2f20 4e4f 5445  k = 8 }; // NOTE
+0000db60: 2053 7563 6820 6120 6c61 7267 6520 7065   Such a large pe
+0000db70: 656c 696e 6720 6661 6374 6f72 2069 7320  eling factor is 
+0000db80: 696d 706f 7274 616e 7420 666f 7220 6c61  important for la
+0000db90: 7267 6520 6d61 7472 6963 6573 2028 7e20  rge matrices (~ 
+0000dba0: 2b35 2520 7768 656e 203e 3130 3030 206f  +5% when >1000 o
+0000dbb0: 6e20 4861 7377 656c 6c29 0a20 2020 2063  n Haswell).    c
+0000dbc0: 6f6e 7374 2049 6e64 6578 2070 6565 6c65  onst Index peele
+0000dbd0: 645f 6b63 2020 3d20 6465 7074 6820 2620  d_kc  = depth & 
+0000dbe0: 7e28 706b 2d31 293b 0a20 2020 2063 6f6e  ~(pk-1);.    con
+0000dbf0: 7374 2069 6e74 2070 7265 6665 7463 685f  st int prefetch_
+0000dc00: 7265 735f 6f66 6673 6574 203d 2033 322f  res_offset = 32/
+0000dc10: 7369 7a65 6f66 2852 6573 5363 616c 6172  sizeof(ResScalar
+0000dc20: 293b 2020 2020 0a2f 2f20 2020 2020 636f  );    .//     co
+0000dc30: 6e73 7420 496e 6465 7820 6465 7074 6832  nst Index depth2
+0000dc40: 2020 2020 203d 2064 6570 7468 2026 207e       = depth & ~
+0000dc50: 313b 0a0a 2020 2020 2f2f 2d2d 2d2d 2d2d  1;..    //------
+0000dc60: 2d2d 2d2d 2050 726f 6365 7373 2033 202a  ---- Process 3 *
+0000dc70: 204c 6873 5072 6f67 7265 7373 2072 6f77   LhsProgress row
+0000dc80: 7320 6174 206f 6e63 6520 2d2d 2d2d 2d2d  s at once ------
+0000dc90: 2d2d 2d2d 0a20 2020 202f 2f20 5468 6973  ----.    // This
+0000dca0: 2063 6f72 7265 7370 6f6e 6473 2074 6f20   corresponds to 
+0000dcb0: 332a 4c68 7350 726f 6772 6573 7320 7820  3*LhsProgress x 
+0000dcc0: 6e72 2072 6567 6973 7465 7220 626c 6f63  nr register bloc
+0000dcd0: 6b73 2e0a 2020 2020 2f2f 2055 7375 616c  ks..    // Usual
+0000dce0: 6c79 2c20 6d61 6b65 2073 656e 7365 206f  ly, make sense o
+0000dcf0: 6e6c 7920 7769 7468 2046 4d41 0a20 2020  nly with FMA.   
+0000dd00: 2069 6628 6d72 3e3d 332a 5472 6169 7473   if(mr>=3*Traits
+0000dd10: 3a3a 4c68 7350 726f 6772 6573 7329 0a20  ::LhsProgress). 
+0000dd20: 2020 207b 0a20 2020 2020 202f 2f20 4865     {.      // He
+0000dd30: 7265 2c20 7468 6520 6765 6e65 7261 6c20  re, the general 
+0000dd40: 6964 6561 2069 7320 746f 206c 6f6f 7020  idea is to loop 
+0000dd50: 6f6e 2065 6163 6820 6c61 7267 6573 7420  on each largest 
+0000dd60: 6d69 6372 6f20 686f 7269 7a6f 6e74 616c  micro horizontal
+0000dd70: 2070 616e 656c 206f 6620 7468 6520 6c68   panel of the lh
+0000dd80: 7320 2833 2a54 7261 6974 733a 3a4c 6873  s (3*Traits::Lhs
+0000dd90: 5072 6f67 7265 7373 2078 2064 6570 7468  Progress x depth
+0000dda0: 290a 2020 2020 2020 2f2f 2061 6e64 206f  ).      // and o
+0000ddb0: 6e20 6561 6368 206c 6172 6765 7374 206d  n each largest m
+0000ddc0: 6963 726f 2076 6572 7469 6361 6c20 7061  icro vertical pa
+0000ddd0: 6e65 6c20 6f66 2074 6865 2072 6873 2028  nel of the rhs (
+0000dde0: 6465 7074 6820 2a20 6e72 292e 0a20 2020  depth * nr)..   
+0000ddf0: 2020 202f 2f20 426c 6f63 6b69 6e67 2073     // Blocking s
+0000de00: 697a 6573 2c20 692e 652e 2c20 2764 6570  izes, i.e., 'dep
+0000de10: 7468 2720 6861 7320 6265 656e 2063 6f6d  th' has been com
+0000de20: 7075 7465 6420 736f 2074 6861 7420 7468  puted so that th
+0000de30: 6520 6d69 6372 6f20 686f 7269 7a6f 6e74  e micro horizont
+0000de40: 616c 2070 616e 656c 206f 6620 7468 6520  al panel of the 
+0000de50: 6c68 7320 6669 7420 696e 204c 312e 0a20  lhs fit in L1.. 
+0000de60: 2020 2020 202f 2f20 486f 7765 7665 722c       // However,
+0000de70: 2069 6620 6465 7074 6820 6973 2074 6f6f   if depth is too
+0000de80: 2073 6d61 6c6c 2c20 7765 2063 616e 2065   small, we can e
+0000de90: 7874 656e 6420 7468 6520 6e75 6d62 6572  xtend the number
+0000dea0: 206f 6620 726f 7773 206f 6620 7468 6573   of rows of thes
+0000deb0: 6520 686f 7269 7a6f 6e74 616c 2070 616e  e horizontal pan
+0000dec0: 656c 732e 0a20 2020 2020 202f 2f20 5468  els..      // Th
+0000ded0: 6973 2061 6374 7561 6c20 6e75 6d62 6572  is actual number
+0000dee0: 206f 6620 726f 7773 2069 7320 636f 6d70   of rows is comp
+0000def0: 7574 6564 2061 7320 666f 6c6c 6f77 3a0a  uted as follow:.
+0000df00: 2020 2020 2020 636f 6e73 7420 496e 6465        const Inde
+0000df10: 7820 6c31 203d 2064 6566 6175 6c74 4c31  x l1 = defaultL1
+0000df20: 4361 6368 6553 697a 653b 202f 2f20 696e  CacheSize; // in
+0000df30: 2042 7974 6573 2c20 544f 444f 2c20 6c31   Bytes, TODO, l1
+0000df40: 2073 686f 756c 6420 6265 2070 6173 7365   should be passe
+0000df50: 6420 746f 2074 6869 7320 6675 6e63 7469  d to this functi
+0000df60: 6f6e 2e0a 2020 2020 2020 2f2f 2054 6865  on..      // The
+0000df70: 206d 6178 2831 2c20 2e2e 2e29 2068 6572   max(1, ...) her
+0000df80: 6520 6973 206e 6565 6465 6420 6265 6361  e is needed beca
+0000df90: 7573 6520 7765 206d 6179 2062 6520 7573  use we may be us
+0000dfa0: 696e 6720 626c 6f63 6b69 6e67 2070 6172  ing blocking par
+0000dfb0: 616d 7320 6c61 7267 6572 2074 6861 6e20  ams larger than 
+0000dfc0: 7768 6174 206f 7572 206b 6e6f 776e 206c  what our known l
+0000dfd0: 3120 6361 6368 6520 7369 7a65 0a20 2020  1 cache size.   
+0000dfe0: 2020 202f 2f20 7375 6767 6573 7473 2077     // suggests w
+0000dff0: 6520 7368 6f75 6c64 2062 6520 7573 696e  e should be usin
+0000e000: 673a 2065 6974 6865 7220 6265 6361 7573  g: either becaus
+0000e010: 6520 6f75 7220 6b6e 6f77 6e20 6c31 2063  e our known l1 c
+0000e020: 6163 6865 2073 697a 6520 6973 2069 6e61  ache size is ina
+0000e030: 6363 7572 6174 6520 2865 2e67 2e20 6f6e  ccurate (e.g. on
+0000e040: 2041 6e64 726f 6964 2c20 7765 2063 616e   Android, we can
+0000e050: 206f 6e6c 7920 6775 6573 7329 2c0a 2020   only guess),.  
+0000e060: 2020 2020 2f2f 206f 7220 6265 6361 7573      // or becaus
+0000e070: 6520 7765 2061 7265 2074 6573 7469 6e67  e we are testing
+0000e080: 2073 7065 6369 6669 6320 626c 6f63 6b69   specific blocki
+0000e090: 6e67 2073 697a 6573 2e0a 2020 2020 2020  ng sizes..      
+0000e0a0: 636f 6e73 7420 496e 6465 7820 6163 7475  const Index actu
+0000e0b0: 616c 5f70 616e 656c 5f72 6f77 7320 3d20  al_panel_rows = 
+0000e0c0: 2833 2a4c 6873 5072 6f67 7265 7373 2920  (3*LhsProgress) 
+0000e0d0: 2a20 7374 643a 3a6d 6178 3c49 6e64 6578  * std::max<Index
+0000e0e0: 3e28 312c 2820 286c 3120 2d20 7369 7a65  >(1,( (l1 - size
+0000e0f0: 6f66 2852 6573 5363 616c 6172 292a 6d72  of(ResScalar)*mr
+0000e100: 2a6e 7220 2d20 6465 7074 682a 6e72 2a73  *nr - depth*nr*s
+0000e110: 697a 656f 6628 5268 7353 6361 6c61 7229  izeof(RhsScalar)
+0000e120: 2920 2f20 2864 6570 7468 202a 2073 697a  ) / (depth * siz
+0000e130: 656f 6628 4c68 7353 6361 6c61 7229 202a  eof(LhsScalar) *
+0000e140: 2033 2a4c 6873 5072 6f67 7265 7373 2920   3*LhsProgress) 
+0000e150: 2929 3b0a 2020 2020 2020 666f 7228 496e  ));.      for(In
+0000e160: 6465 7820 6931 3d30 3b20 6931 3c70 6565  dex i1=0; i1<pee
+0000e170: 6c65 645f 6d63 333b 2069 312b 3d61 6374  led_mc3; i1+=act
+0000e180: 7561 6c5f 7061 6e65 6c5f 726f 7773 290a  ual_panel_rows).
+0000e190: 2020 2020 2020 7b0a 2020 2020 2020 2020        {.        
+0000e1a0: 636f 6e73 7420 496e 6465 7820 6163 7475  const Index actu
+0000e1b0: 616c 5f70 616e 656c 5f65 6e64 203d 2028  al_panel_end = (
+0000e1c0: 7374 643a 3a6d 696e 2928 6931 2b61 6374  std::min)(i1+act
+0000e1d0: 7561 6c5f 7061 6e65 6c5f 726f 7773 2c20  ual_panel_rows, 
+0000e1e0: 7065 656c 6564 5f6d 6333 293b 0a20 2020  peeled_mc3);.   
+0000e1f0: 2020 2020 2066 6f72 2849 6e64 6578 206a       for(Index j
+0000e200: 323d 303b 206a 323c 7061 636b 6574 5f63  2=0; j2<packet_c
+0000e210: 6f6c 7334 3b20 6a32 2b3d 6e72 290a 2020  ols4; j2+=nr).  
+0000e220: 2020 2020 2020 7b0a 2020 2020 2020 2020        {.        
+0000e230: 2020 666f 7228 496e 6465 7820 693d 6931    for(Index i=i1
+0000e240: 3b20 693c 6163 7475 616c 5f70 616e 656c  ; i<actual_panel
+0000e250: 5f65 6e64 3b20 692b 3d33 2a4c 6873 5072  _end; i+=3*LhsPr
+0000e260: 6f67 7265 7373 290a 2020 2020 2020 2020  ogress).        
+0000e270: 2020 7b0a 2020 2020 2020 2020 2020 0a20    {.          . 
+0000e280: 2020 2020 2020 2020 202f 2f20 5765 2073           // We s
+0000e290: 656c 6563 7465 6420 6120 332a 5472 6169  elected a 3*Trai
+0000e2a0: 7473 3a3a 4c68 7350 726f 6772 6573 7320  ts::LhsProgress 
+0000e2b0: 7820 6e72 206d 6963 726f 2062 6c6f 636b  x nr micro block
+0000e2c0: 206f 6620 7265 7320 7768 6963 6820 6973   of res which is
+0000e2d0: 2065 6e74 6972 656c 790a 2020 2020 2020   entirely.      
+0000e2e0: 2020 2020 2f2f 2073 746f 7265 6420 696e      // stored in
+0000e2f0: 746f 2033 2078 206e 7220 7265 6769 7374  to 3 x nr regist
+0000e300: 6572 732e 0a20 2020 2020 2020 2020 200a  ers..          .
+0000e310: 2020 2020 2020 2020 2020 636f 6e73 7420            const 
+0000e320: 4c68 7353 6361 6c61 722a 2062 6c41 203d  LhsScalar* blA =
+0000e330: 2026 626c 6f63 6b41 5b69 2a73 7472 6964   &blockA[i*strid
+0000e340: 6541 2b6f 6666 7365 7441 2a28 332a 4c68  eA+offsetA*(3*Lh
+0000e350: 7350 726f 6772 6573 7329 5d3b 0a20 2020  sProgress)];.   
+0000e360: 2020 2020 2020 2070 7265 6665 7463 6828         prefetch(
+0000e370: 2662 6c41 5b30 5d29 3b0a 0a20 2020 2020  &blA[0]);..     
+0000e380: 2020 2020 202f 2f20 6765 7473 2072 6573       // gets res
+0000e390: 2062 6c6f 636b 2061 7320 7265 6769 7374   block as regist
+0000e3a0: 6572 0a20 2020 2020 2020 2020 2041 6363  er.          Acc
+0000e3b0: 5061 636b 6574 2043 302c 2043 312c 2043  Packet C0, C1, C
+0000e3c0: 322c 2020 4333 2c0a 2020 2020 2020 2020  2,  C3,.        
+0000e3d0: 2020 2020 2020 2020 2020 2020 4334 2c20              C4, 
+0000e3e0: 4335 2c20 4336 2c20 2043 372c 0a20 2020  C5, C6,  C7,.   
 0000e3f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e400: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e410: 2020 2020 2020 205c 0a09 2020 2020 2020         \..      
-0000e420: 646f 207b 2020 2020 2020 2020 2020 2020  do {            
-0000e430: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e440: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000e450: 2020 2020 2020 2020 2020 5c0a 0909 4549            \...EI
-0000e460: 4745 4e5f 4153 4d5f 434f 4d4d 454e 5428  GEN_ASM_COMMENT(
-0000e470: 2262 6567 696e 2073 7465 7020 6f66 2067  "begin step of g
-0000e480: 6562 7020 6d69 6372 6f20 6b65 726e 656c  ebp micro kernel
-0000e490: 2031 2f68 616c 662f 7175 6172 7465 7258   1/half/quarterX
-0000e4a0: 3122 293b 205c 0a09 0945 4947 454e 5f41  1"); \...EIGEN_A
-0000e4b0: 534d 5f43 4f4d 4d45 4e54 2822 4e6f 7465  SM_COMMENT("Note
-0000e4c0: 3a20 7468 6573 6520 6173 6d20 636f 6d6d  : these asm comm
-0000e4d0: 656e 7473 2077 6f72 6b20 6172 6f75 6e64  ents work around
-0000e4e0: 2062 7567 2039 3335 2122 293b 205c 0a20   bug 935!"); \. 
-0000e4f0: 2020 202f 2a20 4649 584d 453a 2077 6879     /* FIXME: why
-0000e500: 2075 6e61 6c69 676e 6564 3f3f 3f3f 202a   unaligned???? *
-0000e510: 2f20 5c0a 0909 7472 6169 7473 2e6c 6f61  / \...traits.loa
-0000e520: 644c 6873 556e 616c 6967 6e65 6428 2662  dLhsUnaligned(&b
-0000e530: 6c41 5b28 302b 312a 4b29 2a4c 6873 5072  lA[(0+1*K)*LhsPr
-0000e540: 6f67 7265 7373 5d2c 2041 3029 3b20 5c0a  ogress], A0); \.
-0000e550: 0909 7472 6169 7473 2e6c 6f61 6452 6873  ..traits.loadRhs
-0000e560: 2826 626c 425b 2830 2b4b 292a 5268 7350  (&blB[(0+K)*RhsP
-0000e570: 726f 6772 6573 735d 2c20 425f 3029 3b09  rogress], B_0);.
-0000e580: 095c 0a09 0974 7261 6974 732e 6d61 6464  .\...traits.madd
-0000e590: 2841 302c 2042 5f30 2c20 4330 2c20 425f  (A0, B_0, C0, B_
-0000e5a0: 302c 2066 6978 3c30 3e29 3b09 0909 095c  0, fix<0>);....\
-0000e5b0: 0a09 0945 4947 454e 5f41 534d 5f43 4f4d  ...EIGEN_ASM_COM
-0000e5c0: 4d45 4e54 2822 656e 6420 7374 6570 206f  MENT("end step o
-0000e5d0: 6620 6765 6270 206d 6963 726f 206b 6572  f gebp micro ker
-0000e5e0: 6e65 6c20 312f 6861 6c66 2f71 7561 7274  nel 1/half/quart
-0000e5f0: 6572 5831 2229 3b20 5c0a 0920 2020 2020  erX1"); \..     
-0000e600: 207d 2077 6869 6c65 2866 616c 7365 293b   } while(false);
-0000e610: 0a0a 2020 2020 2020 2020 2020 4549 4745  ..          EIGE
-0000e620: 4e5f 4745 4247 505f 4f4e 4553 5445 5028  N_GEBGP_ONESTEP(
-0000e630: 3029 3b0a 2020 2020 2020 2020 2020 4549  0);.          EI
-0000e640: 4745 4e5f 4745 4247 505f 4f4e 4553 5445  GEN_GEBGP_ONESTE
-0000e650: 5028 3129 3b0a 2020 2020 2020 2020 2020  P(1);.          
-0000e660: 4549 4745 4e5f 4745 4247 505f 4f4e 4553  EIGEN_GEBGP_ONES
-0000e670: 5445 5028 3229 3b0a 2020 2020 2020 2020  TEP(2);.        
-0000e680: 2020 4549 4745 4e5f 4745 4247 505f 4f4e    EIGEN_GEBGP_ON
-0000e690: 4553 5445 5028 3329 3b0a 2020 2020 2020  ESTEP(3);.      
-0000e6a0: 2020 2020 4549 4745 4e5f 4745 4247 505f      EIGEN_GEBGP_
-0000e6b0: 4f4e 4553 5445 5028 3429 3b0a 2020 2020  ONESTEP(4);.    
-0000e6c0: 2020 2020 2020 4549 4745 4e5f 4745 4247        EIGEN_GEBG
-0000e6d0: 505f 4f4e 4553 5445 5028 3529 3b0a 2020  P_ONESTEP(5);.  
-0000e6e0: 2020 2020 2020 2020 4549 4745 4e5f 4745          EIGEN_GE
-0000e6f0: 4247 505f 4f4e 4553 5445 5028 3629 3b0a  BGP_ONESTEP(6);.
-0000e700: 2020 2020 2020 2020 2020 4549 4745 4e5f            EIGEN_
-0000e710: 4745 4247 505f 4f4e 4553 5445 5028 3729  GEBGP_ONESTEP(7)
-0000e720: 3b0a 0a20 2020 2020 2020 2020 2062 6c42  ;..          blB
-0000e730: 202b 3d20 706b 2a52 6873 5072 6f67 7265   += pk*RhsProgre
-0000e740: 7373 3b0a 2020 2020 2020 2020 2020 626c  ss;.          bl
-0000e750: 4120 2b3d 2070 6b2a 4c68 7350 726f 6772  A += pk*LhsProgr
-0000e760: 6573 733b 0a0a 2020 2020 2020 2020 2020  ess;..          
-0000e770: 4549 4745 4e5f 4153 4d5f 434f 4d4d 454e  EIGEN_ASM_COMMEN
-0000e780: 5428 2265 6e64 2067 6562 7020 6d69 6372  T("end gebp micr
-0000e790: 6f20 6b65 726e 656c 2031 2f68 616c 662f  o kernel 1/half/
-0000e7a0: 7175 6172 7465 7258 3122 293b 0a20 2020  quarterX1");.   
-0000e7b0: 2020 2020 207d 0a0a 2020 2020 2020 2020       }..        
-0000e7c0: 2f2f 2070 726f 6365 7373 2072 656d 6169  // process remai
-0000e7d0: 6e69 6e67 2070 6565 6c65 6420 6c6f 6f70  ning peeled loop
-0000e7e0: 0a20 2020 2020 2020 2066 6f72 2849 6e64  .        for(Ind
-0000e7f0: 6578 206b 3d70 6565 6c65 645f 6b63 3b20  ex k=peeled_kc; 
-0000e800: 6b3c 6465 7074 683b 206b 2b2b 290a 2020  k<depth; k++).  
-0000e810: 2020 2020 2020 7b0a 2020 2020 2020 2020        {.        
-0000e820: 2020 5268 7350 6163 6b65 7420 425f 303b    RhsPacket B_0;
-0000e830: 0a20 2020 2020 2020 2020 2045 4947 454e  .          EIGEN
-0000e840: 5f47 4542 4750 5f4f 4e45 5354 4550 2830  _GEBGP_ONESTEP(0
-0000e850: 293b 0a20 2020 2020 2020 2020 2062 6c42  );.          blB
-0000e860: 202b 3d20 5268 7350 726f 6772 6573 733b   += RhsProgress;
-0000e870: 0a20 2020 2020 2020 2020 2062 6c41 202b  .          blA +
-0000e880: 3d20 4c68 7350 726f 6772 6573 733b 0a20  = LhsProgress;. 
-0000e890: 2020 2020 2020 207d 0a23 756e 6465 6620         }.#undef 
-0000e8a0: 4549 4745 4e5f 4745 4247 505f 4f4e 4553  EIGEN_GEBGP_ONES
-0000e8b0: 5445 500a 2020 2020 2020 2020 5265 7350  TEP.        ResP
-0000e8c0: 6163 6b65 7420 5230 3b0a 2020 2020 2020  acket R0;.      
-0000e8d0: 2020 5265 7350 6163 6b65 7420 616c 7068    ResPacket alph
-0000e8e0: 6176 203d 2070 7365 7431 3c52 6573 5061  av = pset1<ResPa
-0000e8f0: 636b 6574 3e28 616c 7068 6129 3b0a 2020  cket>(alpha);.  
-0000e900: 2020 2020 2020 5230 203d 2072 302e 7465        R0 = r0.te
-0000e910: 6d70 6c61 7465 206c 6f61 6450 6163 6b65  mplate loadPacke
-0000e920: 743c 5265 7350 6163 6b65 743e 2830 293b  t<ResPacket>(0);
-0000e930: 0a20 2020 2020 2020 2074 7261 6974 732e  .        traits.
-0000e940: 6163 6328 4330 2c20 616c 7068 6176 2c20  acc(C0, alphav, 
-0000e950: 5230 293b 0a20 2020 2020 2020 2072 302e  R0);.        r0.
-0000e960: 7374 6f72 6550 6163 6b65 7428 302c 2052  storePacket(0, R
-0000e970: 3029 3b0a 2020 2020 2020 7d0a 2020 2020  0);.      }.    
-0000e980: 7d0a 2020 7d0a 7d3b 0a0a 7465 6d70 6c61  }.  }.};..templa
-0000e990: 7465 3c69 6e74 206e 722c 2049 6e64 6578  te<int nr, Index
-0000e9a0: 204c 6873 5072 6f67 7265 7373 2c20 496e   LhsProgress, In
-0000e9b0: 6465 7820 5268 7350 726f 6772 6573 732c  dex RhsProgress,
-0000e9c0: 2074 7970 656e 616d 6520 4c68 7353 6361   typename LhsSca
-0000e9d0: 6c61 722c 2074 7970 656e 616d 6520 5268  lar, typename Rh
-0000e9e0: 7353 6361 6c61 722c 2074 7970 656e 616d  sScalar, typenam
-0000e9f0: 6520 5265 7353 6361 6c61 722c 2074 7970  e ResScalar, typ
-0000ea00: 656e 616d 6520 4163 6350 6163 6b65 742c  ename AccPacket,
-0000ea10: 2074 7970 656e 616d 6520 4c68 7350 6163   typename LhsPac
-0000ea20: 6b65 742c 2074 7970 656e 616d 6520 5268  ket, typename Rh
-0000ea30: 7350 6163 6b65 742c 2074 7970 656e 616d  sPacket, typenam
-0000ea40: 6520 5265 7350 6163 6b65 742c 2074 7970  e ResPacket, typ
-0000ea50: 656e 616d 6520 4745 4250 5472 6169 7473  ename GEBPTraits
-0000ea60: 2c20 7479 7065 6e61 6d65 204c 696e 6561  , typename Linea
-0000ea70: 724d 6170 7065 722c 2074 7970 656e 616d  rMapper, typenam
-0000ea80: 6520 4461 7461 4d61 7070 6572 3e0a 7374  e DataMapper>.st
-0000ea90: 7275 6374 206c 6873 5f70 726f 6365 7373  ruct lhs_process
-0000eaa0: 5f66 7261 6374 696f 6e5f 6f66 5f70 6163  _fraction_of_pac
-0000eab0: 6b65 7420 3a20 6c68 735f 7072 6f63 6573  ket : lhs_proces
-0000eac0: 735f 6f6e 655f 7061 636b 6574 3c6e 722c  s_one_packet<nr,
-0000ead0: 204c 6873 5072 6f67 7265 7373 2c20 5268   LhsProgress, Rh
-0000eae0: 7350 726f 6772 6573 732c 204c 6873 5363  sProgress, LhsSc
-0000eaf0: 616c 6172 2c20 5268 7353 6361 6c61 722c  alar, RhsScalar,
-0000eb00: 2052 6573 5363 616c 6172 2c20 4163 6350   ResScalar, AccP
-0000eb10: 6163 6b65 742c 204c 6873 5061 636b 6574  acket, LhsPacket
-0000eb20: 2c20 5268 7350 6163 6b65 742c 2052 6573  , RhsPacket, Res
-0000eb30: 5061 636b 6574 2c20 4745 4250 5472 6169  Packet, GEBPTrai
-0000eb40: 7473 2c20 4c69 6e65 6172 4d61 7070 6572  ts, LinearMapper
-0000eb50: 2c20 4461 7461 4d61 7070 6572 3e0a 7b0a  , DataMapper>.{.
-0000eb60: 0a45 4947 454e 5f53 5452 4f4e 475f 494e  .EIGEN_STRONG_IN
-0000eb70: 4c49 4e45 2076 6f69 6420 7065 656c 6564  LINE void peeled
-0000eb80: 5f6b 635f 6f6e 6573 7465 7028 496e 6465  _kc_onestep(Inde
-0000eb90: 7820 4b2c 2063 6f6e 7374 204c 6873 5363  x K, const LhsSc
-0000eba0: 616c 6172 2a20 626c 412c 2063 6f6e 7374  alar* blA, const
-0000ebb0: 2052 6873 5363 616c 6172 2a20 626c 422c   RhsScalar* blB,
-0000ebc0: 2047 4542 5054 7261 6974 7320 7472 6169   GEBPTraits trai
-0000ebd0: 7473 2c20 4c68 7350 6163 6b65 7420 2a41  ts, LhsPacket *A
-0000ebe0: 302c 2052 6873 5061 636b 6574 202a 425f  0, RhsPacket *B_
-0000ebf0: 302c 2052 6873 5061 636b 6574 202a 4231  0, RhsPacket *B1
-0000ec00: 2c20 5268 7350 6163 6b65 7420 2a42 322c  , RhsPacket *B2,
-0000ec10: 2052 6873 5061 636b 6574 202a 4233 2c20   RhsPacket *B3, 
-0000ec20: 4163 6350 6163 6b65 7420 2a43 302c 2041  AccPacket *C0, A
-0000ec30: 6363 5061 636b 6574 202a 4331 2c20 4163  ccPacket *C1, Ac
-0000ec40: 6350 6163 6b65 7420 2a43 322c 2041 6363  cPacket *C2, Acc
-0000ec50: 5061 636b 6574 202a 4333 290a 2020 7b0a  Packet *C3).  {.
-0000ec60: 2020 2020 2020 2020 4549 4745 4e5f 4153          EIGEN_AS
-0000ec70: 4d5f 434f 4d4d 454e 5428 2262 6567 696e  M_COMMENT("begin
-0000ec80: 2073 7465 7020 6f66 2067 6562 7020 6d69   step of gebp mi
-0000ec90: 6372 6f20 6b65 726e 656c 2031 5834 2229  cro kernel 1X4")
-0000eca0: 3b0a 2020 2020 2020 2020 4549 4745 4e5f  ;.        EIGEN_
-0000ecb0: 4153 4d5f 434f 4d4d 454e 5428 224e 6f74  ASM_COMMENT("Not
-0000ecc0: 653a 2074 6865 7365 2061 736d 2063 6f6d  e: these asm com
-0000ecd0: 6d65 6e74 7320 776f 726b 2061 726f 756e  ments work aroun
-0000ece0: 6420 6275 6720 3933 3521 2229 3b0a 2020  d bug 935!");.  
-0000ecf0: 2020 2020 2020 7472 6169 7473 2e6c 6f61        traits.loa
-0000ed00: 644c 6873 556e 616c 6967 6e65 6428 2662  dLhsUnaligned(&b
-0000ed10: 6c41 5b28 302b 312a 4b29 2a28 4c68 7350  lA[(0+1*K)*(LhsP
-0000ed20: 726f 6772 6573 7329 5d2c 202a 4130 293b  rogress)], *A0);
-0000ed30: 0a20 2020 2020 2020 2074 7261 6974 732e  .        traits.
-0000ed40: 6272 6f61 6463 6173 7452 6873 2826 626c  broadcastRhs(&bl
-0000ed50: 425b 2830 2b34 2a4b 292a 5268 7350 726f  B[(0+4*K)*RhsPro
-0000ed60: 6772 6573 735d 2c20 2a42 5f30 2c20 2a42  gress], *B_0, *B
-0000ed70: 312c 202a 4232 2c20 2a42 3329 3b0a 2020  1, *B2, *B3);.  
-0000ed80: 2020 2020 2020 7472 6169 7473 2e6d 6164        traits.mad
-0000ed90: 6428 2a41 302c 202a 425f 302c 202a 4330  d(*A0, *B_0, *C0
-0000eda0: 2c20 2a42 5f30 293b 0a20 2020 2020 2020  , *B_0);.       
-0000edb0: 2074 7261 6974 732e 6d61 6464 282a 4130   traits.madd(*A0
-0000edc0: 2c20 2a42 312c 2020 2a43 312c 202a 4231  , *B1,  *C1, *B1
-0000edd0: 293b 0a20 2020 2020 2020 2074 7261 6974  );.        trait
-0000ede0: 732e 6d61 6464 282a 4130 2c20 2a42 322c  s.madd(*A0, *B2,
-0000edf0: 2020 2a43 322c 202a 4232 293b 0a20 2020    *C2, *B2);.   
-0000ee00: 2020 2020 2074 7261 6974 732e 6d61 6464       traits.madd
-0000ee10: 282a 4130 2c20 2a42 332c 2020 2a43 332c  (*A0, *B3,  *C3,
-0000ee20: 202a 4233 293b 0a20 2020 2020 2020 2045   *B3);.        E
-0000ee30: 4947 454e 5f41 534d 5f43 4f4d 4d45 4e54  IGEN_ASM_COMMENT
-0000ee40: 2822 656e 6420 7374 6570 206f 6620 6765  ("end step of ge
-0000ee50: 6270 206d 6963 726f 206b 6572 6e65 6c20  bp micro kernel 
-0000ee60: 3158 3422 293b 0a20 207d 0a7d 3b0a 0a74  1X4");.  }.};..t
-0000ee70: 656d 706c 6174 653c 7479 7065 6e61 6d65  emplate<typename
-0000ee80: 204c 6873 5363 616c 6172 2c20 7479 7065   LhsScalar, type
-0000ee90: 6e61 6d65 2052 6873 5363 616c 6172 2c20  name RhsScalar, 
-0000eea0: 7479 7065 6e61 6d65 2049 6e64 6578 2c20  typename Index, 
-0000eeb0: 7479 7065 6e61 6d65 2044 6174 614d 6170  typename DataMap
-0000eec0: 7065 722c 2069 6e74 206d 722c 2069 6e74  per, int mr, int
-0000eed0: 206e 722c 2062 6f6f 6c20 436f 6e6a 7567   nr, bool Conjug
-0000eee0: 6174 654c 6873 2c20 626f 6f6c 2043 6f6e  ateLhs, bool Con
-0000eef0: 6a75 6761 7465 5268 733e 0a45 4947 454e  jugateRhs>.EIGEN
-0000ef00: 5f44 4f4e 545f 494e 4c49 4e45 0a76 6f69  _DONT_INLINE.voi
-0000ef10: 6420 6765 6270 5f6b 6572 6e65 6c3c 4c68  d gebp_kernel<Lh
-0000ef20: 7353 6361 6c61 722c 5268 7353 6361 6c61  sScalar,RhsScala
-0000ef30: 722c 496e 6465 782c 4461 7461 4d61 7070  r,Index,DataMapp
-0000ef40: 6572 2c6d 722c 6e72 2c43 6f6e 6a75 6761  er,mr,nr,Conjuga
-0000ef50: 7465 4c68 732c 436f 6e6a 7567 6174 6552  teLhs,ConjugateR
-0000ef60: 6873 3e0a 2020 3a3a 6f70 6572 6174 6f72  hs>.  ::operator
-0000ef70: 2829 2863 6f6e 7374 2044 6174 614d 6170  ()(const DataMap
-0000ef80: 7065 7226 2072 6573 2c20 636f 6e73 7420  per& res, const 
-0000ef90: 4c68 7353 6361 6c61 722a 2062 6c6f 636b  LhsScalar* block
-0000efa0: 412c 2063 6f6e 7374 2052 6873 5363 616c  A, const RhsScal
-0000efb0: 6172 2a20 626c 6f63 6b42 2c0a 2020 2020  ar* blockB,.    
-0000efc0: 2020 2020 2020 2020 2020 2049 6e64 6578             Index
-0000efd0: 2072 6f77 732c 2049 6e64 6578 2064 6570   rows, Index dep
-0000efe0: 7468 2c20 496e 6465 7820 636f 6c73 2c20  th, Index cols, 
-0000eff0: 5265 7353 6361 6c61 7220 616c 7068 612c  ResScalar alpha,
-0000f000: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-0000f010: 496e 6465 7820 7374 7269 6465 412c 2049  Index strideA, I
-0000f020: 6e64 6578 2073 7472 6964 6542 2c20 496e  ndex strideB, In
-0000f030: 6465 7820 6f66 6673 6574 412c 2049 6e64  dex offsetA, Ind
-0000f040: 6578 206f 6666 7365 7442 290a 2020 7b0a  ex offsetB).  {.
-0000f050: 2020 2020 5472 6169 7473 2074 7261 6974      Traits trait
-0000f060: 733b 0a20 2020 2053 7761 7070 6564 5472  s;.    SwappedTr
-0000f070: 6169 7473 2073 7472 6169 7473 3b0a 2020  aits straits;.  
-0000f080: 2020 0a20 2020 2069 6628 7374 7269 6465    .    if(stride
-0000f090: 413d 3d2d 3129 2073 7472 6964 6541 203d  A==-1) strideA =
-0000f0a0: 2064 6570 7468 3b0a 2020 2020 6966 2873   depth;.    if(s
-0000f0b0: 7472 6964 6542 3d3d 2d31 2920 7374 7269  trideB==-1) stri
-0000f0c0: 6465 4220 3d20 6465 7074 683b 0a20 2020  deB = depth;.   
-0000f0d0: 2063 6f6e 6a5f 6865 6c70 6572 3c4c 6873   conj_helper<Lhs
-0000f0e0: 5363 616c 6172 2c52 6873 5363 616c 6172  Scalar,RhsScalar
-0000f0f0: 2c43 6f6e 6a75 6761 7465 4c68 732c 436f  ,ConjugateLhs,Co
-0000f100: 6e6a 7567 6174 6552 6873 3e20 636a 3b0a  njugateRhs> cj;.
-0000f110: 2020 2020 496e 6465 7820 7061 636b 6574      Index packet
-0000f120: 5f63 6f6c 7334 203d 206e 723e 3d34 203f  _cols4 = nr>=4 ?
-0000f130: 2028 636f 6c73 2f34 2920 2a20 3420 3a20   (cols/4) * 4 : 
-0000f140: 303b 0a20 2020 2063 6f6e 7374 2049 6e64  0;.    const Ind
-0000f150: 6578 2070 6565 6c65 645f 6d63 3320 3d20  ex peeled_mc3 = 
-0000f160: 6d72 3e3d 332a 5472 6169 7473 3a3a 4c68  mr>=3*Traits::Lh
-0000f170: 7350 726f 6772 6573 7320 3f20 2872 6f77  sProgress ? (row
-0000f180: 732f 2833 2a4c 6873 5072 6f67 7265 7373  s/(3*LhsProgress
-0000f190: 2929 2a28 332a 4c68 7350 726f 6772 6573  ))*(3*LhsProgres
-0000f1a0: 7329 203a 2030 3b0a 2020 2020 636f 6e73  s) : 0;.    cons
-0000f1b0: 7420 496e 6465 7820 7065 656c 6564 5f6d  t Index peeled_m
-0000f1c0: 6332 203d 206d 723e 3d32 2a54 7261 6974  c2 = mr>=2*Trait
-0000f1d0: 733a 3a4c 6873 5072 6f67 7265 7373 203f  s::LhsProgress ?
-0000f1e0: 2070 6565 6c65 645f 6d63 332b 2828 726f   peeled_mc3+((ro
-0000f1f0: 7773 2d70 6565 6c65 645f 6d63 3329 2f28  ws-peeled_mc3)/(
-0000f200: 322a 4c68 7350 726f 6772 6573 7329 292a  2*LhsProgress))*
-0000f210: 2832 2a4c 6873 5072 6f67 7265 7373 2920  (2*LhsProgress) 
-0000f220: 3a20 303b 0a20 2020 2063 6f6e 7374 2049  : 0;.    const I
-0000f230: 6e64 6578 2070 6565 6c65 645f 6d63 3120  ndex peeled_mc1 
-0000f240: 3d20 6d72 3e3d 312a 5472 6169 7473 3a3a  = mr>=1*Traits::
-0000f250: 4c68 7350 726f 6772 6573 7320 3f20 7065  LhsProgress ? pe
-0000f260: 656c 6564 5f6d 6332 2b28 2872 6f77 732d  eled_mc2+((rows-
-0000f270: 7065 656c 6564 5f6d 6332 292f 2831 2a4c  peeled_mc2)/(1*L
-0000f280: 6873 5072 6f67 7265 7373 2929 2a28 312a  hsProgress))*(1*
-0000f290: 4c68 7350 726f 6772 6573 7329 203a 2030  LhsProgress) : 0
-0000f2a0: 3b0a 2020 2020 636f 6e73 7420 496e 6465  ;.    const Inde
-0000f2b0: 7820 7065 656c 6564 5f6d 635f 6861 6c66  x peeled_mc_half
-0000f2c0: 203d 206d 723e 3d4c 6873 5072 6f67 7265   = mr>=LhsProgre
-0000f2d0: 7373 4861 6c66 203f 2070 6565 6c65 645f  ssHalf ? peeled_
-0000f2e0: 6d63 312b 2828 726f 7773 2d70 6565 6c65  mc1+((rows-peele
-0000f2f0: 645f 6d63 3129 2f28 4c68 7350 726f 6772  d_mc1)/(LhsProgr
-0000f300: 6573 7348 616c 6629 292a 284c 6873 5072  essHalf))*(LhsPr
-0000f310: 6f67 7265 7373 4861 6c66 2920 3a20 303b  ogressHalf) : 0;
-0000f320: 0a20 2020 2063 6f6e 7374 2049 6e64 6578  .    const Index
-0000f330: 2070 6565 6c65 645f 6d63 5f71 7561 7274   peeled_mc_quart
-0000f340: 6572 203d 206d 723e 3d4c 6873 5072 6f67  er = mr>=LhsProg
-0000f350: 7265 7373 5175 6172 7465 7220 3f20 7065  ressQuarter ? pe
-0000f360: 656c 6564 5f6d 635f 6861 6c66 2b28 2872  eled_mc_half+((r
-0000f370: 6f77 732d 7065 656c 6564 5f6d 635f 6861  ows-peeled_mc_ha
-0000f380: 6c66 292f 284c 6873 5072 6f67 7265 7373  lf)/(LhsProgress
-0000f390: 5175 6172 7465 7229 292a 284c 6873 5072  Quarter))*(LhsPr
-0000f3a0: 6f67 7265 7373 5175 6172 7465 7229 203a  ogressQuarter) :
-0000f3b0: 2030 3b0a 2020 2020 656e 756d 207b 2070   0;.    enum { p
-0000f3c0: 6b20 3d20 3820 7d3b 202f 2f20 4e4f 5445  k = 8 }; // NOTE
-0000f3d0: 2053 7563 6820 6120 6c61 7267 6520 7065   Such a large pe
-0000f3e0: 656c 696e 6720 6661 6374 6f72 2069 7320  eling factor is 
-0000f3f0: 696d 706f 7274 616e 7420 666f 7220 6c61  important for la
-0000f400: 7267 6520 6d61 7472 6963 6573 2028 7e20  rge matrices (~ 
-0000f410: 2b35 2520 7768 656e 203e 3130 3030 206f  +5% when >1000 o
-0000f420: 6e20 4861 7377 656c 6c29 0a20 2020 2063  n Haswell).    c
-0000f430: 6f6e 7374 2049 6e64 6578 2070 6565 6c65  onst Index peele
-0000f440: 645f 6b63 2020 3d20 6465 7074 6820 2620  d_kc  = depth & 
-0000f450: 7e28 706b 2d31 293b 0a20 2020 2063 6f6e  ~(pk-1);.    con
-0000f460: 7374 2069 6e74 2070 7265 6665 7463 685f  st int prefetch_
-0000f470: 7265 735f 6f66 6673 6574 203d 2033 322f  res_offset = 32/
-0000f480: 7369 7a65 6f66 2852 6573 5363 616c 6172  sizeof(ResScalar
-0000f490: 293b 2020 2020 0a2f 2f20 2020 2020 636f  );    .//     co
-0000f4a0: 6e73 7420 496e 6465 7820 6465 7074 6832  nst Index depth2
-0000f4b0: 2020 2020 203d 2064 6570 7468 2026 207e       = depth & ~
-0000f4c0: 313b 0a0a 2020 2020 2f2f 2d2d 2d2d 2d2d  1;..    //------
-0000f4d0: 2d2d 2d2d 2050 726f 6365 7373 2033 202a  ---- Process 3 *
-0000f4e0: 204c 6873 5072 6f67 7265 7373 2072 6f77   LhsProgress row
-0000f4f0: 7320 6174 206f 6e63 6520 2d2d 2d2d 2d2d  s at once ------
-0000f500: 2d2d 2d2d 0a20 2020 202f 2f20 5468 6973  ----.    // This
-0000f510: 2063 6f72 7265 7370 6f6e 6473 2074 6f20   corresponds to 
-0000f520: 332a 4c68 7350 726f 6772 6573 7320 7820  3*LhsProgress x 
-0000f530: 6e72 2072 6567 6973 7465 7220 626c 6f63  nr register bloc
-0000f540: 6b73 2e0a 2020 2020 2f2f 2055 7375 616c  ks..    // Usual
-0000f550: 6c79 2c20 6d61 6b65 2073 656e 7365 206f  ly, make sense o
-0000f560: 6e6c 7920 7769 7468 2046 4d41 0a20 2020  nly with FMA.   
-0000f570: 2069 6628 6d72 3e3d 332a 5472 6169 7473   if(mr>=3*Traits
-0000f580: 3a3a 4c68 7350 726f 6772 6573 7329 0a20  ::LhsProgress). 
-0000f590: 2020 207b 0a20 2020 2020 202f 2f20 4865     {.      // He
-0000f5a0: 7265 2c20 7468 6520 6765 6e65 7261 6c20  re, the general 
-0000f5b0: 6964 6561 2069 7320 746f 206c 6f6f 7020  idea is to loop 
-0000f5c0: 6f6e 2065 6163 6820 6c61 7267 6573 7420  on each largest 
-0000f5d0: 6d69 6372 6f20 686f 7269 7a6f 6e74 616c  micro horizontal
-0000f5e0: 2070 616e 656c 206f 6620 7468 6520 6c68   panel of the lh
-0000f5f0: 7320 2833 2a54 7261 6974 733a 3a4c 6873  s (3*Traits::Lhs
-0000f600: 5072 6f67 7265 7373 2078 2064 6570 7468  Progress x depth
-0000f610: 290a 2020 2020 2020 2f2f 2061 6e64 206f  ).      // and o
-0000f620: 6e20 6561 6368 206c 6172 6765 7374 206d  n each largest m
-0000f630: 6963 726f 2076 6572 7469 6361 6c20 7061  icro vertical pa
-0000f640: 6e65 6c20 6f66 2074 6865 2072 6873 2028  nel of the rhs (
-0000f650: 6465 7074 6820 2a20 6e72 292e 0a20 2020  depth * nr)..   
-0000f660: 2020 202f 2f20 426c 6f63 6b69 6e67 2073     // Blocking s
-0000f670: 697a 6573 2c20 692e 652e 2c20 2764 6570  izes, i.e., 'dep
-0000f680: 7468 2720 6861 7320 6265 656e 2063 6f6d  th' has been com
-0000f690: 7075 7465 6420 736f 2074 6861 7420 7468  puted so that th
-0000f6a0: 6520 6d69 6372 6f20 686f 7269 7a6f 6e74  e micro horizont
-0000f6b0: 616c 2070 616e 656c 206f 6620 7468 6520  al panel of the 
-0000f6c0: 6c68 7320 6669 7420 696e 204c 312e 0a20  lhs fit in L1.. 
-0000f6d0: 2020 2020 202f 2f20 486f 7765 7665 722c       // However,
-0000f6e0: 2069 6620 6465 7074 6820 6973 2074 6f6f   if depth is too
-0000f6f0: 2073 6d61 6c6c 2c20 7765 2063 616e 2065   small, we can e
-0000f700: 7874 656e 6420 7468 6520 6e75 6d62 6572  xtend the number
-0000f710: 206f 6620 726f 7773 206f 6620 7468 6573   of rows of thes
-0000f720: 6520 686f 7269 7a6f 6e74 616c 2070 616e  e horizontal pan
-0000f730: 656c 732e 0a20 2020 2020 202f 2f20 5468  els..      // Th
-0000f740: 6973 2061 6374 7561 6c20 6e75 6d62 6572  is actual number
-0000f750: 206f 6620 726f 7773 2069 7320 636f 6d70   of rows is comp
-0000f760: 7574 6564 2061 7320 666f 6c6c 6f77 3a0a  uted as follow:.
-0000f770: 2020 2020 2020 636f 6e73 7420 496e 6465        const Inde
-0000f780: 7820 6c31 203d 2064 6566 6175 6c74 4c31  x l1 = defaultL1
-0000f790: 4361 6368 6553 697a 653b 202f 2f20 696e  CacheSize; // in
-0000f7a0: 2042 7974 6573 2c20 544f 444f 2c20 6c31   Bytes, TODO, l1
-0000f7b0: 2073 686f 756c 6420 6265 2070 6173 7365   should be passe
-0000f7c0: 6420 746f 2074 6869 7320 6675 6e63 7469  d to this functi
-0000f7d0: 6f6e 2e0a 2020 2020 2020 2f2f 2054 6865  on..      // The
-0000f7e0: 206d 6178 2831 2c20 2e2e 2e29 2068 6572   max(1, ...) her
-0000f7f0: 6520 6973 206e 6565 6465 6420 6265 6361  e is needed beca
-0000f800: 7573 6520 7765 206d 6179 2062 6520 7573  use we may be us
-0000f810: 696e 6720 626c 6f63 6b69 6e67 2070 6172  ing blocking par
-0000f820: 616d 7320 6c61 7267 6572 2074 6861 6e20  ams larger than 
-0000f830: 7768 6174 206f 7572 206b 6e6f 776e 206c  what our known l
-0000f840: 3120 6361 6368 6520 7369 7a65 0a20 2020  1 cache size.   
-0000f850: 2020 202f 2f20 7375 6767 6573 7473 2077     // suggests w
-0000f860: 6520 7368 6f75 6c64 2062 6520 7573 696e  e should be usin
-0000f870: 673a 2065 6974 6865 7220 6265 6361 7573  g: either becaus
-0000f880: 6520 6f75 7220 6b6e 6f77 6e20 6c31 2063  e our known l1 c
-0000f890: 6163 6865 2073 697a 6520 6973 2069 6e61  ache size is ina
-0000f8a0: 6363 7572 6174 6520 2865 2e67 2e20 6f6e  ccurate (e.g. on
-0000f8b0: 2041 6e64 726f 6964 2c20 7765 2063 616e   Android, we can
-0000f8c0: 206f 6e6c 7920 6775 6573 7329 2c0a 2020   only guess),.  
-0000f8d0: 2020 2020 2f2f 206f 7220 6265 6361 7573      // or becaus
-0000f8e0: 6520 7765 2061 7265 2074 6573 7469 6e67  e we are testing
-0000f8f0: 2073 7065 6369 6669 6320 626c 6f63 6b69   specific blocki
-0000f900: 6e67 2073 697a 6573 2e0a 2020 2020 2020  ng sizes..      
-0000f910: 636f 6e73 7420 496e 6465 7820 6163 7475  const Index actu
-0000f920: 616c 5f70 616e 656c 5f72 6f77 7320 3d20  al_panel_rows = 
-0000f930: 2833 2a4c 6873 5072 6f67 7265 7373 2920  (3*LhsProgress) 
-0000f940: 2a20 7374 643a 3a6d 6178 3c49 6e64 6578  * std::max<Index
-0000f950: 3e28 312c 2820 286c 3120 2d20 7369 7a65  >(1,( (l1 - size
-0000f960: 6f66 2852 6573 5363 616c 6172 292a 6d72  of(ResScalar)*mr
-0000f970: 2a6e 7220 2d20 6465 7074 682a 6e72 2a73  *nr - depth*nr*s
-0000f980: 697a 656f 6628 5268 7353 6361 6c61 7229  izeof(RhsScalar)
-0000f990: 2920 2f20 2864 6570 7468 202a 2073 697a  ) / (depth * siz
-0000f9a0: 656f 6628 4c68 7353 6361 6c61 7229 202a  eof(LhsScalar) *
-0000f9b0: 2033 2a4c 6873 5072 6f67 7265 7373 2920   3*LhsProgress) 
-0000f9c0: 2929 3b0a 2020 2020 2020 666f 7228 496e  ));.      for(In
-0000f9d0: 6465 7820 6931 3d30 3b20 6931 3c70 6565  dex i1=0; i1<pee
-0000f9e0: 6c65 645f 6d63 333b 2069 312b 3d61 6374  led_mc3; i1+=act
-0000f9f0: 7561 6c5f 7061 6e65 6c5f 726f 7773 290a  ual_panel_rows).
-0000fa00: 2020 2020 2020 7b0a 2020 2020 2020 2020        {.        
-0000fa10: 636f 6e73 7420 496e 6465 7820 6163 7475  const Index actu
-0000fa20: 616c 5f70 616e 656c 5f65 6e64 203d 2028  al_panel_end = (
-0000fa30: 7374 643a 3a6d 696e 2928 6931 2b61 6374  std::min)(i1+act
-0000fa40: 7561 6c5f 7061 6e65 6c5f 726f 7773 2c20  ual_panel_rows, 
-0000fa50: 7065 656c 6564 5f6d 6333 293b 0a20 2020  peeled_mc3);.   
-0000fa60: 2020 2020 2066 6f72 2849 6e64 6578 206a       for(Index j
-0000fa70: 323d 303b 206a 323c 7061 636b 6574 5f63  2=0; j2<packet_c
-0000fa80: 6f6c 7334 3b20 6a32 2b3d 6e72 290a 2020  ols4; j2+=nr).  
-0000fa90: 2020 2020 2020 7b0a 2020 2020 2020 2020        {.        
-0000faa0: 2020 666f 7228 496e 6465 7820 693d 6931    for(Index i=i1
-0000fab0: 3b20 693c 6163 7475 616c 5f70 616e 656c  ; i<actual_panel
-0000fac0: 5f65 6e64 3b20 692b 3d33 2a4c 6873 5072  _end; i+=3*LhsPr
-0000fad0: 6f67 7265 7373 290a 2020 2020 2020 2020  ogress).        
-0000fae0: 2020 7b0a 2020 2020 2020 2020 2020 0a20    {.          . 
-0000faf0: 2020 2020 2020 2020 202f 2f20 5765 2073           // We s
-0000fb00: 656c 6563 7465 6420 6120 332a 5472 6169  elected a 3*Trai
-0000fb10: 7473 3a3a 4c68 7350 726f 6772 6573 7320  ts::LhsProgress 
-0000fb20: 7820 6e72 206d 6963 726f 2062 6c6f 636b  x nr micro block
-0000fb30: 206f 6620 7265 7320 7768 6963 6820 6973   of res which is
-0000fb40: 2065 6e74 6972 656c 790a 2020 2020 2020   entirely.      
-0000fb50: 2020 2020 2f2f 2073 746f 7265 6420 696e      // stored in
-0000fb60: 746f 2033 2078 206e 7220 7265 6769 7374  to 3 x nr regist
-0000fb70: 6572 732e 0a20 2020 2020 2020 2020 200a  ers..          .
-0000fb80: 2020 2020 2020 2020 2020 636f 6e73 7420            const 
-0000fb90: 4c68 7353 6361 6c61 722a 2062 6c41 203d  LhsScalar* blA =
-0000fba0: 2026 626c 6f63 6b41 5b69 2a73 7472 6964   &blockA[i*strid
-0000fbb0: 6541 2b6f 6666 7365 7441 2a28 332a 4c68  eA+offsetA*(3*Lh
-0000fbc0: 7350 726f 6772 6573 7329 5d3b 0a20 2020  sProgress)];.   
-0000fbd0: 2020 2020 2020 2070 7265 6665 7463 6828         prefetch(
-0000fbe0: 2662 6c41 5b30 5d29 3b0a 0a20 2020 2020  &blA[0]);..     
-0000fbf0: 2020 2020 202f 2f20 6765 7473 2072 6573       // gets res
-0000fc00: 2062 6c6f 636b 2061 7320 7265 6769 7374   block as regist
-0000fc10: 6572 0a20 2020 2020 2020 2020 2041 6363  er.          Acc
-0000fc20: 5061 636b 6574 2043 302c 2043 312c 2043  Packet C0, C1, C
-0000fc30: 322c 2020 4333 2c0a 2020 2020 2020 2020  2,  C3,.        
-0000fc40: 2020 2020 2020 2020 2020 2020 4334 2c20              C4, 
-0000fc50: 4335 2c20 4336 2c20 2043 372c 0a20 2020  C5, C6,  C7,.   
-0000fc60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000fc70: 2043 382c 2043 392c 2043 3130 2c20 4331   C8, C9, C10, C1
-0000fc80: 313b 0a20 2020 2020 2020 2020 2074 7261  1;.          tra
-0000fc90: 6974 732e 696e 6974 4163 6328 4330 293b  its.initAcc(C0);
-0000fca0: 2020 7472 6169 7473 2e69 6e69 7441 6363    traits.initAcc
-0000fcb0: 2843 3129 3b20 2074 7261 6974 732e 696e  (C1);  traits.in
-0000fcc0: 6974 4163 6328 4332 293b 2020 7472 6169  itAcc(C2);  trai
-0000fcd0: 7473 2e69 6e69 7441 6363 2843 3329 3b0a  ts.initAcc(C3);.
-0000fce0: 2020 2020 2020 2020 2020 7472 6169 7473            traits
-0000fcf0: 2e69 6e69 7441 6363 2843 3429 3b20 2074  .initAcc(C4);  t
-0000fd00: 7261 6974 732e 696e 6974 4163 6328 4335  raits.initAcc(C5
-0000fd10: 293b 2020 7472 6169 7473 2e69 6e69 7441  );  traits.initA
-0000fd20: 6363 2843 3629 3b20 2074 7261 6974 732e  cc(C6);  traits.
-0000fd30: 696e 6974 4163 6328 4337 293b 0a20 2020  initAcc(C7);.   
-0000fd40: 2020 2020 2020 2074 7261 6974 732e 696e         traits.in
-0000fd50: 6974 4163 6328 4338 293b 2020 7472 6169  itAcc(C8);  trai
-0000fd60: 7473 2e69 6e69 7441 6363 2843 3929 3b20  ts.initAcc(C9); 
-0000fd70: 2074 7261 6974 732e 696e 6974 4163 6328   traits.initAcc(
-0000fd80: 4331 3029 3b20 7472 6169 7473 2e69 6e69  C10); traits.ini
-0000fd90: 7441 6363 2843 3131 293b 0a0a 2020 2020  tAcc(C11);..    
-0000fda0: 2020 2020 2020 4c69 6e65 6172 4d61 7070        LinearMapp
-0000fdb0: 6572 2072 3020 3d20 7265 732e 6765 744c  er r0 = res.getL
-0000fdc0: 696e 6561 724d 6170 7065 7228 692c 206a  inearMapper(i, j
-0000fdd0: 3220 2b20 3029 3b0a 2020 2020 2020 2020  2 + 0);.        
-0000fde0: 2020 4c69 6e65 6172 4d61 7070 6572 2072    LinearMapper r
-0000fdf0: 3120 3d20 7265 732e 6765 744c 696e 6561  1 = res.getLinea
-0000fe00: 724d 6170 7065 7228 692c 206a 3220 2b20  rMapper(i, j2 + 
-0000fe10: 3129 3b0a 2020 2020 2020 2020 2020 4c69  1);.          Li
-0000fe20: 6e65 6172 4d61 7070 6572 2072 3220 3d20  nearMapper r2 = 
-0000fe30: 7265 732e 6765 744c 696e 6561 724d 6170  res.getLinearMap
-0000fe40: 7065 7228 692c 206a 3220 2b20 3229 3b0a  per(i, j2 + 2);.
-0000fe50: 2020 2020 2020 2020 2020 4c69 6e65 6172            Linear
-0000fe60: 4d61 7070 6572 2072 3320 3d20 7265 732e  Mapper r3 = res.
-0000fe70: 6765 744c 696e 6561 724d 6170 7065 7228  getLinearMapper(
-0000fe80: 692c 206a 3220 2b20 3329 3b0a 0a20 2020  i, j2 + 3);..   
-0000fe90: 2020 2020 2020 2072 302e 7072 6566 6574         r0.prefet
-0000fea0: 6368 2830 293b 0a20 2020 2020 2020 2020  ch(0);.         
-0000feb0: 2072 312e 7072 6566 6574 6368 2830 293b   r1.prefetch(0);
-0000fec0: 0a20 2020 2020 2020 2020 2072 322e 7072  .          r2.pr
-0000fed0: 6566 6574 6368 2830 293b 0a20 2020 2020  efetch(0);.     
-0000fee0: 2020 2020 2072 332e 7072 6566 6574 6368       r3.prefetch
-0000fef0: 2830 293b 0a0a 2020 2020 2020 2020 2020  (0);..          
-0000ff00: 2f2f 2070 6572 666f 726d 7320 2269 6e6e  // performs "inn
-0000ff10: 6572 2220 7072 6f64 7563 7473 0a20 2020  er" products.   
-0000ff20: 2020 2020 2020 2063 6f6e 7374 2052 6873         const Rhs
-0000ff30: 5363 616c 6172 2a20 626c 4220 3d20 2662  Scalar* blB = &b
-0000ff40: 6c6f 636b 425b 6a32 2a73 7472 6964 6542  lockB[j2*strideB
-0000ff50: 2b6f 6666 7365 7442 2a6e 725d 3b0a 2020  +offsetB*nr];.  
-0000ff60: 2020 2020 2020 2020 7072 6566 6574 6368          prefetch
-0000ff70: 2826 626c 425b 305d 293b 0a20 2020 2020  (&blB[0]);.     
-0000ff80: 2020 2020 204c 6873 5061 636b 6574 2041       LhsPacket A
-0000ff90: 302c 2041 313b 0a0a 2020 2020 2020 2020  0, A1;..        
-0000ffa0: 2020 666f 7228 496e 6465 7820 6b3d 303b    for(Index k=0;
-0000ffb0: 206b 3c70 6565 6c65 645f 6b63 3b20 6b2b   k<peeled_kc; k+
-0000ffc0: 3d70 6b29 0a20 2020 2020 2020 2020 207b  =pk).          {
-0000ffd0: 0a20 2020 2020 2020 2020 2020 2045 4947  .            EIG
-0000ffe0: 454e 5f41 534d 5f43 4f4d 4d45 4e54 2822  EN_ASM_COMMENT("
-0000fff0: 6265 6769 6e20 6765 6270 206d 6963 726f  begin gebp micro
-00010000: 206b 6572 6e65 6c20 3370 5834 2229 3b0a   kernel 3pX4");.
-00010010: 2020 2020 2020 2020 2020 2020 2f2f 2031              // 1
-00010020: 3520 7265 6769 7374 6572 7320 6172 6520  5 registers are 
-00010030: 7461 6b65 6e20 2831 3220 666f 7220 6163  taken (12 for ac
-00010040: 632c 2032 2066 6f72 206c 6873 292e 0a20  c, 2 for lhs).. 
-00010050: 2020 2020 2020 2020 2020 2052 6873 5061             RhsPa
-00010060: 6e65 6c31 3520 7268 735f 7061 6e65 6c3b  nel15 rhs_panel;
-00010070: 0a20 2020 2020 2020 2020 2020 2052 6873  .            Rhs
-00010080: 5061 636b 6574 2054 303b 0a20 2020 2020  Packet T0;.     
-00010090: 2020 2020 2020 204c 6873 5061 636b 6574         LhsPacket
-000100a0: 2041 323b 0a20 2020 2020 2020 2020 2020   A2;.           
-000100b0: 2023 6966 2045 4947 454e 5f43 4f4d 505f   #if EIGEN_COMP_
-000100c0: 474e 5543 5f53 5452 4943 5420 2626 2045  GNUC_STRICT && E
-000100d0: 4947 454e 5f41 5243 485f 4152 4d36 3420  IGEN_ARCH_ARM64 
-000100e0: 2626 2064 6566 696e 6564 2845 4947 454e  && defined(EIGEN
-000100f0: 5f56 4543 544f 5249 5a45 5f4e 454f 4e29  _VECTORIZE_NEON)
-00010100: 2026 2620 2128 4549 4745 4e5f 474e 5543   && !(EIGEN_GNUC
-00010110: 5f41 545f 4c45 4153 5428 392c 3029 290a  _AT_LEAST(9,0)).
-00010120: 2020 2020 2020 2020 2020 2020 2f2f 2073              // s
-00010130: 6565 2068 7474 703a 2f2f 6569 6765 6e2e  ee http://eigen.
-00010140: 7475 7866 616d 696c 792e 6f72 672f 627a  tuxfamily.org/bz
-00010150: 2f73 686f 775f 6275 672e 6367 693f 6964  /show_bug.cgi?id
-00010160: 3d31 3633 330a 2020 2020 2020 2020 2020  =1633.          
-00010170: 2020 2f2f 2077 6974 686f 7574 2074 6869    // without thi
-00010180: 7320 776f 726b 6172 6f75 6e64 2041 302c  s workaround A0,
-00010190: 2041 312c 2061 6e64 2041 3220 6172 6520   A1, and A2 are 
-000101a0: 6c6f 6164 6564 2069 6e20 7468 6520 7361  loaded in the sa
-000101b0: 6d65 2072 6567 6973 7465 722c 0a20 2020  me register,.   
-000101c0: 2020 2020 2020 2020 202f 2f20 7768 6963           // whic
-000101d0: 6820 6973 206e 6f74 2067 6f6f 6420 666f  h is not good fo
-000101e0: 7220 7069 7065 6c69 6e69 6e67 0a20 2020  r pipelining.   
-000101f0: 2020 2020 2020 2020 2023 6465 6669 6e65           #define
-00010200: 2045 4947 454e 5f47 4542 505f 3350 5834   EIGEN_GEBP_3PX4
-00010210: 5f52 4547 4953 5445 525f 414c 4c4f 435f  _REGISTER_ALLOC_
-00010220: 574f 524b 4152 4f55 4e44 205f 5f61 736d  WORKAROUND __asm
-00010230: 5f5f 2020 2822 2220 3a20 222b 772c 6d22  __  ("" : "+w,m"
-00010240: 2028 4130 292c 2022 2b77 2c6d 2220 2841   (A0), "+w,m" (A
-00010250: 3129 2c20 222b 772c 6d22 2028 4132 2929  1), "+w,m" (A2))
-00010260: 3b0a 2020 2020 2020 2020 2020 2020 2365  ;.            #e
-00010270: 6c73 650a 2020 2020 2020 2020 2020 2020  lse.            
-00010280: 2364 6566 696e 6520 4549 4745 4e5f 4745  #define EIGEN_GE
-00010290: 4250 5f33 5058 345f 5245 4749 5354 4552  BP_3PX4_REGISTER
-000102a0: 5f41 4c4c 4f43 5f57 4f52 4b41 524f 554e  _ALLOC_WORKAROUN
-000102b0: 440a 2020 2020 2020 2020 2020 2020 2365  D.            #e
-000102c0: 6e64 6966 0a23 6465 6669 6e65 2045 4947  ndif.#define EIG
-000102d0: 454e 5f47 4542 505f 4f4e 4553 5445 5028  EN_GEBP_ONESTEP(
-000102e0: 4b29 2020 2020 2020 2020 2020 2020 2020  K)              
-000102f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010300: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010310: 2020 2020 2020 205c 0a20 2020 2020 2020         \.       
-00010320: 2020 2020 2064 6f20 7b20 2020 2020 2020       do {       
+0000e400: 2043 382c 2043 392c 2043 3130 2c20 4331   C8, C9, C10, C1
+0000e410: 313b 0a20 2020 2020 2020 2020 2074 7261  1;.          tra
+0000e420: 6974 732e 696e 6974 4163 6328 4330 293b  its.initAcc(C0);
+0000e430: 2020 7472 6169 7473 2e69 6e69 7441 6363    traits.initAcc
+0000e440: 2843 3129 3b20 2074 7261 6974 732e 696e  (C1);  traits.in
+0000e450: 6974 4163 6328 4332 293b 2020 7472 6169  itAcc(C2);  trai
+0000e460: 7473 2e69 6e69 7441 6363 2843 3329 3b0a  ts.initAcc(C3);.
+0000e470: 2020 2020 2020 2020 2020 7472 6169 7473            traits
+0000e480: 2e69 6e69 7441 6363 2843 3429 3b20 2074  .initAcc(C4);  t
+0000e490: 7261 6974 732e 696e 6974 4163 6328 4335  raits.initAcc(C5
+0000e4a0: 293b 2020 7472 6169 7473 2e69 6e69 7441  );  traits.initA
+0000e4b0: 6363 2843 3629 3b20 2074 7261 6974 732e  cc(C6);  traits.
+0000e4c0: 696e 6974 4163 6328 4337 293b 0a20 2020  initAcc(C7);.   
+0000e4d0: 2020 2020 2020 2074 7261 6974 732e 696e         traits.in
+0000e4e0: 6974 4163 6328 4338 293b 2020 7472 6169  itAcc(C8);  trai
+0000e4f0: 7473 2e69 6e69 7441 6363 2843 3929 3b20  ts.initAcc(C9); 
+0000e500: 2074 7261 6974 732e 696e 6974 4163 6328   traits.initAcc(
+0000e510: 4331 3029 3b20 7472 6169 7473 2e69 6e69  C10); traits.ini
+0000e520: 7441 6363 2843 3131 293b 0a0a 2020 2020  tAcc(C11);..    
+0000e530: 2020 2020 2020 4c69 6e65 6172 4d61 7070        LinearMapp
+0000e540: 6572 2072 3020 3d20 7265 732e 6765 744c  er r0 = res.getL
+0000e550: 696e 6561 724d 6170 7065 7228 692c 206a  inearMapper(i, j
+0000e560: 3220 2b20 3029 3b0a 2020 2020 2020 2020  2 + 0);.        
+0000e570: 2020 4c69 6e65 6172 4d61 7070 6572 2072    LinearMapper r
+0000e580: 3120 3d20 7265 732e 6765 744c 696e 6561  1 = res.getLinea
+0000e590: 724d 6170 7065 7228 692c 206a 3220 2b20  rMapper(i, j2 + 
+0000e5a0: 3129 3b0a 2020 2020 2020 2020 2020 4c69  1);.          Li
+0000e5b0: 6e65 6172 4d61 7070 6572 2072 3220 3d20  nearMapper r2 = 
+0000e5c0: 7265 732e 6765 744c 696e 6561 724d 6170  res.getLinearMap
+0000e5d0: 7065 7228 692c 206a 3220 2b20 3229 3b0a  per(i, j2 + 2);.
+0000e5e0: 2020 2020 2020 2020 2020 4c69 6e65 6172            Linear
+0000e5f0: 4d61 7070 6572 2072 3320 3d20 7265 732e  Mapper r3 = res.
+0000e600: 6765 744c 696e 6561 724d 6170 7065 7228  getLinearMapper(
+0000e610: 692c 206a 3220 2b20 3329 3b0a 0a20 2020  i, j2 + 3);..   
+0000e620: 2020 2020 2020 2072 302e 7072 6566 6574         r0.prefet
+0000e630: 6368 2830 293b 0a20 2020 2020 2020 2020  ch(0);.         
+0000e640: 2072 312e 7072 6566 6574 6368 2830 293b   r1.prefetch(0);
+0000e650: 0a20 2020 2020 2020 2020 2072 322e 7072  .          r2.pr
+0000e660: 6566 6574 6368 2830 293b 0a20 2020 2020  efetch(0);.     
+0000e670: 2020 2020 2072 332e 7072 6566 6574 6368       r3.prefetch
+0000e680: 2830 293b 0a0a 2020 2020 2020 2020 2020  (0);..          
+0000e690: 2f2f 2070 6572 666f 726d 7320 2269 6e6e  // performs "inn
+0000e6a0: 6572 2220 7072 6f64 7563 7473 0a20 2020  er" products.   
+0000e6b0: 2020 2020 2020 2063 6f6e 7374 2052 6873         const Rhs
+0000e6c0: 5363 616c 6172 2a20 626c 4220 3d20 2662  Scalar* blB = &b
+0000e6d0: 6c6f 636b 425b 6a32 2a73 7472 6964 6542  lockB[j2*strideB
+0000e6e0: 2b6f 6666 7365 7442 2a6e 725d 3b0a 2020  +offsetB*nr];.  
+0000e6f0: 2020 2020 2020 2020 7072 6566 6574 6368          prefetch
+0000e700: 2826 626c 425b 305d 293b 0a20 2020 2020  (&blB[0]);.     
+0000e710: 2020 2020 204c 6873 5061 636b 6574 2041       LhsPacket A
+0000e720: 302c 2041 313b 0a0a 2020 2020 2020 2020  0, A1;..        
+0000e730: 2020 666f 7228 496e 6465 7820 6b3d 303b    for(Index k=0;
+0000e740: 206b 3c70 6565 6c65 645f 6b63 3b20 6b2b   k<peeled_kc; k+
+0000e750: 3d70 6b29 0a20 2020 2020 2020 2020 207b  =pk).          {
+0000e760: 0a20 2020 2020 2020 2020 2020 2045 4947  .            EIG
+0000e770: 454e 5f41 534d 5f43 4f4d 4d45 4e54 2822  EN_ASM_COMMENT("
+0000e780: 6265 6769 6e20 6765 6270 206d 6963 726f  begin gebp micro
+0000e790: 206b 6572 6e65 6c20 3370 5834 2229 3b0a   kernel 3pX4");.
+0000e7a0: 2020 2020 2020 2020 2020 2020 2f2f 2031              // 1
+0000e7b0: 3520 7265 6769 7374 6572 7320 6172 6520  5 registers are 
+0000e7c0: 7461 6b65 6e20 2831 3220 666f 7220 6163  taken (12 for ac
+0000e7d0: 632c 2032 2066 6f72 206c 6873 292e 0a20  c, 2 for lhs).. 
+0000e7e0: 2020 2020 2020 2020 2020 2052 6873 5061             RhsPa
+0000e7f0: 6e65 6c31 3520 7268 735f 7061 6e65 6c3b  nel15 rhs_panel;
+0000e800: 0a20 2020 2020 2020 2020 2020 2052 6873  .            Rhs
+0000e810: 5061 636b 6574 2054 303b 0a20 2020 2020  Packet T0;.     
+0000e820: 2020 2020 2020 204c 6873 5061 636b 6574         LhsPacket
+0000e830: 2041 323b 0a20 2020 2020 2020 2020 2020   A2;.           
+0000e840: 2023 6966 2045 4947 454e 5f43 4f4d 505f   #if EIGEN_COMP_
+0000e850: 474e 5543 5f53 5452 4943 5420 2626 2045  GNUC_STRICT && E
+0000e860: 4947 454e 5f41 5243 485f 4152 4d36 3420  IGEN_ARCH_ARM64 
+0000e870: 2626 2064 6566 696e 6564 2845 4947 454e  && defined(EIGEN
+0000e880: 5f56 4543 544f 5249 5a45 5f4e 454f 4e29  _VECTORIZE_NEON)
+0000e890: 2026 2620 2128 4549 4745 4e5f 474e 5543   && !(EIGEN_GNUC
+0000e8a0: 5f41 545f 4c45 4153 5428 392c 3029 290a  _AT_LEAST(9,0)).
+0000e8b0: 2020 2020 2020 2020 2020 2020 2f2f 2073              // s
+0000e8c0: 6565 2068 7474 703a 2f2f 6569 6765 6e2e  ee http://eigen.
+0000e8d0: 7475 7866 616d 696c 792e 6f72 672f 627a  tuxfamily.org/bz
+0000e8e0: 2f73 686f 775f 6275 672e 6367 693f 6964  /show_bug.cgi?id
+0000e8f0: 3d31 3633 330a 2020 2020 2020 2020 2020  =1633.          
+0000e900: 2020 2f2f 2077 6974 686f 7574 2074 6869    // without thi
+0000e910: 7320 776f 726b 6172 6f75 6e64 2041 302c  s workaround A0,
+0000e920: 2041 312c 2061 6e64 2041 3220 6172 6520   A1, and A2 are 
+0000e930: 6c6f 6164 6564 2069 6e20 7468 6520 7361  loaded in the sa
+0000e940: 6d65 2072 6567 6973 7465 722c 0a20 2020  me register,.   
+0000e950: 2020 2020 2020 2020 202f 2f20 7768 6963           // whic
+0000e960: 6820 6973 206e 6f74 2067 6f6f 6420 666f  h is not good fo
+0000e970: 7220 7069 7065 6c69 6e69 6e67 0a20 2020  r pipelining.   
+0000e980: 2020 2020 2020 2020 2023 6465 6669 6e65           #define
+0000e990: 2045 4947 454e 5f47 4542 505f 3350 5834   EIGEN_GEBP_3PX4
+0000e9a0: 5f52 4547 4953 5445 525f 414c 4c4f 435f  _REGISTER_ALLOC_
+0000e9b0: 574f 524b 4152 4f55 4e44 205f 5f61 736d  WORKAROUND __asm
+0000e9c0: 5f5f 2020 2822 2220 3a20 222b 772c 6d22  __  ("" : "+w,m"
+0000e9d0: 2028 4130 292c 2022 2b77 2c6d 2220 2841   (A0), "+w,m" (A
+0000e9e0: 3129 2c20 222b 772c 6d22 2028 4132 2929  1), "+w,m" (A2))
+0000e9f0: 3b0a 2020 2020 2020 2020 2020 2020 2365  ;.            #e
+0000ea00: 6c73 650a 2020 2020 2020 2020 2020 2020  lse.            
+0000ea10: 2364 6566 696e 6520 4549 4745 4e5f 4745  #define EIGEN_GE
+0000ea20: 4250 5f33 5058 345f 5245 4749 5354 4552  BP_3PX4_REGISTER
+0000ea30: 5f41 4c4c 4f43 5f57 4f52 4b41 524f 554e  _ALLOC_WORKAROUN
+0000ea40: 440a 2020 2020 2020 2020 2020 2020 2365  D.            #e
+0000ea50: 6e64 6966 0a23 6465 6669 6e65 2045 4947  ndif.#define EIG
+0000ea60: 454e 5f47 4542 505f 4f4e 4553 5445 5028  EN_GEBP_ONESTEP(
+0000ea70: 4b29 2020 2020 2020 2020 2020 2020 2020  K)              
+0000ea80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ea90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000eaa0: 2020 2020 2020 205c 0a20 2020 2020 2020         \.       
+0000eab0: 2020 2020 2064 6f20 7b20 2020 2020 2020       do {       
+0000eac0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ead0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000eae0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000eaf0: 2020 2020 2020 2020 2020 205c 0a20 2020             \.   
+0000eb00: 2020 2020 2020 2020 2020 2045 4947 454e             EIGEN
+0000eb10: 5f41 534d 5f43 4f4d 4d45 4e54 2822 6265  _ASM_COMMENT("be
+0000eb20: 6769 6e20 7374 6570 206f 6620 6765 6270  gin step of gebp
+0000eb30: 206d 6963 726f 206b 6572 6e65 6c20 3370   micro kernel 3p
+0000eb40: 5834 2229 3b20 2020 2020 2020 2020 205c  X4");          \
+0000eb50: 0a20 2020 2020 2020 2020 2020 2020 2045  .              E
+0000eb60: 4947 454e 5f41 534d 5f43 4f4d 4d45 4e54  IGEN_ASM_COMMENT
+0000eb70: 2822 4e6f 7465 3a20 7468 6573 6520 6173  ("Note: these as
+0000eb80: 6d20 636f 6d6d 656e 7473 2077 6f72 6b20  m comments work 
+0000eb90: 6172 6f75 6e64 2062 7567 2039 3335 2122  around bug 935!"
+0000eba0: 293b 205c 0a20 2020 2020 2020 2020 2020  ); \.           
+0000ebb0: 2020 2069 6e74 6572 6e61 6c3a 3a70 7265     internal::pre
+0000ebc0: 6665 7463 6828 626c 4120 2b20 2833 202a  fetch(blA + (3 *
+0000ebd0: 204b 202b 2031 3629 202a 204c 6873 5072   K + 16) * LhsPr
+0000ebe0: 6f67 7265 7373 293b 2020 2020 2020 2020  ogress);        
+0000ebf0: 2020 2020 2020 205c 0a20 2020 2020 2020         \.       
+0000ec00: 2020 2020 2020 2069 6620 2845 4947 454e         if (EIGEN
+0000ec10: 5f41 5243 485f 4152 4d20 7c7c 2045 4947  _ARCH_ARM || EIG
+0000ec20: 454e 5f41 5243 485f 4d49 5053 2920 7b20  EN_ARCH_MIPS) { 
+0000ec30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ec40: 2020 2020 2020 2020 2020 205c 0a20 2020             \.   
+0000ec50: 2020 2020 2020 2020 2020 2020 2069 6e74               int
+0000ec60: 6572 6e61 6c3a 3a70 7265 6665 7463 6828  ernal::prefetch(
+0000ec70: 626c 4220 2b20 2834 202a 204b 202b 2031  blB + (4 * K + 1
+0000ec80: 3629 202a 2052 6873 5072 6f67 7265 7373  6) * RhsProgress
+0000ec90: 293b 2020 2020 2020 2020 2020 2020 205c  );             \
+0000eca0: 0a20 2020 2020 2020 2020 2020 2020 207d  .              }
+0000ecb0: 202f 2a20 4275 6720 3935 3320 2a2f 2020   /* Bug 953 */  
+0000ecc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ecd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ece0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ecf0: 2020 205c 0a20 2020 2020 2020 2020 2020     \.           
+0000ed00: 2020 2074 7261 6974 732e 6c6f 6164 4c68     traits.loadLh
+0000ed10: 7328 2662 6c41 5b28 3020 2b20 3320 2a20  s(&blA[(0 + 3 * 
+0000ed20: 4b29 202a 204c 6873 5072 6f67 7265 7373  K) * LhsProgress
+0000ed30: 5d2c 2041 3029 3b20 2020 2020 2020 2020  ], A0);         
+0000ed40: 2020 2020 2020 205c 0a20 2020 2020 2020         \.       
+0000ed50: 2020 2020 2020 2074 7261 6974 732e 6c6f         traits.lo
+0000ed60: 6164 4c68 7328 2662 6c41 5b28 3120 2b20  adLhs(&blA[(1 + 
+0000ed70: 3320 2a20 4b29 202a 204c 6873 5072 6f67  3 * K) * LhsProg
+0000ed80: 7265 7373 5d2c 2041 3129 3b20 2020 2020  ress], A1);     
+0000ed90: 2020 2020 2020 2020 2020 205c 0a20 2020             \.   
+0000eda0: 2020 2020 2020 2020 2020 2074 7261 6974             trait
+0000edb0: 732e 6c6f 6164 4c68 7328 2662 6c41 5b28  s.loadLhs(&blA[(
+0000edc0: 3220 2b20 3320 2a20 4b29 202a 204c 6873  2 + 3 * K) * Lhs
+0000edd0: 5072 6f67 7265 7373 5d2c 2041 3229 3b20  Progress], A2); 
+0000ede0: 2020 2020 2020 2020 2020 2020 2020 205c                 \
+0000edf0: 0a20 2020 2020 2020 2020 2020 2020 2045  .              E
+0000ee00: 4947 454e 5f47 4542 505f 3350 5834 5f52  IGEN_GEBP_3PX4_R
+0000ee10: 4547 4953 5445 525f 414c 4c4f 435f 574f  EGISTER_ALLOC_WO
+0000ee20: 524b 4152 4f55 4e44 205c 0a20 2020 2020  RKAROUND \.     
+0000ee30: 2020 2020 2020 2020 2074 7261 6974 732e           traits.
+0000ee40: 6c6f 6164 5268 7328 626c 4220 2b20 2830  loadRhs(blB + (0
+0000ee50: 2b34 2a4b 2920 2a20 5472 6169 7473 3a3a  +4*K) * Traits::
+0000ee60: 5268 7350 726f 6772 6573 732c 2072 6873  RhsProgress, rhs
+0000ee70: 5f70 616e 656c 293b 2020 2020 205c 0a20  _panel);     \. 
+0000ee80: 2020 2020 2020 2020 2020 2020 2074 7261               tra
+0000ee90: 6974 732e 6d61 6464 2841 302c 2072 6873  its.madd(A0, rhs
+0000eea0: 5f70 616e 656c 2c20 4330 2c20 5430 2c20  _panel, C0, T0, 
+0000eeb0: 6669 783c 303e 293b 2020 2020 2020 2020  fix<0>);        
+0000eec0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000eed0: 205c 0a20 2020 2020 2020 2020 2020 2020   \.             
+0000eee0: 2074 7261 6974 732e 6d61 6464 2841 312c   traits.madd(A1,
+0000eef0: 2072 6873 5f70 616e 656c 2c20 4334 2c20   rhs_panel, C4, 
+0000ef00: 5430 2c20 6669 783c 303e 293b 2020 2020  T0, fix<0>);    
+0000ef10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ef20: 2020 2020 205c 0a20 2020 2020 2020 2020       \.         
+0000ef30: 2020 2020 2074 7261 6974 732e 6d61 6464       traits.madd
+0000ef40: 2841 322c 2072 6873 5f70 616e 656c 2c20  (A2, rhs_panel, 
+0000ef50: 4338 2c20 5430 2c20 6669 783c 303e 293b  C8, T0, fix<0>);
+0000ef60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ef70: 2020 2020 2020 2020 205c 0a20 2020 2020           \.     
+0000ef80: 2020 2020 2020 2020 2074 7261 6974 732e           traits.
+0000ef90: 7570 6461 7465 5268 7328 626c 4220 2b20  updateRhs(blB + 
+0000efa0: 2831 2b34 2a4b 2920 2a20 5472 6169 7473  (1+4*K) * Traits
+0000efb0: 3a3a 5268 7350 726f 6772 6573 732c 2072  ::RhsProgress, r
+0000efc0: 6873 5f70 616e 656c 293b 2020 205c 0a20  hs_panel);   \. 
+0000efd0: 2020 2020 2020 2020 2020 2020 2074 7261               tra
+0000efe0: 6974 732e 6d61 6464 2841 302c 2072 6873  its.madd(A0, rhs
+0000eff0: 5f70 616e 656c 2c20 4331 2c20 5430 2c20  _panel, C1, T0, 
+0000f000: 6669 783c 313e 293b 2020 2020 2020 2020  fix<1>);        
+0000f010: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f020: 205c 0a20 2020 2020 2020 2020 2020 2020   \.             
+0000f030: 2074 7261 6974 732e 6d61 6464 2841 312c   traits.madd(A1,
+0000f040: 2072 6873 5f70 616e 656c 2c20 4335 2c20   rhs_panel, C5, 
+0000f050: 5430 2c20 6669 783c 313e 293b 2020 2020  T0, fix<1>);    
+0000f060: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f070: 2020 2020 205c 0a20 2020 2020 2020 2020       \.         
+0000f080: 2020 2020 2074 7261 6974 732e 6d61 6464       traits.madd
+0000f090: 2841 322c 2072 6873 5f70 616e 656c 2c20  (A2, rhs_panel, 
+0000f0a0: 4339 2c20 5430 2c20 6669 783c 313e 293b  C9, T0, fix<1>);
+0000f0b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f0c0: 2020 2020 2020 2020 205c 0a20 2020 2020           \.     
+0000f0d0: 2020 2020 2020 2020 2074 7261 6974 732e           traits.
+0000f0e0: 7570 6461 7465 5268 7328 626c 4220 2b20  updateRhs(blB + 
+0000f0f0: 2832 2b34 2a4b 2920 2a20 5472 6169 7473  (2+4*K) * Traits
+0000f100: 3a3a 5268 7350 726f 6772 6573 732c 2072  ::RhsProgress, r
+0000f110: 6873 5f70 616e 656c 293b 2020 205c 0a20  hs_panel);   \. 
+0000f120: 2020 2020 2020 2020 2020 2020 2074 7261               tra
+0000f130: 6974 732e 6d61 6464 2841 302c 2072 6873  its.madd(A0, rhs
+0000f140: 5f70 616e 656c 2c20 4332 2c20 5430 2c20  _panel, C2, T0, 
+0000f150: 6669 783c 323e 293b 2020 2020 2020 2020  fix<2>);        
+0000f160: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f170: 205c 0a20 2020 2020 2020 2020 2020 2020   \.             
+0000f180: 2074 7261 6974 732e 6d61 6464 2841 312c   traits.madd(A1,
+0000f190: 2072 6873 5f70 616e 656c 2c20 4336 2c20   rhs_panel, C6, 
+0000f1a0: 5430 2c20 6669 783c 323e 293b 2020 2020  T0, fix<2>);    
+0000f1b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f1c0: 2020 2020 205c 0a20 2020 2020 2020 2020       \.         
+0000f1d0: 2020 2020 2074 7261 6974 732e 6d61 6464       traits.madd
+0000f1e0: 2841 322c 2072 6873 5f70 616e 656c 2c20  (A2, rhs_panel, 
+0000f1f0: 4331 302c 2054 302c 2066 6978 3c32 3e29  C10, T0, fix<2>)
+0000f200: 3b20 2020 2020 2020 2020 2020 2020 2020  ;               
+0000f210: 2020 2020 2020 2020 205c 0a20 2020 2020           \.     
+0000f220: 2020 2020 2020 2020 2074 7261 6974 732e           traits.
+0000f230: 7570 6461 7465 5268 7328 626c 4220 2b20  updateRhs(blB + 
+0000f240: 2833 2b34 2a4b 2920 2a20 5472 6169 7473  (3+4*K) * Traits
+0000f250: 3a3a 5268 7350 726f 6772 6573 732c 2072  ::RhsProgress, r
+0000f260: 6873 5f70 616e 656c 293b 2020 205c 0a20  hs_panel);   \. 
+0000f270: 2020 2020 2020 2020 2020 2020 2074 7261               tra
+0000f280: 6974 732e 6d61 6464 2841 302c 2072 6873  its.madd(A0, rhs
+0000f290: 5f70 616e 656c 2c20 4333 2c20 5430 2c20  _panel, C3, T0, 
+0000f2a0: 6669 783c 333e 293b 2020 2020 2020 2020  fix<3>);        
+0000f2b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f2c0: 205c 0a20 2020 2020 2020 2020 2020 2020   \.             
+0000f2d0: 2074 7261 6974 732e 6d61 6464 2841 312c   traits.madd(A1,
+0000f2e0: 2072 6873 5f70 616e 656c 2c20 4337 2c20   rhs_panel, C7, 
+0000f2f0: 5430 2c20 6669 783c 333e 293b 2020 2020  T0, fix<3>);    
+0000f300: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f310: 2020 2020 205c 0a20 2020 2020 2020 2020       \.         
+0000f320: 2020 2020 2074 7261 6974 732e 6d61 6464       traits.madd
+0000f330: 2841 322c 2072 6873 5f70 616e 656c 2c20  (A2, rhs_panel, 
+0000f340: 4331 312c 2054 302c 2066 6978 3c33 3e29  C11, T0, fix<3>)
+0000f350: 3b20 2020 2020 2020 2020 2020 2020 2020  ;               
+0000f360: 2020 2020 2020 2020 205c 0a20 2020 2020           \.     
+0000f370: 2020 2020 2020 2020 2045 4947 454e 5f41           EIGEN_A
+0000f380: 534d 5f43 4f4d 4d45 4e54 2822 656e 6420  SM_COMMENT("end 
+0000f390: 7374 6570 206f 6620 6765 6270 206d 6963  step of gebp mic
+0000f3a0: 726f 206b 6572 6e65 6c20 3370 5834 2229  ro kernel 3pX4")
+0000f3b0: 3b20 2020 2020 2020 2020 2020 205c 0a20  ;            \. 
+0000f3c0: 2020 2020 2020 2020 2020 207d 2077 6869             } whi
+0000f3d0: 6c65 2028 6661 6c73 6529 0a0a 2020 2020  le (false)..    
+0000f3e0: 2020 2020 2020 2020 696e 7465 726e 616c          internal
+0000f3f0: 3a3a 7072 6566 6574 6368 2862 6c42 293b  ::prefetch(blB);
+0000f400: 0a20 2020 2020 2020 2020 2020 2045 4947  .            EIG
+0000f410: 454e 5f47 4542 505f 4f4e 4553 5445 5028  EN_GEBP_ONESTEP(
+0000f420: 3029 3b0a 2020 2020 2020 2020 2020 2020  0);.            
+0000f430: 4549 4745 4e5f 4745 4250 5f4f 4e45 5354  EIGEN_GEBP_ONEST
+0000f440: 4550 2831 293b 0a20 2020 2020 2020 2020  EP(1);.         
+0000f450: 2020 2045 4947 454e 5f47 4542 505f 4f4e     EIGEN_GEBP_ON
+0000f460: 4553 5445 5028 3229 3b0a 2020 2020 2020  ESTEP(2);.      
+0000f470: 2020 2020 2020 4549 4745 4e5f 4745 4250        EIGEN_GEBP
+0000f480: 5f4f 4e45 5354 4550 2833 293b 0a20 2020  _ONESTEP(3);.   
+0000f490: 2020 2020 2020 2020 2045 4947 454e 5f47           EIGEN_G
+0000f4a0: 4542 505f 4f4e 4553 5445 5028 3429 3b0a  EBP_ONESTEP(4);.
+0000f4b0: 2020 2020 2020 2020 2020 2020 4549 4745              EIGE
+0000f4c0: 4e5f 4745 4250 5f4f 4e45 5354 4550 2835  N_GEBP_ONESTEP(5
+0000f4d0: 293b 0a20 2020 2020 2020 2020 2020 2045  );.            E
+0000f4e0: 4947 454e 5f47 4542 505f 4f4e 4553 5445  IGEN_GEBP_ONESTE
+0000f4f0: 5028 3629 3b0a 2020 2020 2020 2020 2020  P(6);.          
+0000f500: 2020 4549 4745 4e5f 4745 4250 5f4f 4e45    EIGEN_GEBP_ONE
+0000f510: 5354 4550 2837 293b 0a0a 2020 2020 2020  STEP(7);..      
+0000f520: 2020 2020 2020 626c 4220 2b3d 2070 6b2a        blB += pk*
+0000f530: 342a 5268 7350 726f 6772 6573 733b 0a20  4*RhsProgress;. 
+0000f540: 2020 2020 2020 2020 2020 2062 6c41 202b             blA +
+0000f550: 3d20 706b 2a33 2a54 7261 6974 733a 3a4c  = pk*3*Traits::L
+0000f560: 6873 5072 6f67 7265 7373 3b0a 0a20 2020  hsProgress;..   
+0000f570: 2020 2020 2020 2020 2045 4947 454e 5f41           EIGEN_A
+0000f580: 534d 5f43 4f4d 4d45 4e54 2822 656e 6420  SM_COMMENT("end 
+0000f590: 6765 6270 206d 6963 726f 206b 6572 6e65  gebp micro kerne
+0000f5a0: 6c20 3370 5834 2229 3b0a 2020 2020 2020  l 3pX4");.      
+0000f5b0: 2020 2020 7d0a 2020 2020 2020 2020 2020      }.          
+0000f5c0: 2f2f 2070 726f 6365 7373 2072 656d 6169  // process remai
+0000f5d0: 6e69 6e67 2070 6565 6c65 6420 6c6f 6f70  ning peeled loop
+0000f5e0: 0a20 2020 2020 2020 2020 2066 6f72 2849  .          for(I
+0000f5f0: 6e64 6578 206b 3d70 6565 6c65 645f 6b63  ndex k=peeled_kc
+0000f600: 3b20 6b3c 6465 7074 683b 206b 2b2b 290a  ; k<depth; k++).
+0000f610: 2020 2020 2020 2020 2020 7b0a 2020 2020            {.    
+0000f620: 2020 2020 2020 2020 5268 7350 616e 656c          RhsPanel
+0000f630: 3135 2072 6873 5f70 616e 656c 3b0a 2020  15 rhs_panel;.  
+0000f640: 2020 2020 2020 2020 2020 5268 7350 6163            RhsPac
+0000f650: 6b65 7420 5430 3b0a 2020 2020 2020 2020  ket T0;.        
+0000f660: 2020 2020 4c68 7350 6163 6b65 7420 4132      LhsPacket A2
+0000f670: 3b0a 2020 2020 2020 2020 2020 2020 4549  ;.            EI
+0000f680: 4745 4e5f 4745 4250 5f4f 4e45 5354 4550  GEN_GEBP_ONESTEP
+0000f690: 2830 293b 0a20 2020 2020 2020 2020 2020  (0);.           
+0000f6a0: 2062 6c42 202b 3d20 342a 5268 7350 726f   blB += 4*RhsPro
+0000f6b0: 6772 6573 733b 0a20 2020 2020 2020 2020  gress;.         
+0000f6c0: 2020 2062 6c41 202b 3d20 332a 5472 6169     blA += 3*Trai
+0000f6d0: 7473 3a3a 4c68 7350 726f 6772 6573 733b  ts::LhsProgress;
+0000f6e0: 0a20 2020 2020 2020 2020 207d 0a0a 2375  .          }..#u
+0000f6f0: 6e64 6566 2045 4947 454e 5f47 4542 505f  ndef EIGEN_GEBP_
+0000f700: 4f4e 4553 5445 500a 0a20 2020 2020 2020  ONESTEP..       
+0000f710: 2020 2052 6573 5061 636b 6574 2052 302c     ResPacket R0,
+0000f720: 2052 312c 2052 323b 0a20 2020 2020 2020   R1, R2;.       
+0000f730: 2020 2052 6573 5061 636b 6574 2061 6c70     ResPacket alp
+0000f740: 6861 7620 3d20 7073 6574 313c 5265 7350  hav = pset1<ResP
+0000f750: 6163 6b65 743e 2861 6c70 6861 293b 0a0a  acket>(alpha);..
+0000f760: 2020 2020 2020 2020 2020 5230 203d 2072            R0 = r
+0000f770: 302e 7465 6d70 6c61 7465 206c 6f61 6450  0.template loadP
+0000f780: 6163 6b65 743c 5265 7350 6163 6b65 743e  acket<ResPacket>
+0000f790: 2830 202a 2054 7261 6974 733a 3a52 6573  (0 * Traits::Res
+0000f7a0: 5061 636b 6574 5369 7a65 293b 0a20 2020  PacketSize);.   
+0000f7b0: 2020 2020 2020 2052 3120 3d20 7230 2e74         R1 = r0.t
+0000f7c0: 656d 706c 6174 6520 6c6f 6164 5061 636b  emplate loadPack
+0000f7d0: 6574 3c52 6573 5061 636b 6574 3e28 3120  et<ResPacket>(1 
+0000f7e0: 2a20 5472 6169 7473 3a3a 5265 7350 6163  * Traits::ResPac
+0000f7f0: 6b65 7453 697a 6529 3b0a 2020 2020 2020  ketSize);.      
+0000f800: 2020 2020 5232 203d 2072 302e 7465 6d70      R2 = r0.temp
+0000f810: 6c61 7465 206c 6f61 6450 6163 6b65 743c  late loadPacket<
+0000f820: 5265 7350 6163 6b65 743e 2832 202a 2054  ResPacket>(2 * T
+0000f830: 7261 6974 733a 3a52 6573 5061 636b 6574  raits::ResPacket
+0000f840: 5369 7a65 293b 0a20 2020 2020 2020 2020  Size);.         
+0000f850: 2074 7261 6974 732e 6163 6328 4330 2c20   traits.acc(C0, 
+0000f860: 616c 7068 6176 2c20 5230 293b 0a20 2020  alphav, R0);.   
+0000f870: 2020 2020 2020 2074 7261 6974 732e 6163         traits.ac
+0000f880: 6328 4334 2c20 616c 7068 6176 2c20 5231  c(C4, alphav, R1
+0000f890: 293b 0a20 2020 2020 2020 2020 2074 7261  );.          tra
+0000f8a0: 6974 732e 6163 6328 4338 2c20 616c 7068  its.acc(C8, alph
+0000f8b0: 6176 2c20 5232 293b 0a20 2020 2020 2020  av, R2);.       
+0000f8c0: 2020 2072 302e 7374 6f72 6550 6163 6b65     r0.storePacke
+0000f8d0: 7428 3020 2a20 5472 6169 7473 3a3a 5265  t(0 * Traits::Re
+0000f8e0: 7350 6163 6b65 7453 697a 652c 2052 3029  sPacketSize, R0)
+0000f8f0: 3b0a 2020 2020 2020 2020 2020 7230 2e73  ;.          r0.s
+0000f900: 746f 7265 5061 636b 6574 2831 202a 2054  torePacket(1 * T
+0000f910: 7261 6974 733a 3a52 6573 5061 636b 6574  raits::ResPacket
+0000f920: 5369 7a65 2c20 5231 293b 0a20 2020 2020  Size, R1);.     
+0000f930: 2020 2020 2072 302e 7374 6f72 6550 6163       r0.storePac
+0000f940: 6b65 7428 3220 2a20 5472 6169 7473 3a3a  ket(2 * Traits::
+0000f950: 5265 7350 6163 6b65 7453 697a 652c 2052  ResPacketSize, R
+0000f960: 3229 3b0a 0a20 2020 2020 2020 2020 2052  2);..          R
+0000f970: 3020 3d20 7231 2e74 656d 706c 6174 6520  0 = r1.template 
+0000f980: 6c6f 6164 5061 636b 6574 3c52 6573 5061  loadPacket<ResPa
+0000f990: 636b 6574 3e28 3020 2a20 5472 6169 7473  cket>(0 * Traits
+0000f9a0: 3a3a 5265 7350 6163 6b65 7453 697a 6529  ::ResPacketSize)
+0000f9b0: 3b0a 2020 2020 2020 2020 2020 5231 203d  ;.          R1 =
+0000f9c0: 2072 312e 7465 6d70 6c61 7465 206c 6f61   r1.template loa
+0000f9d0: 6450 6163 6b65 743c 5265 7350 6163 6b65  dPacket<ResPacke
+0000f9e0: 743e 2831 202a 2054 7261 6974 733a 3a52  t>(1 * Traits::R
+0000f9f0: 6573 5061 636b 6574 5369 7a65 293b 0a20  esPacketSize);. 
+0000fa00: 2020 2020 2020 2020 2052 3220 3d20 7231           R2 = r1
+0000fa10: 2e74 656d 706c 6174 6520 6c6f 6164 5061  .template loadPa
+0000fa20: 636b 6574 3c52 6573 5061 636b 6574 3e28  cket<ResPacket>(
+0000fa30: 3220 2a20 5472 6169 7473 3a3a 5265 7350  2 * Traits::ResP
+0000fa40: 6163 6b65 7453 697a 6529 3b0a 2020 2020  acketSize);.    
+0000fa50: 2020 2020 2020 7472 6169 7473 2e61 6363        traits.acc
+0000fa60: 2843 312c 2061 6c70 6861 762c 2052 3029  (C1, alphav, R0)
+0000fa70: 3b0a 2020 2020 2020 2020 2020 7472 6169  ;.          trai
+0000fa80: 7473 2e61 6363 2843 352c 2061 6c70 6861  ts.acc(C5, alpha
+0000fa90: 762c 2052 3129 3b0a 2020 2020 2020 2020  v, R1);.        
+0000faa0: 2020 7472 6169 7473 2e61 6363 2843 392c    traits.acc(C9,
+0000fab0: 2061 6c70 6861 762c 2052 3229 3b0a 2020   alphav, R2);.  
+0000fac0: 2020 2020 2020 2020 7231 2e73 746f 7265          r1.store
+0000fad0: 5061 636b 6574 2830 202a 2054 7261 6974  Packet(0 * Trait
+0000fae0: 733a 3a52 6573 5061 636b 6574 5369 7a65  s::ResPacketSize
+0000faf0: 2c20 5230 293b 0a20 2020 2020 2020 2020  , R0);.         
+0000fb00: 2072 312e 7374 6f72 6550 6163 6b65 7428   r1.storePacket(
+0000fb10: 3120 2a20 5472 6169 7473 3a3a 5265 7350  1 * Traits::ResP
+0000fb20: 6163 6b65 7453 697a 652c 2052 3129 3b0a  acketSize, R1);.
+0000fb30: 2020 2020 2020 2020 2020 7231 2e73 746f            r1.sto
+0000fb40: 7265 5061 636b 6574 2832 202a 2054 7261  rePacket(2 * Tra
+0000fb50: 6974 733a 3a52 6573 5061 636b 6574 5369  its::ResPacketSi
+0000fb60: 7a65 2c20 5232 293b 0a0a 2020 2020 2020  ze, R2);..      
+0000fb70: 2020 2020 5230 203d 2072 322e 7465 6d70      R0 = r2.temp
+0000fb80: 6c61 7465 206c 6f61 6450 6163 6b65 743c  late loadPacket<
+0000fb90: 5265 7350 6163 6b65 743e 2830 202a 2054  ResPacket>(0 * T
+0000fba0: 7261 6974 733a 3a52 6573 5061 636b 6574  raits::ResPacket
+0000fbb0: 5369 7a65 293b 0a20 2020 2020 2020 2020  Size);.         
+0000fbc0: 2052 3120 3d20 7232 2e74 656d 706c 6174   R1 = r2.templat
+0000fbd0: 6520 6c6f 6164 5061 636b 6574 3c52 6573  e loadPacket<Res
+0000fbe0: 5061 636b 6574 3e28 3120 2a20 5472 6169  Packet>(1 * Trai
+0000fbf0: 7473 3a3a 5265 7350 6163 6b65 7453 697a  ts::ResPacketSiz
+0000fc00: 6529 3b0a 2020 2020 2020 2020 2020 5232  e);.          R2
+0000fc10: 203d 2072 322e 7465 6d70 6c61 7465 206c   = r2.template l
+0000fc20: 6f61 6450 6163 6b65 743c 5265 7350 6163  oadPacket<ResPac
+0000fc30: 6b65 743e 2832 202a 2054 7261 6974 733a  ket>(2 * Traits:
+0000fc40: 3a52 6573 5061 636b 6574 5369 7a65 293b  :ResPacketSize);
+0000fc50: 0a20 2020 2020 2020 2020 2074 7261 6974  .          trait
+0000fc60: 732e 6163 6328 4332 2c20 616c 7068 6176  s.acc(C2, alphav
+0000fc70: 2c20 5230 293b 0a20 2020 2020 2020 2020  , R0);.         
+0000fc80: 2074 7261 6974 732e 6163 6328 4336 2c20   traits.acc(C6, 
+0000fc90: 616c 7068 6176 2c20 5231 293b 0a20 2020  alphav, R1);.   
+0000fca0: 2020 2020 2020 2074 7261 6974 732e 6163         traits.ac
+0000fcb0: 6328 4331 302c 2061 6c70 6861 762c 2052  c(C10, alphav, R
+0000fcc0: 3229 3b0a 2020 2020 2020 2020 2020 7232  2);.          r2
+0000fcd0: 2e73 746f 7265 5061 636b 6574 2830 202a  .storePacket(0 *
+0000fce0: 2054 7261 6974 733a 3a52 6573 5061 636b   Traits::ResPack
+0000fcf0: 6574 5369 7a65 2c20 5230 293b 0a20 2020  etSize, R0);.   
+0000fd00: 2020 2020 2020 2072 322e 7374 6f72 6550         r2.storeP
+0000fd10: 6163 6b65 7428 3120 2a20 5472 6169 7473  acket(1 * Traits
+0000fd20: 3a3a 5265 7350 6163 6b65 7453 697a 652c  ::ResPacketSize,
+0000fd30: 2052 3129 3b0a 2020 2020 2020 2020 2020   R1);.          
+0000fd40: 7232 2e73 746f 7265 5061 636b 6574 2832  r2.storePacket(2
+0000fd50: 202a 2054 7261 6974 733a 3a52 6573 5061   * Traits::ResPa
+0000fd60: 636b 6574 5369 7a65 2c20 5232 293b 0a0a  cketSize, R2);..
+0000fd70: 2020 2020 2020 2020 2020 5230 203d 2072            R0 = r
+0000fd80: 332e 7465 6d70 6c61 7465 206c 6f61 6450  3.template loadP
+0000fd90: 6163 6b65 743c 5265 7350 6163 6b65 743e  acket<ResPacket>
+0000fda0: 2830 202a 2054 7261 6974 733a 3a52 6573  (0 * Traits::Res
+0000fdb0: 5061 636b 6574 5369 7a65 293b 0a20 2020  PacketSize);.   
+0000fdc0: 2020 2020 2020 2052 3120 3d20 7233 2e74         R1 = r3.t
+0000fdd0: 656d 706c 6174 6520 6c6f 6164 5061 636b  emplate loadPack
+0000fde0: 6574 3c52 6573 5061 636b 6574 3e28 3120  et<ResPacket>(1 
+0000fdf0: 2a20 5472 6169 7473 3a3a 5265 7350 6163  * Traits::ResPac
+0000fe00: 6b65 7453 697a 6529 3b0a 2020 2020 2020  ketSize);.      
+0000fe10: 2020 2020 5232 203d 2072 332e 7465 6d70      R2 = r3.temp
+0000fe20: 6c61 7465 206c 6f61 6450 6163 6b65 743c  late loadPacket<
+0000fe30: 5265 7350 6163 6b65 743e 2832 202a 2054  ResPacket>(2 * T
+0000fe40: 7261 6974 733a 3a52 6573 5061 636b 6574  raits::ResPacket
+0000fe50: 5369 7a65 293b 0a20 2020 2020 2020 2020  Size);.         
+0000fe60: 2074 7261 6974 732e 6163 6328 4333 2c20   traits.acc(C3, 
+0000fe70: 616c 7068 6176 2c20 5230 293b 0a20 2020  alphav, R0);.   
+0000fe80: 2020 2020 2020 2074 7261 6974 732e 6163         traits.ac
+0000fe90: 6328 4337 2c20 616c 7068 6176 2c20 5231  c(C7, alphav, R1
+0000fea0: 293b 0a20 2020 2020 2020 2020 2074 7261  );.          tra
+0000feb0: 6974 732e 6163 6328 4331 312c 2061 6c70  its.acc(C11, alp
+0000fec0: 6861 762c 2052 3229 3b0a 2020 2020 2020  hav, R2);.      
+0000fed0: 2020 2020 7233 2e73 746f 7265 5061 636b      r3.storePack
+0000fee0: 6574 2830 202a 2054 7261 6974 733a 3a52  et(0 * Traits::R
+0000fef0: 6573 5061 636b 6574 5369 7a65 2c20 5230  esPacketSize, R0
+0000ff00: 293b 0a20 2020 2020 2020 2020 2072 332e  );.          r3.
+0000ff10: 7374 6f72 6550 6163 6b65 7428 3120 2a20  storePacket(1 * 
+0000ff20: 5472 6169 7473 3a3a 5265 7350 6163 6b65  Traits::ResPacke
+0000ff30: 7453 697a 652c 2052 3129 3b0a 2020 2020  tSize, R1);.    
+0000ff40: 2020 2020 2020 7233 2e73 746f 7265 5061        r3.storePa
+0000ff50: 636b 6574 2832 202a 2054 7261 6974 733a  cket(2 * Traits:
+0000ff60: 3a52 6573 5061 636b 6574 5369 7a65 2c20  :ResPacketSize, 
+0000ff70: 5232 293b 2020 2020 2020 2020 2020 0a20  R2);          . 
+0000ff80: 2020 2020 2020 2020 207d 0a20 2020 2020           }.     
+0000ff90: 2020 207d 0a0a 2020 2020 2020 2020 2f2f     }..        //
+0000ffa0: 2044 6561 6c20 7769 7468 2072 656d 6169   Deal with remai
+0000ffb0: 6e69 6e67 2063 6f6c 756d 6e73 206f 6620  ning columns of 
+0000ffc0: 7468 6520 7268 730a 2020 2020 2020 2020  the rhs.        
+0000ffd0: 666f 7228 496e 6465 7820 6a32 3d70 6163  for(Index j2=pac
+0000ffe0: 6b65 745f 636f 6c73 343b 206a 323c 636f  ket_cols4; j2<co
+0000fff0: 6c73 3b20 6a32 2b2b 290a 2020 2020 2020  ls; j2++).      
+00010000: 2020 7b0a 2020 2020 2020 2020 2020 666f    {.          fo
+00010010: 7228 496e 6465 7820 693d 6931 3b20 693c  r(Index i=i1; i<
+00010020: 6163 7475 616c 5f70 616e 656c 5f65 6e64  actual_panel_end
+00010030: 3b20 692b 3d33 2a4c 6873 5072 6f67 7265  ; i+=3*LhsProgre
+00010040: 7373 290a 2020 2020 2020 2020 2020 7b0a  ss).          {.
+00010050: 2020 2020 2020 2020 2020 2f2f 204f 6e65            // One
+00010060: 2063 6f6c 756d 6e20 6174 2061 2074 696d   column at a tim
+00010070: 650a 2020 2020 2020 2020 2020 636f 6e73  e.          cons
+00010080: 7420 4c68 7353 6361 6c61 722a 2062 6c41  t LhsScalar* blA
+00010090: 203d 2026 626c 6f63 6b41 5b69 2a73 7472   = &blockA[i*str
+000100a0: 6964 6541 2b6f 6666 7365 7441 2a28 332a  ideA+offsetA*(3*
+000100b0: 5472 6169 7473 3a3a 4c68 7350 726f 6772  Traits::LhsProgr
+000100c0: 6573 7329 5d3b 0a20 2020 2020 2020 2020  ess)];.         
+000100d0: 2070 7265 6665 7463 6828 2662 6c41 5b30   prefetch(&blA[0
+000100e0: 5d29 3b0a 0a20 2020 2020 2020 2020 202f  ]);..          /
+000100f0: 2f20 6765 7473 2072 6573 2062 6c6f 636b  / gets res block
+00010100: 2061 7320 7265 6769 7374 6572 0a20 2020   as register.   
+00010110: 2020 2020 2020 2041 6363 5061 636b 6574         AccPacket
+00010120: 2043 302c 2043 342c 2043 383b 0a20 2020   C0, C4, C8;.   
+00010130: 2020 2020 2020 2074 7261 6974 732e 696e         traits.in
+00010140: 6974 4163 6328 4330 293b 0a20 2020 2020  itAcc(C0);.     
+00010150: 2020 2020 2074 7261 6974 732e 696e 6974       traits.init
+00010160: 4163 6328 4334 293b 0a20 2020 2020 2020  Acc(C4);.       
+00010170: 2020 2074 7261 6974 732e 696e 6974 4163     traits.initAc
+00010180: 6328 4338 293b 0a0a 2020 2020 2020 2020  c(C8);..        
+00010190: 2020 4c69 6e65 6172 4d61 7070 6572 2072    LinearMapper r
+000101a0: 3020 3d20 7265 732e 6765 744c 696e 6561  0 = res.getLinea
+000101b0: 724d 6170 7065 7228 692c 206a 3229 3b0a  rMapper(i, j2);.
+000101c0: 2020 2020 2020 2020 2020 7230 2e70 7265            r0.pre
+000101d0: 6665 7463 6828 3029 3b0a 0a20 2020 2020  fetch(0);..     
+000101e0: 2020 2020 202f 2f20 7065 7266 6f72 6d73       // performs
+000101f0: 2022 696e 6e65 7222 2070 726f 6475 6374   "inner" product
+00010200: 730a 2020 2020 2020 2020 2020 636f 6e73  s.          cons
+00010210: 7420 5268 7353 6361 6c61 722a 2062 6c42  t RhsScalar* blB
+00010220: 203d 2026 626c 6f63 6b42 5b6a 322a 7374   = &blockB[j2*st
+00010230: 7269 6465 422b 6f66 6673 6574 425d 3b0a  rideB+offsetB];.
+00010240: 2020 2020 2020 2020 2020 4c68 7350 6163            LhsPac
+00010250: 6b65 7420 4130 2c20 4131 2c20 4132 3b0a  ket A0, A1, A2;.
+00010260: 2020 2020 2020 2020 2020 0a20 2020 2020            .     
+00010270: 2020 2020 2066 6f72 2849 6e64 6578 206b       for(Index k
+00010280: 3d30 3b20 6b3c 7065 656c 6564 5f6b 633b  =0; k<peeled_kc;
+00010290: 206b 2b3d 706b 290a 2020 2020 2020 2020   k+=pk).        
+000102a0: 2020 7b0a 2020 2020 2020 2020 2020 2020    {.            
+000102b0: 4549 4745 4e5f 4153 4d5f 434f 4d4d 454e  EIGEN_ASM_COMMEN
+000102c0: 5428 2262 6567 696e 2067 6562 7020 6d69  T("begin gebp mi
+000102d0: 6372 6f20 6b65 726e 656c 2033 7058 3122  cro kernel 3pX1"
+000102e0: 293b 0a20 2020 2020 2020 2020 2020 2052  );.            R
+000102f0: 6873 5061 636b 6574 2042 5f30 3b0a 2364  hsPacket B_0;.#d
+00010300: 6566 696e 6520 4549 4745 4e5f 4745 4247  efine EIGEN_GEBG
+00010310: 505f 4f4e 4553 5445 5028 4b29 2020 2020  P_ONESTEP(K)    
+00010320: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00010330: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00010340: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010350: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010360: 2020 2020 2020 2020 2020 205c 0a20 2020             \.   
-00010370: 2020 2020 2020 2020 2020 2045 4947 454e             EIGEN
-00010380: 5f41 534d 5f43 4f4d 4d45 4e54 2822 6265  _ASM_COMMENT("be
-00010390: 6769 6e20 7374 6570 206f 6620 6765 6270  gin step of gebp
-000103a0: 206d 6963 726f 206b 6572 6e65 6c20 3370   micro kernel 3p
-000103b0: 5834 2229 3b20 2020 2020 2020 2020 205c  X4");          \
-000103c0: 0a20 2020 2020 2020 2020 2020 2020 2045  .              E
-000103d0: 4947 454e 5f41 534d 5f43 4f4d 4d45 4e54  IGEN_ASM_COMMENT
-000103e0: 2822 4e6f 7465 3a20 7468 6573 6520 6173  ("Note: these as
-000103f0: 6d20 636f 6d6d 656e 7473 2077 6f72 6b20  m comments work 
-00010400: 6172 6f75 6e64 2062 7567 2039 3335 2122  around bug 935!"
-00010410: 293b 205c 0a20 2020 2020 2020 2020 2020  ); \.           
-00010420: 2020 2069 6e74 6572 6e61 6c3a 3a70 7265     internal::pre
-00010430: 6665 7463 6828 626c 4120 2b20 2833 202a  fetch(blA + (3 *
-00010440: 204b 202b 2031 3629 202a 204c 6873 5072   K + 16) * LhsPr
-00010450: 6f67 7265 7373 293b 2020 2020 2020 2020  ogress);        
-00010460: 2020 2020 2020 205c 0a20 2020 2020 2020         \.       
-00010470: 2020 2020 2020 2069 6620 2845 4947 454e         if (EIGEN
-00010480: 5f41 5243 485f 4152 4d20 7c7c 2045 4947  _ARCH_ARM || EIG
-00010490: 454e 5f41 5243 485f 4d49 5053 2920 7b20  EN_ARCH_MIPS) { 
-000104a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000104b0: 2020 2020 2020 2020 2020 205c 0a20 2020             \.   
-000104c0: 2020 2020 2020 2020 2020 2020 2069 6e74               int
-000104d0: 6572 6e61 6c3a 3a70 7265 6665 7463 6828  ernal::prefetch(
-000104e0: 626c 4220 2b20 2834 202a 204b 202b 2031  blB + (4 * K + 1
-000104f0: 3629 202a 2052 6873 5072 6f67 7265 7373  6) * RhsProgress
-00010500: 293b 2020 2020 2020 2020 2020 2020 205c  );             \
-00010510: 0a20 2020 2020 2020 2020 2020 2020 207d  .              }
-00010520: 202f 2a20 4275 6720 3935 3320 2a2f 2020   /* Bug 953 */  
-00010530: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010540: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010550: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010560: 2020 205c 0a20 2020 2020 2020 2020 2020     \.           
-00010570: 2020 2074 7261 6974 732e 6c6f 6164 4c68     traits.loadLh
-00010580: 7328 2662 6c41 5b28 3020 2b20 3320 2a20  s(&blA[(0 + 3 * 
-00010590: 4b29 202a 204c 6873 5072 6f67 7265 7373  K) * LhsProgress
-000105a0: 5d2c 2041 3029 3b20 2020 2020 2020 2020  ], A0);         
-000105b0: 2020 2020 2020 205c 0a20 2020 2020 2020         \.       
-000105c0: 2020 2020 2020 2074 7261 6974 732e 6c6f         traits.lo
-000105d0: 6164 4c68 7328 2662 6c41 5b28 3120 2b20  adLhs(&blA[(1 + 
-000105e0: 3320 2a20 4b29 202a 204c 6873 5072 6f67  3 * K) * LhsProg
-000105f0: 7265 7373 5d2c 2041 3129 3b20 2020 2020  ress], A1);     
-00010600: 2020 2020 2020 2020 2020 205c 0a20 2020             \.   
-00010610: 2020 2020 2020 2020 2020 2074 7261 6974             trait
-00010620: 732e 6c6f 6164 4c68 7328 2662 6c41 5b28  s.loadLhs(&blA[(
-00010630: 3220 2b20 3320 2a20 4b29 202a 204c 6873  2 + 3 * K) * Lhs
-00010640: 5072 6f67 7265 7373 5d2c 2041 3229 3b20  Progress], A2); 
-00010650: 2020 2020 2020 2020 2020 2020 2020 205c                 \
-00010660: 0a20 2020 2020 2020 2020 2020 2020 2045  .              E
-00010670: 4947 454e 5f47 4542 505f 3350 5834 5f52  IGEN_GEBP_3PX4_R
-00010680: 4547 4953 5445 525f 414c 4c4f 435f 574f  EGISTER_ALLOC_WO
-00010690: 524b 4152 4f55 4e44 205c 0a20 2020 2020  RKAROUND \.     
-000106a0: 2020 2020 2020 2020 2074 7261 6974 732e           traits.
-000106b0: 6c6f 6164 5268 7328 626c 4220 2b20 2830  loadRhs(blB + (0
-000106c0: 2b34 2a4b 2920 2a20 5472 6169 7473 3a3a  +4*K) * Traits::
-000106d0: 5268 7350 726f 6772 6573 732c 2072 6873  RhsProgress, rhs
-000106e0: 5f70 616e 656c 293b 2020 2020 205c 0a20  _panel);     \. 
-000106f0: 2020 2020 2020 2020 2020 2020 2074 7261               tra
-00010700: 6974 732e 6d61 6464 2841 302c 2072 6873  its.madd(A0, rhs
-00010710: 5f70 616e 656c 2c20 4330 2c20 5430 2c20  _panel, C0, T0, 
-00010720: 6669 783c 303e 293b 2020 2020 2020 2020  fix<0>);        
-00010730: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010740: 205c 0a20 2020 2020 2020 2020 2020 2020   \.             
-00010750: 2074 7261 6974 732e 6d61 6464 2841 312c   traits.madd(A1,
-00010760: 2072 6873 5f70 616e 656c 2c20 4334 2c20   rhs_panel, C4, 
-00010770: 5430 2c20 6669 783c 303e 293b 2020 2020  T0, fix<0>);    
-00010780: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010790: 2020 2020 205c 0a20 2020 2020 2020 2020       \.         
-000107a0: 2020 2020 2074 7261 6974 732e 6d61 6464       traits.madd
-000107b0: 2841 322c 2072 6873 5f70 616e 656c 2c20  (A2, rhs_panel, 
-000107c0: 4338 2c20 5430 2c20 6669 783c 303e 293b  C8, T0, fix<0>);
-000107d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000107e0: 2020 2020 2020 2020 205c 0a20 2020 2020           \.     
-000107f0: 2020 2020 2020 2020 2074 7261 6974 732e           traits.
-00010800: 7570 6461 7465 5268 7328 626c 4220 2b20  updateRhs(blB + 
-00010810: 2831 2b34 2a4b 2920 2a20 5472 6169 7473  (1+4*K) * Traits
-00010820: 3a3a 5268 7350 726f 6772 6573 732c 2072  ::RhsProgress, r
-00010830: 6873 5f70 616e 656c 293b 2020 205c 0a20  hs_panel);   \. 
-00010840: 2020 2020 2020 2020 2020 2020 2074 7261               tra
-00010850: 6974 732e 6d61 6464 2841 302c 2072 6873  its.madd(A0, rhs
-00010860: 5f70 616e 656c 2c20 4331 2c20 5430 2c20  _panel, C1, T0, 
-00010870: 6669 783c 313e 293b 2020 2020 2020 2020  fix<1>);        
-00010880: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010890: 205c 0a20 2020 2020 2020 2020 2020 2020   \.             
-000108a0: 2074 7261 6974 732e 6d61 6464 2841 312c   traits.madd(A1,
-000108b0: 2072 6873 5f70 616e 656c 2c20 4335 2c20   rhs_panel, C5, 
-000108c0: 5430 2c20 6669 783c 313e 293b 2020 2020  T0, fix<1>);    
-000108d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000108e0: 2020 2020 205c 0a20 2020 2020 2020 2020       \.         
-000108f0: 2020 2020 2074 7261 6974 732e 6d61 6464       traits.madd
-00010900: 2841 322c 2072 6873 5f70 616e 656c 2c20  (A2, rhs_panel, 
-00010910: 4339 2c20 5430 2c20 6669 783c 313e 293b  C9, T0, fix<1>);
-00010920: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010930: 2020 2020 2020 2020 205c 0a20 2020 2020           \.     
-00010940: 2020 2020 2020 2020 2074 7261 6974 732e           traits.
-00010950: 7570 6461 7465 5268 7328 626c 4220 2b20  updateRhs(blB + 
-00010960: 2832 2b34 2a4b 2920 2a20 5472 6169 7473  (2+4*K) * Traits
-00010970: 3a3a 5268 7350 726f 6772 6573 732c 2072  ::RhsProgress, r
-00010980: 6873 5f70 616e 656c 293b 2020 205c 0a20  hs_panel);   \. 
-00010990: 2020 2020 2020 2020 2020 2020 2074 7261               tra
-000109a0: 6974 732e 6d61 6464 2841 302c 2072 6873  its.madd(A0, rhs
-000109b0: 5f70 616e 656c 2c20 4332 2c20 5430 2c20  _panel, C2, T0, 
-000109c0: 6669 783c 323e 293b 2020 2020 2020 2020  fix<2>);        
-000109d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000109e0: 205c 0a20 2020 2020 2020 2020 2020 2020   \.             
-000109f0: 2074 7261 6974 732e 6d61 6464 2841 312c   traits.madd(A1,
-00010a00: 2072 6873 5f70 616e 656c 2c20 4336 2c20   rhs_panel, C6, 
-00010a10: 5430 2c20 6669 783c 323e 293b 2020 2020  T0, fix<2>);    
-00010a20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010a30: 2020 2020 205c 0a20 2020 2020 2020 2020       \.         
-00010a40: 2020 2020 2074 7261 6974 732e 6d61 6464       traits.madd
-00010a50: 2841 322c 2072 6873 5f70 616e 656c 2c20  (A2, rhs_panel, 
-00010a60: 4331 302c 2054 302c 2066 6978 3c32 3e29  C10, T0, fix<2>)
-00010a70: 3b20 2020 2020 2020 2020 2020 2020 2020  ;               
-00010a80: 2020 2020 2020 2020 205c 0a20 2020 2020           \.     
-00010a90: 2020 2020 2020 2020 2074 7261 6974 732e           traits.
-00010aa0: 7570 6461 7465 5268 7328 626c 4220 2b20  updateRhs(blB + 
-00010ab0: 2833 2b34 2a4b 2920 2a20 5472 6169 7473  (3+4*K) * Traits
-00010ac0: 3a3a 5268 7350 726f 6772 6573 732c 2072  ::RhsProgress, r
-00010ad0: 6873 5f70 616e 656c 293b 2020 205c 0a20  hs_panel);   \. 
-00010ae0: 2020 2020 2020 2020 2020 2020 2074 7261               tra
-00010af0: 6974 732e 6d61 6464 2841 302c 2072 6873  its.madd(A0, rhs
-00010b00: 5f70 616e 656c 2c20 4333 2c20 5430 2c20  _panel, C3, T0, 
-00010b10: 6669 783c 333e 293b 2020 2020 2020 2020  fix<3>);        
-00010b20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010b30: 205c 0a20 2020 2020 2020 2020 2020 2020   \.             
-00010b40: 2074 7261 6974 732e 6d61 6464 2841 312c   traits.madd(A1,
-00010b50: 2072 6873 5f70 616e 656c 2c20 4337 2c20   rhs_panel, C7, 
-00010b60: 5430 2c20 6669 783c 333e 293b 2020 2020  T0, fix<3>);    
-00010b70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010b80: 2020 2020 205c 0a20 2020 2020 2020 2020       \.         
-00010b90: 2020 2020 2074 7261 6974 732e 6d61 6464       traits.madd
-00010ba0: 2841 322c 2072 6873 5f70 616e 656c 2c20  (A2, rhs_panel, 
-00010bb0: 4331 312c 2054 302c 2066 6978 3c33 3e29  C11, T0, fix<3>)
-00010bc0: 3b20 2020 2020 2020 2020 2020 2020 2020  ;               
-00010bd0: 2020 2020 2020 2020 205c 0a20 2020 2020           \.     
-00010be0: 2020 2020 2020 2020 2045 4947 454e 5f41           EIGEN_A
-00010bf0: 534d 5f43 4f4d 4d45 4e54 2822 656e 6420  SM_COMMENT("end 
-00010c00: 7374 6570 206f 6620 6765 6270 206d 6963  step of gebp mic
-00010c10: 726f 206b 6572 6e65 6c20 3370 5834 2229  ro kernel 3pX4")
-00010c20: 3b20 2020 2020 2020 2020 2020 205c 0a20  ;            \. 
-00010c30: 2020 2020 2020 2020 2020 207d 2077 6869             } whi
-00010c40: 6c65 2028 6661 6c73 6529 0a0a 2020 2020  le (false)..    
-00010c50: 2020 2020 2020 2020 696e 7465 726e 616c          internal
-00010c60: 3a3a 7072 6566 6574 6368 2862 6c42 293b  ::prefetch(blB);
-00010c70: 0a20 2020 2020 2020 2020 2020 2045 4947  .            EIG
-00010c80: 454e 5f47 4542 505f 4f4e 4553 5445 5028  EN_GEBP_ONESTEP(
-00010c90: 3029 3b0a 2020 2020 2020 2020 2020 2020  0);.            
-00010ca0: 4549 4745 4e5f 4745 4250 5f4f 4e45 5354  EIGEN_GEBP_ONEST
-00010cb0: 4550 2831 293b 0a20 2020 2020 2020 2020  EP(1);.         
-00010cc0: 2020 2045 4947 454e 5f47 4542 505f 4f4e     EIGEN_GEBP_ON
-00010cd0: 4553 5445 5028 3229 3b0a 2020 2020 2020  ESTEP(2);.      
-00010ce0: 2020 2020 2020 4549 4745 4e5f 4745 4250        EIGEN_GEBP
-00010cf0: 5f4f 4e45 5354 4550 2833 293b 0a20 2020  _ONESTEP(3);.   
-00010d00: 2020 2020 2020 2020 2045 4947 454e 5f47           EIGEN_G
-00010d10: 4542 505f 4f4e 4553 5445 5028 3429 3b0a  EBP_ONESTEP(4);.
-00010d20: 2020 2020 2020 2020 2020 2020 4549 4745              EIGE
-00010d30: 4e5f 4745 4250 5f4f 4e45 5354 4550 2835  N_GEBP_ONESTEP(5
-00010d40: 293b 0a20 2020 2020 2020 2020 2020 2045  );.            E
-00010d50: 4947 454e 5f47 4542 505f 4f4e 4553 5445  IGEN_GEBP_ONESTE
-00010d60: 5028 3629 3b0a 2020 2020 2020 2020 2020  P(6);.          
-00010d70: 2020 4549 4745 4e5f 4745 4250 5f4f 4e45    EIGEN_GEBP_ONE
-00010d80: 5354 4550 2837 293b 0a0a 2020 2020 2020  STEP(7);..      
-00010d90: 2020 2020 2020 626c 4220 2b3d 2070 6b2a        blB += pk*
-00010da0: 342a 5268 7350 726f 6772 6573 733b 0a20  4*RhsProgress;. 
-00010db0: 2020 2020 2020 2020 2020 2062 6c41 202b             blA +
-00010dc0: 3d20 706b 2a33 2a54 7261 6974 733a 3a4c  = pk*3*Traits::L
-00010dd0: 6873 5072 6f67 7265 7373 3b0a 0a20 2020  hsProgress;..   
-00010de0: 2020 2020 2020 2020 2045 4947 454e 5f41           EIGEN_A
-00010df0: 534d 5f43 4f4d 4d45 4e54 2822 656e 6420  SM_COMMENT("end 
-00010e00: 6765 6270 206d 6963 726f 206b 6572 6e65  gebp micro kerne
-00010e10: 6c20 3370 5834 2229 3b0a 2020 2020 2020  l 3pX4");.      
-00010e20: 2020 2020 7d0a 2020 2020 2020 2020 2020      }.          
-00010e30: 2f2f 2070 726f 6365 7373 2072 656d 6169  // process remai
-00010e40: 6e69 6e67 2070 6565 6c65 6420 6c6f 6f70  ning peeled loop
-00010e50: 0a20 2020 2020 2020 2020 2066 6f72 2849  .          for(I
-00010e60: 6e64 6578 206b 3d70 6565 6c65 645f 6b63  ndex k=peeled_kc
-00010e70: 3b20 6b3c 6465 7074 683b 206b 2b2b 290a  ; k<depth; k++).
-00010e80: 2020 2020 2020 2020 2020 7b0a 2020 2020            {.    
-00010e90: 2020 2020 2020 2020 5268 7350 616e 656c          RhsPanel
-00010ea0: 3135 2072 6873 5f70 616e 656c 3b0a 2020  15 rhs_panel;.  
-00010eb0: 2020 2020 2020 2020 2020 5268 7350 6163            RhsPac
-00010ec0: 6b65 7420 5430 3b0a 2020 2020 2020 2020  ket T0;.        
-00010ed0: 2020 2020 4c68 7350 6163 6b65 7420 4132      LhsPacket A2
-00010ee0: 3b0a 2020 2020 2020 2020 2020 2020 4549  ;.            EI
-00010ef0: 4745 4e5f 4745 4250 5f4f 4e45 5354 4550  GEN_GEBP_ONESTEP
-00010f00: 2830 293b 0a20 2020 2020 2020 2020 2020  (0);.           
-00010f10: 2062 6c42 202b 3d20 342a 5268 7350 726f   blB += 4*RhsPro
-00010f20: 6772 6573 733b 0a20 2020 2020 2020 2020  gress;.         
-00010f30: 2020 2062 6c41 202b 3d20 332a 5472 6169     blA += 3*Trai
-00010f40: 7473 3a3a 4c68 7350 726f 6772 6573 733b  ts::LhsProgress;
-00010f50: 0a20 2020 2020 2020 2020 207d 0a0a 2375  .          }..#u
-00010f60: 6e64 6566 2045 4947 454e 5f47 4542 505f  ndef EIGEN_GEBP_
-00010f70: 4f4e 4553 5445 500a 0a20 2020 2020 2020  ONESTEP..       
-00010f80: 2020 2052 6573 5061 636b 6574 2052 302c     ResPacket R0,
-00010f90: 2052 312c 2052 323b 0a20 2020 2020 2020   R1, R2;.       
-00010fa0: 2020 2052 6573 5061 636b 6574 2061 6c70     ResPacket alp
-00010fb0: 6861 7620 3d20 7073 6574 313c 5265 7350  hav = pset1<ResP
-00010fc0: 6163 6b65 743e 2861 6c70 6861 293b 0a0a  acket>(alpha);..
-00010fd0: 2020 2020 2020 2020 2020 5230 203d 2072            R0 = r
-00010fe0: 302e 7465 6d70 6c61 7465 206c 6f61 6450  0.template loadP
-00010ff0: 6163 6b65 743c 5265 7350 6163 6b65 743e  acket<ResPacket>
-00011000: 2830 202a 2054 7261 6974 733a 3a52 6573  (0 * Traits::Res
-00011010: 5061 636b 6574 5369 7a65 293b 0a20 2020  PacketSize);.   
-00011020: 2020 2020 2020 2052 3120 3d20 7230 2e74         R1 = r0.t
-00011030: 656d 706c 6174 6520 6c6f 6164 5061 636b  emplate loadPack
-00011040: 6574 3c52 6573 5061 636b 6574 3e28 3120  et<ResPacket>(1 
-00011050: 2a20 5472 6169 7473 3a3a 5265 7350 6163  * Traits::ResPac
-00011060: 6b65 7453 697a 6529 3b0a 2020 2020 2020  ketSize);.      
-00011070: 2020 2020 5232 203d 2072 302e 7465 6d70      R2 = r0.temp
-00011080: 6c61 7465 206c 6f61 6450 6163 6b65 743c  late loadPacket<
-00011090: 5265 7350 6163 6b65 743e 2832 202a 2054  ResPacket>(2 * T
-000110a0: 7261 6974 733a 3a52 6573 5061 636b 6574  raits::ResPacket
-000110b0: 5369 7a65 293b 0a20 2020 2020 2020 2020  Size);.         
-000110c0: 2074 7261 6974 732e 6163 6328 4330 2c20   traits.acc(C0, 
-000110d0: 616c 7068 6176 2c20 5230 293b 0a20 2020  alphav, R0);.   
-000110e0: 2020 2020 2020 2074 7261 6974 732e 6163         traits.ac
-000110f0: 6328 4334 2c20 616c 7068 6176 2c20 5231  c(C4, alphav, R1
-00011100: 293b 0a20 2020 2020 2020 2020 2074 7261  );.          tra
-00011110: 6974 732e 6163 6328 4338 2c20 616c 7068  its.acc(C8, alph
-00011120: 6176 2c20 5232 293b 0a20 2020 2020 2020  av, R2);.       
-00011130: 2020 2072 302e 7374 6f72 6550 6163 6b65     r0.storePacke
-00011140: 7428 3020 2a20 5472 6169 7473 3a3a 5265  t(0 * Traits::Re
-00011150: 7350 6163 6b65 7453 697a 652c 2052 3029  sPacketSize, R0)
-00011160: 3b0a 2020 2020 2020 2020 2020 7230 2e73  ;.          r0.s
-00011170: 746f 7265 5061 636b 6574 2831 202a 2054  torePacket(1 * T
-00011180: 7261 6974 733a 3a52 6573 5061 636b 6574  raits::ResPacket
-00011190: 5369 7a65 2c20 5231 293b 0a20 2020 2020  Size, R1);.     
-000111a0: 2020 2020 2072 302e 7374 6f72 6550 6163       r0.storePac
-000111b0: 6b65 7428 3220 2a20 5472 6169 7473 3a3a  ket(2 * Traits::
-000111c0: 5265 7350 6163 6b65 7453 697a 652c 2052  ResPacketSize, R
-000111d0: 3229 3b0a 0a20 2020 2020 2020 2020 2052  2);..          R
-000111e0: 3020 3d20 7231 2e74 656d 706c 6174 6520  0 = r1.template 
-000111f0: 6c6f 6164 5061 636b 6574 3c52 6573 5061  loadPacket<ResPa
-00011200: 636b 6574 3e28 3020 2a20 5472 6169 7473  cket>(0 * Traits
-00011210: 3a3a 5265 7350 6163 6b65 7453 697a 6529  ::ResPacketSize)
-00011220: 3b0a 2020 2020 2020 2020 2020 5231 203d  ;.          R1 =
-00011230: 2072 312e 7465 6d70 6c61 7465 206c 6f61   r1.template loa
-00011240: 6450 6163 6b65 743c 5265 7350 6163 6b65  dPacket<ResPacke
-00011250: 743e 2831 202a 2054 7261 6974 733a 3a52  t>(1 * Traits::R
-00011260: 6573 5061 636b 6574 5369 7a65 293b 0a20  esPacketSize);. 
-00011270: 2020 2020 2020 2020 2052 3220 3d20 7231           R2 = r1
-00011280: 2e74 656d 706c 6174 6520 6c6f 6164 5061  .template loadPa
-00011290: 636b 6574 3c52 6573 5061 636b 6574 3e28  cket<ResPacket>(
-000112a0: 3220 2a20 5472 6169 7473 3a3a 5265 7350  2 * Traits::ResP
-000112b0: 6163 6b65 7453 697a 6529 3b0a 2020 2020  acketSize);.    
-000112c0: 2020 2020 2020 7472 6169 7473 2e61 6363        traits.acc
-000112d0: 2843 312c 2061 6c70 6861 762c 2052 3029  (C1, alphav, R0)
-000112e0: 3b0a 2020 2020 2020 2020 2020 7472 6169  ;.          trai
-000112f0: 7473 2e61 6363 2843 352c 2061 6c70 6861  ts.acc(C5, alpha
-00011300: 762c 2052 3129 3b0a 2020 2020 2020 2020  v, R1);.        
-00011310: 2020 7472 6169 7473 2e61 6363 2843 392c    traits.acc(C9,
-00011320: 2061 6c70 6861 762c 2052 3229 3b0a 2020   alphav, R2);.  
-00011330: 2020 2020 2020 2020 7231 2e73 746f 7265          r1.store
-00011340: 5061 636b 6574 2830 202a 2054 7261 6974  Packet(0 * Trait
-00011350: 733a 3a52 6573 5061 636b 6574 5369 7a65  s::ResPacketSize
-00011360: 2c20 5230 293b 0a20 2020 2020 2020 2020  , R0);.         
-00011370: 2072 312e 7374 6f72 6550 6163 6b65 7428   r1.storePacket(
-00011380: 3120 2a20 5472 6169 7473 3a3a 5265 7350  1 * Traits::ResP
-00011390: 6163 6b65 7453 697a 652c 2052 3129 3b0a  acketSize, R1);.
-000113a0: 2020 2020 2020 2020 2020 7231 2e73 746f            r1.sto
-000113b0: 7265 5061 636b 6574 2832 202a 2054 7261  rePacket(2 * Tra
-000113c0: 6974 733a 3a52 6573 5061 636b 6574 5369  its::ResPacketSi
-000113d0: 7a65 2c20 5232 293b 0a0a 2020 2020 2020  ze, R2);..      
-000113e0: 2020 2020 5230 203d 2072 322e 7465 6d70      R0 = r2.temp
-000113f0: 6c61 7465 206c 6f61 6450 6163 6b65 743c  late loadPacket<
-00011400: 5265 7350 6163 6b65 743e 2830 202a 2054  ResPacket>(0 * T
-00011410: 7261 6974 733a 3a52 6573 5061 636b 6574  raits::ResPacket
-00011420: 5369 7a65 293b 0a20 2020 2020 2020 2020  Size);.         
-00011430: 2052 3120 3d20 7232 2e74 656d 706c 6174   R1 = r2.templat
-00011440: 6520 6c6f 6164 5061 636b 6574 3c52 6573  e loadPacket<Res
-00011450: 5061 636b 6574 3e28 3120 2a20 5472 6169  Packet>(1 * Trai
-00011460: 7473 3a3a 5265 7350 6163 6b65 7453 697a  ts::ResPacketSiz
-00011470: 6529 3b0a 2020 2020 2020 2020 2020 5232  e);.          R2
-00011480: 203d 2072 322e 7465 6d70 6c61 7465 206c   = r2.template l
-00011490: 6f61 6450 6163 6b65 743c 5265 7350 6163  oadPacket<ResPac
-000114a0: 6b65 743e 2832 202a 2054 7261 6974 733a  ket>(2 * Traits:
-000114b0: 3a52 6573 5061 636b 6574 5369 7a65 293b  :ResPacketSize);
-000114c0: 0a20 2020 2020 2020 2020 2074 7261 6974  .          trait
-000114d0: 732e 6163 6328 4332 2c20 616c 7068 6176  s.acc(C2, alphav
-000114e0: 2c20 5230 293b 0a20 2020 2020 2020 2020  , R0);.         
-000114f0: 2074 7261 6974 732e 6163 6328 4336 2c20   traits.acc(C6, 
-00011500: 616c 7068 6176 2c20 5231 293b 0a20 2020  alphav, R1);.   
-00011510: 2020 2020 2020 2074 7261 6974 732e 6163         traits.ac
-00011520: 6328 4331 302c 2061 6c70 6861 762c 2052  c(C10, alphav, R
-00011530: 3229 3b0a 2020 2020 2020 2020 2020 7232  2);.          r2
-00011540: 2e73 746f 7265 5061 636b 6574 2830 202a  .storePacket(0 *
-00011550: 2054 7261 6974 733a 3a52 6573 5061 636b   Traits::ResPack
-00011560: 6574 5369 7a65 2c20 5230 293b 0a20 2020  etSize, R0);.   
-00011570: 2020 2020 2020 2072 322e 7374 6f72 6550         r2.storeP
-00011580: 6163 6b65 7428 3120 2a20 5472 6169 7473  acket(1 * Traits
-00011590: 3a3a 5265 7350 6163 6b65 7453 697a 652c  ::ResPacketSize,
-000115a0: 2052 3129 3b0a 2020 2020 2020 2020 2020   R1);.          
-000115b0: 7232 2e73 746f 7265 5061 636b 6574 2832  r2.storePacket(2
-000115c0: 202a 2054 7261 6974 733a 3a52 6573 5061   * Traits::ResPa
-000115d0: 636b 6574 5369 7a65 2c20 5232 293b 0a0a  cketSize, R2);..
-000115e0: 2020 2020 2020 2020 2020 5230 203d 2072            R0 = r
-000115f0: 332e 7465 6d70 6c61 7465 206c 6f61 6450  3.template loadP
-00011600: 6163 6b65 743c 5265 7350 6163 6b65 743e  acket<ResPacket>
-00011610: 2830 202a 2054 7261 6974 733a 3a52 6573  (0 * Traits::Res
-00011620: 5061 636b 6574 5369 7a65 293b 0a20 2020  PacketSize);.   
-00011630: 2020 2020 2020 2052 3120 3d20 7233 2e74         R1 = r3.t
-00011640: 656d 706c 6174 6520 6c6f 6164 5061 636b  emplate loadPack
-00011650: 6574 3c52 6573 5061 636b 6574 3e28 3120  et<ResPacket>(1 
-00011660: 2a20 5472 6169 7473 3a3a 5265 7350 6163  * Traits::ResPac
-00011670: 6b65 7453 697a 6529 3b0a 2020 2020 2020  ketSize);.      
-00011680: 2020 2020 5232 203d 2072 332e 7465 6d70      R2 = r3.temp
-00011690: 6c61 7465 206c 6f61 6450 6163 6b65 743c  late loadPacket<
-000116a0: 5265 7350 6163 6b65 743e 2832 202a 2054  ResPacket>(2 * T
-000116b0: 7261 6974 733a 3a52 6573 5061 636b 6574  raits::ResPacket
-000116c0: 5369 7a65 293b 0a20 2020 2020 2020 2020  Size);.         
-000116d0: 2074 7261 6974 732e 6163 6328 4333 2c20   traits.acc(C3, 
-000116e0: 616c 7068 6176 2c20 5230 293b 0a20 2020  alphav, R0);.   
-000116f0: 2020 2020 2020 2074 7261 6974 732e 6163         traits.ac
-00011700: 6328 4337 2c20 616c 7068 6176 2c20 5231  c(C7, alphav, R1
-00011710: 293b 0a20 2020 2020 2020 2020 2074 7261  );.          tra
-00011720: 6974 732e 6163 6328 4331 312c 2061 6c70  its.acc(C11, alp
-00011730: 6861 762c 2052 3229 3b0a 2020 2020 2020  hav, R2);.      
-00011740: 2020 2020 7233 2e73 746f 7265 5061 636b      r3.storePack
-00011750: 6574 2830 202a 2054 7261 6974 733a 3a52  et(0 * Traits::R
-00011760: 6573 5061 636b 6574 5369 7a65 2c20 5230  esPacketSize, R0
-00011770: 293b 0a20 2020 2020 2020 2020 2072 332e  );.          r3.
-00011780: 7374 6f72 6550 6163 6b65 7428 3120 2a20  storePacket(1 * 
-00011790: 5472 6169 7473 3a3a 5265 7350 6163 6b65  Traits::ResPacke
-000117a0: 7453 697a 652c 2052 3129 3b0a 2020 2020  tSize, R1);.    
-000117b0: 2020 2020 2020 7233 2e73 746f 7265 5061        r3.storePa
-000117c0: 636b 6574 2832 202a 2054 7261 6974 733a  cket(2 * Traits:
-000117d0: 3a52 6573 5061 636b 6574 5369 7a65 2c20  :ResPacketSize, 
-000117e0: 5232 293b 2020 2020 2020 2020 2020 0a20  R2);          . 
-000117f0: 2020 2020 2020 2020 207d 0a20 2020 2020           }.     
-00011800: 2020 207d 0a0a 2020 2020 2020 2020 2f2f     }..        //
-00011810: 2044 6561 6c20 7769 7468 2072 656d 6169   Deal with remai
-00011820: 6e69 6e67 2063 6f6c 756d 6e73 206f 6620  ning columns of 
-00011830: 7468 6520 7268 730a 2020 2020 2020 2020  the rhs.        
-00011840: 666f 7228 496e 6465 7820 6a32 3d70 6163  for(Index j2=pac
-00011850: 6b65 745f 636f 6c73 343b 206a 323c 636f  ket_cols4; j2<co
-00011860: 6c73 3b20 6a32 2b2b 290a 2020 2020 2020  ls; j2++).      
-00011870: 2020 7b0a 2020 2020 2020 2020 2020 666f    {.          fo
-00011880: 7228 496e 6465 7820 693d 6931 3b20 693c  r(Index i=i1; i<
-00011890: 6163 7475 616c 5f70 616e 656c 5f65 6e64  actual_panel_end
-000118a0: 3b20 692b 3d33 2a4c 6873 5072 6f67 7265  ; i+=3*LhsProgre
-000118b0: 7373 290a 2020 2020 2020 2020 2020 7b0a  ss).          {.
-000118c0: 2020 2020 2020 2020 2020 2f2f 204f 6e65            // One
-000118d0: 2063 6f6c 756d 6e20 6174 2061 2074 696d   column at a tim
-000118e0: 650a 2020 2020 2020 2020 2020 636f 6e73  e.          cons
-000118f0: 7420 4c68 7353 6361 6c61 722a 2062 6c41  t LhsScalar* blA
-00011900: 203d 2026 626c 6f63 6b41 5b69 2a73 7472   = &blockA[i*str
-00011910: 6964 6541 2b6f 6666 7365 7441 2a28 332a  ideA+offsetA*(3*
-00011920: 5472 6169 7473 3a3a 4c68 7350 726f 6772  Traits::LhsProgr
-00011930: 6573 7329 5d3b 0a20 2020 2020 2020 2020  ess)];.         
-00011940: 2070 7265 6665 7463 6828 2662 6c41 5b30   prefetch(&blA[0
-00011950: 5d29 3b0a 0a20 2020 2020 2020 2020 202f  ]);..          /
-00011960: 2f20 6765 7473 2072 6573 2062 6c6f 636b  / gets res block
-00011970: 2061 7320 7265 6769 7374 6572 0a20 2020   as register.   
-00011980: 2020 2020 2020 2041 6363 5061 636b 6574         AccPacket
-00011990: 2043 302c 2043 342c 2043 383b 0a20 2020   C0, C4, C8;.   
-000119a0: 2020 2020 2020 2074 7261 6974 732e 696e         traits.in
-000119b0: 6974 4163 6328 4330 293b 0a20 2020 2020  itAcc(C0);.     
-000119c0: 2020 2020 2074 7261 6974 732e 696e 6974       traits.init
-000119d0: 4163 6328 4334 293b 0a20 2020 2020 2020  Acc(C4);.       
-000119e0: 2020 2074 7261 6974 732e 696e 6974 4163     traits.initAc
-000119f0: 6328 4338 293b 0a0a 2020 2020 2020 2020  c(C8);..        
-00011a00: 2020 4c69 6e65 6172 4d61 7070 6572 2072    LinearMapper r
-00011a10: 3020 3d20 7265 732e 6765 744c 696e 6561  0 = res.getLinea
-00011a20: 724d 6170 7065 7228 692c 206a 3229 3b0a  rMapper(i, j2);.
-00011a30: 2020 2020 2020 2020 2020 7230 2e70 7265            r0.pre
-00011a40: 6665 7463 6828 3029 3b0a 0a20 2020 2020  fetch(0);..     
-00011a50: 2020 2020 202f 2f20 7065 7266 6f72 6d73       // performs
-00011a60: 2022 696e 6e65 7222 2070 726f 6475 6374   "inner" product
-00011a70: 730a 2020 2020 2020 2020 2020 636f 6e73  s.          cons
-00011a80: 7420 5268 7353 6361 6c61 722a 2062 6c42  t RhsScalar* blB
-00011a90: 203d 2026 626c 6f63 6b42 5b6a 322a 7374   = &blockB[j2*st
-00011aa0: 7269 6465 422b 6f66 6673 6574 425d 3b0a  rideB+offsetB];.
-00011ab0: 2020 2020 2020 2020 2020 4c68 7350 6163            LhsPac
-00011ac0: 6b65 7420 4130 2c20 4131 2c20 4132 3b0a  ket A0, A1, A2;.
-00011ad0: 2020 2020 2020 2020 2020 0a20 2020 2020            .     
-00011ae0: 2020 2020 2066 6f72 2849 6e64 6578 206b       for(Index k
-00011af0: 3d30 3b20 6b3c 7065 656c 6564 5f6b 633b  =0; k<peeled_kc;
-00011b00: 206b 2b3d 706b 290a 2020 2020 2020 2020   k+=pk).        
-00011b10: 2020 7b0a 2020 2020 2020 2020 2020 2020    {.            
-00011b20: 4549 4745 4e5f 4153 4d5f 434f 4d4d 454e  EIGEN_ASM_COMMEN
-00011b30: 5428 2262 6567 696e 2067 6562 7020 6d69  T("begin gebp mi
-00011b40: 6372 6f20 6b65 726e 656c 2033 7058 3122  cro kernel 3pX1"
-00011b50: 293b 0a20 2020 2020 2020 2020 2020 2052  );.            R
-00011b60: 6873 5061 636b 6574 2042 5f30 3b0a 2364  hsPacket B_0;.#d
-00011b70: 6566 696e 6520 4549 4745 4e5f 4745 4247  efine EIGEN_GEBG
-00011b80: 505f 4f4e 4553 5445 5028 4b29 2020 2020  P_ONESTEP(K)    
-00011b90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011ba0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011bb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011bc0: 5c0a 2020 2020 2020 2020 2020 2020 646f  \.            do
-00011bd0: 207b 2020 2020 2020 2020 2020 2020 2020   {              
-00011be0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011bf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011c00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011c10: 2020 2020 5c0a 2020 2020 2020 2020 2020      \.          
-00011c20: 2020 2020 4549 4745 4e5f 4153 4d5f 434f      EIGEN_ASM_CO
-00011c30: 4d4d 454e 5428 2262 6567 696e 2073 7465  MMENT("begin ste
-00011c40: 7020 6f66 2067 6562 7020 6d69 6372 6f20  p of gebp micro 
-00011c50: 6b65 726e 656c 2033 7058 3122 293b 2020  kernel 3pX1");  
-00011c60: 2020 2020 2020 2020 5c0a 2020 2020 2020          \.      
-00011c70: 2020 2020 2020 2020 4549 4745 4e5f 4153          EIGEN_AS
-00011c80: 4d5f 434f 4d4d 454e 5428 224e 6f74 653a  M_COMMENT("Note:
-00011c90: 2074 6865 7365 2061 736d 2063 6f6d 6d65   these asm comme
-00011ca0: 6e74 7320 776f 726b 2061 726f 756e 6420  nts work around 
-00011cb0: 6275 6720 3933 3521 2229 3b20 5c0a 2020  bug 935!"); \.  
-00011cc0: 2020 2020 2020 2020 2020 2020 7472 6169              trai
-00011cd0: 7473 2e6c 6f61 644c 6873 2826 626c 415b  ts.loadLhs(&blA[
-00011ce0: 2830 202b 2033 202a 204b 2920 2a20 4c68  (0 + 3 * K) * Lh
-00011cf0: 7350 726f 6772 6573 735d 2c20 4130 293b  sProgress], A0);
-00011d00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011d10: 5c0a 2020 2020 2020 2020 2020 2020 2020  \.              
-00011d20: 7472 6169 7473 2e6c 6f61 644c 6873 2826  traits.loadLhs(&
-00011d30: 626c 415b 2831 202b 2033 202a 204b 2920  blA[(1 + 3 * K) 
-00011d40: 2a20 4c68 7350 726f 6772 6573 735d 2c20  * LhsProgress], 
-00011d50: 4131 293b 2020 2020 2020 2020 2020 2020  A1);            
-00011d60: 2020 2020 5c0a 2020 2020 2020 2020 2020      \.          
-00011d70: 2020 2020 7472 6169 7473 2e6c 6f61 644c      traits.loadL
-00011d80: 6873 2826 626c 415b 2832 202b 2033 202a  hs(&blA[(2 + 3 *
-00011d90: 204b 2920 2a20 4c68 7350 726f 6772 6573   K) * LhsProgres
-00011da0: 735d 2c20 4132 293b 2020 2020 2020 2020  s], A2);        
-00011db0: 2020 2020 2020 2020 5c0a 2020 2020 2020          \.      
-00011dc0: 2020 2020 2020 2020 7472 6169 7473 2e6c          traits.l
-00011dd0: 6f61 6452 6873 2826 626c 425b 2830 202b  oadRhs(&blB[(0 +
-00011de0: 204b 2920 2a20 5268 7350 726f 6772 6573   K) * RhsProgres
-00011df0: 735d 2c20 425f 3029 3b20 2020 2020 2020  s], B_0);       
-00011e00: 2020 2020 2020 2020 2020 2020 5c0a 2020              \.  
-00011e10: 2020 2020 2020 2020 2020 2020 7472 6169              trai
-00011e20: 7473 2e6d 6164 6428 4130 2c20 425f 302c  ts.madd(A0, B_0,
-00011e30: 2043 302c 2042 5f30 2c20 6669 783c 303e   C0, B_0, fix<0>
-00011e40: 293b 2020 2020 2020 2020 2020 2020 2020  );              
-00011e50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011e60: 5c0a 2020 2020 2020 2020 2020 2020 2020  \.              
-00011e70: 7472 6169 7473 2e6d 6164 6428 4131 2c20  traits.madd(A1, 
-00011e80: 425f 302c 2043 342c 2042 5f30 2c20 6669  B_0, C4, B_0, fi
-00011e90: 783c 303e 293b 2020 2020 2020 2020 2020  x<0>);          
-00011ea0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011eb0: 2020 2020 5c0a 2020 2020 2020 2020 2020      \.          
-00011ec0: 2020 2020 7472 6169 7473 2e6d 6164 6428      traits.madd(
-00011ed0: 4132 2c20 425f 302c 2043 382c 2042 5f30  A2, B_0, C8, B_0
-00011ee0: 2c20 6669 783c 303e 293b 2020 2020 2020  , fix<0>);      
-00011ef0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011f00: 2020 2020 2020 2020 5c0a 2020 2020 2020          \.      
-00011f10: 2020 2020 2020 2020 4549 4745 4e5f 4153          EIGEN_AS
-00011f20: 4d5f 434f 4d4d 454e 5428 2265 6e64 2073  M_COMMENT("end s
-00011f30: 7465 7020 6f66 2067 6562 7020 6d69 6372  tep of gebp micr
-00011f40: 6f20 6b65 726e 656c 2033 7058 3122 293b  o kernel 3pX1");
-00011f50: 2020 2020 2020 2020 2020 2020 5c0a 2020              \.  
-00011f60: 2020 2020 2020 2020 2020 7d20 7768 696c            } whil
-00011f70: 6520 2866 616c 7365 290a 0a20 2020 2020  e (false)..     
-00011f80: 2020 2020 2020 2045 4947 454e 5f47 4542         EIGEN_GEB
-00011f90: 4750 5f4f 4e45 5354 4550 2830 293b 0a20  GP_ONESTEP(0);. 
-00011fa0: 2020 2020 2020 2020 2020 2045 4947 454e             EIGEN
-00011fb0: 5f47 4542 4750 5f4f 4e45 5354 4550 2831  _GEBGP_ONESTEP(1
-00011fc0: 293b 0a20 2020 2020 2020 2020 2020 2045  );.            E
-00011fd0: 4947 454e 5f47 4542 4750 5f4f 4e45 5354  IGEN_GEBGP_ONEST
-00011fe0: 4550 2832 293b 0a20 2020 2020 2020 2020  EP(2);.         
-00011ff0: 2020 2045 4947 454e 5f47 4542 4750 5f4f     EIGEN_GEBGP_O
-00012000: 4e45 5354 4550 2833 293b 0a20 2020 2020  NESTEP(3);.     
-00012010: 2020 2020 2020 2045 4947 454e 5f47 4542         EIGEN_GEB
-00012020: 4750 5f4f 4e45 5354 4550 2834 293b 0a20  GP_ONESTEP(4);. 
-00012030: 2020 2020 2020 2020 2020 2045 4947 454e             EIGEN
-00012040: 5f47 4542 4750 5f4f 4e45 5354 4550 2835  _GEBGP_ONESTEP(5
-00012050: 293b 0a20 2020 2020 2020 2020 2020 2045  );.            E
-00012060: 4947 454e 5f47 4542 4750 5f4f 4e45 5354  IGEN_GEBGP_ONEST
-00012070: 4550 2836 293b 0a20 2020 2020 2020 2020  EP(6);.         
-00012080: 2020 2045 4947 454e 5f47 4542 4750 5f4f     EIGEN_GEBGP_O
-00012090: 4e45 5354 4550 2837 293b 0a0a 2020 2020  NESTEP(7);..    
-000120a0: 2020 2020 2020 2020 626c 4220 2b3d 2070          blB += p
-000120b0: 6b2a 5268 7350 726f 6772 6573 733b 0a20  k*RhsProgress;. 
-000120c0: 2020 2020 2020 2020 2020 2062 6c41 202b             blA +
-000120d0: 3d20 706b 2a33 2a54 7261 6974 733a 3a4c  = pk*3*Traits::L
-000120e0: 6873 5072 6f67 7265 7373 3b0a 0a20 2020  hsProgress;..   
-000120f0: 2020 2020 2020 2020 2045 4947 454e 5f41           EIGEN_A
-00012100: 534d 5f43 4f4d 4d45 4e54 2822 656e 6420  SM_COMMENT("end 
-00012110: 6765 6270 206d 6963 726f 206b 6572 6e65  gebp micro kerne
-00012120: 6c20 3370 5831 2229 3b0a 2020 2020 2020  l 3pX1");.      
-00012130: 2020 2020 7d0a 0a20 2020 2020 2020 2020      }..         
-00012140: 202f 2f20 7072 6f63 6573 7320 7265 6d61   // process rema
-00012150: 696e 696e 6720 7065 656c 6564 206c 6f6f  ining peeled loo
-00012160: 700a 2020 2020 2020 2020 2020 666f 7228  p.          for(
-00012170: 496e 6465 7820 6b3d 7065 656c 6564 5f6b  Index k=peeled_k
-00012180: 633b 206b 3c64 6570 7468 3b20 6b2b 2b29  c; k<depth; k++)
-00012190: 0a20 2020 2020 2020 2020 207b 0a20 2020  .          {.   
-000121a0: 2020 2020 2020 2020 2052 6873 5061 636b           RhsPack
-000121b0: 6574 2042 5f30 3b0a 2020 2020 2020 2020  et B_0;.        
-000121c0: 2020 2020 4549 4745 4e5f 4745 4247 505f      EIGEN_GEBGP_
-000121d0: 4f4e 4553 5445 5028 3029 3b0a 2020 2020  ONESTEP(0);.    
-000121e0: 2020 2020 2020 2020 626c 4220 2b3d 2052          blB += R
-000121f0: 6873 5072 6f67 7265 7373 3b0a 2020 2020  hsProgress;.    
-00012200: 2020 2020 2020 2020 626c 4120 2b3d 2033          blA += 3
-00012210: 2a54 7261 6974 733a 3a4c 6873 5072 6f67  *Traits::LhsProg
-00012220: 7265 7373 3b0a 2020 2020 2020 2020 2020  ress;.          
-00012230: 7d0a 2375 6e64 6566 2045 4947 454e 5f47  }.#undef EIGEN_G
-00012240: 4542 4750 5f4f 4e45 5354 4550 0a20 2020  EBGP_ONESTEP.   
-00012250: 2020 2020 2020 2052 6573 5061 636b 6574         ResPacket
-00012260: 2052 302c 2052 312c 2052 323b 0a20 2020   R0, R1, R2;.   
-00012270: 2020 2020 2020 2052 6573 5061 636b 6574         ResPacket
-00012280: 2061 6c70 6861 7620 3d20 7073 6574 313c   alphav = pset1<
-00012290: 5265 7350 6163 6b65 743e 2861 6c70 6861  ResPacket>(alpha
-000122a0: 293b 0a0a 2020 2020 2020 2020 2020 5230  );..          R0
-000122b0: 203d 2072 302e 7465 6d70 6c61 7465 206c   = r0.template l
-000122c0: 6f61 6450 6163 6b65 743c 5265 7350 6163  oadPacket<ResPac
-000122d0: 6b65 743e 2830 202a 2054 7261 6974 733a  ket>(0 * Traits:
-000122e0: 3a52 6573 5061 636b 6574 5369 7a65 293b  :ResPacketSize);
-000122f0: 0a20 2020 2020 2020 2020 2052 3120 3d20  .          R1 = 
-00012300: 7230 2e74 656d 706c 6174 6520 6c6f 6164  r0.template load
-00012310: 5061 636b 6574 3c52 6573 5061 636b 6574  Packet<ResPacket
-00012320: 3e28 3120 2a20 5472 6169 7473 3a3a 5265  >(1 * Traits::Re
-00012330: 7350 6163 6b65 7453 697a 6529 3b0a 2020  sPacketSize);.  
-00012340: 2020 2020 2020 2020 5232 203d 2072 302e          R2 = r0.
-00012350: 7465 6d70 6c61 7465 206c 6f61 6450 6163  template loadPac
-00012360: 6b65 743c 5265 7350 6163 6b65 743e 2832  ket<ResPacket>(2
-00012370: 202a 2054 7261 6974 733a 3a52 6573 5061   * Traits::ResPa
-00012380: 636b 6574 5369 7a65 293b 0a20 2020 2020  cketSize);.     
-00012390: 2020 2020 2074 7261 6974 732e 6163 6328       traits.acc(
-000123a0: 4330 2c20 616c 7068 6176 2c20 5230 293b  C0, alphav, R0);
-000123b0: 0a20 2020 2020 2020 2020 2074 7261 6974  .          trait
-000123c0: 732e 6163 6328 4334 2c20 616c 7068 6176  s.acc(C4, alphav
-000123d0: 2c20 5231 293b 0a20 2020 2020 2020 2020  , R1);.         
-000123e0: 2074 7261 6974 732e 6163 6328 4338 2c20   traits.acc(C8, 
-000123f0: 616c 7068 6176 2c20 5232 293b 0a20 2020  alphav, R2);.   
-00012400: 2020 2020 2020 2072 302e 7374 6f72 6550         r0.storeP
-00012410: 6163 6b65 7428 3020 2a20 5472 6169 7473  acket(0 * Traits
-00012420: 3a3a 5265 7350 6163 6b65 7453 697a 652c  ::ResPacketSize,
-00012430: 2052 3029 3b0a 2020 2020 2020 2020 2020   R0);.          
-00012440: 7230 2e73 746f 7265 5061 636b 6574 2831  r0.storePacket(1
-00012450: 202a 2054 7261 6974 733a 3a52 6573 5061   * Traits::ResPa
-00012460: 636b 6574 5369 7a65 2c20 5231 293b 0a20  cketSize, R1);. 
-00012470: 2020 2020 2020 2020 2072 302e 7374 6f72           r0.stor
-00012480: 6550 6163 6b65 7428 3220 2a20 5472 6169  ePacket(2 * Trai
-00012490: 7473 3a3a 5265 7350 6163 6b65 7453 697a  ts::ResPacketSiz
-000124a0: 652c 2052 3229 3b20 2020 2020 2020 2020  e, R2);         
-000124b0: 200a 2020 2020 2020 2020 2020 7d0a 2020   .          }.  
-000124c0: 2020 2020 2020 7d0a 2020 2020 2020 7d0a        }.      }.
-000124d0: 2020 2020 7d0a 0a20 2020 202f 2f2d 2d2d      }..    //---
-000124e0: 2d2d 2d2d 2d2d 2d20 5072 6f63 6573 7320  ------- Process 
-000124f0: 3220 2a20 4c68 7350 726f 6772 6573 7320  2 * LhsProgress 
-00012500: 726f 7773 2061 7420 6f6e 6365 202d 2d2d  rows at once ---
-00012510: 2d2d 2d2d 2d2d 2d0a 2020 2020 6966 286d  -------.    if(m
-00012520: 723e 3d32 2a54 7261 6974 733a 3a4c 6873  r>=2*Traits::Lhs
-00012530: 5072 6f67 7265 7373 290a 2020 2020 7b0a  Progress).    {.
-00012540: 2020 2020 2020 636f 6e73 7420 496e 6465        const Inde
-00012550: 7820 6c31 203d 2064 6566 6175 6c74 4c31  x l1 = defaultL1
-00012560: 4361 6368 6553 697a 653b 202f 2f20 696e  CacheSize; // in
-00012570: 2042 7974 6573 2c20 544f 444f 2c20 6c31   Bytes, TODO, l1
-00012580: 2073 686f 756c 6420 6265 2070 6173 7365   should be passe
-00012590: 6420 746f 2074 6869 7320 6675 6e63 7469  d to this functi
-000125a0: 6f6e 2e0a 2020 2020 2020 2f2f 2054 6865  on..      // The
-000125b0: 206d 6178 2831 2c20 2e2e 2e29 2068 6572   max(1, ...) her
-000125c0: 6520 6973 206e 6565 6465 6420 6265 6361  e is needed beca
-000125d0: 7573 6520 7765 206d 6179 2062 6520 7573  use we may be us
-000125e0: 696e 6720 626c 6f63 6b69 6e67 2070 6172  ing blocking par
-000125f0: 616d 7320 6c61 7267 6572 2074 6861 6e20  ams larger than 
-00012600: 7768 6174 206f 7572 206b 6e6f 776e 206c  what our known l
-00012610: 3120 6361 6368 6520 7369 7a65 0a20 2020  1 cache size.   
-00012620: 2020 202f 2f20 7375 6767 6573 7473 2077     // suggests w
-00012630: 6520 7368 6f75 6c64 2062 6520 7573 696e  e should be usin
-00012640: 673a 2065 6974 6865 7220 6265 6361 7573  g: either becaus
-00012650: 6520 6f75 7220 6b6e 6f77 6e20 6c31 2063  e our known l1 c
-00012660: 6163 6865 2073 697a 6520 6973 2069 6e61  ache size is ina
-00012670: 6363 7572 6174 6520 2865 2e67 2e20 6f6e  ccurate (e.g. on
-00012680: 2041 6e64 726f 6964 2c20 7765 2063 616e   Android, we can
-00012690: 206f 6e6c 7920 6775 6573 7329 2c0a 2020   only guess),.  
-000126a0: 2020 2020 2f2f 206f 7220 6265 6361 7573      // or becaus
-000126b0: 6520 7765 2061 7265 2074 6573 7469 6e67  e we are testing
-000126c0: 2073 7065 6369 6669 6320 626c 6f63 6b69   specific blocki
-000126d0: 6e67 2073 697a 6573 2e0a 2020 2020 2020  ng sizes..      
-000126e0: 496e 6465 7820 6163 7475 616c 5f70 616e  Index actual_pan
-000126f0: 656c 5f72 6f77 7320 3d20 2832 2a4c 6873  el_rows = (2*Lhs
-00012700: 5072 6f67 7265 7373 2920 2a20 7374 643a  Progress) * std:
-00012710: 3a6d 6178 3c49 6e64 6578 3e28 312c 2820  :max<Index>(1,( 
-00012720: 286c 3120 2d20 7369 7a65 6f66 2852 6573  (l1 - sizeof(Res
-00012730: 5363 616c 6172 292a 6d72 2a6e 7220 2d20  Scalar)*mr*nr - 
-00012740: 6465 7074 682a 6e72 2a73 697a 656f 6628  depth*nr*sizeof(
-00012750: 5268 7353 6361 6c61 7229 2920 2f20 2864  RhsScalar)) / (d
-00012760: 6570 7468 202a 2073 697a 656f 6628 4c68  epth * sizeof(Lh
-00012770: 7353 6361 6c61 7229 202a 2032 2a4c 6873  sScalar) * 2*Lhs
-00012780: 5072 6f67 7265 7373 2920 2929 3b0a 0a20  Progress) ));.. 
-00012790: 2020 2020 2066 6f72 2849 6e64 6578 2069       for(Index i
-000127a0: 313d 7065 656c 6564 5f6d 6333 3b20 6931  1=peeled_mc3; i1
-000127b0: 3c70 6565 6c65 645f 6d63 323b 2069 312b  <peeled_mc2; i1+
-000127c0: 3d61 6374 7561 6c5f 7061 6e65 6c5f 726f  =actual_panel_ro
-000127d0: 7773 290a 2020 2020 2020 7b0a 2020 2020  ws).      {.    
-000127e0: 2020 2020 496e 6465 7820 6163 7475 616c      Index actual
-000127f0: 5f70 616e 656c 5f65 6e64 203d 2028 7374  _panel_end = (st
-00012800: 643a 3a6d 696e 2928 6931 2b61 6374 7561  d::min)(i1+actua
-00012810: 6c5f 7061 6e65 6c5f 726f 7773 2c20 7065  l_panel_rows, pe
-00012820: 656c 6564 5f6d 6332 293b 0a20 2020 2020  eled_mc2);.     
-00012830: 2020 2066 6f72 2849 6e64 6578 206a 323d     for(Index j2=
-00012840: 303b 206a 323c 7061 636b 6574 5f63 6f6c  0; j2<packet_col
-00012850: 7334 3b20 6a32 2b3d 6e72 290a 2020 2020  s4; j2+=nr).    
-00012860: 2020 2020 7b0a 2020 2020 2020 2020 2020      {.          
-00012870: 666f 7228 496e 6465 7820 693d 6931 3b20  for(Index i=i1; 
-00012880: 693c 6163 7475 616c 5f70 616e 656c 5f65  i<actual_panel_e
-00012890: 6e64 3b20 692b 3d32 2a4c 6873 5072 6f67  nd; i+=2*LhsProg
-000128a0: 7265 7373 290a 2020 2020 2020 2020 2020  ress).          
-000128b0: 7b0a 2020 2020 2020 2020 2020 0a20 2020  {.          .   
-000128c0: 2020 2020 2020 202f 2f20 5765 2073 656c         // We sel
-000128d0: 6563 7465 6420 6120 322a 5472 6169 7473  ected a 2*Traits
-000128e0: 3a3a 4c68 7350 726f 6772 6573 7320 7820  ::LhsProgress x 
-000128f0: 6e72 206d 6963 726f 2062 6c6f 636b 206f  nr micro block o
-00012900: 6620 7265 7320 7768 6963 6820 6973 2065  f res which is e
-00012910: 6e74 6972 656c 790a 2020 2020 2020 2020  ntirely.        
-00012920: 2020 2f2f 2073 746f 7265 6420 696e 746f    // stored into
-00012930: 2032 2078 206e 7220 7265 6769 7374 6572   2 x nr register
-00012940: 732e 0a20 2020 2020 2020 2020 200a 2020  s..          .  
-00012950: 2020 2020 2020 2020 636f 6e73 7420 4c68          const Lh
-00012960: 7353 6361 6c61 722a 2062 6c41 203d 2026  sScalar* blA = &
-00012970: 626c 6f63 6b41 5b69 2a73 7472 6964 6541  blockA[i*strideA
-00012980: 2b6f 6666 7365 7441 2a28 322a 5472 6169  +offsetA*(2*Trai
-00012990: 7473 3a3a 4c68 7350 726f 6772 6573 7329  ts::LhsProgress)
-000129a0: 5d3b 0a20 2020 2020 2020 2020 2070 7265  ];.          pre
-000129b0: 6665 7463 6828 2662 6c41 5b30 5d29 3b0a  fetch(&blA[0]);.
-000129c0: 0a20 2020 2020 2020 2020 202f 2f20 6765  .          // ge
-000129d0: 7473 2072 6573 2062 6c6f 636b 2061 7320  ts res block as 
-000129e0: 7265 6769 7374 6572 0a20 2020 2020 2020  register.       
-000129f0: 2020 2041 6363 5061 636b 6574 2043 302c     AccPacket C0,
-00012a00: 2043 312c 2043 322c 2043 332c 0a20 2020   C1, C2, C3,.   
-00012a10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012a20: 2043 342c 2043 352c 2043 362c 2043 373b   C4, C5, C6, C7;
-00012a30: 0a20 2020 2020 2020 2020 2074 7261 6974  .          trait
-00012a40: 732e 696e 6974 4163 6328 4330 293b 2074  s.initAcc(C0); t
-00012a50: 7261 6974 732e 696e 6974 4163 6328 4331  raits.initAcc(C1
-00012a60: 293b 2074 7261 6974 732e 696e 6974 4163  ); traits.initAc
-00012a70: 6328 4332 293b 2074 7261 6974 732e 696e  c(C2); traits.in
-00012a80: 6974 4163 6328 4333 293b 0a20 2020 2020  itAcc(C3);.     
-00012a90: 2020 2020 2074 7261 6974 732e 696e 6974       traits.init
-00012aa0: 4163 6328 4334 293b 2074 7261 6974 732e  Acc(C4); traits.
-00012ab0: 696e 6974 4163 6328 4335 293b 2074 7261  initAcc(C5); tra
-00012ac0: 6974 732e 696e 6974 4163 6328 4336 293b  its.initAcc(C6);
-00012ad0: 2074 7261 6974 732e 696e 6974 4163 6328   traits.initAcc(
-00012ae0: 4337 293b 0a0a 2020 2020 2020 2020 2020  C7);..          
-00012af0: 4c69 6e65 6172 4d61 7070 6572 2072 3020  LinearMapper r0 
-00012b00: 3d20 7265 732e 6765 744c 696e 6561 724d  = res.getLinearM
-00012b10: 6170 7065 7228 692c 206a 3220 2b20 3029  apper(i, j2 + 0)
-00012b20: 3b0a 2020 2020 2020 2020 2020 4c69 6e65  ;.          Line
-00012b30: 6172 4d61 7070 6572 2072 3120 3d20 7265  arMapper r1 = re
-00012b40: 732e 6765 744c 696e 6561 724d 6170 7065  s.getLinearMappe
-00012b50: 7228 692c 206a 3220 2b20 3129 3b0a 2020  r(i, j2 + 1);.  
-00012b60: 2020 2020 2020 2020 4c69 6e65 6172 4d61          LinearMa
-00012b70: 7070 6572 2072 3220 3d20 7265 732e 6765  pper r2 = res.ge
-00012b80: 744c 696e 6561 724d 6170 7065 7228 692c  tLinearMapper(i,
-00012b90: 206a 3220 2b20 3229 3b0a 2020 2020 2020   j2 + 2);.      
-00012ba0: 2020 2020 4c69 6e65 6172 4d61 7070 6572      LinearMapper
-00012bb0: 2072 3320 3d20 7265 732e 6765 744c 696e   r3 = res.getLin
-00012bc0: 6561 724d 6170 7065 7228 692c 206a 3220  earMapper(i, j2 
-00012bd0: 2b20 3329 3b0a 0a20 2020 2020 2020 2020  + 3);..         
-00012be0: 2072 302e 7072 6566 6574 6368 2870 7265   r0.prefetch(pre
-00012bf0: 6665 7463 685f 7265 735f 6f66 6673 6574  fetch_res_offset
-00012c00: 293b 0a20 2020 2020 2020 2020 2072 312e  );.          r1.
-00012c10: 7072 6566 6574 6368 2870 7265 6665 7463  prefetch(prefetc
-00012c20: 685f 7265 735f 6f66 6673 6574 293b 0a20  h_res_offset);. 
-00012c30: 2020 2020 2020 2020 2072 322e 7072 6566           r2.pref
-00012c40: 6574 6368 2870 7265 6665 7463 685f 7265  etch(prefetch_re
-00012c50: 735f 6f66 6673 6574 293b 0a20 2020 2020  s_offset);.     
-00012c60: 2020 2020 2072 332e 7072 6566 6574 6368       r3.prefetch
-00012c70: 2870 7265 6665 7463 685f 7265 735f 6f66  (prefetch_res_of
-00012c80: 6673 6574 293b 0a0a 2020 2020 2020 2020  fset);..        
-00012c90: 2020 2f2f 2070 6572 666f 726d 7320 2269    // performs "i
-00012ca0: 6e6e 6572 2220 7072 6f64 7563 7473 0a20  nner" products. 
-00012cb0: 2020 2020 2020 2020 2063 6f6e 7374 2052           const R
-00012cc0: 6873 5363 616c 6172 2a20 626c 4220 3d20  hsScalar* blB = 
-00012cd0: 2662 6c6f 636b 425b 6a32 2a73 7472 6964  &blockB[j2*strid
-00012ce0: 6542 2b6f 6666 7365 7442 2a6e 725d 3b0a  eB+offsetB*nr];.
-00012cf0: 2020 2020 2020 2020 2020 7072 6566 6574            prefet
-00012d00: 6368 2826 626c 425b 305d 293b 0a20 2020  ch(&blB[0]);.   
-00012d10: 2020 2020 2020 204c 6873 5061 636b 6574         LhsPacket
-00012d20: 2041 302c 2041 313b 0a0a 2020 2020 2020   A0, A1;..      
-00012d30: 2020 2020 666f 7228 496e 6465 7820 6b3d      for(Index k=
-00012d40: 303b 206b 3c70 6565 6c65 645f 6b63 3b20  0; k<peeled_kc; 
-00012d50: 6b2b 3d70 6b29 0a20 2020 2020 2020 2020  k+=pk).         
-00012d60: 207b 0a20 2020 2020 2020 2020 2020 2045   {.            E
-00012d70: 4947 454e 5f41 534d 5f43 4f4d 4d45 4e54  IGEN_ASM_COMMENT
-00012d80: 2822 6265 6769 6e20 6765 6270 206d 6963  ("begin gebp mic
-00012d90: 726f 206b 6572 6e65 6c20 3270 5834 2229  ro kernel 2pX4")
-00012da0: 3b0a 2020 2020 2020 2020 2020 2020 5268  ;.            Rh
-00012db0: 7350 6163 6b65 7478 3420 7268 735f 7061  sPacketx4 rhs_pa
-00012dc0: 6e65 6c3b 0a20 2020 2020 2020 2020 2020  nel;.           
-00012dd0: 2052 6873 5061 636b 6574 2054 303b 0a0a   RhsPacket T0;..
-00012de0: 2020 2020 2020 2020 2020 2f2f 204e 4f54            // NOT
-00012df0: 453a 2074 6865 2062 6567 696e 2f65 6e64  E: the begin/end
-00012e00: 2061 736d 2063 6f6d 6d65 6e74 7320 6265   asm comments be
-00012e10: 6c6f 7720 776f 726b 2061 726f 756e 6420  low work around 
-00012e20: 6275 6720 3933 3521 0a20 2020 2020 2020  bug 935!.       
-00012e30: 2020 202f 2f20 6275 7420 7468 6579 2061     // but they a
-00012e40: 7265 206e 6f74 2065 6e6f 7567 6820 666f  re not enough fo
-00012e50: 7220 6763 633e 3d36 2077 6974 686f 7574  r gcc>=6 without
-00012e60: 2046 4d41 2028 6275 6720 3136 3337 290a   FMA (bug 1637).
-00012e70: 2020 2020 2020 2020 2020 2369 6620 4549            #if EI
-00012e80: 4745 4e5f 474e 5543 5f41 545f 4c45 4153  GEN_GNUC_AT_LEAS
-00012e90: 5428 362c 3029 2026 2620 6465 6669 6e65  T(6,0) && define
-00012ea0: 6428 4549 4745 4e5f 5645 4354 4f52 495a  d(EIGEN_VECTORIZ
-00012eb0: 455f 5353 4529 0a20 2020 2020 2020 2020  E_SSE).         
-00012ec0: 2020 2023 6465 6669 6e65 2045 4947 454e     #define EIGEN
-00012ed0: 5f47 4542 505f 3250 5834 5f53 5049 4c4c  _GEBP_2PX4_SPILL
-00012ee0: 494e 475f 574f 524b 4152 4f55 4e44 205f  ING_WORKAROUND _
-00012ef0: 5f61 736d 5f5f 2020 2822 2220 3a20 5b61  _asm__  ("" : [a
-00012f00: 305d 2022 2b78 2c6d 2220 2841 3029 2c5b  0] "+x,m" (A0),[
-00012f10: 6131 5d20 222b 782c 6d22 2028 4131 2929  a1] "+x,m" (A1))
-00012f20: 3b0a 2020 2020 2020 2020 2020 2365 6c73  ;.          #els
-00012f30: 650a 2020 2020 2020 2020 2020 2020 2364  e.            #d
-00012f40: 6566 696e 6520 4549 4745 4e5f 4745 4250  efine EIGEN_GEBP
-00012f50: 5f32 5058 345f 5350 494c 4c49 4e47 5f57  _2PX4_SPILLING_W
-00012f60: 4f52 4b41 524f 554e 440a 2020 2020 2020  ORKAROUND.      
-00012f70: 2020 2020 2365 6e64 6966 0a23 6465 6669      #endif.#defi
-00012f80: 6e65 2045 4947 454e 5f47 4542 4750 5f4f  ne EIGEN_GEBGP_O
-00012f90: 4e45 5354 4550 284b 2920 2020 2020 2020  NESTEP(K)       
-00012fa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012fb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012fc0: 2020 2020 205c 0a20 2020 2020 2020 2020       \.         
-00012fd0: 2020 2064 6f20 7b20 2020 2020 2020 2020     do {         
-00012fe0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012ff0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013000: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013010: 205c 0a20 2020 2020 2020 2020 2020 2020   \.             
-00013020: 2045 4947 454e 5f41 534d 5f43 4f4d 4d45   EIGEN_ASM_COMME
-00013030: 4e54 2822 6265 6769 6e20 7374 6570 206f  NT("begin step o
-00013040: 6620 6765 6270 206d 6963 726f 206b 6572  f gebp micro ker
-00013050: 6e65 6c20 3270 5834 2229 3b20 205c 0a20  nel 2pX4");  \. 
-00013060: 2020 2020 2020 2020 2020 2020 2074 7261               tra
-00013070: 6974 732e 6c6f 6164 4c68 7328 2662 6c41  its.loadLhs(&blA
-00013080: 5b28 3020 2b20 3220 2a20 4b29 202a 204c  [(0 + 2 * K) * L
-00013090: 6873 5072 6f67 7265 7373 5d2c 2041 3029  hsProgress], A0)
-000130a0: 3b20 2020 2020 2020 205c 0a20 2020 2020  ;        \.     
-000130b0: 2020 2020 2020 2020 2074 7261 6974 732e           traits.
-000130c0: 6c6f 6164 4c68 7328 2662 6c41 5b28 3120  loadLhs(&blA[(1 
-000130d0: 2b20 3220 2a20 4b29 202a 204c 6873 5072  + 2 * K) * LhsPr
-000130e0: 6f67 7265 7373 5d2c 2041 3129 3b20 2020  ogress], A1);   
-000130f0: 2020 2020 205c 0a20 2020 2020 2020 2020       \.         
-00013100: 2020 2020 2074 7261 6974 732e 6c6f 6164       traits.load
-00013110: 5268 7328 2662 6c42 5b28 3020 2b20 3420  Rhs(&blB[(0 + 4 
-00013120: 2a20 4b29 202a 2052 6873 5072 6f67 7265  * K) * RhsProgre
-00013130: 7373 5d2c 2072 6873 5f70 616e 656c 293b  ss], rhs_panel);
-00013140: 205c 0a20 2020 2020 2020 2020 2020 2020   \.             
-00013150: 2074 7261 6974 732e 6d61 6464 2841 302c   traits.madd(A0,
-00013160: 2072 6873 5f70 616e 656c 2c20 4330 2c20   rhs_panel, C0, 
-00013170: 5430 2c20 6669 783c 303e 293b 2020 2020  T0, fix<0>);    
-00013180: 2020 2020 2020 2020 2020 2020 205c 0a20               \. 
-00013190: 2020 2020 2020 2020 2020 2020 2074 7261               tra
-000131a0: 6974 732e 6d61 6464 2841 312c 2072 6873  its.madd(A1, rhs
-000131b0: 5f70 616e 656c 2c20 4334 2c20 5430 2c20  _panel, C4, T0, 
-000131c0: 6669 783c 303e 293b 2020 2020 2020 2020  fix<0>);        
-000131d0: 2020 2020 2020 2020 205c 0a20 2020 2020           \.     
-000131e0: 2020 2020 2020 2020 2074 7261 6974 732e           traits.
-000131f0: 6d61 6464 2841 302c 2072 6873 5f70 616e  madd(A0, rhs_pan
-00013200: 656c 2c20 4331 2c20 5430 2c20 6669 783c  el, C1, T0, fix<
-00013210: 313e 293b 2020 2020 2020 2020 2020 2020  1>);            
-00013220: 2020 2020 205c 0a20 2020 2020 2020 2020       \.         
-00013230: 2020 2020 2074 7261 6974 732e 6d61 6464       traits.madd
-00013240: 2841 312c 2072 6873 5f70 616e 656c 2c20  (A1, rhs_panel, 
-00013250: 4335 2c20 5430 2c20 6669 783c 313e 293b  C5, T0, fix<1>);
-00013260: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013270: 205c 0a20 2020 2020 2020 2020 2020 2020   \.             
-00013280: 2074 7261 6974 732e 6d61 6464 2841 302c   traits.madd(A0,
-00013290: 2072 6873 5f70 616e 656c 2c20 4332 2c20   rhs_panel, C2, 
-000132a0: 5430 2c20 6669 783c 323e 293b 2020 2020  T0, fix<2>);    
-000132b0: 2020 2020 2020 2020 2020 2020 205c 0a20               \. 
-000132c0: 2020 2020 2020 2020 2020 2020 2074 7261               tra
-000132d0: 6974 732e 6d61 6464 2841 312c 2072 6873  its.madd(A1, rhs
-000132e0: 5f70 616e 656c 2c20 4336 2c20 5430 2c20  _panel, C6, T0, 
-000132f0: 6669 783c 323e 293b 2020 2020 2020 2020  fix<2>);        
-00013300: 2020 2020 2020 2020 205c 0a20 2020 2020           \.     
-00013310: 2020 2020 2020 2020 2074 7261 6974 732e           traits.
-00013320: 6d61 6464 2841 302c 2072 6873 5f70 616e  madd(A0, rhs_pan
-00013330: 656c 2c20 4333 2c20 5430 2c20 6669 783c  el, C3, T0, fix<
-00013340: 333e 293b 2020 2020 2020 2020 2020 2020  3>);            
-00013350: 2020 2020 205c 0a20 2020 2020 2020 2020       \.         
-00013360: 2020 2020 2074 7261 6974 732e 6d61 6464       traits.madd
-00013370: 2841 312c 2072 6873 5f70 616e 656c 2c20  (A1, rhs_panel, 
-00013380: 4337 2c20 5430 2c20 6669 783c 333e 293b  C7, T0, fix<3>);
-00013390: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000133a0: 205c 0a20 2020 2020 2020 2020 2020 2020   \.             
-000133b0: 2045 4947 454e 5f47 4542 505f 3250 5834   EIGEN_GEBP_2PX4
-000133c0: 5f53 5049 4c4c 494e 475f 574f 524b 4152  _SPILLING_WORKAR
-000133d0: 4f55 4e44 2020 2020 2020 2020 2020 2020  OUND            
-000133e0: 2020 2020 2020 2020 2020 2020 205c 0a20               \. 
-000133f0: 2020 2020 2020 2020 2020 2020 2045 4947               EIG
-00013400: 454e 5f41 534d 5f43 4f4d 4d45 4e54 2822  EN_ASM_COMMENT("
-00013410: 656e 6420 7374 6570 206f 6620 6765 6270  end step of gebp
-00013420: 206d 6963 726f 206b 6572 6e65 6c20 3270   micro kernel 2p
-00013430: 5834 2229 3b20 2020 205c 0a20 2020 2020  X4");    \.     
-00013440: 2020 2020 2020 207d 2077 6869 6c65 2028         } while (
-00013450: 6661 6c73 6529 0a0a 2020 2020 2020 2020  false)..        
-00013460: 2020 2020 696e 7465 726e 616c 3a3a 7072      internal::pr
-00013470: 6566 6574 6368 2862 6c42 2b28 3438 2b30  efetch(blB+(48+0
-00013480: 2929 3b0a 2020 2020 2020 2020 2020 2020  ));.            
-00013490: 4549 4745 4e5f 4745 4247 505f 4f4e 4553  EIGEN_GEBGP_ONES
-000134a0: 5445 5028 3029 3b0a 2020 2020 2020 2020  TEP(0);.        
-000134b0: 2020 2020 4549 4745 4e5f 4745 4247 505f      EIGEN_GEBGP_
-000134c0: 4f4e 4553 5445 5028 3129 3b0a 2020 2020  ONESTEP(1);.    
-000134d0: 2020 2020 2020 2020 4549 4745 4e5f 4745          EIGEN_GE
-000134e0: 4247 505f 4f4e 4553 5445 5028 3229 3b0a  BGP_ONESTEP(2);.
-000134f0: 2020 2020 2020 2020 2020 2020 4549 4745              EIGE
-00013500: 4e5f 4745 4247 505f 4f4e 4553 5445 5028  N_GEBGP_ONESTEP(
-00013510: 3329 3b0a 2020 2020 2020 2020 2020 2020  3);.            
-00013520: 696e 7465 726e 616c 3a3a 7072 6566 6574  internal::prefet
-00013530: 6368 2862 6c42 2b28 3438 2b31 3629 293b  ch(blB+(48+16));
-00013540: 0a20 2020 2020 2020 2020 2020 2045 4947  .            EIG
-00013550: 454e 5f47 4542 4750 5f4f 4e45 5354 4550  EN_GEBGP_ONESTEP
-00013560: 2834 293b 0a20 2020 2020 2020 2020 2020  (4);.           
-00013570: 2045 4947 454e 5f47 4542 4750 5f4f 4e45   EIGEN_GEBGP_ONE
-00013580: 5354 4550 2835 293b 0a20 2020 2020 2020  STEP(5);.       
-00013590: 2020 2020 2045 4947 454e 5f47 4542 4750       EIGEN_GEBGP
-000135a0: 5f4f 4e45 5354 4550 2836 293b 0a20 2020  _ONESTEP(6);.   
-000135b0: 2020 2020 2020 2020 2045 4947 454e 5f47           EIGEN_G
-000135c0: 4542 4750 5f4f 4e45 5354 4550 2837 293b  EBGP_ONESTEP(7);
-000135d0: 0a0a 2020 2020 2020 2020 2020 2020 626c  ..            bl
-000135e0: 4220 2b3d 2070 6b2a 342a 5268 7350 726f  B += pk*4*RhsPro
-000135f0: 6772 6573 733b 0a20 2020 2020 2020 2020  gress;.         
-00013600: 2020 2062 6c41 202b 3d20 706b 2a28 322a     blA += pk*(2*
-00013610: 5472 6169 7473 3a3a 4c68 7350 726f 6772  Traits::LhsProgr
-00013620: 6573 7329 3b0a 0a20 2020 2020 2020 2020  ess);..         
-00013630: 2020 2045 4947 454e 5f41 534d 5f43 4f4d     EIGEN_ASM_COM
-00013640: 4d45 4e54 2822 656e 6420 6765 6270 206d  MENT("end gebp m
-00013650: 6963 726f 206b 6572 6e65 6c20 3270 5834  icro kernel 2pX4
-00013660: 2229 3b0a 2020 2020 2020 2020 2020 7d0a  ");.          }.
-00013670: 2020 2020 2020 2020 2020 2f2f 2070 726f            // pro
-00013680: 6365 7373 2072 656d 6169 6e69 6e67 2070  cess remaining p
-00013690: 6565 6c65 6420 6c6f 6f70 0a20 2020 2020  eeled loop.     
-000136a0: 2020 2020 2066 6f72 2849 6e64 6578 206b       for(Index k
-000136b0: 3d70 6565 6c65 645f 6b63 3b20 6b3c 6465  =peeled_kc; k<de
-000136c0: 7074 683b 206b 2b2b 290a 2020 2020 2020  pth; k++).      
-000136d0: 2020 2020 7b0a 2020 2020 2020 2020 2020      {.          
-000136e0: 2020 5268 7350 6163 6b65 7478 3420 7268    RhsPacketx4 rh
-000136f0: 735f 7061 6e65 6c3b 0a20 2020 2020 2020  s_panel;.       
-00013700: 2020 2020 2052 6873 5061 636b 6574 2054       RhsPacket T
-00013710: 303b 0a20 2020 2020 2020 2020 2020 2045  0;.            E
-00013720: 4947 454e 5f47 4542 4750 5f4f 4e45 5354  IGEN_GEBGP_ONEST
-00013730: 4550 2830 293b 0a20 2020 2020 2020 2020  EP(0);.         
-00013740: 2020 2062 6c42 202b 3d20 342a 5268 7350     blB += 4*RhsP
-00013750: 726f 6772 6573 733b 0a20 2020 2020 2020  rogress;.       
-00013760: 2020 2020 2062 6c41 202b 3d20 322a 5472       blA += 2*Tr
-00013770: 6169 7473 3a3a 4c68 7350 726f 6772 6573  aits::LhsProgres
-00013780: 733b 0a20 2020 2020 2020 2020 207d 0a23  s;.          }.#
-00013790: 756e 6465 6620 4549 4745 4e5f 4745 4247  undef EIGEN_GEBG
-000137a0: 505f 4f4e 4553 5445 500a 0a20 2020 2020  P_ONESTEP..     
-000137b0: 2020 2020 2052 6573 5061 636b 6574 2052       ResPacket R
-000137c0: 302c 2052 312c 2052 322c 2052 333b 0a20  0, R1, R2, R3;. 
-000137d0: 2020 2020 2020 2020 2052 6573 5061 636b           ResPack
-000137e0: 6574 2061 6c70 6861 7620 3d20 7073 6574  et alphav = pset
-000137f0: 313c 5265 7350 6163 6b65 743e 2861 6c70  1<ResPacket>(alp
-00013800: 6861 293b 0a0a 2020 2020 2020 2020 2020  ha);..          
-00013810: 5230 203d 2072 302e 7465 6d70 6c61 7465  R0 = r0.template
-00013820: 206c 6f61 6450 6163 6b65 743c 5265 7350   loadPacket<ResP
-00013830: 6163 6b65 743e 2830 202a 2054 7261 6974  acket>(0 * Trait
-00013840: 733a 3a52 6573 5061 636b 6574 5369 7a65  s::ResPacketSize
-00013850: 293b 0a20 2020 2020 2020 2020 2052 3120  );.          R1 
-00013860: 3d20 7230 2e74 656d 706c 6174 6520 6c6f  = r0.template lo
-00013870: 6164 5061 636b 6574 3c52 6573 5061 636b  adPacket<ResPack
-00013880: 6574 3e28 3120 2a20 5472 6169 7473 3a3a  et>(1 * Traits::
-00013890: 5265 7350 6163 6b65 7453 697a 6529 3b0a  ResPacketSize);.
-000138a0: 2020 2020 2020 2020 2020 5232 203d 2072            R2 = r
-000138b0: 312e 7465 6d70 6c61 7465 206c 6f61 6450  1.template loadP
-000138c0: 6163 6b65 743c 5265 7350 6163 6b65 743e  acket<ResPacket>
-000138d0: 2830 202a 2054 7261 6974 733a 3a52 6573  (0 * Traits::Res
-000138e0: 5061 636b 6574 5369 7a65 293b 0a20 2020  PacketSize);.   
-000138f0: 2020 2020 2020 2052 3320 3d20 7231 2e74         R3 = r1.t
-00013900: 656d 706c 6174 6520 6c6f 6164 5061 636b  emplate loadPack
-00013910: 6574 3c52 6573 5061 636b 6574 3e28 3120  et<ResPacket>(1 
-00013920: 2a20 5472 6169 7473 3a3a 5265 7350 6163  * Traits::ResPac
-00013930: 6b65 7453 697a 6529 3b0a 2020 2020 2020  ketSize);.      
-00013940: 2020 2020 7472 6169 7473 2e61 6363 2843      traits.acc(C
-00013950: 302c 2061 6c70 6861 762c 2052 3029 3b0a  0, alphav, R0);.
-00013960: 2020 2020 2020 2020 2020 7472 6169 7473            traits
-00013970: 2e61 6363 2843 342c 2061 6c70 6861 762c  .acc(C4, alphav,
-00013980: 2052 3129 3b0a 2020 2020 2020 2020 2020   R1);.          
-00013990: 7472 6169 7473 2e61 6363 2843 312c 2061  traits.acc(C1, a
-000139a0: 6c70 6861 762c 2052 3229 3b0a 2020 2020  lphav, R2);.    
-000139b0: 2020 2020 2020 7472 6169 7473 2e61 6363        traits.acc
-000139c0: 2843 352c 2061 6c70 6861 762c 2052 3329  (C5, alphav, R3)
-000139d0: 3b0a 2020 2020 2020 2020 2020 7230 2e73  ;.          r0.s
-000139e0: 746f 7265 5061 636b 6574 2830 202a 2054  torePacket(0 * T
-000139f0: 7261 6974 733a 3a52 6573 5061 636b 6574  raits::ResPacket
-00013a00: 5369 7a65 2c20 5230 293b 0a20 2020 2020  Size, R0);.     
-00013a10: 2020 2020 2072 302e 7374 6f72 6550 6163       r0.storePac
-00013a20: 6b65 7428 3120 2a20 5472 6169 7473 3a3a  ket(1 * Traits::
-00013a30: 5265 7350 6163 6b65 7453 697a 652c 2052  ResPacketSize, R
-00013a40: 3129 3b0a 2020 2020 2020 2020 2020 7231  1);.          r1
-00013a50: 2e73 746f 7265 5061 636b 6574 2830 202a  .storePacket(0 *
-00013a60: 2054 7261 6974 733a 3a52 6573 5061 636b   Traits::ResPack
-00013a70: 6574 5369 7a65 2c20 5232 293b 0a20 2020  etSize, R2);.   
-00013a80: 2020 2020 2020 2072 312e 7374 6f72 6550         r1.storeP
-00013a90: 6163 6b65 7428 3120 2a20 5472 6169 7473  acket(1 * Traits
-00013aa0: 3a3a 5265 7350 6163 6b65 7453 697a 652c  ::ResPacketSize,
-00013ab0: 2052 3329 3b0a 0a20 2020 2020 2020 2020   R3);..         
-00013ac0: 2052 3020 3d20 7232 2e74 656d 706c 6174   R0 = r2.templat
-00013ad0: 6520 6c6f 6164 5061 636b 6574 3c52 6573  e loadPacket<Res
-00013ae0: 5061 636b 6574 3e28 3020 2a20 5472 6169  Packet>(0 * Trai
-00013af0: 7473 3a3a 5265 7350 6163 6b65 7453 697a  ts::ResPacketSiz
-00013b00: 6529 3b0a 2020 2020 2020 2020 2020 5231  e);.          R1
-00013b10: 203d 2072 322e 7465 6d70 6c61 7465 206c   = r2.template l
-00013b20: 6f61 6450 6163 6b65 743c 5265 7350 6163  oadPacket<ResPac
-00013b30: 6b65 743e 2831 202a 2054 7261 6974 733a  ket>(1 * Traits:
-00013b40: 3a52 6573 5061 636b 6574 5369 7a65 293b  :ResPacketSize);
-00013b50: 0a20 2020 2020 2020 2020 2052 3220 3d20  .          R2 = 
-00013b60: 7233 2e74 656d 706c 6174 6520 6c6f 6164  r3.template load
-00013b70: 5061 636b 6574 3c52 6573 5061 636b 6574  Packet<ResPacket
-00013b80: 3e28 3020 2a20 5472 6169 7473 3a3a 5265  >(0 * Traits::Re
-00013b90: 7350 6163 6b65 7453 697a 6529 3b0a 2020  sPacketSize);.  
-00013ba0: 2020 2020 2020 2020 5233 203d 2072 332e          R3 = r3.
-00013bb0: 7465 6d70 6c61 7465 206c 6f61 6450 6163  template loadPac
-00013bc0: 6b65 743c 5265 7350 6163 6b65 743e 2831  ket<ResPacket>(1
-00013bd0: 202a 2054 7261 6974 733a 3a52 6573 5061   * Traits::ResPa
-00013be0: 636b 6574 5369 7a65 293b 0a20 2020 2020  cketSize);.     
-00013bf0: 2020 2020 2074 7261 6974 732e 6163 6328       traits.acc(
-00013c00: 4332 2c20 2061 6c70 6861 762c 2052 3029  C2,  alphav, R0)
-00013c10: 3b0a 2020 2020 2020 2020 2020 7472 6169  ;.          trai
-00013c20: 7473 2e61 6363 2843 362c 2020 616c 7068  ts.acc(C6,  alph
-00013c30: 6176 2c20 5231 293b 0a20 2020 2020 2020  av, R1);.       
-00013c40: 2020 2074 7261 6974 732e 6163 6328 4333     traits.acc(C3
-00013c50: 2c20 2061 6c70 6861 762c 2052 3229 3b0a  ,  alphav, R2);.
-00013c60: 2020 2020 2020 2020 2020 7472 6169 7473            traits
-00013c70: 2e61 6363 2843 372c 2020 616c 7068 6176  .acc(C7,  alphav
-00013c80: 2c20 5233 293b 0a20 2020 2020 2020 2020  , R3);.         
-00013c90: 2072 322e 7374 6f72 6550 6163 6b65 7428   r2.storePacket(
-00013ca0: 3020 2a20 5472 6169 7473 3a3a 5265 7350  0 * Traits::ResP
-00013cb0: 6163 6b65 7453 697a 652c 2052 3029 3b0a  acketSize, R0);.
-00013cc0: 2020 2020 2020 2020 2020 7232 2e73 746f            r2.sto
-00013cd0: 7265 5061 636b 6574 2831 202a 2054 7261  rePacket(1 * Tra
-00013ce0: 6974 733a 3a52 6573 5061 636b 6574 5369  its::ResPacketSi
-00013cf0: 7a65 2c20 5231 293b 0a20 2020 2020 2020  ze, R1);.       
-00013d00: 2020 2072 332e 7374 6f72 6550 6163 6b65     r3.storePacke
-00013d10: 7428 3020 2a20 5472 6169 7473 3a3a 5265  t(0 * Traits::Re
-00013d20: 7350 6163 6b65 7453 697a 652c 2052 3229  sPacketSize, R2)
-00013d30: 3b0a 2020 2020 2020 2020 2020 7233 2e73  ;.          r3.s
-00013d40: 746f 7265 5061 636b 6574 2831 202a 2054  torePacket(1 * T
-00013d50: 7261 6974 733a 3a52 6573 5061 636b 6574  raits::ResPacket
-00013d60: 5369 7a65 2c20 5233 293b 0a20 2020 2020  Size, R3);.     
-00013d70: 2020 2020 207d 0a20 2020 2020 2020 207d       }.        }
-00013d80: 0a20 2020 2020 200a 2020 2020 2020 2020  .      .        
-00013d90: 2f2f 2044 6561 6c20 7769 7468 2072 656d  // Deal with rem
-00013da0: 6169 6e69 6e67 2063 6f6c 756d 6e73 206f  aining columns o
-00013db0: 6620 7468 6520 7268 730a 2020 2020 2020  f the rhs.      
-00013dc0: 2020 666f 7228 496e 6465 7820 6a32 3d70    for(Index j2=p
-00013dd0: 6163 6b65 745f 636f 6c73 343b 206a 323c  acket_cols4; j2<
-00013de0: 636f 6c73 3b20 6a32 2b2b 290a 2020 2020  cols; j2++).    
-00013df0: 2020 2020 7b0a 2020 2020 2020 2020 2020      {.          
-00013e00: 666f 7228 496e 6465 7820 693d 6931 3b20  for(Index i=i1; 
-00013e10: 693c 6163 7475 616c 5f70 616e 656c 5f65  i<actual_panel_e
-00013e20: 6e64 3b20 692b 3d32 2a4c 6873 5072 6f67  nd; i+=2*LhsProg
-00013e30: 7265 7373 290a 2020 2020 2020 2020 2020  ress).          
-00013e40: 7b0a 2020 2020 2020 2020 2020 2f2f 204f  {.          // O
-00013e50: 6e65 2063 6f6c 756d 6e20 6174 2061 2074  ne column at a t
-00013e60: 696d 650a 2020 2020 2020 2020 2020 636f  ime.          co
-00013e70: 6e73 7420 4c68 7353 6361 6c61 722a 2062  nst LhsScalar* b
-00013e80: 6c41 203d 2026 626c 6f63 6b41 5b69 2a73  lA = &blockA[i*s
-00013e90: 7472 6964 6541 2b6f 6666 7365 7441 2a28  trideA+offsetA*(
-00013ea0: 322a 5472 6169 7473 3a3a 4c68 7350 726f  2*Traits::LhsPro
-00013eb0: 6772 6573 7329 5d3b 0a20 2020 2020 2020  gress)];.       
-00013ec0: 2020 2070 7265 6665 7463 6828 2662 6c41     prefetch(&blA
-00013ed0: 5b30 5d29 3b0a 0a20 2020 2020 2020 2020  [0]);..         
-00013ee0: 202f 2f20 6765 7473 2072 6573 2062 6c6f   // gets res blo
-00013ef0: 636b 2061 7320 7265 6769 7374 6572 0a20  ck as register. 
-00013f00: 2020 2020 2020 2020 2041 6363 5061 636b           AccPack
-00013f10: 6574 2043 302c 2043 343b 0a20 2020 2020  et C0, C4;.     
-00013f20: 2020 2020 2074 7261 6974 732e 696e 6974       traits.init
-00013f30: 4163 6328 4330 293b 0a20 2020 2020 2020  Acc(C0);.       
-00013f40: 2020 2074 7261 6974 732e 696e 6974 4163     traits.initAc
-00013f50: 6328 4334 293b 0a0a 2020 2020 2020 2020  c(C4);..        
-00013f60: 2020 4c69 6e65 6172 4d61 7070 6572 2072    LinearMapper r
-00013f70: 3020 3d20 7265 732e 6765 744c 696e 6561  0 = res.getLinea
-00013f80: 724d 6170 7065 7228 692c 206a 3229 3b0a  rMapper(i, j2);.
-00013f90: 2020 2020 2020 2020 2020 7230 2e70 7265            r0.pre
-00013fa0: 6665 7463 6828 7072 6566 6574 6368 5f72  fetch(prefetch_r
-00013fb0: 6573 5f6f 6666 7365 7429 3b0a 0a20 2020  es_offset);..   
-00013fc0: 2020 2020 2020 202f 2f20 7065 7266 6f72         // perfor
-00013fd0: 6d73 2022 696e 6e65 7222 2070 726f 6475  ms "inner" produ
-00013fe0: 6374 730a 2020 2020 2020 2020 2020 636f  cts.          co
-00013ff0: 6e73 7420 5268 7353 6361 6c61 722a 2062  nst RhsScalar* b
-00014000: 6c42 203d 2026 626c 6f63 6b42 5b6a 322a  lB = &blockB[j2*
-00014010: 7374 7269 6465 422b 6f66 6673 6574 425d  strideB+offsetB]
-00014020: 3b0a 2020 2020 2020 2020 2020 4c68 7350  ;.          LhsP
-00014030: 6163 6b65 7420 4130 2c20 4131 3b0a 0a20  acket A0, A1;.. 
-00014040: 2020 2020 2020 2020 2066 6f72 2849 6e64           for(Ind
-00014050: 6578 206b 3d30 3b20 6b3c 7065 656c 6564  ex k=0; k<peeled
-00014060: 5f6b 633b 206b 2b3d 706b 290a 2020 2020  _kc; k+=pk).    
-00014070: 2020 2020 2020 7b0a 2020 2020 2020 2020        {.        
-00014080: 2020 2020 4549 4745 4e5f 4153 4d5f 434f      EIGEN_ASM_CO
-00014090: 4d4d 454e 5428 2262 6567 696e 2067 6562  MMENT("begin geb
-000140a0: 7020 6d69 6372 6f20 6b65 726e 656c 2032  p micro kernel 2
-000140b0: 7058 3122 293b 0a20 2020 2020 2020 2020  pX1");.         
-000140c0: 2020 2052 6873 5061 636b 6574 2042 5f30     RhsPacket B_0
-000140d0: 2c20 4231 3b0a 2020 2020 2020 2020 0a23  , B1;.        .#
-000140e0: 6465 6669 6e65 2045 4947 454e 5f47 4542  define EIGEN_GEB
-000140f0: 4750 5f4f 4e45 5354 4550 284b 2920 5c0a  GP_ONESTEP(K) \.
-00014100: 2020 2020 2020 2020 2020 2020 646f 207b              do {
-00014110: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014120: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014130: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014140: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014150: 2020 5c0a 2020 2020 2020 2020 2020 2020    \.            
-00014160: 2020 4549 4745 4e5f 4153 4d5f 434f 4d4d    EIGEN_ASM_COMM
-00014170: 454e 5428 2262 6567 696e 2073 7465 7020  ENT("begin step 
-00014180: 6f66 2067 6562 7020 6d69 6372 6f20 6b65  of gebp micro ke
-00014190: 726e 656c 2032 7058 3122 293b 2020 2020  rnel 2pX1");    
-000141a0: 2020 2020 2020 5c0a 2020 2020 2020 2020        \.        
-000141b0: 2020 2020 2020 4549 4745 4e5f 4153 4d5f        EIGEN_ASM_
-000141c0: 434f 4d4d 454e 5428 224e 6f74 653a 2074  COMMENT("Note: t
-000141d0: 6865 7365 2061 736d 2063 6f6d 6d65 6e74  hese asm comment
-000141e0: 7320 776f 726b 2061 726f 756e 6420 6275  s work around bu
-000141f0: 6720 3933 3521 2229 3b20 5c0a 2020 2020  g 935!"); \.    
-00014200: 2020 2020 2020 2020 2020 7472 6169 7473            traits
-00014210: 2e6c 6f61 644c 6873 2826 626c 415b 2830  .loadLhs(&blA[(0
-00014220: 2b32 2a4b 292a 4c68 7350 726f 6772 6573  +2*K)*LhsProgres
-00014230: 735d 2c20 4130 293b 2020 2020 2020 2020  s], A0);        
-00014240: 2020 2020 2020 2020 2020 2020 2020 5c0a                \.
-00014250: 2020 2020 2020 2020 2020 2020 2020 7472                tr
-00014260: 6169 7473 2e6c 6f61 644c 6873 2826 626c  aits.loadLhs(&bl
-00014270: 415b 2831 2b32 2a4b 292a 4c68 7350 726f  A[(1+2*K)*LhsPro
-00014280: 6772 6573 735d 2c20 4131 293b 2020 2020  gress], A1);    
-00014290: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000142a0: 2020 5c0a 2020 2020 2020 2020 2020 2020    \.            
-000142b0: 2020 7472 6169 7473 2e6c 6f61 6452 6873    traits.loadRhs
-000142c0: 2826 626c 425b 2830 2b4b 292a 5268 7350  (&blB[(0+K)*RhsP
-000142d0: 726f 6772 6573 735d 2c20 425f 3029 3b20  rogress], B_0); 
-000142e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000142f0: 2020 2020 2020 5c0a 2020 2020 2020 2020        \.        
-00014300: 2020 2020 2020 7472 6169 7473 2e6d 6164        traits.mad
-00014310: 6428 4130 2c20 425f 302c 2043 302c 2042  d(A0, B_0, C0, B
-00014320: 312c 2066 6978 3c30 3e29 3b20 2020 2020  1, fix<0>);     
-00014330: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014340: 2020 2020 2020 2020 2020 5c0a 2020 2020            \.    
-00014350: 2020 2020 2020 2020 2020 7472 6169 7473            traits
-00014360: 2e6d 6164 6428 4131 2c20 425f 302c 2043  .madd(A1, B_0, C
-00014370: 342c 2042 5f30 2c20 6669 783c 303e 293b  4, B_0, fix<0>);
-00014380: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00014390: 2020 2020 2020 2020 2020 2020 2020 5c0a                \.
-000143a0: 2020 2020 2020 2020 2020 2020 2020 4549                EI
-000143b0: 4745 4e5f 4153 4d5f 434f 4d4d 454e 5428  GEN_ASM_COMMENT(
-000143c0: 2265 6e64 2073 7465 7020 6f66 2067 6562  "end step of geb
-000143d0: 7020 6d69 6372 6f20 6b65 726e 656c 2032  p micro kernel 2
-000143e0: 7058 3122 293b 2020 2020 2020 2020 2020  pX1");          
-000143f0: 2020 5c0a 2020 2020 2020 2020 2020 2020    \.            
-00014400: 7d20 7768 696c 6528 6661 6c73 6529 0a20  } while(false). 
-00014410: 2020 2020 2020 200a 2020 2020 2020 2020         .        
-00014420: 2020 2020 4549 4745 4e5f 4745 4247 505f      EIGEN_GEBGP_
-00014430: 4f4e 4553 5445 5028 3029 3b0a 2020 2020  ONESTEP(0);.    
-00014440: 2020 2020 2020 2020 4549 4745 4e5f 4745          EIGEN_GE
-00014450: 4247 505f 4f4e 4553 5445 5028 3129 3b0a  BGP_ONESTEP(1);.
-00014460: 2020 2020 2020 2020 2020 2020 4549 4745              EIGE
-00014470: 4e5f 4745 4247 505f 4f4e 4553 5445 5028  N_GEBGP_ONESTEP(
-00014480: 3229 3b0a 2020 2020 2020 2020 2020 2020  2);.            
-00014490: 4549 4745 4e5f 4745 4247 505f 4f4e 4553  EIGEN_GEBGP_ONES
-000144a0: 5445 5028 3329 3b0a 2020 2020 2020 2020  TEP(3);.        
-000144b0: 2020 2020 4549 4745 4e5f 4745 4247 505f      EIGEN_GEBGP_
-000144c0: 4f4e 4553 5445 5028 3429 3b0a 2020 2020  ONESTEP(4);.    
-000144d0: 2020 2020 2020 2020 4549 4745 4e5f 4745          EIGEN_GE
-000144e0: 4247 505f 4f4e 4553 5445 5028 3529 3b0a  BGP_ONESTEP(5);.
-000144f0: 2020 2020 2020 2020 2020 2020 4549 4745              EIGE
-00014500: 4e5f 4745 4247 505f 4f4e 4553 5445 5028  N_GEBGP_ONESTEP(
-00014510: 3629 3b0a 2020 2020 2020 2020 2020 2020  6);.            
-00014520: 4549 4745 4e5f 4745 4247 505f 4f4e 4553  EIGEN_GEBGP_ONES
-00014530: 5445 5028 3729 3b0a 0a20 2020 2020 2020  TEP(7);..       
-00014540: 2020 2020 2062 6c42 202b 3d20 706b 2a52       blB += pk*R
-00014550: 6873 5072 6f67 7265 7373 3b0a 2020 2020  hsProgress;.    
-00014560: 2020 2020 2020 2020 626c 4120 2b3d 2070          blA += p
-00014570: 6b2a 322a 5472 6169 7473 3a3a 4c68 7350  k*2*Traits::LhsP
-00014580: 726f 6772 6573 733b 0a0a 2020 2020 2020  rogress;..      
-00014590: 2020 2020 2020 4549 4745 4e5f 4153 4d5f        EIGEN_ASM_
-000145a0: 434f 4d4d 454e 5428 2265 6e64 2067 6562  COMMENT("end geb
-000145b0: 7020 6d69 6372 6f20 6b65 726e 656c 2032  p micro kernel 2
-000145c0: 7058 3122 293b 0a20 2020 2020 2020 2020  pX1");.         
-000145d0: 207d 0a0a 2020 2020 2020 2020 2020 2f2f   }..          //
-000145e0: 2070 726f 6365 7373 2072 656d 6169 6e69   process remaini
-000145f0: 6e67 2070 6565 6c65 6420 6c6f 6f70 0a20  ng peeled loop. 
-00014600: 2020 2020 2020 2020 2066 6f72 2849 6e64           for(Ind
-00014610: 6578 206b 3d70 6565 6c65 645f 6b63 3b20  ex k=peeled_kc; 
-00014620: 6b3c 6465 7074 683b 206b 2b2b 290a 2020  k<depth; k++).  
-00014630: 2020 2020 2020 2020 7b0a 2020 2020 2020          {.      
-00014640: 2020 2020 2020 5268 7350 6163 6b65 7420        RhsPacket 
-00014650: 425f 302c 2042 313b 0a20 2020 2020 2020  B_0, B1;.       
-00014660: 2020 2020 2045 4947 454e 5f47 4542 4750       EIGEN_GEBGP
-00014670: 5f4f 4e45 5354 4550 2830 293b 0a20 2020  _ONESTEP(0);.   
-00014680: 2020 2020 2020 2020 2062 6c42 202b 3d20           blB += 
-00014690: 5268 7350 726f 6772 6573 733b 0a20 2020  RhsProgress;.   
-000146a0: 2020 2020 2020 2020 2062 6c41 202b 3d20           blA += 
-000146b0: 322a 5472 6169 7473 3a3a 4c68 7350 726f  2*Traits::LhsPro
-000146c0: 6772 6573 733b 0a20 2020 2020 2020 2020  gress;.         
-000146d0: 207d 0a23 756e 6465 6620 4549 4745 4e5f   }.#undef EIGEN_
-000146e0: 4745 4247 505f 4f4e 4553 5445 500a 2020  GEBGP_ONESTEP.  
-000146f0: 2020 2020 2020 2020 5265 7350 6163 6b65          ResPacke
-00014700: 7420 5230 2c20 5231 3b0a 2020 2020 2020  t R0, R1;.      
-00014710: 2020 2020 5265 7350 6163 6b65 7420 616c      ResPacket al
-00014720: 7068 6176 203d 2070 7365 7431 3c52 6573  phav = pset1<Res
-00014730: 5061 636b 6574 3e28 616c 7068 6129 3b0a  Packet>(alpha);.
-00014740: 0a20 2020 2020 2020 2020 2052 3020 3d20  .          R0 = 
-00014750: 7230 2e74 656d 706c 6174 6520 6c6f 6164  r0.template load
-00014760: 5061 636b 6574 3c52 6573 5061 636b 6574  Packet<ResPacket
-00014770: 3e28 3020 2a20 5472 6169 7473 3a3a 5265  >(0 * Traits::Re
-00014780: 7350 6163 6b65 7453 697a 6529 3b0a 2020  sPacketSize);.  
-00014790: 2020 2020 2020 2020 5231 203d 2072 302e          R1 = r0.
-000147a0: 7465 6d70 6c61 7465 206c 6f61 6450 6163  template loadPac
-000147b0: 6b65 743c 5265 7350 6163 6b65 743e 2831  ket<ResPacket>(1
-000147c0: 202a 2054 7261 6974 733a 3a52 6573 5061   * Traits::ResPa
-000147d0: 636b 6574 5369 7a65 293b 0a20 2020 2020  cketSize);.     
-000147e0: 2020 2020 2074 7261 6974 732e 6163 6328       traits.acc(
-000147f0: 4330 2c20 616c 7068 6176 2c20 5230 293b  C0, alphav, R0);
-00014800: 0a20 2020 2020 2020 2020 2074 7261 6974  .          trait
-00014810: 732e 6163 6328 4334 2c20 616c 7068 6176  s.acc(C4, alphav
-00014820: 2c20 5231 293b 0a20 2020 2020 2020 2020  , R1);.         
-00014830: 2072 302e 7374 6f72 6550 6163 6b65 7428   r0.storePacket(
-00014840: 3020 2a20 5472 6169 7473 3a3a 5265 7350  0 * Traits::ResP
-00014850: 6163 6b65 7453 697a 652c 2052 3029 3b0a  acketSize, R0);.
-00014860: 2020 2020 2020 2020 2020 7230 2e73 746f            r0.sto
-00014870: 7265 5061 636b 6574 2831 202a 2054 7261  rePacket(1 * Tra
-00014880: 6974 733a 3a52 6573 5061 636b 6574 5369  its::ResPacketSi
-00014890: 7a65 2c20 5231 293b 0a20 2020 2020 2020  ze, R1);.       
-000148a0: 2020 207d 0a20 2020 2020 2020 207d 0a20     }.        }. 
-000148b0: 2020 2020 207d 0a20 2020 207d 0a20 2020       }.    }.   
-000148c0: 202f 2f2d 2d2d 2d2d 2d2d 2d2d 2d20 5072   //---------- Pr
-000148d0: 6f63 6573 7320 3120 2a20 4c68 7350 726f  ocess 1 * LhsPro
-000148e0: 6772 6573 7320 726f 7773 2061 7420 6f6e  gress rows at on
-000148f0: 6365 202d 2d2d 2d2d 2d2d 2d2d 2d0a 2020  ce ----------.  
-00014900: 2020 6966 286d 723e 3d31 2a54 7261 6974    if(mr>=1*Trait
-00014910: 733a 3a4c 6873 5072 6f67 7265 7373 290a  s::LhsProgress).
-00014920: 2020 2020 7b0a 2020 2020 2020 6c68 735f      {.      lhs_
-00014930: 7072 6f63 6573 735f 6f6e 655f 7061 636b  process_one_pack
-00014940: 6574 3c6e 722c 204c 6873 5072 6f67 7265  et<nr, LhsProgre
-00014950: 7373 2c20 5268 7350 726f 6772 6573 732c  ss, RhsProgress,
-00014960: 204c 6873 5363 616c 6172 2c20 5268 7353   LhsScalar, RhsS
-00014970: 6361 6c61 722c 2052 6573 5363 616c 6172  calar, ResScalar
-00014980: 2c20 4163 6350 6163 6b65 742c 204c 6873  , AccPacket, Lhs
-00014990: 5061 636b 6574 2c20 5268 7350 6163 6b65  Packet, RhsPacke
-000149a0: 742c 2052 6573 5061 636b 6574 2c20 5472  t, ResPacket, Tr
-000149b0: 6169 7473 2c20 4c69 6e65 6172 4d61 7070  aits, LinearMapp
-000149c0: 6572 2c20 4461 7461 4d61 7070 6572 3e20  er, DataMapper> 
-000149d0: 703b 0a20 2020 2020 2070 2872 6573 2c20  p;.      p(res, 
-000149e0: 626c 6f63 6b41 2c20 626c 6f63 6b42 2c20  blockA, blockB, 
-000149f0: 616c 7068 612c 2070 6565 6c65 645f 6d63  alpha, peeled_mc
-00014a00: 322c 2070 6565 6c65 645f 6d63 312c 2073  2, peeled_mc1, s
-00014a10: 7472 6964 6541 2c20 7374 7269 6465 422c  trideA, strideB,
-00014a20: 206f 6666 7365 7441 2c20 6f66 6673 6574   offsetA, offset
-00014a30: 422c 2070 7265 6665 7463 685f 7265 735f  B, prefetch_res_
-00014a40: 6f66 6673 6574 2c20 7065 656c 6564 5f6b  offset, peeled_k
-00014a50: 632c 2070 6b2c 2063 6f6c 732c 2064 6570  c, pk, cols, dep
-00014a60: 7468 2c20 7061 636b 6574 5f63 6f6c 7334  th, packet_cols4
-00014a70: 293b 0a20 2020 207d 0a20 2020 202f 2f2d  );.    }.    //-
-00014a80: 2d2d 2d2d 2d2d 2d2d 2d20 5072 6f63 6573  --------- Proces
-00014a90: 7320 4c68 7350 726f 6772 6573 7348 616c  s LhsProgressHal
-00014aa0: 6620 726f 7773 2061 7420 6f6e 6365 202d  f rows at once -
-00014ab0: 2d2d 2d2d 2d2d 2d2d 2d0a 2020 2020 6966  ---------.    if
-00014ac0: 2828 4c68 7350 726f 6772 6573 7348 616c  ((LhsProgressHal
-00014ad0: 6620 3c20 4c68 7350 726f 6772 6573 7329  f < LhsProgress)
-00014ae0: 2026 2620 6d72 3e3d 4c68 7350 726f 6772   && mr>=LhsProgr
-00014af0: 6573 7348 616c 6629 0a20 2020 207b 0a20  essHalf).    {. 
-00014b00: 2020 2020 206c 6873 5f70 726f 6365 7373       lhs_process
-00014b10: 5f66 7261 6374 696f 6e5f 6f66 5f70 6163  _fraction_of_pac
-00014b20: 6b65 743c 6e72 2c20 4c68 7350 726f 6772  ket<nr, LhsProgr
-00014b30: 6573 7348 616c 662c 2052 6873 5072 6f67  essHalf, RhsProg
-00014b40: 7265 7373 4861 6c66 2c20 4c68 7353 6361  ressHalf, LhsSca
-00014b50: 6c61 722c 2052 6873 5363 616c 6172 2c20  lar, RhsScalar, 
-00014b60: 5265 7353 6361 6c61 722c 2041 6363 5061  ResScalar, AccPa
-00014b70: 636b 6574 4861 6c66 2c20 4c68 7350 6163  cketHalf, LhsPac
-00014b80: 6b65 7448 616c 662c 2052 6873 5061 636b  ketHalf, RhsPack
-00014b90: 6574 4861 6c66 2c20 5265 7350 6163 6b65  etHalf, ResPacke
-00014ba0: 7448 616c 662c 2048 616c 6654 7261 6974  tHalf, HalfTrait
-00014bb0: 732c 204c 696e 6561 724d 6170 7065 722c  s, LinearMapper,
-00014bc0: 2044 6174 614d 6170 7065 723e 2070 3b0a   DataMapper> p;.
-00014bd0: 2020 2020 2020 7028 7265 732c 2062 6c6f        p(res, blo
-00014be0: 636b 412c 2062 6c6f 636b 422c 2061 6c70  ckA, blockB, alp
-00014bf0: 6861 2c20 7065 656c 6564 5f6d 6331 2c20  ha, peeled_mc1, 
-00014c00: 7065 656c 6564 5f6d 635f 6861 6c66 2c20  peeled_mc_half, 
-00014c10: 7374 7269 6465 412c 2073 7472 6964 6542  strideA, strideB
-00014c20: 2c20 6f66 6673 6574 412c 206f 6666 7365  , offsetA, offse
-00014c30: 7442 2c20 7072 6566 6574 6368 5f72 6573  tB, prefetch_res
-00014c40: 5f6f 6666 7365 742c 2070 6565 6c65 645f  _offset, peeled_
-00014c50: 6b63 2c20 706b 2c20 636f 6c73 2c20 6465  kc, pk, cols, de
-00014c60: 7074 682c 2070 6163 6b65 745f 636f 6c73  pth, packet_cols
-00014c70: 3429 3b0a 2020 2020 7d0a 2020 2020 2f2f  4);.    }.    //
-00014c80: 2d2d 2d2d 2d2d 2d2d 2d2d 2050 726f 6365  ---------- Proce
-00014c90: 7373 204c 6873 5072 6f67 7265 7373 5175  ss LhsProgressQu
-00014ca0: 6172 7465 7220 726f 7773 2061 7420 6f6e  arter rows at on
-00014cb0: 6365 202d 2d2d 2d2d 2d2d 2d2d 2d0a 2020  ce ----------.  
-00014cc0: 2020 6966 2828 4c68 7350 726f 6772 6573    if((LhsProgres
-00014cd0: 7351 7561 7274 6572 203c 204c 6873 5072  sQuarter < LhsPr
-00014ce0: 6f67 7265 7373 4861 6c66 2920 2626 206d  ogressHalf) && m
-00014cf0: 723e 3d4c 6873 5072 6f67 7265 7373 5175  r>=LhsProgressQu
-00014d00: 6172 7465 7229 0a20 2020 207b 0a20 2020  arter).    {.   
-00014d10: 2020 206c 6873 5f70 726f 6365 7373 5f66     lhs_process_f
-00014d20: 7261 6374 696f 6e5f 6f66 5f70 6163 6b65  raction_of_packe
-00014d30: 743c 6e72 2c20 4c68 7350 726f 6772 6573  t<nr, LhsProgres
-00014d40: 7351 7561 7274 6572 2c20 5268 7350 726f  sQuarter, RhsPro
-00014d50: 6772 6573 7351 7561 7274 6572 2c20 4c68  gressQuarter, Lh
-00014d60: 7353 6361 6c61 722c 2052 6873 5363 616c  sScalar, RhsScal
-00014d70: 6172 2c20 5265 7353 6361 6c61 722c 2041  ar, ResScalar, A
-00014d80: 6363 5061 636b 6574 5175 6172 7465 722c  ccPacketQuarter,
-00014d90: 204c 6873 5061 636b 6574 5175 6172 7465   LhsPacketQuarte
-00014da0: 722c 2052 6873 5061 636b 6574 5175 6172  r, RhsPacketQuar
-00014db0: 7465 722c 2052 6573 5061 636b 6574 5175  ter, ResPacketQu
-00014dc0: 6172 7465 722c 2051 7561 7274 6572 5472  arter, QuarterTr
-00014dd0: 6169 7473 2c20 4c69 6e65 6172 4d61 7070  aits, LinearMapp
-00014de0: 6572 2c20 4461 7461 4d61 7070 6572 3e20  er, DataMapper> 
-00014df0: 703b 0a20 2020 2020 2070 2872 6573 2c20  p;.      p(res, 
-00014e00: 626c 6f63 6b41 2c20 626c 6f63 6b42 2c20  blockA, blockB, 
-00014e10: 616c 7068 612c 2070 6565 6c65 645f 6d63  alpha, peeled_mc
-00014e20: 5f68 616c 662c 2070 6565 6c65 645f 6d63  _half, peeled_mc
-00014e30: 5f71 7561 7274 6572 2c20 7374 7269 6465  _quarter, stride
-00014e40: 412c 2073 7472 6964 6542 2c20 6f66 6673  A, strideB, offs
-00014e50: 6574 412c 206f 6666 7365 7442 2c20 7072  etA, offsetB, pr
-00014e60: 6566 6574 6368 5f72 6573 5f6f 6666 7365  efetch_res_offse
-00014e70: 742c 2070 6565 6c65 645f 6b63 2c20 706b  t, peeled_kc, pk
-00014e80: 2c20 636f 6c73 2c20 6465 7074 682c 2070  , cols, depth, p
-00014e90: 6163 6b65 745f 636f 6c73 3429 3b0a 2020  acket_cols4);.  
-00014ea0: 2020 7d0a 2020 2020 2f2f 2d2d 2d2d 2d2d    }.    //------
-00014eb0: 2d2d 2d2d 2050 726f 6365 7373 2072 656d  ---- Process rem
-00014ec0: 6169 6e69 6e67 2072 6f77 732c 2031 2061  aining rows, 1 a
-00014ed0: 7420 6f6e 6365 202d 2d2d 2d2d 2d2d 2d2d  t once ---------
-00014ee0: 2d0a 2020 2020 6966 2870 6565 6c65 645f  -.    if(peeled_
-00014ef0: 6d63 5f71 7561 7274 6572 3c72 6f77 7329  mc_quarter<rows)
-00014f00: 0a20 2020 207b 0a20 2020 2020 202f 2f20  .    {.      // 
-00014f10: 6c6f 6f70 206f 6e20 6561 6368 2070 616e  loop on each pan
-00014f20: 656c 206f 6620 7468 6520 7268 730a 2020  el of the rhs.  
-00014f30: 2020 2020 666f 7228 496e 6465 7820 6a32      for(Index j2
-00014f40: 3d30 3b20 6a32 3c70 6163 6b65 745f 636f  =0; j2<packet_co
-00014f50: 6c73 343b 206a 322b 3d6e 7229 0a20 2020  ls4; j2+=nr).   
-00014f60: 2020 207b 0a20 2020 2020 2020 202f 2f20     {.        // 
-00014f70: 6c6f 6f70 206f 6e20 6561 6368 2072 6f77  loop on each row
-00014f80: 206f 6620 7468 6520 6c68 7320 2831 2a4c   of the lhs (1*L
-00014f90: 6873 5072 6f67 7265 7373 2078 2064 6570  hsProgress x dep
-00014fa0: 7468 290a 2020 2020 2020 2020 666f 7228  th).        for(
-00014fb0: 496e 6465 7820 693d 7065 656c 6564 5f6d  Index i=peeled_m
-00014fc0: 635f 7175 6172 7465 723b 2069 3c72 6f77  c_quarter; i<row
-00014fd0: 733b 2069 2b3d 3129 0a20 2020 2020 2020  s; i+=1).       
-00014fe0: 207b 0a20 2020 2020 2020 2020 2063 6f6e   {.          con
-00014ff0: 7374 204c 6873 5363 616c 6172 2a20 626c  st LhsScalar* bl
-00015000: 4120 3d20 2662 6c6f 636b 415b 692a 7374  A = &blockA[i*st
-00015010: 7269 6465 412b 6f66 6673 6574 415d 3b0a  rideA+offsetA];.
-00015020: 2020 2020 2020 2020 2020 7072 6566 6574            prefet
-00015030: 6368 2826 626c 415b 305d 293b 0a20 2020  ch(&blA[0]);.   
-00015040: 2020 2020 2020 2063 6f6e 7374 2052 6873         const Rhs
-00015050: 5363 616c 6172 2a20 626c 4220 3d20 2662  Scalar* blB = &b
-00015060: 6c6f 636b 425b 6a32 2a73 7472 6964 6542  lockB[j2*strideB
-00015070: 2b6f 6666 7365 7442 2a6e 725d 3b0a 0a20  +offsetB*nr];.. 
-00015080: 2020 2020 2020 2020 202f 2f20 4966 204c           // If L
-00015090: 6873 5072 6f67 7265 7373 2069 7320 3820  hsProgress is 8 
-000150a0: 6f72 2031 362c 2069 7420 6173 7375 6d65  or 16, it assume
-000150b0: 7320 7468 6174 2074 6865 7265 2069 7320  s that there is 
-000150c0: 610a 2020 2020 2020 2020 2020 2f2f 2068  a.          // h
-000150d0: 616c 6620 6f72 2071 7561 7274 6572 2070  alf or quarter p
-000150e0: 6163 6b65 742c 2072 6573 7065 6374 6976  acket, respectiv
-000150f0: 656c 792c 206f 6620 7468 6520 7361 6d65  ely, of the same
-00015100: 2073 697a 6520 6173 0a20 2020 2020 2020   size as.       
-00015110: 2020 202f 2f20 6e72 2028 7768 6963 6820     // nr (which 
-00015120: 6973 2063 7572 7265 6e74 6c79 2034 2920  is currently 4) 
-00015130: 666f 7220 7468 6520 7265 7475 726e 2074  for the return t
-00015140: 7970 652e 0a20 2020 2020 2020 2020 2063  ype..          c
-00015150: 6f6e 7374 2069 6e74 2053 5265 7350 6163  onst int SResPac
-00015160: 6b65 7448 616c 6653 697a 6520 3d20 756e  ketHalfSize = un
-00015170: 7061 636b 6574 5f74 7261 6974 733c 7479  packet_traits<ty
-00015180: 7065 6e61 6d65 2075 6e70 6163 6b65 745f  pename unpacket_
-00015190: 7472 6169 7473 3c53 5265 7350 6163 6b65  traits<SResPacke
-000151a0: 743e 3a3a 6861 6c66 3e3a 3a73 697a 653b  t>::half>::size;
-000151b0: 0a20 2020 2020 2020 2020 2063 6f6e 7374  .          const
-000151c0: 2069 6e74 2053 5265 7350 6163 6b65 7451   int SResPacketQ
-000151d0: 7561 7274 6572 5369 7a65 203d 2075 6e70  uarterSize = unp
-000151e0: 6163 6b65 745f 7472 6169 7473 3c74 7970  acket_traits<typ
-000151f0: 656e 616d 6520 756e 7061 636b 6574 5f74  ename unpacket_t
-00015200: 7261 6974 733c 7479 7065 6e61 6d65 2075  raits<typename u
-00015210: 6e70 6163 6b65 745f 7472 6169 7473 3c53  npacket_traits<S
-00015220: 5265 7350 6163 6b65 743e 3a3a 6861 6c66  ResPacket>::half
-00015230: 3e3a 3a68 616c 663e 3a3a 7369 7a65 3b0a  >::half>::size;.
-00015240: 2020 2020 2020 2020 2020 6966 2028 2853            if ((S
-00015250: 7761 7070 6564 5472 6169 7473 3a3a 4c68  wappedTraits::Lh
-00015260: 7350 726f 6772 6573 7320 2520 3429 203d  sProgress % 4) =
-00015270: 3d20 3020 2626 0a20 2020 2020 2020 2020  = 0 &&.         
-00015280: 2020 2020 2028 5377 6170 7065 6454 7261       (SwappedTra
-00015290: 6974 733a 3a4c 6873 5072 6f67 7265 7373  its::LhsProgress
-000152a0: 3c3d 3136 2920 2626 0a20 2020 2020 2020  <=16) &&.       
-000152b0: 2020 2020 2020 2028 5377 6170 7065 6454         (SwappedT
-000152c0: 7261 6974 733a 3a4c 6873 5072 6f67 7265  raits::LhsProgre
-000152d0: 7373 213d 3820 207c 7c20 5352 6573 5061  ss!=8  || SResPa
-000152e0: 636b 6574 4861 6c66 5369 7a65 3d3d 6e72  cketHalfSize==nr
-000152f0: 2920 2626 0a20 2020 2020 2020 2020 2020  ) &&.           
-00015300: 2020 2028 5377 6170 7065 6454 7261 6974     (SwappedTrait
-00015310: 733a 3a4c 6873 5072 6f67 7265 7373 213d  s::LhsProgress!=
-00015320: 3136 207c 7c20 5352 6573 5061 636b 6574  16 || SResPacket
-00015330: 5175 6172 7465 7253 697a 653d 3d6e 7229  QuarterSize==nr)
-00015340: 290a 2020 2020 2020 2020 2020 7b0a 2020  ).          {.  
-00015350: 2020 2020 2020 2020 2020 5341 6363 5061            SAccPa
-00015360: 636b 6574 2043 302c 2043 312c 2043 322c  cket C0, C1, C2,
-00015370: 2043 333b 0a20 2020 2020 2020 2020 2020   C3;.           
-00015380: 2073 7472 6169 7473 2e69 6e69 7441 6363   straits.initAcc
-00015390: 2843 3029 3b0a 2020 2020 2020 2020 2020  (C0);.          
-000153a0: 2020 7374 7261 6974 732e 696e 6974 4163    straits.initAc
-000153b0: 6328 4331 293b 0a20 2020 2020 2020 2020  c(C1);.         
-000153c0: 2020 2073 7472 6169 7473 2e69 6e69 7441     straits.initA
-000153d0: 6363 2843 3229 3b0a 2020 2020 2020 2020  cc(C2);.        
-000153e0: 2020 2020 7374 7261 6974 732e 696e 6974      straits.init
-000153f0: 4163 6328 4333 293b 0a0a 2020 2020 2020  Acc(C3);..      
-00015400: 2020 2020 2020 636f 6e73 7420 496e 6465        const Inde
-00015410: 7820 7370 6b20 2020 3d20 2873 7464 3a3a  x spk   = (std::
-00015420: 6d61 7829 2831 2c53 7761 7070 6564 5472  max)(1,SwappedTr
-00015430: 6169 7473 3a3a 4c68 7350 726f 6772 6573  aits::LhsProgres
-00015440: 732f 3429 3b0a 2020 2020 2020 2020 2020  s/4);.          
-00015450: 2020 636f 6e73 7420 496e 6465 7820 656e    const Index en
-00015460: 646b 2020 3d20 2864 6570 7468 2f73 706b  dk  = (depth/spk
-00015470: 292a 7370 6b3b 0a20 2020 2020 2020 2020  )*spk;.         
-00015480: 2020 2063 6f6e 7374 2049 6e64 6578 2065     const Index e
-00015490: 6e64 6b34 203d 2028 6465 7074 682f 2873  ndk4 = (depth/(s
-000154a0: 706b 2a34 2929 2a28 7370 6b2a 3429 3b0a  pk*4))*(spk*4);.
-000154b0: 0a20 2020 2020 2020 2020 2020 2049 6e64  .            Ind
-000154c0: 6578 206b 3d30 3b0a 2020 2020 2020 2020  ex k=0;.        
-000154d0: 2020 2020 666f 7228 3b20 6b3c 656e 646b      for(; k<endk
-000154e0: 343b 206b 2b3d 342a 7370 6b29 0a20 2020  4; k+=4*spk).   
-000154f0: 2020 2020 2020 2020 207b 0a20 2020 2020           {.     
-00015500: 2020 2020 2020 2020 2053 4c68 7350 6163           SLhsPac
-00015510: 6b65 7420 4130 2c41 313b 0a20 2020 2020  ket A0,A1;.     
-00015520: 2020 2020 2020 2020 2053 5268 7350 6163           SRhsPac
-00015530: 6b65 7420 425f 302c 425f 313b 0a0a 2020  ket B_0,B_1;..  
-00015540: 2020 2020 2020 2020 2020 2020 7374 7261              stra
-00015550: 6974 732e 6c6f 6164 4c68 7355 6e61 6c69  its.loadLhsUnali
-00015560: 676e 6564 2862 6c42 2b30 2a53 7761 7070  gned(blB+0*Swapp
-00015570: 6564 5472 6169 7473 3a3a 4c68 7350 726f  edTraits::LhsPro
-00015580: 6772 6573 732c 2041 3029 3b0a 2020 2020  gress, A0);.    
-00015590: 2020 2020 2020 2020 2020 7374 7261 6974            strait
-000155a0: 732e 6c6f 6164 4c68 7355 6e61 6c69 676e  s.loadLhsUnalign
-000155b0: 6564 2862 6c42 2b31 2a53 7761 7070 6564  ed(blB+1*Swapped
-000155c0: 5472 6169 7473 3a3a 4c68 7350 726f 6772  Traits::LhsProgr
-000155d0: 6573 732c 2041 3129 3b0a 0a20 2020 2020  ess, A1);..     
-000155e0: 2020 2020 2020 2020 2073 7472 6169 7473           straits
-000155f0: 2e6c 6f61 6452 6873 5175 6164 2862 6c41  .loadRhsQuad(blA
-00015600: 2b30 2a73 706b 2c20 425f 3029 3b0a 2020  +0*spk, B_0);.  
-00015610: 2020 2020 2020 2020 2020 2020 7374 7261              stra
-00015620: 6974 732e 6c6f 6164 5268 7351 7561 6428  its.loadRhsQuad(
-00015630: 626c 412b 312a 7370 6b2c 2042 5f31 293b  blA+1*spk, B_1);
-00015640: 0a20 2020 2020 2020 2020 2020 2020 2073  .              s
-00015650: 7472 6169 7473 2e6d 6164 6428 4130 2c42  traits.madd(A0,B
-00015660: 5f30 2c43 302c 425f 302c 2066 6978 3c30  _0,C0,B_0, fix<0
-00015670: 3e29 3b0a 2020 2020 2020 2020 2020 2020  >);.            
-00015680: 2020 7374 7261 6974 732e 6d61 6464 2841    straits.madd(A
-00015690: 312c 425f 312c 4331 2c42 5f31 2c20 6669  1,B_1,C1,B_1, fi
-000156a0: 783c 303e 293b 0a0a 2020 2020 2020 2020  x<0>);..        
-000156b0: 2020 2020 2020 7374 7261 6974 732e 6c6f        straits.lo
-000156c0: 6164 4c68 7355 6e61 6c69 676e 6564 2862  adLhsUnaligned(b
-000156d0: 6c42 2b32 2a53 7761 7070 6564 5472 6169  lB+2*SwappedTrai
-000156e0: 7473 3a3a 4c68 7350 726f 6772 6573 732c  ts::LhsProgress,
-000156f0: 2041 3029 3b0a 2020 2020 2020 2020 2020   A0);.          
-00015700: 2020 2020 7374 7261 6974 732e 6c6f 6164      straits.load
-00015710: 4c68 7355 6e61 6c69 676e 6564 2862 6c42  LhsUnaligned(blB
-00015720: 2b33 2a53 7761 7070 6564 5472 6169 7473  +3*SwappedTraits
-00015730: 3a3a 4c68 7350 726f 6772 6573 732c 2041  ::LhsProgress, A
-00015740: 3129 3b0a 2020 2020 2020 2020 2020 2020  1);.            
-00015750: 2020 7374 7261 6974 732e 6c6f 6164 5268    straits.loadRh
-00015760: 7351 7561 6428 626c 412b 322a 7370 6b2c  sQuad(blA+2*spk,
-00015770: 2042 5f30 293b 0a20 2020 2020 2020 2020   B_0);.         
-00015780: 2020 2020 2073 7472 6169 7473 2e6c 6f61       straits.loa
-00015790: 6452 6873 5175 6164 2862 6c41 2b33 2a73  dRhsQuad(blA+3*s
-000157a0: 706b 2c20 425f 3129 3b0a 2020 2020 2020  pk, B_1);.      
-000157b0: 2020 2020 2020 2020 7374 7261 6974 732e          straits.
-000157c0: 6d61 6464 2841 302c 425f 302c 4332 2c42  madd(A0,B_0,C2,B
-000157d0: 5f30 2c20 6669 783c 303e 293b 0a20 2020  _0, fix<0>);.   
-000157e0: 2020 2020 2020 2020 2020 2073 7472 6169             strai
-000157f0: 7473 2e6d 6164 6428 4131 2c42 5f31 2c43  ts.madd(A1,B_1,C
-00015800: 332c 425f 312c 2066 6978 3c30 3e29 3b0a  3,B_1, fix<0>);.
-00015810: 0a20 2020 2020 2020 2020 2020 2020 2062  .              b
-00015820: 6c42 202b 3d20 342a 5377 6170 7065 6454  lB += 4*SwappedT
-00015830: 7261 6974 733a 3a4c 6873 5072 6f67 7265  raits::LhsProgre
-00015840: 7373 3b0a 2020 2020 2020 2020 2020 2020  ss;.            
-00015850: 2020 626c 4120 2b3d 2034 2a73 706b 3b0a    blA += 4*spk;.
-00015860: 2020 2020 2020 2020 2020 2020 7d0a 2020              }.  
-00015870: 2020 2020 2020 2020 2020 4330 203d 2070            C0 = p
-00015880: 6164 6428 7061 6464 2843 302c 4331 292c  add(padd(C0,C1),
-00015890: 7061 6464 2843 322c 4333 2929 3b0a 2020  padd(C2,C3));.  
-000158a0: 2020 2020 2020 2020 2020 666f 7228 3b20            for(; 
-000158b0: 6b3c 656e 646b 3b20 6b2b 3d73 706b 290a  k<endk; k+=spk).
-000158c0: 2020 2020 2020 2020 2020 2020 7b0a 2020              {.  
-000158d0: 2020 2020 2020 2020 2020 2020 534c 6873              SLhs
-000158e0: 5061 636b 6574 2041 303b 0a20 2020 2020  Packet A0;.     
-000158f0: 2020 2020 2020 2020 2053 5268 7350 6163           SRhsPac
-00015900: 6b65 7420 425f 303b 0a0a 2020 2020 2020  ket B_0;..      
-00015910: 2020 2020 2020 2020 7374 7261 6974 732e          straits.
-00015920: 6c6f 6164 4c68 7355 6e61 6c69 676e 6564  loadLhsUnaligned
-00015930: 2862 6c42 2c20 4130 293b 0a20 2020 2020  (blB, A0);.     
-00015940: 2020 2020 2020 2020 2073 7472 6169 7473           straits
-00015950: 2e6c 6f61 6452 6873 5175 6164 2862 6c41  .loadRhsQuad(blA
-00015960: 2c20 425f 3029 3b0a 2020 2020 2020 2020  , B_0);.        
-00015970: 2020 2020 2020 7374 7261 6974 732e 6d61        straits.ma
-00015980: 6464 2841 302c 425f 302c 4330 2c42 5f30  dd(A0,B_0,C0,B_0
-00015990: 2c20 6669 783c 303e 293b 0a0a 2020 2020  , fix<0>);..    
-000159a0: 2020 2020 2020 2020 2020 626c 4220 2b3d            blB +=
-000159b0: 2053 7761 7070 6564 5472 6169 7473 3a3a   SwappedTraits::
-000159c0: 4c68 7350 726f 6772 6573 733b 0a20 2020  LhsProgress;.   
-000159d0: 2020 2020 2020 2020 2020 2062 6c41 202b             blA +
-000159e0: 3d20 7370 6b3b 0a20 2020 2020 2020 2020  = spk;.         
-000159f0: 2020 207d 0a20 2020 2020 2020 2020 2020     }.           
-00015a00: 2069 6628 5377 6170 7065 6454 7261 6974   if(SwappedTrait
-00015a10: 733a 3a4c 6873 5072 6f67 7265 7373 3d3d  s::LhsProgress==
-00015a20: 3829 0a20 2020 2020 2020 2020 2020 207b  8).            {
-00015a30: 0a20 2020 2020 2020 2020 2020 2020 202f  .              /
-00015a40: 2f20 5370 6563 6961 6c20 6361 7365 2077  / Special case w
-00015a50: 6865 7265 2077 6520 6861 7665 2074 6f20  here we have to 
-00015a60: 6669 7273 7420 7265 6475 6365 2074 6865  first reduce the
-00015a70: 2061 6363 756d 756c 6174 696f 6e20 7265   accumulation re
-00015a80: 6769 7374 6572 2043 300a 2020 2020 2020  gister C0.      
-00015a90: 2020 2020 2020 2020 7479 7065 6465 6620          typedef 
-00015aa0: 7479 7065 6e61 6d65 2063 6f6e 6469 7469  typename conditi
-00015ab0: 6f6e 616c 3c53 7761 7070 6564 5472 6169  onal<SwappedTrai
-00015ac0: 7473 3a3a 4c68 7350 726f 6772 6573 733e  ts::LhsProgress>
-00015ad0: 3d38 2c74 7970 656e 616d 6520 756e 7061  =8,typename unpa
-00015ae0: 636b 6574 5f74 7261 6974 733c 5352 6573  cket_traits<SRes
-00015af0: 5061 636b 6574 3e3a 3a68 616c 662c 5352  Packet>::half,SR
-00015b00: 6573 5061 636b 6574 3e3a 3a74 7970 6520  esPacket>::type 
-00015b10: 5352 6573 5061 636b 6574 4861 6c66 3b0a  SResPacketHalf;.
-00015b20: 2020 2020 2020 2020 2020 2020 2020 7479                ty
-00015b30: 7065 6465 6620 7479 7065 6e61 6d65 2063  pedef typename c
-00015b40: 6f6e 6469 7469 6f6e 616c 3c53 7761 7070  onditional<Swapp
-00015b50: 6564 5472 6169 7473 3a3a 4c68 7350 726f  edTraits::LhsPro
-00015b60: 6772 6573 733e 3d38 2c74 7970 656e 616d  gress>=8,typenam
-00015b70: 6520 756e 7061 636b 6574 5f74 7261 6974  e unpacket_trait
-00015b80: 733c 534c 6873 5061 636b 6574 3e3a 3a68  s<SLhsPacket>::h
-00015b90: 616c 662c 534c 6873 5061 636b 6574 3e3a  alf,SLhsPacket>:
-00015ba0: 3a74 7970 6520 534c 6873 5061 636b 6574  :type SLhsPacket
-00015bb0: 4861 6c66 3b0a 2020 2020 2020 2020 2020  Half;.          
-00015bc0: 2020 2020 7479 7065 6465 6620 7479 7065      typedef type
-00015bd0: 6e61 6d65 2063 6f6e 6469 7469 6f6e 616c  name conditional
-00015be0: 3c53 7761 7070 6564 5472 6169 7473 3a3a  <SwappedTraits::
-00015bf0: 4c68 7350 726f 6772 6573 733e 3d38 2c74  LhsProgress>=8,t
-00015c00: 7970 656e 616d 6520 756e 7061 636b 6574  ypename unpacket
-00015c10: 5f74 7261 6974 733c 5352 6873 5061 636b  _traits<SRhsPack
-00015c20: 6574 3e3a 3a68 616c 662c 5352 6873 5061  et>::half,SRhsPa
-00015c30: 636b 6574 3e3a 3a74 7970 6520 5352 6873  cket>::type SRhs
-00015c40: 5061 636b 6574 4861 6c66 3b0a 2020 2020  PacketHalf;.    
-00015c50: 2020 2020 2020 2020 2020 7479 7065 6465            typede
-00015c60: 6620 7479 7065 6e61 6d65 2063 6f6e 6469  f typename condi
-00015c70: 7469 6f6e 616c 3c53 7761 7070 6564 5472  tional<SwappedTr
-00015c80: 6169 7473 3a3a 4c68 7350 726f 6772 6573  aits::LhsProgres
-00015c90: 733e 3d38 2c74 7970 656e 616d 6520 756e  s>=8,typename un
-00015ca0: 7061 636b 6574 5f74 7261 6974 733c 5341  packet_traits<SA
-00015cb0: 6363 5061 636b 6574 3e3a 3a68 616c 662c  ccPacket>::half,
-00015cc0: 5341 6363 5061 636b 6574 3e3a 3a74 7970  SAccPacket>::typ
-00015cd0: 6520 5341 6363 5061 636b 6574 4861 6c66  e SAccPacketHalf
-00015ce0: 3b0a 0a20 2020 2020 2020 2020 2020 2020  ;..             
-00015cf0: 2053 5265 7350 6163 6b65 7448 616c 6620   SResPacketHalf 
-00015d00: 5220 3d20 7265 732e 7465 6d70 6c61 7465  R = res.template
-00015d10: 2067 6174 6865 7250 6163 6b65 743c 5352   gatherPacket<SR
-00015d20: 6573 5061 636b 6574 4861 6c66 3e28 692c  esPacketHalf>(i,
-00015d30: 206a 3229 3b0a 2020 2020 2020 2020 2020   j2);.          
-00015d40: 2020 2020 5352 6573 5061 636b 6574 4861      SResPacketHa
-00015d50: 6c66 2061 6c70 6861 7620 3d20 7073 6574  lf alphav = pset
-00015d60: 313c 5352 6573 5061 636b 6574 4861 6c66  1<SResPacketHalf
-00015d70: 3e28 616c 7068 6129 3b0a 0a20 2020 2020  >(alpha);..     
-00015d80: 2020 2020 2020 2020 2069 6628 6465 7074           if(dept
-00015d90: 682d 656e 646b 3e30 290a 2020 2020 2020  h-endk>0).      
-00015da0: 2020 2020 2020 2020 7b0a 2020 2020 2020          {.      
-00015db0: 2020 2020 2020 2020 2020 2f2f 2057 6520            // We 
-00015dc0: 6861 7665 2074 6f20 6861 6e64 6c65 2074  have to handle t
-00015dd0: 6865 206c 6173 7420 726f 7720 6f66 2074  he last row of t
-00015de0: 6865 2072 6873 2077 6869 6368 2063 6f72  he rhs which cor
-00015df0: 7265 7370 6f6e 6473 2074 6f20 6120 6861  responds to a ha
-00015e00: 6c66 2d70 6163 6b65 740a 2020 2020 2020  lf-packet.      
-00015e10: 2020 2020 2020 2020 2020 534c 6873 5061            SLhsPa
-00015e20: 636b 6574 4861 6c66 2061 303b 0a20 2020  cketHalf a0;.   
-00015e30: 2020 2020 2020 2020 2020 2020 2053 5268               SRh
-00015e40: 7350 6163 6b65 7448 616c 6620 6230 3b0a  sPacketHalf b0;.
-00015e50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00015e60: 7374 7261 6974 732e 6c6f 6164 4c68 7355  straits.loadLhsU
-00015e70: 6e61 6c69 676e 6564 2862 6c42 2c20 6130  naligned(blB, a0
-00015e80: 293b 0a20 2020 2020 2020 2020 2020 2020  );.             
-00015e90: 2020 2073 7472 6169 7473 2e6c 6f61 6452     straits.loadR
-00015ea0: 6873 2862 6c41 2c20 6230 293b 0a20 2020  hs(blA, b0);.   
-00015eb0: 2020 2020 2020 2020 2020 2020 2053 4163               SAc
-00015ec0: 6350 6163 6b65 7448 616c 6620 6330 203d  cPacketHalf c0 =
-00015ed0: 2070 7265 6475 785f 6861 6c66 5f64 6f77   predux_half_dow
-00015ee0: 746f 3428 4330 293b 0a20 2020 2020 2020  to4(C0);.       
-00015ef0: 2020 2020 2020 2020 2073 7472 6169 7473           straits
-00015f00: 2e6d 6164 6428 6130 2c62 302c 6330 2c62  .madd(a0,b0,c0,b
-00015f10: 302c 2066 6978 3c30 3e29 3b0a 2020 2020  0, fix<0>);.    
-00015f20: 2020 2020 2020 2020 2020 2020 7374 7261              stra
-00015f30: 6974 732e 6163 6328 6330 2c20 616c 7068  its.acc(c0, alph
-00015f40: 6176 2c20 5229 3b0a 2020 2020 2020 2020  av, R);.        
-00015f50: 2020 2020 2020 7d0a 2020 2020 2020 2020        }.        
-00015f60: 2020 2020 2020 656c 7365 0a20 2020 2020        else.     
-00015f70: 2020 2020 2020 2020 207b 0a20 2020 2020           {.     
-00015f80: 2020 2020 2020 2020 2020 2073 7472 6169             strai
-00015f90: 7473 2e61 6363 2870 7265 6475 785f 6861  ts.acc(predux_ha
-00015fa0: 6c66 5f64 6f77 746f 3428 4330 292c 2061  lf_dowto4(C0), a
-00015fb0: 6c70 6861 762c 2052 293b 0a20 2020 2020  lphav, R);.     
-00015fc0: 2020 2020 2020 2020 207d 0a20 2020 2020           }.     
-00015fd0: 2020 2020 2020 2020 2072 6573 2e73 6361           res.sca
-00015fe0: 7474 6572 5061 636b 6574 2869 2c20 6a32  tterPacket(i, j2
-00015ff0: 2c20 5229 3b0a 2020 2020 2020 2020 2020  , R);.          
-00016000: 2020 7d0a 2020 2020 2020 2020 2020 2020    }.            
-00016010: 656c 7365 2069 6620 2853 7761 7070 6564  else if (Swapped
-00016020: 5472 6169 7473 3a3a 4c68 7350 726f 6772  Traits::LhsProgr
-00016030: 6573 733d 3d31 3629 0a20 2020 2020 2020  ess==16).       
-00016040: 2020 2020 207b 0a20 2020 2020 2020 2020       {.         
-00016050: 2020 2020 202f 2f20 5370 6563 6961 6c20       // Special 
-00016060: 6361 7365 2077 6865 7265 2077 6520 6861  case where we ha
-00016070: 7665 2074 6f20 6669 7273 7420 7265 6475  ve to first redu
-00016080: 6365 2074 6865 0a20 2020 2020 2020 2020  ce the.         
-00016090: 2020 2020 202f 2f20 6163 6375 6d75 6c61       // accumula
-000160a0: 7469 6f6e 2072 6567 6973 7465 7220 4330  tion register C0
-000160b0: 2e20 5765 2073 7065 6369 616c 697a 6520  . We specialize 
-000160c0: 7468 6520 626c 6f63 6b20 696e 0a20 2020  the block in.   
-000160d0: 2020 2020 2020 2020 2020 202f 2f20 7465             // te
-000160e0: 6d70 6c61 7465 2066 6f72 6d2c 2073 6f20  mplate form, so 
-000160f0: 7468 6174 204c 6873 5072 6f67 7265 7373  that LhsProgress
-00016100: 203c 2031 3620 7061 7468 7320 646f 6e27   < 16 paths don'
-00016110: 740a 2020 2020 2020 2020 2020 2020 2020  t.              
-00016120: 2f2f 2066 6169 6c20 746f 2063 6f6d 7069  // fail to compi
-00016130: 6c65 0a20 2020 2020 2020 2020 2020 2020  le.             
-00016140: 206c 6173 745f 726f 775f 7072 6f63 6573   last_row_proces
-00016150: 735f 3136 5f70 6163 6b65 7473 3c4c 6873  s_16_packets<Lhs
-00016160: 5363 616c 6172 2c20 5268 7353 6361 6c61  Scalar, RhsScala
-00016170: 722c 2049 6e64 6578 2c20 4461 7461 4d61  r, Index, DataMa
-00016180: 7070 6572 2c20 6d72 2c20 6e72 2c20 436f  pper, mr, nr, Co
-00016190: 6e6a 7567 6174 654c 6873 2c20 436f 6e6a  njugateLhs, Conj
-000161a0: 7567 6174 6552 6873 3e20 703b 0a09 2020  ugateRhs> p;..  
-000161b0: 2020 2020 2020 2020 2020 7028 7265 732c            p(res,
-000161c0: 2073 7472 6169 7473 2c20 626c 412c 2062   straits, blA, b
-000161d0: 6c42 2c20 6465 7074 682c 2065 6e64 6b2c  lB, depth, endk,
-000161e0: 2069 2c20 6a32 2c61 6c70 6861 2c20 4330   i, j2,alpha, C0
-000161f0: 293b 0a20 2020 2020 2020 2020 2020 207d  );.            }
-00016200: 0a20 2020 2020 2020 2020 2020 2065 6c73  .            els
-00016210: 650a 2020 2020 2020 2020 2020 2020 7b0a  e.            {.
-00016220: 2020 2020 2020 2020 2020 2020 2020 5352                SR
-00016230: 6573 5061 636b 6574 2052 203d 2072 6573  esPacket R = res
-00016240: 2e74 656d 706c 6174 6520 6761 7468 6572  .template gather
-00016250: 5061 636b 6574 3c53 5265 7350 6163 6b65  Packet<SResPacke
-00016260: 743e 2869 2c20 6a32 293b 0a20 2020 2020  t>(i, j2);.     
-00016270: 2020 2020 2020 2020 2053 5265 7350 6163           SResPac
-00016280: 6b65 7420 616c 7068 6176 203d 2070 7365  ket alphav = pse
-00016290: 7431 3c53 5265 7350 6163 6b65 743e 2861  t1<SResPacket>(a
-000162a0: 6c70 6861 293b 0a20 2020 2020 2020 2020  lpha);.         
-000162b0: 2020 2020 2073 7472 6169 7473 2e61 6363       straits.acc
-000162c0: 2843 302c 2061 6c70 6861 762c 2052 293b  (C0, alphav, R);
-000162d0: 0a20 2020 2020 2020 2020 2020 2020 2072  .              r
-000162e0: 6573 2e73 6361 7474 6572 5061 636b 6574  es.scatterPacket
-000162f0: 2869 2c20 6a32 2c20 5229 3b0a 2020 2020  (i, j2, R);.    
-00016300: 2020 2020 2020 2020 7d0a 2020 2020 2020          }.      
-00016310: 2020 2020 7d0a 2020 2020 2020 2020 2020      }.          
-00016320: 656c 7365 202f 2f20 7363 616c 6172 2070  else // scalar p
-00016330: 6174 680a 2020 2020 2020 2020 2020 7b0a  ath.          {.
-00016340: 2020 2020 2020 2020 2020 2020 2f2f 2067              // g
-00016350: 6574 2061 2031 2078 2034 2072 6573 2062  et a 1 x 4 res b
-00016360: 6c6f 636b 2061 7320 7265 6769 7374 6572  lock as register
-00016370: 730a 2020 2020 2020 2020 2020 2020 5265  s.            Re
-00016380: 7353 6361 6c61 7220 4330 2830 292c 2043  sScalar C0(0), C
-00016390: 3128 3029 2c20 4332 2830 292c 2043 3328  1(0), C2(0), C3(
-000163a0: 3029 3b0a 0a20 2020 2020 2020 2020 2020  0);..           
-000163b0: 2066 6f72 2849 6e64 6578 206b 3d30 3b20   for(Index k=0; 
-000163c0: 6b3c 6465 7074 683b 206b 2b2b 290a 2020  k<depth; k++).  
-000163d0: 2020 2020 2020 2020 2020 7b0a 2020 2020            {.    
-000163e0: 2020 2020 2020 2020 2020 4c68 7353 6361            LhsSca
-000163f0: 6c61 7220 4130 3b0a 2020 2020 2020 2020  lar A0;.        
-00016400: 2020 2020 2020 5268 7353 6361 6c61 7220        RhsScalar 
-00016410: 425f 302c 2042 5f31 3b0a 0a20 2020 2020  B_0, B_1;..     
-00016420: 2020 2020 2020 2020 2041 3020 3d20 626c           A0 = bl
-00016430: 415b 6b5d 3b0a 0a20 2020 2020 2020 2020  A[k];..         
-00016440: 2020 2020 2042 5f30 203d 2062 6c42 5b30       B_0 = blB[0
-00016450: 5d3b 0a20 2020 2020 2020 2020 2020 2020  ];.             
-00016460: 2042 5f31 203d 2062 6c42 5b31 5d3b 0a20   B_1 = blB[1];. 
-00016470: 2020 2020 2020 2020 2020 2020 2043 4a4d               CJM
-00016480: 4144 4428 636a 2c41 302c 425f 302c 4330  ADD(cj,A0,B_0,C0
-00016490: 2c20 2042 5f30 293b 0a20 2020 2020 2020  ,  B_0);.       
-000164a0: 2020 2020 2020 2043 4a4d 4144 4428 636a         CJMADD(cj
-000164b0: 2c41 302c 425f 312c 4331 2c20 2042 5f31  ,A0,B_1,C1,  B_1
-000164c0: 293b 0a20 2020 2020 2020 2020 2020 2020  );.             
-000164d0: 200a 2020 2020 2020 2020 2020 2020 2020   .              
-000164e0: 425f 3020 3d20 626c 425b 325d 3b0a 2020  B_0 = blB[2];.  
-000164f0: 2020 2020 2020 2020 2020 2020 425f 3120              B_1 
-00016500: 3d20 626c 425b 335d 3b0a 2020 2020 2020  = blB[3];.      
-00016510: 2020 2020 2020 2020 434a 4d41 4444 2863          CJMADD(c
-00016520: 6a2c 4130 2c42 5f30 2c43 322c 2020 425f  j,A0,B_0,C2,  B_
-00016530: 3029 3b0a 2020 2020 2020 2020 2020 2020  0);.            
-00016540: 2020 434a 4d41 4444 2863 6a2c 4130 2c42    CJMADD(cj,A0,B
-00016550: 5f31 2c43 332c 2020 425f 3129 3b0a 2020  _1,C3,  B_1);.  
-00016560: 2020 2020 2020 2020 2020 2020 0a20 2020              .   
-00016570: 2020 2020 2020 2020 2020 2062 6c42 202b             blB +
-00016580: 3d20 343b 0a20 2020 2020 2020 2020 2020  = 4;.           
-00016590: 207d 0a20 2020 2020 2020 2020 2020 2072   }.            r
-000165a0: 6573 2869 2c20 6a32 202b 2030 2920 2b3d  es(i, j2 + 0) +=
-000165b0: 2061 6c70 6861 202a 2043 303b 0a20 2020   alpha * C0;.   
-000165c0: 2020 2020 2020 2020 2072 6573 2869 2c20           res(i, 
-000165d0: 6a32 202b 2031 2920 2b3d 2061 6c70 6861  j2 + 1) += alpha
-000165e0: 202a 2043 313b 0a20 2020 2020 2020 2020   * C1;.         
-000165f0: 2020 2072 6573 2869 2c20 6a32 202b 2032     res(i, j2 + 2
-00016600: 2920 2b3d 2061 6c70 6861 202a 2043 323b  ) += alpha * C2;
-00016610: 0a20 2020 2020 2020 2020 2020 2072 6573  .            res
-00016620: 2869 2c20 6a32 202b 2033 2920 2b3d 2061  (i, j2 + 3) += a
-00016630: 6c70 6861 202a 2043 333b 0a20 2020 2020  lpha * C3;.     
-00016640: 2020 2020 207d 0a20 2020 2020 2020 207d       }.        }
-00016650: 0a20 2020 2020 207d 0a20 2020 2020 202f  .      }.      /
-00016660: 2f20 7265 6d61 696e 696e 6720 636f 6c75  / remaining colu
-00016670: 6d6e 730a 2020 2020 2020 666f 7228 496e  mns.      for(In
-00016680: 6465 7820 6a32 3d70 6163 6b65 745f 636f  dex j2=packet_co
-00016690: 6c73 343b 206a 323c 636f 6c73 3b20 6a32  ls4; j2<cols; j2
-000166a0: 2b2b 290a 2020 2020 2020 7b0a 2020 2020  ++).      {.    
-000166b0: 2020 2020 2f2f 206c 6f6f 7020 6f6e 2065      // loop on e
-000166c0: 6163 6820 726f 7720 6f66 2074 6865 206c  ach row of the l
-000166d0: 6873 2028 312a 4c68 7350 726f 6772 6573  hs (1*LhsProgres
-000166e0: 7320 7820 6465 7074 6829 0a20 2020 2020  s x depth).     
-000166f0: 2020 2066 6f72 2849 6e64 6578 2069 3d70     for(Index i=p
-00016700: 6565 6c65 645f 6d63 5f71 7561 7274 6572  eeled_mc_quarter
-00016710: 3b20 693c 726f 7773 3b20 692b 3d31 290a  ; i<rows; i+=1).
-00016720: 2020 2020 2020 2020 7b0a 2020 2020 2020          {.      
-00016730: 2020 2020 636f 6e73 7420 4c68 7353 6361      const LhsSca
-00016740: 6c61 722a 2062 6c41 203d 2026 626c 6f63  lar* blA = &bloc
-00016750: 6b41 5b69 2a73 7472 6964 6541 2b6f 6666  kA[i*strideA+off
-00016760: 7365 7441 5d3b 0a20 2020 2020 2020 2020  setA];.         
-00016770: 2070 7265 6665 7463 6828 2662 6c41 5b30   prefetch(&blA[0
-00016780: 5d29 3b0a 2020 2020 2020 2020 2020 2f2f  ]);.          //
-00016790: 2067 6574 7320 6120 3120 7820 3120 7265   gets a 1 x 1 re
-000167a0: 7320 626c 6f63 6b20 6173 2072 6567 6973  s block as regis
-000167b0: 7465 7273 0a20 2020 2020 2020 2020 2052  ters.          R
-000167c0: 6573 5363 616c 6172 2043 3028 3029 3b0a  esScalar C0(0);.
-000167d0: 2020 2020 2020 2020 2020 636f 6e73 7420            const 
-000167e0: 5268 7353 6361 6c61 722a 2062 6c42 203d  RhsScalar* blB =
-000167f0: 2026 626c 6f63 6b42 5b6a 322a 7374 7269   &blockB[j2*stri
-00016800: 6465 422b 6f66 6673 6574 425d 3b0a 2020  deB+offsetB];.  
-00016810: 2020 2020 2020 2020 666f 7228 496e 6465          for(Inde
-00016820: 7820 6b3d 303b 206b 3c64 6570 7468 3b20  x k=0; k<depth; 
-00016830: 6b2b 2b29 0a20 2020 2020 2020 2020 207b  k++).          {
-00016840: 0a20 2020 2020 2020 2020 2020 204c 6873  .            Lhs
-00016850: 5363 616c 6172 2041 3020 3d20 626c 415b  Scalar A0 = blA[
-00016860: 6b5d 3b0a 2020 2020 2020 2020 2020 2020  k];.            
-00016870: 5268 7353 6361 6c61 7220 425f 3020 3d20  RhsScalar B_0 = 
-00016880: 626c 425b 6b5d 3b0a 2020 2020 2020 2020  blB[k];.        
-00016890: 2020 2020 434a 4d41 4444 2863 6a2c 2041      CJMADD(cj, A
-000168a0: 302c 2042 5f30 2c20 4330 2c20 425f 3029  0, B_0, C0, B_0)
-000168b0: 3b0a 2020 2020 2020 2020 2020 7d0a 2020  ;.          }.  
-000168c0: 2020 2020 2020 2020 7265 7328 692c 206a          res(i, j
-000168d0: 3229 202b 3d20 616c 7068 6120 2a20 4330  2) += alpha * C0
-000168e0: 3b0a 2020 2020 2020 2020 7d0a 2020 2020  ;.        }.    
-000168f0: 2020 7d0a 2020 2020 7d0a 2020 7d0a 0a0a    }.    }.  }...
-00016900: 2375 6e64 6566 2043 4a4d 4144 440a 0a2f  #undef CJMADD../
-00016910: 2f20 7061 636b 2061 2062 6c6f 636b 206f  / pack a block o
-00016920: 6620 7468 6520 6c68 730a 2f2f 2054 6865  f the lhs.// The
-00016930: 2074 7261 7665 7273 616c 2069 7320 6173   traversal is as
-00016940: 2066 6f6c 6c6f 7720 286d 723d 3d34 293a   follow (mr==4):
-00016950: 0a2f 2f20 2020 3020 2034 2020 3820 3132  .//   0  4  8 12
-00016960: 202e 2e2e 0a2f 2f20 2020 3120 2035 2020   ....//   1  5  
-00016970: 3920 3133 202e 2e2e 0a2f 2f20 2020 3220  9 13 ....//   2 
-00016980: 2036 2031 3020 3134 202e 2e2e 0a2f 2f20   6 10 14 ....// 
-00016990: 2020 3320 2037 2031 3120 3135 202e 2e2e    3  7 11 15 ...
-000169a0: 0a2f 2f0a 2f2f 2020 3136 2032 3020 3234  .//.//  16 20 24
-000169b0: 2032 3820 2e2e 2e0a 2f2f 2020 3137 2032   28 ....//  17 2
-000169c0: 3120 3235 2032 3920 2e2e 2e0a 2f2f 2020  1 25 29 ....//  
-000169d0: 3138 2032 3220 3236 2033 3020 2e2e 2e0a  18 22 26 30 ....
-000169e0: 2f2f 2020 3139 2032 3320 3237 2033 3120  //  19 23 27 31 
-000169f0: 2e2e 2e0a 2f2f 0a2f 2f20 2033 3220 3333  ....//.//  32 33
-00016a00: 2033 3420 3335 202e 2e2e 0a2f 2f20 2033   34 35 ....//  3
-00016a10: 3620 3336 2033 3820 3339 202e 2e2e 0a74  6 36 38 39 ....t
-00016a20: 656d 706c 6174 653c 7479 7065 6e61 6d65  emplate<typename
-00016a30: 2053 6361 6c61 722c 2074 7970 656e 616d   Scalar, typenam
-00016a40: 6520 496e 6465 782c 2074 7970 656e 616d  e Index, typenam
-00016a50: 6520 4461 7461 4d61 7070 6572 2c20 696e  e DataMapper, in
-00016a60: 7420 5061 636b 312c 2069 6e74 2050 6163  t Pack1, int Pac
-00016a70: 6b32 2c20 7479 7065 6e61 6d65 2050 6163  k2, typename Pac
-00016a80: 6b65 742c 2062 6f6f 6c20 436f 6e6a 7567  ket, bool Conjug
-00016a90: 6174 652c 2062 6f6f 6c20 5061 6e65 6c4d  ate, bool PanelM
-00016aa0: 6f64 653e 0a73 7472 7563 7420 6765 6d6d  ode>.struct gemm
-00016ab0: 5f70 6163 6b5f 6c68 733c 5363 616c 6172  _pack_lhs<Scalar
-00016ac0: 2c20 496e 6465 782c 2044 6174 614d 6170  , Index, DataMap
-00016ad0: 7065 722c 2050 6163 6b31 2c20 5061 636b  per, Pack1, Pack
-00016ae0: 322c 2050 6163 6b65 742c 2043 6f6c 4d61  2, Packet, ColMa
-00016af0: 6a6f 722c 2043 6f6e 6a75 6761 7465 2c20  jor, Conjugate, 
-00016b00: 5061 6e65 6c4d 6f64 653e 0a7b 0a20 2074  PanelMode>.{.  t
-00016b10: 7970 6564 6566 2074 7970 656e 616d 6520  ypedef typename 
-00016b20: 4461 7461 4d61 7070 6572 3a3a 4c69 6e65  DataMapper::Line
-00016b30: 6172 4d61 7070 6572 204c 696e 6561 724d  arMapper LinearM
-00016b40: 6170 7065 723b 0a20 2045 4947 454e 5f44  apper;.  EIGEN_D
-00016b50: 4f4e 545f 494e 4c49 4e45 2076 6f69 6420  ONT_INLINE void 
-00016b60: 6f70 6572 6174 6f72 2829 2853 6361 6c61  operator()(Scala
-00016b70: 722a 2062 6c6f 636b 412c 2063 6f6e 7374  r* blockA, const
-00016b80: 2044 6174 614d 6170 7065 7226 206c 6873   DataMapper& lhs
-00016b90: 2c20 496e 6465 7820 6465 7074 682c 2049  , Index depth, I
-00016ba0: 6e64 6578 2072 6f77 732c 2049 6e64 6578  ndex rows, Index
-00016bb0: 2073 7472 6964 653d 302c 2049 6e64 6578   stride=0, Index
-00016bc0: 206f 6666 7365 743d 3029 3b0a 7d3b 0a0a   offset=0);.};..
-00016bd0: 7465 6d70 6c61 7465 3c74 7970 656e 616d  template<typenam
-00016be0: 6520 5363 616c 6172 2c20 7479 7065 6e61  e Scalar, typena
-00016bf0: 6d65 2049 6e64 6578 2c20 7479 7065 6e61  me Index, typena
-00016c00: 6d65 2044 6174 614d 6170 7065 722c 2069  me DataMapper, i
-00016c10: 6e74 2050 6163 6b31 2c20 696e 7420 5061  nt Pack1, int Pa
-00016c20: 636b 322c 2074 7970 656e 616d 6520 5061  ck2, typename Pa
-00016c30: 636b 6574 2c20 626f 6f6c 2043 6f6e 6a75  cket, bool Conju
-00016c40: 6761 7465 2c20 626f 6f6c 2050 616e 656c  gate, bool Panel
-00016c50: 4d6f 6465 3e0a 4549 4745 4e5f 444f 4e54  Mode>.EIGEN_DONT
-00016c60: 5f49 4e4c 494e 4520 766f 6964 2067 656d  _INLINE void gem
-00016c70: 6d5f 7061 636b 5f6c 6873 3c53 6361 6c61  m_pack_lhs<Scala
-00016c80: 722c 2049 6e64 6578 2c20 4461 7461 4d61  r, Index, DataMa
-00016c90: 7070 6572 2c20 5061 636b 312c 2050 6163  pper, Pack1, Pac
-00016ca0: 6b32 2c20 5061 636b 6574 2c20 436f 6c4d  k2, Packet, ColM
-00016cb0: 616a 6f72 2c20 436f 6e6a 7567 6174 652c  ajor, Conjugate,
-00016cc0: 2050 616e 656c 4d6f 6465 3e0a 2020 3a3a   PanelMode>.  ::
-00016cd0: 6f70 6572 6174 6f72 2829 2853 6361 6c61  operator()(Scala
-00016ce0: 722a 2062 6c6f 636b 412c 2063 6f6e 7374  r* blockA, const
-00016cf0: 2044 6174 614d 6170 7065 7226 206c 6873   DataMapper& lhs
-00016d00: 2c20 496e 6465 7820 6465 7074 682c 2049  , Index depth, I
-00016d10: 6e64 6578 2072 6f77 732c 2049 6e64 6578  ndex rows, Index
-00016d20: 2073 7472 6964 652c 2049 6e64 6578 206f   stride, Index o
-00016d30: 6666 7365 7429 0a7b 0a20 2074 7970 6564  ffset).{.  typed
-00016d40: 6566 2074 7970 656e 616d 6520 756e 7061  ef typename unpa
+00010350: 5c0a 2020 2020 2020 2020 2020 2020 646f  \.            do
+00010360: 207b 2020 2020 2020 2020 2020 2020 2020   {              
+00010370: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010380: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010390: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000103a0: 2020 2020 5c0a 2020 2020 2020 2020 2020      \.          
+000103b0: 2020 2020 4549 4745 4e5f 4153 4d5f 434f      EIGEN_ASM_CO
+000103c0: 4d4d 454e 5428 2262 6567 696e 2073 7465  MMENT("begin ste
+000103d0: 7020 6f66 2067 6562 7020 6d69 6372 6f20  p of gebp micro 
+000103e0: 6b65 726e 656c 2033 7058 3122 293b 2020  kernel 3pX1");  
+000103f0: 2020 2020 2020 2020 5c0a 2020 2020 2020          \.      
+00010400: 2020 2020 2020 2020 4549 4745 4e5f 4153          EIGEN_AS
+00010410: 4d5f 434f 4d4d 454e 5428 224e 6f74 653a  M_COMMENT("Note:
+00010420: 2074 6865 7365 2061 736d 2063 6f6d 6d65   these asm comme
+00010430: 6e74 7320 776f 726b 2061 726f 756e 6420  nts work around 
+00010440: 6275 6720 3933 3521 2229 3b20 5c0a 2020  bug 935!"); \.  
+00010450: 2020 2020 2020 2020 2020 2020 7472 6169              trai
+00010460: 7473 2e6c 6f61 644c 6873 2826 626c 415b  ts.loadLhs(&blA[
+00010470: 2830 202b 2033 202a 204b 2920 2a20 4c68  (0 + 3 * K) * Lh
+00010480: 7350 726f 6772 6573 735d 2c20 4130 293b  sProgress], A0);
+00010490: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000104a0: 5c0a 2020 2020 2020 2020 2020 2020 2020  \.              
+000104b0: 7472 6169 7473 2e6c 6f61 644c 6873 2826  traits.loadLhs(&
+000104c0: 626c 415b 2831 202b 2033 202a 204b 2920  blA[(1 + 3 * K) 
+000104d0: 2a20 4c68 7350 726f 6772 6573 735d 2c20  * LhsProgress], 
+000104e0: 4131 293b 2020 2020 2020 2020 2020 2020  A1);            
+000104f0: 2020 2020 5c0a 2020 2020 2020 2020 2020      \.          
+00010500: 2020 2020 7472 6169 7473 2e6c 6f61 644c      traits.loadL
+00010510: 6873 2826 626c 415b 2832 202b 2033 202a  hs(&blA[(2 + 3 *
+00010520: 204b 2920 2a20 4c68 7350 726f 6772 6573   K) * LhsProgres
+00010530: 735d 2c20 4132 293b 2020 2020 2020 2020  s], A2);        
+00010540: 2020 2020 2020 2020 5c0a 2020 2020 2020          \.      
+00010550: 2020 2020 2020 2020 7472 6169 7473 2e6c          traits.l
+00010560: 6f61 6452 6873 2826 626c 425b 2830 202b  oadRhs(&blB[(0 +
+00010570: 204b 2920 2a20 5268 7350 726f 6772 6573   K) * RhsProgres
+00010580: 735d 2c20 425f 3029 3b20 2020 2020 2020  s], B_0);       
+00010590: 2020 2020 2020 2020 2020 2020 5c0a 2020              \.  
+000105a0: 2020 2020 2020 2020 2020 2020 7472 6169              trai
+000105b0: 7473 2e6d 6164 6428 4130 2c20 425f 302c  ts.madd(A0, B_0,
+000105c0: 2043 302c 2042 5f30 2c20 6669 783c 303e   C0, B_0, fix<0>
+000105d0: 293b 2020 2020 2020 2020 2020 2020 2020  );              
+000105e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000105f0: 5c0a 2020 2020 2020 2020 2020 2020 2020  \.              
+00010600: 7472 6169 7473 2e6d 6164 6428 4131 2c20  traits.madd(A1, 
+00010610: 425f 302c 2043 342c 2042 5f30 2c20 6669  B_0, C4, B_0, fi
+00010620: 783c 303e 293b 2020 2020 2020 2020 2020  x<0>);          
+00010630: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010640: 2020 2020 5c0a 2020 2020 2020 2020 2020      \.          
+00010650: 2020 2020 7472 6169 7473 2e6d 6164 6428      traits.madd(
+00010660: 4132 2c20 425f 302c 2043 382c 2042 5f30  A2, B_0, C8, B_0
+00010670: 2c20 6669 783c 303e 293b 2020 2020 2020  , fix<0>);      
+00010680: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010690: 2020 2020 2020 2020 5c0a 2020 2020 2020          \.      
+000106a0: 2020 2020 2020 2020 4549 4745 4e5f 4153          EIGEN_AS
+000106b0: 4d5f 434f 4d4d 454e 5428 2265 6e64 2073  M_COMMENT("end s
+000106c0: 7465 7020 6f66 2067 6562 7020 6d69 6372  tep of gebp micr
+000106d0: 6f20 6b65 726e 656c 2033 7058 3122 293b  o kernel 3pX1");
+000106e0: 2020 2020 2020 2020 2020 2020 5c0a 2020              \.  
+000106f0: 2020 2020 2020 2020 2020 7d20 7768 696c            } whil
+00010700: 6520 2866 616c 7365 290a 0a20 2020 2020  e (false)..     
+00010710: 2020 2020 2020 2045 4947 454e 5f47 4542         EIGEN_GEB
+00010720: 4750 5f4f 4e45 5354 4550 2830 293b 0a20  GP_ONESTEP(0);. 
+00010730: 2020 2020 2020 2020 2020 2045 4947 454e             EIGEN
+00010740: 5f47 4542 4750 5f4f 4e45 5354 4550 2831  _GEBGP_ONESTEP(1
+00010750: 293b 0a20 2020 2020 2020 2020 2020 2045  );.            E
+00010760: 4947 454e 5f47 4542 4750 5f4f 4e45 5354  IGEN_GEBGP_ONEST
+00010770: 4550 2832 293b 0a20 2020 2020 2020 2020  EP(2);.         
+00010780: 2020 2045 4947 454e 5f47 4542 4750 5f4f     EIGEN_GEBGP_O
+00010790: 4e45 5354 4550 2833 293b 0a20 2020 2020  NESTEP(3);.     
+000107a0: 2020 2020 2020 2045 4947 454e 5f47 4542         EIGEN_GEB
+000107b0: 4750 5f4f 4e45 5354 4550 2834 293b 0a20  GP_ONESTEP(4);. 
+000107c0: 2020 2020 2020 2020 2020 2045 4947 454e             EIGEN
+000107d0: 5f47 4542 4750 5f4f 4e45 5354 4550 2835  _GEBGP_ONESTEP(5
+000107e0: 293b 0a20 2020 2020 2020 2020 2020 2045  );.            E
+000107f0: 4947 454e 5f47 4542 4750 5f4f 4e45 5354  IGEN_GEBGP_ONEST
+00010800: 4550 2836 293b 0a20 2020 2020 2020 2020  EP(6);.         
+00010810: 2020 2045 4947 454e 5f47 4542 4750 5f4f     EIGEN_GEBGP_O
+00010820: 4e45 5354 4550 2837 293b 0a0a 2020 2020  NESTEP(7);..    
+00010830: 2020 2020 2020 2020 626c 4220 2b3d 2069          blB += i
+00010840: 6e74 2870 6b29 202a 2069 6e74 2852 6873  nt(pk) * int(Rhs
+00010850: 5072 6f67 7265 7373 293b 0a20 2020 2020  Progress);.     
+00010860: 2020 2020 2020 2062 6c41 202b 3d20 696e         blA += in
+00010870: 7428 706b 2920 2a20 3320 2a20 696e 7428  t(pk) * 3 * int(
+00010880: 5472 6169 7473 3a3a 4c68 7350 726f 6772  Traits::LhsProgr
+00010890: 6573 7329 3b0a 0a20 2020 2020 2020 2020  ess);..         
+000108a0: 2020 2045 4947 454e 5f41 534d 5f43 4f4d     EIGEN_ASM_COM
+000108b0: 4d45 4e54 2822 656e 6420 6765 6270 206d  MENT("end gebp m
+000108c0: 6963 726f 206b 6572 6e65 6c20 3370 5831  icro kernel 3pX1
+000108d0: 2229 3b0a 2020 2020 2020 2020 2020 7d0a  ");.          }.
+000108e0: 0a20 2020 2020 2020 2020 202f 2f20 7072  .          // pr
+000108f0: 6f63 6573 7320 7265 6d61 696e 696e 6720  ocess remaining 
+00010900: 7065 656c 6564 206c 6f6f 700a 2020 2020  peeled loop.    
+00010910: 2020 2020 2020 666f 7228 496e 6465 7820        for(Index 
+00010920: 6b3d 7065 656c 6564 5f6b 633b 206b 3c64  k=peeled_kc; k<d
+00010930: 6570 7468 3b20 6b2b 2b29 0a20 2020 2020  epth; k++).     
+00010940: 2020 2020 207b 0a20 2020 2020 2020 2020       {.         
+00010950: 2020 2052 6873 5061 636b 6574 2042 5f30     RhsPacket B_0
+00010960: 3b0a 2020 2020 2020 2020 2020 2020 4549  ;.            EI
+00010970: 4745 4e5f 4745 4247 505f 4f4e 4553 5445  GEN_GEBGP_ONESTE
+00010980: 5028 3029 3b0a 2020 2020 2020 2020 2020  P(0);.          
+00010990: 2020 626c 4220 2b3d 2052 6873 5072 6f67    blB += RhsProg
+000109a0: 7265 7373 3b0a 2020 2020 2020 2020 2020  ress;.          
+000109b0: 2020 626c 4120 2b3d 2033 2a54 7261 6974    blA += 3*Trait
+000109c0: 733a 3a4c 6873 5072 6f67 7265 7373 3b0a  s::LhsProgress;.
+000109d0: 2020 2020 2020 2020 2020 7d0a 2375 6e64            }.#und
+000109e0: 6566 2045 4947 454e 5f47 4542 4750 5f4f  ef EIGEN_GEBGP_O
+000109f0: 4e45 5354 4550 0a20 2020 2020 2020 2020  NESTEP.         
+00010a00: 2052 6573 5061 636b 6574 2052 302c 2052   ResPacket R0, R
+00010a10: 312c 2052 323b 0a20 2020 2020 2020 2020  1, R2;.         
+00010a20: 2052 6573 5061 636b 6574 2061 6c70 6861   ResPacket alpha
+00010a30: 7620 3d20 7073 6574 313c 5265 7350 6163  v = pset1<ResPac
+00010a40: 6b65 743e 2861 6c70 6861 293b 0a0a 2020  ket>(alpha);..  
+00010a50: 2020 2020 2020 2020 5230 203d 2072 302e          R0 = r0.
+00010a60: 7465 6d70 6c61 7465 206c 6f61 6450 6163  template loadPac
+00010a70: 6b65 743c 5265 7350 6163 6b65 743e 2830  ket<ResPacket>(0
+00010a80: 202a 2054 7261 6974 733a 3a52 6573 5061   * Traits::ResPa
+00010a90: 636b 6574 5369 7a65 293b 0a20 2020 2020  cketSize);.     
+00010aa0: 2020 2020 2052 3120 3d20 7230 2e74 656d       R1 = r0.tem
+00010ab0: 706c 6174 6520 6c6f 6164 5061 636b 6574  plate loadPacket
+00010ac0: 3c52 6573 5061 636b 6574 3e28 3120 2a20  <ResPacket>(1 * 
+00010ad0: 5472 6169 7473 3a3a 5265 7350 6163 6b65  Traits::ResPacke
+00010ae0: 7453 697a 6529 3b0a 2020 2020 2020 2020  tSize);.        
+00010af0: 2020 5232 203d 2072 302e 7465 6d70 6c61    R2 = r0.templa
+00010b00: 7465 206c 6f61 6450 6163 6b65 743c 5265  te loadPacket<Re
+00010b10: 7350 6163 6b65 743e 2832 202a 2054 7261  sPacket>(2 * Tra
+00010b20: 6974 733a 3a52 6573 5061 636b 6574 5369  its::ResPacketSi
+00010b30: 7a65 293b 0a20 2020 2020 2020 2020 2074  ze);.          t
+00010b40: 7261 6974 732e 6163 6328 4330 2c20 616c  raits.acc(C0, al
+00010b50: 7068 6176 2c20 5230 293b 0a20 2020 2020  phav, R0);.     
+00010b60: 2020 2020 2074 7261 6974 732e 6163 6328       traits.acc(
+00010b70: 4334 2c20 616c 7068 6176 2c20 5231 293b  C4, alphav, R1);
+00010b80: 0a20 2020 2020 2020 2020 2074 7261 6974  .          trait
+00010b90: 732e 6163 6328 4338 2c20 616c 7068 6176  s.acc(C8, alphav
+00010ba0: 2c20 5232 293b 0a20 2020 2020 2020 2020  , R2);.         
+00010bb0: 2072 302e 7374 6f72 6550 6163 6b65 7428   r0.storePacket(
+00010bc0: 3020 2a20 5472 6169 7473 3a3a 5265 7350  0 * Traits::ResP
+00010bd0: 6163 6b65 7453 697a 652c 2052 3029 3b0a  acketSize, R0);.
+00010be0: 2020 2020 2020 2020 2020 7230 2e73 746f            r0.sto
+00010bf0: 7265 5061 636b 6574 2831 202a 2054 7261  rePacket(1 * Tra
+00010c00: 6974 733a 3a52 6573 5061 636b 6574 5369  its::ResPacketSi
+00010c10: 7a65 2c20 5231 293b 0a20 2020 2020 2020  ze, R1);.       
+00010c20: 2020 2072 302e 7374 6f72 6550 6163 6b65     r0.storePacke
+00010c30: 7428 3220 2a20 5472 6169 7473 3a3a 5265  t(2 * Traits::Re
+00010c40: 7350 6163 6b65 7453 697a 652c 2052 3229  sPacketSize, R2)
+00010c50: 3b20 2020 2020 2020 2020 200a 2020 2020  ;          .    
+00010c60: 2020 2020 2020 7d0a 2020 2020 2020 2020        }.        
+00010c70: 7d0a 2020 2020 2020 7d0a 2020 2020 7d0a  }.      }.    }.
+00010c80: 0a20 2020 202f 2f2d 2d2d 2d2d 2d2d 2d2d  .    //---------
+00010c90: 2d20 5072 6f63 6573 7320 3220 2a20 4c68  - Process 2 * Lh
+00010ca0: 7350 726f 6772 6573 7320 726f 7773 2061  sProgress rows a
+00010cb0: 7420 6f6e 6365 202d 2d2d 2d2d 2d2d 2d2d  t once ---------
+00010cc0: 2d0a 2020 2020 6966 286d 723e 3d32 2a54  -.    if(mr>=2*T
+00010cd0: 7261 6974 733a 3a4c 6873 5072 6f67 7265  raits::LhsProgre
+00010ce0: 7373 290a 2020 2020 7b0a 2020 2020 2020  ss).    {.      
+00010cf0: 636f 6e73 7420 496e 6465 7820 6c31 203d  const Index l1 =
+00010d00: 2064 6566 6175 6c74 4c31 4361 6368 6553   defaultL1CacheS
+00010d10: 697a 653b 202f 2f20 696e 2042 7974 6573  ize; // in Bytes
+00010d20: 2c20 544f 444f 2c20 6c31 2073 686f 756c  , TODO, l1 shoul
+00010d30: 6420 6265 2070 6173 7365 6420 746f 2074  d be passed to t
+00010d40: 6869 7320 6675 6e63 7469 6f6e 2e0a 2020  his function..  
+00010d50: 2020 2020 2f2f 2054 6865 206d 6178 2831      // The max(1
+00010d60: 2c20 2e2e 2e29 2068 6572 6520 6973 206e  , ...) here is n
+00010d70: 6565 6465 6420 6265 6361 7573 6520 7765  eeded because we
+00010d80: 206d 6179 2062 6520 7573 696e 6720 626c   may be using bl
+00010d90: 6f63 6b69 6e67 2070 6172 616d 7320 6c61  ocking params la
+00010da0: 7267 6572 2074 6861 6e20 7768 6174 206f  rger than what o
+00010db0: 7572 206b 6e6f 776e 206c 3120 6361 6368  ur known l1 cach
+00010dc0: 6520 7369 7a65 0a20 2020 2020 202f 2f20  e size.      // 
+00010dd0: 7375 6767 6573 7473 2077 6520 7368 6f75  suggests we shou
+00010de0: 6c64 2062 6520 7573 696e 673a 2065 6974  ld be using: eit
+00010df0: 6865 7220 6265 6361 7573 6520 6f75 7220  her because our 
+00010e00: 6b6e 6f77 6e20 6c31 2063 6163 6865 2073  known l1 cache s
+00010e10: 697a 6520 6973 2069 6e61 6363 7572 6174  ize is inaccurat
+00010e20: 6520 2865 2e67 2e20 6f6e 2041 6e64 726f  e (e.g. on Andro
+00010e30: 6964 2c20 7765 2063 616e 206f 6e6c 7920  id, we can only 
+00010e40: 6775 6573 7329 2c0a 2020 2020 2020 2f2f  guess),.      //
+00010e50: 206f 7220 6265 6361 7573 6520 7765 2061   or because we a
+00010e60: 7265 2074 6573 7469 6e67 2073 7065 6369  re testing speci
+00010e70: 6669 6320 626c 6f63 6b69 6e67 2073 697a  fic blocking siz
+00010e80: 6573 2e0a 2020 2020 2020 496e 6465 7820  es..      Index 
+00010e90: 6163 7475 616c 5f70 616e 656c 5f72 6f77  actual_panel_row
+00010ea0: 7320 3d20 2832 2a4c 6873 5072 6f67 7265  s = (2*LhsProgre
+00010eb0: 7373 2920 2a20 7374 643a 3a6d 6178 3c49  ss) * std::max<I
+00010ec0: 6e64 6578 3e28 312c 2820 286c 3120 2d20  ndex>(1,( (l1 - 
+00010ed0: 7369 7a65 6f66 2852 6573 5363 616c 6172  sizeof(ResScalar
+00010ee0: 292a 6d72 2a6e 7220 2d20 6465 7074 682a  )*mr*nr - depth*
+00010ef0: 6e72 2a73 697a 656f 6628 5268 7353 6361  nr*sizeof(RhsSca
+00010f00: 6c61 7229 2920 2f20 2864 6570 7468 202a  lar)) / (depth *
+00010f10: 2073 697a 656f 6628 4c68 7353 6361 6c61   sizeof(LhsScala
+00010f20: 7229 202a 2032 2a4c 6873 5072 6f67 7265  r) * 2*LhsProgre
+00010f30: 7373 2920 2929 3b0a 0a20 2020 2020 2066  ss) ));..      f
+00010f40: 6f72 2849 6e64 6578 2069 313d 7065 656c  or(Index i1=peel
+00010f50: 6564 5f6d 6333 3b20 6931 3c70 6565 6c65  ed_mc3; i1<peele
+00010f60: 645f 6d63 323b 2069 312b 3d61 6374 7561  d_mc2; i1+=actua
+00010f70: 6c5f 7061 6e65 6c5f 726f 7773 290a 2020  l_panel_rows).  
+00010f80: 2020 2020 7b0a 2020 2020 2020 2020 496e      {.        In
+00010f90: 6465 7820 6163 7475 616c 5f70 616e 656c  dex actual_panel
+00010fa0: 5f65 6e64 203d 2028 7374 643a 3a6d 696e  _end = (std::min
+00010fb0: 2928 6931 2b61 6374 7561 6c5f 7061 6e65  )(i1+actual_pane
+00010fc0: 6c5f 726f 7773 2c20 7065 656c 6564 5f6d  l_rows, peeled_m
+00010fd0: 6332 293b 0a20 2020 2020 2020 2066 6f72  c2);.        for
+00010fe0: 2849 6e64 6578 206a 323d 303b 206a 323c  (Index j2=0; j2<
+00010ff0: 7061 636b 6574 5f63 6f6c 7334 3b20 6a32  packet_cols4; j2
+00011000: 2b3d 6e72 290a 2020 2020 2020 2020 7b0a  +=nr).        {.
+00011010: 2020 2020 2020 2020 2020 666f 7228 496e            for(In
+00011020: 6465 7820 693d 6931 3b20 693c 6163 7475  dex i=i1; i<actu
+00011030: 616c 5f70 616e 656c 5f65 6e64 3b20 692b  al_panel_end; i+
+00011040: 3d32 2a4c 6873 5072 6f67 7265 7373 290a  =2*LhsProgress).
+00011050: 2020 2020 2020 2020 2020 7b0a 2020 2020            {.    
+00011060: 2020 2020 2020 0a20 2020 2020 2020 2020        .         
+00011070: 202f 2f20 5765 2073 656c 6563 7465 6420   // We selected 
+00011080: 6120 322a 5472 6169 7473 3a3a 4c68 7350  a 2*Traits::LhsP
+00011090: 726f 6772 6573 7320 7820 6e72 206d 6963  rogress x nr mic
+000110a0: 726f 2062 6c6f 636b 206f 6620 7265 7320  ro block of res 
+000110b0: 7768 6963 6820 6973 2065 6e74 6972 656c  which is entirel
+000110c0: 790a 2020 2020 2020 2020 2020 2f2f 2073  y.          // s
+000110d0: 746f 7265 6420 696e 746f 2032 2078 206e  tored into 2 x n
+000110e0: 7220 7265 6769 7374 6572 732e 0a20 2020  r registers..   
+000110f0: 2020 2020 2020 200a 2020 2020 2020 2020         .        
+00011100: 2020 636f 6e73 7420 4c68 7353 6361 6c61    const LhsScala
+00011110: 722a 2062 6c41 203d 2026 626c 6f63 6b41  r* blA = &blockA
+00011120: 5b69 2a73 7472 6964 6541 2b6f 6666 7365  [i*strideA+offse
+00011130: 7441 2a28 322a 5472 6169 7473 3a3a 4c68  tA*(2*Traits::Lh
+00011140: 7350 726f 6772 6573 7329 5d3b 0a20 2020  sProgress)];.   
+00011150: 2020 2020 2020 2070 7265 6665 7463 6828         prefetch(
+00011160: 2662 6c41 5b30 5d29 3b0a 0a20 2020 2020  &blA[0]);..     
+00011170: 2020 2020 202f 2f20 6765 7473 2072 6573       // gets res
+00011180: 2062 6c6f 636b 2061 7320 7265 6769 7374   block as regist
+00011190: 6572 0a20 2020 2020 2020 2020 2041 6363  er.          Acc
+000111a0: 5061 636b 6574 2043 302c 2043 312c 2043  Packet C0, C1, C
+000111b0: 322c 2043 332c 0a20 2020 2020 2020 2020  2, C3,.         
+000111c0: 2020 2020 2020 2020 2020 2043 342c 2043             C4, C
+000111d0: 352c 2043 362c 2043 373b 0a20 2020 2020  5, C6, C7;.     
+000111e0: 2020 2020 2074 7261 6974 732e 696e 6974       traits.init
+000111f0: 4163 6328 4330 293b 2074 7261 6974 732e  Acc(C0); traits.
+00011200: 696e 6974 4163 6328 4331 293b 2074 7261  initAcc(C1); tra
+00011210: 6974 732e 696e 6974 4163 6328 4332 293b  its.initAcc(C2);
+00011220: 2074 7261 6974 732e 696e 6974 4163 6328   traits.initAcc(
+00011230: 4333 293b 0a20 2020 2020 2020 2020 2074  C3);.          t
+00011240: 7261 6974 732e 696e 6974 4163 6328 4334  raits.initAcc(C4
+00011250: 293b 2074 7261 6974 732e 696e 6974 4163  ); traits.initAc
+00011260: 6328 4335 293b 2074 7261 6974 732e 696e  c(C5); traits.in
+00011270: 6974 4163 6328 4336 293b 2074 7261 6974  itAcc(C6); trait
+00011280: 732e 696e 6974 4163 6328 4337 293b 0a0a  s.initAcc(C7);..
+00011290: 2020 2020 2020 2020 2020 4c69 6e65 6172            Linear
+000112a0: 4d61 7070 6572 2072 3020 3d20 7265 732e  Mapper r0 = res.
+000112b0: 6765 744c 696e 6561 724d 6170 7065 7228  getLinearMapper(
+000112c0: 692c 206a 3220 2b20 3029 3b0a 2020 2020  i, j2 + 0);.    
+000112d0: 2020 2020 2020 4c69 6e65 6172 4d61 7070        LinearMapp
+000112e0: 6572 2072 3120 3d20 7265 732e 6765 744c  er r1 = res.getL
+000112f0: 696e 6561 724d 6170 7065 7228 692c 206a  inearMapper(i, j
+00011300: 3220 2b20 3129 3b0a 2020 2020 2020 2020  2 + 1);.        
+00011310: 2020 4c69 6e65 6172 4d61 7070 6572 2072    LinearMapper r
+00011320: 3220 3d20 7265 732e 6765 744c 696e 6561  2 = res.getLinea
+00011330: 724d 6170 7065 7228 692c 206a 3220 2b20  rMapper(i, j2 + 
+00011340: 3229 3b0a 2020 2020 2020 2020 2020 4c69  2);.          Li
+00011350: 6e65 6172 4d61 7070 6572 2072 3320 3d20  nearMapper r3 = 
+00011360: 7265 732e 6765 744c 696e 6561 724d 6170  res.getLinearMap
+00011370: 7065 7228 692c 206a 3220 2b20 3329 3b0a  per(i, j2 + 3);.
+00011380: 0a20 2020 2020 2020 2020 2072 302e 7072  .          r0.pr
+00011390: 6566 6574 6368 2870 7265 6665 7463 685f  efetch(prefetch_
+000113a0: 7265 735f 6f66 6673 6574 293b 0a20 2020  res_offset);.   
+000113b0: 2020 2020 2020 2072 312e 7072 6566 6574         r1.prefet
+000113c0: 6368 2870 7265 6665 7463 685f 7265 735f  ch(prefetch_res_
+000113d0: 6f66 6673 6574 293b 0a20 2020 2020 2020  offset);.       
+000113e0: 2020 2072 322e 7072 6566 6574 6368 2870     r2.prefetch(p
+000113f0: 7265 6665 7463 685f 7265 735f 6f66 6673  refetch_res_offs
+00011400: 6574 293b 0a20 2020 2020 2020 2020 2072  et);.          r
+00011410: 332e 7072 6566 6574 6368 2870 7265 6665  3.prefetch(prefe
+00011420: 7463 685f 7265 735f 6f66 6673 6574 293b  tch_res_offset);
+00011430: 0a0a 2020 2020 2020 2020 2020 2f2f 2070  ..          // p
+00011440: 6572 666f 726d 7320 2269 6e6e 6572 2220  erforms "inner" 
+00011450: 7072 6f64 7563 7473 0a20 2020 2020 2020  products.       
+00011460: 2020 2063 6f6e 7374 2052 6873 5363 616c     const RhsScal
+00011470: 6172 2a20 626c 4220 3d20 2662 6c6f 636b  ar* blB = &block
+00011480: 425b 6a32 2a73 7472 6964 6542 2b6f 6666  B[j2*strideB+off
+00011490: 7365 7442 2a6e 725d 3b0a 2020 2020 2020  setB*nr];.      
+000114a0: 2020 2020 7072 6566 6574 6368 2826 626c      prefetch(&bl
+000114b0: 425b 305d 293b 0a20 2020 2020 2020 2020  B[0]);.         
+000114c0: 204c 6873 5061 636b 6574 2041 302c 2041   LhsPacket A0, A
+000114d0: 313b 0a0a 2020 2020 2020 2020 2020 666f  1;..          fo
+000114e0: 7228 496e 6465 7820 6b3d 303b 206b 3c70  r(Index k=0; k<p
+000114f0: 6565 6c65 645f 6b63 3b20 6b2b 3d70 6b29  eeled_kc; k+=pk)
+00011500: 0a20 2020 2020 2020 2020 207b 0a20 2020  .          {.   
+00011510: 2020 2020 2020 2020 2045 4947 454e 5f41           EIGEN_A
+00011520: 534d 5f43 4f4d 4d45 4e54 2822 6265 6769  SM_COMMENT("begi
+00011530: 6e20 6765 6270 206d 6963 726f 206b 6572  n gebp micro ker
+00011540: 6e65 6c20 3270 5834 2229 3b0a 2020 2020  nel 2pX4");.    
+00011550: 2020 2020 2020 2020 5268 7350 6163 6b65          RhsPacke
+00011560: 7478 3420 7268 735f 7061 6e65 6c3b 0a20  tx4 rhs_panel;. 
+00011570: 2020 2020 2020 2020 2020 2052 6873 5061             RhsPa
+00011580: 636b 6574 2054 303b 0a0a 2020 2020 2020  cket T0;..      
+00011590: 2020 2020 2f2f 204e 4f54 453a 2074 6865      // NOTE: the
+000115a0: 2062 6567 696e 2f65 6e64 2061 736d 2063   begin/end asm c
+000115b0: 6f6d 6d65 6e74 7320 6265 6c6f 7720 776f  omments below wo
+000115c0: 726b 2061 726f 756e 6420 6275 6720 3933  rk around bug 93
+000115d0: 3521 0a20 2020 2020 2020 2020 202f 2f20  5!.          // 
+000115e0: 6275 7420 7468 6579 2061 7265 206e 6f74  but they are not
+000115f0: 2065 6e6f 7567 6820 666f 7220 6763 633e   enough for gcc>
+00011600: 3d36 2077 6974 686f 7574 2046 4d41 2028  =6 without FMA (
+00011610: 6275 6720 3136 3337 290a 2020 2020 2020  bug 1637).      
+00011620: 2020 2020 2369 6620 4549 4745 4e5f 474e      #if EIGEN_GN
+00011630: 5543 5f41 545f 4c45 4153 5428 362c 3029  UC_AT_LEAST(6,0)
+00011640: 2026 2620 6465 6669 6e65 6428 4549 4745   && defined(EIGE
+00011650: 4e5f 5645 4354 4f52 495a 455f 5353 4529  N_VECTORIZE_SSE)
+00011660: 0a20 2020 2020 2020 2020 2020 2023 6465  .            #de
+00011670: 6669 6e65 2045 4947 454e 5f47 4542 505f  fine EIGEN_GEBP_
+00011680: 3250 5834 5f53 5049 4c4c 494e 475f 574f  2PX4_SPILLING_WO
+00011690: 524b 4152 4f55 4e44 205f 5f61 736d 5f5f  RKAROUND __asm__
+000116a0: 2020 2822 2220 3a20 5b61 305d 2022 2b78    ("" : [a0] "+x
+000116b0: 2c6d 2220 2841 3029 2c5b 6131 5d20 222b  ,m" (A0),[a1] "+
+000116c0: 782c 6d22 2028 4131 2929 3b0a 2020 2020  x,m" (A1));.    
+000116d0: 2020 2020 2020 2365 6c73 650a 2020 2020        #else.    
+000116e0: 2020 2020 2020 2020 2364 6566 696e 6520          #define 
+000116f0: 4549 4745 4e5f 4745 4250 5f32 5058 345f  EIGEN_GEBP_2PX4_
+00011700: 5350 494c 4c49 4e47 5f57 4f52 4b41 524f  SPILLING_WORKARO
+00011710: 554e 440a 2020 2020 2020 2020 2020 2365  UND.          #e
+00011720: 6e64 6966 0a23 6465 6669 6e65 2045 4947  ndif.#define EIG
+00011730: 454e 5f47 4542 4750 5f4f 4e45 5354 4550  EN_GEBGP_ONESTEP
+00011740: 284b 2920 2020 2020 2020 2020 2020 2020  (K)             
+00011750: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011760: 2020 2020 2020 2020 2020 2020 2020 205c                 \
+00011770: 0a20 2020 2020 2020 2020 2020 2064 6f20  .            do 
+00011780: 7b20 2020 2020 2020 2020 2020 2020 2020  {               
+00011790: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000117a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000117b0: 2020 2020 2020 2020 2020 205c 0a20 2020             \.   
+000117c0: 2020 2020 2020 2020 2020 2045 4947 454e             EIGEN
+000117d0: 5f41 534d 5f43 4f4d 4d45 4e54 2822 6265  _ASM_COMMENT("be
+000117e0: 6769 6e20 7374 6570 206f 6620 6765 6270  gin step of gebp
+000117f0: 206d 6963 726f 206b 6572 6e65 6c20 3270   micro kernel 2p
+00011800: 5834 2229 3b20 205c 0a20 2020 2020 2020  X4");  \.       
+00011810: 2020 2020 2020 2074 7261 6974 732e 6c6f         traits.lo
+00011820: 6164 4c68 7328 2662 6c41 5b28 3020 2b20  adLhs(&blA[(0 + 
+00011830: 3220 2a20 4b29 202a 204c 6873 5072 6f67  2 * K) * LhsProg
+00011840: 7265 7373 5d2c 2041 3029 3b20 2020 2020  ress], A0);     
+00011850: 2020 205c 0a20 2020 2020 2020 2020 2020     \.           
+00011860: 2020 2074 7261 6974 732e 6c6f 6164 4c68     traits.loadLh
+00011870: 7328 2662 6c41 5b28 3120 2b20 3220 2a20  s(&blA[(1 + 2 * 
+00011880: 4b29 202a 204c 6873 5072 6f67 7265 7373  K) * LhsProgress
+00011890: 5d2c 2041 3129 3b20 2020 2020 2020 205c  ], A1);        \
+000118a0: 0a20 2020 2020 2020 2020 2020 2020 2074  .              t
+000118b0: 7261 6974 732e 6c6f 6164 5268 7328 2662  raits.loadRhs(&b
+000118c0: 6c42 5b28 3020 2b20 3420 2a20 4b29 202a  lB[(0 + 4 * K) *
+000118d0: 2052 6873 5072 6f67 7265 7373 5d2c 2072   RhsProgress], r
+000118e0: 6873 5f70 616e 656c 293b 205c 0a20 2020  hs_panel); \.   
+000118f0: 2020 2020 2020 2020 2020 2074 7261 6974             trait
+00011900: 732e 6d61 6464 2841 302c 2072 6873 5f70  s.madd(A0, rhs_p
+00011910: 616e 656c 2c20 4330 2c20 5430 2c20 6669  anel, C0, T0, fi
+00011920: 783c 303e 293b 2020 2020 2020 2020 2020  x<0>);          
+00011930: 2020 2020 2020 205c 0a20 2020 2020 2020         \.       
+00011940: 2020 2020 2020 2074 7261 6974 732e 6d61         traits.ma
+00011950: 6464 2841 312c 2072 6873 5f70 616e 656c  dd(A1, rhs_panel
+00011960: 2c20 4334 2c20 5430 2c20 6669 783c 303e  , C4, T0, fix<0>
+00011970: 293b 2020 2020 2020 2020 2020 2020 2020  );              
+00011980: 2020 205c 0a20 2020 2020 2020 2020 2020     \.           
+00011990: 2020 2074 7261 6974 732e 6d61 6464 2841     traits.madd(A
+000119a0: 302c 2072 6873 5f70 616e 656c 2c20 4331  0, rhs_panel, C1
+000119b0: 2c20 5430 2c20 6669 783c 313e 293b 2020  , T0, fix<1>);  
+000119c0: 2020 2020 2020 2020 2020 2020 2020 205c                 \
+000119d0: 0a20 2020 2020 2020 2020 2020 2020 2074  .              t
+000119e0: 7261 6974 732e 6d61 6464 2841 312c 2072  raits.madd(A1, r
+000119f0: 6873 5f70 616e 656c 2c20 4335 2c20 5430  hs_panel, C5, T0
+00011a00: 2c20 6669 783c 313e 293b 2020 2020 2020  , fix<1>);      
+00011a10: 2020 2020 2020 2020 2020 205c 0a20 2020             \.   
+00011a20: 2020 2020 2020 2020 2020 2074 7261 6974             trait
+00011a30: 732e 6d61 6464 2841 302c 2072 6873 5f70  s.madd(A0, rhs_p
+00011a40: 616e 656c 2c20 4332 2c20 5430 2c20 6669  anel, C2, T0, fi
+00011a50: 783c 323e 293b 2020 2020 2020 2020 2020  x<2>);          
+00011a60: 2020 2020 2020 205c 0a20 2020 2020 2020         \.       
+00011a70: 2020 2020 2020 2074 7261 6974 732e 6d61         traits.ma
+00011a80: 6464 2841 312c 2072 6873 5f70 616e 656c  dd(A1, rhs_panel
+00011a90: 2c20 4336 2c20 5430 2c20 6669 783c 323e  , C6, T0, fix<2>
+00011aa0: 293b 2020 2020 2020 2020 2020 2020 2020  );              
+00011ab0: 2020 205c 0a20 2020 2020 2020 2020 2020     \.           
+00011ac0: 2020 2074 7261 6974 732e 6d61 6464 2841     traits.madd(A
+00011ad0: 302c 2072 6873 5f70 616e 656c 2c20 4333  0, rhs_panel, C3
+00011ae0: 2c20 5430 2c20 6669 783c 333e 293b 2020  , T0, fix<3>);  
+00011af0: 2020 2020 2020 2020 2020 2020 2020 205c                 \
+00011b00: 0a20 2020 2020 2020 2020 2020 2020 2074  .              t
+00011b10: 7261 6974 732e 6d61 6464 2841 312c 2072  raits.madd(A1, r
+00011b20: 6873 5f70 616e 656c 2c20 4337 2c20 5430  hs_panel, C7, T0
+00011b30: 2c20 6669 783c 333e 293b 2020 2020 2020  , fix<3>);      
+00011b40: 2020 2020 2020 2020 2020 205c 0a20 2020             \.   
+00011b50: 2020 2020 2020 2020 2020 2045 4947 454e             EIGEN
+00011b60: 5f47 4542 505f 3250 5834 5f53 5049 4c4c  _GEBP_2PX4_SPILL
+00011b70: 494e 475f 574f 524b 4152 4f55 4e44 2020  ING_WORKAROUND  
+00011b80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011b90: 2020 2020 2020 205c 0a20 2020 2020 2020         \.       
+00011ba0: 2020 2020 2020 2045 4947 454e 5f41 534d         EIGEN_ASM
+00011bb0: 5f43 4f4d 4d45 4e54 2822 656e 6420 7374  _COMMENT("end st
+00011bc0: 6570 206f 6620 6765 6270 206d 6963 726f  ep of gebp micro
+00011bd0: 206b 6572 6e65 6c20 3270 5834 2229 3b20   kernel 2pX4"); 
+00011be0: 2020 205c 0a20 2020 2020 2020 2020 2020     \.           
+00011bf0: 207d 2077 6869 6c65 2028 6661 6c73 6529   } while (false)
+00011c00: 0a0a 2020 2020 2020 2020 2020 2020 696e  ..            in
+00011c10: 7465 726e 616c 3a3a 7072 6566 6574 6368  ternal::prefetch
+00011c20: 2862 6c42 2b28 3438 2b30 2929 3b0a 2020  (blB+(48+0));.  
+00011c30: 2020 2020 2020 2020 2020 4549 4745 4e5f            EIGEN_
+00011c40: 4745 4247 505f 4f4e 4553 5445 5028 3029  GEBGP_ONESTEP(0)
+00011c50: 3b0a 2020 2020 2020 2020 2020 2020 4549  ;.            EI
+00011c60: 4745 4e5f 4745 4247 505f 4f4e 4553 5445  GEN_GEBGP_ONESTE
+00011c70: 5028 3129 3b0a 2020 2020 2020 2020 2020  P(1);.          
+00011c80: 2020 4549 4745 4e5f 4745 4247 505f 4f4e    EIGEN_GEBGP_ON
+00011c90: 4553 5445 5028 3229 3b0a 2020 2020 2020  ESTEP(2);.      
+00011ca0: 2020 2020 2020 4549 4745 4e5f 4745 4247        EIGEN_GEBG
+00011cb0: 505f 4f4e 4553 5445 5028 3329 3b0a 2020  P_ONESTEP(3);.  
+00011cc0: 2020 2020 2020 2020 2020 696e 7465 726e            intern
+00011cd0: 616c 3a3a 7072 6566 6574 6368 2862 6c42  al::prefetch(blB
+00011ce0: 2b28 3438 2b31 3629 293b 0a20 2020 2020  +(48+16));.     
+00011cf0: 2020 2020 2020 2045 4947 454e 5f47 4542         EIGEN_GEB
+00011d00: 4750 5f4f 4e45 5354 4550 2834 293b 0a20  GP_ONESTEP(4);. 
+00011d10: 2020 2020 2020 2020 2020 2045 4947 454e             EIGEN
+00011d20: 5f47 4542 4750 5f4f 4e45 5354 4550 2835  _GEBGP_ONESTEP(5
+00011d30: 293b 0a20 2020 2020 2020 2020 2020 2045  );.            E
+00011d40: 4947 454e 5f47 4542 4750 5f4f 4e45 5354  IGEN_GEBGP_ONEST
+00011d50: 4550 2836 293b 0a20 2020 2020 2020 2020  EP(6);.         
+00011d60: 2020 2045 4947 454e 5f47 4542 4750 5f4f     EIGEN_GEBGP_O
+00011d70: 4e45 5354 4550 2837 293b 0a0a 2020 2020  NESTEP(7);..    
+00011d80: 2020 2020 2020 2020 626c 4220 2b3d 2070          blB += p
+00011d90: 6b2a 342a 5268 7350 726f 6772 6573 733b  k*4*RhsProgress;
+00011da0: 0a20 2020 2020 2020 2020 2020 2062 6c41  .            blA
+00011db0: 202b 3d20 706b 2a28 322a 5472 6169 7473   += pk*(2*Traits
+00011dc0: 3a3a 4c68 7350 726f 6772 6573 7329 3b0a  ::LhsProgress);.
+00011dd0: 0a20 2020 2020 2020 2020 2020 2045 4947  .            EIG
+00011de0: 454e 5f41 534d 5f43 4f4d 4d45 4e54 2822  EN_ASM_COMMENT("
+00011df0: 656e 6420 6765 6270 206d 6963 726f 206b  end gebp micro k
+00011e00: 6572 6e65 6c20 3270 5834 2229 3b0a 2020  ernel 2pX4");.  
+00011e10: 2020 2020 2020 2020 7d0a 2020 2020 2020          }.      
+00011e20: 2020 2020 2f2f 2070 726f 6365 7373 2072      // process r
+00011e30: 656d 6169 6e69 6e67 2070 6565 6c65 6420  emaining peeled 
+00011e40: 6c6f 6f70 0a20 2020 2020 2020 2020 2066  loop.          f
+00011e50: 6f72 2849 6e64 6578 206b 3d70 6565 6c65  or(Index k=peele
+00011e60: 645f 6b63 3b20 6b3c 6465 7074 683b 206b  d_kc; k<depth; k
+00011e70: 2b2b 290a 2020 2020 2020 2020 2020 7b0a  ++).          {.
+00011e80: 2020 2020 2020 2020 2020 2020 5268 7350              RhsP
+00011e90: 6163 6b65 7478 3420 7268 735f 7061 6e65  acketx4 rhs_pane
+00011ea0: 6c3b 0a20 2020 2020 2020 2020 2020 2052  l;.            R
+00011eb0: 6873 5061 636b 6574 2054 303b 0a20 2020  hsPacket T0;.   
+00011ec0: 2020 2020 2020 2020 2045 4947 454e 5f47           EIGEN_G
+00011ed0: 4542 4750 5f4f 4e45 5354 4550 2830 293b  EBGP_ONESTEP(0);
+00011ee0: 0a20 2020 2020 2020 2020 2020 2062 6c42  .            blB
+00011ef0: 202b 3d20 342a 5268 7350 726f 6772 6573   += 4*RhsProgres
+00011f00: 733b 0a20 2020 2020 2020 2020 2020 2062  s;.            b
+00011f10: 6c41 202b 3d20 322a 5472 6169 7473 3a3a  lA += 2*Traits::
+00011f20: 4c68 7350 726f 6772 6573 733b 0a20 2020  LhsProgress;.   
+00011f30: 2020 2020 2020 207d 0a23 756e 6465 6620         }.#undef 
+00011f40: 4549 4745 4e5f 4745 4247 505f 4f4e 4553  EIGEN_GEBGP_ONES
+00011f50: 5445 500a 0a20 2020 2020 2020 2020 2052  TEP..          R
+00011f60: 6573 5061 636b 6574 2052 302c 2052 312c  esPacket R0, R1,
+00011f70: 2052 322c 2052 333b 0a20 2020 2020 2020   R2, R3;.       
+00011f80: 2020 2052 6573 5061 636b 6574 2061 6c70     ResPacket alp
+00011f90: 6861 7620 3d20 7073 6574 313c 5265 7350  hav = pset1<ResP
+00011fa0: 6163 6b65 743e 2861 6c70 6861 293b 0a0a  acket>(alpha);..
+00011fb0: 2020 2020 2020 2020 2020 5230 203d 2072            R0 = r
+00011fc0: 302e 7465 6d70 6c61 7465 206c 6f61 6450  0.template loadP
+00011fd0: 6163 6b65 743c 5265 7350 6163 6b65 743e  acket<ResPacket>
+00011fe0: 2830 202a 2054 7261 6974 733a 3a52 6573  (0 * Traits::Res
+00011ff0: 5061 636b 6574 5369 7a65 293b 0a20 2020  PacketSize);.   
+00012000: 2020 2020 2020 2052 3120 3d20 7230 2e74         R1 = r0.t
+00012010: 656d 706c 6174 6520 6c6f 6164 5061 636b  emplate loadPack
+00012020: 6574 3c52 6573 5061 636b 6574 3e28 3120  et<ResPacket>(1 
+00012030: 2a20 5472 6169 7473 3a3a 5265 7350 6163  * Traits::ResPac
+00012040: 6b65 7453 697a 6529 3b0a 2020 2020 2020  ketSize);.      
+00012050: 2020 2020 5232 203d 2072 312e 7465 6d70      R2 = r1.temp
+00012060: 6c61 7465 206c 6f61 6450 6163 6b65 743c  late loadPacket<
+00012070: 5265 7350 6163 6b65 743e 2830 202a 2054  ResPacket>(0 * T
+00012080: 7261 6974 733a 3a52 6573 5061 636b 6574  raits::ResPacket
+00012090: 5369 7a65 293b 0a20 2020 2020 2020 2020  Size);.         
+000120a0: 2052 3320 3d20 7231 2e74 656d 706c 6174   R3 = r1.templat
+000120b0: 6520 6c6f 6164 5061 636b 6574 3c52 6573  e loadPacket<Res
+000120c0: 5061 636b 6574 3e28 3120 2a20 5472 6169  Packet>(1 * Trai
+000120d0: 7473 3a3a 5265 7350 6163 6b65 7453 697a  ts::ResPacketSiz
+000120e0: 6529 3b0a 2020 2020 2020 2020 2020 7472  e);.          tr
+000120f0: 6169 7473 2e61 6363 2843 302c 2061 6c70  aits.acc(C0, alp
+00012100: 6861 762c 2052 3029 3b0a 2020 2020 2020  hav, R0);.      
+00012110: 2020 2020 7472 6169 7473 2e61 6363 2843      traits.acc(C
+00012120: 342c 2061 6c70 6861 762c 2052 3129 3b0a  4, alphav, R1);.
+00012130: 2020 2020 2020 2020 2020 7472 6169 7473            traits
+00012140: 2e61 6363 2843 312c 2061 6c70 6861 762c  .acc(C1, alphav,
+00012150: 2052 3229 3b0a 2020 2020 2020 2020 2020   R2);.          
+00012160: 7472 6169 7473 2e61 6363 2843 352c 2061  traits.acc(C5, a
+00012170: 6c70 6861 762c 2052 3329 3b0a 2020 2020  lphav, R3);.    
+00012180: 2020 2020 2020 7230 2e73 746f 7265 5061        r0.storePa
+00012190: 636b 6574 2830 202a 2054 7261 6974 733a  cket(0 * Traits:
+000121a0: 3a52 6573 5061 636b 6574 5369 7a65 2c20  :ResPacketSize, 
+000121b0: 5230 293b 0a20 2020 2020 2020 2020 2072  R0);.          r
+000121c0: 302e 7374 6f72 6550 6163 6b65 7428 3120  0.storePacket(1 
+000121d0: 2a20 5472 6169 7473 3a3a 5265 7350 6163  * Traits::ResPac
+000121e0: 6b65 7453 697a 652c 2052 3129 3b0a 2020  ketSize, R1);.  
+000121f0: 2020 2020 2020 2020 7231 2e73 746f 7265          r1.store
+00012200: 5061 636b 6574 2830 202a 2054 7261 6974  Packet(0 * Trait
+00012210: 733a 3a52 6573 5061 636b 6574 5369 7a65  s::ResPacketSize
+00012220: 2c20 5232 293b 0a20 2020 2020 2020 2020  , R2);.         
+00012230: 2072 312e 7374 6f72 6550 6163 6b65 7428   r1.storePacket(
+00012240: 3120 2a20 5472 6169 7473 3a3a 5265 7350  1 * Traits::ResP
+00012250: 6163 6b65 7453 697a 652c 2052 3329 3b0a  acketSize, R3);.
+00012260: 0a20 2020 2020 2020 2020 2052 3020 3d20  .          R0 = 
+00012270: 7232 2e74 656d 706c 6174 6520 6c6f 6164  r2.template load
+00012280: 5061 636b 6574 3c52 6573 5061 636b 6574  Packet<ResPacket
+00012290: 3e28 3020 2a20 5472 6169 7473 3a3a 5265  >(0 * Traits::Re
+000122a0: 7350 6163 6b65 7453 697a 6529 3b0a 2020  sPacketSize);.  
+000122b0: 2020 2020 2020 2020 5231 203d 2072 322e          R1 = r2.
+000122c0: 7465 6d70 6c61 7465 206c 6f61 6450 6163  template loadPac
+000122d0: 6b65 743c 5265 7350 6163 6b65 743e 2831  ket<ResPacket>(1
+000122e0: 202a 2054 7261 6974 733a 3a52 6573 5061   * Traits::ResPa
+000122f0: 636b 6574 5369 7a65 293b 0a20 2020 2020  cketSize);.     
+00012300: 2020 2020 2052 3220 3d20 7233 2e74 656d       R2 = r3.tem
+00012310: 706c 6174 6520 6c6f 6164 5061 636b 6574  plate loadPacket
+00012320: 3c52 6573 5061 636b 6574 3e28 3020 2a20  <ResPacket>(0 * 
+00012330: 5472 6169 7473 3a3a 5265 7350 6163 6b65  Traits::ResPacke
+00012340: 7453 697a 6529 3b0a 2020 2020 2020 2020  tSize);.        
+00012350: 2020 5233 203d 2072 332e 7465 6d70 6c61    R3 = r3.templa
+00012360: 7465 206c 6f61 6450 6163 6b65 743c 5265  te loadPacket<Re
+00012370: 7350 6163 6b65 743e 2831 202a 2054 7261  sPacket>(1 * Tra
+00012380: 6974 733a 3a52 6573 5061 636b 6574 5369  its::ResPacketSi
+00012390: 7a65 293b 0a20 2020 2020 2020 2020 2074  ze);.          t
+000123a0: 7261 6974 732e 6163 6328 4332 2c20 2061  raits.acc(C2,  a
+000123b0: 6c70 6861 762c 2052 3029 3b0a 2020 2020  lphav, R0);.    
+000123c0: 2020 2020 2020 7472 6169 7473 2e61 6363        traits.acc
+000123d0: 2843 362c 2020 616c 7068 6176 2c20 5231  (C6,  alphav, R1
+000123e0: 293b 0a20 2020 2020 2020 2020 2074 7261  );.          tra
+000123f0: 6974 732e 6163 6328 4333 2c20 2061 6c70  its.acc(C3,  alp
+00012400: 6861 762c 2052 3229 3b0a 2020 2020 2020  hav, R2);.      
+00012410: 2020 2020 7472 6169 7473 2e61 6363 2843      traits.acc(C
+00012420: 372c 2020 616c 7068 6176 2c20 5233 293b  7,  alphav, R3);
+00012430: 0a20 2020 2020 2020 2020 2072 322e 7374  .          r2.st
+00012440: 6f72 6550 6163 6b65 7428 3020 2a20 5472  orePacket(0 * Tr
+00012450: 6169 7473 3a3a 5265 7350 6163 6b65 7453  aits::ResPacketS
+00012460: 697a 652c 2052 3029 3b0a 2020 2020 2020  ize, R0);.      
+00012470: 2020 2020 7232 2e73 746f 7265 5061 636b      r2.storePack
+00012480: 6574 2831 202a 2054 7261 6974 733a 3a52  et(1 * Traits::R
+00012490: 6573 5061 636b 6574 5369 7a65 2c20 5231  esPacketSize, R1
+000124a0: 293b 0a20 2020 2020 2020 2020 2072 332e  );.          r3.
+000124b0: 7374 6f72 6550 6163 6b65 7428 3020 2a20  storePacket(0 * 
+000124c0: 5472 6169 7473 3a3a 5265 7350 6163 6b65  Traits::ResPacke
+000124d0: 7453 697a 652c 2052 3229 3b0a 2020 2020  tSize, R2);.    
+000124e0: 2020 2020 2020 7233 2e73 746f 7265 5061        r3.storePa
+000124f0: 636b 6574 2831 202a 2054 7261 6974 733a  cket(1 * Traits:
+00012500: 3a52 6573 5061 636b 6574 5369 7a65 2c20  :ResPacketSize, 
+00012510: 5233 293b 0a20 2020 2020 2020 2020 207d  R3);.          }
+00012520: 0a20 2020 2020 2020 207d 0a20 2020 2020  .        }.     
+00012530: 200a 2020 2020 2020 2020 2f2f 2044 6561   .        // Dea
+00012540: 6c20 7769 7468 2072 656d 6169 6e69 6e67  l with remaining
+00012550: 2063 6f6c 756d 6e73 206f 6620 7468 6520   columns of the 
+00012560: 7268 730a 2020 2020 2020 2020 666f 7228  rhs.        for(
+00012570: 496e 6465 7820 6a32 3d70 6163 6b65 745f  Index j2=packet_
+00012580: 636f 6c73 343b 206a 323c 636f 6c73 3b20  cols4; j2<cols; 
+00012590: 6a32 2b2b 290a 2020 2020 2020 2020 7b0a  j2++).        {.
+000125a0: 2020 2020 2020 2020 2020 666f 7228 496e            for(In
+000125b0: 6465 7820 693d 6931 3b20 693c 6163 7475  dex i=i1; i<actu
+000125c0: 616c 5f70 616e 656c 5f65 6e64 3b20 692b  al_panel_end; i+
+000125d0: 3d32 2a4c 6873 5072 6f67 7265 7373 290a  =2*LhsProgress).
+000125e0: 2020 2020 2020 2020 2020 7b0a 2020 2020            {.    
+000125f0: 2020 2020 2020 2f2f 204f 6e65 2063 6f6c        // One col
+00012600: 756d 6e20 6174 2061 2074 696d 650a 2020  umn at a time.  
+00012610: 2020 2020 2020 2020 636f 6e73 7420 4c68          const Lh
+00012620: 7353 6361 6c61 722a 2062 6c41 203d 2026  sScalar* blA = &
+00012630: 626c 6f63 6b41 5b69 2a73 7472 6964 6541  blockA[i*strideA
+00012640: 2b6f 6666 7365 7441 2a28 322a 5472 6169  +offsetA*(2*Trai
+00012650: 7473 3a3a 4c68 7350 726f 6772 6573 7329  ts::LhsProgress)
+00012660: 5d3b 0a20 2020 2020 2020 2020 2070 7265  ];.          pre
+00012670: 6665 7463 6828 2662 6c41 5b30 5d29 3b0a  fetch(&blA[0]);.
+00012680: 0a20 2020 2020 2020 2020 202f 2f20 6765  .          // ge
+00012690: 7473 2072 6573 2062 6c6f 636b 2061 7320  ts res block as 
+000126a0: 7265 6769 7374 6572 0a20 2020 2020 2020  register.       
+000126b0: 2020 2041 6363 5061 636b 6574 2043 302c     AccPacket C0,
+000126c0: 2043 343b 0a20 2020 2020 2020 2020 2074   C4;.          t
+000126d0: 7261 6974 732e 696e 6974 4163 6328 4330  raits.initAcc(C0
+000126e0: 293b 0a20 2020 2020 2020 2020 2074 7261  );.          tra
+000126f0: 6974 732e 696e 6974 4163 6328 4334 293b  its.initAcc(C4);
+00012700: 0a0a 2020 2020 2020 2020 2020 4c69 6e65  ..          Line
+00012710: 6172 4d61 7070 6572 2072 3020 3d20 7265  arMapper r0 = re
+00012720: 732e 6765 744c 696e 6561 724d 6170 7065  s.getLinearMappe
+00012730: 7228 692c 206a 3229 3b0a 2020 2020 2020  r(i, j2);.      
+00012740: 2020 2020 7230 2e70 7265 6665 7463 6828      r0.prefetch(
+00012750: 7072 6566 6574 6368 5f72 6573 5f6f 6666  prefetch_res_off
+00012760: 7365 7429 3b0a 0a20 2020 2020 2020 2020  set);..         
+00012770: 202f 2f20 7065 7266 6f72 6d73 2022 696e   // performs "in
+00012780: 6e65 7222 2070 726f 6475 6374 730a 2020  ner" products.  
+00012790: 2020 2020 2020 2020 636f 6e73 7420 5268          const Rh
+000127a0: 7353 6361 6c61 722a 2062 6c42 203d 2026  sScalar* blB = &
+000127b0: 626c 6f63 6b42 5b6a 322a 7374 7269 6465  blockB[j2*stride
+000127c0: 422b 6f66 6673 6574 425d 3b0a 2020 2020  B+offsetB];.    
+000127d0: 2020 2020 2020 4c68 7350 6163 6b65 7420        LhsPacket 
+000127e0: 4130 2c20 4131 3b0a 0a20 2020 2020 2020  A0, A1;..       
+000127f0: 2020 2066 6f72 2849 6e64 6578 206b 3d30     for(Index k=0
+00012800: 3b20 6b3c 7065 656c 6564 5f6b 633b 206b  ; k<peeled_kc; k
+00012810: 2b3d 706b 290a 2020 2020 2020 2020 2020  +=pk).          
+00012820: 7b0a 2020 2020 2020 2020 2020 2020 4549  {.            EI
+00012830: 4745 4e5f 4153 4d5f 434f 4d4d 454e 5428  GEN_ASM_COMMENT(
+00012840: 2262 6567 696e 2067 6562 7020 6d69 6372  "begin gebp micr
+00012850: 6f20 6b65 726e 656c 2032 7058 3122 293b  o kernel 2pX1");
+00012860: 0a20 2020 2020 2020 2020 2020 2052 6873  .            Rhs
+00012870: 5061 636b 6574 2042 5f30 2c20 4231 3b0a  Packet B_0, B1;.
+00012880: 2020 2020 2020 2020 0a23 6465 6669 6e65          .#define
+00012890: 2045 4947 454e 5f47 4542 4750 5f4f 4e45   EIGEN_GEBGP_ONE
+000128a0: 5354 4550 284b 2920 5c0a 2020 2020 2020  STEP(K) \.      
+000128b0: 2020 2020 2020 646f 207b 2020 2020 2020        do {      
+000128c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000128d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000128e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000128f0: 2020 2020 2020 2020 2020 2020 5c0a 2020              \.  
+00012900: 2020 2020 2020 2020 2020 2020 4549 4745              EIGE
+00012910: 4e5f 4153 4d5f 434f 4d4d 454e 5428 2262  N_ASM_COMMENT("b
+00012920: 6567 696e 2073 7465 7020 6f66 2067 6562  egin step of geb
+00012930: 7020 6d69 6372 6f20 6b65 726e 656c 2032  p micro kernel 2
+00012940: 7058 3122 293b 2020 2020 2020 2020 2020  pX1");          
+00012950: 5c0a 2020 2020 2020 2020 2020 2020 2020  \.              
+00012960: 4549 4745 4e5f 4153 4d5f 434f 4d4d 454e  EIGEN_ASM_COMMEN
+00012970: 5428 224e 6f74 653a 2074 6865 7365 2061  T("Note: these a
+00012980: 736d 2063 6f6d 6d65 6e74 7320 776f 726b  sm comments work
+00012990: 2061 726f 756e 6420 6275 6720 3933 3521   around bug 935!
+000129a0: 2229 3b20 5c0a 2020 2020 2020 2020 2020  "); \.          
+000129b0: 2020 2020 7472 6169 7473 2e6c 6f61 644c      traits.loadL
+000129c0: 6873 2826 626c 415b 2830 2b32 2a4b 292a  hs(&blA[(0+2*K)*
+000129d0: 4c68 7350 726f 6772 6573 735d 2c20 4130  LhsProgress], A0
+000129e0: 293b 2020 2020 2020 2020 2020 2020 2020  );              
+000129f0: 2020 2020 2020 2020 5c0a 2020 2020 2020          \.      
+00012a00: 2020 2020 2020 2020 7472 6169 7473 2e6c          traits.l
+00012a10: 6f61 644c 6873 2826 626c 415b 2831 2b32  oadLhs(&blA[(1+2
+00012a20: 2a4b 292a 4c68 7350 726f 6772 6573 735d  *K)*LhsProgress]
+00012a30: 2c20 4131 293b 2020 2020 2020 2020 2020  , A1);          
+00012a40: 2020 2020 2020 2020 2020 2020 5c0a 2020              \.  
+00012a50: 2020 2020 2020 2020 2020 2020 7472 6169              trai
+00012a60: 7473 2e6c 6f61 6452 6873 2826 626c 425b  ts.loadRhs(&blB[
+00012a70: 2830 2b4b 292a 5268 7350 726f 6772 6573  (0+K)*RhsProgres
+00012a80: 735d 2c20 425f 3029 3b20 2020 2020 2020  s], B_0);       
+00012a90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012aa0: 5c0a 2020 2020 2020 2020 2020 2020 2020  \.              
+00012ab0: 7472 6169 7473 2e6d 6164 6428 4130 2c20  traits.madd(A0, 
+00012ac0: 425f 302c 2043 302c 2042 312c 2066 6978  B_0, C0, B1, fix
+00012ad0: 3c30 3e29 3b20 2020 2020 2020 2020 2020  <0>);           
+00012ae0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012af0: 2020 2020 5c0a 2020 2020 2020 2020 2020      \.          
+00012b00: 2020 2020 7472 6169 7473 2e6d 6164 6428      traits.madd(
+00012b10: 4131 2c20 425f 302c 2043 342c 2042 5f30  A1, B_0, C4, B_0
+00012b20: 2c20 6669 783c 303e 293b 2020 2020 2020  , fix<0>);      
+00012b30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012b40: 2020 2020 2020 2020 5c0a 2020 2020 2020          \.      
+00012b50: 2020 2020 2020 2020 4549 4745 4e5f 4153          EIGEN_AS
+00012b60: 4d5f 434f 4d4d 454e 5428 2265 6e64 2073  M_COMMENT("end s
+00012b70: 7465 7020 6f66 2067 6562 7020 6d69 6372  tep of gebp micr
+00012b80: 6f20 6b65 726e 656c 2032 7058 3122 293b  o kernel 2pX1");
+00012b90: 2020 2020 2020 2020 2020 2020 5c0a 2020              \.  
+00012ba0: 2020 2020 2020 2020 2020 7d20 7768 696c            } whil
+00012bb0: 6528 6661 6c73 6529 0a20 2020 2020 2020  e(false).       
+00012bc0: 200a 2020 2020 2020 2020 2020 2020 4549   .            EI
+00012bd0: 4745 4e5f 4745 4247 505f 4f4e 4553 5445  GEN_GEBGP_ONESTE
+00012be0: 5028 3029 3b0a 2020 2020 2020 2020 2020  P(0);.          
+00012bf0: 2020 4549 4745 4e5f 4745 4247 505f 4f4e    EIGEN_GEBGP_ON
+00012c00: 4553 5445 5028 3129 3b0a 2020 2020 2020  ESTEP(1);.      
+00012c10: 2020 2020 2020 4549 4745 4e5f 4745 4247        EIGEN_GEBG
+00012c20: 505f 4f4e 4553 5445 5028 3229 3b0a 2020  P_ONESTEP(2);.  
+00012c30: 2020 2020 2020 2020 2020 4549 4745 4e5f            EIGEN_
+00012c40: 4745 4247 505f 4f4e 4553 5445 5028 3329  GEBGP_ONESTEP(3)
+00012c50: 3b0a 2020 2020 2020 2020 2020 2020 4549  ;.            EI
+00012c60: 4745 4e5f 4745 4247 505f 4f4e 4553 5445  GEN_GEBGP_ONESTE
+00012c70: 5028 3429 3b0a 2020 2020 2020 2020 2020  P(4);.          
+00012c80: 2020 4549 4745 4e5f 4745 4247 505f 4f4e    EIGEN_GEBGP_ON
+00012c90: 4553 5445 5028 3529 3b0a 2020 2020 2020  ESTEP(5);.      
+00012ca0: 2020 2020 2020 4549 4745 4e5f 4745 4247        EIGEN_GEBG
+00012cb0: 505f 4f4e 4553 5445 5028 3629 3b0a 2020  P_ONESTEP(6);.  
+00012cc0: 2020 2020 2020 2020 2020 4549 4745 4e5f            EIGEN_
+00012cd0: 4745 4247 505f 4f4e 4553 5445 5028 3729  GEBGP_ONESTEP(7)
+00012ce0: 3b0a 0a20 2020 2020 2020 2020 2020 2062  ;..            b
+00012cf0: 6c42 202b 3d20 696e 7428 706b 2920 2a20  lB += int(pk) * 
+00012d00: 696e 7428 5268 7350 726f 6772 6573 7329  int(RhsProgress)
+00012d10: 3b0a 2020 2020 2020 2020 2020 2020 626c  ;.            bl
+00012d20: 4120 2b3d 2069 6e74 2870 6b29 202a 2032  A += int(pk) * 2
+00012d30: 202a 2069 6e74 2854 7261 6974 733a 3a4c   * int(Traits::L
+00012d40: 6873 5072 6f67 7265 7373 293b 0a0a 2020  hsProgress);..  
+00012d50: 2020 2020 2020 2020 2020 4549 4745 4e5f            EIGEN_
+00012d60: 4153 4d5f 434f 4d4d 454e 5428 2265 6e64  ASM_COMMENT("end
+00012d70: 2067 6562 7020 6d69 6372 6f20 6b65 726e   gebp micro kern
+00012d80: 656c 2032 7058 3122 293b 0a20 2020 2020  el 2pX1");.     
+00012d90: 2020 2020 207d 0a0a 2020 2020 2020 2020       }..        
+00012da0: 2020 2f2f 2070 726f 6365 7373 2072 656d    // process rem
+00012db0: 6169 6e69 6e67 2070 6565 6c65 6420 6c6f  aining peeled lo
+00012dc0: 6f70 0a20 2020 2020 2020 2020 2066 6f72  op.          for
+00012dd0: 2849 6e64 6578 206b 3d70 6565 6c65 645f  (Index k=peeled_
+00012de0: 6b63 3b20 6b3c 6465 7074 683b 206b 2b2b  kc; k<depth; k++
+00012df0: 290a 2020 2020 2020 2020 2020 7b0a 2020  ).          {.  
+00012e00: 2020 2020 2020 2020 2020 5268 7350 6163            RhsPac
+00012e10: 6b65 7420 425f 302c 2042 313b 0a20 2020  ket B_0, B1;.   
+00012e20: 2020 2020 2020 2020 2045 4947 454e 5f47           EIGEN_G
+00012e30: 4542 4750 5f4f 4e45 5354 4550 2830 293b  EBGP_ONESTEP(0);
+00012e40: 0a20 2020 2020 2020 2020 2020 2062 6c42  .            blB
+00012e50: 202b 3d20 5268 7350 726f 6772 6573 733b   += RhsProgress;
+00012e60: 0a20 2020 2020 2020 2020 2020 2062 6c41  .            blA
+00012e70: 202b 3d20 322a 5472 6169 7473 3a3a 4c68   += 2*Traits::Lh
+00012e80: 7350 726f 6772 6573 733b 0a20 2020 2020  sProgress;.     
+00012e90: 2020 2020 207d 0a23 756e 6465 6620 4549       }.#undef EI
+00012ea0: 4745 4e5f 4745 4247 505f 4f4e 4553 5445  GEN_GEBGP_ONESTE
+00012eb0: 500a 2020 2020 2020 2020 2020 5265 7350  P.          ResP
+00012ec0: 6163 6b65 7420 5230 2c20 5231 3b0a 2020  acket R0, R1;.  
+00012ed0: 2020 2020 2020 2020 5265 7350 6163 6b65          ResPacke
+00012ee0: 7420 616c 7068 6176 203d 2070 7365 7431  t alphav = pset1
+00012ef0: 3c52 6573 5061 636b 6574 3e28 616c 7068  <ResPacket>(alph
+00012f00: 6129 3b0a 0a20 2020 2020 2020 2020 2052  a);..          R
+00012f10: 3020 3d20 7230 2e74 656d 706c 6174 6520  0 = r0.template 
+00012f20: 6c6f 6164 5061 636b 6574 3c52 6573 5061  loadPacket<ResPa
+00012f30: 636b 6574 3e28 3020 2a20 5472 6169 7473  cket>(0 * Traits
+00012f40: 3a3a 5265 7350 6163 6b65 7453 697a 6529  ::ResPacketSize)
+00012f50: 3b0a 2020 2020 2020 2020 2020 5231 203d  ;.          R1 =
+00012f60: 2072 302e 7465 6d70 6c61 7465 206c 6f61   r0.template loa
+00012f70: 6450 6163 6b65 743c 5265 7350 6163 6b65  dPacket<ResPacke
+00012f80: 743e 2831 202a 2054 7261 6974 733a 3a52  t>(1 * Traits::R
+00012f90: 6573 5061 636b 6574 5369 7a65 293b 0a20  esPacketSize);. 
+00012fa0: 2020 2020 2020 2020 2074 7261 6974 732e           traits.
+00012fb0: 6163 6328 4330 2c20 616c 7068 6176 2c20  acc(C0, alphav, 
+00012fc0: 5230 293b 0a20 2020 2020 2020 2020 2074  R0);.          t
+00012fd0: 7261 6974 732e 6163 6328 4334 2c20 616c  raits.acc(C4, al
+00012fe0: 7068 6176 2c20 5231 293b 0a20 2020 2020  phav, R1);.     
+00012ff0: 2020 2020 2072 302e 7374 6f72 6550 6163       r0.storePac
+00013000: 6b65 7428 3020 2a20 5472 6169 7473 3a3a  ket(0 * Traits::
+00013010: 5265 7350 6163 6b65 7453 697a 652c 2052  ResPacketSize, R
+00013020: 3029 3b0a 2020 2020 2020 2020 2020 7230  0);.          r0
+00013030: 2e73 746f 7265 5061 636b 6574 2831 202a  .storePacket(1 *
+00013040: 2054 7261 6974 733a 3a52 6573 5061 636b   Traits::ResPack
+00013050: 6574 5369 7a65 2c20 5231 293b 0a20 2020  etSize, R1);.   
+00013060: 2020 2020 2020 207d 0a20 2020 2020 2020         }.       
+00013070: 207d 0a20 2020 2020 207d 0a20 2020 207d   }.      }.    }
+00013080: 0a20 2020 202f 2f2d 2d2d 2d2d 2d2d 2d2d  .    //---------
+00013090: 2d20 5072 6f63 6573 7320 3120 2a20 4c68  - Process 1 * Lh
+000130a0: 7350 726f 6772 6573 7320 726f 7773 2061  sProgress rows a
+000130b0: 7420 6f6e 6365 202d 2d2d 2d2d 2d2d 2d2d  t once ---------
+000130c0: 2d0a 2020 2020 6966 286d 723e 3d31 2a54  -.    if(mr>=1*T
+000130d0: 7261 6974 733a 3a4c 6873 5072 6f67 7265  raits::LhsProgre
+000130e0: 7373 290a 2020 2020 7b0a 2020 2020 2020  ss).    {.      
+000130f0: 6c68 735f 7072 6f63 6573 735f 6f6e 655f  lhs_process_one_
+00013100: 7061 636b 6574 3c6e 722c 204c 6873 5072  packet<nr, LhsPr
+00013110: 6f67 7265 7373 2c20 5268 7350 726f 6772  ogress, RhsProgr
+00013120: 6573 732c 204c 6873 5363 616c 6172 2c20  ess, LhsScalar, 
+00013130: 5268 7353 6361 6c61 722c 2052 6573 5363  RhsScalar, ResSc
+00013140: 616c 6172 2c20 4163 6350 6163 6b65 742c  alar, AccPacket,
+00013150: 204c 6873 5061 636b 6574 2c20 5268 7350   LhsPacket, RhsP
+00013160: 6163 6b65 742c 2052 6573 5061 636b 6574  acket, ResPacket
+00013170: 2c20 5472 6169 7473 2c20 4c69 6e65 6172  , Traits, Linear
+00013180: 4d61 7070 6572 2c20 4461 7461 4d61 7070  Mapper, DataMapp
+00013190: 6572 3e20 703b 0a20 2020 2020 2070 2872  er> p;.      p(r
+000131a0: 6573 2c20 626c 6f63 6b41 2c20 626c 6f63  es, blockA, bloc
+000131b0: 6b42 2c20 616c 7068 612c 2070 6565 6c65  kB, alpha, peele
+000131c0: 645f 6d63 322c 2070 6565 6c65 645f 6d63  d_mc2, peeled_mc
+000131d0: 312c 2073 7472 6964 6541 2c20 7374 7269  1, strideA, stri
+000131e0: 6465 422c 206f 6666 7365 7441 2c20 6f66  deB, offsetA, of
+000131f0: 6673 6574 422c 2070 7265 6665 7463 685f  fsetB, prefetch_
+00013200: 7265 735f 6f66 6673 6574 2c20 7065 656c  res_offset, peel
+00013210: 6564 5f6b 632c 2070 6b2c 2063 6f6c 732c  ed_kc, pk, cols,
+00013220: 2064 6570 7468 2c20 7061 636b 6574 5f63   depth, packet_c
+00013230: 6f6c 7334 293b 0a20 2020 207d 0a20 2020  ols4);.    }.   
+00013240: 202f 2f2d 2d2d 2d2d 2d2d 2d2d 2d20 5072   //---------- Pr
+00013250: 6f63 6573 7320 4c68 7350 726f 6772 6573  ocess LhsProgres
+00013260: 7348 616c 6620 726f 7773 2061 7420 6f6e  sHalf rows at on
+00013270: 6365 202d 2d2d 2d2d 2d2d 2d2d 2d0a 2020  ce ----------.  
+00013280: 2020 6966 2828 4c68 7350 726f 6772 6573    if((LhsProgres
+00013290: 7348 616c 6620 3c20 4c68 7350 726f 6772  sHalf < LhsProgr
+000132a0: 6573 7329 2026 2620 6d72 3e3d 4c68 7350  ess) && mr>=LhsP
+000132b0: 726f 6772 6573 7348 616c 6629 0a20 2020  rogressHalf).   
+000132c0: 207b 0a20 2020 2020 206c 6873 5f70 726f   {.      lhs_pro
+000132d0: 6365 7373 5f66 7261 6374 696f 6e5f 6f66  cess_fraction_of
+000132e0: 5f70 6163 6b65 743c 6e72 2c20 4c68 7350  _packet<nr, LhsP
+000132f0: 726f 6772 6573 7348 616c 662c 2052 6873  rogressHalf, Rhs
+00013300: 5072 6f67 7265 7373 4861 6c66 2c20 4c68  ProgressHalf, Lh
+00013310: 7353 6361 6c61 722c 2052 6873 5363 616c  sScalar, RhsScal
+00013320: 6172 2c20 5265 7353 6361 6c61 722c 2041  ar, ResScalar, A
+00013330: 6363 5061 636b 6574 4861 6c66 2c20 4c68  ccPacketHalf, Lh
+00013340: 7350 6163 6b65 7448 616c 662c 2052 6873  sPacketHalf, Rhs
+00013350: 5061 636b 6574 4861 6c66 2c20 5265 7350  PacketHalf, ResP
+00013360: 6163 6b65 7448 616c 662c 2048 616c 6654  acketHalf, HalfT
+00013370: 7261 6974 732c 204c 696e 6561 724d 6170  raits, LinearMap
+00013380: 7065 722c 2044 6174 614d 6170 7065 723e  per, DataMapper>
+00013390: 2070 3b0a 2020 2020 2020 7028 7265 732c   p;.      p(res,
+000133a0: 2062 6c6f 636b 412c 2062 6c6f 636b 422c   blockA, blockB,
+000133b0: 2061 6c70 6861 2c20 7065 656c 6564 5f6d   alpha, peeled_m
+000133c0: 6331 2c20 7065 656c 6564 5f6d 635f 6861  c1, peeled_mc_ha
+000133d0: 6c66 2c20 7374 7269 6465 412c 2073 7472  lf, strideA, str
+000133e0: 6964 6542 2c20 6f66 6673 6574 412c 206f  ideB, offsetA, o
+000133f0: 6666 7365 7442 2c20 7072 6566 6574 6368  ffsetB, prefetch
+00013400: 5f72 6573 5f6f 6666 7365 742c 2070 6565  _res_offset, pee
+00013410: 6c65 645f 6b63 2c20 706b 2c20 636f 6c73  led_kc, pk, cols
+00013420: 2c20 6465 7074 682c 2070 6163 6b65 745f  , depth, packet_
+00013430: 636f 6c73 3429 3b0a 2020 2020 7d0a 2020  cols4);.    }.  
+00013440: 2020 2f2f 2d2d 2d2d 2d2d 2d2d 2d2d 2050    //---------- P
+00013450: 726f 6365 7373 204c 6873 5072 6f67 7265  rocess LhsProgre
+00013460: 7373 5175 6172 7465 7220 726f 7773 2061  ssQuarter rows a
+00013470: 7420 6f6e 6365 202d 2d2d 2d2d 2d2d 2d2d  t once ---------
+00013480: 2d0a 2020 2020 6966 2828 4c68 7350 726f  -.    if((LhsPro
+00013490: 6772 6573 7351 7561 7274 6572 203c 204c  gressQuarter < L
+000134a0: 6873 5072 6f67 7265 7373 4861 6c66 2920  hsProgressHalf) 
+000134b0: 2626 206d 723e 3d4c 6873 5072 6f67 7265  && mr>=LhsProgre
+000134c0: 7373 5175 6172 7465 7229 0a20 2020 207b  ssQuarter).    {
+000134d0: 0a20 2020 2020 206c 6873 5f70 726f 6365  .      lhs_proce
+000134e0: 7373 5f66 7261 6374 696f 6e5f 6f66 5f70  ss_fraction_of_p
+000134f0: 6163 6b65 743c 6e72 2c20 4c68 7350 726f  acket<nr, LhsPro
+00013500: 6772 6573 7351 7561 7274 6572 2c20 5268  gressQuarter, Rh
+00013510: 7350 726f 6772 6573 7351 7561 7274 6572  sProgressQuarter
+00013520: 2c20 4c68 7353 6361 6c61 722c 2052 6873  , LhsScalar, Rhs
+00013530: 5363 616c 6172 2c20 5265 7353 6361 6c61  Scalar, ResScala
+00013540: 722c 2041 6363 5061 636b 6574 5175 6172  r, AccPacketQuar
+00013550: 7465 722c 204c 6873 5061 636b 6574 5175  ter, LhsPacketQu
+00013560: 6172 7465 722c 2052 6873 5061 636b 6574  arter, RhsPacket
+00013570: 5175 6172 7465 722c 2052 6573 5061 636b  Quarter, ResPack
+00013580: 6574 5175 6172 7465 722c 2051 7561 7274  etQuarter, Quart
+00013590: 6572 5472 6169 7473 2c20 4c69 6e65 6172  erTraits, Linear
+000135a0: 4d61 7070 6572 2c20 4461 7461 4d61 7070  Mapper, DataMapp
+000135b0: 6572 3e20 703b 0a20 2020 2020 2070 2872  er> p;.      p(r
+000135c0: 6573 2c20 626c 6f63 6b41 2c20 626c 6f63  es, blockA, bloc
+000135d0: 6b42 2c20 616c 7068 612c 2070 6565 6c65  kB, alpha, peele
+000135e0: 645f 6d63 5f68 616c 662c 2070 6565 6c65  d_mc_half, peele
+000135f0: 645f 6d63 5f71 7561 7274 6572 2c20 7374  d_mc_quarter, st
+00013600: 7269 6465 412c 2073 7472 6964 6542 2c20  rideA, strideB, 
+00013610: 6f66 6673 6574 412c 206f 6666 7365 7442  offsetA, offsetB
+00013620: 2c20 7072 6566 6574 6368 5f72 6573 5f6f  , prefetch_res_o
+00013630: 6666 7365 742c 2070 6565 6c65 645f 6b63  ffset, peeled_kc
+00013640: 2c20 706b 2c20 636f 6c73 2c20 6465 7074  , pk, cols, dept
+00013650: 682c 2070 6163 6b65 745f 636f 6c73 3429  h, packet_cols4)
+00013660: 3b0a 2020 2020 7d0a 2020 2020 2f2f 2d2d  ;.    }.    //--
+00013670: 2d2d 2d2d 2d2d 2d2d 2050 726f 6365 7373  -------- Process
+00013680: 2072 656d 6169 6e69 6e67 2072 6f77 732c   remaining rows,
+00013690: 2031 2061 7420 6f6e 6365 202d 2d2d 2d2d   1 at once -----
+000136a0: 2d2d 2d2d 2d0a 2020 2020 6966 2870 6565  -----.    if(pee
+000136b0: 6c65 645f 6d63 5f71 7561 7274 6572 3c72  led_mc_quarter<r
+000136c0: 6f77 7329 0a20 2020 207b 0a20 2020 2020  ows).    {.     
+000136d0: 202f 2f20 6c6f 6f70 206f 6e20 6561 6368   // loop on each
+000136e0: 2070 616e 656c 206f 6620 7468 6520 7268   panel of the rh
+000136f0: 730a 2020 2020 2020 666f 7228 496e 6465  s.      for(Inde
+00013700: 7820 6a32 3d30 3b20 6a32 3c70 6163 6b65  x j2=0; j2<packe
+00013710: 745f 636f 6c73 343b 206a 322b 3d6e 7229  t_cols4; j2+=nr)
+00013720: 0a20 2020 2020 207b 0a20 2020 2020 2020  .      {.       
+00013730: 202f 2f20 6c6f 6f70 206f 6e20 6561 6368   // loop on each
+00013740: 2072 6f77 206f 6620 7468 6520 6c68 7320   row of the lhs 
+00013750: 2831 2a4c 6873 5072 6f67 7265 7373 2078  (1*LhsProgress x
+00013760: 2064 6570 7468 290a 2020 2020 2020 2020   depth).        
+00013770: 666f 7228 496e 6465 7820 693d 7065 656c  for(Index i=peel
+00013780: 6564 5f6d 635f 7175 6172 7465 723b 2069  ed_mc_quarter; i
+00013790: 3c72 6f77 733b 2069 2b3d 3129 0a20 2020  <rows; i+=1).   
+000137a0: 2020 2020 207b 0a20 2020 2020 2020 2020       {.         
+000137b0: 2063 6f6e 7374 204c 6873 5363 616c 6172   const LhsScalar
+000137c0: 2a20 626c 4120 3d20 2662 6c6f 636b 415b  * blA = &blockA[
+000137d0: 692a 7374 7269 6465 412b 6f66 6673 6574  i*strideA+offset
+000137e0: 415d 3b0a 2020 2020 2020 2020 2020 7072  A];.          pr
+000137f0: 6566 6574 6368 2826 626c 415b 305d 293b  efetch(&blA[0]);
+00013800: 0a20 2020 2020 2020 2020 2063 6f6e 7374  .          const
+00013810: 2052 6873 5363 616c 6172 2a20 626c 4220   RhsScalar* blB 
+00013820: 3d20 2662 6c6f 636b 425b 6a32 2a73 7472  = &blockB[j2*str
+00013830: 6964 6542 2b6f 6666 7365 7442 2a6e 725d  ideB+offsetB*nr]
+00013840: 3b0a 0a20 2020 2020 2020 2020 202f 2f20  ;..          // 
+00013850: 4966 204c 6873 5072 6f67 7265 7373 2069  If LhsProgress i
+00013860: 7320 3820 6f72 2031 362c 2069 7420 6173  s 8 or 16, it as
+00013870: 7375 6d65 7320 7468 6174 2074 6865 7265  sumes that there
+00013880: 2069 7320 610a 2020 2020 2020 2020 2020   is a.          
+00013890: 2f2f 2068 616c 6620 6f72 2071 7561 7274  // half or quart
+000138a0: 6572 2070 6163 6b65 742c 2072 6573 7065  er packet, respe
+000138b0: 6374 6976 656c 792c 206f 6620 7468 6520  ctively, of the 
+000138c0: 7361 6d65 2073 697a 6520 6173 0a20 2020  same size as.   
+000138d0: 2020 2020 2020 202f 2f20 6e72 2028 7768         // nr (wh
+000138e0: 6963 6820 6973 2063 7572 7265 6e74 6c79  ich is currently
+000138f0: 2034 2920 666f 7220 7468 6520 7265 7475   4) for the retu
+00013900: 726e 2074 7970 652e 0a20 2020 2020 2020  rn type..       
+00013910: 2020 2063 6f6e 7374 2069 6e74 2053 5265     const int SRe
+00013920: 7350 6163 6b65 7448 616c 6653 697a 6520  sPacketHalfSize 
+00013930: 3d20 756e 7061 636b 6574 5f74 7261 6974  = unpacket_trait
+00013940: 733c 7479 7065 6e61 6d65 2075 6e70 6163  s<typename unpac
+00013950: 6b65 745f 7472 6169 7473 3c53 5265 7350  ket_traits<SResP
+00013960: 6163 6b65 743e 3a3a 6861 6c66 3e3a 3a73  acket>::half>::s
+00013970: 697a 653b 0a20 2020 2020 2020 2020 2063  ize;.          c
+00013980: 6f6e 7374 2069 6e74 2053 5265 7350 6163  onst int SResPac
+00013990: 6b65 7451 7561 7274 6572 5369 7a65 203d  ketQuarterSize =
+000139a0: 2075 6e70 6163 6b65 745f 7472 6169 7473   unpacket_traits
+000139b0: 3c74 7970 656e 616d 6520 756e 7061 636b  <typename unpack
+000139c0: 6574 5f74 7261 6974 733c 7479 7065 6e61  et_traits<typena
+000139d0: 6d65 2075 6e70 6163 6b65 745f 7472 6169  me unpacket_trai
+000139e0: 7473 3c53 5265 7350 6163 6b65 743e 3a3a  ts<SResPacket>::
+000139f0: 6861 6c66 3e3a 3a68 616c 663e 3a3a 7369  half>::half>::si
+00013a00: 7a65 3b0a 2020 2020 2020 2020 2020 6966  ze;.          if
+00013a10: 2028 2853 7761 7070 6564 5472 6169 7473   ((SwappedTraits
+00013a20: 3a3a 4c68 7350 726f 6772 6573 7320 2520  ::LhsProgress % 
+00013a30: 3429 203d 3d20 3020 2626 0a20 2020 2020  4) == 0 &&.     
+00013a40: 2020 2020 2020 2020 2028 5377 6170 7065           (Swappe
+00013a50: 6454 7261 6974 733a 3a4c 6873 5072 6f67  dTraits::LhsProg
+00013a60: 7265 7373 3c3d 3136 2920 2626 0a20 2020  ress<=16) &&.   
+00013a70: 2020 2020 2020 2020 2020 2028 5377 6170             (Swap
+00013a80: 7065 6454 7261 6974 733a 3a4c 6873 5072  pedTraits::LhsPr
+00013a90: 6f67 7265 7373 213d 3820 207c 7c20 5352  ogress!=8  || SR
+00013aa0: 6573 5061 636b 6574 4861 6c66 5369 7a65  esPacketHalfSize
+00013ab0: 3d3d 6e72 2920 2626 0a20 2020 2020 2020  ==nr) &&.       
+00013ac0: 2020 2020 2020 2028 5377 6170 7065 6454         (SwappedT
+00013ad0: 7261 6974 733a 3a4c 6873 5072 6f67 7265  raits::LhsProgre
+00013ae0: 7373 213d 3136 207c 7c20 5352 6573 5061  ss!=16 || SResPa
+00013af0: 636b 6574 5175 6172 7465 7253 697a 653d  cketQuarterSize=
+00013b00: 3d6e 7229 290a 2020 2020 2020 2020 2020  =nr)).          
+00013b10: 7b0a 2020 2020 2020 2020 2020 2020 5341  {.            SA
+00013b20: 6363 5061 636b 6574 2043 302c 2043 312c  ccPacket C0, C1,
+00013b30: 2043 322c 2043 333b 0a20 2020 2020 2020   C2, C3;.       
+00013b40: 2020 2020 2073 7472 6169 7473 2e69 6e69       straits.ini
+00013b50: 7441 6363 2843 3029 3b0a 2020 2020 2020  tAcc(C0);.      
+00013b60: 2020 2020 2020 7374 7261 6974 732e 696e        straits.in
+00013b70: 6974 4163 6328 4331 293b 0a20 2020 2020  itAcc(C1);.     
+00013b80: 2020 2020 2020 2073 7472 6169 7473 2e69         straits.i
+00013b90: 6e69 7441 6363 2843 3229 3b0a 2020 2020  nitAcc(C2);.    
+00013ba0: 2020 2020 2020 2020 7374 7261 6974 732e          straits.
+00013bb0: 696e 6974 4163 6328 4333 293b 0a0a 2020  initAcc(C3);..  
+00013bc0: 2020 2020 2020 2020 2020 636f 6e73 7420            const 
+00013bd0: 496e 6465 7820 7370 6b20 2020 3d20 2873  Index spk   = (s
+00013be0: 7464 3a3a 6d61 7829 2831 2c53 7761 7070  td::max)(1,Swapp
+00013bf0: 6564 5472 6169 7473 3a3a 4c68 7350 726f  edTraits::LhsPro
+00013c00: 6772 6573 732f 3429 3b0a 2020 2020 2020  gress/4);.      
+00013c10: 2020 2020 2020 636f 6e73 7420 496e 6465        const Inde
+00013c20: 7820 656e 646b 2020 3d20 2864 6570 7468  x endk  = (depth
+00013c30: 2f73 706b 292a 7370 6b3b 0a20 2020 2020  /spk)*spk;.     
+00013c40: 2020 2020 2020 2063 6f6e 7374 2049 6e64         const Ind
+00013c50: 6578 2065 6e64 6b34 203d 2028 6465 7074  ex endk4 = (dept
+00013c60: 682f 2873 706b 2a34 2929 2a28 7370 6b2a  h/(spk*4))*(spk*
+00013c70: 3429 3b0a 0a20 2020 2020 2020 2020 2020  4);..           
+00013c80: 2049 6e64 6578 206b 3d30 3b0a 2020 2020   Index k=0;.    
+00013c90: 2020 2020 2020 2020 666f 7228 3b20 6b3c          for(; k<
+00013ca0: 656e 646b 343b 206b 2b3d 342a 7370 6b29  endk4; k+=4*spk)
+00013cb0: 0a20 2020 2020 2020 2020 2020 207b 0a20  .            {. 
+00013cc0: 2020 2020 2020 2020 2020 2020 2053 4c68               SLh
+00013cd0: 7350 6163 6b65 7420 4130 2c41 313b 0a20  sPacket A0,A1;. 
+00013ce0: 2020 2020 2020 2020 2020 2020 2053 5268               SRh
+00013cf0: 7350 6163 6b65 7420 425f 302c 425f 313b  sPacket B_0,B_1;
+00013d00: 0a0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00013d10: 7374 7261 6974 732e 6c6f 6164 4c68 7355  straits.loadLhsU
+00013d20: 6e61 6c69 676e 6564 2862 6c42 2b30 2a53  naligned(blB+0*S
+00013d30: 7761 7070 6564 5472 6169 7473 3a3a 4c68  wappedTraits::Lh
+00013d40: 7350 726f 6772 6573 732c 2041 3029 3b0a  sProgress, A0);.
+00013d50: 2020 2020 2020 2020 2020 2020 2020 7374                st
+00013d60: 7261 6974 732e 6c6f 6164 4c68 7355 6e61  raits.loadLhsUna
+00013d70: 6c69 676e 6564 2862 6c42 2b31 2a53 7761  ligned(blB+1*Swa
+00013d80: 7070 6564 5472 6169 7473 3a3a 4c68 7350  ppedTraits::LhsP
+00013d90: 726f 6772 6573 732c 2041 3129 3b0a 0a20  rogress, A1);.. 
+00013da0: 2020 2020 2020 2020 2020 2020 2073 7472               str
+00013db0: 6169 7473 2e6c 6f61 6452 6873 5175 6164  aits.loadRhsQuad
+00013dc0: 2862 6c41 2b30 2a73 706b 2c20 425f 3029  (blA+0*spk, B_0)
+00013dd0: 3b0a 2020 2020 2020 2020 2020 2020 2020  ;.              
+00013de0: 7374 7261 6974 732e 6c6f 6164 5268 7351  straits.loadRhsQ
+00013df0: 7561 6428 626c 412b 312a 7370 6b2c 2042  uad(blA+1*spk, B
+00013e00: 5f31 293b 0a20 2020 2020 2020 2020 2020  _1);.           
+00013e10: 2020 2073 7472 6169 7473 2e6d 6164 6428     straits.madd(
+00013e20: 4130 2c42 5f30 2c43 302c 425f 302c 2066  A0,B_0,C0,B_0, f
+00013e30: 6978 3c30 3e29 3b0a 2020 2020 2020 2020  ix<0>);.        
+00013e40: 2020 2020 2020 7374 7261 6974 732e 6d61        straits.ma
+00013e50: 6464 2841 312c 425f 312c 4331 2c42 5f31  dd(A1,B_1,C1,B_1
+00013e60: 2c20 6669 783c 303e 293b 0a0a 2020 2020  , fix<0>);..    
+00013e70: 2020 2020 2020 2020 2020 7374 7261 6974            strait
+00013e80: 732e 6c6f 6164 4c68 7355 6e61 6c69 676e  s.loadLhsUnalign
+00013e90: 6564 2862 6c42 2b32 2a53 7761 7070 6564  ed(blB+2*Swapped
+00013ea0: 5472 6169 7473 3a3a 4c68 7350 726f 6772  Traits::LhsProgr
+00013eb0: 6573 732c 2041 3029 3b0a 2020 2020 2020  ess, A0);.      
+00013ec0: 2020 2020 2020 2020 7374 7261 6974 732e          straits.
+00013ed0: 6c6f 6164 4c68 7355 6e61 6c69 676e 6564  loadLhsUnaligned
+00013ee0: 2862 6c42 2b33 2a53 7761 7070 6564 5472  (blB+3*SwappedTr
+00013ef0: 6169 7473 3a3a 4c68 7350 726f 6772 6573  aits::LhsProgres
+00013f00: 732c 2041 3129 3b0a 2020 2020 2020 2020  s, A1);.        
+00013f10: 2020 2020 2020 7374 7261 6974 732e 6c6f        straits.lo
+00013f20: 6164 5268 7351 7561 6428 626c 412b 322a  adRhsQuad(blA+2*
+00013f30: 7370 6b2c 2042 5f30 293b 0a20 2020 2020  spk, B_0);.     
+00013f40: 2020 2020 2020 2020 2073 7472 6169 7473           straits
+00013f50: 2e6c 6f61 6452 6873 5175 6164 2862 6c41  .loadRhsQuad(blA
+00013f60: 2b33 2a73 706b 2c20 425f 3129 3b0a 2020  +3*spk, B_1);.  
+00013f70: 2020 2020 2020 2020 2020 2020 7374 7261              stra
+00013f80: 6974 732e 6d61 6464 2841 302c 425f 302c  its.madd(A0,B_0,
+00013f90: 4332 2c42 5f30 2c20 6669 783c 303e 293b  C2,B_0, fix<0>);
+00013fa0: 0a20 2020 2020 2020 2020 2020 2020 2073  .              s
+00013fb0: 7472 6169 7473 2e6d 6164 6428 4131 2c42  traits.madd(A1,B
+00013fc0: 5f31 2c43 332c 425f 312c 2066 6978 3c30  _1,C3,B_1, fix<0
+00013fd0: 3e29 3b0a 0a20 2020 2020 2020 2020 2020  >);..           
+00013fe0: 2020 2062 6c42 202b 3d20 342a 5377 6170     blB += 4*Swap
+00013ff0: 7065 6454 7261 6974 733a 3a4c 6873 5072  pedTraits::LhsPr
+00014000: 6f67 7265 7373 3b0a 2020 2020 2020 2020  ogress;.        
+00014010: 2020 2020 2020 626c 4120 2b3d 2034 2a73        blA += 4*s
+00014020: 706b 3b0a 2020 2020 2020 2020 2020 2020  pk;.            
+00014030: 7d0a 2020 2020 2020 2020 2020 2020 4330  }.            C0
+00014040: 203d 2070 6164 6428 7061 6464 2843 302c   = padd(padd(C0,
+00014050: 4331 292c 7061 6464 2843 322c 4333 2929  C1),padd(C2,C3))
+00014060: 3b0a 2020 2020 2020 2020 2020 2020 666f  ;.            fo
+00014070: 7228 3b20 6b3c 656e 646b 3b20 6b2b 3d73  r(; k<endk; k+=s
+00014080: 706b 290a 2020 2020 2020 2020 2020 2020  pk).            
+00014090: 7b0a 2020 2020 2020 2020 2020 2020 2020  {.              
+000140a0: 534c 6873 5061 636b 6574 2041 303b 0a20  SLhsPacket A0;. 
+000140b0: 2020 2020 2020 2020 2020 2020 2053 5268               SRh
+000140c0: 7350 6163 6b65 7420 425f 303b 0a0a 2020  sPacket B_0;..  
+000140d0: 2020 2020 2020 2020 2020 2020 7374 7261              stra
+000140e0: 6974 732e 6c6f 6164 4c68 7355 6e61 6c69  its.loadLhsUnali
+000140f0: 676e 6564 2862 6c42 2c20 4130 293b 0a20  gned(blB, A0);. 
+00014100: 2020 2020 2020 2020 2020 2020 2073 7472               str
+00014110: 6169 7473 2e6c 6f61 6452 6873 5175 6164  aits.loadRhsQuad
+00014120: 2862 6c41 2c20 425f 3029 3b0a 2020 2020  (blA, B_0);.    
+00014130: 2020 2020 2020 2020 2020 7374 7261 6974            strait
+00014140: 732e 6d61 6464 2841 302c 425f 302c 4330  s.madd(A0,B_0,C0
+00014150: 2c42 5f30 2c20 6669 783c 303e 293b 0a0a  ,B_0, fix<0>);..
+00014160: 2020 2020 2020 2020 2020 2020 2020 626c                bl
+00014170: 4220 2b3d 2053 7761 7070 6564 5472 6169  B += SwappedTrai
+00014180: 7473 3a3a 4c68 7350 726f 6772 6573 733b  ts::LhsProgress;
+00014190: 0a20 2020 2020 2020 2020 2020 2020 2062  .              b
+000141a0: 6c41 202b 3d20 7370 6b3b 0a20 2020 2020  lA += spk;.     
+000141b0: 2020 2020 2020 207d 0a20 2020 2020 2020         }.       
+000141c0: 2020 2020 2069 6628 5377 6170 7065 6454       if(SwappedT
+000141d0: 7261 6974 733a 3a4c 6873 5072 6f67 7265  raits::LhsProgre
+000141e0: 7373 3d3d 3829 0a20 2020 2020 2020 2020  ss==8).         
+000141f0: 2020 207b 0a20 2020 2020 2020 2020 2020     {.           
+00014200: 2020 202f 2f20 5370 6563 6961 6c20 6361     // Special ca
+00014210: 7365 2077 6865 7265 2077 6520 6861 7665  se where we have
+00014220: 2074 6f20 6669 7273 7420 7265 6475 6365   to first reduce
+00014230: 2074 6865 2061 6363 756d 756c 6174 696f   the accumulatio
+00014240: 6e20 7265 6769 7374 6572 2043 300a 2020  n register C0.  
+00014250: 2020 2020 2020 2020 2020 2020 7479 7065              type
+00014260: 6465 6620 7479 7065 6e61 6d65 2063 6f6e  def typename con
+00014270: 6469 7469 6f6e 616c 3c53 7761 7070 6564  ditional<Swapped
+00014280: 5472 6169 7473 3a3a 4c68 7350 726f 6772  Traits::LhsProgr
+00014290: 6573 733e 3d38 2c74 7970 656e 616d 6520  ess>=8,typename 
+000142a0: 756e 7061 636b 6574 5f74 7261 6974 733c  unpacket_traits<
+000142b0: 5352 6573 5061 636b 6574 3e3a 3a68 616c  SResPacket>::hal
+000142c0: 662c 5352 6573 5061 636b 6574 3e3a 3a74  f,SResPacket>::t
+000142d0: 7970 6520 5352 6573 5061 636b 6574 4861  ype SResPacketHa
+000142e0: 6c66 3b0a 2020 2020 2020 2020 2020 2020  lf;.            
+000142f0: 2020 7479 7065 6465 6620 7479 7065 6e61    typedef typena
+00014300: 6d65 2063 6f6e 6469 7469 6f6e 616c 3c53  me conditional<S
+00014310: 7761 7070 6564 5472 6169 7473 3a3a 4c68  wappedTraits::Lh
+00014320: 7350 726f 6772 6573 733e 3d38 2c74 7970  sProgress>=8,typ
+00014330: 656e 616d 6520 756e 7061 636b 6574 5f74  ename unpacket_t
+00014340: 7261 6974 733c 534c 6873 5061 636b 6574  raits<SLhsPacket
+00014350: 3e3a 3a68 616c 662c 534c 6873 5061 636b  >::half,SLhsPack
+00014360: 6574 3e3a 3a74 7970 6520 534c 6873 5061  et>::type SLhsPa
+00014370: 636b 6574 4861 6c66 3b0a 2020 2020 2020  cketHalf;.      
+00014380: 2020 2020 2020 2020 7479 7065 6465 6620          typedef 
+00014390: 7479 7065 6e61 6d65 2063 6f6e 6469 7469  typename conditi
+000143a0: 6f6e 616c 3c53 7761 7070 6564 5472 6169  onal<SwappedTrai
+000143b0: 7473 3a3a 4c68 7350 726f 6772 6573 733e  ts::LhsProgress>
+000143c0: 3d38 2c74 7970 656e 616d 6520 756e 7061  =8,typename unpa
+000143d0: 636b 6574 5f74 7261 6974 733c 5352 6873  cket_traits<SRhs
+000143e0: 5061 636b 6574 3e3a 3a68 616c 662c 5352  Packet>::half,SR
+000143f0: 6873 5061 636b 6574 3e3a 3a74 7970 6520  hsPacket>::type 
+00014400: 5352 6873 5061 636b 6574 4861 6c66 3b0a  SRhsPacketHalf;.
+00014410: 2020 2020 2020 2020 2020 2020 2020 7479                ty
+00014420: 7065 6465 6620 7479 7065 6e61 6d65 2063  pedef typename c
+00014430: 6f6e 6469 7469 6f6e 616c 3c53 7761 7070  onditional<Swapp
+00014440: 6564 5472 6169 7473 3a3a 4c68 7350 726f  edTraits::LhsPro
+00014450: 6772 6573 733e 3d38 2c74 7970 656e 616d  gress>=8,typenam
+00014460: 6520 756e 7061 636b 6574 5f74 7261 6974  e unpacket_trait
+00014470: 733c 5341 6363 5061 636b 6574 3e3a 3a68  s<SAccPacket>::h
+00014480: 616c 662c 5341 6363 5061 636b 6574 3e3a  alf,SAccPacket>:
+00014490: 3a74 7970 6520 5341 6363 5061 636b 6574  :type SAccPacket
+000144a0: 4861 6c66 3b0a 0a20 2020 2020 2020 2020  Half;..         
+000144b0: 2020 2020 2053 5265 7350 6163 6b65 7448       SResPacketH
+000144c0: 616c 6620 5220 3d20 7265 732e 7465 6d70  alf R = res.temp
+000144d0: 6c61 7465 2067 6174 6865 7250 6163 6b65  late gatherPacke
+000144e0: 743c 5352 6573 5061 636b 6574 4861 6c66  t<SResPacketHalf
+000144f0: 3e28 692c 206a 3229 3b0a 2020 2020 2020  >(i, j2);.      
+00014500: 2020 2020 2020 2020 5352 6573 5061 636b          SResPack
+00014510: 6574 4861 6c66 2061 6c70 6861 7620 3d20  etHalf alphav = 
+00014520: 7073 6574 313c 5352 6573 5061 636b 6574  pset1<SResPacket
+00014530: 4861 6c66 3e28 616c 7068 6129 3b0a 0a20  Half>(alpha);.. 
+00014540: 2020 2020 2020 2020 2020 2020 2069 6628               if(
+00014550: 6465 7074 682d 656e 646b 3e30 290a 2020  depth-endk>0).  
+00014560: 2020 2020 2020 2020 2020 2020 7b0a 2020              {.  
+00014570: 2020 2020 2020 2020 2020 2020 2020 2f2f                //
+00014580: 2057 6520 6861 7665 2074 6f20 6861 6e64   We have to hand
+00014590: 6c65 2074 6865 206c 6173 7420 726f 7720  le the last row 
+000145a0: 6f66 2074 6865 2072 6873 2077 6869 6368  of the rhs which
+000145b0: 2063 6f72 7265 7370 6f6e 6473 2074 6f20   corresponds to 
+000145c0: 6120 6861 6c66 2d70 6163 6b65 740a 2020  a half-packet.  
+000145d0: 2020 2020 2020 2020 2020 2020 2020 534c                SL
+000145e0: 6873 5061 636b 6574 4861 6c66 2061 303b  hsPacketHalf a0;
+000145f0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00014600: 2053 5268 7350 6163 6b65 7448 616c 6620   SRhsPacketHalf 
+00014610: 6230 3b0a 2020 2020 2020 2020 2020 2020  b0;.            
+00014620: 2020 2020 7374 7261 6974 732e 6c6f 6164      straits.load
+00014630: 4c68 7355 6e61 6c69 676e 6564 2862 6c42  LhsUnaligned(blB
+00014640: 2c20 6130 293b 0a20 2020 2020 2020 2020  , a0);.         
+00014650: 2020 2020 2020 2073 7472 6169 7473 2e6c         straits.l
+00014660: 6f61 6452 6873 2862 6c41 2c20 6230 293b  oadRhs(blA, b0);
+00014670: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00014680: 2053 4163 6350 6163 6b65 7448 616c 6620   SAccPacketHalf 
+00014690: 6330 203d 2070 7265 6475 785f 6861 6c66  c0 = predux_half
+000146a0: 5f64 6f77 746f 3428 4330 293b 0a20 2020  _dowto4(C0);.   
+000146b0: 2020 2020 2020 2020 2020 2020 2073 7472               str
+000146c0: 6169 7473 2e6d 6164 6428 6130 2c62 302c  aits.madd(a0,b0,
+000146d0: 6330 2c62 302c 2066 6978 3c30 3e29 3b0a  c0,b0, fix<0>);.
+000146e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000146f0: 7374 7261 6974 732e 6163 6328 6330 2c20  straits.acc(c0, 
+00014700: 616c 7068 6176 2c20 5229 3b0a 2020 2020  alphav, R);.    
+00014710: 2020 2020 2020 2020 2020 7d0a 2020 2020            }.    
+00014720: 2020 2020 2020 2020 2020 656c 7365 0a20            else. 
+00014730: 2020 2020 2020 2020 2020 2020 207b 0a20               {. 
+00014740: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+00014750: 7472 6169 7473 2e61 6363 2870 7265 6475  traits.acc(predu
+00014760: 785f 6861 6c66 5f64 6f77 746f 3428 4330  x_half_dowto4(C0
+00014770: 292c 2061 6c70 6861 762c 2052 293b 0a20  ), alphav, R);. 
+00014780: 2020 2020 2020 2020 2020 2020 207d 0a20               }. 
+00014790: 2020 2020 2020 2020 2020 2020 2072 6573               res
+000147a0: 2e73 6361 7474 6572 5061 636b 6574 2869  .scatterPacket(i
+000147b0: 2c20 6a32 2c20 5229 3b0a 2020 2020 2020  , j2, R);.      
+000147c0: 2020 2020 2020 7d0a 2020 2020 2020 2020        }.        
+000147d0: 2020 2020 656c 7365 2069 6620 2853 7761      else if (Swa
+000147e0: 7070 6564 5472 6169 7473 3a3a 4c68 7350  ppedTraits::LhsP
+000147f0: 726f 6772 6573 733d 3d31 3629 0a20 2020  rogress==16).   
+00014800: 2020 2020 2020 2020 207b 0a20 2020 2020           {.     
+00014810: 2020 2020 2020 2020 202f 2f20 5370 6563           // Spec
+00014820: 6961 6c20 6361 7365 2077 6865 7265 2077  ial case where w
+00014830: 6520 6861 7665 2074 6f20 6669 7273 7420  e have to first 
+00014840: 7265 6475 6365 2074 6865 0a20 2020 2020  reduce the.     
+00014850: 2020 2020 2020 2020 202f 2f20 6163 6375           // accu
+00014860: 6d75 6c61 7469 6f6e 2072 6567 6973 7465  mulation registe
+00014870: 7220 4330 2e20 5765 2073 7065 6369 616c  r C0. We special
+00014880: 697a 6520 7468 6520 626c 6f63 6b20 696e  ize the block in
+00014890: 0a20 2020 2020 2020 2020 2020 2020 202f  .              /
+000148a0: 2f20 7465 6d70 6c61 7465 2066 6f72 6d2c  / template form,
+000148b0: 2073 6f20 7468 6174 204c 6873 5072 6f67   so that LhsProg
+000148c0: 7265 7373 203c 2031 3620 7061 7468 7320  ress < 16 paths 
+000148d0: 646f 6e27 740a 2020 2020 2020 2020 2020  don't.          
+000148e0: 2020 2020 2f2f 2066 6169 6c20 746f 2063      // fail to c
+000148f0: 6f6d 7069 6c65 0a20 2020 2020 2020 2020  ompile.         
+00014900: 2020 2020 206c 6173 745f 726f 775f 7072       last_row_pr
+00014910: 6f63 6573 735f 3136 5f70 6163 6b65 7473  ocess_16_packets
+00014920: 3c4c 6873 5363 616c 6172 2c20 5268 7353  <LhsScalar, RhsS
+00014930: 6361 6c61 722c 2049 6e64 6578 2c20 4461  calar, Index, Da
+00014940: 7461 4d61 7070 6572 2c20 6d72 2c20 6e72  taMapper, mr, nr
+00014950: 2c20 436f 6e6a 7567 6174 654c 6873 2c20  , ConjugateLhs, 
+00014960: 436f 6e6a 7567 6174 6552 6873 3e20 703b  ConjugateRhs> p;
+00014970: 0a09 2020 2020 2020 2020 2020 2020 7028  ..            p(
+00014980: 7265 732c 2073 7472 6169 7473 2c20 626c  res, straits, bl
+00014990: 412c 2062 6c42 2c20 6465 7074 682c 2065  A, blB, depth, e
+000149a0: 6e64 6b2c 2069 2c20 6a32 2c61 6c70 6861  ndk, i, j2,alpha
+000149b0: 2c20 4330 293b 0a20 2020 2020 2020 2020  , C0);.         
+000149c0: 2020 207d 0a20 2020 2020 2020 2020 2020     }.           
+000149d0: 2065 6c73 650a 2020 2020 2020 2020 2020   else.          
+000149e0: 2020 7b0a 2020 2020 2020 2020 2020 2020    {.            
+000149f0: 2020 5352 6573 5061 636b 6574 2052 203d    SResPacket R =
+00014a00: 2072 6573 2e74 656d 706c 6174 6520 6761   res.template ga
+00014a10: 7468 6572 5061 636b 6574 3c53 5265 7350  therPacket<SResP
+00014a20: 6163 6b65 743e 2869 2c20 6a32 293b 0a20  acket>(i, j2);. 
+00014a30: 2020 2020 2020 2020 2020 2020 2053 5265               SRe
+00014a40: 7350 6163 6b65 7420 616c 7068 6176 203d  sPacket alphav =
+00014a50: 2070 7365 7431 3c53 5265 7350 6163 6b65   pset1<SResPacke
+00014a60: 743e 2861 6c70 6861 293b 0a20 2020 2020  t>(alpha);.     
+00014a70: 2020 2020 2020 2020 2073 7472 6169 7473           straits
+00014a80: 2e61 6363 2843 302c 2061 6c70 6861 762c  .acc(C0, alphav,
+00014a90: 2052 293b 0a20 2020 2020 2020 2020 2020   R);.           
+00014aa0: 2020 2072 6573 2e73 6361 7474 6572 5061     res.scatterPa
+00014ab0: 636b 6574 2869 2c20 6a32 2c20 5229 3b0a  cket(i, j2, R);.
+00014ac0: 2020 2020 2020 2020 2020 2020 7d0a 2020              }.  
+00014ad0: 2020 2020 2020 2020 7d0a 2020 2020 2020          }.      
+00014ae0: 2020 2020 656c 7365 202f 2f20 7363 616c      else // scal
+00014af0: 6172 2070 6174 680a 2020 2020 2020 2020  ar path.        
+00014b00: 2020 7b0a 2020 2020 2020 2020 2020 2020    {.            
+00014b10: 2f2f 2067 6574 2061 2031 2078 2034 2072  // get a 1 x 4 r
+00014b20: 6573 2062 6c6f 636b 2061 7320 7265 6769  es block as regi
+00014b30: 7374 6572 730a 2020 2020 2020 2020 2020  sters.          
+00014b40: 2020 5265 7353 6361 6c61 7220 4330 2830    ResScalar C0(0
+00014b50: 292c 2043 3128 3029 2c20 4332 2830 292c  ), C1(0), C2(0),
+00014b60: 2043 3328 3029 3b0a 0a20 2020 2020 2020   C3(0);..       
+00014b70: 2020 2020 2066 6f72 2849 6e64 6578 206b       for(Index k
+00014b80: 3d30 3b20 6b3c 6465 7074 683b 206b 2b2b  =0; k<depth; k++
+00014b90: 290a 2020 2020 2020 2020 2020 2020 7b0a  ).            {.
+00014ba0: 2020 2020 2020 2020 2020 2020 2020 4c68                Lh
+00014bb0: 7353 6361 6c61 7220 4130 3b0a 2020 2020  sScalar A0;.    
+00014bc0: 2020 2020 2020 2020 2020 5268 7353 6361            RhsSca
+00014bd0: 6c61 7220 425f 302c 2042 5f31 3b0a 0a20  lar B_0, B_1;.. 
+00014be0: 2020 2020 2020 2020 2020 2020 2041 3020               A0 
+00014bf0: 3d20 626c 415b 6b5d 3b0a 0a20 2020 2020  = blA[k];..     
+00014c00: 2020 2020 2020 2020 2042 5f30 203d 2062           B_0 = b
+00014c10: 6c42 5b30 5d3b 0a20 2020 2020 2020 2020  lB[0];.         
+00014c20: 2020 2020 2042 5f31 203d 2062 6c42 5b31       B_1 = blB[1
+00014c30: 5d3b 0a20 2020 2020 2020 2020 2020 2020  ];.             
+00014c40: 2043 3020 3d20 636a 2e70 6d61 6464 2841   C0 = cj.pmadd(A
+00014c50: 302c 425f 302c 4330 293b 0a20 2020 2020  0,B_0,C0);.     
+00014c60: 2020 2020 2020 2020 2043 3120 3d20 636a           C1 = cj
+00014c70: 2e70 6d61 6464 2841 302c 425f 312c 4331  .pmadd(A0,B_1,C1
+00014c80: 293b 0a0a 2020 2020 2020 2020 2020 2020  );..            
+00014c90: 2020 425f 3020 3d20 626c 425b 325d 3b0a    B_0 = blB[2];.
+00014ca0: 2020 2020 2020 2020 2020 2020 2020 425f                B_
+00014cb0: 3120 3d20 626c 425b 335d 3b0a 2020 2020  1 = blB[3];.    
+00014cc0: 2020 2020 2020 2020 2020 4332 203d 2063            C2 = c
+00014cd0: 6a2e 706d 6164 6428 4130 2c42 5f30 2c43  j.pmadd(A0,B_0,C
+00014ce0: 3229 3b0a 2020 2020 2020 2020 2020 2020  2);.            
+00014cf0: 2020 4333 203d 2063 6a2e 706d 6164 6428    C3 = cj.pmadd(
+00014d00: 4130 2c42 5f31 2c43 3329 3b0a 0a20 2020  A0,B_1,C3);..   
+00014d10: 2020 2020 2020 2020 2020 2062 6c42 202b             blB +
+00014d20: 3d20 343b 0a20 2020 2020 2020 2020 2020  = 4;.           
+00014d30: 207d 0a20 2020 2020 2020 2020 2020 2072   }.            r
+00014d40: 6573 2869 2c20 6a32 202b 2030 2920 2b3d  es(i, j2 + 0) +=
+00014d50: 2061 6c70 6861 202a 2043 303b 0a20 2020   alpha * C0;.   
+00014d60: 2020 2020 2020 2020 2072 6573 2869 2c20           res(i, 
+00014d70: 6a32 202b 2031 2920 2b3d 2061 6c70 6861  j2 + 1) += alpha
+00014d80: 202a 2043 313b 0a20 2020 2020 2020 2020   * C1;.         
+00014d90: 2020 2072 6573 2869 2c20 6a32 202b 2032     res(i, j2 + 2
+00014da0: 2920 2b3d 2061 6c70 6861 202a 2043 323b  ) += alpha * C2;
+00014db0: 0a20 2020 2020 2020 2020 2020 2072 6573  .            res
+00014dc0: 2869 2c20 6a32 202b 2033 2920 2b3d 2061  (i, j2 + 3) += a
+00014dd0: 6c70 6861 202a 2043 333b 0a20 2020 2020  lpha * C3;.     
+00014de0: 2020 2020 207d 0a20 2020 2020 2020 207d       }.        }
+00014df0: 0a20 2020 2020 207d 0a20 2020 2020 202f  .      }.      /
+00014e00: 2f20 7265 6d61 696e 696e 6720 636f 6c75  / remaining colu
+00014e10: 6d6e 730a 2020 2020 2020 666f 7228 496e  mns.      for(In
+00014e20: 6465 7820 6a32 3d70 6163 6b65 745f 636f  dex j2=packet_co
+00014e30: 6c73 343b 206a 323c 636f 6c73 3b20 6a32  ls4; j2<cols; j2
+00014e40: 2b2b 290a 2020 2020 2020 7b0a 2020 2020  ++).      {.    
+00014e50: 2020 2020 2f2f 206c 6f6f 7020 6f6e 2065      // loop on e
+00014e60: 6163 6820 726f 7720 6f66 2074 6865 206c  ach row of the l
+00014e70: 6873 2028 312a 4c68 7350 726f 6772 6573  hs (1*LhsProgres
+00014e80: 7320 7820 6465 7074 6829 0a20 2020 2020  s x depth).     
+00014e90: 2020 2066 6f72 2849 6e64 6578 2069 3d70     for(Index i=p
+00014ea0: 6565 6c65 645f 6d63 5f71 7561 7274 6572  eeled_mc_quarter
+00014eb0: 3b20 693c 726f 7773 3b20 692b 3d31 290a  ; i<rows; i+=1).
+00014ec0: 2020 2020 2020 2020 7b0a 2020 2020 2020          {.      
+00014ed0: 2020 2020 636f 6e73 7420 4c68 7353 6361      const LhsSca
+00014ee0: 6c61 722a 2062 6c41 203d 2026 626c 6f63  lar* blA = &bloc
+00014ef0: 6b41 5b69 2a73 7472 6964 6541 2b6f 6666  kA[i*strideA+off
+00014f00: 7365 7441 5d3b 0a20 2020 2020 2020 2020  setA];.         
+00014f10: 2070 7265 6665 7463 6828 2662 6c41 5b30   prefetch(&blA[0
+00014f20: 5d29 3b0a 2020 2020 2020 2020 2020 2f2f  ]);.          //
+00014f30: 2067 6574 7320 6120 3120 7820 3120 7265   gets a 1 x 1 re
+00014f40: 7320 626c 6f63 6b20 6173 2072 6567 6973  s block as regis
+00014f50: 7465 7273 0a20 2020 2020 2020 2020 2052  ters.          R
+00014f60: 6573 5363 616c 6172 2043 3028 3029 3b0a  esScalar C0(0);.
+00014f70: 2020 2020 2020 2020 2020 636f 6e73 7420            const 
+00014f80: 5268 7353 6361 6c61 722a 2062 6c42 203d  RhsScalar* blB =
+00014f90: 2026 626c 6f63 6b42 5b6a 322a 7374 7269   &blockB[j2*stri
+00014fa0: 6465 422b 6f66 6673 6574 425d 3b0a 2020  deB+offsetB];.  
+00014fb0: 2020 2020 2020 2020 666f 7228 496e 6465          for(Inde
+00014fc0: 7820 6b3d 303b 206b 3c64 6570 7468 3b20  x k=0; k<depth; 
+00014fd0: 6b2b 2b29 0a20 2020 2020 2020 2020 207b  k++).          {
+00014fe0: 0a20 2020 2020 2020 2020 2020 204c 6873  .            Lhs
+00014ff0: 5363 616c 6172 2041 3020 3d20 626c 415b  Scalar A0 = blA[
+00015000: 6b5d 3b0a 2020 2020 2020 2020 2020 2020  k];.            
+00015010: 5268 7353 6361 6c61 7220 425f 3020 3d20  RhsScalar B_0 = 
+00015020: 626c 425b 6b5d 3b0a 2020 2020 2020 2020  blB[k];.        
+00015030: 2020 2020 4330 203d 2063 6a2e 706d 6164      C0 = cj.pmad
+00015040: 6428 4130 2c20 425f 302c 2043 3029 3b0a  d(A0, B_0, C0);.
+00015050: 2020 2020 2020 2020 2020 7d0a 2020 2020            }.    
+00015060: 2020 2020 2020 7265 7328 692c 206a 3229        res(i, j2)
+00015070: 202b 3d20 616c 7068 6120 2a20 4330 3b0a   += alpha * C0;.
+00015080: 2020 2020 2020 2020 7d0a 2020 2020 2020          }.      
+00015090: 7d0a 2020 2020 7d0a 2020 7d0a 0a0a 2f2f  }.    }.  }...//
+000150a0: 2070 6163 6b20 6120 626c 6f63 6b20 6f66   pack a block of
+000150b0: 2074 6865 206c 6873 0a2f 2f20 5468 6520   the lhs.// The 
+000150c0: 7472 6176 6572 7361 6c20 6973 2061 7320  traversal is as 
+000150d0: 666f 6c6c 6f77 2028 6d72 3d3d 3429 3a0a  follow (mr==4):.
+000150e0: 2f2f 2020 2030 2020 3420 2038 2031 3220  //   0  4  8 12 
+000150f0: 2e2e 2e0a 2f2f 2020 2031 2020 3520 2039  ....//   1  5  9
+00015100: 2031 3320 2e2e 2e0a 2f2f 2020 2032 2020   13 ....//   2  
+00015110: 3620 3130 2031 3420 2e2e 2e0a 2f2f 2020  6 10 14 ....//  
+00015120: 2033 2020 3720 3131 2031 3520 2e2e 2e0a   3  7 11 15 ....
+00015130: 2f2f 0a2f 2f20 2031 3620 3230 2032 3420  //.//  16 20 24 
+00015140: 3238 202e 2e2e 0a2f 2f20 2031 3720 3231  28 ....//  17 21
+00015150: 2032 3520 3239 202e 2e2e 0a2f 2f20 2031   25 29 ....//  1
+00015160: 3820 3232 2032 3620 3330 202e 2e2e 0a2f  8 22 26 30 ..../
+00015170: 2f20 2031 3920 3233 2032 3720 3331 202e  /  19 23 27 31 .
+00015180: 2e2e 0a2f 2f0a 2f2f 2020 3332 2033 3320  ...//.//  32 33 
+00015190: 3334 2033 3520 2e2e 2e0a 2f2f 2020 3336  34 35 ....//  36
+000151a0: 2033 3620 3338 2033 3920 2e2e 2e0a 7465   36 38 39 ....te
+000151b0: 6d70 6c61 7465 3c74 7970 656e 616d 6520  mplate<typename 
+000151c0: 5363 616c 6172 2c20 7479 7065 6e61 6d65  Scalar, typename
+000151d0: 2049 6e64 6578 2c20 7479 7065 6e61 6d65   Index, typename
+000151e0: 2044 6174 614d 6170 7065 722c 2069 6e74   DataMapper, int
+000151f0: 2050 6163 6b31 2c20 696e 7420 5061 636b   Pack1, int Pack
+00015200: 322c 2074 7970 656e 616d 6520 5061 636b  2, typename Pack
+00015210: 6574 2c20 626f 6f6c 2043 6f6e 6a75 6761  et, bool Conjuga
+00015220: 7465 2c20 626f 6f6c 2050 616e 656c 4d6f  te, bool PanelMo
+00015230: 6465 3e0a 7374 7275 6374 2067 656d 6d5f  de>.struct gemm_
+00015240: 7061 636b 5f6c 6873 3c53 6361 6c61 722c  pack_lhs<Scalar,
+00015250: 2049 6e64 6578 2c20 4461 7461 4d61 7070   Index, DataMapp
+00015260: 6572 2c20 5061 636b 312c 2050 6163 6b32  er, Pack1, Pack2
+00015270: 2c20 5061 636b 6574 2c20 436f 6c4d 616a  , Packet, ColMaj
+00015280: 6f72 2c20 436f 6e6a 7567 6174 652c 2050  or, Conjugate, P
+00015290: 616e 656c 4d6f 6465 3e0a 7b0a 2020 7479  anelMode>.{.  ty
+000152a0: 7065 6465 6620 7479 7065 6e61 6d65 2044  pedef typename D
+000152b0: 6174 614d 6170 7065 723a 3a4c 696e 6561  ataMapper::Linea
+000152c0: 724d 6170 7065 7220 4c69 6e65 6172 4d61  rMapper LinearMa
+000152d0: 7070 6572 3b0a 2020 4549 4745 4e5f 444f  pper;.  EIGEN_DO
+000152e0: 4e54 5f49 4e4c 494e 4520 766f 6964 206f  NT_INLINE void o
+000152f0: 7065 7261 746f 7228 2928 5363 616c 6172  perator()(Scalar
+00015300: 2a20 626c 6f63 6b41 2c20 636f 6e73 7420  * blockA, const 
+00015310: 4461 7461 4d61 7070 6572 2620 6c68 732c  DataMapper& lhs,
+00015320: 2049 6e64 6578 2064 6570 7468 2c20 496e   Index depth, In
+00015330: 6465 7820 726f 7773 2c20 496e 6465 7820  dex rows, Index 
+00015340: 7374 7269 6465 3d30 2c20 496e 6465 7820  stride=0, Index 
+00015350: 6f66 6673 6574 3d30 293b 0a7d 3b0a 0a74  offset=0);.};..t
+00015360: 656d 706c 6174 653c 7479 7065 6e61 6d65  emplate<typename
+00015370: 2053 6361 6c61 722c 2074 7970 656e 616d   Scalar, typenam
+00015380: 6520 496e 6465 782c 2074 7970 656e 616d  e Index, typenam
+00015390: 6520 4461 7461 4d61 7070 6572 2c20 696e  e DataMapper, in
+000153a0: 7420 5061 636b 312c 2069 6e74 2050 6163  t Pack1, int Pac
+000153b0: 6b32 2c20 7479 7065 6e61 6d65 2050 6163  k2, typename Pac
+000153c0: 6b65 742c 2062 6f6f 6c20 436f 6e6a 7567  ket, bool Conjug
+000153d0: 6174 652c 2062 6f6f 6c20 5061 6e65 6c4d  ate, bool PanelM
+000153e0: 6f64 653e 0a45 4947 454e 5f44 4f4e 545f  ode>.EIGEN_DONT_
+000153f0: 494e 4c49 4e45 2076 6f69 6420 6765 6d6d  INLINE void gemm
+00015400: 5f70 6163 6b5f 6c68 733c 5363 616c 6172  _pack_lhs<Scalar
+00015410: 2c20 496e 6465 782c 2044 6174 614d 6170  , Index, DataMap
+00015420: 7065 722c 2050 6163 6b31 2c20 5061 636b  per, Pack1, Pack
+00015430: 322c 2050 6163 6b65 742c 2043 6f6c 4d61  2, Packet, ColMa
+00015440: 6a6f 722c 2043 6f6e 6a75 6761 7465 2c20  jor, Conjugate, 
+00015450: 5061 6e65 6c4d 6f64 653e 0a20 203a 3a6f  PanelMode>.  ::o
+00015460: 7065 7261 746f 7228 2928 5363 616c 6172  perator()(Scalar
+00015470: 2a20 626c 6f63 6b41 2c20 636f 6e73 7420  * blockA, const 
+00015480: 4461 7461 4d61 7070 6572 2620 6c68 732c  DataMapper& lhs,
+00015490: 2049 6e64 6578 2064 6570 7468 2c20 496e   Index depth, In
+000154a0: 6465 7820 726f 7773 2c20 496e 6465 7820  dex rows, Index 
+000154b0: 7374 7269 6465 2c20 496e 6465 7820 6f66  stride, Index of
+000154c0: 6673 6574 290a 7b0a 2020 7479 7065 6465  fset).{.  typede
+000154d0: 6620 7479 7065 6e61 6d65 2075 6e70 6163  f typename unpac
+000154e0: 6b65 745f 7472 6169 7473 3c50 6163 6b65  ket_traits<Packe
+000154f0: 743e 3a3a 6861 6c66 2048 616c 6650 6163  t>::half HalfPac
+00015500: 6b65 743b 0a20 2074 7970 6564 6566 2074  ket;.  typedef t
+00015510: 7970 656e 616d 6520 756e 7061 636b 6574  ypename unpacket
+00015520: 5f74 7261 6974 733c 7479 7065 6e61 6d65  _traits<typename
+00015530: 2075 6e70 6163 6b65 745f 7472 6169 7473   unpacket_traits
+00015540: 3c50 6163 6b65 743e 3a3a 6861 6c66 3e3a  <Packet>::half>:
+00015550: 3a68 616c 6620 5175 6172 7465 7250 6163  :half QuarterPac
+00015560: 6b65 743b 0a20 2065 6e75 6d20 7b20 5061  ket;.  enum { Pa
+00015570: 636b 6574 5369 7a65 203d 2075 6e70 6163  cketSize = unpac
+00015580: 6b65 745f 7472 6169 7473 3c50 6163 6b65  ket_traits<Packe
+00015590: 743e 3a3a 7369 7a65 2c0a 2020 2020 2020  t>::size,.      
+000155a0: 2020 2048 616c 6650 6163 6b65 7453 697a     HalfPacketSiz
+000155b0: 6520 3d20 756e 7061 636b 6574 5f74 7261  e = unpacket_tra
+000155c0: 6974 733c 4861 6c66 5061 636b 6574 3e3a  its<HalfPacket>:
+000155d0: 3a73 697a 652c 0a20 2020 2020 2020 2020  :size,.         
+000155e0: 5175 6172 7465 7250 6163 6b65 7453 697a  QuarterPacketSiz
+000155f0: 6520 3d20 756e 7061 636b 6574 5f74 7261  e = unpacket_tra
+00015600: 6974 733c 5175 6172 7465 7250 6163 6b65  its<QuarterPacke
+00015610: 743e 3a3a 7369 7a65 2c0a 2020 2020 2020  t>::size,.      
+00015620: 2020 2048 6173 4861 6c66 203d 2028 696e     HasHalf = (in
+00015630: 7429 4861 6c66 5061 636b 6574 5369 7a65  t)HalfPacketSize
+00015640: 203c 2028 696e 7429 5061 636b 6574 5369   < (int)PacketSi
+00015650: 7a65 2c0a 2020 2020 2020 2020 2048 6173  ze,.         Has
+00015660: 5175 6172 7465 7220 3d20 2869 6e74 2951  Quarter = (int)Q
+00015670: 7561 7274 6572 5061 636b 6574 5369 7a65  uarterPacketSize
+00015680: 203c 2028 696e 7429 4861 6c66 5061 636b   < (int)HalfPack
+00015690: 6574 5369 7a65 7d3b 0a0a 2020 4549 4745  etSize};..  EIGE
+000156a0: 4e5f 4153 4d5f 434f 4d4d 454e 5428 2245  N_ASM_COMMENT("E
+000156b0: 4947 454e 2050 524f 4455 4354 2050 4143  IGEN PRODUCT PAC
+000156c0: 4b20 4c48 5322 293b 0a20 2045 4947 454e  K LHS");.  EIGEN
+000156d0: 5f55 4e55 5345 445f 5641 5249 4142 4c45  _UNUSED_VARIABLE
+000156e0: 2873 7472 6964 6529 3b0a 2020 4549 4745  (stride);.  EIGE
+000156f0: 4e5f 554e 5553 4544 5f56 4152 4941 424c  N_UNUSED_VARIABL
+00015700: 4528 6f66 6673 6574 293b 0a20 2065 6967  E(offset);.  eig
+00015710: 656e 5f61 7373 6572 7428 2828 2150 616e  en_assert(((!Pan
+00015720: 656c 4d6f 6465 2920 2626 2073 7472 6964  elMode) && strid
+00015730: 653d 3d30 2026 2620 6f66 6673 6574 3d3d  e==0 && offset==
+00015740: 3029 207c 7c20 2850 616e 656c 4d6f 6465  0) || (PanelMode
+00015750: 2026 2620 7374 7269 6465 3e3d 6465 7074   && stride>=dept
+00015760: 6820 2626 206f 6666 7365 743c 3d73 7472  h && offset<=str
+00015770: 6964 6529 293b 0a20 2065 6967 656e 5f61  ide));.  eigen_a
+00015780: 7373 6572 7428 2028 2850 6163 6b31 2550  ssert( ((Pack1%P
+00015790: 6163 6b65 7453 697a 6529 3d3d 3020 2626  acketSize)==0 &&
+000157a0: 2050 6163 6b31 3c3d 342a 5061 636b 6574   Pack1<=4*Packet
+000157b0: 5369 7a65 2920 7c7c 2028 5061 636b 313c  Size) || (Pack1<
+000157c0: 3d34 2920 293b 0a20 2063 6f6e 6a5f 6966  =4) );.  conj_if
+000157d0: 3c4e 756d 5472 6169 7473 3c53 6361 6c61  <NumTraits<Scala
+000157e0: 723e 3a3a 4973 436f 6d70 6c65 7820 2626  r>::IsComplex &&
+000157f0: 2043 6f6e 6a75 6761 7465 3e20 636a 3b0a   Conjugate> cj;.
+00015800: 2020 496e 6465 7820 636f 756e 7420 3d20    Index count = 
+00015810: 303b 0a0a 2020 636f 6e73 7420 496e 6465  0;..  const Inde
+00015820: 7820 7065 656c 6564 5f6d 6333 203d 2050  x peeled_mc3 = P
+00015830: 6163 6b31 3e3d 332a 5061 636b 6574 5369  ack1>=3*PacketSi
+00015840: 7a65 203f 2028 726f 7773 2f28 332a 5061  ze ? (rows/(3*Pa
+00015850: 636b 6574 5369 7a65 2929 2a28 332a 5061  cketSize))*(3*Pa
+00015860: 636b 6574 5369 7a65 2920 3a20 303b 0a20  cketSize) : 0;. 
+00015870: 2063 6f6e 7374 2049 6e64 6578 2070 6565   const Index pee
+00015880: 6c65 645f 6d63 3220 3d20 5061 636b 313e  led_mc2 = Pack1>
+00015890: 3d32 2a50 6163 6b65 7453 697a 6520 3f20  =2*PacketSize ? 
+000158a0: 7065 656c 6564 5f6d 6333 2b28 2872 6f77  peeled_mc3+((row
+000158b0: 732d 7065 656c 6564 5f6d 6333 292f 2832  s-peeled_mc3)/(2
+000158c0: 2a50 6163 6b65 7453 697a 6529 292a 2832  *PacketSize))*(2
+000158d0: 2a50 6163 6b65 7453 697a 6529 203a 2030  *PacketSize) : 0
+000158e0: 3b0a 2020 636f 6e73 7420 496e 6465 7820  ;.  const Index 
+000158f0: 7065 656c 6564 5f6d 6331 203d 2050 6163  peeled_mc1 = Pac
+00015900: 6b31 3e3d 312a 5061 636b 6574 5369 7a65  k1>=1*PacketSize
+00015910: 203f 2070 6565 6c65 645f 6d63 322b 2828   ? peeled_mc2+((
+00015920: 726f 7773 2d70 6565 6c65 645f 6d63 3229  rows-peeled_mc2)
+00015930: 2f28 312a 5061 636b 6574 5369 7a65 2929  /(1*PacketSize))
+00015940: 2a28 312a 5061 636b 6574 5369 7a65 2920  *(1*PacketSize) 
+00015950: 3a20 303b 0a20 2063 6f6e 7374 2049 6e64  : 0;.  const Ind
+00015960: 6578 2070 6565 6c65 645f 6d63 5f68 616c  ex peeled_mc_hal
+00015970: 6620 3d20 5061 636b 313e 3d48 616c 6650  f = Pack1>=HalfP
+00015980: 6163 6b65 7453 697a 6520 3f20 7065 656c  acketSize ? peel
+00015990: 6564 5f6d 6331 2b28 2872 6f77 732d 7065  ed_mc1+((rows-pe
+000159a0: 656c 6564 5f6d 6331 292f 2848 616c 6650  eled_mc1)/(HalfP
+000159b0: 6163 6b65 7453 697a 6529 292a 2848 616c  acketSize))*(Hal
+000159c0: 6650 6163 6b65 7453 697a 6529 203a 2030  fPacketSize) : 0
+000159d0: 3b0a 2020 636f 6e73 7420 496e 6465 7820  ;.  const Index 
+000159e0: 7065 656c 6564 5f6d 635f 7175 6172 7465  peeled_mc_quarte
+000159f0: 7220 3d20 5061 636b 313e 3d51 7561 7274  r = Pack1>=Quart
+00015a00: 6572 5061 636b 6574 5369 7a65 203f 2028  erPacketSize ? (
+00015a10: 726f 7773 2f28 5175 6172 7465 7250 6163  rows/(QuarterPac
+00015a20: 6b65 7453 697a 6529 292a 2851 7561 7274  ketSize))*(Quart
+00015a30: 6572 5061 636b 6574 5369 7a65 2920 3a20  erPacketSize) : 
+00015a40: 303b 0a20 2063 6f6e 7374 2049 6e64 6578  0;.  const Index
+00015a50: 206c 6173 745f 6c68 735f 7072 6f67 7265   last_lhs_progre
+00015a60: 7373 203d 2072 6f77 7320 3e20 7065 656c  ss = rows > peel
+00015a70: 6564 5f6d 635f 7175 6172 7465 7220 3f20  ed_mc_quarter ? 
+00015a80: 2872 6f77 7320 2d20 7065 656c 6564 5f6d  (rows - peeled_m
+00015a90: 635f 7175 6172 7465 7229 2026 207e 3120  c_quarter) & ~1 
+00015aa0: 3a20 303b 0a20 2063 6f6e 7374 2049 6e64  : 0;.  const Ind
+00015ab0: 6578 2070 6565 6c65 645f 6d63 3020 3d20  ex peeled_mc0 = 
+00015ac0: 5061 636b 323e 3d50 6163 6b65 7453 697a  Pack2>=PacketSiz
+00015ad0: 6520 3f20 7065 656c 6564 5f6d 635f 7175  e ? peeled_mc_qu
+00015ae0: 6172 7465 720a 2020 2020 2020 2020 2020  arter.          
+00015af0: 2020 2020 2020 2020 2020 2020 2020 203a                 :
+00015b00: 2050 6163 6b32 3e31 2026 2620 6c61 7374   Pack2>1 && last
+00015b10: 5f6c 6873 5f70 726f 6772 6573 7320 3f20  _lhs_progress ? 
+00015b20: 2872 6f77 732f 6c61 7374 5f6c 6873 5f70  (rows/last_lhs_p
+00015b30: 726f 6772 6573 7329 2a6c 6173 745f 6c68  rogress)*last_lh
+00015b40: 735f 7072 6f67 7265 7373 203a 2030 3b0a  s_progress : 0;.
+00015b50: 0a20 2049 6e64 6578 2069 3d30 3b0a 0a20  .  Index i=0;.. 
+00015b60: 202f 2f20 5061 636b 2033 2070 6163 6b65   // Pack 3 packe
+00015b70: 7473 0a20 2069 6628 5061 636b 313e 3d33  ts.  if(Pack1>=3
+00015b80: 2a50 6163 6b65 7453 697a 6529 0a20 207b  *PacketSize).  {
+00015b90: 0a20 2020 2066 6f72 283b 2069 3c70 6565  .    for(; i<pee
+00015ba0: 6c65 645f 6d63 333b 2069 2b3d 332a 5061  led_mc3; i+=3*Pa
+00015bb0: 636b 6574 5369 7a65 290a 2020 2020 7b0a  cketSize).    {.
+00015bc0: 2020 2020 2020 6966 2850 616e 656c 4d6f        if(PanelMo
+00015bd0: 6465 2920 636f 756e 7420 2b3d 2028 332a  de) count += (3*
+00015be0: 5061 636b 6574 5369 7a65 2920 2a20 6f66  PacketSize) * of
+00015bf0: 6673 6574 3b0a 0a20 2020 2020 2066 6f72  fset;..      for
+00015c00: 2849 6e64 6578 206b 3d30 3b20 6b3c 6465  (Index k=0; k<de
+00015c10: 7074 683b 206b 2b2b 290a 2020 2020 2020  pth; k++).      
+00015c20: 7b0a 2020 2020 2020 2020 5061 636b 6574  {.        Packet
+00015c30: 2041 2c20 422c 2043 3b0a 2020 2020 2020   A, B, C;.      
+00015c40: 2020 4120 3d20 6c68 732e 7465 6d70 6c61    A = lhs.templa
+00015c50: 7465 206c 6f61 6450 6163 6b65 743c 5061  te loadPacket<Pa
+00015c60: 636b 6574 3e28 692b 302a 5061 636b 6574  cket>(i+0*Packet
+00015c70: 5369 7a65 2c20 6b29 3b0a 2020 2020 2020  Size, k);.      
+00015c80: 2020 4220 3d20 6c68 732e 7465 6d70 6c61    B = lhs.templa
+00015c90: 7465 206c 6f61 6450 6163 6b65 743c 5061  te loadPacket<Pa
+00015ca0: 636b 6574 3e28 692b 312a 5061 636b 6574  cket>(i+1*Packet
+00015cb0: 5369 7a65 2c20 6b29 3b0a 2020 2020 2020  Size, k);.      
+00015cc0: 2020 4320 3d20 6c68 732e 7465 6d70 6c61    C = lhs.templa
+00015cd0: 7465 206c 6f61 6450 6163 6b65 743c 5061  te loadPacket<Pa
+00015ce0: 636b 6574 3e28 692b 322a 5061 636b 6574  cket>(i+2*Packet
+00015cf0: 5369 7a65 2c20 6b29 3b0a 2020 2020 2020  Size, k);.      
+00015d00: 2020 7073 746f 7265 2862 6c6f 636b 412b    pstore(blockA+
+00015d10: 636f 756e 742c 2063 6a2e 7063 6f6e 6a28  count, cj.pconj(
+00015d20: 4129 293b 2063 6f75 6e74 2b3d 5061 636b  A)); count+=Pack
+00015d30: 6574 5369 7a65 3b0a 2020 2020 2020 2020  etSize;.        
+00015d40: 7073 746f 7265 2862 6c6f 636b 412b 636f  pstore(blockA+co
+00015d50: 756e 742c 2063 6a2e 7063 6f6e 6a28 4229  unt, cj.pconj(B)
+00015d60: 293b 2063 6f75 6e74 2b3d 5061 636b 6574  ); count+=Packet
+00015d70: 5369 7a65 3b0a 2020 2020 2020 2020 7073  Size;.        ps
+00015d80: 746f 7265 2862 6c6f 636b 412b 636f 756e  tore(blockA+coun
+00015d90: 742c 2063 6a2e 7063 6f6e 6a28 4329 293b  t, cj.pconj(C));
+00015da0: 2063 6f75 6e74 2b3d 5061 636b 6574 5369   count+=PacketSi
+00015db0: 7a65 3b0a 2020 2020 2020 7d0a 2020 2020  ze;.      }.    
+00015dc0: 2020 6966 2850 616e 656c 4d6f 6465 2920    if(PanelMode) 
+00015dd0: 636f 756e 7420 2b3d 2028 332a 5061 636b  count += (3*Pack
+00015de0: 6574 5369 7a65 2920 2a20 2873 7472 6964  etSize) * (strid
+00015df0: 652d 6f66 6673 6574 2d64 6570 7468 293b  e-offset-depth);
+00015e00: 0a20 2020 207d 0a20 207d 0a20 202f 2f20  .    }.  }.  // 
+00015e10: 5061 636b 2032 2070 6163 6b65 7473 0a20  Pack 2 packets. 
+00015e20: 2069 6628 5061 636b 313e 3d32 2a50 6163   if(Pack1>=2*Pac
+00015e30: 6b65 7453 697a 6529 0a20 207b 0a20 2020  ketSize).  {.   
+00015e40: 2066 6f72 283b 2069 3c70 6565 6c65 645f   for(; i<peeled_
+00015e50: 6d63 323b 2069 2b3d 322a 5061 636b 6574  mc2; i+=2*Packet
+00015e60: 5369 7a65 290a 2020 2020 7b0a 2020 2020  Size).    {.    
+00015e70: 2020 6966 2850 616e 656c 4d6f 6465 2920    if(PanelMode) 
+00015e80: 636f 756e 7420 2b3d 2028 322a 5061 636b  count += (2*Pack
+00015e90: 6574 5369 7a65 2920 2a20 6f66 6673 6574  etSize) * offset
+00015ea0: 3b0a 0a20 2020 2020 2066 6f72 2849 6e64  ;..      for(Ind
+00015eb0: 6578 206b 3d30 3b20 6b3c 6465 7074 683b  ex k=0; k<depth;
+00015ec0: 206b 2b2b 290a 2020 2020 2020 7b0a 2020   k++).      {.  
+00015ed0: 2020 2020 2020 5061 636b 6574 2041 2c20        Packet A, 
+00015ee0: 423b 0a20 2020 2020 2020 2041 203d 206c  B;.        A = l
+00015ef0: 6873 2e74 656d 706c 6174 6520 6c6f 6164  hs.template load
+00015f00: 5061 636b 6574 3c50 6163 6b65 743e 2869  Packet<Packet>(i
+00015f10: 2b30 2a50 6163 6b65 7453 697a 652c 206b  +0*PacketSize, k
+00015f20: 293b 0a20 2020 2020 2020 2042 203d 206c  );.        B = l
+00015f30: 6873 2e74 656d 706c 6174 6520 6c6f 6164  hs.template load
+00015f40: 5061 636b 6574 3c50 6163 6b65 743e 2869  Packet<Packet>(i
+00015f50: 2b31 2a50 6163 6b65 7453 697a 652c 206b  +1*PacketSize, k
+00015f60: 293b 0a20 2020 2020 2020 2070 7374 6f72  );.        pstor
+00015f70: 6528 626c 6f63 6b41 2b63 6f75 6e74 2c20  e(blockA+count, 
+00015f80: 636a 2e70 636f 6e6a 2841 2929 3b20 636f  cj.pconj(A)); co
+00015f90: 756e 742b 3d50 6163 6b65 7453 697a 653b  unt+=PacketSize;
+00015fa0: 0a20 2020 2020 2020 2070 7374 6f72 6528  .        pstore(
+00015fb0: 626c 6f63 6b41 2b63 6f75 6e74 2c20 636a  blockA+count, cj
+00015fc0: 2e70 636f 6e6a 2842 2929 3b20 636f 756e  .pconj(B)); coun
+00015fd0: 742b 3d50 6163 6b65 7453 697a 653b 0a20  t+=PacketSize;. 
+00015fe0: 2020 2020 207d 0a20 2020 2020 2069 6628       }.      if(
+00015ff0: 5061 6e65 6c4d 6f64 6529 2063 6f75 6e74  PanelMode) count
+00016000: 202b 3d20 2832 2a50 6163 6b65 7453 697a   += (2*PacketSiz
+00016010: 6529 202a 2028 7374 7269 6465 2d6f 6666  e) * (stride-off
+00016020: 7365 742d 6465 7074 6829 3b0a 2020 2020  set-depth);.    
+00016030: 7d0a 2020 7d0a 2020 2f2f 2050 6163 6b20  }.  }.  // Pack 
+00016040: 3120 7061 636b 6574 730a 2020 6966 2850  1 packets.  if(P
+00016050: 6163 6b31 3e3d 312a 5061 636b 6574 5369  ack1>=1*PacketSi
+00016060: 7a65 290a 2020 7b0a 2020 2020 666f 7228  ze).  {.    for(
+00016070: 3b20 693c 7065 656c 6564 5f6d 6331 3b20  ; i<peeled_mc1; 
+00016080: 692b 3d31 2a50 6163 6b65 7453 697a 6529  i+=1*PacketSize)
+00016090: 0a20 2020 207b 0a20 2020 2020 2069 6628  .    {.      if(
+000160a0: 5061 6e65 6c4d 6f64 6529 2063 6f75 6e74  PanelMode) count
+000160b0: 202b 3d20 2831 2a50 6163 6b65 7453 697a   += (1*PacketSiz
+000160c0: 6529 202a 206f 6666 7365 743b 0a0a 2020  e) * offset;..  
+000160d0: 2020 2020 666f 7228 496e 6465 7820 6b3d      for(Index k=
+000160e0: 303b 206b 3c64 6570 7468 3b20 6b2b 2b29  0; k<depth; k++)
+000160f0: 0a20 2020 2020 207b 0a20 2020 2020 2020  .      {.       
+00016100: 2050 6163 6b65 7420 413b 0a20 2020 2020   Packet A;.     
+00016110: 2020 2041 203d 206c 6873 2e74 656d 706c     A = lhs.templ
+00016120: 6174 6520 6c6f 6164 5061 636b 6574 3c50  ate loadPacket<P
+00016130: 6163 6b65 743e 2869 2b30 2a50 6163 6b65  acket>(i+0*Packe
+00016140: 7453 697a 652c 206b 293b 0a20 2020 2020  tSize, k);.     
+00016150: 2020 2070 7374 6f72 6528 626c 6f63 6b41     pstore(blockA
+00016160: 2b63 6f75 6e74 2c20 636a 2e70 636f 6e6a  +count, cj.pconj
+00016170: 2841 2929 3b0a 2020 2020 2020 2020 636f  (A));.        co
+00016180: 756e 742b 3d50 6163 6b65 7453 697a 653b  unt+=PacketSize;
+00016190: 0a20 2020 2020 207d 0a20 2020 2020 2069  .      }.      i
+000161a0: 6628 5061 6e65 6c4d 6f64 6529 2063 6f75  f(PanelMode) cou
+000161b0: 6e74 202b 3d20 2831 2a50 6163 6b65 7453  nt += (1*PacketS
+000161c0: 697a 6529 202a 2028 7374 7269 6465 2d6f  ize) * (stride-o
+000161d0: 6666 7365 742d 6465 7074 6829 3b0a 2020  ffset-depth);.  
+000161e0: 2020 7d0a 2020 7d0a 2020 2f2f 2050 6163    }.  }.  // Pac
+000161f0: 6b20 6861 6c66 2070 6163 6b65 7473 0a20  k half packets. 
+00016200: 2069 6628 4861 7348 616c 6620 2626 2050   if(HasHalf && P
+00016210: 6163 6b31 3e3d 4861 6c66 5061 636b 6574  ack1>=HalfPacket
+00016220: 5369 7a65 290a 2020 7b0a 2020 2020 666f  Size).  {.    fo
+00016230: 7228 3b20 693c 7065 656c 6564 5f6d 635f  r(; i<peeled_mc_
+00016240: 6861 6c66 3b20 692b 3d48 616c 6650 6163  half; i+=HalfPac
+00016250: 6b65 7453 697a 6529 0a20 2020 207b 0a20  ketSize).    {. 
+00016260: 2020 2020 2069 6628 5061 6e65 6c4d 6f64       if(PanelMod
+00016270: 6529 2063 6f75 6e74 202b 3d20 2848 616c  e) count += (Hal
+00016280: 6650 6163 6b65 7453 697a 6529 202a 206f  fPacketSize) * o
+00016290: 6666 7365 743b 0a0a 2020 2020 2020 666f  ffset;..      fo
+000162a0: 7228 496e 6465 7820 6b3d 303b 206b 3c64  r(Index k=0; k<d
+000162b0: 6570 7468 3b20 6b2b 2b29 0a20 2020 2020  epth; k++).     
+000162c0: 207b 0a20 2020 2020 2020 2048 616c 6650   {.        HalfP
+000162d0: 6163 6b65 7420 413b 0a20 2020 2020 2020  acket A;.       
+000162e0: 2041 203d 206c 6873 2e74 656d 706c 6174   A = lhs.templat
+000162f0: 6520 6c6f 6164 5061 636b 6574 3c48 616c  e loadPacket<Hal
+00016300: 6650 6163 6b65 743e 2869 2b30 2a28 4861  fPacket>(i+0*(Ha
+00016310: 6c66 5061 636b 6574 5369 7a65 292c 206b  lfPacketSize), k
+00016320: 293b 0a20 2020 2020 2020 2070 7374 6f72  );.        pstor
+00016330: 6575 2862 6c6f 636b 412b 636f 756e 742c  eu(blockA+count,
+00016340: 2063 6a2e 7063 6f6e 6a28 4129 293b 0a20   cj.pconj(A));. 
+00016350: 2020 2020 2020 2063 6f75 6e74 2b3d 4861         count+=Ha
+00016360: 6c66 5061 636b 6574 5369 7a65 3b0a 2020  lfPacketSize;.  
+00016370: 2020 2020 7d0a 2020 2020 2020 6966 2850      }.      if(P
+00016380: 616e 656c 4d6f 6465 2920 636f 756e 7420  anelMode) count 
+00016390: 2b3d 2028 4861 6c66 5061 636b 6574 5369  += (HalfPacketSi
+000163a0: 7a65 2920 2a20 2873 7472 6964 652d 6f66  ze) * (stride-of
+000163b0: 6673 6574 2d64 6570 7468 293b 0a20 2020  fset-depth);.   
+000163c0: 207d 0a20 207d 0a20 202f 2f20 5061 636b   }.  }.  // Pack
+000163d0: 2071 7561 7274 6572 2070 6163 6b65 7473   quarter packets
+000163e0: 0a20 2069 6628 4861 7351 7561 7274 6572  .  if(HasQuarter
+000163f0: 2026 2620 5061 636b 313e 3d51 7561 7274   && Pack1>=Quart
+00016400: 6572 5061 636b 6574 5369 7a65 290a 2020  erPacketSize).  
+00016410: 7b0a 2020 2020 666f 7228 3b20 693c 7065  {.    for(; i<pe
+00016420: 656c 6564 5f6d 635f 7175 6172 7465 723b  eled_mc_quarter;
+00016430: 2069 2b3d 5175 6172 7465 7250 6163 6b65   i+=QuarterPacke
+00016440: 7453 697a 6529 0a20 2020 207b 0a20 2020  tSize).    {.   
+00016450: 2020 2069 6628 5061 6e65 6c4d 6f64 6529     if(PanelMode)
+00016460: 2063 6f75 6e74 202b 3d20 2851 7561 7274   count += (Quart
+00016470: 6572 5061 636b 6574 5369 7a65 2920 2a20  erPacketSize) * 
+00016480: 6f66 6673 6574 3b0a 0a20 2020 2020 2066  offset;..      f
+00016490: 6f72 2849 6e64 6578 206b 3d30 3b20 6b3c  or(Index k=0; k<
+000164a0: 6465 7074 683b 206b 2b2b 290a 2020 2020  depth; k++).    
+000164b0: 2020 7b0a 2020 2020 2020 2020 5175 6172    {.        Quar
+000164c0: 7465 7250 6163 6b65 7420 413b 0a20 2020  terPacket A;.   
+000164d0: 2020 2020 2041 203d 206c 6873 2e74 656d       A = lhs.tem
+000164e0: 706c 6174 6520 6c6f 6164 5061 636b 6574  plate loadPacket
+000164f0: 3c51 7561 7274 6572 5061 636b 6574 3e28  <QuarterPacket>(
+00016500: 692b 302a 2851 7561 7274 6572 5061 636b  i+0*(QuarterPack
+00016510: 6574 5369 7a65 292c 206b 293b 0a20 2020  etSize), k);.   
+00016520: 2020 2020 2070 7374 6f72 6575 2862 6c6f       pstoreu(blo
+00016530: 636b 412b 636f 756e 742c 2063 6a2e 7063  ckA+count, cj.pc
+00016540: 6f6e 6a28 4129 293b 0a20 2020 2020 2020  onj(A));.       
+00016550: 2063 6f75 6e74 2b3d 5175 6172 7465 7250   count+=QuarterP
+00016560: 6163 6b65 7453 697a 653b 0a20 2020 2020  acketSize;.     
+00016570: 207d 0a20 2020 2020 2069 6628 5061 6e65   }.      if(Pane
+00016580: 6c4d 6f64 6529 2063 6f75 6e74 202b 3d20  lMode) count += 
+00016590: 2851 7561 7274 6572 5061 636b 6574 5369  (QuarterPacketSi
+000165a0: 7a65 2920 2a20 2873 7472 6964 652d 6f66  ze) * (stride-of
+000165b0: 6673 6574 2d64 6570 7468 293b 0a20 2020  fset-depth);.   
+000165c0: 207d 0a20 207d 0a20 202f 2f20 5061 636b   }.  }.  // Pack
+000165d0: 3220 6d61 7920 6265 202a 736d 616c 6c65  2 may be *smalle
+000165e0: 722a 2074 6861 6e20 5061 636b 6574 5369  r* than PacketSi
+000165f0: 7a65 e280 9474 6861 7420 6861 7070 656e  ze...that happen
+00016600: 7320 666f 720a 2020 2f2f 2070 726f 6475  s for.  // produ
+00016610: 6374 7320 6c69 6b65 2072 6561 6c20 2a20  cts like real * 
+00016620: 636f 6d70 6c65 782c 2077 6865 7265 2077  complex, where w
+00016630: 6520 6861 7665 2074 6f20 676f 2068 616c  e have to go hal
+00016640: 6620 7468 650a 2020 2f2f 2070 726f 6772  f the.  // progr
+00016650: 6573 7320 6f6e 2074 6865 206c 6873 2069  ess on the lhs i
+00016660: 6e20 6f72 6465 7220 746f 2064 7570 6c69  n order to dupli
+00016670: 6361 7465 2074 686f 7365 206f 7065 7261  cate those opera
+00016680: 6e64 7320 746f 0a20 202f 2f20 6164 6472  nds to.  // addr
+00016690: 6573 7320 626f 7468 2072 6561 6c20 2620  ess both real & 
+000166a0: 696d 6167 696e 6172 7920 7061 7274 7320  imaginary parts 
+000166b0: 6f6e 2074 6865 2072 6873 2e20 5468 6973  on the rhs. This
+000166c0: 2070 6f72 7469 6f6e 2077 696c 6c0a 2020   portion will.  
+000166d0: 2f2f 2070 6163 6b20 7468 6f73 6520 6861  // pack those ha
+000166e0: 6c66 206f 6e65 7320 756e 7469 6c20 7468  lf ones until th
+000166f0: 6579 206d 6174 6368 2074 6865 206e 756d  ey match the num
+00016700: 6265 7220 6578 7065 6374 6564 206f 6e20  ber expected on 
+00016710: 7468 650a 2020 2f2f 206c 6173 7420 7065  the.  // last pe
+00016720: 656c 696e 6720 6c6f 6f70 2061 7420 7468  eling loop at th
+00016730: 6973 2070 6f69 6e74 2028 666f 7220 7468  is point (for th
+00016740: 6520 7268 7329 2e0a 2020 6966 2850 6163  e rhs)..  if(Pac
+00016750: 6b32 3c50 6163 6b65 7453 697a 6520 2626  k2<PacketSize &&
+00016760: 2050 6163 6b32 3e31 290a 2020 7b0a 2020   Pack2>1).  {.  
+00016770: 2020 666f 7228 3b20 693c 7065 656c 6564    for(; i<peeled
+00016780: 5f6d 6330 3b20 692b 3d6c 6173 745f 6c68  _mc0; i+=last_lh
+00016790: 735f 7072 6f67 7265 7373 290a 2020 2020  s_progress).    
+000167a0: 7b0a 2020 2020 2020 6966 2850 616e 656c  {.      if(Panel
+000167b0: 4d6f 6465 2920 636f 756e 7420 2b3d 206c  Mode) count += l
+000167c0: 6173 745f 6c68 735f 7072 6f67 7265 7373  ast_lhs_progress
+000167d0: 202a 206f 6666 7365 743b 0a0a 2020 2020   * offset;..    
+000167e0: 2020 666f 7228 496e 6465 7820 6b3d 303b    for(Index k=0;
+000167f0: 206b 3c64 6570 7468 3b20 6b2b 2b29 0a20   k<depth; k++). 
+00016800: 2020 2020 2020 2066 6f72 2849 6e64 6578         for(Index
+00016810: 2077 3d30 3b20 773c 6c61 7374 5f6c 6873   w=0; w<last_lhs
+00016820: 5f70 726f 6772 6573 733b 2077 2b2b 290a  _progress; w++).
+00016830: 2020 2020 2020 2020 2020 626c 6f63 6b41            blockA
+00016840: 5b63 6f75 6e74 2b2b 5d20 3d20 636a 286c  [count++] = cj(l
+00016850: 6873 2869 2b77 2c20 6b29 293b 0a0a 2020  hs(i+w, k));..  
+00016860: 2020 2020 6966 2850 616e 656c 4d6f 6465      if(PanelMode
+00016870: 2920 636f 756e 7420 2b3d 206c 6173 745f  ) count += last_
+00016880: 6c68 735f 7072 6f67 7265 7373 202a 2028  lhs_progress * (
+00016890: 7374 7269 6465 2d6f 6666 7365 742d 6465  stride-offset-de
+000168a0: 7074 6829 3b0a 2020 2020 7d0a 2020 7d0a  pth);.    }.  }.
+000168b0: 2020 2f2f 2050 6163 6b20 7363 616c 6172    // Pack scalar
+000168c0: 730a 2020 666f 7228 3b20 693c 726f 7773  s.  for(; i<rows
+000168d0: 3b20 692b 2b29 0a20 207b 0a20 2020 2069  ; i++).  {.    i
+000168e0: 6628 5061 6e65 6c4d 6f64 6529 2063 6f75  f(PanelMode) cou
+000168f0: 6e74 202b 3d20 6f66 6673 6574 3b0a 2020  nt += offset;.  
+00016900: 2020 666f 7228 496e 6465 7820 6b3d 303b    for(Index k=0;
+00016910: 206b 3c64 6570 7468 3b20 6b2b 2b29 0a20   k<depth; k++). 
+00016920: 2020 2020 2062 6c6f 636b 415b 636f 756e       blockA[coun
+00016930: 742b 2b5d 203d 2063 6a28 6c68 7328 692c  t++] = cj(lhs(i,
+00016940: 206b 2929 3b0a 2020 2020 6966 2850 616e   k));.    if(Pan
+00016950: 656c 4d6f 6465 2920 636f 756e 7420 2b3d  elMode) count +=
+00016960: 2028 7374 7269 6465 2d6f 6666 7365 742d   (stride-offset-
+00016970: 6465 7074 6829 3b0a 2020 7d0a 7d0a 0a74  depth);.  }.}..t
+00016980: 656d 706c 6174 653c 7479 7065 6e61 6d65  emplate<typename
+00016990: 2053 6361 6c61 722c 2074 7970 656e 616d   Scalar, typenam
+000169a0: 6520 496e 6465 782c 2074 7970 656e 616d  e Index, typenam
+000169b0: 6520 4461 7461 4d61 7070 6572 2c20 696e  e DataMapper, in
+000169c0: 7420 5061 636b 312c 2069 6e74 2050 6163  t Pack1, int Pac
+000169d0: 6b32 2c20 7479 7065 6e61 6d65 2050 6163  k2, typename Pac
+000169e0: 6b65 742c 2062 6f6f 6c20 436f 6e6a 7567  ket, bool Conjug
+000169f0: 6174 652c 2062 6f6f 6c20 5061 6e65 6c4d  ate, bool PanelM
+00016a00: 6f64 653e 0a73 7472 7563 7420 6765 6d6d  ode>.struct gemm
+00016a10: 5f70 6163 6b5f 6c68 733c 5363 616c 6172  _pack_lhs<Scalar
+00016a20: 2c20 496e 6465 782c 2044 6174 614d 6170  , Index, DataMap
+00016a30: 7065 722c 2050 6163 6b31 2c20 5061 636b  per, Pack1, Pack
+00016a40: 322c 2050 6163 6b65 742c 2052 6f77 4d61  2, Packet, RowMa
+00016a50: 6a6f 722c 2043 6f6e 6a75 6761 7465 2c20  jor, Conjugate, 
+00016a60: 5061 6e65 6c4d 6f64 653e 0a7b 0a20 2074  PanelMode>.{.  t
+00016a70: 7970 6564 6566 2074 7970 656e 616d 6520  ypedef typename 
+00016a80: 4461 7461 4d61 7070 6572 3a3a 4c69 6e65  DataMapper::Line
+00016a90: 6172 4d61 7070 6572 204c 696e 6561 724d  arMapper LinearM
+00016aa0: 6170 7065 723b 0a20 2045 4947 454e 5f44  apper;.  EIGEN_D
+00016ab0: 4f4e 545f 494e 4c49 4e45 2076 6f69 6420  ONT_INLINE void 
+00016ac0: 6f70 6572 6174 6f72 2829 2853 6361 6c61  operator()(Scala
+00016ad0: 722a 2062 6c6f 636b 412c 2063 6f6e 7374  r* blockA, const
+00016ae0: 2044 6174 614d 6170 7065 7226 206c 6873   DataMapper& lhs
+00016af0: 2c20 496e 6465 7820 6465 7074 682c 2049  , Index depth, I
+00016b00: 6e64 6578 2072 6f77 732c 2049 6e64 6578  ndex rows, Index
+00016b10: 2073 7472 6964 653d 302c 2049 6e64 6578   stride=0, Index
+00016b20: 206f 6666 7365 743d 3029 3b0a 7d3b 0a0a   offset=0);.};..
+00016b30: 7465 6d70 6c61 7465 3c74 7970 656e 616d  template<typenam
+00016b40: 6520 5363 616c 6172 2c20 7479 7065 6e61  e Scalar, typena
+00016b50: 6d65 2049 6e64 6578 2c20 7479 7065 6e61  me Index, typena
+00016b60: 6d65 2044 6174 614d 6170 7065 722c 2069  me DataMapper, i
+00016b70: 6e74 2050 6163 6b31 2c20 696e 7420 5061  nt Pack1, int Pa
+00016b80: 636b 322c 2074 7970 656e 616d 6520 5061  ck2, typename Pa
+00016b90: 636b 6574 2c20 626f 6f6c 2043 6f6e 6a75  cket, bool Conju
+00016ba0: 6761 7465 2c20 626f 6f6c 2050 616e 656c  gate, bool Panel
+00016bb0: 4d6f 6465 3e0a 4549 4745 4e5f 444f 4e54  Mode>.EIGEN_DONT
+00016bc0: 5f49 4e4c 494e 4520 766f 6964 2067 656d  _INLINE void gem
+00016bd0: 6d5f 7061 636b 5f6c 6873 3c53 6361 6c61  m_pack_lhs<Scala
+00016be0: 722c 2049 6e64 6578 2c20 4461 7461 4d61  r, Index, DataMa
+00016bf0: 7070 6572 2c20 5061 636b 312c 2050 6163  pper, Pack1, Pac
+00016c00: 6b32 2c20 5061 636b 6574 2c20 526f 774d  k2, Packet, RowM
+00016c10: 616a 6f72 2c20 436f 6e6a 7567 6174 652c  ajor, Conjugate,
+00016c20: 2050 616e 656c 4d6f 6465 3e0a 2020 3a3a   PanelMode>.  ::
+00016c30: 6f70 6572 6174 6f72 2829 2853 6361 6c61  operator()(Scala
+00016c40: 722a 2062 6c6f 636b 412c 2063 6f6e 7374  r* blockA, const
+00016c50: 2044 6174 614d 6170 7065 7226 206c 6873   DataMapper& lhs
+00016c60: 2c20 496e 6465 7820 6465 7074 682c 2049  , Index depth, I
+00016c70: 6e64 6578 2072 6f77 732c 2049 6e64 6578  ndex rows, Index
+00016c80: 2073 7472 6964 652c 2049 6e64 6578 206f   stride, Index o
+00016c90: 6666 7365 7429 0a7b 0a20 2074 7970 6564  ffset).{.  typed
+00016ca0: 6566 2074 7970 656e 616d 6520 756e 7061  ef typename unpa
+00016cb0: 636b 6574 5f74 7261 6974 733c 5061 636b  cket_traits<Pack
+00016cc0: 6574 3e3a 3a68 616c 6620 4861 6c66 5061  et>::half HalfPa
+00016cd0: 636b 6574 3b0a 2020 7479 7065 6465 6620  cket;.  typedef 
+00016ce0: 7479 7065 6e61 6d65 2075 6e70 6163 6b65  typename unpacke
+00016cf0: 745f 7472 6169 7473 3c74 7970 656e 616d  t_traits<typenam
+00016d00: 6520 756e 7061 636b 6574 5f74 7261 6974  e unpacket_trait
+00016d10: 733c 5061 636b 6574 3e3a 3a68 616c 663e  s<Packet>::half>
+00016d20: 3a3a 6861 6c66 2051 7561 7274 6572 5061  ::half QuarterPa
+00016d30: 636b 6574 3b0a 2020 656e 756d 207b 2050  cket;.  enum { P
+00016d40: 6163 6b65 7453 697a 6520 3d20 756e 7061  acketSize = unpa
 00016d50: 636b 6574 5f74 7261 6974 733c 5061 636b  cket_traits<Pack
-00016d60: 6574 3e3a 3a68 616c 6620 4861 6c66 5061  et>::half HalfPa
-00016d70: 636b 6574 3b0a 2020 7479 7065 6465 6620  cket;.  typedef 
-00016d80: 7479 7065 6e61 6d65 2075 6e70 6163 6b65  typename unpacke
-00016d90: 745f 7472 6169 7473 3c74 7970 656e 616d  t_traits<typenam
-00016da0: 6520 756e 7061 636b 6574 5f74 7261 6974  e unpacket_trait
-00016db0: 733c 5061 636b 6574 3e3a 3a68 616c 663e  s<Packet>::half>
-00016dc0: 3a3a 6861 6c66 2051 7561 7274 6572 5061  ::half QuarterPa
-00016dd0: 636b 6574 3b0a 2020 656e 756d 207b 2050  cket;.  enum { P
-00016de0: 6163 6b65 7453 697a 6520 3d20 756e 7061  acketSize = unpa
-00016df0: 636b 6574 5f74 7261 6974 733c 5061 636b  cket_traits<Pack
-00016e00: 6574 3e3a 3a73 697a 652c 0a20 2020 2020  et>::size,.     
-00016e10: 2020 2020 4861 6c66 5061 636b 6574 5369      HalfPacketSi
-00016e20: 7a65 203d 2075 6e70 6163 6b65 745f 7472  ze = unpacket_tr
-00016e30: 6169 7473 3c48 616c 6650 6163 6b65 743e  aits<HalfPacket>
-00016e40: 3a3a 7369 7a65 2c0a 2020 2020 2020 2020  ::size,.        
-00016e50: 2051 7561 7274 6572 5061 636b 6574 5369   QuarterPacketSi
-00016e60: 7a65 203d 2075 6e70 6163 6b65 745f 7472  ze = unpacket_tr
-00016e70: 6169 7473 3c51 7561 7274 6572 5061 636b  aits<QuarterPack
-00016e80: 6574 3e3a 3a73 697a 652c 0a20 2020 2020  et>::size,.     
-00016e90: 2020 2020 4861 7348 616c 6620 3d20 2869      HasHalf = (i
-00016ea0: 6e74 2948 616c 6650 6163 6b65 7453 697a  nt)HalfPacketSiz
-00016eb0: 6520 3c20 2869 6e74 2950 6163 6b65 7453  e < (int)PacketS
-00016ec0: 697a 652c 0a20 2020 2020 2020 2020 4861  ize,.         Ha
-00016ed0: 7351 7561 7274 6572 203d 2028 696e 7429  sQuarter = (int)
-00016ee0: 5175 6172 7465 7250 6163 6b65 7453 697a  QuarterPacketSiz
-00016ef0: 6520 3c20 2869 6e74 2948 616c 6650 6163  e < (int)HalfPac
-00016f00: 6b65 7453 697a 657d 3b0a 0a20 2045 4947  ketSize};..  EIG
-00016f10: 454e 5f41 534d 5f43 4f4d 4d45 4e54 2822  EN_ASM_COMMENT("
-00016f20: 4549 4745 4e20 5052 4f44 5543 5420 5041  EIGEN PRODUCT PA
-00016f30: 434b 204c 4853 2229 3b0a 2020 4549 4745  CK LHS");.  EIGE
-00016f40: 4e5f 554e 5553 4544 5f56 4152 4941 424c  N_UNUSED_VARIABL
-00016f50: 4528 7374 7269 6465 293b 0a20 2045 4947  E(stride);.  EIG
-00016f60: 454e 5f55 4e55 5345 445f 5641 5249 4142  EN_UNUSED_VARIAB
-00016f70: 4c45 286f 6666 7365 7429 3b0a 2020 6569  LE(offset);.  ei
-00016f80: 6765 6e5f 6173 7365 7274 2828 2821 5061  gen_assert(((!Pa
-00016f90: 6e65 6c4d 6f64 6529 2026 2620 7374 7269  nelMode) && stri
-00016fa0: 6465 3d3d 3020 2626 206f 6666 7365 743d  de==0 && offset=
-00016fb0: 3d30 2920 7c7c 2028 5061 6e65 6c4d 6f64  =0) || (PanelMod
-00016fc0: 6520 2626 2073 7472 6964 653e 3d64 6570  e && stride>=dep
-00016fd0: 7468 2026 2620 6f66 6673 6574 3c3d 7374  th && offset<=st
-00016fe0: 7269 6465 2929 3b0a 2020 6569 6765 6e5f  ride));.  eigen_
-00016ff0: 6173 7365 7274 2820 2828 5061 636b 3125  assert( ((Pack1%
-00017000: 5061 636b 6574 5369 7a65 293d 3d30 2026  PacketSize)==0 &
-00017010: 2620 5061 636b 313c 3d34 2a50 6163 6b65  & Pack1<=4*Packe
-00017020: 7453 697a 6529 207c 7c20 2850 6163 6b31  tSize) || (Pack1
-00017030: 3c3d 3429 2029 3b0a 2020 636f 6e6a 5f69  <=4) );.  conj_i
-00017040: 663c 4e75 6d54 7261 6974 733c 5363 616c  f<NumTraits<Scal
-00017050: 6172 3e3a 3a49 7343 6f6d 706c 6578 2026  ar>::IsComplex &
-00017060: 2620 436f 6e6a 7567 6174 653e 2063 6a3b  & Conjugate> cj;
-00017070: 0a20 2049 6e64 6578 2063 6f75 6e74 203d  .  Index count =
-00017080: 2030 3b0a 0a20 2063 6f6e 7374 2049 6e64   0;..  const Ind
-00017090: 6578 2070 6565 6c65 645f 6d63 3320 3d20  ex peeled_mc3 = 
-000170a0: 5061 636b 313e 3d33 2a50 6163 6b65 7453  Pack1>=3*PacketS
-000170b0: 697a 6520 3f20 2872 6f77 732f 2833 2a50  ize ? (rows/(3*P
-000170c0: 6163 6b65 7453 697a 6529 292a 2833 2a50  acketSize))*(3*P
-000170d0: 6163 6b65 7453 697a 6529 203a 2030 3b0a  acketSize) : 0;.
-000170e0: 2020 636f 6e73 7420 496e 6465 7820 7065    const Index pe
-000170f0: 656c 6564 5f6d 6332 203d 2050 6163 6b31  eled_mc2 = Pack1
-00017100: 3e3d 322a 5061 636b 6574 5369 7a65 203f  >=2*PacketSize ?
-00017110: 2070 6565 6c65 645f 6d63 332b 2828 726f   peeled_mc3+((ro
-00017120: 7773 2d70 6565 6c65 645f 6d63 3329 2f28  ws-peeled_mc3)/(
-00017130: 322a 5061 636b 6574 5369 7a65 2929 2a28  2*PacketSize))*(
-00017140: 322a 5061 636b 6574 5369 7a65 2920 3a20  2*PacketSize) : 
-00017150: 303b 0a20 2063 6f6e 7374 2049 6e64 6578  0;.  const Index
-00017160: 2070 6565 6c65 645f 6d63 3120 3d20 5061   peeled_mc1 = Pa
-00017170: 636b 313e 3d31 2a50 6163 6b65 7453 697a  ck1>=1*PacketSiz
-00017180: 6520 3f20 7065 656c 6564 5f6d 6332 2b28  e ? peeled_mc2+(
-00017190: 2872 6f77 732d 7065 656c 6564 5f6d 6332  (rows-peeled_mc2
-000171a0: 292f 2831 2a50 6163 6b65 7453 697a 6529  )/(1*PacketSize)
-000171b0: 292a 2831 2a50 6163 6b65 7453 697a 6529  )*(1*PacketSize)
-000171c0: 203a 2030 3b0a 2020 636f 6e73 7420 496e   : 0;.  const In
-000171d0: 6465 7820 7065 656c 6564 5f6d 635f 6861  dex peeled_mc_ha
-000171e0: 6c66 203d 2050 6163 6b31 3e3d 4861 6c66  lf = Pack1>=Half
-000171f0: 5061 636b 6574 5369 7a65 203f 2070 6565  PacketSize ? pee
-00017200: 6c65 645f 6d63 312b 2828 726f 7773 2d70  led_mc1+((rows-p
-00017210: 6565 6c65 645f 6d63 3129 2f28 4861 6c66  eeled_mc1)/(Half
-00017220: 5061 636b 6574 5369 7a65 2929 2a28 4861  PacketSize))*(Ha
-00017230: 6c66 5061 636b 6574 5369 7a65 2920 3a20  lfPacketSize) : 
-00017240: 303b 0a20 2063 6f6e 7374 2049 6e64 6578  0;.  const Index
-00017250: 2070 6565 6c65 645f 6d63 5f71 7561 7274   peeled_mc_quart
-00017260: 6572 203d 2050 6163 6b31 3e3d 5175 6172  er = Pack1>=Quar
-00017270: 7465 7250 6163 6b65 7453 697a 6520 3f20  terPacketSize ? 
-00017280: 2872 6f77 732f 2851 7561 7274 6572 5061  (rows/(QuarterPa
-00017290: 636b 6574 5369 7a65 2929 2a28 5175 6172  cketSize))*(Quar
-000172a0: 7465 7250 6163 6b65 7453 697a 6529 203a  terPacketSize) :
-000172b0: 2030 3b0a 2020 636f 6e73 7420 496e 6465   0;.  const Inde
-000172c0: 7820 6c61 7374 5f6c 6873 5f70 726f 6772  x last_lhs_progr
-000172d0: 6573 7320 3d20 726f 7773 203e 2070 6565  ess = rows > pee
-000172e0: 6c65 645f 6d63 5f71 7561 7274 6572 203f  led_mc_quarter ?
-000172f0: 2028 726f 7773 202d 2070 6565 6c65 645f   (rows - peeled_
-00017300: 6d63 5f71 7561 7274 6572 2920 2620 7e31  mc_quarter) & ~1
-00017310: 203a 2030 3b0a 2020 636f 6e73 7420 496e   : 0;.  const In
-00017320: 6465 7820 7065 656c 6564 5f6d 6330 203d  dex peeled_mc0 =
-00017330: 2050 6163 6b32 3e3d 5061 636b 6574 5369   Pack2>=PacketSi
-00017340: 7a65 203f 2070 6565 6c65 645f 6d63 5f71  ze ? peeled_mc_q
-00017350: 7561 7274 6572 0a20 2020 2020 2020 2020  uarter.         
-00017360: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00017370: 3a20 5061 636b 323e 3120 2626 206c 6173  : Pack2>1 && las
-00017380: 745f 6c68 735f 7072 6f67 7265 7373 203f  t_lhs_progress ?
-00017390: 2028 726f 7773 2f6c 6173 745f 6c68 735f   (rows/last_lhs_
-000173a0: 7072 6f67 7265 7373 292a 6c61 7374 5f6c  progress)*last_l
-000173b0: 6873 5f70 726f 6772 6573 7320 3a20 303b  hs_progress : 0;
-000173c0: 0a0a 2020 496e 6465 7820 693d 303b 0a0a  ..  Index i=0;..
-000173d0: 2020 2f2f 2050 6163 6b20 3320 7061 636b    // Pack 3 pack
-000173e0: 6574 730a 2020 6966 2850 6163 6b31 3e3d  ets.  if(Pack1>=
-000173f0: 332a 5061 636b 6574 5369 7a65 290a 2020  3*PacketSize).  
-00017400: 7b0a 2020 2020 666f 7228 3b20 693c 7065  {.    for(; i<pe
-00017410: 656c 6564 5f6d 6333 3b20 692b 3d33 2a50  eled_mc3; i+=3*P
-00017420: 6163 6b65 7453 697a 6529 0a20 2020 207b  acketSize).    {
-00017430: 0a20 2020 2020 2069 6628 5061 6e65 6c4d  .      if(PanelM
-00017440: 6f64 6529 2063 6f75 6e74 202b 3d20 2833  ode) count += (3
-00017450: 2a50 6163 6b65 7453 697a 6529 202a 206f  *PacketSize) * o
-00017460: 6666 7365 743b 0a0a 2020 2020 2020 666f  ffset;..      fo
-00017470: 7228 496e 6465 7820 6b3d 303b 206b 3c64  r(Index k=0; k<d
-00017480: 6570 7468 3b20 6b2b 2b29 0a20 2020 2020  epth; k++).     
-00017490: 207b 0a20 2020 2020 2020 2050 6163 6b65   {.        Packe
-000174a0: 7420 412c 2042 2c20 433b 0a20 2020 2020  t A, B, C;.     
-000174b0: 2020 2041 203d 206c 6873 2e74 656d 706c     A = lhs.templ
-000174c0: 6174 6520 6c6f 6164 5061 636b 6574 3c50  ate loadPacket<P
-000174d0: 6163 6b65 743e 2869 2b30 2a50 6163 6b65  acket>(i+0*Packe
-000174e0: 7453 697a 652c 206b 293b 0a20 2020 2020  tSize, k);.     
-000174f0: 2020 2042 203d 206c 6873 2e74 656d 706c     B = lhs.templ
-00017500: 6174 6520 6c6f 6164 5061 636b 6574 3c50  ate loadPacket<P
-00017510: 6163 6b65 743e 2869 2b31 2a50 6163 6b65  acket>(i+1*Packe
-00017520: 7453 697a 652c 206b 293b 0a20 2020 2020  tSize, k);.     
-00017530: 2020 2043 203d 206c 6873 2e74 656d 706c     C = lhs.templ
-00017540: 6174 6520 6c6f 6164 5061 636b 6574 3c50  ate loadPacket<P
-00017550: 6163 6b65 743e 2869 2b32 2a50 6163 6b65  acket>(i+2*Packe
-00017560: 7453 697a 652c 206b 293b 0a20 2020 2020  tSize, k);.     
-00017570: 2020 2070 7374 6f72 6528 626c 6f63 6b41     pstore(blockA
-00017580: 2b63 6f75 6e74 2c20 636a 2e70 636f 6e6a  +count, cj.pconj
-00017590: 2841 2929 3b20 636f 756e 742b 3d50 6163  (A)); count+=Pac
-000175a0: 6b65 7453 697a 653b 0a20 2020 2020 2020  ketSize;.       
-000175b0: 2070 7374 6f72 6528 626c 6f63 6b41 2b63   pstore(blockA+c
-000175c0: 6f75 6e74 2c20 636a 2e70 636f 6e6a 2842  ount, cj.pconj(B
-000175d0: 2929 3b20 636f 756e 742b 3d50 6163 6b65  )); count+=Packe
-000175e0: 7453 697a 653b 0a20 2020 2020 2020 2070  tSize;.        p
-000175f0: 7374 6f72 6528 626c 6f63 6b41 2b63 6f75  store(blockA+cou
-00017600: 6e74 2c20 636a 2e70 636f 6e6a 2843 2929  nt, cj.pconj(C))
-00017610: 3b20 636f 756e 742b 3d50 6163 6b65 7453  ; count+=PacketS
-00017620: 697a 653b 0a20 2020 2020 207d 0a20 2020  ize;.      }.   
-00017630: 2020 2069 6628 5061 6e65 6c4d 6f64 6529     if(PanelMode)
-00017640: 2063 6f75 6e74 202b 3d20 2833 2a50 6163   count += (3*Pac
-00017650: 6b65 7453 697a 6529 202a 2028 7374 7269  ketSize) * (stri
-00017660: 6465 2d6f 6666 7365 742d 6465 7074 6829  de-offset-depth)
-00017670: 3b0a 2020 2020 7d0a 2020 7d0a 2020 2f2f  ;.    }.  }.  //
-00017680: 2050 6163 6b20 3220 7061 636b 6574 730a   Pack 2 packets.
-00017690: 2020 6966 2850 6163 6b31 3e3d 322a 5061    if(Pack1>=2*Pa
-000176a0: 636b 6574 5369 7a65 290a 2020 7b0a 2020  cketSize).  {.  
-000176b0: 2020 666f 7228 3b20 693c 7065 656c 6564    for(; i<peeled
-000176c0: 5f6d 6332 3b20 692b 3d32 2a50 6163 6b65  _mc2; i+=2*Packe
-000176d0: 7453 697a 6529 0a20 2020 207b 0a20 2020  tSize).    {.   
-000176e0: 2020 2069 6628 5061 6e65 6c4d 6f64 6529     if(PanelMode)
-000176f0: 2063 6f75 6e74 202b 3d20 2832 2a50 6163   count += (2*Pac
-00017700: 6b65 7453 697a 6529 202a 206f 6666 7365  ketSize) * offse
-00017710: 743b 0a0a 2020 2020 2020 666f 7228 496e  t;..      for(In
-00017720: 6465 7820 6b3d 303b 206b 3c64 6570 7468  dex k=0; k<depth
-00017730: 3b20 6b2b 2b29 0a20 2020 2020 207b 0a20  ; k++).      {. 
-00017740: 2020 2020 2020 2050 6163 6b65 7420 412c         Packet A,
-00017750: 2042 3b0a 2020 2020 2020 2020 4120 3d20   B;.        A = 
-00017760: 6c68 732e 7465 6d70 6c61 7465 206c 6f61  lhs.template loa
-00017770: 6450 6163 6b65 743c 5061 636b 6574 3e28  dPacket<Packet>(
-00017780: 692b 302a 5061 636b 6574 5369 7a65 2c20  i+0*PacketSize, 
-00017790: 6b29 3b0a 2020 2020 2020 2020 4220 3d20  k);.        B = 
-000177a0: 6c68 732e 7465 6d70 6c61 7465 206c 6f61  lhs.template loa
-000177b0: 6450 6163 6b65 743c 5061 636b 6574 3e28  dPacket<Packet>(
-000177c0: 692b 312a 5061 636b 6574 5369 7a65 2c20  i+1*PacketSize, 
-000177d0: 6b29 3b0a 2020 2020 2020 2020 7073 746f  k);.        psto
-000177e0: 7265 2862 6c6f 636b 412b 636f 756e 742c  re(blockA+count,
-000177f0: 2063 6a2e 7063 6f6e 6a28 4129 293b 2063   cj.pconj(A)); c
-00017800: 6f75 6e74 2b3d 5061 636b 6574 5369 7a65  ount+=PacketSize
-00017810: 3b0a 2020 2020 2020 2020 7073 746f 7265  ;.        pstore
-00017820: 2862 6c6f 636b 412b 636f 756e 742c 2063  (blockA+count, c
-00017830: 6a2e 7063 6f6e 6a28 4229 293b 2063 6f75  j.pconj(B)); cou
-00017840: 6e74 2b3d 5061 636b 6574 5369 7a65 3b0a  nt+=PacketSize;.
-00017850: 2020 2020 2020 7d0a 2020 2020 2020 6966        }.      if
-00017860: 2850 616e 656c 4d6f 6465 2920 636f 756e  (PanelMode) coun
-00017870: 7420 2b3d 2028 322a 5061 636b 6574 5369  t += (2*PacketSi
-00017880: 7a65 2920 2a20 2873 7472 6964 652d 6f66  ze) * (stride-of
-00017890: 6673 6574 2d64 6570 7468 293b 0a20 2020  fset-depth);.   
-000178a0: 207d 0a20 207d 0a20 202f 2f20 5061 636b   }.  }.  // Pack
-000178b0: 2031 2070 6163 6b65 7473 0a20 2069 6628   1 packets.  if(
-000178c0: 5061 636b 313e 3d31 2a50 6163 6b65 7453  Pack1>=1*PacketS
-000178d0: 697a 6529 0a20 207b 0a20 2020 2066 6f72  ize).  {.    for
-000178e0: 283b 2069 3c70 6565 6c65 645f 6d63 313b  (; i<peeled_mc1;
-000178f0: 2069 2b3d 312a 5061 636b 6574 5369 7a65   i+=1*PacketSize
-00017900: 290a 2020 2020 7b0a 2020 2020 2020 6966  ).    {.      if
-00017910: 2850 616e 656c 4d6f 6465 2920 636f 756e  (PanelMode) coun
-00017920: 7420 2b3d 2028 312a 5061 636b 6574 5369  t += (1*PacketSi
-00017930: 7a65 2920 2a20 6f66 6673 6574 3b0a 0a20  ze) * offset;.. 
-00017940: 2020 2020 2066 6f72 2849 6e64 6578 206b       for(Index k
-00017950: 3d30 3b20 6b3c 6465 7074 683b 206b 2b2b  =0; k<depth; k++
-00017960: 290a 2020 2020 2020 7b0a 2020 2020 2020  ).      {.      
-00017970: 2020 5061 636b 6574 2041 3b0a 2020 2020    Packet A;.    
-00017980: 2020 2020 4120 3d20 6c68 732e 7465 6d70      A = lhs.temp
-00017990: 6c61 7465 206c 6f61 6450 6163 6b65 743c  late loadPacket<
-000179a0: 5061 636b 6574 3e28 692b 302a 5061 636b  Packet>(i+0*Pack
-000179b0: 6574 5369 7a65 2c20 6b29 3b0a 2020 2020  etSize, k);.    
-000179c0: 2020 2020 7073 746f 7265 2862 6c6f 636b      pstore(block
-000179d0: 412b 636f 756e 742c 2063 6a2e 7063 6f6e  A+count, cj.pcon
-000179e0: 6a28 4129 293b 0a20 2020 2020 2020 2063  j(A));.        c
-000179f0: 6f75 6e74 2b3d 5061 636b 6574 5369 7a65  ount+=PacketSize
-00017a00: 3b0a 2020 2020 2020 7d0a 2020 2020 2020  ;.      }.      
-00017a10: 6966 2850 616e 656c 4d6f 6465 2920 636f  if(PanelMode) co
-00017a20: 756e 7420 2b3d 2028 312a 5061 636b 6574  unt += (1*Packet
-00017a30: 5369 7a65 2920 2a20 2873 7472 6964 652d  Size) * (stride-
-00017a40: 6f66 6673 6574 2d64 6570 7468 293b 0a20  offset-depth);. 
-00017a50: 2020 207d 0a20 207d 0a20 202f 2f20 5061     }.  }.  // Pa
-00017a60: 636b 2068 616c 6620 7061 636b 6574 730a  ck half packets.
-00017a70: 2020 6966 2848 6173 4861 6c66 2026 2620    if(HasHalf && 
-00017a80: 5061 636b 313e 3d48 616c 6650 6163 6b65  Pack1>=HalfPacke
-00017a90: 7453 697a 6529 0a20 207b 0a20 2020 2066  tSize).  {.    f
-00017aa0: 6f72 283b 2069 3c70 6565 6c65 645f 6d63  or(; i<peeled_mc
-00017ab0: 5f68 616c 663b 2069 2b3d 4861 6c66 5061  _half; i+=HalfPa
-00017ac0: 636b 6574 5369 7a65 290a 2020 2020 7b0a  cketSize).    {.
-00017ad0: 2020 2020 2020 6966 2850 616e 656c 4d6f        if(PanelMo
-00017ae0: 6465 2920 636f 756e 7420 2b3d 2028 4861  de) count += (Ha
-00017af0: 6c66 5061 636b 6574 5369 7a65 2920 2a20  lfPacketSize) * 
-00017b00: 6f66 6673 6574 3b0a 0a20 2020 2020 2066  offset;..      f
-00017b10: 6f72 2849 6e64 6578 206b 3d30 3b20 6b3c  or(Index k=0; k<
-00017b20: 6465 7074 683b 206b 2b2b 290a 2020 2020  depth; k++).    
-00017b30: 2020 7b0a 2020 2020 2020 2020 4861 6c66    {.        Half
-00017b40: 5061 636b 6574 2041 3b0a 2020 2020 2020  Packet A;.      
-00017b50: 2020 4120 3d20 6c68 732e 7465 6d70 6c61    A = lhs.templa
-00017b60: 7465 206c 6f61 6450 6163 6b65 743c 4861  te loadPacket<Ha
-00017b70: 6c66 5061 636b 6574 3e28 692b 302a 2848  lfPacket>(i+0*(H
-00017b80: 616c 6650 6163 6b65 7453 697a 6529 2c20  alfPacketSize), 
-00017b90: 6b29 3b0a 2020 2020 2020 2020 7073 746f  k);.        psto
-00017ba0: 7265 7528 626c 6f63 6b41 2b63 6f75 6e74  reu(blockA+count
-00017bb0: 2c20 636a 2e70 636f 6e6a 2841 2929 3b0a  , cj.pconj(A));.
-00017bc0: 2020 2020 2020 2020 636f 756e 742b 3d48          count+=H
-00017bd0: 616c 6650 6163 6b65 7453 697a 653b 0a20  alfPacketSize;. 
-00017be0: 2020 2020 207d 0a20 2020 2020 2069 6628       }.      if(
-00017bf0: 5061 6e65 6c4d 6f64 6529 2063 6f75 6e74  PanelMode) count
-00017c00: 202b 3d20 2848 616c 6650 6163 6b65 7453   += (HalfPacketS
-00017c10: 697a 6529 202a 2028 7374 7269 6465 2d6f  ize) * (stride-o
-00017c20: 6666 7365 742d 6465 7074 6829 3b0a 2020  ffset-depth);.  
-00017c30: 2020 7d0a 2020 7d0a 2020 2f2f 2050 6163    }.  }.  // Pac
-00017c40: 6b20 7175 6172 7465 7220 7061 636b 6574  k quarter packet
-00017c50: 730a 2020 6966 2848 6173 5175 6172 7465  s.  if(HasQuarte
-00017c60: 7220 2626 2050 6163 6b31 3e3d 5175 6172  r && Pack1>=Quar
-00017c70: 7465 7250 6163 6b65 7453 697a 6529 0a20  terPacketSize). 
-00017c80: 207b 0a20 2020 2066 6f72 283b 2069 3c70   {.    for(; i<p
-00017c90: 6565 6c65 645f 6d63 5f71 7561 7274 6572  eeled_mc_quarter
-00017ca0: 3b20 692b 3d51 7561 7274 6572 5061 636b  ; i+=QuarterPack
-00017cb0: 6574 5369 7a65 290a 2020 2020 7b0a 2020  etSize).    {.  
-00017cc0: 2020 2020 6966 2850 616e 656c 4d6f 6465      if(PanelMode
-00017cd0: 2920 636f 756e 7420 2b3d 2028 5175 6172  ) count += (Quar
-00017ce0: 7465 7250 6163 6b65 7453 697a 6529 202a  terPacketSize) *
-00017cf0: 206f 6666 7365 743b 0a0a 2020 2020 2020   offset;..      
-00017d00: 666f 7228 496e 6465 7820 6b3d 303b 206b  for(Index k=0; k
-00017d10: 3c64 6570 7468 3b20 6b2b 2b29 0a20 2020  <depth; k++).   
-00017d20: 2020 207b 0a20 2020 2020 2020 2051 7561     {.        Qua
-00017d30: 7274 6572 5061 636b 6574 2041 3b0a 2020  rterPacket A;.  
-00017d40: 2020 2020 2020 4120 3d20 6c68 732e 7465        A = lhs.te
-00017d50: 6d70 6c61 7465 206c 6f61 6450 6163 6b65  mplate loadPacke
-00017d60: 743c 5175 6172 7465 7250 6163 6b65 743e  t<QuarterPacket>
-00017d70: 2869 2b30 2a28 5175 6172 7465 7250 6163  (i+0*(QuarterPac
-00017d80: 6b65 7453 697a 6529 2c20 6b29 3b0a 2020  ketSize), k);.  
-00017d90: 2020 2020 2020 7073 746f 7265 7528 626c        pstoreu(bl
-00017da0: 6f63 6b41 2b63 6f75 6e74 2c20 636a 2e70  ockA+count, cj.p
-00017db0: 636f 6e6a 2841 2929 3b0a 2020 2020 2020  conj(A));.      
-00017dc0: 2020 636f 756e 742b 3d51 7561 7274 6572    count+=Quarter
-00017dd0: 5061 636b 6574 5369 7a65 3b0a 2020 2020  PacketSize;.    
-00017de0: 2020 7d0a 2020 2020 2020 6966 2850 616e    }.      if(Pan
-00017df0: 656c 4d6f 6465 2920 636f 756e 7420 2b3d  elMode) count +=
-00017e00: 2028 5175 6172 7465 7250 6163 6b65 7453   (QuarterPacketS
-00017e10: 697a 6529 202a 2028 7374 7269 6465 2d6f  ize) * (stride-o
-00017e20: 6666 7365 742d 6465 7074 6829 3b0a 2020  ffset-depth);.  
-00017e30: 2020 7d0a 2020 7d0a 2020 2f2f 2050 6163    }.  }.  // Pac
-00017e40: 6b32 206d 6179 2062 6520 2a73 6d61 6c6c  k2 may be *small
-00017e50: 6572 2a20 7468 616e 2050 6163 6b65 7453  er* than PacketS
-00017e60: 697a 65e2 8094 7468 6174 2068 6170 7065  ize...that happe
-00017e70: 6e73 2066 6f72 0a20 202f 2f20 7072 6f64  ns for.  // prod
-00017e80: 7563 7473 206c 696b 6520 7265 616c 202a  ucts like real *
-00017e90: 2063 6f6d 706c 6578 2c20 7768 6572 6520   complex, where 
-00017ea0: 7765 2068 6176 6520 746f 2067 6f20 6861  we have to go ha
-00017eb0: 6c66 2074 6865 0a20 202f 2f20 7072 6f67  lf the.  // prog
-00017ec0: 7265 7373 206f 6e20 7468 6520 6c68 7320  ress on the lhs 
-00017ed0: 696e 206f 7264 6572 2074 6f20 6475 706c  in order to dupl
-00017ee0: 6963 6174 6520 7468 6f73 6520 6f70 6572  icate those oper
-00017ef0: 616e 6473 2074 6f0a 2020 2f2f 2061 6464  ands to.  // add
-00017f00: 7265 7373 2062 6f74 6820 7265 616c 2026  ress both real &
-00017f10: 2069 6d61 6769 6e61 7279 2070 6172 7473   imaginary parts
-00017f20: 206f 6e20 7468 6520 7268 732e 2054 6869   on the rhs. Thi
-00017f30: 7320 706f 7274 696f 6e20 7769 6c6c 0a20  s portion will. 
-00017f40: 202f 2f20 7061 636b 2074 686f 7365 2068   // pack those h
-00017f50: 616c 6620 6f6e 6573 2075 6e74 696c 2074  alf ones until t
-00017f60: 6865 7920 6d61 7463 6820 7468 6520 6e75  hey match the nu
-00017f70: 6d62 6572 2065 7870 6563 7465 6420 6f6e  mber expected on
-00017f80: 2074 6865 0a20 202f 2f20 6c61 7374 2070   the.  // last p
-00017f90: 6565 6c69 6e67 206c 6f6f 7020 6174 2074  eeling loop at t
-00017fa0: 6869 7320 706f 696e 7420 2866 6f72 2074  his point (for t
-00017fb0: 6865 2072 6873 292e 0a20 2069 6628 5061  he rhs)..  if(Pa
-00017fc0: 636b 323c 5061 636b 6574 5369 7a65 2026  ck2<PacketSize &
-00017fd0: 2620 5061 636b 323e 3129 0a20 207b 0a20  & Pack2>1).  {. 
-00017fe0: 2020 2066 6f72 283b 2069 3c70 6565 6c65     for(; i<peele
-00017ff0: 645f 6d63 303b 2069 2b3d 6c61 7374 5f6c  d_mc0; i+=last_l
-00018000: 6873 5f70 726f 6772 6573 7329 0a20 2020  hs_progress).   
-00018010: 207b 0a20 2020 2020 2069 6628 5061 6e65   {.      if(Pane
-00018020: 6c4d 6f64 6529 2063 6f75 6e74 202b 3d20  lMode) count += 
-00018030: 6c61 7374 5f6c 6873 5f70 726f 6772 6573  last_lhs_progres
-00018040: 7320 2a20 6f66 6673 6574 3b0a 0a20 2020  s * offset;..   
-00018050: 2020 2066 6f72 2849 6e64 6578 206b 3d30     for(Index k=0
-00018060: 3b20 6b3c 6465 7074 683b 206b 2b2b 290a  ; k<depth; k++).
-00018070: 2020 2020 2020 2020 666f 7228 496e 6465          for(Inde
-00018080: 7820 773d 303b 2077 3c6c 6173 745f 6c68  x w=0; w<last_lh
-00018090: 735f 7072 6f67 7265 7373 3b20 772b 2b29  s_progress; w++)
-000180a0: 0a20 2020 2020 2020 2020 2062 6c6f 636b  .          block
-000180b0: 415b 636f 756e 742b 2b5d 203d 2063 6a28  A[count++] = cj(
-000180c0: 6c68 7328 692b 772c 206b 2929 3b0a 0a20  lhs(i+w, k));.. 
-000180d0: 2020 2020 2069 6628 5061 6e65 6c4d 6f64       if(PanelMod
-000180e0: 6529 2063 6f75 6e74 202b 3d20 6c61 7374  e) count += last
-000180f0: 5f6c 6873 5f70 726f 6772 6573 7320 2a20  _lhs_progress * 
-00018100: 2873 7472 6964 652d 6f66 6673 6574 2d64  (stride-offset-d
-00018110: 6570 7468 293b 0a20 2020 207d 0a20 207d  epth);.    }.  }
-00018120: 0a20 202f 2f20 5061 636b 2073 6361 6c61  .  // Pack scala
-00018130: 7273 0a20 2066 6f72 283b 2069 3c72 6f77  rs.  for(; i<row
-00018140: 733b 2069 2b2b 290a 2020 7b0a 2020 2020  s; i++).  {.    
-00018150: 6966 2850 616e 656c 4d6f 6465 2920 636f  if(PanelMode) co
-00018160: 756e 7420 2b3d 206f 6666 7365 743b 0a20  unt += offset;. 
-00018170: 2020 2066 6f72 2849 6e64 6578 206b 3d30     for(Index k=0
-00018180: 3b20 6b3c 6465 7074 683b 206b 2b2b 290a  ; k<depth; k++).
-00018190: 2020 2020 2020 626c 6f63 6b41 5b63 6f75        blockA[cou
-000181a0: 6e74 2b2b 5d20 3d20 636a 286c 6873 2869  nt++] = cj(lhs(i
-000181b0: 2c20 6b29 293b 0a20 2020 2069 6628 5061  , k));.    if(Pa
-000181c0: 6e65 6c4d 6f64 6529 2063 6f75 6e74 202b  nelMode) count +
-000181d0: 3d20 2873 7472 6964 652d 6f66 6673 6574  = (stride-offset
-000181e0: 2d64 6570 7468 293b 0a20 207d 0a7d 0a0a  -depth);.  }.}..
-000181f0: 7465 6d70 6c61 7465 3c74 7970 656e 616d  template<typenam
-00018200: 6520 5363 616c 6172 2c20 7479 7065 6e61  e Scalar, typena
-00018210: 6d65 2049 6e64 6578 2c20 7479 7065 6e61  me Index, typena
-00018220: 6d65 2044 6174 614d 6170 7065 722c 2069  me DataMapper, i
-00018230: 6e74 2050 6163 6b31 2c20 696e 7420 5061  nt Pack1, int Pa
-00018240: 636b 322c 2074 7970 656e 616d 6520 5061  ck2, typename Pa
-00018250: 636b 6574 2c20 626f 6f6c 2043 6f6e 6a75  cket, bool Conju
-00018260: 6761 7465 2c20 626f 6f6c 2050 616e 656c  gate, bool Panel
-00018270: 4d6f 6465 3e0a 7374 7275 6374 2067 656d  Mode>.struct gem
-00018280: 6d5f 7061 636b 5f6c 6873 3c53 6361 6c61  m_pack_lhs<Scala
-00018290: 722c 2049 6e64 6578 2c20 4461 7461 4d61  r, Index, DataMa
-000182a0: 7070 6572 2c20 5061 636b 312c 2050 6163  pper, Pack1, Pac
-000182b0: 6b32 2c20 5061 636b 6574 2c20 526f 774d  k2, Packet, RowM
-000182c0: 616a 6f72 2c20 436f 6e6a 7567 6174 652c  ajor, Conjugate,
-000182d0: 2050 616e 656c 4d6f 6465 3e0a 7b0a 2020   PanelMode>.{.  
-000182e0: 7479 7065 6465 6620 7479 7065 6e61 6d65  typedef typename
-000182f0: 2044 6174 614d 6170 7065 723a 3a4c 696e   DataMapper::Lin
-00018300: 6561 724d 6170 7065 7220 4c69 6e65 6172  earMapper Linear
-00018310: 4d61 7070 6572 3b0a 2020 4549 4745 4e5f  Mapper;.  EIGEN_
-00018320: 444f 4e54 5f49 4e4c 494e 4520 766f 6964  DONT_INLINE void
-00018330: 206f 7065 7261 746f 7228 2928 5363 616c   operator()(Scal
-00018340: 6172 2a20 626c 6f63 6b41 2c20 636f 6e73  ar* blockA, cons
-00018350: 7420 4461 7461 4d61 7070 6572 2620 6c68  t DataMapper& lh
-00018360: 732c 2049 6e64 6578 2064 6570 7468 2c20  s, Index depth, 
-00018370: 496e 6465 7820 726f 7773 2c20 496e 6465  Index rows, Inde
-00018380: 7820 7374 7269 6465 3d30 2c20 496e 6465  x stride=0, Inde
-00018390: 7820 6f66 6673 6574 3d30 293b 0a7d 3b0a  x offset=0);.};.
-000183a0: 0a74 656d 706c 6174 653c 7479 7065 6e61  .template<typena
-000183b0: 6d65 2053 6361 6c61 722c 2074 7970 656e  me Scalar, typen
-000183c0: 616d 6520 496e 6465 782c 2074 7970 656e  ame Index, typen
-000183d0: 616d 6520 4461 7461 4d61 7070 6572 2c20  ame DataMapper, 
-000183e0: 696e 7420 5061 636b 312c 2069 6e74 2050  int Pack1, int P
-000183f0: 6163 6b32 2c20 7479 7065 6e61 6d65 2050  ack2, typename P
-00018400: 6163 6b65 742c 2062 6f6f 6c20 436f 6e6a  acket, bool Conj
-00018410: 7567 6174 652c 2062 6f6f 6c20 5061 6e65  ugate, bool Pane
-00018420: 6c4d 6f64 653e 0a45 4947 454e 5f44 4f4e  lMode>.EIGEN_DON
-00018430: 545f 494e 4c49 4e45 2076 6f69 6420 6765  T_INLINE void ge
-00018440: 6d6d 5f70 6163 6b5f 6c68 733c 5363 616c  mm_pack_lhs<Scal
-00018450: 6172 2c20 496e 6465 782c 2044 6174 614d  ar, Index, DataM
-00018460: 6170 7065 722c 2050 6163 6b31 2c20 5061  apper, Pack1, Pa
-00018470: 636b 322c 2050 6163 6b65 742c 2052 6f77  ck2, Packet, Row
-00018480: 4d61 6a6f 722c 2043 6f6e 6a75 6761 7465  Major, Conjugate
-00018490: 2c20 5061 6e65 6c4d 6f64 653e 0a20 203a  , PanelMode>.  :
-000184a0: 3a6f 7065 7261 746f 7228 2928 5363 616c  :operator()(Scal
-000184b0: 6172 2a20 626c 6f63 6b41 2c20 636f 6e73  ar* blockA, cons
-000184c0: 7420 4461 7461 4d61 7070 6572 2620 6c68  t DataMapper& lh
-000184d0: 732c 2049 6e64 6578 2064 6570 7468 2c20  s, Index depth, 
-000184e0: 496e 6465 7820 726f 7773 2c20 496e 6465  Index rows, Inde
-000184f0: 7820 7374 7269 6465 2c20 496e 6465 7820  x stride, Index 
-00018500: 6f66 6673 6574 290a 7b0a 2020 7479 7065  offset).{.  type
-00018510: 6465 6620 7479 7065 6e61 6d65 2075 6e70  def typename unp
-00018520: 6163 6b65 745f 7472 6169 7473 3c50 6163  acket_traits<Pac
-00018530: 6b65 743e 3a3a 6861 6c66 2048 616c 6650  ket>::half HalfP
-00018540: 6163 6b65 743b 0a20 2074 7970 6564 6566  acket;.  typedef
-00018550: 2074 7970 656e 616d 6520 756e 7061 636b   typename unpack
-00018560: 6574 5f74 7261 6974 733c 7479 7065 6e61  et_traits<typena
-00018570: 6d65 2075 6e70 6163 6b65 745f 7472 6169  me unpacket_trai
-00018580: 7473 3c50 6163 6b65 743e 3a3a 6861 6c66  ts<Packet>::half
-00018590: 3e3a 3a68 616c 6620 5175 6172 7465 7250  >::half QuarterP
-000185a0: 6163 6b65 743b 0a20 2065 6e75 6d20 7b20  acket;.  enum { 
-000185b0: 5061 636b 6574 5369 7a65 203d 2075 6e70  PacketSize = unp
-000185c0: 6163 6b65 745f 7472 6169 7473 3c50 6163  acket_traits<Pac
-000185d0: 6b65 743e 3a3a 7369 7a65 2c0a 2020 2020  ket>::size,.    
-000185e0: 2020 2020 2048 616c 6650 6163 6b65 7453       HalfPacketS
-000185f0: 697a 6520 3d20 756e 7061 636b 6574 5f74  ize = unpacket_t
-00018600: 7261 6974 733c 4861 6c66 5061 636b 6574  raits<HalfPacket
-00018610: 3e3a 3a73 697a 652c 0a20 2020 2020 2020  >::size,.       
-00018620: 2020 5175 6172 7465 7250 6163 6b65 7453    QuarterPacketS
-00018630: 697a 6520 3d20 756e 7061 636b 6574 5f74  ize = unpacket_t
-00018640: 7261 6974 733c 5175 6172 7465 7250 6163  raits<QuarterPac
-00018650: 6b65 743e 3a3a 7369 7a65 2c0a 2020 2020  ket>::size,.    
-00018660: 2020 2020 2048 6173 4861 6c66 203d 2028       HasHalf = (
-00018670: 696e 7429 4861 6c66 5061 636b 6574 5369  int)HalfPacketSi
-00018680: 7a65 203c 2028 696e 7429 5061 636b 6574  ze < (int)Packet
-00018690: 5369 7a65 2c0a 2020 2020 2020 2020 2048  Size,.         H
-000186a0: 6173 5175 6172 7465 7220 3d20 2869 6e74  asQuarter = (int
-000186b0: 2951 7561 7274 6572 5061 636b 6574 5369  )QuarterPacketSi
-000186c0: 7a65 203c 2028 696e 7429 4861 6c66 5061  ze < (int)HalfPa
-000186d0: 636b 6574 5369 7a65 7d3b 0a0a 2020 4549  cketSize};..  EI
-000186e0: 4745 4e5f 4153 4d5f 434f 4d4d 454e 5428  GEN_ASM_COMMENT(
-000186f0: 2245 4947 454e 2050 524f 4455 4354 2050  "EIGEN PRODUCT P
-00018700: 4143 4b20 4c48 5322 293b 0a20 2045 4947  ACK LHS");.  EIG
-00018710: 454e 5f55 4e55 5345 445f 5641 5249 4142  EN_UNUSED_VARIAB
-00018720: 4c45 2873 7472 6964 6529 3b0a 2020 4549  LE(stride);.  EI
-00018730: 4745 4e5f 554e 5553 4544 5f56 4152 4941  GEN_UNUSED_VARIA
-00018740: 424c 4528 6f66 6673 6574 293b 0a20 2065  BLE(offset);.  e
-00018750: 6967 656e 5f61 7373 6572 7428 2828 2150  igen_assert(((!P
-00018760: 616e 656c 4d6f 6465 2920 2626 2073 7472  anelMode) && str
-00018770: 6964 653d 3d30 2026 2620 6f66 6673 6574  ide==0 && offset
-00018780: 3d3d 3029 207c 7c20 2850 616e 656c 4d6f  ==0) || (PanelMo
-00018790: 6465 2026 2620 7374 7269 6465 3e3d 6465  de && stride>=de
-000187a0: 7074 6820 2626 206f 6666 7365 743c 3d73  pth && offset<=s
-000187b0: 7472 6964 6529 293b 0a20 2063 6f6e 6a5f  tride));.  conj_
-000187c0: 6966 3c4e 756d 5472 6169 7473 3c53 6361  if<NumTraits<Sca
-000187d0: 6c61 723e 3a3a 4973 436f 6d70 6c65 7820  lar>::IsComplex 
-000187e0: 2626 2043 6f6e 6a75 6761 7465 3e20 636a  && Conjugate> cj
-000187f0: 3b0a 2020 496e 6465 7820 636f 756e 7420  ;.  Index count 
-00018800: 3d20 303b 0a20 2062 6f6f 6c20 676f 6e65  = 0;.  bool gone
-00018810: 5f68 616c 6620 3d20 6661 6c73 652c 2067  _half = false, g
-00018820: 6f6e 655f 7175 6172 7465 7220 3d20 6661  one_quarter = fa
-00018830: 6c73 652c 2067 6f6e 655f 6c61 7374 203d  lse, gone_last =
-00018840: 2066 616c 7365 3b0a 0a20 2049 6e64 6578   false;..  Index
-00018850: 2069 203d 2030 3b0a 2020 696e 7420 7061   i = 0;.  int pa
-00018860: 636b 203d 2050 6163 6b31 3b0a 2020 696e  ck = Pack1;.  in
-00018870: 7420 7073 697a 6520 3d20 5061 636b 6574  t psize = Packet
-00018880: 5369 7a65 3b0a 2020 7768 696c 6528 7061  Size;.  while(pa
-00018890: 636b 3e30 290a 2020 7b0a 2020 2020 496e  ck>0).  {.    In
-000188a0: 6465 7820 7265 6d61 696e 696e 675f 726f  dex remaining_ro
-000188b0: 7773 203d 2072 6f77 732d 693b 0a20 2020  ws = rows-i;.   
-000188c0: 2049 6e64 6578 2070 6565 6c65 645f 6d63   Index peeled_mc
-000188d0: 203d 2067 6f6e 655f 6c61 7374 203f 2050   = gone_last ? P
-000188e0: 6163 6b32 3e31 203f 2028 726f 7773 2f70  ack2>1 ? (rows/p
-000188f0: 6163 6b29 2a70 6163 6b20 3a20 3020 3a20  ack)*pack : 0 : 
-00018900: 692b 2872 656d 6169 6e69 6e67 5f72 6f77  i+(remaining_row
-00018910: 732f 7061 636b 292a 7061 636b 3b0a 2020  s/pack)*pack;.  
-00018920: 2020 496e 6465 7820 7374 6172 7469 6e67    Index starting
-00018930: 5f70 6f73 203d 2069 3b0a 2020 2020 666f  _pos = i;.    fo
-00018940: 7228 3b20 693c 7065 656c 6564 5f6d 633b  r(; i<peeled_mc;
-00018950: 2069 2b3d 7061 636b 290a 2020 2020 7b0a   i+=pack).    {.
-00018960: 2020 2020 2020 6966 2850 616e 656c 4d6f        if(PanelMo
-00018970: 6465 2920 636f 756e 7420 2b3d 2070 6163  de) count += pac
-00018980: 6b20 2a20 6f66 6673 6574 3b0a 0a20 2020  k * offset;..   
-00018990: 2020 2049 6e64 6578 206b 3d30 3b0a 2020     Index k=0;.  
-000189a0: 2020 2020 6966 2870 6163 6b3e 3d70 7369      if(pack>=psi
-000189b0: 7a65 2026 2620 7073 697a 6520 3e3d 2051  ze && psize >= Q
-000189c0: 7561 7274 6572 5061 636b 6574 5369 7a65  uarterPacketSize
-000189d0: 290a 2020 2020 2020 7b0a 2020 2020 2020  ).      {.      
-000189e0: 2020 636f 6e73 7420 496e 6465 7820 7065    const Index pe
-000189f0: 656c 6564 5f6b 203d 2028 6465 7074 682f  eled_k = (depth/
-00018a00: 7073 697a 6529 2a70 7369 7a65 3b0a 2020  psize)*psize;.  
-00018a10: 2020 2020 2020 666f 7228 3b20 6b3c 7065        for(; k<pe
-00018a20: 656c 6564 5f6b 3b20 6b2b 3d70 7369 7a65  eled_k; k+=psize
-00018a30: 290a 2020 2020 2020 2020 7b0a 2020 2020  ).        {.    
-00018a40: 2020 2020 2020 666f 7220 2849 6e64 6578        for (Index
-00018a50: 206d 203d 2030 3b20 6d20 3c20 7061 636b   m = 0; m < pack
-00018a60: 3b20 6d20 2b3d 2070 7369 7a65 290a 2020  ; m += psize).  
-00018a70: 2020 2020 2020 2020 7b0a 2020 2020 2020          {.      
-00018a80: 2020 2020 2020 6966 2028 7073 697a 6520        if (psize 
-00018a90: 3d3d 2050 6163 6b65 7453 697a 6529 207b  == PacketSize) {
-00018aa0: 0a20 2020 2020 2020 2020 2020 2020 2050  .              P
-00018ab0: 6163 6b65 7442 6c6f 636b 3c50 6163 6b65  acketBlock<Packe
-00018ac0: 743e 206b 6572 6e65 6c3b 0a20 2020 2020  t> kernel;.     
-00018ad0: 2020 2020 2020 2020 2066 6f72 2028 696e           for (in
-00018ae0: 7420 7020 3d20 303b 2070 203c 2070 7369  t p = 0; p < psi
-00018af0: 7a65 3b20 2b2b 7029 206b 6572 6e65 6c2e  ze; ++p) kernel.
-00018b00: 7061 636b 6574 5b70 5d20 3d20 6c68 732e  packet[p] = lhs.
-00018b10: 7465 6d70 6c61 7465 206c 6f61 6450 6163  template loadPac
-00018b20: 6b65 743c 5061 636b 6574 3e28 692b 702b  ket<Packet>(i+p+
-00018b30: 6d2c 206b 293b 0a20 2020 2020 2020 2020  m, k);.         
-00018b40: 2020 2020 2070 7472 616e 7370 6f73 6528       ptranspose(
-00018b50: 6b65 726e 656c 293b 0a20 2020 2020 2020  kernel);.       
-00018b60: 2020 2020 2020 2066 6f72 2028 696e 7420         for (int 
-00018b70: 7020 3d20 303b 2070 203c 2070 7369 7a65  p = 0; p < psize
-00018b80: 3b20 2b2b 7029 2070 7374 6f72 6528 626c  ; ++p) pstore(bl
-00018b90: 6f63 6b41 2b63 6f75 6e74 2b6d 2b28 7061  ockA+count+m+(pa
-00018ba0: 636b 292a 702c 2063 6a2e 7063 6f6e 6a28  ck)*p, cj.pconj(
-00018bb0: 6b65 726e 656c 2e70 6163 6b65 745b 705d  kernel.packet[p]
-00018bc0: 2929 3b0a 2020 2020 2020 2020 2020 2020  ));.            
-00018bd0: 7d20 656c 7365 2069 6620 2848 6173 4861  } else if (HasHa
-00018be0: 6c66 2026 2620 7073 697a 6520 3d3d 2048  lf && psize == H
-00018bf0: 616c 6650 6163 6b65 7453 697a 6529 207b  alfPacketSize) {
-00018c00: 0a20 2020 2020 2020 2020 2020 2020 2067  .              g
-00018c10: 6f6e 655f 6861 6c66 203d 2074 7275 653b  one_half = true;
-00018c20: 0a20 2020 2020 2020 2020 2020 2020 2050  .              P
-00018c30: 6163 6b65 7442 6c6f 636b 3c48 616c 6650  acketBlock<HalfP
-00018c40: 6163 6b65 743e 206b 6572 6e65 6c5f 6861  acket> kernel_ha
-00018c50: 6c66 3b0a 2020 2020 2020 2020 2020 2020  lf;.            
-00018c60: 2020 666f 7220 2869 6e74 2070 203d 2030    for (int p = 0
-00018c70: 3b20 7020 3c20 7073 697a 653b 202b 2b70  ; p < psize; ++p
-00018c80: 2920 6b65 726e 656c 5f68 616c 662e 7061  ) kernel_half.pa
-00018c90: 636b 6574 5b70 5d20 3d20 6c68 732e 7465  cket[p] = lhs.te
-00018ca0: 6d70 6c61 7465 206c 6f61 6450 6163 6b65  mplate loadPacke
-00018cb0: 743c 4861 6c66 5061 636b 6574 3e28 692b  t<HalfPacket>(i+
-00018cc0: 702b 6d2c 206b 293b 0a20 2020 2020 2020  p+m, k);.       
-00018cd0: 2020 2020 2020 2070 7472 616e 7370 6f73         ptranspos
-00018ce0: 6528 6b65 726e 656c 5f68 616c 6629 3b0a  e(kernel_half);.
-00018cf0: 2020 2020 2020 2020 2020 2020 2020 666f                fo
-00018d00: 7220 2869 6e74 2070 203d 2030 3b20 7020  r (int p = 0; p 
-00018d10: 3c20 7073 697a 653b 202b 2b70 2920 7073  < psize; ++p) ps
-00018d20: 746f 7265 2862 6c6f 636b 412b 636f 756e  tore(blockA+coun
-00018d30: 742b 6d2b 2870 6163 6b29 2a70 2c20 636a  t+m+(pack)*p, cj
-00018d40: 2e70 636f 6e6a 286b 6572 6e65 6c5f 6861  .pconj(kernel_ha
-00018d50: 6c66 2e70 6163 6b65 745b 705d 2929 3b0a  lf.packet[p]));.
-00018d60: 2020 2020 2020 2020 2020 2020 7d20 656c              } el
-00018d70: 7365 2069 6620 2848 6173 5175 6172 7465  se if (HasQuarte
-00018d80: 7220 2626 2070 7369 7a65 203d 3d20 5175  r && psize == Qu
-00018d90: 6172 7465 7250 6163 6b65 7453 697a 6529  arterPacketSize)
-00018da0: 207b 0a20 2020 2020 2020 2020 2020 2020   {.             
-00018db0: 2067 6f6e 655f 7175 6172 7465 7220 3d20   gone_quarter = 
-00018dc0: 7472 7565 3b0a 2020 2020 2020 2020 2020  true;.          
-00018dd0: 2020 2020 5061 636b 6574 426c 6f63 6b3c      PacketBlock<
-00018de0: 5175 6172 7465 7250 6163 6b65 743e 206b  QuarterPacket> k
-00018df0: 6572 6e65 6c5f 7175 6172 7465 723b 0a20  ernel_quarter;. 
-00018e00: 2020 2020 2020 2020 2020 2020 2066 6f72               for
-00018e10: 2028 696e 7420 7020 3d20 303b 2070 203c   (int p = 0; p <
-00018e20: 2070 7369 7a65 3b20 2b2b 7029 206b 6572   psize; ++p) ker
-00018e30: 6e65 6c5f 7175 6172 7465 722e 7061 636b  nel_quarter.pack
-00018e40: 6574 5b70 5d20 3d20 6c68 732e 7465 6d70  et[p] = lhs.temp
-00018e50: 6c61 7465 206c 6f61 6450 6163 6b65 743c  late loadPacket<
-00018e60: 5175 6172 7465 7250 6163 6b65 743e 2869  QuarterPacket>(i
-00018e70: 2b70 2b6d 2c20 6b29 3b0a 2020 2020 2020  +p+m, k);.      
-00018e80: 2020 2020 2020 2020 7074 7261 6e73 706f          ptranspo
-00018e90: 7365 286b 6572 6e65 6c5f 7175 6172 7465  se(kernel_quarte
-00018ea0: 7229 3b0a 2020 2020 2020 2020 2020 2020  r);.            
-00018eb0: 2020 666f 7220 2869 6e74 2070 203d 2030    for (int p = 0
-00018ec0: 3b20 7020 3c20 7073 697a 653b 202b 2b70  ; p < psize; ++p
-00018ed0: 2920 7073 746f 7265 2862 6c6f 636b 412b  ) pstore(blockA+
-00018ee0: 636f 756e 742b 6d2b 2870 6163 6b29 2a70  count+m+(pack)*p
-00018ef0: 2c20 636a 2e70 636f 6e6a 286b 6572 6e65  , cj.pconj(kerne
-00018f00: 6c5f 7175 6172 7465 722e 7061 636b 6574  l_quarter.packet
-00018f10: 5b70 5d29 293b 0a09 2020 2020 7d0a 2020  [p]));..    }.  
-00018f20: 2020 2020 2020 2020 7d0a 2020 2020 2020          }.      
-00018f30: 2020 2020 636f 756e 7420 2b3d 2070 7369      count += psi
-00018f40: 7a65 2a70 6163 6b3b 0a20 2020 2020 2020  ze*pack;.       
-00018f50: 207d 0a20 2020 2020 207d 0a0a 2020 2020   }.      }..    
-00018f60: 2020 666f 7228 3b20 6b3c 6465 7074 683b    for(; k<depth;
-00018f70: 206b 2b2b 290a 2020 2020 2020 7b0a 2020   k++).      {.  
-00018f80: 2020 2020 2020 496e 6465 7820 773d 303b        Index w=0;
-00018f90: 0a20 2020 2020 2020 2066 6f72 283b 2077  .        for(; w
-00018fa0: 3c70 6163 6b2d 333b 2077 2b3d 3429 0a20  <pack-3; w+=4). 
-00018fb0: 2020 2020 2020 207b 0a20 2020 2020 2020         {.       
-00018fc0: 2020 2053 6361 6c61 7220 6128 636a 286c     Scalar a(cj(l
-00018fd0: 6873 2869 2b77 2b30 2c20 6b29 2929 2c0a  hs(i+w+0, k))),.
-00018fe0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00018ff0: 2062 2863 6a28 6c68 7328 692b 772b 312c   b(cj(lhs(i+w+1,
-00019000: 206b 2929 292c 0a20 2020 2020 2020 2020   k))),.         
-00019010: 2020 2020 2020 2020 6328 636a 286c 6873          c(cj(lhs
-00019020: 2869 2b77 2b32 2c20 6b29 2929 2c0a 2020  (i+w+2, k))),.  
-00019030: 2020 2020 2020 2020 2020 2020 2020 2064                 d
-00019040: 2863 6a28 6c68 7328 692b 772b 332c 206b  (cj(lhs(i+w+3, k
-00019050: 2929 293b 0a20 2020 2020 2020 2020 2062  )));.          b
-00019060: 6c6f 636b 415b 636f 756e 742b 2b5d 203d  lockA[count++] =
-00019070: 2061 3b0a 2020 2020 2020 2020 2020 626c   a;.          bl
-00019080: 6f63 6b41 5b63 6f75 6e74 2b2b 5d20 3d20  ockA[count++] = 
-00019090: 623b 0a20 2020 2020 2020 2020 2062 6c6f  b;.          blo
-000190a0: 636b 415b 636f 756e 742b 2b5d 203d 2063  ckA[count++] = c
-000190b0: 3b0a 2020 2020 2020 2020 2020 626c 6f63  ;.          bloc
-000190c0: 6b41 5b63 6f75 6e74 2b2b 5d20 3d20 643b  kA[count++] = d;
-000190d0: 0a20 2020 2020 2020 207d 0a20 2020 2020  .        }.     
-000190e0: 2020 2069 6628 7061 636b 2534 290a 2020     if(pack%4).  
-000190f0: 2020 2020 2020 2020 666f 7228 3b77 3c70          for(;w<p
-00019100: 6163 6b3b 2b2b 7729 0a20 2020 2020 2020  ack;++w).       
-00019110: 2020 2020 2062 6c6f 636b 415b 636f 756e       blockA[coun
-00019120: 742b 2b5d 203d 2063 6a28 6c68 7328 692b  t++] = cj(lhs(i+
-00019130: 772c 206b 2929 3b0a 2020 2020 2020 7d0a  w, k));.      }.
-00019140: 0a20 2020 2020 2069 6628 5061 6e65 6c4d  .      if(PanelM
-00019150: 6f64 6529 2063 6f75 6e74 202b 3d20 7061  ode) count += pa
-00019160: 636b 202a 2028 7374 7269 6465 2d6f 6666  ck * (stride-off
-00019170: 7365 742d 6465 7074 6829 3b0a 2020 2020  set-depth);.    
-00019180: 7d0a 0a20 2020 2070 6163 6b20 2d3d 2070  }..    pack -= p
-00019190: 7369 7a65 3b0a 2020 2020 496e 6465 7820  size;.    Index 
-000191a0: 6c65 6674 203d 2072 6f77 7320 2d20 693b  left = rows - i;
-000191b0: 0a20 2020 2069 6620 2870 6163 6b20 3c3d  .    if (pack <=
-000191c0: 2030 2920 7b0a 2020 2020 2020 6966 2028   0) {.      if (
-000191d0: 2167 6f6e 655f 6c61 7374 2026 260a 2020  !gone_last &&.  
-000191e0: 2020 2020 2020 2020 2873 7461 7274 696e          (startin
-000191f0: 675f 706f 7320 3d3d 2069 207c 7c20 6c65  g_pos == i || le
-00019200: 6674 203e 3d20 7073 697a 652f 3220 7c7c  ft >= psize/2 ||
-00019210: 206c 6566 7420 3e3d 2070 7369 7a65 2f34   left >= psize/4
-00019220: 2920 2626 0a20 2020 2020 2020 2020 2028  ) &&.          (
-00019230: 2870 7369 7a65 2f32 203d 3d20 4861 6c66  (psize/2 == Half
-00019240: 5061 636b 6574 5369 7a65 2026 2620 4861  PacketSize && Ha
-00019250: 7348 616c 6620 2626 2021 676f 6e65 5f68  sHalf && !gone_h
-00019260: 616c 6629 207c 7c0a 2020 2020 2020 2020  alf) ||.        
-00019270: 2020 2028 7073 697a 652f 3220 3d3d 2051     (psize/2 == Q
-00019280: 7561 7274 6572 5061 636b 6574 5369 7a65  uarterPacketSize
-00019290: 2026 2620 4861 7351 7561 7274 6572 2026   && HasQuarter &
-000192a0: 2620 2167 6f6e 655f 7175 6172 7465 7229  & !gone_quarter)
-000192b0: 2929 207b 0a20 2020 2020 2020 2070 7369  )) {.        psi
-000192c0: 7a65 202f 3d20 323b 0a20 2020 2020 2020  ze /= 2;.       
-000192d0: 2070 6163 6b20 3d20 7073 697a 653b 0a20   pack = psize;. 
-000192e0: 2020 2020 2020 2063 6f6e 7469 6e75 653b         continue;
-000192f0: 0a20 2020 2020 207d 0a20 2020 2020 202f  .      }.      /
-00019300: 2f20 5061 636b 3220 6d61 7920 6265 202a  / Pack2 may be *
-00019310: 736d 616c 6c65 722a 2074 6861 6e20 5061  smaller* than Pa
-00019320: 636b 6574 5369 7a65 e280 9474 6861 7420  cketSize...that 
-00019330: 6861 7070 656e 7320 666f 720a 2020 2020  happens for.    
-00019340: 2020 2f2f 2070 726f 6475 6374 7320 6c69    // products li
-00019350: 6b65 2072 6561 6c20 2a20 636f 6d70 6c65  ke real * comple
-00019360: 782c 2077 6865 7265 2077 6520 6861 7665  x, where we have
-00019370: 2074 6f20 676f 2068 616c 6620 7468 650a   to go half the.
-00019380: 2020 2020 2020 2f2f 2070 726f 6772 6573        // progres
-00019390: 7320 6f6e 2074 6865 206c 6873 2069 6e20  s on the lhs in 
-000193a0: 6f72 6465 7220 746f 2064 7570 6c69 6361  order to duplica
-000193b0: 7465 2074 686f 7365 206f 7065 7261 6e64  te those operand
-000193c0: 7320 746f 0a20 2020 2020 202f 2f20 6164  s to.      // ad
-000193d0: 6472 6573 7320 626f 7468 2072 6561 6c20  dress both real 
-000193e0: 2620 696d 6167 696e 6172 7920 7061 7274  & imaginary part
-000193f0: 7320 6f6e 2074 6865 2072 6873 2e20 5468  s on the rhs. Th
-00019400: 6973 2070 6f72 7469 6f6e 2077 696c 6c0a  is portion will.
-00019410: 2020 2020 2020 2f2f 2070 6163 6b20 7468        // pack th
-00019420: 6f73 6520 6861 6c66 206f 6e65 7320 756e  ose half ones un
-00019430: 7469 6c20 7468 6579 206d 6174 6368 2074  til they match t
-00019440: 6865 206e 756d 6265 7220 6578 7065 6374  he number expect
-00019450: 6564 206f 6e20 7468 650a 2020 2020 2020  ed on the.      
-00019460: 2f2f 206c 6173 7420 7065 656c 696e 6720  // last peeling 
-00019470: 6c6f 6f70 2061 7420 7468 6973 2070 6f69  loop at this poi
-00019480: 6e74 2028 666f 7220 7468 6520 7268 7329  nt (for the rhs)
-00019490: 2e0a 2020 2020 2020 6966 2028 5061 636b  ..      if (Pack
-000194a0: 3220 3c20 5061 636b 6574 5369 7a65 2026  2 < PacketSize &
-000194b0: 2620 2167 6f6e 655f 6c61 7374 2920 7b0a  & !gone_last) {.
-000194c0: 2020 2020 2020 2020 676f 6e65 5f6c 6173          gone_las
-000194d0: 7420 3d20 7472 7565 3b0a 2020 2020 2020  t = true;.      
-000194e0: 2020 7073 697a 6520 3d20 7061 636b 203d    psize = pack =
-000194f0: 206c 6566 7420 2620 7e31 3b0a 2020 2020   left & ~1;.    
-00019500: 2020 7d0a 2020 2020 7d0a 2020 7d0a 0a20    }.    }.  }.. 
-00019510: 2066 6f72 283b 2069 3c72 6f77 733b 2069   for(; i<rows; i
-00019520: 2b2b 290a 2020 7b0a 2020 2020 6966 2850  ++).  {.    if(P
-00019530: 616e 656c 4d6f 6465 2920 636f 756e 7420  anelMode) count 
-00019540: 2b3d 206f 6666 7365 743b 0a20 2020 2066  += offset;.    f
-00019550: 6f72 2849 6e64 6578 206b 3d30 3b20 6b3c  or(Index k=0; k<
-00019560: 6465 7074 683b 206b 2b2b 290a 2020 2020  depth; k++).    
-00019570: 2020 626c 6f63 6b41 5b63 6f75 6e74 2b2b    blockA[count++
-00019580: 5d20 3d20 636a 286c 6873 2869 2c20 6b29  ] = cj(lhs(i, k)
-00019590: 293b 0a20 2020 2069 6628 5061 6e65 6c4d  );.    if(PanelM
-000195a0: 6f64 6529 2063 6f75 6e74 202b 3d20 2873  ode) count += (s
-000195b0: 7472 6964 652d 6f66 6673 6574 2d64 6570  tride-offset-dep
-000195c0: 7468 293b 0a20 207d 0a7d 0a0a 2f2f 2063  th);.  }.}..// c
-000195d0: 6f70 7920 6120 636f 6d70 6c65 7465 2070  opy a complete p
-000195e0: 616e 656c 206f 6620 7468 6520 7268 730a  anel of the rhs.
-000195f0: 2f2f 2074 6869 7320 7665 7273 696f 6e20  // this version 
-00019600: 6973 206f 7074 696d 697a 6564 2066 6f72  is optimized for
-00019610: 2063 6f6c 756d 6e20 6d61 6a6f 7220 6d61   column major ma
-00019620: 7472 6963 6573 0a2f 2f20 5468 6520 7472  trices.// The tr
-00019630: 6176 6572 7361 6c20 6f72 6465 7220 6973  aversal order is
-00019640: 2061 7320 666f 6c6c 6f77 3a20 286e 723d   as follow: (nr=
-00019650: 3d34 293a 0a2f 2f20 2030 2020 3120 2032  =4):.//  0  1  2
-00019660: 2020 3320 2020 3132 2031 3320 3134 2031    3   12 13 14 1
-00019670: 3520 2020 3234 2032 370a 2f2f 2020 3420  5   24 27.//  4 
-00019680: 2035 2020 3620 2037 2020 2031 3620 3137   5  6  7   16 17
-00019690: 2031 3820 3139 2020 2032 3520 3238 0a2f   18 19   25 28./
-000196a0: 2f20 2038 2020 3920 3130 2031 3120 2020  /  8  9 10 11   
-000196b0: 3230 2032 3120 3232 2032 3320 2020 3236  20 21 22 23   26
-000196c0: 2032 390a 2f2f 2020 2e20 202e 2020 2e20   29.//  .  .  . 
-000196d0: 202e 2020 2020 2e20 202e 2020 2e20 202e   .    .  .  .  .
-000196e0: 2020 2020 2e20 202e 0a74 656d 706c 6174      .  ..templat
-000196f0: 653c 7479 7065 6e61 6d65 2053 6361 6c61  e<typename Scala
-00019700: 722c 2074 7970 656e 616d 6520 496e 6465  r, typename Inde
-00019710: 782c 2074 7970 656e 616d 6520 4461 7461  x, typename Data
-00019720: 4d61 7070 6572 2c20 696e 7420 6e72 2c20  Mapper, int nr, 
-00019730: 626f 6f6c 2043 6f6e 6a75 6761 7465 2c20  bool Conjugate, 
-00019740: 626f 6f6c 2050 616e 656c 4d6f 6465 3e0a  bool PanelMode>.
-00019750: 7374 7275 6374 2067 656d 6d5f 7061 636b  struct gemm_pack
-00019760: 5f72 6873 3c53 6361 6c61 722c 2049 6e64  _rhs<Scalar, Ind
-00019770: 6578 2c20 4461 7461 4d61 7070 6572 2c20  ex, DataMapper, 
-00019780: 6e72 2c20 436f 6c4d 616a 6f72 2c20 436f  nr, ColMajor, Co
-00019790: 6e6a 7567 6174 652c 2050 616e 656c 4d6f  njugate, PanelMo
-000197a0: 6465 3e0a 7b0a 2020 7479 7065 6465 6620  de>.{.  typedef 
-000197b0: 7479 7065 6e61 6d65 2070 6163 6b65 745f  typename packet_
-000197c0: 7472 6169 7473 3c53 6361 6c61 723e 3a3a  traits<Scalar>::
-000197d0: 7479 7065 2050 6163 6b65 743b 0a20 2074  type Packet;.  t
-000197e0: 7970 6564 6566 2074 7970 656e 616d 6520  ypedef typename 
-000197f0: 4461 7461 4d61 7070 6572 3a3a 4c69 6e65  DataMapper::Line
-00019800: 6172 4d61 7070 6572 204c 696e 6561 724d  arMapper LinearM
-00019810: 6170 7065 723b 0a20 2065 6e75 6d20 7b20  apper;.  enum { 
-00019820: 5061 636b 6574 5369 7a65 203d 2070 6163  PacketSize = pac
-00019830: 6b65 745f 7472 6169 7473 3c53 6361 6c61  ket_traits<Scala
-00019840: 723e 3a3a 7369 7a65 207d 3b0a 2020 4549  r>::size };.  EI
-00019850: 4745 4e5f 444f 4e54 5f49 4e4c 494e 4520  GEN_DONT_INLINE 
-00019860: 766f 6964 206f 7065 7261 746f 7228 2928  void operator()(
-00019870: 5363 616c 6172 2a20 626c 6f63 6b42 2c20  Scalar* blockB, 
-00019880: 636f 6e73 7420 4461 7461 4d61 7070 6572  const DataMapper
-00019890: 2620 7268 732c 2049 6e64 6578 2064 6570  & rhs, Index dep
-000198a0: 7468 2c20 496e 6465 7820 636f 6c73 2c20  th, Index cols, 
-000198b0: 496e 6465 7820 7374 7269 6465 3d30 2c20  Index stride=0, 
-000198c0: 496e 6465 7820 6f66 6673 6574 3d30 293b  Index offset=0);
-000198d0: 0a7d 3b0a 0a74 656d 706c 6174 653c 7479  .};..template<ty
-000198e0: 7065 6e61 6d65 2053 6361 6c61 722c 2074  pename Scalar, t
-000198f0: 7970 656e 616d 6520 496e 6465 782c 2074  ypename Index, t
-00019900: 7970 656e 616d 6520 4461 7461 4d61 7070  ypename DataMapp
-00019910: 6572 2c20 696e 7420 6e72 2c20 626f 6f6c  er, int nr, bool
-00019920: 2043 6f6e 6a75 6761 7465 2c20 626f 6f6c   Conjugate, bool
-00019930: 2050 616e 656c 4d6f 6465 3e0a 4549 4745   PanelMode>.EIGE
-00019940: 4e5f 444f 4e54 5f49 4e4c 494e 4520 766f  N_DONT_INLINE vo
-00019950: 6964 2067 656d 6d5f 7061 636b 5f72 6873  id gemm_pack_rhs
-00019960: 3c53 6361 6c61 722c 2049 6e64 6578 2c20  <Scalar, Index, 
-00019970: 4461 7461 4d61 7070 6572 2c20 6e72 2c20  DataMapper, nr, 
-00019980: 436f 6c4d 616a 6f72 2c20 436f 6e6a 7567  ColMajor, Conjug
-00019990: 6174 652c 2050 616e 656c 4d6f 6465 3e0a  ate, PanelMode>.
-000199a0: 2020 3a3a 6f70 6572 6174 6f72 2829 2853    ::operator()(S
-000199b0: 6361 6c61 722a 2062 6c6f 636b 422c 2063  calar* blockB, c
-000199c0: 6f6e 7374 2044 6174 614d 6170 7065 7226  onst DataMapper&
-000199d0: 2072 6873 2c20 496e 6465 7820 6465 7074   rhs, Index dept
-000199e0: 682c 2049 6e64 6578 2063 6f6c 732c 2049  h, Index cols, I
-000199f0: 6e64 6578 2073 7472 6964 652c 2049 6e64  ndex stride, Ind
-00019a00: 6578 206f 6666 7365 7429 0a7b 0a20 2045  ex offset).{.  E
-00019a10: 4947 454e 5f41 534d 5f43 4f4d 4d45 4e54  IGEN_ASM_COMMENT
-00019a20: 2822 4549 4745 4e20 5052 4f44 5543 5420  ("EIGEN PRODUCT 
-00019a30: 5041 434b 2052 4853 2043 4f4c 4d41 4a4f  PACK RHS COLMAJO
-00019a40: 5222 293b 0a20 2045 4947 454e 5f55 4e55  R");.  EIGEN_UNU
-00019a50: 5345 445f 5641 5249 4142 4c45 2873 7472  SED_VARIABLE(str
-00019a60: 6964 6529 3b0a 2020 4549 4745 4e5f 554e  ide);.  EIGEN_UN
-00019a70: 5553 4544 5f56 4152 4941 424c 4528 6f66  USED_VARIABLE(of
-00019a80: 6673 6574 293b 0a20 2065 6967 656e 5f61  fset);.  eigen_a
-00019a90: 7373 6572 7428 2828 2150 616e 656c 4d6f  ssert(((!PanelMo
-00019aa0: 6465 2920 2626 2073 7472 6964 653d 3d30  de) && stride==0
-00019ab0: 2026 2620 6f66 6673 6574 3d3d 3029 207c   && offset==0) |
-00019ac0: 7c20 2850 616e 656c 4d6f 6465 2026 2620  | (PanelMode && 
-00019ad0: 7374 7269 6465 3e3d 6465 7074 6820 2626  stride>=depth &&
-00019ae0: 206f 6666 7365 743c 3d73 7472 6964 6529   offset<=stride)
-00019af0: 293b 0a20 2063 6f6e 6a5f 6966 3c4e 756d  );.  conj_if<Num
-00019b00: 5472 6169 7473 3c53 6361 6c61 723e 3a3a  Traits<Scalar>::
-00019b10: 4973 436f 6d70 6c65 7820 2626 2043 6f6e  IsComplex && Con
-00019b20: 6a75 6761 7465 3e20 636a 3b0a 2020 496e  jugate> cj;.  In
-00019b30: 6465 7820 7061 636b 6574 5f63 6f6c 7338  dex packet_cols8
-00019b40: 203d 206e 723e 3d38 203f 2028 636f 6c73   = nr>=8 ? (cols
-00019b50: 2f38 2920 2a20 3820 3a20 303b 0a20 2049  /8) * 8 : 0;.  I
-00019b60: 6e64 6578 2070 6163 6b65 745f 636f 6c73  ndex packet_cols
-00019b70: 3420 3d20 6e72 3e3d 3420 3f20 2863 6f6c  4 = nr>=4 ? (col
-00019b80: 732f 3429 202a 2034 203a 2030 3b0a 2020  s/4) * 4 : 0;.  
-00019b90: 496e 6465 7820 636f 756e 7420 3d20 303b  Index count = 0;
-00019ba0: 0a20 2063 6f6e 7374 2049 6e64 6578 2070  .  const Index p
-00019bb0: 6565 6c65 645f 6b20 3d20 2864 6570 7468  eeled_k = (depth
-00019bc0: 2f50 6163 6b65 7453 697a 6529 2a50 6163  /PacketSize)*Pac
-00019bd0: 6b65 7453 697a 653b 0a2f 2f20 2020 6966  ketSize;.//   if
-00019be0: 286e 723e 3d38 290a 2f2f 2020 207b 0a2f  (nr>=8).//   {./
-00019bf0: 2f20 2020 2020 666f 7228 496e 6465 7820  /     for(Index 
-00019c00: 6a32 3d30 3b20 6a32 3c70 6163 6b65 745f  j2=0; j2<packet_
-00019c10: 636f 6c73 383b 206a 322b 3d38 290a 2f2f  cols8; j2+=8).//
-00019c20: 2020 2020 207b 0a2f 2f20 2020 2020 2020       {.//       
-00019c30: 2f2f 2073 6b69 7020 7768 6174 2077 6520  // skip what we 
-00019c40: 6861 7665 2062 6566 6f72 650a 2f2f 2020  have before.//  
-00019c50: 2020 2020 2069 6628 5061 6e65 6c4d 6f64       if(PanelMod
-00019c60: 6529 2063 6f75 6e74 202b 3d20 3820 2a20  e) count += 8 * 
-00019c70: 6f66 6673 6574 3b0a 2f2f 2020 2020 2020  offset;.//      
-00019c80: 2063 6f6e 7374 2053 6361 6c61 722a 2062   const Scalar* b
-00019c90: 3020 3d20 2672 6873 5b28 6a32 2b30 292a  0 = &rhs[(j2+0)*
-00019ca0: 7268 7353 7472 6964 655d 3b0a 2f2f 2020  rhsStride];.//  
-00019cb0: 2020 2020 2063 6f6e 7374 2053 6361 6c61       const Scala
-00019cc0: 722a 2062 3120 3d20 2672 6873 5b28 6a32  r* b1 = &rhs[(j2
-00019cd0: 2b31 292a 7268 7353 7472 6964 655d 3b0a  +1)*rhsStride];.
-00019ce0: 2f2f 2020 2020 2020 2063 6f6e 7374 2053  //       const S
-00019cf0: 6361 6c61 722a 2062 3220 3d20 2672 6873  calar* b2 = &rhs
-00019d00: 5b28 6a32 2b32 292a 7268 7353 7472 6964  [(j2+2)*rhsStrid
-00019d10: 655d 3b0a 2f2f 2020 2020 2020 2063 6f6e  e];.//       con
-00019d20: 7374 2053 6361 6c61 722a 2062 3320 3d20  st Scalar* b3 = 
-00019d30: 2672 6873 5b28 6a32 2b33 292a 7268 7353  &rhs[(j2+3)*rhsS
-00019d40: 7472 6964 655d 3b0a 2f2f 2020 2020 2020  tride];.//      
-00019d50: 2063 6f6e 7374 2053 6361 6c61 722a 2062   const Scalar* b
-00019d60: 3420 3d20 2672 6873 5b28 6a32 2b34 292a  4 = &rhs[(j2+4)*
-00019d70: 7268 7353 7472 6964 655d 3b0a 2f2f 2020  rhsStride];.//  
-00019d80: 2020 2020 2063 6f6e 7374 2053 6361 6c61       const Scala
-00019d90: 722a 2062 3520 3d20 2672 6873 5b28 6a32  r* b5 = &rhs[(j2
-00019da0: 2b35 292a 7268 7353 7472 6964 655d 3b0a  +5)*rhsStride];.
-00019db0: 2f2f 2020 2020 2020 2063 6f6e 7374 2053  //       const S
-00019dc0: 6361 6c61 722a 2062 3620 3d20 2672 6873  calar* b6 = &rhs
-00019dd0: 5b28 6a32 2b36 292a 7268 7353 7472 6964  [(j2+6)*rhsStrid
-00019de0: 655d 3b0a 2f2f 2020 2020 2020 2063 6f6e  e];.//       con
-00019df0: 7374 2053 6361 6c61 722a 2062 3720 3d20  st Scalar* b7 = 
-00019e00: 2672 6873 5b28 6a32 2b37 292a 7268 7353  &rhs[(j2+7)*rhsS
-00019e10: 7472 6964 655d 3b0a 2f2f 2020 2020 2020  tride];.//      
-00019e20: 2049 6e64 6578 206b 3d30 3b0a 2f2f 2020   Index k=0;.//  
-00019e30: 2020 2020 2069 6628 5061 636b 6574 5369       if(PacketSi
-00019e40: 7a65 3d3d 3829 202f 2f20 544f 444f 2065  ze==8) // TODO e
-00019e50: 6e61 626c 6520 7665 6374 6f72 697a 6564  nable vectorized
-00019e60: 2074 7261 6e73 706f 7369 7469 6f6e 2066   transposition f
-00019e70: 6f72 2050 6163 6b65 7453 697a 653d 3d34  or PacketSize==4
-00019e80: 0a2f 2f20 2020 2020 2020 7b0a 2f2f 2020  .//       {.//  
-00019e90: 2020 2020 2020 2066 6f72 283b 206b 3c70         for(; k<p
-00019ea0: 6565 6c65 645f 6b3b 206b 2b3d 5061 636b  eeled_k; k+=Pack
-00019eb0: 6574 5369 7a65 2920 7b0a 2f2f 2020 2020  etSize) {.//    
-00019ec0: 2020 2020 2020 2050 6163 6b65 7442 6c6f         PacketBlo
-00019ed0: 636b 3c50 6163 6b65 743e 206b 6572 6e65  ck<Packet> kerne
-00019ee0: 6c3b 0a2f 2f20 2020 2020 2020 2020 2020  l;.//           
-00019ef0: 666f 7220 2869 6e74 2070 203d 2030 3b20  for (int p = 0; 
-00019f00: 7020 3c20 5061 636b 6574 5369 7a65 3b20  p < PacketSize; 
-00019f10: 2b2b 7029 207b 0a2f 2f20 2020 2020 2020  ++p) {.//       
-00019f20: 2020 2020 2020 6b65 726e 656c 2e70 6163        kernel.pac
-00019f30: 6b65 745b 705d 203d 2070 6c6f 6164 753c  ket[p] = ploadu<
-00019f40: 5061 636b 6574 3e28 2672 6873 5b28 6a32  Packet>(&rhs[(j2
-00019f50: 2b70 292a 7268 7353 7472 6964 652b 6b5d  +p)*rhsStride+k]
-00019f60: 293b 0a2f 2f20 2020 2020 2020 2020 2020  );.//           
-00019f70: 7d0a 2f2f 2020 2020 2020 2020 2020 2070  }.//           p
-00019f80: 7472 616e 7370 6f73 6528 6b65 726e 656c  transpose(kernel
-00019f90: 293b 0a2f 2f20 2020 2020 2020 2020 2020  );.//           
-00019fa0: 666f 7220 2869 6e74 2070 203d 2030 3b20  for (int p = 0; 
-00019fb0: 7020 3c20 5061 636b 6574 5369 7a65 3b20  p < PacketSize; 
-00019fc0: 2b2b 7029 207b 0a2f 2f20 2020 2020 2020  ++p) {.//       
-00019fd0: 2020 2020 2020 7073 746f 7265 7528 626c        pstoreu(bl
-00019fe0: 6f63 6b42 2b63 6f75 6e74 2c20 636a 2e70  ockB+count, cj.p
-00019ff0: 636f 6e6a 286b 6572 6e65 6c2e 7061 636b  conj(kernel.pack
-0001a000: 6574 5b70 5d29 293b 0a2f 2f20 2020 2020  et[p]));.//     
-0001a010: 2020 2020 2020 2020 636f 756e 742b 3d50          count+=P
-0001a020: 6163 6b65 7453 697a 653b 0a2f 2f20 2020  acketSize;.//   
-0001a030: 2020 2020 2020 2020 7d0a 2f2f 2020 2020          }.//    
-0001a040: 2020 2020 207d 0a2f 2f20 2020 2020 2020       }.//       
-0001a050: 7d0a 2f2f 2020 2020 2020 2066 6f72 283b  }.//       for(;
-0001a060: 206b 3c64 6570 7468 3b20 6b2b 2b29 0a2f   k<depth; k++)./
-0001a070: 2f20 2020 2020 2020 7b0a 2f2f 2020 2020  /       {.//    
-0001a080: 2020 2020 2062 6c6f 636b 425b 636f 756e       blockB[coun
-0001a090: 742b 305d 203d 2063 6a28 6230 5b6b 5d29  t+0] = cj(b0[k])
-0001a0a0: 3b0a 2f2f 2020 2020 2020 2020 2062 6c6f  ;.//         blo
-0001a0b0: 636b 425b 636f 756e 742b 315d 203d 2063  ckB[count+1] = c
-0001a0c0: 6a28 6231 5b6b 5d29 3b0a 2f2f 2020 2020  j(b1[k]);.//    
-0001a0d0: 2020 2020 2062 6c6f 636b 425b 636f 756e       blockB[coun
-0001a0e0: 742b 325d 203d 2063 6a28 6232 5b6b 5d29  t+2] = cj(b2[k])
-0001a0f0: 3b0a 2f2f 2020 2020 2020 2020 2062 6c6f  ;.//         blo
-0001a100: 636b 425b 636f 756e 742b 335d 203d 2063  ckB[count+3] = c
-0001a110: 6a28 6233 5b6b 5d29 3b0a 2f2f 2020 2020  j(b3[k]);.//    
-0001a120: 2020 2020 2062 6c6f 636b 425b 636f 756e       blockB[coun
-0001a130: 742b 345d 203d 2063 6a28 6234 5b6b 5d29  t+4] = cj(b4[k])
-0001a140: 3b0a 2f2f 2020 2020 2020 2020 2062 6c6f  ;.//         blo
-0001a150: 636b 425b 636f 756e 742b 355d 203d 2063  ckB[count+5] = c
-0001a160: 6a28 6235 5b6b 5d29 3b0a 2f2f 2020 2020  j(b5[k]);.//    
-0001a170: 2020 2020 2062 6c6f 636b 425b 636f 756e       blockB[coun
-0001a180: 742b 365d 203d 2063 6a28 6236 5b6b 5d29  t+6] = cj(b6[k])
-0001a190: 3b0a 2f2f 2020 2020 2020 2020 2062 6c6f  ;.//         blo
-0001a1a0: 636b 425b 636f 756e 742b 375d 203d 2063  ckB[count+7] = c
-0001a1b0: 6a28 6237 5b6b 5d29 3b0a 2f2f 2020 2020  j(b7[k]);.//    
-0001a1c0: 2020 2020 2063 6f75 6e74 202b 3d20 383b       count += 8;
-0001a1d0: 0a2f 2f20 2020 2020 2020 7d0a 2f2f 2020  .//       }.//  
-0001a1e0: 2020 2020 202f 2f20 736b 6970 2077 6861       // skip wha
-0001a1f0: 7420 7765 2068 6176 6520 6166 7465 720a  t we have after.
-0001a200: 2f2f 2020 2020 2020 2069 6628 5061 6e65  //       if(Pane
-0001a210: 6c4d 6f64 6529 2063 6f75 6e74 202b 3d20  lMode) count += 
-0001a220: 3820 2a20 2873 7472 6964 652d 6f66 6673  8 * (stride-offs
-0001a230: 6574 2d64 6570 7468 293b 0a2f 2f20 2020  et-depth);.//   
-0001a240: 2020 7d0a 2f2f 2020 207d 0a0a 2020 6966    }.//   }..  if
-0001a250: 286e 723e 3d34 290a 2020 7b0a 2020 2020  (nr>=4).  {.    
-0001a260: 666f 7228 496e 6465 7820 6a32 3d70 6163  for(Index j2=pac
-0001a270: 6b65 745f 636f 6c73 383b 206a 323c 7061  ket_cols8; j2<pa
-0001a280: 636b 6574 5f63 6f6c 7334 3b20 6a32 2b3d  cket_cols4; j2+=
-0001a290: 3429 0a20 2020 207b 0a20 2020 2020 202f  4).    {.      /
-0001a2a0: 2f20 736b 6970 2077 6861 7420 7765 2068  / skip what we h
-0001a2b0: 6176 6520 6265 666f 7265 0a20 2020 2020  ave before.     
-0001a2c0: 2069 6628 5061 6e65 6c4d 6f64 6529 2063   if(PanelMode) c
-0001a2d0: 6f75 6e74 202b 3d20 3420 2a20 6f66 6673  ount += 4 * offs
-0001a2e0: 6574 3b0a 2020 2020 2020 636f 6e73 7420  et;.      const 
-0001a2f0: 4c69 6e65 6172 4d61 7070 6572 2064 6d30  LinearMapper dm0
-0001a300: 203d 2072 6873 2e67 6574 4c69 6e65 6172   = rhs.getLinear
-0001a310: 4d61 7070 6572 2830 2c20 6a32 202b 2030  Mapper(0, j2 + 0
-0001a320: 293b 0a20 2020 2020 2063 6f6e 7374 204c  );.      const L
-0001a330: 696e 6561 724d 6170 7065 7220 646d 3120  inearMapper dm1 
-0001a340: 3d20 7268 732e 6765 744c 696e 6561 724d  = rhs.getLinearM
-0001a350: 6170 7065 7228 302c 206a 3220 2b20 3129  apper(0, j2 + 1)
-0001a360: 3b0a 2020 2020 2020 636f 6e73 7420 4c69  ;.      const Li
-0001a370: 6e65 6172 4d61 7070 6572 2064 6d32 203d  nearMapper dm2 =
-0001a380: 2072 6873 2e67 6574 4c69 6e65 6172 4d61   rhs.getLinearMa
-0001a390: 7070 6572 2830 2c20 6a32 202b 2032 293b  pper(0, j2 + 2);
-0001a3a0: 0a20 2020 2020 2063 6f6e 7374 204c 696e  .      const Lin
-0001a3b0: 6561 724d 6170 7065 7220 646d 3320 3d20  earMapper dm3 = 
-0001a3c0: 7268 732e 6765 744c 696e 6561 724d 6170  rhs.getLinearMap
-0001a3d0: 7065 7228 302c 206a 3220 2b20 3329 3b0a  per(0, j2 + 3);.
-0001a3e0: 0a20 2020 2020 2049 6e64 6578 206b 3d30  .      Index k=0
-0001a3f0: 3b0a 2020 2020 2020 6966 2828 5061 636b  ;.      if((Pack
-0001a400: 6574 5369 7a65 2534 293d 3d30 2920 2f2f  etSize%4)==0) //
-0001a410: 2054 4f44 4f20 656e 6162 6c65 2076 6563   TODO enable vec
-0001a420: 746f 7269 7a65 6420 7472 616e 7370 6f73  torized transpos
-0001a430: 6974 696f 6e20 666f 7220 5061 636b 6574  ition for Packet
-0001a440: 5369 7a65 3d3d 3220 3f3f 0a20 2020 2020  Size==2 ??.     
-0001a450: 207b 0a20 2020 2020 2020 2066 6f72 283b   {.        for(;
-0001a460: 206b 3c70 6565 6c65 645f 6b3b 206b 2b3d   k<peeled_k; k+=
-0001a470: 5061 636b 6574 5369 7a65 2920 7b0a 2020  PacketSize) {.  
-0001a480: 2020 2020 2020 2020 5061 636b 6574 426c          PacketBl
-0001a490: 6f63 6b3c 5061 636b 6574 2c28 5061 636b  ock<Packet,(Pack
-0001a4a0: 6574 5369 7a65 2534 293d 3d30 3f34 3a50  etSize%4)==0?4:P
-0001a4b0: 6163 6b65 7453 697a 653e 206b 6572 6e65  acketSize> kerne
-0001a4c0: 6c3b 0a20 2020 2020 2020 2020 206b 6572  l;.          ker
-0001a4d0: 6e65 6c2e 7061 636b 6574 5b30 2020 2020  nel.packet[0    
-0001a4e0: 2020 2020 2020 205d 203d 2064 6d30 2e74         ] = dm0.t
-0001a4f0: 656d 706c 6174 6520 6c6f 6164 5061 636b  emplate loadPack
-0001a500: 6574 3c50 6163 6b65 743e 286b 293b 0a20  et<Packet>(k);. 
-0001a510: 2020 2020 2020 2020 206b 6572 6e65 6c2e           kernel.
-0001a520: 7061 636b 6574 5b31 2550 6163 6b65 7453  packet[1%PacketS
-0001a530: 697a 655d 203d 2064 6d31 2e74 656d 706c  ize] = dm1.templ
-0001a540: 6174 6520 6c6f 6164 5061 636b 6574 3c50  ate loadPacket<P
-0001a550: 6163 6b65 743e 286b 293b 0a20 2020 2020  acket>(k);.     
-0001a560: 2020 2020 206b 6572 6e65 6c2e 7061 636b       kernel.pack
-0001a570: 6574 5b32 2550 6163 6b65 7453 697a 655d  et[2%PacketSize]
-0001a580: 203d 2064 6d32 2e74 656d 706c 6174 6520   = dm2.template 
-0001a590: 6c6f 6164 5061 636b 6574 3c50 6163 6b65  loadPacket<Packe
-0001a5a0: 743e 286b 293b 0a20 2020 2020 2020 2020  t>(k);.         
-0001a5b0: 206b 6572 6e65 6c2e 7061 636b 6574 5b33   kernel.packet[3
-0001a5c0: 2550 6163 6b65 7453 697a 655d 203d 2064  %PacketSize] = d
-0001a5d0: 6d33 2e74 656d 706c 6174 6520 6c6f 6164  m3.template load
-0001a5e0: 5061 636b 6574 3c50 6163 6b65 743e 286b  Packet<Packet>(k
-0001a5f0: 293b 0a20 2020 2020 2020 2020 2070 7472  );.          ptr
-0001a600: 616e 7370 6f73 6528 6b65 726e 656c 293b  anspose(kernel);
-0001a610: 0a20 2020 2020 2020 2020 2070 7374 6f72  .          pstor
-0001a620: 6575 2862 6c6f 636b 422b 636f 756e 742b  eu(blockB+count+
-0001a630: 302a 5061 636b 6574 5369 7a65 2c20 636a  0*PacketSize, cj
-0001a640: 2e70 636f 6e6a 286b 6572 6e65 6c2e 7061  .pconj(kernel.pa
-0001a650: 636b 6574 5b30 5d29 293b 0a20 2020 2020  cket[0]));.     
-0001a660: 2020 2020 2070 7374 6f72 6575 2862 6c6f       pstoreu(blo
-0001a670: 636b 422b 636f 756e 742b 312a 5061 636b  ckB+count+1*Pack
-0001a680: 6574 5369 7a65 2c20 636a 2e70 636f 6e6a  etSize, cj.pconj
-0001a690: 286b 6572 6e65 6c2e 7061 636b 6574 5b31  (kernel.packet[1
-0001a6a0: 2550 6163 6b65 7453 697a 655d 2929 3b0a  %PacketSize]));.
-0001a6b0: 2020 2020 2020 2020 2020 7073 746f 7265            pstore
-0001a6c0: 7528 626c 6f63 6b42 2b63 6f75 6e74 2b32  u(blockB+count+2
-0001a6d0: 2a50 6163 6b65 7453 697a 652c 2063 6a2e  *PacketSize, cj.
-0001a6e0: 7063 6f6e 6a28 6b65 726e 656c 2e70 6163  pconj(kernel.pac
-0001a6f0: 6b65 745b 3225 5061 636b 6574 5369 7a65  ket[2%PacketSize
-0001a700: 5d29 293b 0a20 2020 2020 2020 2020 2070  ]));.          p
-0001a710: 7374 6f72 6575 2862 6c6f 636b 422b 636f  storeu(blockB+co
-0001a720: 756e 742b 332a 5061 636b 6574 5369 7a65  unt+3*PacketSize
-0001a730: 2c20 636a 2e70 636f 6e6a 286b 6572 6e65  , cj.pconj(kerne
-0001a740: 6c2e 7061 636b 6574 5b33 2550 6163 6b65  l.packet[3%Packe
-0001a750: 7453 697a 655d 2929 3b0a 2020 2020 2020  tSize]));.      
-0001a760: 2020 2020 636f 756e 742b 3d34 2a50 6163      count+=4*Pac
-0001a770: 6b65 7453 697a 653b 0a20 2020 2020 2020  ketSize;.       
-0001a780: 207d 0a20 2020 2020 207d 0a20 2020 2020   }.      }.     
-0001a790: 2066 6f72 283b 206b 3c64 6570 7468 3b20   for(; k<depth; 
-0001a7a0: 6b2b 2b29 0a20 2020 2020 207b 0a20 2020  k++).      {.   
-0001a7b0: 2020 2020 2062 6c6f 636b 425b 636f 756e       blockB[coun
-0001a7c0: 742b 305d 203d 2063 6a28 646d 3028 6b29  t+0] = cj(dm0(k)
-0001a7d0: 293b 0a20 2020 2020 2020 2062 6c6f 636b  );.        block
-0001a7e0: 425b 636f 756e 742b 315d 203d 2063 6a28  B[count+1] = cj(
-0001a7f0: 646d 3128 6b29 293b 0a20 2020 2020 2020  dm1(k));.       
-0001a800: 2062 6c6f 636b 425b 636f 756e 742b 325d   blockB[count+2]
-0001a810: 203d 2063 6a28 646d 3228 6b29 293b 0a20   = cj(dm2(k));. 
-0001a820: 2020 2020 2020 2062 6c6f 636b 425b 636f         blockB[co
-0001a830: 756e 742b 335d 203d 2063 6a28 646d 3328  unt+3] = cj(dm3(
-0001a840: 6b29 293b 0a20 2020 2020 2020 2063 6f75  k));.        cou
-0001a850: 6e74 202b 3d20 343b 0a20 2020 2020 207d  nt += 4;.      }
-0001a860: 0a20 2020 2020 202f 2f20 736b 6970 2077  .      // skip w
-0001a870: 6861 7420 7765 2068 6176 6520 6166 7465  hat we have afte
-0001a880: 720a 2020 2020 2020 6966 2850 616e 656c  r.      if(Panel
-0001a890: 4d6f 6465 2920 636f 756e 7420 2b3d 2034  Mode) count += 4
-0001a8a0: 202a 2028 7374 7269 6465 2d6f 6666 7365   * (stride-offse
-0001a8b0: 742d 6465 7074 6829 3b0a 2020 2020 7d0a  t-depth);.    }.
-0001a8c0: 2020 7d0a 0a20 202f 2f20 636f 7079 2074    }..  // copy t
-0001a8d0: 6865 2072 656d 6169 6e69 6e67 2063 6f6c  he remaining col
-0001a8e0: 756d 6e73 206f 6e65 2061 7420 6120 7469  umns one at a ti
-0001a8f0: 6d65 2028 6e72 3d3d 3129 0a20 2066 6f72  me (nr==1).  for
-0001a900: 2849 6e64 6578 206a 323d 7061 636b 6574  (Index j2=packet
-0001a910: 5f63 6f6c 7334 3b20 6a32 3c63 6f6c 733b  _cols4; j2<cols;
-0001a920: 202b 2b6a 3229 0a20 207b 0a20 2020 2069   ++j2).  {.    i
-0001a930: 6628 5061 6e65 6c4d 6f64 6529 2063 6f75  f(PanelMode) cou
-0001a940: 6e74 202b 3d20 6f66 6673 6574 3b0a 2020  nt += offset;.  
-0001a950: 2020 636f 6e73 7420 4c69 6e65 6172 4d61    const LinearMa
-0001a960: 7070 6572 2064 6d30 203d 2072 6873 2e67  pper dm0 = rhs.g
-0001a970: 6574 4c69 6e65 6172 4d61 7070 6572 2830  etLinearMapper(0
-0001a980: 2c20 6a32 293b 0a20 2020 2066 6f72 2849  , j2);.    for(I
-0001a990: 6e64 6578 206b 3d30 3b20 6b3c 6465 7074  ndex k=0; k<dept
-0001a9a0: 683b 206b 2b2b 290a 2020 2020 7b0a 2020  h; k++).    {.  
-0001a9b0: 2020 2020 626c 6f63 6b42 5b63 6f75 6e74      blockB[count
-0001a9c0: 5d20 3d20 636a 2864 6d30 286b 2929 3b0a  ] = cj(dm0(k));.
-0001a9d0: 2020 2020 2020 636f 756e 7420 2b3d 2031        count += 1
-0001a9e0: 3b0a 2020 2020 7d0a 2020 2020 6966 2850  ;.    }.    if(P
-0001a9f0: 616e 656c 4d6f 6465 2920 636f 756e 7420  anelMode) count 
-0001aa00: 2b3d 2028 7374 7269 6465 2d6f 6666 7365  += (stride-offse
-0001aa10: 742d 6465 7074 6829 3b0a 2020 7d0a 7d0a  t-depth);.  }.}.
-0001aa20: 0a2f 2f20 7468 6973 2076 6572 7369 6f6e  .// this version
-0001aa30: 2069 7320 6f70 7469 6d69 7a65 6420 666f   is optimized fo
-0001aa40: 7220 726f 7720 6d61 6a6f 7220 6d61 7472  r row major matr
-0001aa50: 6963 6573 0a74 656d 706c 6174 653c 7479  ices.template<ty
-0001aa60: 7065 6e61 6d65 2053 6361 6c61 722c 2074  pename Scalar, t
-0001aa70: 7970 656e 616d 6520 496e 6465 782c 2074  ypename Index, t
-0001aa80: 7970 656e 616d 6520 4461 7461 4d61 7070  ypename DataMapp
-0001aa90: 6572 2c20 696e 7420 6e72 2c20 626f 6f6c  er, int nr, bool
-0001aaa0: 2043 6f6e 6a75 6761 7465 2c20 626f 6f6c   Conjugate, bool
-0001aab0: 2050 616e 656c 4d6f 6465 3e0a 7374 7275   PanelMode>.stru
-0001aac0: 6374 2067 656d 6d5f 7061 636b 5f72 6873  ct gemm_pack_rhs
-0001aad0: 3c53 6361 6c61 722c 2049 6e64 6578 2c20  <Scalar, Index, 
-0001aae0: 4461 7461 4d61 7070 6572 2c20 6e72 2c20  DataMapper, nr, 
-0001aaf0: 526f 774d 616a 6f72 2c20 436f 6e6a 7567  RowMajor, Conjug
-0001ab00: 6174 652c 2050 616e 656c 4d6f 6465 3e0a  ate, PanelMode>.
-0001ab10: 7b0a 2020 7479 7065 6465 6620 7479 7065  {.  typedef type
-0001ab20: 6e61 6d65 2070 6163 6b65 745f 7472 6169  name packet_trai
-0001ab30: 7473 3c53 6361 6c61 723e 3a3a 7479 7065  ts<Scalar>::type
-0001ab40: 2050 6163 6b65 743b 0a20 2074 7970 6564   Packet;.  typed
-0001ab50: 6566 2074 7970 656e 616d 6520 756e 7061  ef typename unpa
-0001ab60: 636b 6574 5f74 7261 6974 733c 5061 636b  cket_traits<Pack
-0001ab70: 6574 3e3a 3a68 616c 6620 4861 6c66 5061  et>::half HalfPa
-0001ab80: 636b 6574 3b0a 2020 7479 7065 6465 6620  cket;.  typedef 
-0001ab90: 7479 7065 6e61 6d65 2075 6e70 6163 6b65  typename unpacke
-0001aba0: 745f 7472 6169 7473 3c74 7970 656e 616d  t_traits<typenam
-0001abb0: 6520 756e 7061 636b 6574 5f74 7261 6974  e unpacket_trait
-0001abc0: 733c 5061 636b 6574 3e3a 3a68 616c 663e  s<Packet>::half>
-0001abd0: 3a3a 6861 6c66 2051 7561 7274 6572 5061  ::half QuarterPa
-0001abe0: 636b 6574 3b0a 2020 7479 7065 6465 6620  cket;.  typedef 
-0001abf0: 7479 7065 6e61 6d65 2044 6174 614d 6170  typename DataMap
-0001ac00: 7065 723a 3a4c 696e 6561 724d 6170 7065  per::LinearMappe
-0001ac10: 7220 4c69 6e65 6172 4d61 7070 6572 3b0a  r LinearMapper;.
-0001ac20: 2020 656e 756d 207b 2050 6163 6b65 7453    enum { PacketS
-0001ac30: 697a 6520 3d20 7061 636b 6574 5f74 7261  ize = packet_tra
-0001ac40: 6974 733c 5363 616c 6172 3e3a 3a73 697a  its<Scalar>::siz
-0001ac50: 652c 0a20 2020 2020 2020 2020 4861 6c66  e,.         Half
-0001ac60: 5061 636b 6574 5369 7a65 203d 2075 6e70  PacketSize = unp
-0001ac70: 6163 6b65 745f 7472 6169 7473 3c48 616c  acket_traits<Hal
-0001ac80: 6650 6163 6b65 743e 3a3a 7369 7a65 2c0a  fPacket>::size,.
-0001ac90: 0909 2051 7561 7274 6572 5061 636b 6574  .. QuarterPacket
-0001aca0: 5369 7a65 203d 2075 6e70 6163 6b65 745f  Size = unpacket_
-0001acb0: 7472 6169 7473 3c51 7561 7274 6572 5061  traits<QuarterPa
-0001acc0: 636b 6574 3e3a 3a73 697a 657d 3b0a 2020  cket>::size};.  
-0001acd0: 4549 4745 4e5f 444f 4e54 5f49 4e4c 494e  EIGEN_DONT_INLIN
-0001ace0: 4520 766f 6964 206f 7065 7261 746f 7228  E void operator(
-0001acf0: 2928 5363 616c 6172 2a20 626c 6f63 6b42  )(Scalar* blockB
-0001ad00: 2c20 636f 6e73 7420 4461 7461 4d61 7070  , const DataMapp
-0001ad10: 6572 2620 7268 732c 2049 6e64 6578 2064  er& rhs, Index d
-0001ad20: 6570 7468 2c20 496e 6465 7820 636f 6c73  epth, Index cols
-0001ad30: 2c20 496e 6465 7820 7374 7269 6465 3d30  , Index stride=0
-0001ad40: 2c20 496e 6465 7820 6f66 6673 6574 3d30  , Index offset=0
-0001ad50: 290a 2020 7b0a 2020 2020 4549 4745 4e5f  ).  {.    EIGEN_
-0001ad60: 4153 4d5f 434f 4d4d 454e 5428 2245 4947  ASM_COMMENT("EIG
-0001ad70: 454e 2050 524f 4455 4354 2050 4143 4b20  EN PRODUCT PACK 
-0001ad80: 5248 5320 524f 574d 414a 4f52 2229 3b0a  RHS ROWMAJOR");.
-0001ad90: 2020 2020 4549 4745 4e5f 554e 5553 4544      EIGEN_UNUSED
-0001ada0: 5f56 4152 4941 424c 4528 7374 7269 6465  _VARIABLE(stride
-0001adb0: 293b 0a20 2020 2045 4947 454e 5f55 4e55  );.    EIGEN_UNU
-0001adc0: 5345 445f 5641 5249 4142 4c45 286f 6666  SED_VARIABLE(off
-0001add0: 7365 7429 3b0a 2020 2020 6569 6765 6e5f  set);.    eigen_
-0001ade0: 6173 7365 7274 2828 2821 5061 6e65 6c4d  assert(((!PanelM
-0001adf0: 6f64 6529 2026 2620 7374 7269 6465 3d3d  ode) && stride==
-0001ae00: 3020 2626 206f 6666 7365 743d 3d30 2920  0 && offset==0) 
-0001ae10: 7c7c 2028 5061 6e65 6c4d 6f64 6520 2626  || (PanelMode &&
-0001ae20: 2073 7472 6964 653e 3d64 6570 7468 2026   stride>=depth &
-0001ae30: 2620 6f66 6673 6574 3c3d 7374 7269 6465  & offset<=stride
-0001ae40: 2929 3b0a 2020 2020 636f 6e73 7420 626f  ));.    const bo
-0001ae50: 6f6c 2048 6173 4861 6c66 203d 2028 696e  ol HasHalf = (in
-0001ae60: 7429 4861 6c66 5061 636b 6574 5369 7a65  t)HalfPacketSize
-0001ae70: 203c 2028 696e 7429 5061 636b 6574 5369   < (int)PacketSi
-0001ae80: 7a65 3b0a 2020 2020 636f 6e73 7420 626f  ze;.    const bo
-0001ae90: 6f6c 2048 6173 5175 6172 7465 7220 3d20  ol HasQuarter = 
-0001aea0: 2869 6e74 2951 7561 7274 6572 5061 636b  (int)QuarterPack
-0001aeb0: 6574 5369 7a65 203c 2028 696e 7429 4861  etSize < (int)Ha
-0001aec0: 6c66 5061 636b 6574 5369 7a65 3b0a 2020  lfPacketSize;.  
-0001aed0: 2020 636f 6e6a 5f69 663c 4e75 6d54 7261    conj_if<NumTra
-0001aee0: 6974 733c 5363 616c 6172 3e3a 3a49 7343  its<Scalar>::IsC
-0001aef0: 6f6d 706c 6578 2026 2620 436f 6e6a 7567  omplex && Conjug
-0001af00: 6174 653e 2063 6a3b 0a20 2020 2049 6e64  ate> cj;.    Ind
-0001af10: 6578 2070 6163 6b65 745f 636f 6c73 3820  ex packet_cols8 
-0001af20: 3d20 6e72 3e3d 3820 3f20 2863 6f6c 732f  = nr>=8 ? (cols/
-0001af30: 3829 202a 2038 203a 2030 3b0a 2020 2020  8) * 8 : 0;.    
-0001af40: 496e 6465 7820 7061 636b 6574 5f63 6f6c  Index packet_col
-0001af50: 7334 203d 206e 723e 3d34 203f 2028 636f  s4 = nr>=4 ? (co
-0001af60: 6c73 2f34 2920 2a20 3420 3a20 303b 0a20  ls/4) * 4 : 0;. 
-0001af70: 2020 2049 6e64 6578 2063 6f75 6e74 203d     Index count =
-0001af80: 2030 3b0a 0a20 202f 2f20 2020 6966 286e   0;..  //   if(n
-0001af90: 723e 3d38 290a 2020 2f2f 2020 207b 0a20  r>=8).  //   {. 
-0001afa0: 202f 2f20 2020 2020 666f 7228 496e 6465   //     for(Inde
-0001afb0: 7820 6a32 3d30 3b20 6a32 3c70 6163 6b65  x j2=0; j2<packe
-0001afc0: 745f 636f 6c73 383b 206a 322b 3d38 290a  t_cols8; j2+=8).
-0001afd0: 2020 2f2f 2020 2020 207b 0a20 202f 2f20    //     {.  // 
-0001afe0: 2020 2020 2020 2f2f 2073 6b69 7020 7768        // skip wh
-0001aff0: 6174 2077 6520 6861 7665 2062 6566 6f72  at we have befor
-0001b000: 650a 2020 2f2f 2020 2020 2020 2069 6628  e.  //       if(
-0001b010: 5061 6e65 6c4d 6f64 6529 2063 6f75 6e74  PanelMode) count
-0001b020: 202b 3d20 3820 2a20 6f66 6673 6574 3b0a   += 8 * offset;.
-0001b030: 2020 2f2f 2020 2020 2020 2066 6f72 2849    //       for(I
-0001b040: 6e64 6578 206b 3d30 3b20 6b3c 6465 7074  ndex k=0; k<dept
-0001b050: 683b 206b 2b2b 290a 2020 2f2f 2020 2020  h; k++).  //    
-0001b060: 2020 207b 0a20 202f 2f20 2020 2020 2020     {.  //       
-0001b070: 2020 6966 2028 5061 636b 6574 5369 7a65    if (PacketSize
-0001b080: 3d3d 3829 207b 0a20 202f 2f20 2020 2020  ==8) {.  //     
-0001b090: 2020 2020 2020 5061 636b 6574 2041 203d        Packet A =
-0001b0a0: 2070 6c6f 6164 753c 5061 636b 6574 3e28   ploadu<Packet>(
-0001b0b0: 2672 6873 5b6b 2a72 6873 5374 7269 6465  &rhs[k*rhsStride
-0001b0c0: 202b 206a 325d 293b 0a20 202f 2f20 2020   + j2]);.  //   
-0001b0d0: 2020 2020 2020 2020 7073 746f 7265 7528          pstoreu(
-0001b0e0: 626c 6f63 6b42 2b63 6f75 6e74 2c20 636a  blockB+count, cj
-0001b0f0: 2e70 636f 6e6a 2841 2929 3b0a 2020 2f2f  .pconj(A));.  //
-0001b100: 2020 2020 2020 2020 207d 2065 6c73 6520           } else 
-0001b110: 6966 2028 5061 636b 6574 5369 7a65 3d3d  if (PacketSize==
-0001b120: 3429 207b 0a20 202f 2f20 2020 2020 2020  4) {.  //       
-0001b130: 2020 2020 5061 636b 6574 2041 203d 2070      Packet A = p
-0001b140: 6c6f 6164 753c 5061 636b 6574 3e28 2672  loadu<Packet>(&r
-0001b150: 6873 5b6b 2a72 6873 5374 7269 6465 202b  hs[k*rhsStride +
-0001b160: 206a 325d 293b 0a20 202f 2f20 2020 2020   j2]);.  //     
-0001b170: 2020 2020 2020 5061 636b 6574 2042 203d        Packet B =
-0001b180: 2070 6c6f 6164 753c 5061 636b 6574 3e28   ploadu<Packet>(
-0001b190: 2672 6873 5b6b 2a72 6873 5374 7269 6465  &rhs[k*rhsStride
-0001b1a0: 202b 206a 3220 2b20 5061 636b 6574 5369   + j2 + PacketSi
-0001b1b0: 7a65 5d29 3b0a 2020 2f2f 2020 2020 2020  ze]);.  //      
-0001b1c0: 2020 2020 2070 7374 6f72 6575 2862 6c6f       pstoreu(blo
-0001b1d0: 636b 422b 636f 756e 742c 2063 6a2e 7063  ckB+count, cj.pc
-0001b1e0: 6f6e 6a28 4129 293b 0a20 202f 2f20 2020  onj(A));.  //   
-0001b1f0: 2020 2020 2020 2020 7073 746f 7265 7528          pstoreu(
-0001b200: 626c 6f63 6b42 2b63 6f75 6e74 2b50 6163  blockB+count+Pac
-0001b210: 6b65 7453 697a 652c 2063 6a2e 7063 6f6e  ketSize, cj.pcon
-0001b220: 6a28 4229 293b 0a20 202f 2f20 2020 2020  j(B));.  //     
-0001b230: 2020 2020 7d20 656c 7365 207b 0a20 202f      } else {.  /
-0001b240: 2f20 2020 2020 2020 2020 2020 636f 6e73  /           cons
-0001b250: 7420 5363 616c 6172 2a20 6230 203d 2026  t Scalar* b0 = &
-0001b260: 7268 735b 6b2a 7268 7353 7472 6964 6520  rhs[k*rhsStride 
-0001b270: 2b20 6a32 5d3b 0a20 202f 2f20 2020 2020  + j2];.  //     
-0001b280: 2020 2020 2020 626c 6f63 6b42 5b63 6f75        blockB[cou
-0001b290: 6e74 2b30 5d20 3d20 636a 2862 305b 305d  nt+0] = cj(b0[0]
-0001b2a0: 293b 0a20 202f 2f20 2020 2020 2020 2020  );.  //         
-0001b2b0: 2020 626c 6f63 6b42 5b63 6f75 6e74 2b31    blockB[count+1
-0001b2c0: 5d20 3d20 636a 2862 305b 315d 293b 0a20  ] = cj(b0[1]);. 
-0001b2d0: 202f 2f20 2020 2020 2020 2020 2020 626c   //           bl
-0001b2e0: 6f63 6b42 5b63 6f75 6e74 2b32 5d20 3d20  ockB[count+2] = 
-0001b2f0: 636a 2862 305b 325d 293b 0a20 202f 2f20  cj(b0[2]);.  // 
-0001b300: 2020 2020 2020 2020 2020 626c 6f63 6b42            blockB
-0001b310: 5b63 6f75 6e74 2b33 5d20 3d20 636a 2862  [count+3] = cj(b
-0001b320: 305b 335d 293b 0a20 202f 2f20 2020 2020  0[3]);.  //     
-0001b330: 2020 2020 2020 626c 6f63 6b42 5b63 6f75        blockB[cou
-0001b340: 6e74 2b34 5d20 3d20 636a 2862 305b 345d  nt+4] = cj(b0[4]
-0001b350: 293b 0a20 202f 2f20 2020 2020 2020 2020  );.  //         
-0001b360: 2020 626c 6f63 6b42 5b63 6f75 6e74 2b35    blockB[count+5
-0001b370: 5d20 3d20 636a 2862 305b 355d 293b 0a20  ] = cj(b0[5]);. 
-0001b380: 202f 2f20 2020 2020 2020 2020 2020 626c   //           bl
-0001b390: 6f63 6b42 5b63 6f75 6e74 2b36 5d20 3d20  ockB[count+6] = 
-0001b3a0: 636a 2862 305b 365d 293b 0a20 202f 2f20  cj(b0[6]);.  // 
-0001b3b0: 2020 2020 2020 2020 2020 626c 6f63 6b42            blockB
-0001b3c0: 5b63 6f75 6e74 2b37 5d20 3d20 636a 2862  [count+7] = cj(b
-0001b3d0: 305b 375d 293b 0a20 202f 2f20 2020 2020  0[7]);.  //     
-0001b3e0: 2020 2020 7d0a 2020 2f2f 2020 2020 2020      }.  //      
-0001b3f0: 2020 2063 6f75 6e74 202b 3d20 383b 0a20     count += 8;. 
-0001b400: 202f 2f20 2020 2020 2020 7d0a 2020 2f2f   //       }.  //
-0001b410: 2020 2020 2020 202f 2f20 736b 6970 2077         // skip w
-0001b420: 6861 7420 7765 2068 6176 6520 6166 7465  hat we have afte
-0001b430: 720a 2020 2f2f 2020 2020 2020 2069 6628  r.  //       if(
-0001b440: 5061 6e65 6c4d 6f64 6529 2063 6f75 6e74  PanelMode) count
-0001b450: 202b 3d20 3820 2a20 2873 7472 6964 652d   += 8 * (stride-
-0001b460: 6f66 6673 6574 2d64 6570 7468 293b 0a20  offset-depth);. 
-0001b470: 202f 2f20 2020 2020 7d0a 2020 2f2f 2020   //     }.  //  
-0001b480: 207d 0a20 2020 2069 6628 6e72 3e3d 3429   }.    if(nr>=4)
-0001b490: 0a20 2020 207b 0a20 2020 2020 2066 6f72  .    {.      for
-0001b4a0: 2849 6e64 6578 206a 323d 7061 636b 6574  (Index j2=packet
-0001b4b0: 5f63 6f6c 7338 3b20 6a32 3c70 6163 6b65  _cols8; j2<packe
-0001b4c0: 745f 636f 6c73 343b 206a 322b 3d34 290a  t_cols4; j2+=4).
-0001b4d0: 2020 2020 2020 7b0a 2020 2020 2020 2020        {.        
-0001b4e0: 2f2f 2073 6b69 7020 7768 6174 2077 6520  // skip what we 
-0001b4f0: 6861 7665 2062 6566 6f72 650a 2020 2020  have before.    
-0001b500: 2020 2020 6966 2850 616e 656c 4d6f 6465      if(PanelMode
-0001b510: 2920 636f 756e 7420 2b3d 2034 202a 206f  ) count += 4 * o
-0001b520: 6666 7365 743b 0a20 2020 2020 2020 2066  ffset;.        f
-0001b530: 6f72 2849 6e64 6578 206b 3d30 3b20 6b3c  or(Index k=0; k<
-0001b540: 6465 7074 683b 206b 2b2b 290a 2020 2020  depth; k++).    
-0001b550: 2020 2020 7b0a 2020 2020 2020 2020 2020      {.          
-0001b560: 6966 2028 5061 636b 6574 5369 7a65 3d3d  if (PacketSize==
-0001b570: 3429 207b 0a20 2020 2020 2020 2020 2020  4) {.           
-0001b580: 2050 6163 6b65 7420 4120 3d20 7268 732e   Packet A = rhs.
-0001b590: 7465 6d70 6c61 7465 206c 6f61 6450 6163  template loadPac
-0001b5a0: 6b65 743c 5061 636b 6574 3e28 6b2c 206a  ket<Packet>(k, j
-0001b5b0: 3229 3b0a 2020 2020 2020 2020 2020 2020  2);.            
-0001b5c0: 7073 746f 7265 7528 626c 6f63 6b42 2b63  pstoreu(blockB+c
-0001b5d0: 6f75 6e74 2c20 636a 2e70 636f 6e6a 2841  ount, cj.pconj(A
-0001b5e0: 2929 3b0a 2020 2020 2020 2020 2020 2020  ));.            
-0001b5f0: 636f 756e 7420 2b3d 2050 6163 6b65 7453  count += PacketS
-0001b600: 697a 653b 0a20 2020 2020 2020 2020 207d  ize;.          }
-0001b610: 2065 6c73 6520 6966 2028 4861 7348 616c   else if (HasHal
-0001b620: 6620 2626 2048 616c 6650 6163 6b65 7453  f && HalfPacketS
-0001b630: 697a 653d 3d34 2920 7b0a 2020 2020 2020  ize==4) {.      
-0001b640: 2020 2020 2020 4861 6c66 5061 636b 6574        HalfPacket
-0001b650: 2041 203d 2072 6873 2e74 656d 706c 6174   A = rhs.templat
-0001b660: 6520 6c6f 6164 5061 636b 6574 3c48 616c  e loadPacket<Hal
-0001b670: 6650 6163 6b65 743e 286b 2c20 6a32 293b  fPacket>(k, j2);
-0001b680: 0a20 2020 2020 2020 2020 2020 2070 7374  .            pst
-0001b690: 6f72 6575 2862 6c6f 636b 422b 636f 756e  oreu(blockB+coun
-0001b6a0: 742c 2063 6a2e 7063 6f6e 6a28 4129 293b  t, cj.pconj(A));
-0001b6b0: 0a20 2020 2020 2020 2020 2020 2063 6f75  .            cou
-0001b6c0: 6e74 202b 3d20 4861 6c66 5061 636b 6574  nt += HalfPacket
-0001b6d0: 5369 7a65 3b0a 2020 2020 2020 2020 2020  Size;.          
-0001b6e0: 7d20 656c 7365 2069 6620 2848 6173 5175  } else if (HasQu
-0001b6f0: 6172 7465 7220 2626 2051 7561 7274 6572  arter && Quarter
-0001b700: 5061 636b 6574 5369 7a65 3d3d 3429 207b  PacketSize==4) {
-0001b710: 0a20 2020 2020 2020 2020 2020 2051 7561  .            Qua
-0001b720: 7274 6572 5061 636b 6574 2041 203d 2072  rterPacket A = r
-0001b730: 6873 2e74 656d 706c 6174 6520 6c6f 6164  hs.template load
-0001b740: 5061 636b 6574 3c51 7561 7274 6572 5061  Packet<QuarterPa
-0001b750: 636b 6574 3e28 6b2c 206a 3229 3b0a 2020  cket>(k, j2);.  
-0001b760: 2020 2020 2020 2020 2020 7073 746f 7265            pstore
-0001b770: 7528 626c 6f63 6b42 2b63 6f75 6e74 2c20  u(blockB+count, 
-0001b780: 636a 2e70 636f 6e6a 2841 2929 3b0a 2020  cj.pconj(A));.  
-0001b790: 2020 2020 2020 2020 2020 636f 756e 7420            count 
-0001b7a0: 2b3d 2051 7561 7274 6572 5061 636b 6574  += QuarterPacket
-0001b7b0: 5369 7a65 3b0a 2020 2020 2020 2020 2020  Size;.          
-0001b7c0: 7d20 656c 7365 207b 0a20 2020 2020 2020  } else {.       
-0001b7d0: 2020 2020 2063 6f6e 7374 204c 696e 6561       const Linea
-0001b7e0: 724d 6170 7065 7220 646d 3020 3d20 7268  rMapper dm0 = rh
-0001b7f0: 732e 6765 744c 696e 6561 724d 6170 7065  s.getLinearMappe
-0001b800: 7228 6b2c 206a 3229 3b0a 2020 2020 2020  r(k, j2);.      
-0001b810: 2020 2020 2020 626c 6f63 6b42 5b63 6f75        blockB[cou
-0001b820: 6e74 2b30 5d20 3d20 636a 2864 6d30 2830  nt+0] = cj(dm0(0
-0001b830: 2929 3b0a 2020 2020 2020 2020 2020 2020  ));.            
-0001b840: 626c 6f63 6b42 5b63 6f75 6e74 2b31 5d20  blockB[count+1] 
-0001b850: 3d20 636a 2864 6d30 2831 2929 3b0a 2020  = cj(dm0(1));.  
-0001b860: 2020 2020 2020 2020 2020 626c 6f63 6b42            blockB
-0001b870: 5b63 6f75 6e74 2b32 5d20 3d20 636a 2864  [count+2] = cj(d
-0001b880: 6d30 2832 2929 3b0a 2020 2020 2020 2020  m0(2));.        
-0001b890: 2020 2020 626c 6f63 6b42 5b63 6f75 6e74      blockB[count
-0001b8a0: 2b33 5d20 3d20 636a 2864 6d30 2833 2929  +3] = cj(dm0(3))
-0001b8b0: 3b0a 2020 2020 2020 2020 2020 2020 636f  ;.            co
-0001b8c0: 756e 7420 2b3d 2034 3b0a 2020 2020 2020  unt += 4;.      
-0001b8d0: 2020 2020 7d0a 2020 2020 2020 2020 7d0a      }.        }.
-0001b8e0: 2020 2020 2020 2020 2f2f 2073 6b69 7020          // skip 
-0001b8f0: 7768 6174 2077 6520 6861 7665 2061 6674  what we have aft
-0001b900: 6572 0a20 2020 2020 2020 2069 6628 5061  er.        if(Pa
-0001b910: 6e65 6c4d 6f64 6529 2063 6f75 6e74 202b  nelMode) count +
-0001b920: 3d20 3420 2a20 2873 7472 6964 652d 6f66  = 4 * (stride-of
-0001b930: 6673 6574 2d64 6570 7468 293b 0a20 2020  fset-depth);.   
-0001b940: 2020 207d 0a20 2020 207d 0a20 2020 202f     }.    }.    /
-0001b950: 2f20 636f 7079 2074 6865 2072 656d 6169  / copy the remai
-0001b960: 6e69 6e67 2063 6f6c 756d 6e73 206f 6e65  ning columns one
-0001b970: 2061 7420 6120 7469 6d65 2028 6e72 3d3d   at a time (nr==
-0001b980: 3129 0a20 2020 2066 6f72 2849 6e64 6578  1).    for(Index
-0001b990: 206a 323d 7061 636b 6574 5f63 6f6c 7334   j2=packet_cols4
-0001b9a0: 3b20 6a32 3c63 6f6c 733b 202b 2b6a 3229  ; j2<cols; ++j2)
-0001b9b0: 0a20 2020 207b 0a20 2020 2020 2069 6628  .    {.      if(
-0001b9c0: 5061 6e65 6c4d 6f64 6529 2063 6f75 6e74  PanelMode) count
-0001b9d0: 202b 3d20 6f66 6673 6574 3b0a 2020 2020   += offset;.    
-0001b9e0: 2020 666f 7228 496e 6465 7820 6b3d 303b    for(Index k=0;
-0001b9f0: 206b 3c64 6570 7468 3b20 6b2b 2b29 0a20   k<depth; k++). 
-0001ba00: 2020 2020 207b 0a20 2020 2020 2020 2062       {.        b
-0001ba10: 6c6f 636b 425b 636f 756e 745d 203d 2063  lockB[count] = c
-0001ba20: 6a28 7268 7328 6b2c 206a 3229 293b 0a20  j(rhs(k, j2));. 
-0001ba30: 2020 2020 2020 2063 6f75 6e74 202b 3d20         count += 
-0001ba40: 313b 0a20 2020 2020 207d 0a20 2020 2020  1;.      }.     
-0001ba50: 2069 6628 5061 6e65 6c4d 6f64 6529 2063   if(PanelMode) c
-0001ba60: 6f75 6e74 202b 3d20 7374 7269 6465 2d6f  ount += stride-o
-0001ba70: 6666 7365 742d 6465 7074 683b 0a20 2020  ffset-depth;.   
-0001ba80: 207d 0a20 207d 0a7d 3b0a 0a7d 202f 2f20   }.  }.};..} // 
-0001ba90: 656e 6420 6e61 6d65 7370 6163 6520 696e  end namespace in
-0001baa0: 7465 726e 616c 0a0a 2f2a 2a20 5c72 6574  ternal../** \ret
-0001bab0: 7572 6e73 2074 6865 2063 7572 7265 6e74  urns the current
-0001bac0: 6c79 2073 6574 206c 6576 656c 2031 2063  ly set level 1 c
-0001bad0: 7075 2063 6163 6865 2073 697a 6520 2869  pu cache size (i
-0001bae0: 6e20 6279 7465 7329 2075 7365 6420 746f  n bytes) used to
-0001baf0: 2065 7374 696d 6174 6520 7468 6520 6964   estimate the id
-0001bb00: 6561 6c20 626c 6f63 6b69 6e67 2073 697a  eal blocking siz
-0001bb10: 6520 7061 7261 6d65 7465 7273 2e0a 2020  e parameters..  
-0001bb20: 2a20 5c73 6120 7365 7443 7075 4361 6368  * \sa setCpuCach
-0001bb30: 6553 697a 6520 2a2f 0a69 6e6c 696e 6520  eSize */.inline 
-0001bb40: 7374 643a 3a70 7472 6469 6666 5f74 206c  std::ptrdiff_t l
-0001bb50: 3143 6163 6865 5369 7a65 2829 0a7b 0a20  1CacheSize().{. 
-0001bb60: 2073 7464 3a3a 7074 7264 6966 665f 7420   std::ptrdiff_t 
-0001bb70: 6c31 2c20 6c32 2c20 6c33 3b0a 2020 696e  l1, l2, l3;.  in
-0001bb80: 7465 726e 616c 3a3a 6d61 6e61 6765 5f63  ternal::manage_c
-0001bb90: 6163 6869 6e67 5f73 697a 6573 2847 6574  aching_sizes(Get
-0001bba0: 4163 7469 6f6e 2c20 266c 312c 2026 6c32  Action, &l1, &l2
-0001bbb0: 2c20 266c 3329 3b0a 2020 7265 7475 726e  , &l3);.  return
-0001bbc0: 206c 313b 0a7d 0a0a 2f2a 2a20 5c72 6574   l1;.}../** \ret
-0001bbd0: 7572 6e73 2074 6865 2063 7572 7265 6e74  urns the current
-0001bbe0: 6c79 2073 6574 206c 6576 656c 2032 2063  ly set level 2 c
-0001bbf0: 7075 2063 6163 6865 2073 697a 6520 2869  pu cache size (i
-0001bc00: 6e20 6279 7465 7329 2075 7365 6420 746f  n bytes) used to
-0001bc10: 2065 7374 696d 6174 6520 7468 6520 6964   estimate the id
-0001bc20: 6561 6c20 626c 6f63 6b69 6e67 2073 697a  eal blocking siz
-0001bc30: 6520 7061 7261 6d65 7465 7273 2e0a 2020  e parameters..  
-0001bc40: 2a20 5c73 6120 7365 7443 7075 4361 6368  * \sa setCpuCach
-0001bc50: 6553 697a 6520 2a2f 0a69 6e6c 696e 6520  eSize */.inline 
-0001bc60: 7374 643a 3a70 7472 6469 6666 5f74 206c  std::ptrdiff_t l
-0001bc70: 3243 6163 6865 5369 7a65 2829 0a7b 0a20  2CacheSize().{. 
-0001bc80: 2073 7464 3a3a 7074 7264 6966 665f 7420   std::ptrdiff_t 
-0001bc90: 6c31 2c20 6c32 2c20 6c33 3b0a 2020 696e  l1, l2, l3;.  in
-0001bca0: 7465 726e 616c 3a3a 6d61 6e61 6765 5f63  ternal::manage_c
-0001bcb0: 6163 6869 6e67 5f73 697a 6573 2847 6574  aching_sizes(Get
-0001bcc0: 4163 7469 6f6e 2c20 266c 312c 2026 6c32  Action, &l1, &l2
-0001bcd0: 2c20 266c 3329 3b0a 2020 7265 7475 726e  , &l3);.  return
-0001bce0: 206c 323b 0a7d 0a0a 2f2a 2a20 5c72 6574   l2;.}../** \ret
-0001bcf0: 7572 6e73 2074 6865 2063 7572 7265 6e74  urns the current
-0001bd00: 6c79 2073 6574 206c 6576 656c 2033 2063  ly set level 3 c
-0001bd10: 7075 2063 6163 6865 2073 697a 6520 2869  pu cache size (i
-0001bd20: 6e20 6279 7465 7329 2075 7365 6420 746f  n bytes) used to
-0001bd30: 2065 7374 696d 6174 6520 7468 6520 6964   estimate the id
-0001bd40: 6561 6c20 626c 6f63 6b69 6e67 2073 697a  eal blocking siz
-0001bd50: 6520 7061 7261 6d65 7465 5c0a 7273 2e20  e paramete\.rs. 
-0001bd60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001bd70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001bd80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001bd90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001bda0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001bdb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001bdc0: 2020 2020 2020 2020 2020 2020 2020 200a                 .
-0001bdd0: 2a20 5c73 6120 7365 7443 7075 4361 6368  * \sa setCpuCach
-0001bde0: 6553 697a 6520 2a2f 0a69 6e6c 696e 6520  eSize */.inline 
-0001bdf0: 7374 643a 3a70 7472 6469 6666 5f74 206c  std::ptrdiff_t l
-0001be00: 3343 6163 6865 5369 7a65 2829 0a7b 0a20  3CacheSize().{. 
-0001be10: 2073 7464 3a3a 7074 7264 6966 665f 7420   std::ptrdiff_t 
-0001be20: 6c31 2c20 6c32 2c20 6c33 3b0a 2020 696e  l1, l2, l3;.  in
-0001be30: 7465 726e 616c 3a3a 6d61 6e61 6765 5f63  ternal::manage_c
-0001be40: 6163 6869 6e67 5f73 697a 6573 2847 6574  aching_sizes(Get
-0001be50: 4163 7469 6f6e 2c20 266c 312c 2026 6c32  Action, &l1, &l2
-0001be60: 2c20 266c 3329 3b0a 2020 7265 7475 726e  , &l3);.  return
-0001be70: 206c 333b 0a7d 0a0a 2f2a 2a20 5365 7420   l3;.}../** Set 
-0001be80: 7468 6520 6370 7520 4c31 2061 6e64 204c  the cpu L1 and L
-0001be90: 3220 6361 6368 6520 7369 7a65 7320 2869  2 cache sizes (i
-0001bea0: 6e20 6279 7465 7329 2e0a 2020 2a20 5468  n bytes)..  * Th
-0001beb0: 6573 6520 7661 6c75 6573 2061 7265 2075  ese values are u
-0001bec0: 7365 2074 6f20 6164 6a75 7374 2074 6865  se to adjust the
-0001bed0: 2073 697a 6520 6f66 2074 6865 2062 6c6f   size of the blo
-0001bee0: 636b 730a 2020 2a20 666f 7220 7468 6520  cks.  * for the 
-0001bef0: 616c 676f 7269 7468 6d73 2077 6f72 6b69  algorithms worki
-0001bf00: 6e67 2070 6572 2062 6c6f 636b 732e 0a20  ng per blocks.. 
-0001bf10: 202a 0a20 202a 205c 7361 2063 6f6d 7075   *.  * \sa compu
-0001bf20: 7465 5072 6f64 7563 7442 6c6f 636b 696e  teProductBlockin
-0001bf30: 6753 697a 6573 202a 2f0a 696e 6c69 6e65  gSizes */.inline
-0001bf40: 2076 6f69 6420 7365 7443 7075 4361 6368   void setCpuCach
-0001bf50: 6553 697a 6573 2873 7464 3a3a 7074 7264  eSizes(std::ptrd
-0001bf60: 6966 665f 7420 6c31 2c20 7374 643a 3a70  iff_t l1, std::p
-0001bf70: 7472 6469 6666 5f74 206c 322c 2073 7464  trdiff_t l2, std
-0001bf80: 3a3a 7074 7264 6966 665f 7420 6c33 290a  ::ptrdiff_t l3).
-0001bf90: 7b0a 2020 696e 7465 726e 616c 3a3a 6d61  {.  internal::ma
-0001bfa0: 6e61 6765 5f63 6163 6869 6e67 5f73 697a  nage_caching_siz
-0001bfb0: 6573 2853 6574 4163 7469 6f6e 2c20 266c  es(SetAction, &l
-0001bfc0: 312c 2026 6c32 2c20 266c 3329 3b0a 7d0a  1, &l2, &l3);.}.
-0001bfd0: 0a7d 202f 2f20 656e 6420 6e61 6d65 7370  .} // end namesp
-0001bfe0: 6163 6520 4569 6765 6e0a 0a23 656e 6469  ace Eigen..#endi
-0001bff0: 6620 2f2f 2045 4947 454e 5f47 454e 4552  f // EIGEN_GENER
-0001c000: 414c 5f42 4c4f 434b 5f50 414e 454c 5f48  AL_BLOCK_PANEL_H
-0001c010: 0a                                       .
+00016d60: 6574 3e3a 3a73 697a 652c 0a20 2020 2020  et>::size,.     
+00016d70: 2020 2020 4861 6c66 5061 636b 6574 5369      HalfPacketSi
+00016d80: 7a65 203d 2075 6e70 6163 6b65 745f 7472  ze = unpacket_tr
+00016d90: 6169 7473 3c48 616c 6650 6163 6b65 743e  aits<HalfPacket>
+00016da0: 3a3a 7369 7a65 2c0a 2020 2020 2020 2020  ::size,.        
+00016db0: 2051 7561 7274 6572 5061 636b 6574 5369   QuarterPacketSi
+00016dc0: 7a65 203d 2075 6e70 6163 6b65 745f 7472  ze = unpacket_tr
+00016dd0: 6169 7473 3c51 7561 7274 6572 5061 636b  aits<QuarterPack
+00016de0: 6574 3e3a 3a73 697a 652c 0a20 2020 2020  et>::size,.     
+00016df0: 2020 2020 4861 7348 616c 6620 3d20 2869      HasHalf = (i
+00016e00: 6e74 2948 616c 6650 6163 6b65 7453 697a  nt)HalfPacketSiz
+00016e10: 6520 3c20 2869 6e74 2950 6163 6b65 7453  e < (int)PacketS
+00016e20: 697a 652c 0a20 2020 2020 2020 2020 4861  ize,.         Ha
+00016e30: 7351 7561 7274 6572 203d 2028 696e 7429  sQuarter = (int)
+00016e40: 5175 6172 7465 7250 6163 6b65 7453 697a  QuarterPacketSiz
+00016e50: 6520 3c20 2869 6e74 2948 616c 6650 6163  e < (int)HalfPac
+00016e60: 6b65 7453 697a 657d 3b0a 0a20 2045 4947  ketSize};..  EIG
+00016e70: 454e 5f41 534d 5f43 4f4d 4d45 4e54 2822  EN_ASM_COMMENT("
+00016e80: 4549 4745 4e20 5052 4f44 5543 5420 5041  EIGEN PRODUCT PA
+00016e90: 434b 204c 4853 2229 3b0a 2020 4549 4745  CK LHS");.  EIGE
+00016ea0: 4e5f 554e 5553 4544 5f56 4152 4941 424c  N_UNUSED_VARIABL
+00016eb0: 4528 7374 7269 6465 293b 0a20 2045 4947  E(stride);.  EIG
+00016ec0: 454e 5f55 4e55 5345 445f 5641 5249 4142  EN_UNUSED_VARIAB
+00016ed0: 4c45 286f 6666 7365 7429 3b0a 2020 6569  LE(offset);.  ei
+00016ee0: 6765 6e5f 6173 7365 7274 2828 2821 5061  gen_assert(((!Pa
+00016ef0: 6e65 6c4d 6f64 6529 2026 2620 7374 7269  nelMode) && stri
+00016f00: 6465 3d3d 3020 2626 206f 6666 7365 743d  de==0 && offset=
+00016f10: 3d30 2920 7c7c 2028 5061 6e65 6c4d 6f64  =0) || (PanelMod
+00016f20: 6520 2626 2073 7472 6964 653e 3d64 6570  e && stride>=dep
+00016f30: 7468 2026 2620 6f66 6673 6574 3c3d 7374  th && offset<=st
+00016f40: 7269 6465 2929 3b0a 2020 636f 6e6a 5f69  ride));.  conj_i
+00016f50: 663c 4e75 6d54 7261 6974 733c 5363 616c  f<NumTraits<Scal
+00016f60: 6172 3e3a 3a49 7343 6f6d 706c 6578 2026  ar>::IsComplex &
+00016f70: 2620 436f 6e6a 7567 6174 653e 2063 6a3b  & Conjugate> cj;
+00016f80: 0a20 2049 6e64 6578 2063 6f75 6e74 203d  .  Index count =
+00016f90: 2030 3b0a 2020 626f 6f6c 2067 6f6e 655f   0;.  bool gone_
+00016fa0: 6861 6c66 203d 2066 616c 7365 2c20 676f  half = false, go
+00016fb0: 6e65 5f71 7561 7274 6572 203d 2066 616c  ne_quarter = fal
+00016fc0: 7365 2c20 676f 6e65 5f6c 6173 7420 3d20  se, gone_last = 
+00016fd0: 6661 6c73 653b 0a0a 2020 496e 6465 7820  false;..  Index 
+00016fe0: 6920 3d20 303b 0a20 2069 6e74 2070 6163  i = 0;.  int pac
+00016ff0: 6b20 3d20 5061 636b 313b 0a20 2069 6e74  k = Pack1;.  int
+00017000: 2070 7369 7a65 203d 2050 6163 6b65 7453   psize = PacketS
+00017010: 697a 653b 0a20 2077 6869 6c65 2870 6163  ize;.  while(pac
+00017020: 6b3e 3029 0a20 207b 0a20 2020 2049 6e64  k>0).  {.    Ind
+00017030: 6578 2072 656d 6169 6e69 6e67 5f72 6f77  ex remaining_row
+00017040: 7320 3d20 726f 7773 2d69 3b0a 2020 2020  s = rows-i;.    
+00017050: 496e 6465 7820 7065 656c 6564 5f6d 6320  Index peeled_mc 
+00017060: 3d20 676f 6e65 5f6c 6173 7420 3f20 5061  = gone_last ? Pa
+00017070: 636b 323e 3120 3f20 2872 6f77 732f 7061  ck2>1 ? (rows/pa
+00017080: 636b 292a 7061 636b 203a 2030 203a 2069  ck)*pack : 0 : i
+00017090: 2b28 7265 6d61 696e 696e 675f 726f 7773  +(remaining_rows
+000170a0: 2f70 6163 6b29 2a70 6163 6b3b 0a20 2020  /pack)*pack;.   
+000170b0: 2049 6e64 6578 2073 7461 7274 696e 675f   Index starting_
+000170c0: 706f 7320 3d20 693b 0a20 2020 2066 6f72  pos = i;.    for
+000170d0: 283b 2069 3c70 6565 6c65 645f 6d63 3b20  (; i<peeled_mc; 
+000170e0: 692b 3d70 6163 6b29 0a20 2020 207b 0a20  i+=pack).    {. 
+000170f0: 2020 2020 2069 6628 5061 6e65 6c4d 6f64       if(PanelMod
+00017100: 6529 2063 6f75 6e74 202b 3d20 7061 636b  e) count += pack
+00017110: 202a 206f 6666 7365 743b 0a0a 2020 2020   * offset;..    
+00017120: 2020 496e 6465 7820 6b3d 303b 0a20 2020    Index k=0;.   
+00017130: 2020 2069 6628 7061 636b 3e3d 7073 697a     if(pack>=psiz
+00017140: 6520 2626 2070 7369 7a65 203e 3d20 5175  e && psize >= Qu
+00017150: 6172 7465 7250 6163 6b65 7453 697a 6529  arterPacketSize)
+00017160: 0a20 2020 2020 207b 0a20 2020 2020 2020  .      {.       
+00017170: 2063 6f6e 7374 2049 6e64 6578 2070 6565   const Index pee
+00017180: 6c65 645f 6b20 3d20 2864 6570 7468 2f70  led_k = (depth/p
+00017190: 7369 7a65 292a 7073 697a 653b 0a20 2020  size)*psize;.   
+000171a0: 2020 2020 2066 6f72 283b 206b 3c70 6565       for(; k<pee
+000171b0: 6c65 645f 6b3b 206b 2b3d 7073 697a 6529  led_k; k+=psize)
+000171c0: 0a20 2020 2020 2020 207b 0a20 2020 2020  .        {.     
+000171d0: 2020 2020 2066 6f72 2028 496e 6465 7820       for (Index 
+000171e0: 6d20 3d20 303b 206d 203c 2070 6163 6b3b  m = 0; m < pack;
+000171f0: 206d 202b 3d20 7073 697a 6529 0a20 2020   m += psize).   
+00017200: 2020 2020 2020 207b 0a20 2020 2020 2020         {.       
+00017210: 2020 2020 2069 6620 2870 7369 7a65 203d       if (psize =
+00017220: 3d20 5061 636b 6574 5369 7a65 2920 7b0a  = PacketSize) {.
+00017230: 2020 2020 2020 2020 2020 2020 2020 5061                Pa
+00017240: 636b 6574 426c 6f63 6b3c 5061 636b 6574  cketBlock<Packet
+00017250: 3e20 6b65 726e 656c 3b0a 2020 2020 2020  > kernel;.      
+00017260: 2020 2020 2020 2020 666f 7220 2869 6e74          for (int
+00017270: 2070 203d 2030 3b20 7020 3c20 7073 697a   p = 0; p < psiz
+00017280: 653b 202b 2b70 2920 6b65 726e 656c 2e70  e; ++p) kernel.p
+00017290: 6163 6b65 745b 705d 203d 206c 6873 2e74  acket[p] = lhs.t
+000172a0: 656d 706c 6174 6520 6c6f 6164 5061 636b  emplate loadPack
+000172b0: 6574 3c50 6163 6b65 743e 2869 2b70 2b6d  et<Packet>(i+p+m
+000172c0: 2c20 6b29 3b0a 2020 2020 2020 2020 2020  , k);.          
+000172d0: 2020 2020 7074 7261 6e73 706f 7365 286b      ptranspose(k
+000172e0: 6572 6e65 6c29 3b0a 2020 2020 2020 2020  ernel);.        
+000172f0: 2020 2020 2020 666f 7220 2869 6e74 2070        for (int p
+00017300: 203d 2030 3b20 7020 3c20 7073 697a 653b   = 0; p < psize;
+00017310: 202b 2b70 2920 7073 746f 7265 2862 6c6f   ++p) pstore(blo
+00017320: 636b 412b 636f 756e 742b 6d2b 2870 6163  ckA+count+m+(pac
+00017330: 6b29 2a70 2c20 636a 2e70 636f 6e6a 286b  k)*p, cj.pconj(k
+00017340: 6572 6e65 6c2e 7061 636b 6574 5b70 5d29  ernel.packet[p])
+00017350: 293b 0a20 2020 2020 2020 2020 2020 207d  );.            }
+00017360: 2065 6c73 6520 6966 2028 4861 7348 616c   else if (HasHal
+00017370: 6620 2626 2070 7369 7a65 203d 3d20 4861  f && psize == Ha
+00017380: 6c66 5061 636b 6574 5369 7a65 2920 7b0a  lfPacketSize) {.
+00017390: 2020 2020 2020 2020 2020 2020 2020 676f                go
+000173a0: 6e65 5f68 616c 6620 3d20 7472 7565 3b0a  ne_half = true;.
+000173b0: 2020 2020 2020 2020 2020 2020 2020 5061                Pa
+000173c0: 636b 6574 426c 6f63 6b3c 4861 6c66 5061  cketBlock<HalfPa
+000173d0: 636b 6574 3e20 6b65 726e 656c 5f68 616c  cket> kernel_hal
+000173e0: 663b 0a20 2020 2020 2020 2020 2020 2020  f;.             
+000173f0: 2066 6f72 2028 696e 7420 7020 3d20 303b   for (int p = 0;
+00017400: 2070 203c 2070 7369 7a65 3b20 2b2b 7029   p < psize; ++p)
+00017410: 206b 6572 6e65 6c5f 6861 6c66 2e70 6163   kernel_half.pac
+00017420: 6b65 745b 705d 203d 206c 6873 2e74 656d  ket[p] = lhs.tem
+00017430: 706c 6174 6520 6c6f 6164 5061 636b 6574  plate loadPacket
+00017440: 3c48 616c 6650 6163 6b65 743e 2869 2b70  <HalfPacket>(i+p
+00017450: 2b6d 2c20 6b29 3b0a 2020 2020 2020 2020  +m, k);.        
+00017460: 2020 2020 2020 7074 7261 6e73 706f 7365        ptranspose
+00017470: 286b 6572 6e65 6c5f 6861 6c66 293b 0a20  (kernel_half);. 
+00017480: 2020 2020 2020 2020 2020 2020 2066 6f72               for
+00017490: 2028 696e 7420 7020 3d20 303b 2070 203c   (int p = 0; p <
+000174a0: 2070 7369 7a65 3b20 2b2b 7029 2070 7374   psize; ++p) pst
+000174b0: 6f72 6528 626c 6f63 6b41 2b63 6f75 6e74  ore(blockA+count
+000174c0: 2b6d 2b28 7061 636b 292a 702c 2063 6a2e  +m+(pack)*p, cj.
+000174d0: 7063 6f6e 6a28 6b65 726e 656c 5f68 616c  pconj(kernel_hal
+000174e0: 662e 7061 636b 6574 5b70 5d29 293b 0a20  f.packet[p]));. 
+000174f0: 2020 2020 2020 2020 2020 207d 2065 6c73             } els
+00017500: 6520 6966 2028 4861 7351 7561 7274 6572  e if (HasQuarter
+00017510: 2026 2620 7073 697a 6520 3d3d 2051 7561   && psize == Qua
+00017520: 7274 6572 5061 636b 6574 5369 7a65 2920  rterPacketSize) 
+00017530: 7b0a 2020 2020 2020 2020 2020 2020 2020  {.              
+00017540: 676f 6e65 5f71 7561 7274 6572 203d 2074  gone_quarter = t
+00017550: 7275 653b 0a20 2020 2020 2020 2020 2020  rue;.           
+00017560: 2020 2050 6163 6b65 7442 6c6f 636b 3c51     PacketBlock<Q
+00017570: 7561 7274 6572 5061 636b 6574 3e20 6b65  uarterPacket> ke
+00017580: 726e 656c 5f71 7561 7274 6572 3b0a 2020  rnel_quarter;.  
+00017590: 2020 2020 2020 2020 2020 2020 666f 7220              for 
+000175a0: 2869 6e74 2070 203d 2030 3b20 7020 3c20  (int p = 0; p < 
+000175b0: 7073 697a 653b 202b 2b70 2920 6b65 726e  psize; ++p) kern
+000175c0: 656c 5f71 7561 7274 6572 2e70 6163 6b65  el_quarter.packe
+000175d0: 745b 705d 203d 206c 6873 2e74 656d 706c  t[p] = lhs.templ
+000175e0: 6174 6520 6c6f 6164 5061 636b 6574 3c51  ate loadPacket<Q
+000175f0: 7561 7274 6572 5061 636b 6574 3e28 692b  uarterPacket>(i+
+00017600: 702b 6d2c 206b 293b 0a20 2020 2020 2020  p+m, k);.       
+00017610: 2020 2020 2020 2070 7472 616e 7370 6f73         ptranspos
+00017620: 6528 6b65 726e 656c 5f71 7561 7274 6572  e(kernel_quarter
+00017630: 293b 0a20 2020 2020 2020 2020 2020 2020  );.             
+00017640: 2066 6f72 2028 696e 7420 7020 3d20 303b   for (int p = 0;
+00017650: 2070 203c 2070 7369 7a65 3b20 2b2b 7029   p < psize; ++p)
+00017660: 2070 7374 6f72 6528 626c 6f63 6b41 2b63   pstore(blockA+c
+00017670: 6f75 6e74 2b6d 2b28 7061 636b 292a 702c  ount+m+(pack)*p,
+00017680: 2063 6a2e 7063 6f6e 6a28 6b65 726e 656c   cj.pconj(kernel
+00017690: 5f71 7561 7274 6572 2e70 6163 6b65 745b  _quarter.packet[
+000176a0: 705d 2929 3b0a 0920 2020 207d 0a20 2020  p]));..    }.   
+000176b0: 2020 2020 2020 207d 0a20 2020 2020 2020         }.       
+000176c0: 2020 2063 6f75 6e74 202b 3d20 7073 697a     count += psiz
+000176d0: 652a 7061 636b 3b0a 2020 2020 2020 2020  e*pack;.        
+000176e0: 7d0a 2020 2020 2020 7d0a 0a20 2020 2020  }.      }..     
+000176f0: 2066 6f72 283b 206b 3c64 6570 7468 3b20   for(; k<depth; 
+00017700: 6b2b 2b29 0a20 2020 2020 207b 0a20 2020  k++).      {.   
+00017710: 2020 2020 2049 6e64 6578 2077 3d30 3b0a       Index w=0;.
+00017720: 2020 2020 2020 2020 666f 7228 3b20 773c          for(; w<
+00017730: 7061 636b 2d33 3b20 772b 3d34 290a 2020  pack-3; w+=4).  
+00017740: 2020 2020 2020 7b0a 2020 2020 2020 2020        {.        
+00017750: 2020 5363 616c 6172 2061 2863 6a28 6c68    Scalar a(cj(lh
+00017760: 7328 692b 772b 302c 206b 2929 292c 0a20  s(i+w+0, k))),. 
+00017770: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017780: 6228 636a 286c 6873 2869 2b77 2b31 2c20  b(cj(lhs(i+w+1, 
+00017790: 6b29 2929 2c0a 2020 2020 2020 2020 2020  k))),.          
+000177a0: 2020 2020 2020 2063 2863 6a28 6c68 7328         c(cj(lhs(
+000177b0: 692b 772b 322c 206b 2929 292c 0a20 2020  i+w+2, k))),.   
+000177c0: 2020 2020 2020 2020 2020 2020 2020 6428                d(
+000177d0: 636a 286c 6873 2869 2b77 2b33 2c20 6b29  cj(lhs(i+w+3, k)
+000177e0: 2929 3b0a 2020 2020 2020 2020 2020 626c  ));.          bl
+000177f0: 6f63 6b41 5b63 6f75 6e74 2b2b 5d20 3d20  ockA[count++] = 
+00017800: 613b 0a20 2020 2020 2020 2020 2062 6c6f  a;.          blo
+00017810: 636b 415b 636f 756e 742b 2b5d 203d 2062  ckA[count++] = b
+00017820: 3b0a 2020 2020 2020 2020 2020 626c 6f63  ;.          bloc
+00017830: 6b41 5b63 6f75 6e74 2b2b 5d20 3d20 633b  kA[count++] = c;
+00017840: 0a20 2020 2020 2020 2020 2062 6c6f 636b  .          block
+00017850: 415b 636f 756e 742b 2b5d 203d 2064 3b0a  A[count++] = d;.
+00017860: 2020 2020 2020 2020 7d0a 2020 2020 2020          }.      
+00017870: 2020 6966 2870 6163 6b25 3429 0a20 2020    if(pack%4).   
+00017880: 2020 2020 2020 2066 6f72 283b 773c 7061         for(;w<pa
+00017890: 636b 3b2b 2b77 290a 2020 2020 2020 2020  ck;++w).        
+000178a0: 2020 2020 626c 6f63 6b41 5b63 6f75 6e74      blockA[count
+000178b0: 2b2b 5d20 3d20 636a 286c 6873 2869 2b77  ++] = cj(lhs(i+w
+000178c0: 2c20 6b29 293b 0a20 2020 2020 207d 0a0a  , k));.      }..
+000178d0: 2020 2020 2020 6966 2850 616e 656c 4d6f        if(PanelMo
+000178e0: 6465 2920 636f 756e 7420 2b3d 2070 6163  de) count += pac
+000178f0: 6b20 2a20 2873 7472 6964 652d 6f66 6673  k * (stride-offs
+00017900: 6574 2d64 6570 7468 293b 0a20 2020 207d  et-depth);.    }
+00017910: 0a0a 2020 2020 7061 636b 202d 3d20 7073  ..    pack -= ps
+00017920: 697a 653b 0a20 2020 2049 6e64 6578 206c  ize;.    Index l
+00017930: 6566 7420 3d20 726f 7773 202d 2069 3b0a  eft = rows - i;.
+00017940: 2020 2020 6966 2028 7061 636b 203c 3d20      if (pack <= 
+00017950: 3029 207b 0a20 2020 2020 2069 6620 2821  0) {.      if (!
+00017960: 676f 6e65 5f6c 6173 7420 2626 0a20 2020  gone_last &&.   
+00017970: 2020 2020 2020 2028 7374 6172 7469 6e67         (starting
+00017980: 5f70 6f73 203d 3d20 6920 7c7c 206c 6566  _pos == i || lef
+00017990: 7420 3e3d 2070 7369 7a65 2f32 207c 7c20  t >= psize/2 || 
+000179a0: 6c65 6674 203e 3d20 7073 697a 652f 3429  left >= psize/4)
+000179b0: 2026 260a 2020 2020 2020 2020 2020 2828   &&.          ((
+000179c0: 7073 697a 652f 3220 3d3d 2048 616c 6650  psize/2 == HalfP
+000179d0: 6163 6b65 7453 697a 6520 2626 2048 6173  acketSize && Has
+000179e0: 4861 6c66 2026 2620 2167 6f6e 655f 6861  Half && !gone_ha
+000179f0: 6c66 2920 7c7c 0a20 2020 2020 2020 2020  lf) ||.         
+00017a00: 2020 2870 7369 7a65 2f32 203d 3d20 5175    (psize/2 == Qu
+00017a10: 6172 7465 7250 6163 6b65 7453 697a 6520  arterPacketSize 
+00017a20: 2626 2048 6173 5175 6172 7465 7220 2626  && HasQuarter &&
+00017a30: 2021 676f 6e65 5f71 7561 7274 6572 2929   !gone_quarter))
+00017a40: 2920 7b0a 2020 2020 2020 2020 7073 697a  ) {.        psiz
+00017a50: 6520 2f3d 2032 3b0a 2020 2020 2020 2020  e /= 2;.        
+00017a60: 7061 636b 203d 2070 7369 7a65 3b0a 2020  pack = psize;.  
+00017a70: 2020 2020 2020 636f 6e74 696e 7565 3b0a        continue;.
+00017a80: 2020 2020 2020 7d0a 2020 2020 2020 2f2f        }.      //
+00017a90: 2050 6163 6b32 206d 6179 2062 6520 2a73   Pack2 may be *s
+00017aa0: 6d61 6c6c 6572 2a20 7468 616e 2050 6163  maller* than Pac
+00017ab0: 6b65 7453 697a 65e2 8094 7468 6174 2068  ketSize...that h
+00017ac0: 6170 7065 6e73 2066 6f72 0a20 2020 2020  appens for.     
+00017ad0: 202f 2f20 7072 6f64 7563 7473 206c 696b   // products lik
+00017ae0: 6520 7265 616c 202a 2063 6f6d 706c 6578  e real * complex
+00017af0: 2c20 7768 6572 6520 7765 2068 6176 6520  , where we have 
+00017b00: 746f 2067 6f20 6861 6c66 2074 6865 0a20  to go half the. 
+00017b10: 2020 2020 202f 2f20 7072 6f67 7265 7373       // progress
+00017b20: 206f 6e20 7468 6520 6c68 7320 696e 206f   on the lhs in o
+00017b30: 7264 6572 2074 6f20 6475 706c 6963 6174  rder to duplicat
+00017b40: 6520 7468 6f73 6520 6f70 6572 616e 6473  e those operands
+00017b50: 2074 6f0a 2020 2020 2020 2f2f 2061 6464   to.      // add
+00017b60: 7265 7373 2062 6f74 6820 7265 616c 2026  ress both real &
+00017b70: 2069 6d61 6769 6e61 7279 2070 6172 7473   imaginary parts
+00017b80: 206f 6e20 7468 6520 7268 732e 2054 6869   on the rhs. Thi
+00017b90: 7320 706f 7274 696f 6e20 7769 6c6c 0a20  s portion will. 
+00017ba0: 2020 2020 202f 2f20 7061 636b 2074 686f       // pack tho
+00017bb0: 7365 2068 616c 6620 6f6e 6573 2075 6e74  se half ones unt
+00017bc0: 696c 2074 6865 7920 6d61 7463 6820 7468  il they match th
+00017bd0: 6520 6e75 6d62 6572 2065 7870 6563 7465  e number expecte
+00017be0: 6420 6f6e 2074 6865 0a20 2020 2020 202f  d on the.      /
+00017bf0: 2f20 6c61 7374 2070 6565 6c69 6e67 206c  / last peeling l
+00017c00: 6f6f 7020 6174 2074 6869 7320 706f 696e  oop at this poin
+00017c10: 7420 2866 6f72 2074 6865 2072 6873 292e  t (for the rhs).
+00017c20: 0a20 2020 2020 2069 6620 2850 6163 6b32  .      if (Pack2
+00017c30: 203c 2050 6163 6b65 7453 697a 6520 2626   < PacketSize &&
+00017c40: 2021 676f 6e65 5f6c 6173 7429 207b 0a20   !gone_last) {. 
+00017c50: 2020 2020 2020 2067 6f6e 655f 6c61 7374         gone_last
+00017c60: 203d 2074 7275 653b 0a20 2020 2020 2020   = true;.       
+00017c70: 2070 7369 7a65 203d 2070 6163 6b20 3d20   psize = pack = 
+00017c80: 6c65 6674 2026 207e 313b 0a20 2020 2020  left & ~1;.     
+00017c90: 207d 0a20 2020 207d 0a20 207d 0a0a 2020   }.    }.  }..  
+00017ca0: 666f 7228 3b20 693c 726f 7773 3b20 692b  for(; i<rows; i+
+00017cb0: 2b29 0a20 207b 0a20 2020 2069 6628 5061  +).  {.    if(Pa
+00017cc0: 6e65 6c4d 6f64 6529 2063 6f75 6e74 202b  nelMode) count +
+00017cd0: 3d20 6f66 6673 6574 3b0a 2020 2020 666f  = offset;.    fo
+00017ce0: 7228 496e 6465 7820 6b3d 303b 206b 3c64  r(Index k=0; k<d
+00017cf0: 6570 7468 3b20 6b2b 2b29 0a20 2020 2020  epth; k++).     
+00017d00: 2062 6c6f 636b 415b 636f 756e 742b 2b5d   blockA[count++]
+00017d10: 203d 2063 6a28 6c68 7328 692c 206b 2929   = cj(lhs(i, k))
+00017d20: 3b0a 2020 2020 6966 2850 616e 656c 4d6f  ;.    if(PanelMo
+00017d30: 6465 2920 636f 756e 7420 2b3d 2028 7374  de) count += (st
+00017d40: 7269 6465 2d6f 6666 7365 742d 6465 7074  ride-offset-dept
+00017d50: 6829 3b0a 2020 7d0a 7d0a 0a2f 2f20 636f  h);.  }.}..// co
+00017d60: 7079 2061 2063 6f6d 706c 6574 6520 7061  py a complete pa
+00017d70: 6e65 6c20 6f66 2074 6865 2072 6873 0a2f  nel of the rhs./
+00017d80: 2f20 7468 6973 2076 6572 7369 6f6e 2069  / this version i
+00017d90: 7320 6f70 7469 6d69 7a65 6420 666f 7220  s optimized for 
+00017da0: 636f 6c75 6d6e 206d 616a 6f72 206d 6174  column major mat
+00017db0: 7269 6365 730a 2f2f 2054 6865 2074 7261  rices.// The tra
+00017dc0: 7665 7273 616c 206f 7264 6572 2069 7320  versal order is 
+00017dd0: 6173 2066 6f6c 6c6f 773a 2028 6e72 3d3d  as follow: (nr==
+00017de0: 3429 3a0a 2f2f 2020 3020 2031 2020 3220  4):.//  0  1  2 
+00017df0: 2033 2020 2031 3220 3133 2031 3420 3135   3   12 13 14 15
+00017e00: 2020 2032 3420 3237 0a2f 2f20 2034 2020     24 27.//  4  
+00017e10: 3520 2036 2020 3720 2020 3136 2031 3720  5  6  7   16 17 
+00017e20: 3138 2031 3920 2020 3235 2032 380a 2f2f  18 19   25 28.//
+00017e30: 2020 3820 2039 2031 3020 3131 2020 2032    8  9 10 11   2
+00017e40: 3020 3231 2032 3220 3233 2020 2032 3620  0 21 22 23   26 
+00017e50: 3239 0a2f 2f20 202e 2020 2e20 202e 2020  29.//  .  .  .  
+00017e60: 2e20 2020 202e 2020 2e20 202e 2020 2e20  .    .  .  .  . 
+00017e70: 2020 202e 2020 2e0a 7465 6d70 6c61 7465     .  ..template
+00017e80: 3c74 7970 656e 616d 6520 5363 616c 6172  <typename Scalar
+00017e90: 2c20 7479 7065 6e61 6d65 2049 6e64 6578  , typename Index
+00017ea0: 2c20 7479 7065 6e61 6d65 2044 6174 614d  , typename DataM
+00017eb0: 6170 7065 722c 2069 6e74 206e 722c 2062  apper, int nr, b
+00017ec0: 6f6f 6c20 436f 6e6a 7567 6174 652c 2062  ool Conjugate, b
+00017ed0: 6f6f 6c20 5061 6e65 6c4d 6f64 653e 0a73  ool PanelMode>.s
+00017ee0: 7472 7563 7420 6765 6d6d 5f70 6163 6b5f  truct gemm_pack_
+00017ef0: 7268 733c 5363 616c 6172 2c20 496e 6465  rhs<Scalar, Inde
+00017f00: 782c 2044 6174 614d 6170 7065 722c 206e  x, DataMapper, n
+00017f10: 722c 2043 6f6c 4d61 6a6f 722c 2043 6f6e  r, ColMajor, Con
+00017f20: 6a75 6761 7465 2c20 5061 6e65 6c4d 6f64  jugate, PanelMod
+00017f30: 653e 0a7b 0a20 2074 7970 6564 6566 2074  e>.{.  typedef t
+00017f40: 7970 656e 616d 6520 7061 636b 6574 5f74  ypename packet_t
+00017f50: 7261 6974 733c 5363 616c 6172 3e3a 3a74  raits<Scalar>::t
+00017f60: 7970 6520 5061 636b 6574 3b0a 2020 7479  ype Packet;.  ty
+00017f70: 7065 6465 6620 7479 7065 6e61 6d65 2044  pedef typename D
+00017f80: 6174 614d 6170 7065 723a 3a4c 696e 6561  ataMapper::Linea
+00017f90: 724d 6170 7065 7220 4c69 6e65 6172 4d61  rMapper LinearMa
+00017fa0: 7070 6572 3b0a 2020 656e 756d 207b 2050  pper;.  enum { P
+00017fb0: 6163 6b65 7453 697a 6520 3d20 7061 636b  acketSize = pack
+00017fc0: 6574 5f74 7261 6974 733c 5363 616c 6172  et_traits<Scalar
+00017fd0: 3e3a 3a73 697a 6520 7d3b 0a20 2045 4947  >::size };.  EIG
+00017fe0: 454e 5f44 4f4e 545f 494e 4c49 4e45 2076  EN_DONT_INLINE v
+00017ff0: 6f69 6420 6f70 6572 6174 6f72 2829 2853  oid operator()(S
+00018000: 6361 6c61 722a 2062 6c6f 636b 422c 2063  calar* blockB, c
+00018010: 6f6e 7374 2044 6174 614d 6170 7065 7226  onst DataMapper&
+00018020: 2072 6873 2c20 496e 6465 7820 6465 7074   rhs, Index dept
+00018030: 682c 2049 6e64 6578 2063 6f6c 732c 2049  h, Index cols, I
+00018040: 6e64 6578 2073 7472 6964 653d 302c 2049  ndex stride=0, I
+00018050: 6e64 6578 206f 6666 7365 743d 3029 3b0a  ndex offset=0);.
+00018060: 7d3b 0a0a 7465 6d70 6c61 7465 3c74 7970  };..template<typ
+00018070: 656e 616d 6520 5363 616c 6172 2c20 7479  ename Scalar, ty
+00018080: 7065 6e61 6d65 2049 6e64 6578 2c20 7479  pename Index, ty
+00018090: 7065 6e61 6d65 2044 6174 614d 6170 7065  pename DataMappe
+000180a0: 722c 2069 6e74 206e 722c 2062 6f6f 6c20  r, int nr, bool 
+000180b0: 436f 6e6a 7567 6174 652c 2062 6f6f 6c20  Conjugate, bool 
+000180c0: 5061 6e65 6c4d 6f64 653e 0a45 4947 454e  PanelMode>.EIGEN
+000180d0: 5f44 4f4e 545f 494e 4c49 4e45 2076 6f69  _DONT_INLINE voi
+000180e0: 6420 6765 6d6d 5f70 6163 6b5f 7268 733c  d gemm_pack_rhs<
+000180f0: 5363 616c 6172 2c20 496e 6465 782c 2044  Scalar, Index, D
+00018100: 6174 614d 6170 7065 722c 206e 722c 2043  ataMapper, nr, C
+00018110: 6f6c 4d61 6a6f 722c 2043 6f6e 6a75 6761  olMajor, Conjuga
+00018120: 7465 2c20 5061 6e65 6c4d 6f64 653e 0a20  te, PanelMode>. 
+00018130: 203a 3a6f 7065 7261 746f 7228 2928 5363   ::operator()(Sc
+00018140: 616c 6172 2a20 626c 6f63 6b42 2c20 636f  alar* blockB, co
+00018150: 6e73 7420 4461 7461 4d61 7070 6572 2620  nst DataMapper& 
+00018160: 7268 732c 2049 6e64 6578 2064 6570 7468  rhs, Index depth
+00018170: 2c20 496e 6465 7820 636f 6c73 2c20 496e  , Index cols, In
+00018180: 6465 7820 7374 7269 6465 2c20 496e 6465  dex stride, Inde
+00018190: 7820 6f66 6673 6574 290a 7b0a 2020 4549  x offset).{.  EI
+000181a0: 4745 4e5f 4153 4d5f 434f 4d4d 454e 5428  GEN_ASM_COMMENT(
+000181b0: 2245 4947 454e 2050 524f 4455 4354 2050  "EIGEN PRODUCT P
+000181c0: 4143 4b20 5248 5320 434f 4c4d 414a 4f52  ACK RHS COLMAJOR
+000181d0: 2229 3b0a 2020 4549 4745 4e5f 554e 5553  ");.  EIGEN_UNUS
+000181e0: 4544 5f56 4152 4941 424c 4528 7374 7269  ED_VARIABLE(stri
+000181f0: 6465 293b 0a20 2045 4947 454e 5f55 4e55  de);.  EIGEN_UNU
+00018200: 5345 445f 5641 5249 4142 4c45 286f 6666  SED_VARIABLE(off
+00018210: 7365 7429 3b0a 2020 6569 6765 6e5f 6173  set);.  eigen_as
+00018220: 7365 7274 2828 2821 5061 6e65 6c4d 6f64  sert(((!PanelMod
+00018230: 6529 2026 2620 7374 7269 6465 3d3d 3020  e) && stride==0 
+00018240: 2626 206f 6666 7365 743d 3d30 2920 7c7c  && offset==0) ||
+00018250: 2028 5061 6e65 6c4d 6f64 6520 2626 2073   (PanelMode && s
+00018260: 7472 6964 653e 3d64 6570 7468 2026 2620  tride>=depth && 
+00018270: 6f66 6673 6574 3c3d 7374 7269 6465 2929  offset<=stride))
+00018280: 3b0a 2020 636f 6e6a 5f69 663c 4e75 6d54  ;.  conj_if<NumT
+00018290: 7261 6974 733c 5363 616c 6172 3e3a 3a49  raits<Scalar>::I
+000182a0: 7343 6f6d 706c 6578 2026 2620 436f 6e6a  sComplex && Conj
+000182b0: 7567 6174 653e 2063 6a3b 0a20 2049 6e64  ugate> cj;.  Ind
+000182c0: 6578 2070 6163 6b65 745f 636f 6c73 3820  ex packet_cols8 
+000182d0: 3d20 6e72 3e3d 3820 3f20 2863 6f6c 732f  = nr>=8 ? (cols/
+000182e0: 3829 202a 2038 203a 2030 3b0a 2020 496e  8) * 8 : 0;.  In
+000182f0: 6465 7820 7061 636b 6574 5f63 6f6c 7334  dex packet_cols4
+00018300: 203d 206e 723e 3d34 203f 2028 636f 6c73   = nr>=4 ? (cols
+00018310: 2f34 2920 2a20 3420 3a20 303b 0a20 2049  /4) * 4 : 0;.  I
+00018320: 6e64 6578 2063 6f75 6e74 203d 2030 3b0a  ndex count = 0;.
+00018330: 2020 636f 6e73 7420 496e 6465 7820 7065    const Index pe
+00018340: 656c 6564 5f6b 203d 2028 6465 7074 682f  eled_k = (depth/
+00018350: 5061 636b 6574 5369 7a65 292a 5061 636b  PacketSize)*Pack
+00018360: 6574 5369 7a65 3b0a 2f2f 2020 2069 6628  etSize;.//   if(
+00018370: 6e72 3e3d 3829 0a2f 2f20 2020 7b0a 2f2f  nr>=8).//   {.//
+00018380: 2020 2020 2066 6f72 2849 6e64 6578 206a       for(Index j
+00018390: 323d 303b 206a 323c 7061 636b 6574 5f63  2=0; j2<packet_c
+000183a0: 6f6c 7338 3b20 6a32 2b3d 3829 0a2f 2f20  ols8; j2+=8).// 
+000183b0: 2020 2020 7b0a 2f2f 2020 2020 2020 202f      {.//       /
+000183c0: 2f20 736b 6970 2077 6861 7420 7765 2068  / skip what we h
+000183d0: 6176 6520 6265 666f 7265 0a2f 2f20 2020  ave before.//   
+000183e0: 2020 2020 6966 2850 616e 656c 4d6f 6465      if(PanelMode
+000183f0: 2920 636f 756e 7420 2b3d 2038 202a 206f  ) count += 8 * o
+00018400: 6666 7365 743b 0a2f 2f20 2020 2020 2020  ffset;.//       
+00018410: 636f 6e73 7420 5363 616c 6172 2a20 6230  const Scalar* b0
+00018420: 203d 2026 7268 735b 286a 322b 3029 2a72   = &rhs[(j2+0)*r
+00018430: 6873 5374 7269 6465 5d3b 0a2f 2f20 2020  hsStride];.//   
+00018440: 2020 2020 636f 6e73 7420 5363 616c 6172      const Scalar
+00018450: 2a20 6231 203d 2026 7268 735b 286a 322b  * b1 = &rhs[(j2+
+00018460: 3129 2a72 6873 5374 7269 6465 5d3b 0a2f  1)*rhsStride];./
+00018470: 2f20 2020 2020 2020 636f 6e73 7420 5363  /       const Sc
+00018480: 616c 6172 2a20 6232 203d 2026 7268 735b  alar* b2 = &rhs[
+00018490: 286a 322b 3229 2a72 6873 5374 7269 6465  (j2+2)*rhsStride
+000184a0: 5d3b 0a2f 2f20 2020 2020 2020 636f 6e73  ];.//       cons
+000184b0: 7420 5363 616c 6172 2a20 6233 203d 2026  t Scalar* b3 = &
+000184c0: 7268 735b 286a 322b 3329 2a72 6873 5374  rhs[(j2+3)*rhsSt
+000184d0: 7269 6465 5d3b 0a2f 2f20 2020 2020 2020  ride];.//       
+000184e0: 636f 6e73 7420 5363 616c 6172 2a20 6234  const Scalar* b4
+000184f0: 203d 2026 7268 735b 286a 322b 3429 2a72   = &rhs[(j2+4)*r
+00018500: 6873 5374 7269 6465 5d3b 0a2f 2f20 2020  hsStride];.//   
+00018510: 2020 2020 636f 6e73 7420 5363 616c 6172      const Scalar
+00018520: 2a20 6235 203d 2026 7268 735b 286a 322b  * b5 = &rhs[(j2+
+00018530: 3529 2a72 6873 5374 7269 6465 5d3b 0a2f  5)*rhsStride];./
+00018540: 2f20 2020 2020 2020 636f 6e73 7420 5363  /       const Sc
+00018550: 616c 6172 2a20 6236 203d 2026 7268 735b  alar* b6 = &rhs[
+00018560: 286a 322b 3629 2a72 6873 5374 7269 6465  (j2+6)*rhsStride
+00018570: 5d3b 0a2f 2f20 2020 2020 2020 636f 6e73  ];.//       cons
+00018580: 7420 5363 616c 6172 2a20 6237 203d 2026  t Scalar* b7 = &
+00018590: 7268 735b 286a 322b 3729 2a72 6873 5374  rhs[(j2+7)*rhsSt
+000185a0: 7269 6465 5d3b 0a2f 2f20 2020 2020 2020  ride];.//       
+000185b0: 496e 6465 7820 6b3d 303b 0a2f 2f20 2020  Index k=0;.//   
+000185c0: 2020 2020 6966 2850 6163 6b65 7453 697a      if(PacketSiz
+000185d0: 653d 3d38 2920 2f2f 2054 4f44 4f20 656e  e==8) // TODO en
+000185e0: 6162 6c65 2076 6563 746f 7269 7a65 6420  able vectorized 
+000185f0: 7472 616e 7370 6f73 6974 696f 6e20 666f  transposition fo
+00018600: 7220 5061 636b 6574 5369 7a65 3d3d 340a  r PacketSize==4.
+00018610: 2f2f 2020 2020 2020 207b 0a2f 2f20 2020  //       {.//   
+00018620: 2020 2020 2020 666f 7228 3b20 6b3c 7065        for(; k<pe
+00018630: 656c 6564 5f6b 3b20 6b2b 3d50 6163 6b65  eled_k; k+=Packe
+00018640: 7453 697a 6529 207b 0a2f 2f20 2020 2020  tSize) {.//     
+00018650: 2020 2020 2020 5061 636b 6574 426c 6f63        PacketBloc
+00018660: 6b3c 5061 636b 6574 3e20 6b65 726e 656c  k<Packet> kernel
+00018670: 3b0a 2f2f 2020 2020 2020 2020 2020 2066  ;.//           f
+00018680: 6f72 2028 696e 7420 7020 3d20 303b 2070  or (int p = 0; p
+00018690: 203c 2050 6163 6b65 7453 697a 653b 202b   < PacketSize; +
+000186a0: 2b70 2920 7b0a 2f2f 2020 2020 2020 2020  +p) {.//        
+000186b0: 2020 2020 206b 6572 6e65 6c2e 7061 636b       kernel.pack
+000186c0: 6574 5b70 5d20 3d20 706c 6f61 6475 3c50  et[p] = ploadu<P
+000186d0: 6163 6b65 743e 2826 7268 735b 286a 322b  acket>(&rhs[(j2+
+000186e0: 7029 2a72 6873 5374 7269 6465 2b6b 5d29  p)*rhsStride+k])
+000186f0: 3b0a 2f2f 2020 2020 2020 2020 2020 207d  ;.//           }
+00018700: 0a2f 2f20 2020 2020 2020 2020 2020 7074  .//           pt
+00018710: 7261 6e73 706f 7365 286b 6572 6e65 6c29  ranspose(kernel)
+00018720: 3b0a 2f2f 2020 2020 2020 2020 2020 2066  ;.//           f
+00018730: 6f72 2028 696e 7420 7020 3d20 303b 2070  or (int p = 0; p
+00018740: 203c 2050 6163 6b65 7453 697a 653b 202b   < PacketSize; +
+00018750: 2b70 2920 7b0a 2f2f 2020 2020 2020 2020  +p) {.//        
+00018760: 2020 2020 2070 7374 6f72 6575 2862 6c6f       pstoreu(blo
+00018770: 636b 422b 636f 756e 742c 2063 6a2e 7063  ckB+count, cj.pc
+00018780: 6f6e 6a28 6b65 726e 656c 2e70 6163 6b65  onj(kernel.packe
+00018790: 745b 705d 2929 3b0a 2f2f 2020 2020 2020  t[p]));.//      
+000187a0: 2020 2020 2020 2063 6f75 6e74 2b3d 5061         count+=Pa
+000187b0: 636b 6574 5369 7a65 3b0a 2f2f 2020 2020  cketSize;.//    
+000187c0: 2020 2020 2020 207d 0a2f 2f20 2020 2020         }.//     
+000187d0: 2020 2020 7d0a 2f2f 2020 2020 2020 207d      }.//       }
+000187e0: 0a2f 2f20 2020 2020 2020 666f 7228 3b20  .//       for(; 
+000187f0: 6b3c 6465 7074 683b 206b 2b2b 290a 2f2f  k<depth; k++).//
+00018800: 2020 2020 2020 207b 0a2f 2f20 2020 2020         {.//     
+00018810: 2020 2020 626c 6f63 6b42 5b63 6f75 6e74      blockB[count
+00018820: 2b30 5d20 3d20 636a 2862 305b 6b5d 293b  +0] = cj(b0[k]);
+00018830: 0a2f 2f20 2020 2020 2020 2020 626c 6f63  .//         bloc
+00018840: 6b42 5b63 6f75 6e74 2b31 5d20 3d20 636a  kB[count+1] = cj
+00018850: 2862 315b 6b5d 293b 0a2f 2f20 2020 2020  (b1[k]);.//     
+00018860: 2020 2020 626c 6f63 6b42 5b63 6f75 6e74      blockB[count
+00018870: 2b32 5d20 3d20 636a 2862 325b 6b5d 293b  +2] = cj(b2[k]);
+00018880: 0a2f 2f20 2020 2020 2020 2020 626c 6f63  .//         bloc
+00018890: 6b42 5b63 6f75 6e74 2b33 5d20 3d20 636a  kB[count+3] = cj
+000188a0: 2862 335b 6b5d 293b 0a2f 2f20 2020 2020  (b3[k]);.//     
+000188b0: 2020 2020 626c 6f63 6b42 5b63 6f75 6e74      blockB[count
+000188c0: 2b34 5d20 3d20 636a 2862 345b 6b5d 293b  +4] = cj(b4[k]);
+000188d0: 0a2f 2f20 2020 2020 2020 2020 626c 6f63  .//         bloc
+000188e0: 6b42 5b63 6f75 6e74 2b35 5d20 3d20 636a  kB[count+5] = cj
+000188f0: 2862 355b 6b5d 293b 0a2f 2f20 2020 2020  (b5[k]);.//     
+00018900: 2020 2020 626c 6f63 6b42 5b63 6f75 6e74      blockB[count
+00018910: 2b36 5d20 3d20 636a 2862 365b 6b5d 293b  +6] = cj(b6[k]);
+00018920: 0a2f 2f20 2020 2020 2020 2020 626c 6f63  .//         bloc
+00018930: 6b42 5b63 6f75 6e74 2b37 5d20 3d20 636a  kB[count+7] = cj
+00018940: 2862 375b 6b5d 293b 0a2f 2f20 2020 2020  (b7[k]);.//     
+00018950: 2020 2020 636f 756e 7420 2b3d 2038 3b0a      count += 8;.
+00018960: 2f2f 2020 2020 2020 207d 0a2f 2f20 2020  //       }.//   
+00018970: 2020 2020 2f2f 2073 6b69 7020 7768 6174      // skip what
+00018980: 2077 6520 6861 7665 2061 6674 6572 0a2f   we have after./
+00018990: 2f20 2020 2020 2020 6966 2850 616e 656c  /       if(Panel
+000189a0: 4d6f 6465 2920 636f 756e 7420 2b3d 2038  Mode) count += 8
+000189b0: 202a 2028 7374 7269 6465 2d6f 6666 7365   * (stride-offse
+000189c0: 742d 6465 7074 6829 3b0a 2f2f 2020 2020  t-depth);.//    
+000189d0: 207d 0a2f 2f20 2020 7d0a 0a20 2069 6628   }.//   }..  if(
+000189e0: 6e72 3e3d 3429 0a20 207b 0a20 2020 2066  nr>=4).  {.    f
+000189f0: 6f72 2849 6e64 6578 206a 323d 7061 636b  or(Index j2=pack
+00018a00: 6574 5f63 6f6c 7338 3b20 6a32 3c70 6163  et_cols8; j2<pac
+00018a10: 6b65 745f 636f 6c73 343b 206a 322b 3d34  ket_cols4; j2+=4
+00018a20: 290a 2020 2020 7b0a 2020 2020 2020 2f2f  ).    {.      //
+00018a30: 2073 6b69 7020 7768 6174 2077 6520 6861   skip what we ha
+00018a40: 7665 2062 6566 6f72 650a 2020 2020 2020  ve before.      
+00018a50: 6966 2850 616e 656c 4d6f 6465 2920 636f  if(PanelMode) co
+00018a60: 756e 7420 2b3d 2034 202a 206f 6666 7365  unt += 4 * offse
+00018a70: 743b 0a20 2020 2020 2063 6f6e 7374 204c  t;.      const L
+00018a80: 696e 6561 724d 6170 7065 7220 646d 3020  inearMapper dm0 
+00018a90: 3d20 7268 732e 6765 744c 696e 6561 724d  = rhs.getLinearM
+00018aa0: 6170 7065 7228 302c 206a 3220 2b20 3029  apper(0, j2 + 0)
+00018ab0: 3b0a 2020 2020 2020 636f 6e73 7420 4c69  ;.      const Li
+00018ac0: 6e65 6172 4d61 7070 6572 2064 6d31 203d  nearMapper dm1 =
+00018ad0: 2072 6873 2e67 6574 4c69 6e65 6172 4d61   rhs.getLinearMa
+00018ae0: 7070 6572 2830 2c20 6a32 202b 2031 293b  pper(0, j2 + 1);
+00018af0: 0a20 2020 2020 2063 6f6e 7374 204c 696e  .      const Lin
+00018b00: 6561 724d 6170 7065 7220 646d 3220 3d20  earMapper dm2 = 
+00018b10: 7268 732e 6765 744c 696e 6561 724d 6170  rhs.getLinearMap
+00018b20: 7065 7228 302c 206a 3220 2b20 3229 3b0a  per(0, j2 + 2);.
+00018b30: 2020 2020 2020 636f 6e73 7420 4c69 6e65        const Line
+00018b40: 6172 4d61 7070 6572 2064 6d33 203d 2072  arMapper dm3 = r
+00018b50: 6873 2e67 6574 4c69 6e65 6172 4d61 7070  hs.getLinearMapp
+00018b60: 6572 2830 2c20 6a32 202b 2033 293b 0a0a  er(0, j2 + 3);..
+00018b70: 2020 2020 2020 496e 6465 7820 6b3d 303b        Index k=0;
+00018b80: 0a20 2020 2020 2069 6628 2850 6163 6b65  .      if((Packe
+00018b90: 7453 697a 6525 3429 3d3d 3029 202f 2f20  tSize%4)==0) // 
+00018ba0: 544f 444f 2065 6e61 626c 6520 7665 6374  TODO enable vect
+00018bb0: 6f72 697a 6564 2074 7261 6e73 706f 7369  orized transposi
+00018bc0: 7469 6f6e 2066 6f72 2050 6163 6b65 7453  tion for PacketS
+00018bd0: 697a 653d 3d32 203f 3f0a 2020 2020 2020  ize==2 ??.      
+00018be0: 7b0a 2020 2020 2020 2020 666f 7228 3b20  {.        for(; 
+00018bf0: 6b3c 7065 656c 6564 5f6b 3b20 6b2b 3d50  k<peeled_k; k+=P
+00018c00: 6163 6b65 7453 697a 6529 207b 0a20 2020  acketSize) {.   
+00018c10: 2020 2020 2020 2050 6163 6b65 7442 6c6f         PacketBlo
+00018c20: 636b 3c50 6163 6b65 742c 2850 6163 6b65  ck<Packet,(Packe
+00018c30: 7453 697a 6525 3429 3d3d 303f 343a 5061  tSize%4)==0?4:Pa
+00018c40: 636b 6574 5369 7a65 3e20 6b65 726e 656c  cketSize> kernel
+00018c50: 3b0a 2020 2020 2020 2020 2020 6b65 726e  ;.          kern
+00018c60: 656c 2e70 6163 6b65 745b 3020 2020 2020  el.packet[0     
+00018c70: 2020 2020 2020 5d20 3d20 646d 302e 7465        ] = dm0.te
+00018c80: 6d70 6c61 7465 206c 6f61 6450 6163 6b65  mplate loadPacke
+00018c90: 743c 5061 636b 6574 3e28 6b29 3b0a 2020  t<Packet>(k);.  
+00018ca0: 2020 2020 2020 2020 6b65 726e 656c 2e70          kernel.p
+00018cb0: 6163 6b65 745b 3125 5061 636b 6574 5369  acket[1%PacketSi
+00018cc0: 7a65 5d20 3d20 646d 312e 7465 6d70 6c61  ze] = dm1.templa
+00018cd0: 7465 206c 6f61 6450 6163 6b65 743c 5061  te loadPacket<Pa
+00018ce0: 636b 6574 3e28 6b29 3b0a 2020 2020 2020  cket>(k);.      
+00018cf0: 2020 2020 6b65 726e 656c 2e70 6163 6b65      kernel.packe
+00018d00: 745b 3225 5061 636b 6574 5369 7a65 5d20  t[2%PacketSize] 
+00018d10: 3d20 646d 322e 7465 6d70 6c61 7465 206c  = dm2.template l
+00018d20: 6f61 6450 6163 6b65 743c 5061 636b 6574  oadPacket<Packet
+00018d30: 3e28 6b29 3b0a 2020 2020 2020 2020 2020  >(k);.          
+00018d40: 6b65 726e 656c 2e70 6163 6b65 745b 3325  kernel.packet[3%
+00018d50: 5061 636b 6574 5369 7a65 5d20 3d20 646d  PacketSize] = dm
+00018d60: 332e 7465 6d70 6c61 7465 206c 6f61 6450  3.template loadP
+00018d70: 6163 6b65 743c 5061 636b 6574 3e28 6b29  acket<Packet>(k)
+00018d80: 3b0a 2020 2020 2020 2020 2020 7074 7261  ;.          ptra
+00018d90: 6e73 706f 7365 286b 6572 6e65 6c29 3b0a  nspose(kernel);.
+00018da0: 2020 2020 2020 2020 2020 7073 746f 7265            pstore
+00018db0: 7528 626c 6f63 6b42 2b63 6f75 6e74 2b30  u(blockB+count+0
+00018dc0: 2a50 6163 6b65 7453 697a 652c 2063 6a2e  *PacketSize, cj.
+00018dd0: 7063 6f6e 6a28 6b65 726e 656c 2e70 6163  pconj(kernel.pac
+00018de0: 6b65 745b 305d 2929 3b0a 2020 2020 2020  ket[0]));.      
+00018df0: 2020 2020 7073 746f 7265 7528 626c 6f63      pstoreu(bloc
+00018e00: 6b42 2b63 6f75 6e74 2b31 2a50 6163 6b65  kB+count+1*Packe
+00018e10: 7453 697a 652c 2063 6a2e 7063 6f6e 6a28  tSize, cj.pconj(
+00018e20: 6b65 726e 656c 2e70 6163 6b65 745b 3125  kernel.packet[1%
+00018e30: 5061 636b 6574 5369 7a65 5d29 293b 0a20  PacketSize]));. 
+00018e40: 2020 2020 2020 2020 2070 7374 6f72 6575           pstoreu
+00018e50: 2862 6c6f 636b 422b 636f 756e 742b 322a  (blockB+count+2*
+00018e60: 5061 636b 6574 5369 7a65 2c20 636a 2e70  PacketSize, cj.p
+00018e70: 636f 6e6a 286b 6572 6e65 6c2e 7061 636b  conj(kernel.pack
+00018e80: 6574 5b32 2550 6163 6b65 7453 697a 655d  et[2%PacketSize]
+00018e90: 2929 3b0a 2020 2020 2020 2020 2020 7073  ));.          ps
+00018ea0: 746f 7265 7528 626c 6f63 6b42 2b63 6f75  toreu(blockB+cou
+00018eb0: 6e74 2b33 2a50 6163 6b65 7453 697a 652c  nt+3*PacketSize,
+00018ec0: 2063 6a2e 7063 6f6e 6a28 6b65 726e 656c   cj.pconj(kernel
+00018ed0: 2e70 6163 6b65 745b 3325 5061 636b 6574  .packet[3%Packet
+00018ee0: 5369 7a65 5d29 293b 0a20 2020 2020 2020  Size]));.       
+00018ef0: 2020 2063 6f75 6e74 2b3d 342a 5061 636b     count+=4*Pack
+00018f00: 6574 5369 7a65 3b0a 2020 2020 2020 2020  etSize;.        
+00018f10: 7d0a 2020 2020 2020 7d0a 2020 2020 2020  }.      }.      
+00018f20: 666f 7228 3b20 6b3c 6465 7074 683b 206b  for(; k<depth; k
+00018f30: 2b2b 290a 2020 2020 2020 7b0a 2020 2020  ++).      {.    
+00018f40: 2020 2020 626c 6f63 6b42 5b63 6f75 6e74      blockB[count
+00018f50: 2b30 5d20 3d20 636a 2864 6d30 286b 2929  +0] = cj(dm0(k))
+00018f60: 3b0a 2020 2020 2020 2020 626c 6f63 6b42  ;.        blockB
+00018f70: 5b63 6f75 6e74 2b31 5d20 3d20 636a 2864  [count+1] = cj(d
+00018f80: 6d31 286b 2929 3b0a 2020 2020 2020 2020  m1(k));.        
+00018f90: 626c 6f63 6b42 5b63 6f75 6e74 2b32 5d20  blockB[count+2] 
+00018fa0: 3d20 636a 2864 6d32 286b 2929 3b0a 2020  = cj(dm2(k));.  
+00018fb0: 2020 2020 2020 626c 6f63 6b42 5b63 6f75        blockB[cou
+00018fc0: 6e74 2b33 5d20 3d20 636a 2864 6d33 286b  nt+3] = cj(dm3(k
+00018fd0: 2929 3b0a 2020 2020 2020 2020 636f 756e  ));.        coun
+00018fe0: 7420 2b3d 2034 3b0a 2020 2020 2020 7d0a  t += 4;.      }.
+00018ff0: 2020 2020 2020 2f2f 2073 6b69 7020 7768        // skip wh
+00019000: 6174 2077 6520 6861 7665 2061 6674 6572  at we have after
+00019010: 0a20 2020 2020 2069 6628 5061 6e65 6c4d  .      if(PanelM
+00019020: 6f64 6529 2063 6f75 6e74 202b 3d20 3420  ode) count += 4 
+00019030: 2a20 2873 7472 6964 652d 6f66 6673 6574  * (stride-offset
+00019040: 2d64 6570 7468 293b 0a20 2020 207d 0a20  -depth);.    }. 
+00019050: 207d 0a0a 2020 2f2f 2063 6f70 7920 7468   }..  // copy th
+00019060: 6520 7265 6d61 696e 696e 6720 636f 6c75  e remaining colu
+00019070: 6d6e 7320 6f6e 6520 6174 2061 2074 696d  mns one at a tim
+00019080: 6520 286e 723d 3d31 290a 2020 666f 7228  e (nr==1).  for(
+00019090: 496e 6465 7820 6a32 3d70 6163 6b65 745f  Index j2=packet_
+000190a0: 636f 6c73 343b 206a 323c 636f 6c73 3b20  cols4; j2<cols; 
+000190b0: 2b2b 6a32 290a 2020 7b0a 2020 2020 6966  ++j2).  {.    if
+000190c0: 2850 616e 656c 4d6f 6465 2920 636f 756e  (PanelMode) coun
+000190d0: 7420 2b3d 206f 6666 7365 743b 0a20 2020  t += offset;.   
+000190e0: 2063 6f6e 7374 204c 696e 6561 724d 6170   const LinearMap
+000190f0: 7065 7220 646d 3020 3d20 7268 732e 6765  per dm0 = rhs.ge
+00019100: 744c 696e 6561 724d 6170 7065 7228 302c  tLinearMapper(0,
+00019110: 206a 3229 3b0a 2020 2020 666f 7228 496e   j2);.    for(In
+00019120: 6465 7820 6b3d 303b 206b 3c64 6570 7468  dex k=0; k<depth
+00019130: 3b20 6b2b 2b29 0a20 2020 207b 0a20 2020  ; k++).    {.   
+00019140: 2020 2062 6c6f 636b 425b 636f 756e 745d     blockB[count]
+00019150: 203d 2063 6a28 646d 3028 6b29 293b 0a20   = cj(dm0(k));. 
+00019160: 2020 2020 2063 6f75 6e74 202b 3d20 313b       count += 1;
+00019170: 0a20 2020 207d 0a20 2020 2069 6628 5061  .    }.    if(Pa
+00019180: 6e65 6c4d 6f64 6529 2063 6f75 6e74 202b  nelMode) count +
+00019190: 3d20 2873 7472 6964 652d 6f66 6673 6574  = (stride-offset
+000191a0: 2d64 6570 7468 293b 0a20 207d 0a7d 0a0a  -depth);.  }.}..
+000191b0: 2f2f 2074 6869 7320 7665 7273 696f 6e20  // this version 
+000191c0: 6973 206f 7074 696d 697a 6564 2066 6f72  is optimized for
+000191d0: 2072 6f77 206d 616a 6f72 206d 6174 7269   row major matri
+000191e0: 6365 730a 7465 6d70 6c61 7465 3c74 7970  ces.template<typ
+000191f0: 656e 616d 6520 5363 616c 6172 2c20 7479  ename Scalar, ty
+00019200: 7065 6e61 6d65 2049 6e64 6578 2c20 7479  pename Index, ty
+00019210: 7065 6e61 6d65 2044 6174 614d 6170 7065  pename DataMappe
+00019220: 722c 2069 6e74 206e 722c 2062 6f6f 6c20  r, int nr, bool 
+00019230: 436f 6e6a 7567 6174 652c 2062 6f6f 6c20  Conjugate, bool 
+00019240: 5061 6e65 6c4d 6f64 653e 0a73 7472 7563  PanelMode>.struc
+00019250: 7420 6765 6d6d 5f70 6163 6b5f 7268 733c  t gemm_pack_rhs<
+00019260: 5363 616c 6172 2c20 496e 6465 782c 2044  Scalar, Index, D
+00019270: 6174 614d 6170 7065 722c 206e 722c 2052  ataMapper, nr, R
+00019280: 6f77 4d61 6a6f 722c 2043 6f6e 6a75 6761  owMajor, Conjuga
+00019290: 7465 2c20 5061 6e65 6c4d 6f64 653e 0a7b  te, PanelMode>.{
+000192a0: 0a20 2074 7970 6564 6566 2074 7970 656e  .  typedef typen
+000192b0: 616d 6520 7061 636b 6574 5f74 7261 6974  ame packet_trait
+000192c0: 733c 5363 616c 6172 3e3a 3a74 7970 6520  s<Scalar>::type 
+000192d0: 5061 636b 6574 3b0a 2020 7479 7065 6465  Packet;.  typede
+000192e0: 6620 7479 7065 6e61 6d65 2075 6e70 6163  f typename unpac
+000192f0: 6b65 745f 7472 6169 7473 3c50 6163 6b65  ket_traits<Packe
+00019300: 743e 3a3a 6861 6c66 2048 616c 6650 6163  t>::half HalfPac
+00019310: 6b65 743b 0a20 2074 7970 6564 6566 2074  ket;.  typedef t
+00019320: 7970 656e 616d 6520 756e 7061 636b 6574  ypename unpacket
+00019330: 5f74 7261 6974 733c 7479 7065 6e61 6d65  _traits<typename
+00019340: 2075 6e70 6163 6b65 745f 7472 6169 7473   unpacket_traits
+00019350: 3c50 6163 6b65 743e 3a3a 6861 6c66 3e3a  <Packet>::half>:
+00019360: 3a68 616c 6620 5175 6172 7465 7250 6163  :half QuarterPac
+00019370: 6b65 743b 0a20 2074 7970 6564 6566 2074  ket;.  typedef t
+00019380: 7970 656e 616d 6520 4461 7461 4d61 7070  ypename DataMapp
+00019390: 6572 3a3a 4c69 6e65 6172 4d61 7070 6572  er::LinearMapper
+000193a0: 204c 696e 6561 724d 6170 7065 723b 0a20   LinearMapper;. 
+000193b0: 2065 6e75 6d20 7b20 5061 636b 6574 5369   enum { PacketSi
+000193c0: 7a65 203d 2070 6163 6b65 745f 7472 6169  ze = packet_trai
+000193d0: 7473 3c53 6361 6c61 723e 3a3a 7369 7a65  ts<Scalar>::size
+000193e0: 2c0a 2020 2020 2020 2020 2048 616c 6650  ,.         HalfP
+000193f0: 6163 6b65 7453 697a 6520 3d20 756e 7061  acketSize = unpa
+00019400: 636b 6574 5f74 7261 6974 733c 4861 6c66  cket_traits<Half
+00019410: 5061 636b 6574 3e3a 3a73 697a 652c 0a09  Packet>::size,..
+00019420: 0920 5175 6172 7465 7250 6163 6b65 7453  . QuarterPacketS
+00019430: 697a 6520 3d20 756e 7061 636b 6574 5f74  ize = unpacket_t
+00019440: 7261 6974 733c 5175 6172 7465 7250 6163  raits<QuarterPac
+00019450: 6b65 743e 3a3a 7369 7a65 7d3b 0a20 2045  ket>::size};.  E
+00019460: 4947 454e 5f44 4f4e 545f 494e 4c49 4e45  IGEN_DONT_INLINE
+00019470: 2076 6f69 6420 6f70 6572 6174 6f72 2829   void operator()
+00019480: 2853 6361 6c61 722a 2062 6c6f 636b 422c  (Scalar* blockB,
+00019490: 2063 6f6e 7374 2044 6174 614d 6170 7065   const DataMappe
+000194a0: 7226 2072 6873 2c20 496e 6465 7820 6465  r& rhs, Index de
+000194b0: 7074 682c 2049 6e64 6578 2063 6f6c 732c  pth, Index cols,
+000194c0: 2049 6e64 6578 2073 7472 6964 653d 302c   Index stride=0,
+000194d0: 2049 6e64 6578 206f 6666 7365 743d 3029   Index offset=0)
+000194e0: 0a20 207b 0a20 2020 2045 4947 454e 5f41  .  {.    EIGEN_A
+000194f0: 534d 5f43 4f4d 4d45 4e54 2822 4549 4745  SM_COMMENT("EIGE
+00019500: 4e20 5052 4f44 5543 5420 5041 434b 2052  N PRODUCT PACK R
+00019510: 4853 2052 4f57 4d41 4a4f 5222 293b 0a20  HS ROWMAJOR");. 
+00019520: 2020 2045 4947 454e 5f55 4e55 5345 445f     EIGEN_UNUSED_
+00019530: 5641 5249 4142 4c45 2873 7472 6964 6529  VARIABLE(stride)
+00019540: 3b0a 2020 2020 4549 4745 4e5f 554e 5553  ;.    EIGEN_UNUS
+00019550: 4544 5f56 4152 4941 424c 4528 6f66 6673  ED_VARIABLE(offs
+00019560: 6574 293b 0a20 2020 2065 6967 656e 5f61  et);.    eigen_a
+00019570: 7373 6572 7428 2828 2150 616e 656c 4d6f  ssert(((!PanelMo
+00019580: 6465 2920 2626 2073 7472 6964 653d 3d30  de) && stride==0
+00019590: 2026 2620 6f66 6673 6574 3d3d 3029 207c   && offset==0) |
+000195a0: 7c20 2850 616e 656c 4d6f 6465 2026 2620  | (PanelMode && 
+000195b0: 7374 7269 6465 3e3d 6465 7074 6820 2626  stride>=depth &&
+000195c0: 206f 6666 7365 743c 3d73 7472 6964 6529   offset<=stride)
+000195d0: 293b 0a20 2020 2063 6f6e 7374 2062 6f6f  );.    const boo
+000195e0: 6c20 4861 7348 616c 6620 3d20 2869 6e74  l HasHalf = (int
+000195f0: 2948 616c 6650 6163 6b65 7453 697a 6520  )HalfPacketSize 
+00019600: 3c20 2869 6e74 2950 6163 6b65 7453 697a  < (int)PacketSiz
+00019610: 653b 0a20 2020 2063 6f6e 7374 2062 6f6f  e;.    const boo
+00019620: 6c20 4861 7351 7561 7274 6572 203d 2028  l HasQuarter = (
+00019630: 696e 7429 5175 6172 7465 7250 6163 6b65  int)QuarterPacke
+00019640: 7453 697a 6520 3c20 2869 6e74 2948 616c  tSize < (int)Hal
+00019650: 6650 6163 6b65 7453 697a 653b 0a20 2020  fPacketSize;.   
+00019660: 2063 6f6e 6a5f 6966 3c4e 756d 5472 6169   conj_if<NumTrai
+00019670: 7473 3c53 6361 6c61 723e 3a3a 4973 436f  ts<Scalar>::IsCo
+00019680: 6d70 6c65 7820 2626 2043 6f6e 6a75 6761  mplex && Conjuga
+00019690: 7465 3e20 636a 3b0a 2020 2020 496e 6465  te> cj;.    Inde
+000196a0: 7820 7061 636b 6574 5f63 6f6c 7338 203d  x packet_cols8 =
+000196b0: 206e 723e 3d38 203f 2028 636f 6c73 2f38   nr>=8 ? (cols/8
+000196c0: 2920 2a20 3820 3a20 303b 0a20 2020 2049  ) * 8 : 0;.    I
+000196d0: 6e64 6578 2070 6163 6b65 745f 636f 6c73  ndex packet_cols
+000196e0: 3420 3d20 6e72 3e3d 3420 3f20 2863 6f6c  4 = nr>=4 ? (col
+000196f0: 732f 3429 202a 2034 203a 2030 3b0a 2020  s/4) * 4 : 0;.  
+00019700: 2020 496e 6465 7820 636f 756e 7420 3d20    Index count = 
+00019710: 303b 0a0a 2020 2f2f 2020 2069 6628 6e72  0;..  //   if(nr
+00019720: 3e3d 3829 0a20 202f 2f20 2020 7b0a 2020  >=8).  //   {.  
+00019730: 2f2f 2020 2020 2066 6f72 2849 6e64 6578  //     for(Index
+00019740: 206a 323d 303b 206a 323c 7061 636b 6574   j2=0; j2<packet
+00019750: 5f63 6f6c 7338 3b20 6a32 2b3d 3829 0a20  _cols8; j2+=8). 
+00019760: 202f 2f20 2020 2020 7b0a 2020 2f2f 2020   //     {.  //  
+00019770: 2020 2020 202f 2f20 736b 6970 2077 6861       // skip wha
+00019780: 7420 7765 2068 6176 6520 6265 666f 7265  t we have before
+00019790: 0a20 202f 2f20 2020 2020 2020 6966 2850  .  //       if(P
+000197a0: 616e 656c 4d6f 6465 2920 636f 756e 7420  anelMode) count 
+000197b0: 2b3d 2038 202a 206f 6666 7365 743b 0a20  += 8 * offset;. 
+000197c0: 202f 2f20 2020 2020 2020 666f 7228 496e   //       for(In
+000197d0: 6465 7820 6b3d 303b 206b 3c64 6570 7468  dex k=0; k<depth
+000197e0: 3b20 6b2b 2b29 0a20 202f 2f20 2020 2020  ; k++).  //     
+000197f0: 2020 7b0a 2020 2f2f 2020 2020 2020 2020    {.  //        
+00019800: 2069 6620 2850 6163 6b65 7453 697a 653d   if (PacketSize=
+00019810: 3d38 2920 7b0a 2020 2f2f 2020 2020 2020  =8) {.  //      
+00019820: 2020 2020 2050 6163 6b65 7420 4120 3d20       Packet A = 
+00019830: 706c 6f61 6475 3c50 6163 6b65 743e 2826  ploadu<Packet>(&
+00019840: 7268 735b 6b2a 7268 7353 7472 6964 6520  rhs[k*rhsStride 
+00019850: 2b20 6a32 5d29 3b0a 2020 2f2f 2020 2020  + j2]);.  //    
+00019860: 2020 2020 2020 2070 7374 6f72 6575 2862         pstoreu(b
+00019870: 6c6f 636b 422b 636f 756e 742c 2063 6a2e  lockB+count, cj.
+00019880: 7063 6f6e 6a28 4129 293b 0a20 202f 2f20  pconj(A));.  // 
+00019890: 2020 2020 2020 2020 7d20 656c 7365 2069          } else i
+000198a0: 6620 2850 6163 6b65 7453 697a 653d 3d34  f (PacketSize==4
+000198b0: 2920 7b0a 2020 2f2f 2020 2020 2020 2020  ) {.  //        
+000198c0: 2020 2050 6163 6b65 7420 4120 3d20 706c     Packet A = pl
+000198d0: 6f61 6475 3c50 6163 6b65 743e 2826 7268  oadu<Packet>(&rh
+000198e0: 735b 6b2a 7268 7353 7472 6964 6520 2b20  s[k*rhsStride + 
+000198f0: 6a32 5d29 3b0a 2020 2f2f 2020 2020 2020  j2]);.  //      
+00019900: 2020 2020 2050 6163 6b65 7420 4220 3d20       Packet B = 
+00019910: 706c 6f61 6475 3c50 6163 6b65 743e 2826  ploadu<Packet>(&
+00019920: 7268 735b 6b2a 7268 7353 7472 6964 6520  rhs[k*rhsStride 
+00019930: 2b20 6a32 202b 2050 6163 6b65 7453 697a  + j2 + PacketSiz
+00019940: 655d 293b 0a20 202f 2f20 2020 2020 2020  e]);.  //       
+00019950: 2020 2020 7073 746f 7265 7528 626c 6f63      pstoreu(bloc
+00019960: 6b42 2b63 6f75 6e74 2c20 636a 2e70 636f  kB+count, cj.pco
+00019970: 6e6a 2841 2929 3b0a 2020 2f2f 2020 2020  nj(A));.  //    
+00019980: 2020 2020 2020 2070 7374 6f72 6575 2862         pstoreu(b
+00019990: 6c6f 636b 422b 636f 756e 742b 5061 636b  lockB+count+Pack
+000199a0: 6574 5369 7a65 2c20 636a 2e70 636f 6e6a  etSize, cj.pconj
+000199b0: 2842 2929 3b0a 2020 2f2f 2020 2020 2020  (B));.  //      
+000199c0: 2020 207d 2065 6c73 6520 7b0a 2020 2f2f     } else {.  //
+000199d0: 2020 2020 2020 2020 2020 2063 6f6e 7374             const
+000199e0: 2053 6361 6c61 722a 2062 3020 3d20 2672   Scalar* b0 = &r
+000199f0: 6873 5b6b 2a72 6873 5374 7269 6465 202b  hs[k*rhsStride +
+00019a00: 206a 325d 3b0a 2020 2f2f 2020 2020 2020   j2];.  //      
+00019a10: 2020 2020 2062 6c6f 636b 425b 636f 756e       blockB[coun
+00019a20: 742b 305d 203d 2063 6a28 6230 5b30 5d29  t+0] = cj(b0[0])
+00019a30: 3b0a 2020 2f2f 2020 2020 2020 2020 2020  ;.  //          
+00019a40: 2062 6c6f 636b 425b 636f 756e 742b 315d   blockB[count+1]
+00019a50: 203d 2063 6a28 6230 5b31 5d29 3b0a 2020   = cj(b0[1]);.  
+00019a60: 2f2f 2020 2020 2020 2020 2020 2062 6c6f  //           blo
+00019a70: 636b 425b 636f 756e 742b 325d 203d 2063  ckB[count+2] = c
+00019a80: 6a28 6230 5b32 5d29 3b0a 2020 2f2f 2020  j(b0[2]);.  //  
+00019a90: 2020 2020 2020 2020 2062 6c6f 636b 425b           blockB[
+00019aa0: 636f 756e 742b 335d 203d 2063 6a28 6230  count+3] = cj(b0
+00019ab0: 5b33 5d29 3b0a 2020 2f2f 2020 2020 2020  [3]);.  //      
+00019ac0: 2020 2020 2062 6c6f 636b 425b 636f 756e       blockB[coun
+00019ad0: 742b 345d 203d 2063 6a28 6230 5b34 5d29  t+4] = cj(b0[4])
+00019ae0: 3b0a 2020 2f2f 2020 2020 2020 2020 2020  ;.  //          
+00019af0: 2062 6c6f 636b 425b 636f 756e 742b 355d   blockB[count+5]
+00019b00: 203d 2063 6a28 6230 5b35 5d29 3b0a 2020   = cj(b0[5]);.  
+00019b10: 2f2f 2020 2020 2020 2020 2020 2062 6c6f  //           blo
+00019b20: 636b 425b 636f 756e 742b 365d 203d 2063  ckB[count+6] = c
+00019b30: 6a28 6230 5b36 5d29 3b0a 2020 2f2f 2020  j(b0[6]);.  //  
+00019b40: 2020 2020 2020 2020 2062 6c6f 636b 425b           blockB[
+00019b50: 636f 756e 742b 375d 203d 2063 6a28 6230  count+7] = cj(b0
+00019b60: 5b37 5d29 3b0a 2020 2f2f 2020 2020 2020  [7]);.  //      
+00019b70: 2020 207d 0a20 202f 2f20 2020 2020 2020     }.  //       
+00019b80: 2020 636f 756e 7420 2b3d 2038 3b0a 2020    count += 8;.  
+00019b90: 2f2f 2020 2020 2020 207d 0a20 202f 2f20  //       }.  // 
+00019ba0: 2020 2020 2020 2f2f 2073 6b69 7020 7768        // skip wh
+00019bb0: 6174 2077 6520 6861 7665 2061 6674 6572  at we have after
+00019bc0: 0a20 202f 2f20 2020 2020 2020 6966 2850  .  //       if(P
+00019bd0: 616e 656c 4d6f 6465 2920 636f 756e 7420  anelMode) count 
+00019be0: 2b3d 2038 202a 2028 7374 7269 6465 2d6f  += 8 * (stride-o
+00019bf0: 6666 7365 742d 6465 7074 6829 3b0a 2020  ffset-depth);.  
+00019c00: 2f2f 2020 2020 207d 0a20 202f 2f20 2020  //     }.  //   
+00019c10: 7d0a 2020 2020 6966 286e 723e 3d34 290a  }.    if(nr>=4).
+00019c20: 2020 2020 7b0a 2020 2020 2020 666f 7228      {.      for(
+00019c30: 496e 6465 7820 6a32 3d70 6163 6b65 745f  Index j2=packet_
+00019c40: 636f 6c73 383b 206a 323c 7061 636b 6574  cols8; j2<packet
+00019c50: 5f63 6f6c 7334 3b20 6a32 2b3d 3429 0a20  _cols4; j2+=4). 
+00019c60: 2020 2020 207b 0a20 2020 2020 2020 202f       {.        /
+00019c70: 2f20 736b 6970 2077 6861 7420 7765 2068  / skip what we h
+00019c80: 6176 6520 6265 666f 7265 0a20 2020 2020  ave before.     
+00019c90: 2020 2069 6628 5061 6e65 6c4d 6f64 6529     if(PanelMode)
+00019ca0: 2063 6f75 6e74 202b 3d20 3420 2a20 6f66   count += 4 * of
+00019cb0: 6673 6574 3b0a 2020 2020 2020 2020 666f  fset;.        fo
+00019cc0: 7228 496e 6465 7820 6b3d 303b 206b 3c64  r(Index k=0; k<d
+00019cd0: 6570 7468 3b20 6b2b 2b29 0a20 2020 2020  epth; k++).     
+00019ce0: 2020 207b 0a20 2020 2020 2020 2020 2069     {.          i
+00019cf0: 6620 2850 6163 6b65 7453 697a 653d 3d34  f (PacketSize==4
+00019d00: 2920 7b0a 2020 2020 2020 2020 2020 2020  ) {.            
+00019d10: 5061 636b 6574 2041 203d 2072 6873 2e74  Packet A = rhs.t
+00019d20: 656d 706c 6174 6520 6c6f 6164 5061 636b  emplate loadPack
+00019d30: 6574 3c50 6163 6b65 743e 286b 2c20 6a32  et<Packet>(k, j2
+00019d40: 293b 0a20 2020 2020 2020 2020 2020 2070  );.            p
+00019d50: 7374 6f72 6575 2862 6c6f 636b 422b 636f  storeu(blockB+co
+00019d60: 756e 742c 2063 6a2e 7063 6f6e 6a28 4129  unt, cj.pconj(A)
+00019d70: 293b 0a20 2020 2020 2020 2020 2020 2063  );.            c
+00019d80: 6f75 6e74 202b 3d20 5061 636b 6574 5369  ount += PacketSi
+00019d90: 7a65 3b0a 2020 2020 2020 2020 2020 7d20  ze;.          } 
+00019da0: 656c 7365 2069 6620 2848 6173 4861 6c66  else if (HasHalf
+00019db0: 2026 2620 4861 6c66 5061 636b 6574 5369   && HalfPacketSi
+00019dc0: 7a65 3d3d 3429 207b 0a20 2020 2020 2020  ze==4) {.       
+00019dd0: 2020 2020 2048 616c 6650 6163 6b65 7420       HalfPacket 
+00019de0: 4120 3d20 7268 732e 7465 6d70 6c61 7465  A = rhs.template
+00019df0: 206c 6f61 6450 6163 6b65 743c 4861 6c66   loadPacket<Half
+00019e00: 5061 636b 6574 3e28 6b2c 206a 3229 3b0a  Packet>(k, j2);.
+00019e10: 2020 2020 2020 2020 2020 2020 7073 746f              psto
+00019e20: 7265 7528 626c 6f63 6b42 2b63 6f75 6e74  reu(blockB+count
+00019e30: 2c20 636a 2e70 636f 6e6a 2841 2929 3b0a  , cj.pconj(A));.
+00019e40: 2020 2020 2020 2020 2020 2020 636f 756e              coun
+00019e50: 7420 2b3d 2048 616c 6650 6163 6b65 7453  t += HalfPacketS
+00019e60: 697a 653b 0a20 2020 2020 2020 2020 207d  ize;.          }
+00019e70: 2065 6c73 6520 6966 2028 4861 7351 7561   else if (HasQua
+00019e80: 7274 6572 2026 2620 5175 6172 7465 7250  rter && QuarterP
+00019e90: 6163 6b65 7453 697a 653d 3d34 2920 7b0a  acketSize==4) {.
+00019ea0: 2020 2020 2020 2020 2020 2020 5175 6172              Quar
+00019eb0: 7465 7250 6163 6b65 7420 4120 3d20 7268  terPacket A = rh
+00019ec0: 732e 7465 6d70 6c61 7465 206c 6f61 6450  s.template loadP
+00019ed0: 6163 6b65 743c 5175 6172 7465 7250 6163  acket<QuarterPac
+00019ee0: 6b65 743e 286b 2c20 6a32 293b 0a20 2020  ket>(k, j2);.   
+00019ef0: 2020 2020 2020 2020 2070 7374 6f72 6575           pstoreu
+00019f00: 2862 6c6f 636b 422b 636f 756e 742c 2063  (blockB+count, c
+00019f10: 6a2e 7063 6f6e 6a28 4129 293b 0a20 2020  j.pconj(A));.   
+00019f20: 2020 2020 2020 2020 2063 6f75 6e74 202b           count +
+00019f30: 3d20 5175 6172 7465 7250 6163 6b65 7453  = QuarterPacketS
+00019f40: 697a 653b 0a20 2020 2020 2020 2020 207d  ize;.          }
+00019f50: 2065 6c73 6520 7b0a 2020 2020 2020 2020   else {.        
+00019f60: 2020 2020 636f 6e73 7420 4c69 6e65 6172      const Linear
+00019f70: 4d61 7070 6572 2064 6d30 203d 2072 6873  Mapper dm0 = rhs
+00019f80: 2e67 6574 4c69 6e65 6172 4d61 7070 6572  .getLinearMapper
+00019f90: 286b 2c20 6a32 293b 0a20 2020 2020 2020  (k, j2);.       
+00019fa0: 2020 2020 2062 6c6f 636b 425b 636f 756e       blockB[coun
+00019fb0: 742b 305d 203d 2063 6a28 646d 3028 3029  t+0] = cj(dm0(0)
+00019fc0: 293b 0a20 2020 2020 2020 2020 2020 2062  );.            b
+00019fd0: 6c6f 636b 425b 636f 756e 742b 315d 203d  lockB[count+1] =
+00019fe0: 2063 6a28 646d 3028 3129 293b 0a20 2020   cj(dm0(1));.   
+00019ff0: 2020 2020 2020 2020 2062 6c6f 636b 425b           blockB[
+0001a000: 636f 756e 742b 325d 203d 2063 6a28 646d  count+2] = cj(dm
+0001a010: 3028 3229 293b 0a20 2020 2020 2020 2020  0(2));.         
+0001a020: 2020 2062 6c6f 636b 425b 636f 756e 742b     blockB[count+
+0001a030: 335d 203d 2063 6a28 646d 3028 3329 293b  3] = cj(dm0(3));
+0001a040: 0a20 2020 2020 2020 2020 2020 2063 6f75  .            cou
+0001a050: 6e74 202b 3d20 343b 0a20 2020 2020 2020  nt += 4;.       
+0001a060: 2020 207d 0a20 2020 2020 2020 207d 0a20     }.        }. 
+0001a070: 2020 2020 2020 202f 2f20 736b 6970 2077         // skip w
+0001a080: 6861 7420 7765 2068 6176 6520 6166 7465  hat we have afte
+0001a090: 720a 2020 2020 2020 2020 6966 2850 616e  r.        if(Pan
+0001a0a0: 656c 4d6f 6465 2920 636f 756e 7420 2b3d  elMode) count +=
+0001a0b0: 2034 202a 2028 7374 7269 6465 2d6f 6666   4 * (stride-off
+0001a0c0: 7365 742d 6465 7074 6829 3b0a 2020 2020  set-depth);.    
+0001a0d0: 2020 7d0a 2020 2020 7d0a 2020 2020 2f2f    }.    }.    //
+0001a0e0: 2063 6f70 7920 7468 6520 7265 6d61 696e   copy the remain
+0001a0f0: 696e 6720 636f 6c75 6d6e 7320 6f6e 6520  ing columns one 
+0001a100: 6174 2061 2074 696d 6520 286e 723d 3d31  at a time (nr==1
+0001a110: 290a 2020 2020 666f 7228 496e 6465 7820  ).    for(Index 
+0001a120: 6a32 3d70 6163 6b65 745f 636f 6c73 343b  j2=packet_cols4;
+0001a130: 206a 323c 636f 6c73 3b20 2b2b 6a32 290a   j2<cols; ++j2).
+0001a140: 2020 2020 7b0a 2020 2020 2020 6966 2850      {.      if(P
+0001a150: 616e 656c 4d6f 6465 2920 636f 756e 7420  anelMode) count 
+0001a160: 2b3d 206f 6666 7365 743b 0a20 2020 2020  += offset;.     
+0001a170: 2066 6f72 2849 6e64 6578 206b 3d30 3b20   for(Index k=0; 
+0001a180: 6b3c 6465 7074 683b 206b 2b2b 290a 2020  k<depth; k++).  
+0001a190: 2020 2020 7b0a 2020 2020 2020 2020 626c      {.        bl
+0001a1a0: 6f63 6b42 5b63 6f75 6e74 5d20 3d20 636a  ockB[count] = cj
+0001a1b0: 2872 6873 286b 2c20 6a32 2929 3b0a 2020  (rhs(k, j2));.  
+0001a1c0: 2020 2020 2020 636f 756e 7420 2b3d 2031        count += 1
+0001a1d0: 3b0a 2020 2020 2020 7d0a 2020 2020 2020  ;.      }.      
+0001a1e0: 6966 2850 616e 656c 4d6f 6465 2920 636f  if(PanelMode) co
+0001a1f0: 756e 7420 2b3d 2073 7472 6964 652d 6f66  unt += stride-of
+0001a200: 6673 6574 2d64 6570 7468 3b0a 2020 2020  fset-depth;.    
+0001a210: 7d0a 2020 7d0a 7d3b 0a0a 7d20 2f2f 2065  }.  }.};..} // e
+0001a220: 6e64 206e 616d 6573 7061 6365 2069 6e74  nd namespace int
+0001a230: 6572 6e61 6c0a 0a2f 2a2a 205c 7265 7475  ernal../** \retu
+0001a240: 726e 7320 7468 6520 6375 7272 656e 746c  rns the currentl
+0001a250: 7920 7365 7420 6c65 7665 6c20 3120 6370  y set level 1 cp
+0001a260: 7520 6361 6368 6520 7369 7a65 2028 696e  u cache size (in
+0001a270: 2062 7974 6573 2920 7573 6564 2074 6f20   bytes) used to 
+0001a280: 6573 7469 6d61 7465 2074 6865 2069 6465  estimate the ide
+0001a290: 616c 2062 6c6f 636b 696e 6720 7369 7a65  al blocking size
+0001a2a0: 2070 6172 616d 6574 6572 732e 0a20 202a   parameters..  *
+0001a2b0: 205c 7361 2073 6574 4370 7543 6163 6865   \sa setCpuCache
+0001a2c0: 5369 7a65 202a 2f0a 696e 6c69 6e65 2073  Size */.inline s
+0001a2d0: 7464 3a3a 7074 7264 6966 665f 7420 6c31  td::ptrdiff_t l1
+0001a2e0: 4361 6368 6553 697a 6528 290a 7b0a 2020  CacheSize().{.  
+0001a2f0: 7374 643a 3a70 7472 6469 6666 5f74 206c  std::ptrdiff_t l
+0001a300: 312c 206c 322c 206c 333b 0a20 2069 6e74  1, l2, l3;.  int
+0001a310: 6572 6e61 6c3a 3a6d 616e 6167 655f 6361  ernal::manage_ca
+0001a320: 6368 696e 675f 7369 7a65 7328 4765 7441  ching_sizes(GetA
+0001a330: 6374 696f 6e2c 2026 6c31 2c20 266c 322c  ction, &l1, &l2,
+0001a340: 2026 6c33 293b 0a20 2072 6574 7572 6e20   &l3);.  return 
+0001a350: 6c31 3b0a 7d0a 0a2f 2a2a 205c 7265 7475  l1;.}../** \retu
+0001a360: 726e 7320 7468 6520 6375 7272 656e 746c  rns the currentl
+0001a370: 7920 7365 7420 6c65 7665 6c20 3220 6370  y set level 2 cp
+0001a380: 7520 6361 6368 6520 7369 7a65 2028 696e  u cache size (in
+0001a390: 2062 7974 6573 2920 7573 6564 2074 6f20   bytes) used to 
+0001a3a0: 6573 7469 6d61 7465 2074 6865 2069 6465  estimate the ide
+0001a3b0: 616c 2062 6c6f 636b 696e 6720 7369 7a65  al blocking size
+0001a3c0: 2070 6172 616d 6574 6572 732e 0a20 202a   parameters..  *
+0001a3d0: 205c 7361 2073 6574 4370 7543 6163 6865   \sa setCpuCache
+0001a3e0: 5369 7a65 202a 2f0a 696e 6c69 6e65 2073  Size */.inline s
+0001a3f0: 7464 3a3a 7074 7264 6966 665f 7420 6c32  td::ptrdiff_t l2
+0001a400: 4361 6368 6553 697a 6528 290a 7b0a 2020  CacheSize().{.  
+0001a410: 7374 643a 3a70 7472 6469 6666 5f74 206c  std::ptrdiff_t l
+0001a420: 312c 206c 322c 206c 333b 0a20 2069 6e74  1, l2, l3;.  int
+0001a430: 6572 6e61 6c3a 3a6d 616e 6167 655f 6361  ernal::manage_ca
+0001a440: 6368 696e 675f 7369 7a65 7328 4765 7441  ching_sizes(GetA
+0001a450: 6374 696f 6e2c 2026 6c31 2c20 266c 322c  ction, &l1, &l2,
+0001a460: 2026 6c33 293b 0a20 2072 6574 7572 6e20   &l3);.  return 
+0001a470: 6c32 3b0a 7d0a 0a2f 2a2a 205c 7265 7475  l2;.}../** \retu
+0001a480: 726e 7320 7468 6520 6375 7272 656e 746c  rns the currentl
+0001a490: 7920 7365 7420 6c65 7665 6c20 3320 6370  y set level 3 cp
+0001a4a0: 7520 6361 6368 6520 7369 7a65 2028 696e  u cache size (in
+0001a4b0: 2062 7974 6573 2920 7573 6564 2074 6f20   bytes) used to 
+0001a4c0: 6573 7469 6d61 7465 2074 6865 2069 6465  estimate the ide
+0001a4d0: 616c 2062 6c6f 636b 696e 6720 7369 7a65  al blocking size
+0001a4e0: 2070 6172 616d 6574 655c 0a72 732e 2020   paramete\.rs.  
+0001a4f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a500: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a510: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a520: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a530: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a540: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a550: 2020 2020 2020 2020 2020 2020 2020 0a2a                .*
+0001a560: 205c 7361 2073 6574 4370 7543 6163 6865   \sa setCpuCache
+0001a570: 5369 7a65 202a 2f0a 696e 6c69 6e65 2073  Size */.inline s
+0001a580: 7464 3a3a 7074 7264 6966 665f 7420 6c33  td::ptrdiff_t l3
+0001a590: 4361 6368 6553 697a 6528 290a 7b0a 2020  CacheSize().{.  
+0001a5a0: 7374 643a 3a70 7472 6469 6666 5f74 206c  std::ptrdiff_t l
+0001a5b0: 312c 206c 322c 206c 333b 0a20 2069 6e74  1, l2, l3;.  int
+0001a5c0: 6572 6e61 6c3a 3a6d 616e 6167 655f 6361  ernal::manage_ca
+0001a5d0: 6368 696e 675f 7369 7a65 7328 4765 7441  ching_sizes(GetA
+0001a5e0: 6374 696f 6e2c 2026 6c31 2c20 266c 322c  ction, &l1, &l2,
+0001a5f0: 2026 6c33 293b 0a20 2072 6574 7572 6e20   &l3);.  return 
+0001a600: 6c33 3b0a 7d0a 0a2f 2a2a 2053 6574 2074  l3;.}../** Set t
+0001a610: 6865 2063 7075 204c 3120 616e 6420 4c32  he cpu L1 and L2
+0001a620: 2063 6163 6865 2073 697a 6573 2028 696e   cache sizes (in
+0001a630: 2062 7974 6573 292e 0a20 202a 2054 6865   bytes)..  * The
+0001a640: 7365 2076 616c 7565 7320 6172 6520 7573  se values are us
+0001a650: 6520 746f 2061 646a 7573 7420 7468 6520  e to adjust the 
+0001a660: 7369 7a65 206f 6620 7468 6520 626c 6f63  size of the bloc
+0001a670: 6b73 0a20 202a 2066 6f72 2074 6865 2061  ks.  * for the a
+0001a680: 6c67 6f72 6974 686d 7320 776f 726b 696e  lgorithms workin
+0001a690: 6720 7065 7220 626c 6f63 6b73 2e0a 2020  g per blocks..  
+0001a6a0: 2a0a 2020 2a20 5c73 6120 636f 6d70 7574  *.  * \sa comput
+0001a6b0: 6550 726f 6475 6374 426c 6f63 6b69 6e67  eProductBlocking
+0001a6c0: 5369 7a65 7320 2a2f 0a69 6e6c 696e 6520  Sizes */.inline 
+0001a6d0: 766f 6964 2073 6574 4370 7543 6163 6865  void setCpuCache
+0001a6e0: 5369 7a65 7328 7374 643a 3a70 7472 6469  Sizes(std::ptrdi
+0001a6f0: 6666 5f74 206c 312c 2073 7464 3a3a 7074  ff_t l1, std::pt
+0001a700: 7264 6966 665f 7420 6c32 2c20 7374 643a  rdiff_t l2, std:
+0001a710: 3a70 7472 6469 6666 5f74 206c 3329 0a7b  :ptrdiff_t l3).{
+0001a720: 0a20 2069 6e74 6572 6e61 6c3a 3a6d 616e  .  internal::man
+0001a730: 6167 655f 6361 6368 696e 675f 7369 7a65  age_caching_size
+0001a740: 7328 5365 7441 6374 696f 6e2c 2026 6c31  s(SetAction, &l1
+0001a750: 2c20 266c 322c 2026 6c33 293b 0a7d 0a0a  , &l2, &l3);.}..
+0001a760: 7d20 2f2f 2065 6e64 206e 616d 6573 7061  } // end namespa
+0001a770: 6365 2045 6967 656e 0a0a 2365 6e64 6966  ce Eigen..#endif
+0001a780: 202f 2f20 4549 4745 4e5f 4745 4e45 5241   // EIGEN_GENERA
+0001a790: 4c5f 424c 4f43 4b5f 5041 4e45 4c5f 480a  L_BLOCK_PANEL_H.
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/products/GeneralMatrixMatrix.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/products/GeneralMatrixMatrix.h`

 * *Files 0% similar despite different names*

```diff
@@ -467,33 +467,33 @@
   template<typename Dest>
   static void scaleAndAddTo(Dest& dst, const Lhs& a_lhs, const Rhs& a_rhs, const Scalar& alpha)
   {
     eigen_assert(dst.rows()==a_lhs.rows() && dst.cols()==a_rhs.cols());
     if(a_lhs.cols()==0 || a_lhs.rows()==0 || a_rhs.cols()==0)
       return;
 
-    // Fallback to GEMV if either the lhs or rhs is a runtime vector
     if (dst.cols() == 1)
     {
+      // Fallback to GEMV if either the lhs or rhs is a runtime vector
       typename Dest::ColXpr dst_vec(dst.col(0));
       return internal::generic_product_impl<Lhs,typename Rhs::ConstColXpr,DenseShape,DenseShape,GemvProduct>
         ::scaleAndAddTo(dst_vec, a_lhs, a_rhs.col(0), alpha);
     }
     else if (dst.rows() == 1)
     {
+      // Fallback to GEMV if either the lhs or rhs is a runtime vector
       typename Dest::RowXpr dst_vec(dst.row(0));
       return internal::generic_product_impl<typename Lhs::ConstRowXpr,Rhs,DenseShape,DenseShape,GemvProduct>
         ::scaleAndAddTo(dst_vec, a_lhs.row(0), a_rhs, alpha);
     }
 
     typename internal::add_const_on_value_type<ActualLhsType>::type lhs = LhsBlasTraits::extract(a_lhs);
     typename internal::add_const_on_value_type<ActualRhsType>::type rhs = RhsBlasTraits::extract(a_rhs);
 
-    Scalar actualAlpha = alpha * LhsBlasTraits::extractScalarFactor(a_lhs)
-                               * RhsBlasTraits::extractScalarFactor(a_rhs);
+    Scalar actualAlpha = combine_scalar_factors(alpha, a_lhs, a_rhs);
 
     typedef internal::gemm_blocking_space<(Dest::Flags&RowMajorBit) ? RowMajor : ColMajor,LhsScalar,RhsScalar,
             Dest::MaxRowsAtCompileTime,Dest::MaxColsAtCompileTime,MaxDepthAtCompileTime> BlockingType;
 
     typedef internal::gemm_functor<
       Scalar, Index,
       internal::general_matrix_matrix_product<
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/products/GeneralMatrixMatrixTriangular.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/products/GeneralMatrixMatrixTriangular.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/products/GeneralMatrixMatrixTriangular_BLAS.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/products/GeneralMatrixMatrixTriangular_BLAS.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/products/GeneralMatrixMatrix_BLAS.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/products/GeneralMatrixMatrix_BLAS.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/products/GeneralMatrixVector.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/products/GeneralMatrixVector.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/products/GeneralMatrixVector_BLAS.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/products/GeneralMatrixVector_BLAS.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/products/Parallelizer.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/products/Parallelizer.h`

 * *Files 1% similar despite different names*

```diff
@@ -18,15 +18,15 @@
 
 namespace internal {
 
 /** \internal */
 inline void manage_multi_threading(Action action, int* v)
 {
   static int m_maxThreads = -1;
-  EIGEN_UNUSED_VARIABLE(m_maxThreads);
+  EIGEN_UNUSED_VARIABLE(m_maxThreads)
 
   if(action==SetAction)
   {
     eigen_internal_assert(v!=0);
     m_maxThreads = *v;
   }
   else if(action==GetAction)
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/products/SelfadjointMatrixMatrix.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/products/SelfadjointMatrixMatrix.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/products/SelfadjointMatrixMatrix_BLAS.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/products/SelfadjointMatrixMatrix_BLAS.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/products/SelfadjointMatrixVector.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/products/SelfadjointMatrixVector.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/products/SelfadjointMatrixVector_BLAS.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/products/SelfadjointMatrixVector_BLAS.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/products/SelfadjointProduct.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/products/SelfadjointProduct.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/products/SelfadjointRank2Update.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/products/SelfadjointRank2Update.h`

 * *Files 3% similar despite different names*

```diff
@@ -76,16 +76,16 @@
 
   enum { IsRowMajor = (internal::traits<MatrixType>::Flags&RowMajorBit) ? 1 : 0 };
   Scalar actualAlpha = alpha * UBlasTraits::extractScalarFactor(u.derived())
                              * numext::conj(VBlasTraits::extractScalarFactor(v.derived()));
   if (IsRowMajor)
     actualAlpha = numext::conj(actualAlpha);
 
-  typedef typename internal::remove_all<typename internal::conj_expr_if<IsRowMajor ^ UBlasTraits::NeedToConjugate,_ActualUType>::type>::type UType;
-  typedef typename internal::remove_all<typename internal::conj_expr_if<IsRowMajor ^ VBlasTraits::NeedToConjugate,_ActualVType>::type>::type VType;
+  typedef typename internal::remove_all<typename internal::conj_expr_if<int(IsRowMajor) ^ int(UBlasTraits::NeedToConjugate), _ActualUType>::type>::type UType;
+  typedef typename internal::remove_all<typename internal::conj_expr_if<int(IsRowMajor) ^ int(VBlasTraits::NeedToConjugate), _ActualVType>::type>::type VType;
   internal::selfadjoint_rank2_update_selector<Scalar, Index, UType, VType,
     (IsRowMajor ? int(UpLo==Upper ? Lower : Upper) : UpLo)>
     ::run(_expression().const_cast_derived().data(),_expression().outerStride(),UType(actualU),VType(actualV),actualAlpha);
 
   return *this;
 }
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/products/TriangularMatrixMatrix.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/products/TriangularMatrixMatrix.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/products/TriangularMatrixMatrix_BLAS.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/products/TriangularMatrixMatrix_BLAS.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/products/TriangularMatrixVector.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/products/TriangularMatrixVector.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/products/TriangularMatrixVector_BLAS.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/products/TriangularMatrixVector_BLAS.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/products/TriangularSolverMatrix.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/products/TriangularSolverMatrix.h`

 * *Files 1% similar despite different names*

```diff
@@ -132,15 +132,17 @@
                 for (Index i3=0; i3<k; ++i3)
                   b += conj(l[i3]) * r(i3);
 
                 other(i,j) = (other(i,j) - b)*a;
               }
               else
               {
-                Scalar b = (other(i,j) *= a);
+                Scalar& otherij = other(i,j);
+                otherij *= a;
+                Scalar b = otherij;
                 typename OtherMapper::LinearMapper r = other.getLinearMapper(s,j);
                 typename TriMapper::LinearMapper l = tri.getLinearMapper(s,i);
                 for (Index i3=0;i3<rs;++i3)
                   r(i3) -= b * conj(l(i3));
               }
             }
           }
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/products/TriangularSolverMatrix_BLAS.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/products/TriangularSolverMatrix_BLAS.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/products/TriangularSolverVector.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/products/TriangularSolverVector.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/util/BlasUtil.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/util/BlasUtil.h`

 * *Files 13% similar despite different names*

```diff
@@ -35,98 +35,14 @@
 struct general_matrix_matrix_product;
 
 template<typename Index,
          typename LhsScalar, typename LhsMapper, int LhsStorageOrder, bool ConjugateLhs,
          typename RhsScalar, typename RhsMapper, bool ConjugateRhs, int Version=Specialized>
 struct general_matrix_vector_product;
 
-
-template<bool Conjugate> struct conj_if;
-
-template<> struct conj_if<true> {
-  template<typename T>
-  inline T operator()(const T& x) const { return numext::conj(x); }
-  template<typename T>
-  inline T pconj(const T& x) const { return internal::pconj(x); }
-};
-
-template<> struct conj_if<false> {
-  template<typename T>
-  inline const T& operator()(const T& x) const { return x; }
-  template<typename T>
-  inline const T& pconj(const T& x) const { return x; }
-};
-
-// Generic implementation for custom complex types.
-template<typename LhsScalar, typename RhsScalar, bool ConjLhs, bool ConjRhs>
-struct conj_helper
-{
-  typedef typename ScalarBinaryOpTraits<LhsScalar,RhsScalar>::ReturnType Scalar;
-
-  EIGEN_STRONG_INLINE Scalar pmadd(const LhsScalar& x, const RhsScalar& y, const Scalar& c) const
-  { return padd(c, pmul(x,y)); }
-
-  EIGEN_STRONG_INLINE Scalar pmul(const LhsScalar& x, const RhsScalar& y) const
-  { return conj_if<ConjLhs>()(x) *  conj_if<ConjRhs>()(y); }
-};
-
-template<typename Scalar> struct conj_helper<Scalar,Scalar,false,false>
-{
-  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar pmadd(const Scalar& x, const Scalar& y, const Scalar& c) const { return internal::pmadd(x,y,c); }
-  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar pmul(const Scalar& x, const Scalar& y) const { return internal::pmul(x,y); }
-};
-
-template<typename RealScalar> struct conj_helper<std::complex<RealScalar>, std::complex<RealScalar>, false,true>
-{
-  typedef std::complex<RealScalar> Scalar;
-  EIGEN_STRONG_INLINE Scalar pmadd(const Scalar& x, const Scalar& y, const Scalar& c) const
-  { return c + pmul(x,y); }
-
-  EIGEN_STRONG_INLINE Scalar pmul(const Scalar& x, const Scalar& y) const
-  { return Scalar(numext::real(x)*numext::real(y) + numext::imag(x)*numext::imag(y), numext::imag(x)*numext::real(y) - numext::real(x)*numext::imag(y)); }
-};
-
-template<typename RealScalar> struct conj_helper<std::complex<RealScalar>, std::complex<RealScalar>, true,false>
-{
-  typedef std::complex<RealScalar> Scalar;
-  EIGEN_STRONG_INLINE Scalar pmadd(const Scalar& x, const Scalar& y, const Scalar& c) const
-  { return c + pmul(x,y); }
-
-  EIGEN_STRONG_INLINE Scalar pmul(const Scalar& x, const Scalar& y) const
-  { return Scalar(numext::real(x)*numext::real(y) + numext::imag(x)*numext::imag(y), numext::real(x)*numext::imag(y) - numext::imag(x)*numext::real(y)); }
-};
-
-template<typename RealScalar> struct conj_helper<std::complex<RealScalar>, std::complex<RealScalar>, true,true>
-{
-  typedef std::complex<RealScalar> Scalar;
-  EIGEN_STRONG_INLINE Scalar pmadd(const Scalar& x, const Scalar& y, const Scalar& c) const
-  { return c + pmul(x,y); }
-
-  EIGEN_STRONG_INLINE Scalar pmul(const Scalar& x, const Scalar& y) const
-  { return Scalar(numext::real(x)*numext::real(y) - numext::imag(x)*numext::imag(y), - numext::real(x)*numext::imag(y) - numext::imag(x)*numext::real(y)); }
-};
-
-template<typename RealScalar,bool Conj> struct conj_helper<std::complex<RealScalar>, RealScalar, Conj,false>
-{
-  typedef std::complex<RealScalar> Scalar;
-  EIGEN_STRONG_INLINE Scalar pmadd(const Scalar& x, const RealScalar& y, const Scalar& c) const
-  { return padd(c, pmul(x,y)); }
-  EIGEN_STRONG_INLINE Scalar pmul(const Scalar& x, const RealScalar& y) const
-  { return conj_if<Conj>()(x)*y; }
-};
-
-template<typename RealScalar,bool Conj> struct conj_helper<RealScalar, std::complex<RealScalar>, false,Conj>
-{
-  typedef std::complex<RealScalar> Scalar;
-  EIGEN_STRONG_INLINE Scalar pmadd(const RealScalar& x, const Scalar& y, const Scalar& c) const
-  { return padd(c, pmul(x,y)); }
-  EIGEN_STRONG_INLINE Scalar pmul(const RealScalar& x, const Scalar& y) const
-  { return x*conj_if<Conj>()(y); }
-};
-
 template<typename From,typename To> struct get_factor {
   EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE To run(const From& x) { return To(x); }
 };
 
 template<typename Scalar> struct get_factor<Scalar,typename NumTraits<Scalar>::Real> {
   EIGEN_DEVICE_FUNC
   static EIGEN_STRONG_INLINE typename NumTraits<Scalar>::Real run(const Scalar& x) { return numext::real(x); }
@@ -387,14 +303,85 @@
   }
 
   template<typename SubPacket>
   EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE SubPacket gatherPacket(Index i, Index j) const {
     return pgather<Scalar, SubPacket>(&operator()(i, j), m_stride);
   }
 
+  // storePacketBlock_helper defines a way to access values inside the PacketBlock, this is essentially required by the Complex types.
+  template<typename SubPacket, typename ScalarT, int n, int idx>
+  struct storePacketBlock_helper
+  {
+    storePacketBlock_helper<SubPacket, ScalarT, n, idx-1> spbh;
+    EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void store(const blas_data_mapper<Scalar, Index, StorageOrder, AlignmentType, Incr>* sup, Index i, Index j, const PacketBlock<SubPacket, n>& block) const {
+      spbh.store(sup, i,j,block);
+      for(int l = 0; l < unpacket_traits<SubPacket>::size; l++)
+      {
+        ScalarT *v = &sup->operator()(i+l, j+idx);
+        *v = block.packet[idx][l];
+      }
+    }
+  };
+
+  template<typename SubPacket, int n, int idx>
+  struct storePacketBlock_helper<SubPacket, std::complex<float>, n, idx>
+  {
+    storePacketBlock_helper<SubPacket, std::complex<float>, n, idx-1> spbh;
+    EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void store(const blas_data_mapper<Scalar, Index, StorageOrder, AlignmentType, Incr>* sup, Index i, Index j, const PacketBlock<SubPacket, n>& block) const {
+      spbh.store(sup,i,j,block);
+      for(int l = 0; l < unpacket_traits<SubPacket>::size; l++)
+      {
+        std::complex<float> *v = &sup->operator()(i+l, j+idx);
+        v->real(block.packet[idx].v[2*l+0]);
+        v->imag(block.packet[idx].v[2*l+1]);
+      }
+    }
+  };
+
+  template<typename SubPacket, int n, int idx>
+  struct storePacketBlock_helper<SubPacket, std::complex<double>, n, idx>
+  {
+    storePacketBlock_helper<SubPacket, std::complex<double>, n, idx-1> spbh;
+    EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void store(const blas_data_mapper<Scalar, Index, StorageOrder, AlignmentType, Incr>* sup, Index i, Index j, const PacketBlock<SubPacket, n>& block) const {
+      spbh.store(sup,i,j,block);
+      for(int l = 0; l < unpacket_traits<SubPacket>::size; l++)
+      {
+        std::complex<double> *v = &sup->operator()(i+l, j+idx);
+        v->real(block.packet[idx].v[2*l+0]);
+        v->imag(block.packet[idx].v[2*l+1]);
+      }
+    }
+  };
+
+  template<typename SubPacket, typename ScalarT, int n>
+  struct storePacketBlock_helper<SubPacket, ScalarT, n, -1>
+  {
+    EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void store(const blas_data_mapper<Scalar, Index, StorageOrder, AlignmentType, Incr>*, Index, Index, const PacketBlock<SubPacket, n>& ) const {
+    }
+  };
+
+  template<typename SubPacket, int n>
+  struct storePacketBlock_helper<SubPacket, std::complex<float>, n, -1>
+  {
+    EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void store(const blas_data_mapper<Scalar, Index, StorageOrder, AlignmentType, Incr>*, Index, Index, const PacketBlock<SubPacket, n>& ) const {
+    }
+  };
+
+  template<typename SubPacket, int n>
+  struct storePacketBlock_helper<SubPacket, std::complex<double>, n, -1>
+  {
+    EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void store(const blas_data_mapper<Scalar, Index, StorageOrder, AlignmentType, Incr>*, Index, Index, const PacketBlock<SubPacket, n>& ) const {
+    }
+  };
+  // This function stores a PacketBlock on m_data, this approach is really quite slow compare to Incr=1 and should be avoided when possible.
+  template<typename SubPacket, int n>
+  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void storePacketBlock(Index i, Index j, const PacketBlock<SubPacket, n>&block) const {
+    storePacketBlock_helper<SubPacket, Scalar, n, n-1> spb;
+    spb.store(this, i,j,block);
+  }
 protected:
   Scalar* EIGEN_RESTRICT m_data;
   const Index m_stride;
   const internal::variable_if_dynamic<Index,Incr> m_incr;
 };
 
 // lightweight helper class to access matrix coefficients (const version)
@@ -527,28 +514,70 @@
 template<typename T>
 struct blas_traits<const T>
      : blas_traits<T>
 {};
 
 template<typename T, bool HasUsableDirectAccess=blas_traits<T>::HasUsableDirectAccess>
 struct extract_data_selector {
-  static const typename T::Scalar* run(const T& m)
+  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE static const typename T::Scalar* run(const T& m)
   {
     return blas_traits<T>::extract(m).data();
   }
 };
 
 template<typename T>
 struct extract_data_selector<T,false> {
   static typename T::Scalar* run(const T&) { return 0; }
 };
 
-template<typename T> const typename T::Scalar* extract_data(const T& m)
+template<typename T>
+EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE const typename T::Scalar* extract_data(const T& m)
 {
   return extract_data_selector<T>::run(m);
 }
 
+/**
+ * \c combine_scalar_factors extracts and multiplies factors from GEMM and GEMV products.
+ * There is a specialization for booleans
+ */
+template<typename ResScalar, typename Lhs, typename Rhs>
+struct combine_scalar_factors_impl
+{
+  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE static ResScalar run(const Lhs& lhs, const Rhs& rhs)
+  {
+    return blas_traits<Lhs>::extractScalarFactor(lhs) * blas_traits<Rhs>::extractScalarFactor(rhs);
+  }
+  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE static ResScalar run(const ResScalar& alpha, const Lhs& lhs, const Rhs& rhs)
+  {
+    return alpha * blas_traits<Lhs>::extractScalarFactor(lhs) * blas_traits<Rhs>::extractScalarFactor(rhs);
+  }
+};
+template<typename Lhs, typename Rhs>
+struct combine_scalar_factors_impl<bool, Lhs, Rhs>
+{
+  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE static bool run(const Lhs& lhs, const Rhs& rhs)
+  {
+    return blas_traits<Lhs>::extractScalarFactor(lhs) && blas_traits<Rhs>::extractScalarFactor(rhs);
+  }
+  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE static bool run(const bool& alpha, const Lhs& lhs, const Rhs& rhs)
+  {
+    return alpha && blas_traits<Lhs>::extractScalarFactor(lhs) && blas_traits<Rhs>::extractScalarFactor(rhs);
+  }
+};
+
+template<typename ResScalar, typename Lhs, typename Rhs>
+EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE ResScalar combine_scalar_factors(const ResScalar& alpha, const Lhs& lhs, const Rhs& rhs)
+{
+  return combine_scalar_factors_impl<ResScalar,Lhs,Rhs>::run(alpha, lhs, rhs);
+}
+template<typename ResScalar, typename Lhs, typename Rhs>
+EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE ResScalar combine_scalar_factors(const Lhs& lhs, const Rhs& rhs)
+{
+  return combine_scalar_factors_impl<ResScalar,Lhs,Rhs>::run(lhs, rhs);
+}
+
+
 } // end namespace internal
 
 } // end namespace Eigen
 
 #endif // EIGEN_BLASUTIL_H
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/util/ConfigureVectorization.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/util/ConfigureVectorization.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,11 +1,12 @@
 // This file is part of Eigen, a lightweight C++ template library
 // for linear algebra.
 //
 // Copyright (C) 2008-2018 Gael Guennebaud <gael.guennebaud@inria.fr>
+// Copyright (C) 2020, Arm Limited and Contributors
 //
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_CONFIGURE_VECTORIZATION_H
 #define EIGEN_CONFIGURE_VECTORIZATION_H
@@ -380,42 +381,65 @@
     #include <altivec.h>
     // We need to #undef all these ugly tokens defined in <altivec.h>
     // => use __vector instead of vector
     #undef bool
     #undef vector
     #undef pixel
 
-  #elif (defined  __ARM_NEON) || (defined __ARM_NEON__)
+  #elif ((defined  __ARM_NEON) || (defined __ARM_NEON__)) && !(defined EIGEN_ARM64_USE_SVE)
 
     #define EIGEN_VECTORIZE
     #define EIGEN_VECTORIZE_NEON
     #include <arm_neon.h>
 
-  #elif (defined __s390x__ && defined __VEC__)
+  // We currently require SVE to be enabled explicitly via EIGEN_ARM64_USE_SVE and
+  // will not select the backend automatically
+  #elif (defined __ARM_FEATURE_SVE) && (defined EIGEN_ARM64_USE_SVE)
 
     #define EIGEN_VECTORIZE
-    #define EIGEN_VECTORIZE_ZVECTOR
-    #include <vecintrin.h>
+    #define EIGEN_VECTORIZE_SVE
+    #include <arm_sve.h>
 
-  #elif defined __mips_msa
+    // Since we depend on knowing SVE vector lengths at compile-time, we need
+    // to ensure a fixed lengths is set
+    #if defined __ARM_FEATURE_SVE_BITS
+      #define EIGEN_ARM64_SVE_VL __ARM_FEATURE_SVE_BITS
+    #else
+#error "Eigen requires a fixed SVE lector length but EIGEN_ARM64_SVE_VL is not set."
+#endif
+
+#elif (defined __s390x__ && defined __VEC__)
+
+#define EIGEN_VECTORIZE
+#define EIGEN_VECTORIZE_ZVECTOR
+#include <vecintrin.h>
+
+#elif defined __mips_msa
+
+// Limit MSA optimizations to little-endian CPUs for now.
+// TODO: Perhaps, eventually support MSA optimizations on big-endian CPUs?
+#if defined(__BYTE_ORDER__) && (__BYTE_ORDER__ == __ORDER_LITTLE_ENDIAN__)
+#if defined(__LP64__)
+#define EIGEN_MIPS_64
+#else
+#define EIGEN_MIPS_32
+#endif
+#define EIGEN_VECTORIZE
+#define EIGEN_VECTORIZE_MSA
+#include <msa.h>
+#endif
 
-    // Limit MSA optimizations to little-endian CPUs for now.
-    // TODO: Perhaps, eventually support MSA optimizations on big-endian CPUs?
-    #if defined(__BYTE_ORDER__) && (__BYTE_ORDER__ == __ORDER_LITTLE_ENDIAN__)
-      #if defined(__LP64__)
-        #define EIGEN_MIPS_64
-      #else
-        #define EIGEN_MIPS_32
-      #endif
-      #define EIGEN_VECTORIZE
-      #define EIGEN_VECTORIZE_MSA
-      #include <msa.h>
-    #endif
+#endif
+#endif
 
-  #endif
+// Following the Arm ACLE arm_neon.h should also include arm_fp16.h but not all
+// compilers seem to follow this. We therefore include it explicitly.
+// See also: https://bugs.llvm.org/show_bug.cgi?id=47955
+#if defined(EIGEN_HAS_ARM64_FP16_SCALAR_ARITHMETIC)
+  #include <arm_fp16.h>
 #endif
 
 #if defined(__F16C__) && (!defined(EIGEN_GPUCC) && (!defined(EIGEN_COMP_CLANG) || EIGEN_COMP_CLANG>=380))
   // We can use the optimized fp16 to float and float to fp16 conversion routines
   #define EIGEN_HAS_FP16_C
 
   #if defined(EIGEN_COMP_CLANG)
@@ -467,14 +491,16 @@
   return "SSE, SSE2";
 #elif defined(EIGEN_VECTORIZE_ALTIVEC)
   return "AltiVec";
 #elif defined(EIGEN_VECTORIZE_VSX)
   return "VSX";
 #elif defined(EIGEN_VECTORIZE_NEON)
   return "ARM NEON";
+#elif defined(EIGEN_VECTORIZE_SVE)
+  return "ARM SVE";
 #elif defined(EIGEN_VECTORIZE_ZVECTOR)
   return "S390X ZVECTOR";
 #elif defined(EIGEN_VECTORIZE_MSA)
   return "MIPS MSA";
 #else
   return "None";
 #endif
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/util/Constants.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/util/Constants.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 // This file is part of Eigen, a lightweight C++ template library
 // for linear algebra.
 //
 // Copyright (C) 2008-2015 Gael Guennebaud <gael.guennebaud@inria.fr>
 // Copyright (C) 2007-2009 Benoit Jacob <jacob.benoit.1@gmail.com>
+// Copyright (C) 2020, Arm Limited and Contributors
 //
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_CONSTANTS_H
 #define EIGEN_CONSTANTS_H
@@ -152,15 +153,15 @@
   * See the comment on LvalueBit for an explanation of how LvalueBit and DirectAccessBit are mutually orthogonal.
   */
 const unsigned int DirectAccessBit = 0x40;
 
 /** \deprecated \ingroup flags
   *
   * means the first coefficient packet is guaranteed to be aligned.
-  * An expression cannot has the AlignedBit without the PacketAccessBit flag.
+  * An expression cannot have the AlignedBit without the PacketAccessBit flag.
   * In other words, this means we are allow to perform an aligned packet access to the first element regardless
   * of the expression kind:
   * \code
   * expression.packet<Aligned>(0);
   * \endcode
   */
 EIGEN_DEPRECATED const unsigned int AlignedBit = 0x80;
@@ -324,20 +325,29 @@
   DontAlign = 0x2
 };
 
 /** \ingroup enums
   * Enum for specifying whether to apply or solve on the left or right. */
 enum SideType {
   /** Apply transformation on the left. */
-  OnTheLeft = 1,  
+  OnTheLeft = 1,
   /** Apply transformation on the right. */
-  OnTheRight = 2  
+  OnTheRight = 2
 };
 
-
+/** \ingroup enums
+ * Enum for specifying NaN-propagation behavior, e.g. for coeff-wise min/max. */
+enum NaNPropagationOptions {
+  /**  Implementation defined behavior if NaNs are present. */
+  PropagateFast = 0,
+  /**  Always propagate NaNs. */
+  PropagateNaN,
+  /**  Always propagate not-NaNs. */
+  PropagateNumbers
+};
 
 /* the following used to be written as:
  *
  *   struct NoChange_t {};
  *   namespace {
  *     EIGEN_UNUSED NoChange_t NoChange;
  *   }
@@ -461,22 +471,25 @@
   enum Type {
     Generic = 0x0,
     SSE = 0x1,
     AltiVec = 0x2,
     VSX = 0x3,
     NEON = 0x4,
     MSA = 0x5,
+    SVE = 0x6,
 #if defined EIGEN_VECTORIZE_SSE
     Target = SSE
 #elif defined EIGEN_VECTORIZE_ALTIVEC
     Target = AltiVec
 #elif defined EIGEN_VECTORIZE_VSX
     Target = VSX
 #elif defined EIGEN_VECTORIZE_NEON
     Target = NEON
+#elif defined EIGEN_VECTORIZE_SVE
+    Target = SVE
 #elif defined EIGEN_VECTORIZE_MSA
     Target = MSA
 #else
     Target = Generic
 #endif
   };
 }
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/util/DisableStupidWarnings.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/util/DisableStupidWarnings.h`

 * *Files 2% similar despite different names*

```diff
@@ -40,14 +40,17 @@
   #ifndef EIGEN_PERMANENTLY_DISABLE_STUPID_WARNINGS
     #pragma clang diagnostic push
   #endif
   #pragma clang diagnostic ignored "-Wconstant-logical-operand"
   #if __clang_major__ >= 3 && __clang_minor__ >= 5
     #pragma clang diagnostic ignored "-Wabsolute-value"
   #endif
+  #if __clang_major__ >= 10
+    #pragma clang diagnostic ignored "-Wimplicit-int-float-conversion"
+  #endif
   #if ( defined(__ALTIVEC__) || defined(__VSX__) ) && __cplusplus < 201103L
     // warning: generic selections are a C11-specific feature
     // ignoring warnings thrown at vec_ctf in Altivec/PacketMath.h
     #pragma clang diagnostic ignored "-Wc11-extensions"
   #endif
 
 #elif defined __GNUC__
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/util/ForwardDeclarations.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/util/ForwardDeclarations.h`

 * *Files 0% similar despite different names*

```diff
@@ -176,16 +176,16 @@
 // Provides scalar/packet-wise product and product with accumulation
 // with optional conjugation of the arguments.
 template<typename LhsScalar, typename RhsScalar, bool ConjLhs=false, bool ConjRhs=false> struct conj_helper;
 
 template<typename LhsScalar,typename RhsScalar=LhsScalar> struct scalar_sum_op;
 template<typename LhsScalar,typename RhsScalar=LhsScalar> struct scalar_difference_op;
 template<typename LhsScalar,typename RhsScalar=LhsScalar> struct scalar_conj_product_op;
-template<typename LhsScalar,typename RhsScalar=LhsScalar> struct scalar_min_op;
-template<typename LhsScalar,typename RhsScalar=LhsScalar> struct scalar_max_op;
+template<typename LhsScalar,typename RhsScalar=LhsScalar, int NaNPropagation=PropagateFast> struct scalar_min_op;
+template<typename LhsScalar,typename RhsScalar=LhsScalar, int NaNPropagation=PropagateFast> struct scalar_max_op;
 template<typename Scalar> struct scalar_opposite_op;
 template<typename Scalar> struct scalar_conjugate_op;
 template<typename Scalar> struct scalar_real_op;
 template<typename Scalar> struct scalar_imag_op;
 template<typename Scalar> struct scalar_abs_op;
 template<typename Scalar> struct scalar_abs2_op;
 template<typename LhsScalar,typename RhsScalar=LhsScalar> struct scalar_absolute_difference_op;
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/util/IndexedViewHelper.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/util/IndexedViewHelper.h`

 * *Files 5% similar despite different names*

```diff
@@ -74,15 +74,15 @@
 // Extract increment/step at compile time
 template<typename T, typename EnableIf = void> struct get_compile_time_incr {
   enum { value = UndefinedIncr };
 };
 
 // Analogue of std::get<0>(x), but tailored for our needs.
 template<typename T>
-Index first(const T& x) { return x.first(); }
+EIGEN_CONSTEXPR Index first(const T& x) EIGEN_NOEXCEPT { return x.first(); }
 
 // IndexedViewCompatibleType/makeIndexedViewCompatible turn an arbitrary object of type T into something usable by MatrixSlice
 // The generic implementation is a no-op
 template<typename T,int XprSize,typename EnableIf=void>
 struct IndexedViewCompatibleType {
   typedef T type;
 };
@@ -96,16 +96,16 @@
 
 struct SingleRange {
   enum {
     SizeAtCompileTime = 1
   };
   SingleRange(Index val) : m_value(val) {}
   Index operator[](Index) const { return m_value; }
-  Index size() const { return 1; }
-  Index first() const { return m_value; }
+  static EIGEN_CONSTEXPR Index size() EIGEN_NOEXCEPT { return 1; }
+  Index first() const EIGEN_NOEXCEPT { return m_value; }
   Index m_value;
 };
 
 template<> struct get_compile_time_incr<SingleRange> {
   enum { value = 1 }; // 1 or 0 ??
 };
 
@@ -137,17 +137,17 @@
 struct all_t { all_t() {} };
 
 // Convert a symbolic 'all' into a usable range type
 template<int XprSize>
 struct AllRange {
   enum { SizeAtCompileTime = XprSize };
   AllRange(Index size = XprSize) : m_size(size) {}
-  Index operator[](Index i) const { return i; }
-  Index size() const { return m_size.value(); }
-  Index first() const { return 0; }
+  EIGEN_CONSTEXPR Index operator[](Index i) const EIGEN_NOEXCEPT { return i; }
+  EIGEN_CONSTEXPR Index size() const EIGEN_NOEXCEPT { return m_size.value(); }
+  EIGEN_CONSTEXPR Index first() const EIGEN_NOEXCEPT { return 0; }
   variable_if_dynamic<Index,XprSize> m_size;
 };
 
 template<int XprSize>
 struct IndexedViewCompatibleType<all_t,XprSize> {
   typedef AllRange<XprSize> type;
 };
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/util/IntegralConstant.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/util/IntegralConstant.h`

 * *Files 3% similar despite different names*

```diff
@@ -48,15 +48,15 @@
   *
   * \sa fix<N>, class VariableAndFixedInt
   */
 template<int N> class FixedInt
 {
 public:
   static const int value = N;
-  operator int() const { return value; }
+  EIGEN_CONSTEXPR operator int() const { return value; }
   FixedInt() {}
   FixedInt( VariableAndFixedInt<N> other) {
     #ifndef EIGEN_INTERNAL_DEBUGGING
     EIGEN_UNUSED_VARIABLE(other);
     #endif
     eigen_internal_assert(int(other)==N);
   }
@@ -73,15 +73,15 @@
   template<int M>
   FixedInt<N%M> operator%( FixedInt<M>) const { return FixedInt<N%M>(); }
   template<int M>
   FixedInt<N|M> operator|( FixedInt<M>) const { return FixedInt<N|M>(); }
   template<int M>
   FixedInt<N&M> operator&( FixedInt<M>) const { return FixedInt<N&M>(); }
 
-#if EIGEN_HAS_CXX14
+#if EIGEN_HAS_CXX14_VARIABLE_TEMPLATES
   // Needed in C++14 to allow fix<N>():
   FixedInt operator() () const { return *this; }
 
   VariableAndFixedInt<N> operator() (int val) const { return VariableAndFixedInt<N>(val); }
 #else
   FixedInt ( FixedInt<N> (*)() ) {}
 #endif
@@ -180,15 +180,15 @@
 template<int N, int DynamicKey> struct cleanup_index_type<std::integral_constant<int,N>, DynamicKey> { typedef FixedInt<N> type; };
 #endif
 
 } // end namespace internal
 
 #ifndef EIGEN_PARSED_BY_DOXYGEN
 
-#if EIGEN_HAS_CXX14
+#if EIGEN_HAS_CXX14_VARIABLE_TEMPLATES
 template<int N>
 static const internal::FixedInt<N> fix{};
 #else
 template<int N>
 inline internal::FixedInt<N> fix() { return internal::FixedInt<N>(); }
 
 // The generic typename T is mandatory. Otherwise, a code like fix<N> could refer to either the function above or this next overload.
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/util/MKL_support.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/util/MKL_support.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/util/Macros.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/util/Macros.h`

 * *Files 2% similar despite different names*

```diff
@@ -12,16 +12,16 @@
 #define EIGEN_MACROS_H
 
 //------------------------------------------------------------------------------------------
 // Eigen version and basic defaults
 //------------------------------------------------------------------------------------------
 
 #define EIGEN_WORLD_VERSION 3
-#define EIGEN_MAJOR_VERSION 3
-#define EIGEN_MINOR_VERSION 90
+#define EIGEN_MAJOR_VERSION 4
+#define EIGEN_MINOR_VERSION 0
 
 #define EIGEN_VERSION_AT_LEAST(x,y,z) (EIGEN_WORLD_VERSION>x || (EIGEN_WORLD_VERSION>=x && \
                                       (EIGEN_MAJOR_VERSION>y || (EIGEN_MAJOR_VERSION>=y && \
                                                                  EIGEN_MINOR_VERSION>=z))))
 
 #ifdef EIGEN_DEFAULT_TO_ROW_MAJOR
 #define EIGEN_DEFAULT_MATRIX_STORAGE_ORDER_OPTION Eigen::RowMajor
@@ -68,14 +68,20 @@
 /// \internal EIGEN_COMP_CLANG set to major+minor version (e.g., 307 for clang 3.7) if the compiler is clang
 #if defined(__clang__)
   #define EIGEN_COMP_CLANG (__clang_major__*100+__clang_minor__)
 #else
   #define EIGEN_COMP_CLANG 0
 #endif
 
+/// \internal EIGEN_COMP_CASTXML set to 1 if being preprocessed by CastXML
+#if defined(__castxml__)
+  #define EIGEN_COMP_CASTXML 1
+#else
+  #define EIGEN_COMP_CASTXML 0
+#endif
 
 /// \internal EIGEN_COMP_LLVM set to 1 if the compiler backend is llvm
 #if defined(__llvm__)
   #define EIGEN_COMP_LLVM 1
 #else
   #define EIGEN_COMP_LLVM 0
 #endif
@@ -152,16 +158,16 @@
   #define EIGEN_COMP_MSVC_STRICT _MSC_VER
 #else
   #define EIGEN_COMP_MSVC_STRICT 0
 #endif
 
 /// \internal EIGEN_COMP_IBM set to xlc version if the compiler is IBM XL C++
 // XLC   version
-// 3.1   0x0301	
-// 4.5   0x0405	
+// 3.1   0x0301
+// 4.5   0x0405
 // 5.0   0x0500
 // 12.1  0x0C01
 #if defined(__IBMCPP__) || defined(__xlc__) || defined(__ibmxl__)
   #define EIGEN_COMP_IBM __xlC__
 #else
   #define EIGEN_COMP_IBM 0
 #endif
@@ -216,15 +222,15 @@
 
 
 //------------------------------------------------------------------------------------------
 // Architecture identification, EIGEN_ARCH_*
 //------------------------------------------------------------------------------------------
 
 
-#if defined(__x86_64__) || defined(_M_X64) || defined(__amd64)
+#if defined(__x86_64__) || (defined(_M_X64) && !defined(_M_ARM64EC)) || defined(__amd64)
   #define EIGEN_ARCH_x86_64 1
 #else
   #define EIGEN_ARCH_x86_64 0
 #endif
 
 #if defined(__i386__) || defined(_M_IX86) || defined(_X86_) || defined(__i386)
   #define EIGEN_ARCH_i386 1
@@ -242,26 +248,69 @@
 #if defined(__arm__)
   #define EIGEN_ARCH_ARM 1
 #else
   #define EIGEN_ARCH_ARM 0
 #endif
 
 /// \internal EIGEN_ARCH_ARM64 set to 1 if the architecture is ARM64
-#if defined(__aarch64__)
+#if defined(__aarch64__) || defined(_M_ARM64) || defined(_M_ARM64EC)
   #define EIGEN_ARCH_ARM64 1
 #else
   #define EIGEN_ARCH_ARM64 0
 #endif
 
+/// \internal EIGEN_ARCH_ARM_OR_ARM64 set to 1 if the architecture is ARM or ARM64
 #if EIGEN_ARCH_ARM || EIGEN_ARCH_ARM64
   #define EIGEN_ARCH_ARM_OR_ARM64 1
 #else
   #define EIGEN_ARCH_ARM_OR_ARM64 0
 #endif
 
+/// \internal EIGEN_ARCH_ARMV8 set to 1 if the architecture is armv8 or greater.
+#if EIGEN_ARCH_ARM_OR_ARM64 && defined(__ARM_ARCH) && __ARM_ARCH >= 8
+#define EIGEN_ARCH_ARMV8 1
+#else
+#define EIGEN_ARCH_ARMV8 0
+#endif
+
+
+/// \internal EIGEN_HAS_ARM64_FP16 set to 1 if the architecture provides an IEEE
+/// compliant Arm fp16 type
+#if EIGEN_ARCH_ARM64
+  #ifndef EIGEN_HAS_ARM64_FP16
+    #if defined(__ARM_FP16_FORMAT_IEEE)
+      #define EIGEN_HAS_ARM64_FP16 1
+    #else
+      #define EIGEN_HAS_ARM64_FP16 0
+    #endif
+  #endif
+#endif
+
+/// \internal EIGEN_HAS_ARM64_FP16_VECTOR_ARITHMETIC set to 1 if the architecture
+/// supports Neon vector intrinsics for fp16.
+#if EIGEN_ARCH_ARM64
+  #ifndef EIGEN_HAS_ARM64_FP16_VECTOR_ARITHMETIC
+    #if defined(__ARM_FEATURE_FP16_VECTOR_ARITHMETIC)
+      #define EIGEN_HAS_ARM64_FP16_VECTOR_ARITHMETIC 1
+    #else
+      #define EIGEN_HAS_ARM64_FP16_VECTOR_ARITHMETIC 0
+    #endif
+  #endif
+#endif
+
+/// \internal EIGEN_HAS_ARM64_FP16_SCALAR_ARITHMETIC set to 1 if the architecture
+/// supports Neon scalar intrinsics for fp16.
+#if EIGEN_ARCH_ARM64
+  #ifndef EIGEN_HAS_ARM64_FP16_SCALAR_ARITHMETIC
+    #if defined(__ARM_FEATURE_FP16_SCALAR_ARITHMETIC)
+      #define EIGEN_HAS_ARM64_FP16_SCALAR_ARITHMETIC 1
+    #endif
+  #endif
+#endif
+
 /// \internal EIGEN_ARCH_MIPS set to 1 if the architecture is MIPS
 #if defined(__mips__) || defined(__mips)
   #define EIGEN_ARCH_MIPS 1
 #else
   #define EIGEN_ARCH_MIPS 0
 #endif
 
@@ -436,16 +485,35 @@
   // ++ host_defines.h which contains the defines for the __host__ and __device__ macros
   #include <hip/hip_runtime.h>
 
   #if defined(__HIP_DEVICE_COMPILE__)
     // analogous to EIGEN_CUDA_ARCH, but for HIP
     #define EIGEN_HIP_DEVICE_COMPILE __HIP_DEVICE_COMPILE__
   #endif
+
+  // For HIP (ROCm 3.5 and higher), we need to explicitly set the launch_bounds attribute
+  // value to 1024. The compiler assigns a default value of 256 when the attribute is not
+  // specified. This results in failures on the HIP platform, for cases when a GPU kernel
+  // without an explicit launch_bounds attribute is called with a threads_per_block value
+  // greater than 256.
+  //
+  // This is a regression in functioanlity and is expected to be fixed within the next
+  // couple of ROCm releases (compiler will go back to using 1024 value as the default)
+  //
+  // In the meantime, we will use a "only enabled for HIP" macro to set the launch_bounds
+  // attribute.
+
+  #define EIGEN_HIP_LAUNCH_BOUNDS_1024 __launch_bounds__(1024)
+
 #endif
 
+#if !defined(EIGEN_HIP_LAUNCH_BOUNDS_1024)
+#define EIGEN_HIP_LAUNCH_BOUNDS_1024
+#endif // !defined(EIGEN_HIP_LAUNCH_BOUNDS_1024)
+
 // Unify CUDA/HIPCC
 
 #if defined(EIGEN_CUDACC) || defined(EIGEN_HIPCC)
 //
 // If either EIGEN_CUDACC or EIGEN_HIPCC is defined, then define EIGEN_GPUCC
 //
 #define EIGEN_GPUCC
@@ -533,26 +601,52 @@
                               || (defined(__apple_build_version__) && (__apple_build_version__ < 9000000)))  \
       || EIGEN_COMP_GNUC_STRICT && EIGEN_COMP_GNUC<49)
 #define EIGEN_HAS_STATIC_ARRAY_TEMPLATE 1
 #else
 #define EIGEN_HAS_STATIC_ARRAY_TEMPLATE 0
 #endif
 
+// The macro EIGEN_CPLUSPLUS is a replacement for __cplusplus/_MSVC_LANG that
+// works for both platforms, indicating the C++ standard version number.
+//
+// With MSVC, without defining /Zc:__cplusplus, the __cplusplus macro will
+// report 199711L regardless of the language standard specified via /std.
+// We need to rely on _MSVC_LANG instead, which is only available after
+// VS2015.3.
+#if EIGEN_COMP_MSVC_LANG > 0
+#define EIGEN_CPLUSPLUS EIGEN_COMP_MSVC_LANG
+#elif EIGEN_COMP_MSVC >= 1900
+#define EIGEN_CPLUSPLUS 201103L
+#elif defined(__cplusplus)
+#define EIGEN_CPLUSPLUS __cplusplus
+#else
+#define EIGEN_CPLUSPLUS 0
+#endif
 
 // The macro EIGEN_COMP_CXXVER defines the c++ verson expected by the compiler.
 // For instance, if compiling with gcc and -std=c++17, then EIGEN_COMP_CXXVER
 // is defined to 17.
-#if   (defined(__cplusplus) && (__cplusplus >  201402L) || EIGEN_COMP_MSVC_LANG > 201402L)
-#define EIGEN_COMP_CXXVER 17
-#elif (defined(__cplusplus) && (__cplusplus >  201103L) || EIGEN_COMP_MSVC >= 1910)
-#define EIGEN_COMP_CXXVER 14
-#elif (defined(__cplusplus) && (__cplusplus >= 201103L) || EIGEN_COMP_MSVC >= 1900)
-#define EIGEN_COMP_CXXVER 11
-#else
-#define EIGEN_COMP_CXXVER 03
+#if EIGEN_CPLUSPLUS > 201703L
+  #define EIGEN_COMP_CXXVER 20
+#elif EIGEN_CPLUSPLUS > 201402L
+  #define EIGEN_COMP_CXXVER 17
+#elif EIGEN_CPLUSPLUS > 201103L
+  #define EIGEN_COMP_CXXVER 14
+#elif EIGEN_CPLUSPLUS >= 201103L
+  #define EIGEN_COMP_CXXVER 11
+#else
+  #define EIGEN_COMP_CXXVER 03
+#endif
+
+#ifndef EIGEN_HAS_CXX14_VARIABLE_TEMPLATES
+  #if defined(__cpp_variable_templates) && __cpp_variable_templates >= 201304 && EIGEN_MAX_CPP_VER>=14
+    #define EIGEN_HAS_CXX14_VARIABLE_TEMPLATES 1
+  #else
+    #define EIGEN_HAS_CXX14_VARIABLE_TEMPLATES 0
+  #endif
 #endif
 
 
 // The macros EIGEN_HAS_CXX?? defines a rough estimate of available c++ features
 // but in practice we should not rely on them but rather on the availabilty of
 // individual features as defined later.
 // This is why there is no EIGEN_HAS_CXX17.
@@ -569,16 +663,15 @@
 #define EIGEN_HAS_CXX14 0
 #endif
 
 // Do we support r-value references?
 #ifndef EIGEN_HAS_RVALUE_REFERENCES
 #if EIGEN_MAX_CPP_VER>=11 && \
     (__has_feature(cxx_rvalue_references) || \
-    (defined(__cplusplus) && __cplusplus >= 201103L) || \
-    (EIGEN_COMP_MSVC >= 1600))
+     (EIGEN_COMP_CXXVER >= 11) || (EIGEN_COMP_MSVC >= 1600))
   #define EIGEN_HAS_RVALUE_REFERENCES 1
 #else
   #define EIGEN_HAS_RVALUE_REFERENCES 0
 #endif
 #endif
 
 // Does the compiler support C99?
@@ -593,25 +686,42 @@
   #define EIGEN_HAS_C99_MATH 1
 #else
   #define EIGEN_HAS_C99_MATH 0
 #endif
 #endif
 
 // Does the compiler support result_of?
-// It's likely that MSVC 2013 supports result_of but I couldn't not find a good source for that,
-// so let's be conservative.
+// result_of was deprecated in c++17 and removed in c++ 20
 #ifndef EIGEN_HAS_STD_RESULT_OF
-#if EIGEN_MAX_CPP_VER>=11 && \
-    (__has_feature(cxx_lambdas) || (defined(__cplusplus) && __cplusplus >= 201103L) || EIGEN_COMP_MSVC >= 1900)
+#if EIGEN_HAS_CXX11 && EIGEN_COMP_CXXVER < 17
 #define EIGEN_HAS_STD_RESULT_OF 1
 #else
 #define EIGEN_HAS_STD_RESULT_OF 0
 #endif
 #endif
 
+// Does the compiler support std::hash?
+#ifndef EIGEN_HAS_STD_HASH
+// The std::hash struct is defined in C++11 but is not labelled as a __device__
+// function and is not constexpr, so cannot be used on device.
+#if EIGEN_HAS_CXX11 && !defined(EIGEN_GPU_COMPILE_PHASE)
+#define EIGEN_HAS_STD_HASH 1
+#else
+#define EIGEN_HAS_STD_HASH 0
+#endif
+#endif  // EIGEN_HAS_STD_HASH
+
+#ifndef EIGEN_HAS_STD_INVOKE_RESULT
+#if EIGEN_MAX_CPP_VER >= 17 && EIGEN_COMP_CXXVER >= 17
+#define EIGEN_HAS_STD_INVOKE_RESULT 1
+#else
+#define EIGEN_HAS_STD_INVOKE_RESULT 0
+#endif
+#endif
+
 #ifndef EIGEN_HAS_ALIGNAS
 #if EIGEN_MAX_CPP_VER>=11 && EIGEN_HAS_CXX11 &&   \
       (     __has_feature(cxx_alignas)            \
         ||  EIGEN_HAS_CXX14                       \
         || (EIGEN_COMP_MSVC >= 1800)              \
         || (EIGEN_GNUC_AT_LEAST(4,8))             \
         || (EIGEN_COMP_CLANG>=305)                \
@@ -636,102 +746,106 @@
 #else
 #define EIGEN_HAS_TYPE_TRAITS 0
 #endif
 #endif
 
 // Does the compiler support variadic templates?
 #ifndef EIGEN_HAS_VARIADIC_TEMPLATES
-#if EIGEN_MAX_CPP_VER>=11 && (__cplusplus > 199711L || EIGEN_COMP_MSVC >= 1900) \
+#if EIGEN_MAX_CPP_VER>=11 && (EIGEN_COMP_CXXVER >= 11) \
   && (!defined(__NVCC__) || !EIGEN_ARCH_ARM_OR_ARM64 || (EIGEN_COMP_NVCC >= 80000) )
     // ^^ Disable the use of variadic templates when compiling with versions of nvcc older than 8.0 on ARM devices:
     //    this prevents nvcc from crashing when compiling Eigen on Tegra X1
 #define EIGEN_HAS_VARIADIC_TEMPLATES 1
-#elif  EIGEN_MAX_CPP_VER>=11 && (__cplusplus > 199711L || EIGEN_COMP_MSVC >= 1900) && defined(SYCL_DEVICE_ONLY)
+#elif  EIGEN_MAX_CPP_VER>=11 && (EIGEN_COMP_CXXVER >= 11) && defined(SYCL_DEVICE_ONLY)
 #define EIGEN_HAS_VARIADIC_TEMPLATES 1
 #else
 #define EIGEN_HAS_VARIADIC_TEMPLATES 0
 #endif
 #endif
 
 // Does the compiler fully support const expressions? (as in c++14)
 #ifndef EIGEN_HAS_CONSTEXPR
   #if defined(EIGEN_CUDACC)
   // Const expressions are supported provided that c++11 is enabled and we're using either clang or nvcc 7.5 or above
-    #if EIGEN_MAX_CPP_VER>=14 && (__cplusplus > 199711L && (EIGEN_COMP_CLANG || EIGEN_COMP_NVCC >= 70500))
+    #if EIGEN_MAX_CPP_VER>=14 && (EIGEN_COMP_CXXVER >= 11 && (EIGEN_COMP_CLANG || EIGEN_COMP_NVCC >= 70500))
       #define EIGEN_HAS_CONSTEXPR 1
     #endif
-  #elif EIGEN_MAX_CPP_VER>=14 && (__has_feature(cxx_relaxed_constexpr) || (defined(__cplusplus) && __cplusplus >= 201402L) || \
-    (EIGEN_GNUC_AT_LEAST(4,8) && (__cplusplus > 199711L)) || \
-    (EIGEN_COMP_CLANG >= 306 && (__cplusplus > 199711L)))
+  #elif EIGEN_MAX_CPP_VER>=14 && (__has_feature(cxx_relaxed_constexpr) || (EIGEN_COMP_CXXVER >= 14) || \
+    (EIGEN_GNUC_AT_LEAST(4,8) && (EIGEN_COMP_CXXVER >= 11)) || \
+    (EIGEN_COMP_CLANG >= 306 && (EIGEN_COMP_CXXVER >= 11)))
     #define EIGEN_HAS_CONSTEXPR 1
   #endif
 
   #ifndef EIGEN_HAS_CONSTEXPR
     #define EIGEN_HAS_CONSTEXPR 0
   #endif
 
 #endif // EIGEN_HAS_CONSTEXPR
 
+#if EIGEN_HAS_CONSTEXPR
+#define EIGEN_CONSTEXPR constexpr
+#else
+#define EIGEN_CONSTEXPR
+#endif
+
 // Does the compiler support C++11 math?
 // Let's be conservative and enable the default C++11 implementation only if we are sure it exists
 #ifndef EIGEN_HAS_CXX11_MATH
-  #if EIGEN_MAX_CPP_VER>=11 && ((__cplusplus > 201103L) || (__cplusplus >= 201103L) && (EIGEN_COMP_GNUC_STRICT || EIGEN_COMP_CLANG || EIGEN_COMP_MSVC || EIGEN_COMP_ICC)  \
+  #if EIGEN_MAX_CPP_VER>=11 && ((EIGEN_COMP_CXXVER > 11) || (EIGEN_COMP_CXXVER == 11) && (EIGEN_COMP_GNUC_STRICT || EIGEN_COMP_CLANG || EIGEN_COMP_MSVC || EIGEN_COMP_ICC)  \
       && (EIGEN_ARCH_i386_OR_x86_64) && (EIGEN_OS_GNULINUX || EIGEN_OS_WIN_STRICT || EIGEN_OS_MAC))
     #define EIGEN_HAS_CXX11_MATH 1
   #else
     #define EIGEN_HAS_CXX11_MATH 0
   #endif
 #endif
 
 // Does the compiler support proper C++11 containers?
 #ifndef EIGEN_HAS_CXX11_CONTAINERS
   #if    EIGEN_MAX_CPP_VER>=11 && \
-         ((__cplusplus > 201103L) \
-      || ((__cplusplus >= 201103L) && (EIGEN_COMP_GNUC_STRICT || EIGEN_COMP_CLANG || EIGEN_COMP_ICC>=1400)) \
-      || EIGEN_COMP_MSVC >= 1900)
+         ((EIGEN_COMP_CXXVER > 11) \
+      || ((EIGEN_COMP_CXXVER == 11) && (EIGEN_COMP_GNUC_STRICT || EIGEN_COMP_CLANG || EIGEN_COMP_MSVC || EIGEN_COMP_ICC>=1400)))
     #define EIGEN_HAS_CXX11_CONTAINERS 1
   #else
     #define EIGEN_HAS_CXX11_CONTAINERS 0
   #endif
 #endif
 
 // Does the compiler support C++11 noexcept?
 #ifndef EIGEN_HAS_CXX11_NOEXCEPT
   #if    EIGEN_MAX_CPP_VER>=11 && \
          (__has_feature(cxx_noexcept) \
-      || (__cplusplus > 201103L) \
-      || ((__cplusplus >= 201103L) && (EIGEN_COMP_GNUC_STRICT || EIGEN_COMP_CLANG || EIGEN_COMP_ICC>=1400)) \
-      || EIGEN_COMP_MSVC >= 1900)
+      || (EIGEN_COMP_CXXVER > 11) \
+      || ((EIGEN_COMP_CXXVER == 11) && (EIGEN_COMP_GNUC_STRICT || EIGEN_COMP_CLANG || EIGEN_COMP_MSVC || EIGEN_COMP_ICC>=1400)))
     #define EIGEN_HAS_CXX11_NOEXCEPT 1
   #else
     #define EIGEN_HAS_CXX11_NOEXCEPT 0
   #endif
 #endif
 
 #ifndef EIGEN_HAS_CXX11_ATOMIC
   #if    EIGEN_MAX_CPP_VER>=11 && \
          (__has_feature(cxx_atomic) \
-      || (__cplusplus > 201103L) \
-      || ((__cplusplus >= 201103L) && (EIGEN_COMP_MSVC==0 || EIGEN_COMP_MSVC >= 1700)))
+      || (EIGEN_COMP_CXXVER > 11) \
+      || ((EIGEN_COMP_CXXVER == 11) && (EIGEN_COMP_MSVC==0 || EIGEN_COMP_MSVC >= 1700)))
     #define EIGEN_HAS_CXX11_ATOMIC 1
   #else
     #define EIGEN_HAS_CXX11_ATOMIC 0
   #endif
 #endif
 
 #ifndef EIGEN_HAS_CXX11_OVERRIDE_FINAL
   #if    EIGEN_MAX_CPP_VER>=11 && \
-       (__cplusplus >= 201103L || EIGEN_COMP_MSVC >= 1700)
+       (EIGEN_COMP_CXXVER >= 11 || EIGEN_COMP_MSVC >= 1700)
     #define EIGEN_HAS_CXX11_OVERRIDE_FINAL 1
   #else
     #define EIGEN_HAS_CXX11_OVERRIDE_FINAL 0
   #endif
 #endif
 
-// NOTE: the required Apple's clang version is very conservative 
+// NOTE: the required Apple's clang version is very conservative
 //       and it could be that XCode 9 works just fine.
 // NOTE: the MSVC version is based on https://en.cppreference.com/w/cpp/compiler_support
 //       and not tested.
 #ifndef EIGEN_HAS_CXX17_OVERALIGN
 #if EIGEN_MAX_CPP_VER>=17 && EIGEN_COMP_CXXVER>=17 && (                                 \
            (EIGEN_COMP_MSVC >= 1912)                                                    \
         || (EIGEN_GNUC_AT_LEAST(7,0))                                                   \
@@ -793,15 +907,15 @@
 #define EIGEN_MAKESTRING2(a) #a
 #define EIGEN_MAKESTRING(a) EIGEN_MAKESTRING2(a)
 
 // EIGEN_STRONG_INLINE is a stronger version of the inline, using __forceinline on MSVC,
 // but it still doesn't use GCC's always_inline. This is useful in (common) situations where MSVC needs forceinline
 // but GCC is still doing fine with just inline.
 #ifndef EIGEN_STRONG_INLINE
-#if EIGEN_COMP_MSVC || EIGEN_COMP_ICC
+#if (EIGEN_COMP_MSVC || EIGEN_COMP_ICC) && !defined(EIGEN_GPUCC)
 #define EIGEN_STRONG_INLINE __forceinline
 #else
 #define EIGEN_STRONG_INLINE inline
 #endif
 #endif
 
 // EIGEN_ALWAYS_INLINE is the stronget, it has the effect of making the function inline and adding every possible
@@ -852,15 +966,15 @@
 
 #if defined(SYCL_DEVICE_ONLY)
   #ifndef EIGEN_DONT_VECTORIZE
     #define EIGEN_DONT_VECTORIZE
   #endif
   #define EIGEN_DEVICE_FUNC __attribute__((flatten)) __attribute__((always_inline))
 // All functions callable from CUDA/HIP code must be qualified with __device__
-#elif defined(EIGEN_GPUCC) 
+#elif defined(EIGEN_GPUCC)
     #define EIGEN_DEVICE_FUNC __host__ __device__
 #else
   #define EIGEN_DEVICE_FUNC
 #endif
 
 
 // this macro allows to get rid of linking errors about multiply defined functions.
@@ -879,15 +993,15 @@
 // eigen_plain_assert is where we implement the workaround for the assert() bug in GCC <= 4.3, see bug 89
 #ifdef EIGEN_NO_DEBUG
   #ifdef SYCL_DEVICE_ONLY // used to silence the warning on SYCL device
     #define eigen_plain_assert(x) EIGEN_UNUSED_VARIABLE(x)
   #else
     #define eigen_plain_assert(x)
   #endif
-#else 
+#else
   #if EIGEN_SAFE_TO_USE_STANDARD_ASSERT_MACRO
     namespace Eigen {
     namespace internal {
     inline bool copy_bool(bool b) { return b; }
     }
     }
     #define eigen_plain_assert(x) assert(x)
@@ -966,14 +1080,75 @@
     #define EIGEN_ASM_COMMENT(X)  __asm__("#" X)
   #else
     #define EIGEN_ASM_COMMENT(X)
   #endif
 #endif
 
 
+// Acts as a barrier preventing operations involving `X` from crossing. This
+// occurs, for example, in the fast rounding trick where a magic constant is
+// added then subtracted, which is otherwise compiled away with -ffast-math.
+//
+// See bug 1674
+#if !defined(EIGEN_OPTIMIZATION_BARRIER)
+  #if EIGEN_COMP_GNUC
+    // According to https://gcc.gnu.org/onlinedocs/gcc/Constraints.html:
+    //   X: Any operand whatsoever.
+    //   r: A register operand is allowed provided that it is in a general
+    //      register.
+    //   g: Any register, memory or immediate integer operand is allowed, except
+    //      for registers that are not general registers.
+    //   w: (AArch32/AArch64) Floating point register, Advanced SIMD vector
+    //      register or SVE vector register.
+    //   x: (SSE) Any SSE register.
+    //      (AArch64) Like w, but restricted to registers 0 to 15 inclusive.
+    //   v: (PowerPC) An Altivec vector register.
+    //   wa:(PowerPC) A VSX register.
+    //
+    // "X" (uppercase) should work for all cases, though this seems to fail for
+    // some versions of GCC for arm/aarch64 with
+    //   "error: inconsistent operand constraints in an 'asm'"
+    // Clang x86_64/arm/aarch64 seems to require "g" to support both scalars and
+    // vectors, otherwise
+    //   "error: non-trivial scalar-to-vector conversion, possible invalid
+    //    constraint for vector type"
+    //
+    // GCC for ppc64le generates an internal compiler error with x/X/g.
+    // GCC for AVX generates an internal compiler error with X.
+    //
+    // Tested on icc/gcc/clang for sse, avx, avx2, avx512dq
+    //           gcc for arm, aarch64,
+    //           gcc for ppc64le,
+    // both vectors and scalars.
+    //
+    // Note that this is restricted to plain types - this will not work
+    // directly for std::complex<T>, Eigen::half, Eigen::bfloat16. For these,
+    // you will need to apply to the underlying POD type.
+    #if EIGEN_ARCH_PPC && EIGEN_COMP_GNUC_STRICT
+      // This seems to be broken on clang.  Packet4f is loaded into a single
+      //   register rather than a vector, zeroing out some entries.  Integer
+      //   types also generate a compile error.
+      // General, Altivec, VSX.
+      #define EIGEN_OPTIMIZATION_BARRIER(X)  __asm__  ("" : "+r,v,wa" (X));
+    #elif EIGEN_ARCH_ARM_OR_ARM64
+      // General, NEON.
+      #define EIGEN_OPTIMIZATION_BARRIER(X)  __asm__  ("" : "+g,w" (X));
+    #elif EIGEN_ARCH_i386_OR_x86_64
+      // General, SSE.
+      #define EIGEN_OPTIMIZATION_BARRIER(X)  __asm__  ("" : "+g,x" (X));
+    #else
+      // Not implemented for other architectures.
+      #define EIGEN_OPTIMIZATION_BARRIER(X)
+    #endif
+  #else
+    // Not implemented for other compilers.
+    #define EIGEN_OPTIMIZATION_BARRIER(X)
+  #endif
+#endif
+
 #if EIGEN_COMP_MSVC
   // NOTE MSVC often gives C4127 warnings with compiletime if statements. See bug 1362.
   // This workaround is ugly, but it does the job.
 #  define EIGEN_CONST_CONDITIONAL(cond)  (void)0, cond
 #else
 #  define EIGEN_CONST_CONDITIONAL(cond)  cond
 #endif
@@ -1001,35 +1176,25 @@
 
 
 // When compiling CUDA/HIP device code with NVCC or HIPCC
 // pull in math functions from the global namespace.
 // In host mode, and when device code is compiled with clang,
 // use the std versions.
 #if (defined(EIGEN_CUDA_ARCH) && defined(__NVCC__)) || defined(EIGEN_HIP_DEVICE_COMPILE)
-  #define EIGEN_USING_STD_MATH(FUNC) using ::FUNC;
-#else
-  #define EIGEN_USING_STD_MATH(FUNC) using std::FUNC;
-#endif
-
-
-// When compiling HIP device code with HIPCC, certain functions
-// from the stdlib need to be pulled in from the global namespace
-// (as opposed to from the std:: namespace). This is because HIPCC
-// does not natively support all the std:: routines in device code.
-// Instead it contains header files that declare the corresponding
-// routines in the global namespace such they can be used in device code.
-#if defined(EIGEN_HIP_DEVICE_COMPILE)
   #define EIGEN_USING_STD(FUNC) using ::FUNC;
 #else
   #define EIGEN_USING_STD(FUNC) using std::FUNC;
 #endif
 
-
-#if EIGEN_COMP_MSVC_STRICT && (EIGEN_COMP_MSVC < 1900 || EIGEN_COMP_NVCC)
-  // for older MSVC versions, as well as 1900 && CUDA 8, using the base operator is sufficient (cf Bugs 1000, 1324)
+#if EIGEN_COMP_MSVC_STRICT && (EIGEN_COMP_MSVC < 1900 || (EIGEN_COMP_MSVC == 1900 && EIGEN_COMP_NVCC))
+  // For older MSVC versions, as well as 1900 && CUDA 8, using the base operator is necessary,
+  //   otherwise we get duplicate definition errors
+  // For later MSVC versions, we require explicit operator= definition, otherwise we get
+  //   use of implicitly deleted operator errors.
+  // (cf Bugs 920, 1000, 1324, 2291)
   #define EIGEN_INHERIT_ASSIGNMENT_EQUAL_OPERATOR(Derived) \
     using Base::operator =;
 #elif EIGEN_COMP_CLANG // workaround clang bug (see http://forum.kde.org/viewtopic.php?f=74&t=102653)
   #define EIGEN_INHERIT_ASSIGNMENT_EQUAL_OPERATOR(Derived) \
     using Base::operator =; \
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& operator=(const Derived& other) { Base::operator=(other); return *this; } \
     template <typename OtherDerived> \
@@ -1047,15 +1212,15 @@
 
 /**
  * \internal
  * \brief Macro to explicitly define the default copy constructor.
  * This is necessary, because the implicit definition is deprecated if the copy-assignment is overridden.
  */
 #if EIGEN_HAS_CXX11
-#define EIGEN_DEFAULT_COPY_CONSTRUCTOR(CLASS) EIGEN_DEVICE_FUNC CLASS(const CLASS&) = default;
+#define EIGEN_DEFAULT_COPY_CONSTRUCTOR(CLASS) CLASS(const CLASS&) = default;
 #else
 #define EIGEN_DEFAULT_COPY_CONSTRUCTOR(CLASS)
 #endif
 
 
 
 /** \internal
@@ -1072,20 +1237,20 @@
  * This is necessary when the copy constructor is re-defined.
  * For empty helper classes this should usually be protected, to avoid accidentally creating empty objects.
  *
  * Hiding the default destructor lead to problems in C++03 mode together with boost::multiprecision
  */
 #if EIGEN_HAS_CXX11
 #define EIGEN_DEFAULT_EMPTY_CONSTRUCTOR_AND_DESTRUCTOR(Derived)  \
-    EIGEN_DEVICE_FUNC Derived() = default; \
-    EIGEN_DEVICE_FUNC ~Derived() = default;
+    Derived() = default; \
+    ~Derived() = default;
 #else
 #define EIGEN_DEFAULT_EMPTY_CONSTRUCTOR_AND_DESTRUCTOR(Derived)  \
-    EIGEN_DEVICE_FUNC Derived() {}; \
-    /* EIGEN_DEVICE_FUNC ~Derived() {}; */
+    Derived() {}; \
+    /* ~Derived() {}; */
 #endif
 
 
 
 
 
 /**
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/util/Memory.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/util/Memory.h`

 * *Files 2% similar despite different names*

```diff
@@ -78,15 +78,16 @@
     //
     // "throw_std_bad_alloc" has the EIGEN_DEVICE_FUNC attribute, so it seems that hipcc expects
     // the same on "operator new"
     // Reverting code back to the old version in this #if block for the hipcc compiler
     //
     new int[huge];
     #else
-    ::operator new(huge);
+    void* unused = ::operator new(huge);
+    EIGEN_UNUSED_VARIABLE(unused);
     #endif
   #endif
 }
 
 /*****************************************************************************
 *** Implementation of handmade aligned functions                           ***
 *****************************************************************************/
@@ -209,15 +210,15 @@
 /**
   * \internal
   * \brief Reallocates an aligned block of memory.
   * \throws std::bad_alloc on allocation failure
   */
 inline void* aligned_realloc(void *ptr, std::size_t new_size, std::size_t old_size)
 {
-  EIGEN_UNUSED_VARIABLE(old_size);
+  EIGEN_UNUSED_VARIABLE(old_size)
 
   void *result;
 #if (EIGEN_DEFAULT_ALIGN_BYTES==0) || EIGEN_MALLOC_ALREADY_ALIGNED
   result = std::realloc(ptr,new_size);
 #else
   result = handmade_aligned_realloc(ptr,new_size,old_size);
 #endif
@@ -561,14 +562,25 @@
     {
       std::ptrdiff_t count = (std::ptrdiff_t(end)-std::ptrdiff_t(start)) / sizeof(T);
       std::copy_backward(start, end, target + count);
     }
   }
 };
 
+#if EIGEN_HAS_RVALUE_REFERENCES
+template<typename T> EIGEN_DEVICE_FUNC T* smart_move(T* start, T* end, T* target)
+{
+  return std::move(start, end, target);
+}
+#else
+template<typename T> EIGEN_DEVICE_FUNC T* smart_move(T* start, T* end, T* target)
+{
+  return std::copy(start, end, target);
+}
+#endif
 
 /*****************************************************************************
 *** Implementation of runtime stack allocation (falling back to malloc)    ***
 *****************************************************************************/
 
 // you can overwrite Eigen's default behavior regarding alloca by defining EIGEN_ALLOCA
 // to the appropriate stack allocation function
@@ -775,40 +787,53 @@
 #define EIGEN_MAKE_ALIGNED_OPERATOR_NEW_NOTHROW(NeedsToAlign)
 #define EIGEN_MAKE_ALIGNED_OPERATOR_NEW_IF(NeedsToAlign)
 #define EIGEN_MAKE_ALIGNED_OPERATOR_NEW
 #define EIGEN_MAKE_ALIGNED_OPERATOR_NEW_IF_VECTORIZABLE_FIXED_SIZE(Scalar,Size)
 
 #else
 
-#if EIGEN_MAX_ALIGN_BYTES!=0
+// HIP does not support new/delete on device.
+#if EIGEN_MAX_ALIGN_BYTES!=0 && !defined(EIGEN_HIP_DEVICE_COMPILE)
   #define EIGEN_MAKE_ALIGNED_OPERATOR_NEW_NOTHROW(NeedsToAlign) \
+      EIGEN_DEVICE_FUNC \
       void* operator new(std::size_t size, const std::nothrow_t&) EIGEN_NO_THROW { \
         EIGEN_TRY { return Eigen::internal::conditional_aligned_malloc<NeedsToAlign>(size); } \
         EIGEN_CATCH (...) { return 0; } \
       }
   #define EIGEN_MAKE_ALIGNED_OPERATOR_NEW_IF(NeedsToAlign) \
+      EIGEN_DEVICE_FUNC \
       void *operator new(std::size_t size) { \
         return Eigen::internal::conditional_aligned_malloc<NeedsToAlign>(size); \
       } \
+      EIGEN_DEVICE_FUNC \
       void *operator new[](std::size_t size) { \
         return Eigen::internal::conditional_aligned_malloc<NeedsToAlign>(size); \
       } \
+      EIGEN_DEVICE_FUNC \
       void operator delete(void * ptr) EIGEN_NO_THROW { Eigen::internal::conditional_aligned_free<NeedsToAlign>(ptr); } \
+      EIGEN_DEVICE_FUNC \
       void operator delete[](void * ptr) EIGEN_NO_THROW { Eigen::internal::conditional_aligned_free<NeedsToAlign>(ptr); } \
+      EIGEN_DEVICE_FUNC \
       void operator delete(void * ptr, std::size_t /* sz */) EIGEN_NO_THROW { Eigen::internal::conditional_aligned_free<NeedsToAlign>(ptr); } \
+      EIGEN_DEVICE_FUNC \
       void operator delete[](void * ptr, std::size_t /* sz */) EIGEN_NO_THROW { Eigen::internal::conditional_aligned_free<NeedsToAlign>(ptr); } \
       /* in-place new and delete. since (at least afaik) there is no actual   */ \
       /* memory allocated we can safely let the default implementation handle */ \
       /* this particular case. */ \
+      EIGEN_DEVICE_FUNC \
       static void *operator new(std::size_t size, void *ptr) { return ::operator new(size,ptr); } \
+      EIGEN_DEVICE_FUNC \
       static void *operator new[](std::size_t size, void* ptr) { return ::operator new[](size,ptr); } \
+      EIGEN_DEVICE_FUNC \
       void operator delete(void * memory, void *ptr) EIGEN_NO_THROW { return ::operator delete(memory,ptr); } \
+      EIGEN_DEVICE_FUNC \
       void operator delete[](void * memory, void *ptr) EIGEN_NO_THROW { return ::operator delete[](memory,ptr); } \
       /* nothrow-new (returns zero instead of std::bad_alloc) */ \
       EIGEN_MAKE_ALIGNED_OPERATOR_NEW_NOTHROW(NeedsToAlign) \
+      EIGEN_DEVICE_FUNC \
       void operator delete(void *ptr, const std::nothrow_t&) EIGEN_NO_THROW { \
         Eigen::internal::conditional_aligned_free<NeedsToAlign>(ptr); \
       } \
       typedef void eigen_aligned_operator_new_marker_type;
 #else
   #define EIGEN_MAKE_ALIGNED_OPERATOR_NEW_IF(NeedsToAlign)
 #endif
@@ -1043,28 +1068,40 @@
   l3 *= 1024;
 }
 
 inline void queryCacheSizes_intel(int& l1, int& l2, int& l3, int max_std_funcs)
 {
   if(max_std_funcs>=4)
     queryCacheSizes_intel_direct(l1,l2,l3);
-  else
+  else if(max_std_funcs>=2)
     queryCacheSizes_intel_codes(l1,l2,l3);
+  else
+    l1 = l2 = l3 = 0;
 }
 
 inline void queryCacheSizes_amd(int& l1, int& l2, int& l3)
 {
   int abcd[4];
   abcd[0] = abcd[1] = abcd[2] = abcd[3] = 0;
-  EIGEN_CPUID(abcd,0x80000005,0);
-  l1 = (abcd[2] >> 24) * 1024; // C[31:24] = L1 size in KB
-  abcd[0] = abcd[1] = abcd[2] = abcd[3] = 0;
-  EIGEN_CPUID(abcd,0x80000006,0);
-  l2 = (abcd[2] >> 16) * 1024; // C[31;16] = l2 cache size in KB
-  l3 = ((abcd[3] & 0xFFFC000) >> 18) * 512 * 1024; // D[31;18] = l3 cache size in 512KB
+  
+  // First query the max supported function.
+  EIGEN_CPUID(abcd,0x80000000,0);
+  if(static_cast<numext::uint32_t>(abcd[0]) >= static_cast<numext::uint32_t>(0x80000006))
+  {
+    EIGEN_CPUID(abcd,0x80000005,0);
+    l1 = (abcd[2] >> 24) * 1024; // C[31:24] = L1 size in KB
+    abcd[0] = abcd[1] = abcd[2] = abcd[3] = 0;
+    EIGEN_CPUID(abcd,0x80000006,0);
+    l2 = (abcd[2] >> 16) * 1024; // C[31;16] = l2 cache size in KB
+    l3 = ((abcd[3] & 0xFFFC000) >> 18) * 512 * 1024; // D[31;18] = l3 cache size in 512KB
+  }
+  else
+  {
+    l1 = l2 = l3 = 0;
+  }
 }
 #endif
 
 /** \internal
  * Queries and returns the cache sizes in Bytes of the L1, L2, and L3 data caches respectively */
 inline void queryCacheSizes(int& l1, int& l2, int& l3)
 {
@@ -1072,15 +1109,15 @@
   int abcd[4];
   const int GenuineIntel[] = {0x756e6547, 0x49656e69, 0x6c65746e};
   const int AuthenticAMD[] = {0x68747541, 0x69746e65, 0x444d4163};
   const int AMDisbetter_[] = {0x69444d41, 0x74656273, 0x21726574}; // "AMDisbetter!"
 
   // identify the CPU vendor
   EIGEN_CPUID(abcd,0x0,0);
-  int max_std_funcs = abcd[1];
+  int max_std_funcs = abcd[0];
   if(cpuid_is_vendor(abcd,GenuineIntel))
     queryCacheSizes_intel(l1,l2,l3,max_std_funcs);
   else if(cpuid_is_vendor(abcd,AuthenticAMD) || cpuid_is_vendor(abcd,AMDisbetter_))
     queryCacheSizes_amd(l1,l2,l3);
   else
     // by default let's use Intel's API
     queryCacheSizes_intel(l1,l2,l3,max_std_funcs);
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/util/Meta.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/util/Meta.h`

 * *Files 25% similar despite different names*

```diff
@@ -21,16 +21,48 @@
 
  #if defined(EIGEN_HIP_DEVICE_COMPILE)
   #include "Eigen/src/Core/arch/HIP/hcc/math_constants.h"
   #endif
 
 #endif
 
-#if EIGEN_COMP_ICC>=1600 &&  __cplusplus >= 201103L
+// Recent versions of ICC require <cstdint> for pointer types below.
+#define EIGEN_ICC_NEEDS_CSTDINT (EIGEN_COMP_ICC>=1600 && EIGEN_COMP_CXXVER >= 11)
+
+// Define portable (u)int{32,64} types
+#if EIGEN_HAS_CXX11 || EIGEN_ICC_NEEDS_CSTDINT
 #include <cstdint>
+namespace Eigen {
+namespace numext {
+typedef std::uint8_t  uint8_t;
+typedef std::int8_t   int8_t;
+typedef std::uint16_t uint16_t;
+typedef std::int16_t  int16_t;
+typedef std::uint32_t uint32_t;
+typedef std::int32_t  int32_t;
+typedef std::uint64_t uint64_t;
+typedef std::int64_t  int64_t;
+}
+}
+#else
+// Without c++11, all compilers able to compile Eigen also
+// provide the C99 stdint.h header file.
+#include <stdint.h>
+namespace Eigen {
+namespace numext {
+typedef ::uint8_t  uint8_t;
+typedef ::int8_t   int8_t;
+typedef ::uint16_t uint16_t;
+typedef ::int16_t  int16_t;
+typedef ::uint32_t uint32_t;
+typedef ::int32_t  int32_t;
+typedef ::uint64_t uint64_t;
+typedef ::int64_t  int64_t;
+}
+}
 #endif
 
 namespace Eigen {
 
 typedef EIGEN_DEFAULT_DENSE_INDEX_TYPE DenseIndex;
 
 /**
@@ -48,21 +80,22 @@
   * This file contains generic metaprogramming classes which are not specifically related to Eigen.
   * \note In case you wonder, yes we're aware that Boost already provides all these features,
   * we however don't want to add a dependency to Boost.
   */
 
 // Only recent versions of ICC complain about using ptrdiff_t to hold pointers,
 // and older versions do not provide *intptr_t types.
-#if EIGEN_COMP_ICC>=1600 &&  __cplusplus >= 201103L
+#if EIGEN_ICC_NEEDS_CSTDINT
 typedef std::intptr_t  IntPtr;
 typedef std::uintptr_t UIntPtr;
 #else
 typedef std::ptrdiff_t IntPtr;
 typedef std::size_t UIntPtr;
 #endif
+#undef EIGEN_ICC_NEEDS_CSTDINT
 
 struct true_type {  enum { value = 1 }; };
 struct false_type { enum { value = 0 }; };
 
 template<bool Condition>
 struct bool_constant;
 
@@ -156,14 +189,24 @@
 template<> struct make_unsigned<unsigned int>     { typedef unsigned int type; };
 template<> struct make_unsigned<signed long>      { typedef unsigned long type; };
 template<> struct make_unsigned<unsigned long>    { typedef unsigned long type; };
 #if EIGEN_COMP_MSVC
 template<> struct make_unsigned<signed __int64>   { typedef unsigned __int64 type; };
 template<> struct make_unsigned<unsigned __int64> { typedef unsigned __int64 type; };
 #endif
+
+// Some platforms define int64_t as `long long` even for C++03, where
+// `long long` is not guaranteed by the standard. In this case we are missing
+// the definition for make_unsigned. If we just define it, we run into issues
+// where `long long` doesn't exist in some compilers for C++03. We therefore add
+// the specialization for these platforms only.
+#if EIGEN_OS_MAC || EIGEN_COMP_MINGW
+template<> struct make_unsigned<unsigned long long> { typedef unsigned long long type; };
+template<> struct make_unsigned<long long>          { typedef unsigned long long type; };
+#endif
 #endif
 
 template <typename T> struct add_const { typedef const T type; };
 template <typename T> struct add_const<T&> { typedef T& type; };
 
 template <typename T> struct is_const { enum { value = 0 }; };
 template <typename T> struct is_const<T const> { enum { value = 1 }; };
@@ -228,44 +271,44 @@
   * according to a compile time condition.
   */
 template<bool Condition, typename T=void> struct enable_if;
 
 template<typename T> struct enable_if<true,T>
 { typedef T type; };
 
-#if defined(EIGEN_GPU_COMPILE_PHASE)
+#if defined(EIGEN_GPU_COMPILE_PHASE) && !EIGEN_HAS_CXX11
 #if !defined(__FLT_EPSILON__)
 #define __FLT_EPSILON__ FLT_EPSILON
 #define __DBL_EPSILON__ DBL_EPSILON
 #endif
 
 namespace device {
 
 template<typename T> struct numeric_limits
 {
   EIGEN_DEVICE_FUNC
-  static T epsilon() { return 0; }
+  static EIGEN_CONSTEXPR T epsilon() { return 0; }
   static T (max)() { assert(false && "Highest not supported for this type"); }
   static T (min)() { assert(false && "Lowest not supported for this type"); }
   static T infinity() { assert(false && "Infinity not supported for this type"); }
   static T quiet_NaN() { assert(false && "quiet_NaN not supported for this type"); }
 };
 template<> struct numeric_limits<float>
 {
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static float epsilon() { return __FLT_EPSILON__; }
   EIGEN_DEVICE_FUNC
   static float (max)() {
   #if defined(EIGEN_CUDA_ARCH)
     return CUDART_MAX_NORMAL_F;
   #else
     return HIPRT_MAX_NORMAL_F;
   #endif
   }
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static float (min)() { return FLT_MIN; }
   EIGEN_DEVICE_FUNC
   static float infinity() {
   #if defined(EIGEN_CUDA_ARCH)
     return CUDART_INF_F;
   #else
     return HIPRT_INF_F;
@@ -278,19 +321,19 @@
   #else
     return HIPRT_NAN_F;
   #endif
   }
 };
 template<> struct numeric_limits<double>
 {
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static double epsilon() { return __DBL_EPSILON__; }
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static double (max)() { return DBL_MAX; }
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static double (min)() { return DBL_MIN; }
   EIGEN_DEVICE_FUNC
   static double infinity() {
   #if defined(EIGEN_CUDA_ARCH)
     return CUDART_INF;
   #else
     return HIPRT_INF;
@@ -303,79 +346,79 @@
   #else
     return HIPRT_NAN;
   #endif
   }
 };
 template<> struct numeric_limits<int>
 {
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static int epsilon() { return 0; }
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static int (max)() { return INT_MAX; }
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static int (min)() { return INT_MIN; }
 };
 template<> struct numeric_limits<unsigned int>
 {
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static unsigned int epsilon() { return 0; }
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static unsigned int (max)() { return UINT_MAX; }
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static unsigned int (min)() { return 0; }
 };
 template<> struct numeric_limits<long>
 {
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static long epsilon() { return 0; }
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static long (max)() { return LONG_MAX; }
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static long (min)() { return LONG_MIN; }
 };
 template<> struct numeric_limits<unsigned long>
 {
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static unsigned long epsilon() { return 0; }
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static unsigned long (max)() { return ULONG_MAX; }
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static unsigned long (min)() { return 0; }
 };
 template<> struct numeric_limits<long long>
 {
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static long long epsilon() { return 0; }
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static long long (max)() { return LLONG_MAX; }
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static long long (min)() { return LLONG_MIN; }
 };
 template<> struct numeric_limits<unsigned long long>
 {
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static unsigned long long epsilon() { return 0; }
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static unsigned long long (max)() { return ULLONG_MAX; }
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static unsigned long long (min)() { return 0; }
 };
 template<> struct numeric_limits<bool>
 {
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static bool epsilon() { return false; }
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static bool (max)() { return true; }
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR 
   static bool (min)() { return false; }
 };
 
 }
 
-#endif
+#endif // defined(EIGEN_GPU_COMPILE_PHASE) && !EIGEN_HAS_CXX11
 
 /** \internal
   * A base class do disable default copy ctor and copy assignment operator.
   */
 class noncopyable
 {
   EIGEN_DEVICE_FUNC noncopyable(const noncopyable&);
@@ -429,38 +472,76 @@
   *
   * It currently supports:
   *  - any types T defining a member T::size() const
   *  - plain C arrays as T[N]
   *
   */
 template<typename T>
-Index size(const T& x) { return x.size(); }
+EIGEN_CONSTEXPR Index size(const T& x) { return x.size(); }
 
 template<typename T,std::size_t N>
-Index size(const T (&) [N]) { return N; }
+EIGEN_CONSTEXPR Index size(const T (&) [N]) { return N; }
 
 /** \internal
-  * Convenient struct to get the result type of a unary or binary functor.
-  *
-  * It supports both the current STL mechanism (using the result_type member) as well as
-  * upcoming next STL generation (using a templated result member).
-  * If none of these members is provided, then the type of the first argument is returned. FIXME, that behavior is a pretty bad hack.
+  * Convenient struct to get the result type of a nullary, unary, binary, or
+  * ternary functor.
+  * 
+  * Pre C++11:
+  * Supports both a Func::result_type member and templated
+  * Func::result<Func(ArgTypes...)>::type member.
+  * 
+  * If none of these members is provided, then the type of the first
+  * argument is returned.
+  * 
+  * Post C++11:
+  * This uses std::result_of. However, note the `type` member removes
+  * const and converts references/pointers to their corresponding value type.
   */
-#if EIGEN_HAS_STD_RESULT_OF
+#if EIGEN_HAS_STD_INVOKE_RESULT
+template<typename T> struct result_of;
+
+template<typename F, typename... ArgTypes>
+struct result_of<F(ArgTypes...)> {
+  typedef typename std::invoke_result<F, ArgTypes...>::type type1;
+  typedef typename remove_all<type1>::type type;
+};
+#elif EIGEN_HAS_STD_RESULT_OF
 template<typename T> struct result_of {
   typedef typename std::result_of<T>::type type1;
   typedef typename remove_all<type1>::type type;
 };
 #else
 template<typename T> struct result_of { };
 
 struct has_none {int a[1];};
 struct has_std_result_type {int a[2];};
 struct has_tr1_result {int a[3];};
 
+template<typename Func, int SizeOf>
+struct nullary_result_of_select {};
+
+template<typename Func>
+struct nullary_result_of_select<Func, sizeof(has_std_result_type)> {typedef typename Func::result_type type;};
+
+template<typename Func>
+struct nullary_result_of_select<Func, sizeof(has_tr1_result)> {typedef typename Func::template result<Func()>::type type;};
+
+template<typename Func>
+struct result_of<Func()> {
+    template<typename T>
+    static has_std_result_type    testFunctor(T const *, typename T::result_type const * = 0);
+    template<typename T>
+    static has_tr1_result         testFunctor(T const *, typename T::template result<T()>::type const * = 0);
+    static has_none               testFunctor(...);
+
+    // note that the following indirection is needed for gcc-3.3
+    enum {FunctorType = sizeof(testFunctor(static_cast<Func*>(0)))};
+    typedef typename nullary_result_of_select<Func, FunctorType>::type type;
+};
+
 template<typename Func, typename ArgType, int SizeOf=sizeof(has_none)>
 struct unary_result_of_select {typedef typename internal::remove_all<ArgType>::type type;};
 
 template<typename Func, typename ArgType>
 struct unary_result_of_select<Func, ArgType, sizeof(has_std_result_type)> {typedef typename Func::result_type type;};
 
 template<typename Func, typename ArgType>
@@ -522,14 +603,53 @@
     static has_tr1_result         testFunctor(T const *, typename T::template result<T(ArgType0,ArgType1,ArgType2)>::type const * = 0);
     static has_none               testFunctor(...);
 
     // note that the following indirection is needed for gcc-3.3
     enum {FunctorType = sizeof(testFunctor(static_cast<Func*>(0)))};
     typedef typename ternary_result_of_select<Func, ArgType0, ArgType1, ArgType2, FunctorType>::type type;
 };
+
+#endif
+
+#if EIGEN_HAS_STD_INVOKE_RESULT
+template<typename F, typename... ArgTypes>
+struct invoke_result {
+  typedef typename std::invoke_result<F, ArgTypes...>::type type1;
+  typedef typename remove_all<type1>::type type;
+};
+#elif EIGEN_HAS_CXX11
+template<typename F, typename... ArgTypes>
+struct invoke_result {
+  typedef typename result_of<F(ArgTypes...)>::type type1;
+  typedef typename remove_all<type1>::type type;
+};
+#else
+template<typename F, typename ArgType0 = void, typename ArgType1 = void, typename ArgType2 = void>
+struct invoke_result {
+  typedef typename result_of<F(ArgType0, ArgType1, ArgType2)>::type type1;
+  typedef typename remove_all<type1>::type type;
+};
+
+template<typename F>
+struct invoke_result<F, void, void, void> {
+  typedef typename result_of<F()>::type type1;
+  typedef typename remove_all<type1>::type type;
+};
+
+template<typename F, typename ArgType0>
+struct invoke_result<F, ArgType0, void, void> {
+  typedef typename result_of<F(ArgType0)>::type type1;
+  typedef typename remove_all<type1>::type type;
+};
+
+template<typename F, typename ArgType0, typename ArgType1>
+struct invoke_result<F, ArgType0, ArgType1, void> {
+  typedef typename result_of<F(ArgType0, ArgType1)>::type type1;
+  typedef typename remove_all<type1>::type type;
+};
 #endif
 
 struct meta_yes { char a[1]; };
 struct meta_no  { char a[2]; };
 
 // Check whether T::ReturnType does exist
 template <typename T>
@@ -591,28 +711,33 @@
 };
 
 template<int Y, int InfX, int SupX>
 class meta_sqrt<Y, InfX, SupX, true> { public:  enum { ret = (SupX*SupX <= Y) ? SupX : InfX }; };
 
 
 /** \internal Computes the least common multiple of two positive integer A and B
-  * at compile-time. It implements a naive algorithm testing all multiples of A.
-  * It thus works better if A>=B.
+  * at compile-time. 
   */
-template<int A, int B, int K=1, bool Done = ((A*K)%B)==0>
+template<int A, int B, int K=1, bool Done = ((A*K)%B)==0, bool Big=(A>=B)>
 struct meta_least_common_multiple
 {
   enum { ret = meta_least_common_multiple<A,B,K+1>::ret };
 };
+template<int A, int B, int K, bool Done>
+struct meta_least_common_multiple<A,B,K,Done,false>
+{
+  enum { ret = meta_least_common_multiple<B,A,K>::ret };
+};
 template<int A, int B, int K>
-struct meta_least_common_multiple<A,B,K,true>
+struct meta_least_common_multiple<A,B,K,true,true>
 {
   enum { ret = A*K };
 };
 
+
 /** \internal determines whether the product of two numeric types is allowed and what the return type is */
 template<typename T, typename U> struct scalar_product_traits
 {
   enum { Defined = 0 };
 };
 
 // FIXME quick workaround around current limitation of result_of
@@ -637,15 +762,15 @@
 
 #if defined(EIGEN_GPU_COMPILE_PHASE)
 template<typename T> EIGEN_DEVICE_FUNC   void swap(T &a, T &b) { T tmp = b; b = a; a = tmp; }
 #else
 template<typename T> EIGEN_STRONG_INLINE void swap(T &a, T &b) { std::swap(a,b); }
 #endif
 
-#if defined(EIGEN_GPU_COMPILE_PHASE)
+#if defined(EIGEN_GPU_COMPILE_PHASE) && !EIGEN_HAS_CXX11
 using internal::device::numeric_limits;
 #else
 using std::numeric_limits;
 #endif
 
 // Integer division with rounding up.
 // T is assumed to be an integer type with a>=0, and b>0
@@ -676,54 +801,12 @@
 template<> EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC
 bool not_equal_strict(const float& x,const float& y) { return std::not_equal_to<float>()(x,y); }
 
 template<> EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC
 bool not_equal_strict(const double& x,const double& y) { return std::not_equal_to<double>()(x,y); }
 #endif
 
-/** \internal extract the bits of the float \a x */
-EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC unsigned int as_uint(float x)
-{
-  unsigned int ret;
-  EIGEN_USING_STD(memcpy);
-  memcpy(&ret, &x, sizeof(float));
-  return ret;
-}
-
 } // end namespace numext
 
 } // end namespace Eigen
 
-// Define portable (u)int{32,64} types
-#if EIGEN_HAS_CXX11
-#include <cstdint>
-namespace Eigen {
-namespace numext {
-typedef std::uint8_t  uint8_t;
-typedef std::int8_t   int8_t;
-typedef std::uint16_t uint16_t;
-typedef std::int16_t  int16_t;
-typedef std::uint32_t uint32_t;
-typedef std::int32_t  int32_t;
-typedef std::uint64_t uint64_t;
-typedef std::int64_t  int64_t;
-}
-}
-#else
-// Without c++11, all compilers able to compile Eigen also
-// provides the C99 stdint.h header file.
-#include <stdint.h>
-namespace Eigen {
-namespace numext {
-typedef ::uint8_t  uint8_t;
-typedef ::int8_t   int8_t;
-typedef ::uint16_t uint16_t;
-typedef ::int16_t  int16_t;
-typedef ::uint32_t uint32_t;
-typedef ::int32_t  int32_t;
-typedef ::uint64_t uint64_t;
-typedef ::int64_t  int64_t;
-}
-}
-#endif
-
 #endif // EIGEN_META_H
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/util/ReenableStupidWarnings.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/util/ReenableStupidWarnings.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/util/ReshapedHelper.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/util/ReshapedHelper.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/util/StaticAssert.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/util/StaticAssert.h`

 * *Files 1% similar despite different names*

```diff
@@ -23,15 +23,15 @@
  *  - currently EIGEN_STATIC_ASSERT can only be used in function scope
  *
  */
 
 #ifndef EIGEN_STATIC_ASSERT
 #ifndef EIGEN_NO_STATIC_ASSERT
 
-  #if EIGEN_MAX_CPP_VER>=11 && (__has_feature(cxx_static_assert) || (defined(__cplusplus) && __cplusplus >= 201103L) || (EIGEN_COMP_MSVC >= 1600))
+  #if EIGEN_MAX_CPP_VER>=11 && (__has_feature(cxx_static_assert) || (EIGEN_COMP_CXXVER >= 11) || (EIGEN_COMP_MSVC >= 1600))
 
     // if native static_assert is enabled, let's use it
     #define EIGEN_STATIC_ASSERT(X,MSG) static_assert(X,#MSG);
 
   #else // not CXX0X
 
     namespace Eigen {
@@ -101,15 +101,16 @@
         MATRIX_FREE_CONJUGATE_GRADIENT_IS_COMPATIBLE_WITH_UPPER_UNION_LOWER_MODE_ONLY=1,
         THIS_TYPE_IS_NOT_SUPPORTED=1,
         STORAGE_KIND_MUST_MATCH=1,
         STORAGE_INDEX_MUST_MATCH=1,
         CHOLMOD_SUPPORTS_DOUBLE_PRECISION_ONLY=1,
         SELFADJOINTVIEW_ACCEPTS_UPPER_AND_LOWER_MODE_ONLY=1,
         INVALID_TEMPLATE_PARAMETER=1,
-        GPU_TENSOR_CONTRACTION_DOES_NOT_SUPPORT_OUTPUT_KERNELS=1
+        GPU_TENSOR_CONTRACTION_DOES_NOT_SUPPORT_OUTPUT_KERNELS=1,
+        THE_ARRAY_SIZE_SHOULD_EQUAL_WITH_PACKET_SIZE=1
       };
     };
 
     } // end namespace internal
 
     } // end namespace Eigen
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/util/SymbolicIndex.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/util/SymbolicIndex.h`

 * *Files 1% similar despite different names*

```diff
@@ -61,15 +61,15 @@
 // Specialization for compile-time value,
 // It is similar to ValueExpr(N) but this version helps the compiler to generate better code.
 template<int N>
 class ValueExpr<internal::FixedInt<N> > {
 public:
   ValueExpr() {}
   template<typename T>
-  Index eval_impl(const T&) const { return N; }
+  EIGEN_CONSTEXPR Index eval_impl(const T&) const { return N; }
 };
 
 
 /** \class BaseExpr
   * \ingroup Core_Module
   * Common base class of any symbolic expressions
   */
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Core/util/XprHelper.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Core/util/XprHelper.h`

 * *Files 0% similar despite different names*

```diff
@@ -125,41 +125,45 @@
 /** \internal If the template parameter Value is Dynamic, this class is just a wrapper around a T variable that
   * can be accessed using value() and setValue().
   * Otherwise, this class is an empty structure and value() just returns the template parameter Value.
   */
 template<typename T, int Value> class variable_if_dynamic
 {
   public:
-    EIGEN_EMPTY_STRUCT_CTOR(variable_if_dynamic)
+    EIGEN_DEFAULT_EMPTY_CONSTRUCTOR_AND_DESTRUCTOR(variable_if_dynamic)
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit variable_if_dynamic(T v) { EIGEN_ONLY_USED_FOR_DEBUG(v); eigen_assert(v == T(Value)); }
-    EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE T value() { return T(Value); }
-    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE operator T() const { return T(Value); }
-    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void setValue(T) {}
+    EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    T value() { return T(Value); }
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    operator T() const { return T(Value); }
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
+    void setValue(T v) const { EIGEN_ONLY_USED_FOR_DEBUG(v); eigen_assert(v == T(Value)); }
 };
 
 template<typename T> class variable_if_dynamic<T, Dynamic>
 {
     T m_value;
-    EIGEN_DEVICE_FUNC variable_if_dynamic() { eigen_assert(false); }
   public:
-    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit variable_if_dynamic(T value) : m_value(value) {}
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit variable_if_dynamic(T value = 0) EIGEN_NO_THROW : m_value(value) {}
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE T value() const { return m_value; }
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE operator T() const { return m_value; }
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void setValue(T value) { m_value = value; }
 };
 
 /** \internal like variable_if_dynamic but for DynamicIndex
   */
 template<typename T, int Value> class variable_if_dynamicindex
 {
   public:
     EIGEN_EMPTY_STRUCT_CTOR(variable_if_dynamicindex)
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit variable_if_dynamicindex(T v) { EIGEN_ONLY_USED_FOR_DEBUG(v); eigen_assert(v == T(Value)); }
-    EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE T value() { return T(Value); }
-    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void setValue(T) {}
+    EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    T value() { return T(Value); }
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
+    void setValue(T) {}
 };
 
 template<typename T> class variable_if_dynamicindex<T, DynamicIndex>
 {
     T m_value;
     EIGEN_DEVICE_FUNC variable_if_dynamicindex() { eigen_assert(false); }
   public:
@@ -176,27 +180,15 @@
     PacketAccess = false,
     IsRepeatable = false
   };
 };
 
 template<typename T> struct packet_traits;
 
-template<typename T> struct unpacket_traits
-{
-  typedef T type;
-  typedef T half;
-  enum
-  {
-    size = 1,
-    alignment = 1,
-    vectorizable = false,
-    masked_load_available=false,
-    masked_store_available=false
-  };
-};
+template<typename T> struct unpacket_traits;
 
 template<int Size, typename PacketType,
          bool Stop = Size==Dynamic || (Size%unpacket_traits<PacketType>::size)==0 || is_same<PacketType,typename unpacket_traits<PacketType>::half>::value>
 struct find_best_packet_helper;
 
 template< int Size, typename PacketType>
 struct find_best_packet_helper<Size,PacketType,true>
@@ -424,15 +416,15 @@
 struct ref_selector
 {
   typedef typename conditional<
     bool(traits<T>::Flags & NestByRefBit),
     T const&,
     const T
   >::type type;
-  
+
   typedef typename conditional<
     bool(traits<T>::Flags & NestByRefBit),
     T &,
     T
   >::type non_const_type;
 };
 
@@ -603,37 +595,37 @@
 /** \internal gives the plain matrix or array type to store a row/column/diagonal of a matrix type.
   * \tparam Scalar optional parameter allowing to pass a different scalar type than the one of the MatrixType.
   */
 template<typename ExpressionType, typename Scalar = typename ExpressionType::Scalar>
 struct plain_row_type
 {
   typedef Matrix<Scalar, 1, ExpressionType::ColsAtCompileTime,
-                 ExpressionType::PlainObject::Options | RowMajor, 1, ExpressionType::MaxColsAtCompileTime> MatrixRowType;
+                 int(ExpressionType::PlainObject::Options) | int(RowMajor), 1, ExpressionType::MaxColsAtCompileTime> MatrixRowType;
   typedef Array<Scalar, 1, ExpressionType::ColsAtCompileTime,
-                 ExpressionType::PlainObject::Options | RowMajor, 1, ExpressionType::MaxColsAtCompileTime> ArrayRowType;
+                 int(ExpressionType::PlainObject::Options) | int(RowMajor), 1, ExpressionType::MaxColsAtCompileTime> ArrayRowType;
 
   typedef typename conditional<
     is_same< typename traits<ExpressionType>::XprKind, MatrixXpr >::value,
     MatrixRowType,
-    ArrayRowType 
+    ArrayRowType
   >::type type;
 };
 
 template<typename ExpressionType, typename Scalar = typename ExpressionType::Scalar>
 struct plain_col_type
 {
   typedef Matrix<Scalar, ExpressionType::RowsAtCompileTime, 1,
                  ExpressionType::PlainObject::Options & ~RowMajor, ExpressionType::MaxRowsAtCompileTime, 1> MatrixColType;
   typedef Array<Scalar, ExpressionType::RowsAtCompileTime, 1,
                  ExpressionType::PlainObject::Options & ~RowMajor, ExpressionType::MaxRowsAtCompileTime, 1> ArrayColType;
 
   typedef typename conditional<
     is_same< typename traits<ExpressionType>::XprKind, MatrixXpr >::value,
     MatrixColType,
-    ArrayColType 
+    ArrayColType
   >::type type;
 };
 
 template<typename ExpressionType, typename Scalar = typename ExpressionType::Scalar>
 struct plain_diag_type
 {
   enum { diag_size = EIGEN_SIZE_MIN_PREFER_DYNAMIC(ExpressionType::RowsAtCompileTime, ExpressionType::ColsAtCompileTime),
@@ -641,15 +633,15 @@
   };
   typedef Matrix<Scalar, diag_size, 1, ExpressionType::PlainObject::Options & ~RowMajor, max_diag_size, 1> MatrixDiagType;
   typedef Array<Scalar, diag_size, 1, ExpressionType::PlainObject::Options & ~RowMajor, max_diag_size, 1> ArrayDiagType;
 
   typedef typename conditional<
     is_same< typename traits<ExpressionType>::XprKind, MatrixXpr >::value,
     MatrixDiagType,
-    ArrayDiagType 
+    ArrayDiagType
   >::type type;
 };
 
 template<typename Expr,typename Scalar = typename Expr::Scalar>
 struct plain_constant_type
 {
   enum { Options = (traits<Expr>::Flags&RowMajorBit)?RowMajor:0 };
@@ -757,15 +749,15 @@
   if(f&RowMajorBit)                 res += " | RowMajor";
   if(f&PacketAccessBit)             res += " | Packet";
   if(f&LinearAccessBit)             res += " | Linear";
   if(f&LvalueBit)                   res += " | Lvalue";
   if(f&DirectAccessBit)             res += " | Direct";
   if(f&NestByRefBit)                res += " | NestByRef";
   if(f&NoPreferredStorageOrderBit)  res += " | NoPreferredStorageOrderBit";
-  
+
   return res;
 }
 #endif
 
 } // end namespace internal
 
 
@@ -854,11 +846,11 @@
 // We require Lhs and Rhs to have "compatible" scalar types.
 // It is tempting to always allow mixing different types but remember that this is often impossible in the vectorized paths.
 // So allowing mixing different types gives very unexpected errors when enabling vectorization, when the user tries to
 // add together a float matrix and a double matrix.
 #define EIGEN_CHECK_BINARY_COMPATIBILIY(BINOP,LHS,RHS) \
   EIGEN_STATIC_ASSERT((Eigen::internal::has_ReturnType<ScalarBinaryOpTraits<LHS, RHS,BINOP> >::value), \
     YOU_MIXED_DIFFERENT_NUMERIC_TYPES__YOU_NEED_TO_USE_THE_CAST_METHOD_OF_MATRIXBASE_TO_CAST_NUMERIC_TYPES_EXPLICITLY)
-    
+
 } // end namespace Eigen
 
 #endif // EIGEN_XPRHELPER_H
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Eigenvalues/ComplexEigenSolver.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Eigenvalues/ComplexEigenSolver.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Eigenvalues/ComplexSchur.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Eigenvalues/ComplexSchur.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Eigenvalues/ComplexSchur_LAPACKE.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Eigenvalues/ComplexSchur_LAPACKE.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Eigenvalues/EigenSolver.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Eigenvalues/EigenSolver.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Eigenvalues/GeneralizedEigenSolver.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Eigenvalues/GeneralizedEigenSolver.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Eigenvalues/GeneralizedSelfAdjointEigenSolver.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Eigenvalues/GeneralizedSelfAdjointEigenSolver.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Eigenvalues/HessenbergDecomposition.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Eigenvalues/HessenbergDecomposition.h`

 * *Files 0% similar despite different names*

```diff
@@ -263,15 +263,15 @@
     {
       eigen_assert(m_isInitialized && "HessenbergDecomposition is not initialized.");
       return MatrixHReturnType(*this);
     }
 
   private:
 
-    typedef Matrix<Scalar, 1, Size, Options | RowMajor, 1, MaxSize> VectorType;
+    typedef Matrix<Scalar, 1, Size, int(Options) | int(RowMajor), 1, MaxSize> VectorType;
     typedef typename NumTraits<Scalar>::Real RealScalar;
     static void _compute(MatrixType& matA, CoeffVectorType& hCoeffs, VectorType& temp);
 
   protected:
     MatrixType m_matrix;
     CoeffVectorType m_hCoeffs;
     VectorType m_temp;
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Eigenvalues/MatrixBaseEigenvalues.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Eigenvalues/MatrixBaseEigenvalues.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Eigenvalues/RealQZ.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Eigenvalues/RealQZ.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Eigenvalues/RealSchur.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Eigenvalues/RealSchur.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Eigenvalues/RealSchur_LAPACKE.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Eigenvalues/RealSchur_LAPACKE.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h`

 * *Files 2% similar despite different names*

```diff
@@ -40,18 +40,22 @@
   * A matrix \f$ A \f$ is selfadjoint if it equals its adjoint. For real
   * matrices, this means that the matrix is symmetric: it equals its
   * transpose. This class computes the eigenvalues and eigenvectors of a
   * selfadjoint matrix. These are the scalars \f$ \lambda \f$ and vectors
   * \f$ v \f$ such that \f$ Av = \lambda v \f$.  The eigenvalues of a
   * selfadjoint matrix are always real. If \f$ D \f$ is a diagonal matrix with
   * the eigenvalues on the diagonal, and \f$ V \f$ is a matrix with the
-  * eigenvectors as its columns, then \f$ A = V D V^{-1} \f$ (for selfadjoint
-  * matrices, the matrix \f$ V \f$ is always invertible). This is called the
+  * eigenvectors as its columns, then \f$ A = V D V^{-1} \f$. This is called the
   * eigendecomposition.
   *
+  * For a selfadjoint matrix, \f$ V \f$ is unitary, meaning its inverse is equal
+  * to its adjoint, \f$ V^{-1} = V^{\dagger} \f$. If \f$ A \f$ is real, then
+  * \f$ V \f$ is also real and therefore orthogonal, meaning its inverse is
+  * equal to its transpose, \f$ V^{-1} = V^T \f$.
+  *
   * The algorithm exploits the fact that the matrix is selfadjoint, making it
   * faster and more accurate than the general purpose eigenvalue algorithms
   * implemented in EigenSolver and ComplexEigenSolver.
   *
   * Only the \b lower \b triangular \b part of the input matrix is referenced.
   *
   * Call the function compute() to compute the eigenvalues and eigenvectors of
@@ -117,14 +121,15 @@
       * Output: \verbinclude SelfAdjointEigenSolver_SelfAdjointEigenSolver.out
       */
     EIGEN_DEVICE_FUNC
     SelfAdjointEigenSolver()
         : m_eivec(),
           m_eivalues(),
           m_subdiag(),
+          m_hcoeffs(),
           m_info(InvalidInput),
           m_isInitialized(false),
           m_eigenvectorsOk(false)
     { }
 
     /** \brief Constructor, pre-allocates memory for dynamic-size matrices.
       *
@@ -139,14 +144,15 @@
       * \sa compute() for an example
       */
     EIGEN_DEVICE_FUNC
     explicit SelfAdjointEigenSolver(Index size)
         : m_eivec(size, size),
           m_eivalues(size),
           m_subdiag(size > 1 ? size - 1 : 1),
+          m_hcoeffs(size > 1 ? size - 1 : 1),
           m_isInitialized(false),
           m_eigenvectorsOk(false)
     {}
 
     /** \brief Constructor; computes eigendecomposition of given matrix.
       *
       * \param[in]  matrix  Selfadjoint matrix whose eigendecomposition is to
@@ -164,14 +170,15 @@
       */
     template<typename InputType>
     EIGEN_DEVICE_FUNC
     explicit SelfAdjointEigenSolver(const EigenBase<InputType>& matrix, int options = ComputeEigenvectors)
       : m_eivec(matrix.rows(), matrix.cols()),
         m_eivalues(matrix.cols()),
         m_subdiag(matrix.rows() > 1 ? matrix.rows() - 1 : 1),
+        m_hcoeffs(matrix.cols() > 1 ? matrix.cols() - 1 : 1),
         m_isInitialized(false),
         m_eigenvectorsOk(false)
     {
       compute(matrix.derived(), options);
     }
 
     /** \brief Computes eigendecomposition of given matrix.
@@ -252,14 +259,19 @@
       * Column \f$ k \f$ of the returned matrix is an eigenvector corresponding
       * to eigenvalue number \f$ k \f$ as returned by eigenvalues().  The
       * eigenvectors are normalized to have (Euclidean) norm equal to one. If
       * this object was used to solve the eigenproblem for the selfadjoint
       * matrix \f$ A \f$, then the matrix returned by this function is the
       * matrix \f$ V \f$ in the eigendecomposition \f$ A = V D V^{-1} \f$.
       *
+      * For a selfadjoint matrix, \f$ V \f$ is unitary, meaning its inverse is equal
+      * to its adjoint, \f$ V^{-1} = V^{\dagger} \f$. If \f$ A \f$ is real, then
+      * \f$ V \f$ is also real and therefore orthogonal, meaning its inverse is
+      * equal to its transpose, \f$ V^{-1} = V^T \f$.
+      *
       * Example: \include SelfAdjointEigenSolver_eigenvectors.cpp
       * Output: \verbinclude SelfAdjointEigenSolver_eigenvectors.out
       *
       * \sa eigenvalues()
       */
     EIGEN_DEVICE_FUNC
     const EigenvectorsType& eigenvectors() const
@@ -365,14 +377,15 @@
     {
       EIGEN_STATIC_ASSERT_NON_INTEGER(Scalar);
     }
     
     EigenvectorsType m_eivec;
     RealVectorType m_eivalues;
     typename TridiagonalizationType::SubDiagonalType m_subdiag;
+    typename TridiagonalizationType::CoeffVectorType m_hcoeffs;
     ComputationInfo m_info;
     bool m_isInitialized;
     bool m_eigenvectorsOk;
 };
 
 namespace internal {
 /** \internal
@@ -406,15 +419,15 @@
 SelfAdjointEigenSolver<MatrixType>& SelfAdjointEigenSolver<MatrixType>
 ::compute(const EigenBase<InputType>& a_matrix, int options)
 {
   check_template_parameters();
   
   const InputType &matrix(a_matrix.derived());
   
-  EIGEN_USING_STD_MATH(abs);
+  EIGEN_USING_STD(abs);
   eigen_assert(matrix.cols() == matrix.rows());
   eigen_assert((options&~(EigVecMask|GenEigMask))==0
           && (options&EigVecMask)!=EigVecMask
           && "invalid option parameter");
   bool computeEigenvectors = (options&ComputeEigenvectors)==ComputeEigenvectors;
   Index n = matrix.cols();
   m_eivalues.resize(n,1);
@@ -437,15 +450,16 @@
 
   // map the matrix coefficients to [-1:1] to avoid over- and underflow.
   mat = matrix.template triangularView<Lower>();
   RealScalar scale = mat.cwiseAbs().maxCoeff();
   if(scale==RealScalar(0)) scale = RealScalar(1);
   mat.template triangularView<Lower>() /= scale;
   m_subdiag.resize(n-1);
-  internal::tridiagonalization_inplace(mat, diag, m_subdiag, computeEigenvectors);
+  m_hcoeffs.resize(n-1);
+  internal::tridiagonalization_inplace(mat, diag, m_subdiag, m_hcoeffs, computeEigenvectors);
 
   m_info = internal::computeFromTridiagonal_impl(diag, m_subdiag, m_maxIterations, computeEigenvectors, m_eivec);
   
   // scale back the eigen values
   m_eivalues *= scale;
 
   m_isInitialized = true;
@@ -485,35 +499,41 @@
   * \param[out] eivec : The matrix to store the eigenvectors if computeEigenvectors==true. Must be allocated on input.
   * \returns \c Success or \c NoConvergence
   */
 template<typename MatrixType, typename DiagType, typename SubDiagType>
 EIGEN_DEVICE_FUNC
 ComputationInfo computeFromTridiagonal_impl(DiagType& diag, SubDiagType& subdiag, const Index maxIterations, bool computeEigenvectors, MatrixType& eivec)
 {
-  EIGEN_USING_STD_MATH(abs);
-
   ComputationInfo info;
   typedef typename MatrixType::Scalar Scalar;
 
   Index n = diag.size();
   Index end = n-1;
   Index start = 0;
   Index iter = 0; // total number of iterations
   
   typedef typename DiagType::RealScalar RealScalar;
   const RealScalar considerAsZero = (std::numeric_limits<RealScalar>::min)();
-  const RealScalar precision = RealScalar(2)*NumTraits<RealScalar>::epsilon();
-  
+  const RealScalar precision_inv = RealScalar(1)/NumTraits<RealScalar>::epsilon();
   while (end>0)
   {
-    for (Index i = start; i<end; ++i)
-      if (internal::isMuchSmallerThan(abs(subdiag[i]),(abs(diag[i])+abs(diag[i+1])),precision) || abs(subdiag[i]) <= considerAsZero)
-        subdiag[i] = 0;
+    for (Index i = start; i<end; ++i) {
+      if (numext::abs(subdiag[i]) < considerAsZero) {
+        subdiag[i] = RealScalar(0);
+      } else {
+        // abs(subdiag[i]) <= epsilon * sqrt(abs(diag[i]) + abs(diag[i+1]))
+        // Scaled to prevent underflows.
+        const RealScalar scaled_subdiag = precision_inv * subdiag[i];
+        if (scaled_subdiag * scaled_subdiag <= (numext::abs(diag[i])+numext::abs(diag[i+1]))) {
+          subdiag[i] = RealScalar(0);
+        }
+      }
+    }
 
-    // find the largest unreduced block
+    // find the largest unreduced block at the end of the matrix.
     while (end>0 && subdiag[end-1]==RealScalar(0))
     {
       end--;
     }
     if (end<=0)
       break;
 
@@ -570,18 +590,18 @@
   /** \internal
    * Computes the roots of the characteristic polynomial of \a m.
    * For numerical stability m.trace() should be near zero and to avoid over- or underflow m should be normalized.
    */
   EIGEN_DEVICE_FUNC
   static inline void computeRoots(const MatrixType& m, VectorType& roots)
   {
-    EIGEN_USING_STD_MATH(sqrt)
-    EIGEN_USING_STD_MATH(atan2)
-    EIGEN_USING_STD_MATH(cos)
-    EIGEN_USING_STD_MATH(sin)
+    EIGEN_USING_STD(sqrt)
+    EIGEN_USING_STD(atan2)
+    EIGEN_USING_STD(cos)
+    EIGEN_USING_STD(sin)
     const Scalar s_inv3 = Scalar(1)/Scalar(3);
     const Scalar s_sqrt3 = sqrt(Scalar(3));
 
     // The characteristic equation is x^3 - c2*x^2 + c1*x - c0 = 0.  The
     // eigenvalues are the roots to this equation, all guaranteed to be
     // real-valued, because the matrix is symmetric.
     Scalar c0 = m(0,0)*m(1,1)*m(2,2) + Scalar(2)*m(1,0)*m(2,0)*m(2,1) - m(0,0)*m(2,1)*m(2,1) - m(1,1)*m(2,0)*m(2,0) - m(2,2)*m(1,0)*m(1,0);
@@ -609,16 +629,16 @@
     roots(1) = c2_over_3 - rho*(cos_theta - s_sqrt3*sin_theta); // == 2*rho*cos(theta+ pi/3)
     roots(2) = c2_over_3 + Scalar(2)*rho*cos_theta;
   }
 
   EIGEN_DEVICE_FUNC
   static inline bool extract_kernel(MatrixType& mat, Ref<VectorType> res, Ref<VectorType> representative)
   {
-    EIGEN_USING_STD_MATH(abs);
-    EIGEN_USING_STD_MATH(sqrt);
+    EIGEN_USING_STD(abs);
+    EIGEN_USING_STD(sqrt);
     Index i0;
     // Find non-zero column i0 (by construction, there must exist a non zero coefficient on the diagonal):
     mat.diagonal().cwiseAbs().maxCoeff(&i0);
     // mat.col(i0) is a good candidate for an orthogonal vector to the current eigenvector,
     // so let's save it:
     representative = mat.col(i0);
     Scalar n0, n1;
@@ -724,26 +744,26 @@
   typedef typename SolverType::RealVectorType VectorType;
   typedef typename SolverType::Scalar Scalar;
   typedef typename SolverType::EigenvectorsType EigenvectorsType;
   
   EIGEN_DEVICE_FUNC
   static inline void computeRoots(const MatrixType& m, VectorType& roots)
   {
-    EIGEN_USING_STD_MATH(sqrt);
+    EIGEN_USING_STD(sqrt);
     const Scalar t0 = Scalar(0.5) * sqrt( numext::abs2(m(0,0)-m(1,1)) + Scalar(4)*numext::abs2(m(1,0)));
     const Scalar t1 = Scalar(0.5) * (m(0,0) + m(1,1));
     roots(0) = t1 - t0;
     roots(1) = t1 + t0;
   }
   
   EIGEN_DEVICE_FUNC
   static inline void run(SolverType& solver, const MatrixType& mat, int options)
   {
-    EIGEN_USING_STD_MATH(sqrt);
-    EIGEN_USING_STD_MATH(abs);
+    EIGEN_USING_STD(sqrt);
+    EIGEN_USING_STD(abs);
     
     eigen_assert(mat.cols() == 2 && mat.cols() == mat.rows());
     eigen_assert((options&~(EigVecMask|GenEigMask))==0
             && (options&EigVecMask)!=EigVecMask
             && "invalid option parameter");
     bool computeEigenvectors = (options&ComputeEigenvectors)==ComputeEigenvectors;
     
@@ -808,58 +828,63 @@
 ::computeDirect(const MatrixType& matrix, int options)
 {
   internal::direct_selfadjoint_eigenvalues<SelfAdjointEigenSolver,Size,NumTraits<Scalar>::IsComplex>::run(*this,matrix,options);
   return *this;
 }
 
 namespace internal {
+
+// Francis implicit QR step.
 template<int StorageOrder,typename RealScalar, typename Scalar, typename Index>
 EIGEN_DEVICE_FUNC
 static void tridiagonal_qr_step(RealScalar* diag, RealScalar* subdiag, Index start, Index end, Scalar* matrixQ, Index n)
 {
-  EIGEN_USING_STD_MATH(abs);
+  // Wilkinson Shift.
   RealScalar td = (diag[end-1] - diag[end])*RealScalar(0.5);
   RealScalar e = subdiag[end-1];
   // Note that thanks to scaling, e^2 or td^2 cannot overflow, however they can still
   // underflow thus leading to inf/NaN values when using the following commented code:
-//   RealScalar e2 = numext::abs2(subdiag[end-1]);
-//   RealScalar mu = diag[end] - e2 / (td + (td>0 ? 1 : -1) * sqrt(td*td + e2));
+  //   RealScalar e2 = numext::abs2(subdiag[end-1]);
+  //   RealScalar mu = diag[end] - e2 / (td + (td>0 ? 1 : -1) * sqrt(td*td + e2));
   // This explain the following, somewhat more complicated, version:
   RealScalar mu = diag[end];
-  if(td==RealScalar(0))
-    mu -= abs(e);
-  else
-  {
-    RealScalar e2 = numext::abs2(subdiag[end-1]);
-    RealScalar h = numext::hypot(td,e);
-    if(e2==RealScalar(0)) mu -= (e / (td + (td>RealScalar(0) ? RealScalar(1) : RealScalar(-1)))) * (e / h);
-    else                  mu -= e2 / (td + (td>RealScalar(0) ? h : -h));
+  if(td==RealScalar(0)) {
+    mu -= numext::abs(e);
+  } else if (e != RealScalar(0)) {
+    const RealScalar e2 = numext::abs2(e);
+    const RealScalar h = numext::hypot(td,e);
+    if(e2 == RealScalar(0)) {
+      mu -= e / ((td + (td>RealScalar(0) ? h : -h)) / e);
+    } else {
+      mu -= e2 / (td + (td>RealScalar(0) ? h : -h)); 
+    }
   }
-  
+
   RealScalar x = diag[start] - mu;
   RealScalar z = subdiag[start];
-  for (Index k = start; k < end; ++k)
+  // If z ever becomes zero, the Givens rotation will be the identity and
+  // z will stay zero for all future iterations.
+  for (Index k = start; k < end && z != RealScalar(0); ++k)
   {
     JacobiRotation<RealScalar> rot;
     rot.makeGivens(x, z);
 
     // do T = G' T G
     RealScalar sdk = rot.s() * diag[k] + rot.c() * subdiag[k];
     RealScalar dkp1 = rot.s() * subdiag[k] + rot.c() * diag[k+1];
 
     diag[k] = rot.c() * (rot.c() * diag[k] - rot.s() * subdiag[k]) - rot.s() * (rot.c() * subdiag[k] - rot.s() * diag[k+1]);
     diag[k+1] = rot.s() * sdk + rot.c() * dkp1;
     subdiag[k] = rot.c() * sdk - rot.s() * dkp1;
     
-
     if (k > start)
       subdiag[k - 1] = rot.c() * subdiag[k-1] - rot.s() * z;
 
+    // "Chasing the bulge" to return to triangular form.
     x = subdiag[k];
-
     if (k < end - 1)
     {
       z = -rot.s() * subdiag[k+1];
       subdiag[k + 1] = rot.c() * subdiag[k+1];
     }
     
     // apply the givens rotation to the unit matrix Q = Q * G
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Eigenvalues/SelfAdjointEigenSolver_LAPACKE.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Eigenvalues/SelfAdjointEigenSolver_LAPACKE.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Eigenvalues/Tridiagonalization.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Eigenvalues/Tridiagonalization.h`

 * *Files 1% similar despite different names*

```diff
@@ -7,18 +7,18 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_TRIDIAGONALIZATION_H
 #define EIGEN_TRIDIAGONALIZATION_H
 
-namespace Eigen { 
+namespace Eigen {
 
 namespace internal {
-  
+
 template<typename MatrixType> struct TridiagonalizationMatrixTReturnType;
 template<typename MatrixType>
 struct traits<TridiagonalizationMatrixTReturnType<MatrixType> >
   : public traits<typename MatrixType::PlainObject>
 {
   typedef typename MatrixType::PlainObject ReturnType; // FIXME shall it be a BandMatrix?
   enum { Flags = 0 };
@@ -350,15 +350,15 @@
 {
   using numext::conj;
   typedef typename MatrixType::Scalar Scalar;
   typedef typename MatrixType::RealScalar RealScalar;
   Index n = matA.rows();
   eigen_assert(n==matA.cols());
   eigen_assert(n==hCoeffs.size()+1 || n==1);
-  
+
   for (Index i = 0; i<n-1; ++i)
   {
     Index remainingSize = n-i-1;
     RealScalar beta;
     Scalar h;
     matA.col(i).tail(remainingSize).makeHouseholderInPlace(h, beta);
 
@@ -421,36 +421,36 @@
   * Example (this uses the same matrix as the example in
   *    Tridiagonalization::Tridiagonalization(const MatrixType&)):
   *    \include Tridiagonalization_decomposeInPlace.cpp
   * Output: \verbinclude Tridiagonalization_decomposeInPlace.out
   *
   * \sa class Tridiagonalization
   */
-template<typename MatrixType, typename DiagonalType, typename SubDiagonalType>
+template<typename MatrixType, typename DiagonalType, typename SubDiagonalType, typename CoeffVectorType>
 EIGEN_DEVICE_FUNC
-void tridiagonalization_inplace(MatrixType& mat, DiagonalType& diag, SubDiagonalType& subdiag, bool extractQ)
+void tridiagonalization_inplace(MatrixType& mat, DiagonalType& diag, SubDiagonalType& subdiag,
+                                CoeffVectorType& hcoeffs, bool extractQ)
 {
   eigen_assert(mat.cols()==mat.rows() && diag.size()==mat.rows() && subdiag.size()==mat.rows()-1);
-  tridiagonalization_inplace_selector<MatrixType>::run(mat, diag, subdiag, extractQ);
+  tridiagonalization_inplace_selector<MatrixType>::run(mat, diag, subdiag, hcoeffs, extractQ);
 }
 
 /** \internal
   * General full tridiagonalization
   */
 template<typename MatrixType, int Size, bool IsComplex>
 struct tridiagonalization_inplace_selector
 {
   typedef typename Tridiagonalization<MatrixType>::CoeffVectorType CoeffVectorType;
   typedef typename Tridiagonalization<MatrixType>::HouseholderSequenceType HouseholderSequenceType;
   template<typename DiagonalType, typename SubDiagonalType>
   static EIGEN_DEVICE_FUNC
-  void run(MatrixType& mat, DiagonalType& diag, SubDiagonalType& subdiag, bool extractQ)
+      void run(MatrixType& mat, DiagonalType& diag, SubDiagonalType& subdiag, CoeffVectorType& hCoeffs, bool extractQ)
   {
-    CoeffVectorType hCoeffs(mat.cols()-1);
-    tridiagonalization_inplace(mat,hCoeffs);
+    tridiagonalization_inplace(mat, hCoeffs);
     diag = mat.diagonal().real();
     subdiag = mat.template diagonal<-1>().real();
     if(extractQ)
       mat = HouseholderSequenceType(mat, hCoeffs.conjugate())
             .setLength(mat.rows() - 1)
             .setShift(1);
   }
@@ -462,16 +462,16 @@
   */
 template<typename MatrixType>
 struct tridiagonalization_inplace_selector<MatrixType,3,false>
 {
   typedef typename MatrixType::Scalar Scalar;
   typedef typename MatrixType::RealScalar RealScalar;
 
-  template<typename DiagonalType, typename SubDiagonalType>
-  static void run(MatrixType& mat, DiagonalType& diag, SubDiagonalType& subdiag, bool extractQ)
+  template<typename DiagonalType, typename SubDiagonalType, typename CoeffVectorType>
+  static void run(MatrixType& mat, DiagonalType& diag, SubDiagonalType& subdiag, CoeffVectorType&, bool extractQ)
   {
     using std::sqrt;
     const RealScalar tol = (std::numeric_limits<RealScalar>::min)();
     diag[0] = mat(0,0);
     RealScalar v1norm2 = numext::abs2(mat(2,0));
     if(v1norm2 <= tol)
     {
@@ -507,17 +507,17 @@
   * Trivial specialization for 1x1 matrices
   */
 template<typename MatrixType, bool IsComplex>
 struct tridiagonalization_inplace_selector<MatrixType,1,IsComplex>
 {
   typedef typename MatrixType::Scalar Scalar;
 
-  template<typename DiagonalType, typename SubDiagonalType>
+  template<typename DiagonalType, typename SubDiagonalType, typename CoeffVectorType>
   static EIGEN_DEVICE_FUNC
-  void run(MatrixType& mat, DiagonalType& diag, SubDiagonalType&, bool extractQ)
+  void run(MatrixType& mat, DiagonalType& diag, SubDiagonalType&, CoeffVectorType&, bool extractQ)
   {
     diag(0,0) = numext::real(mat(0,0));
     if(extractQ)
       mat(0,0) = Scalar(1);
   }
 };
 
@@ -543,16 +543,16 @@
     {
       result.setZero();
       result.template diagonal<1>() = m_matrix.template diagonal<-1>().conjugate();
       result.diagonal() = m_matrix.diagonal();
       result.template diagonal<-1>() = m_matrix.template diagonal<-1>();
     }
 
-    Index rows() const { return m_matrix.rows(); }
-    Index cols() const { return m_matrix.cols(); }
+    EIGEN_CONSTEXPR Index rows() const EIGEN_NOEXCEPT { return m_matrix.rows(); }
+    EIGEN_CONSTEXPR Index cols() const EIGEN_NOEXCEPT { return m_matrix.cols(); }
 
   protected:
     typename MatrixType::Nested m_matrix;
 };
 
 } // end namespace internal
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Geometry/AlignedBox.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Geometry/AlignedBox.h`

 * *Files 23% similar despite different names*

```diff
@@ -3,18 +3,54 @@
 //
 // Copyright (C) 2008 Gael Guennebaud <gael.guennebaud@inria.fr>
 //
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
+// Function void Eigen::AlignedBox::transform(const Transform& transform)
+// is provided under the following license agreement:
+//
+// Software License Agreement (BSD License)
+//
+// Copyright (c) 2011-2014, Willow Garage, Inc.
+// Copyright (c) 2014-2015, Open Source Robotics Foundation
+// All rights reserved.
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions
+// are met:
+//
+//  * Redistributions of source code must retain the above copyright
+//    notice, this list of conditions and the following disclaimer.
+//  * Redistributions in binary form must reproduce the above
+//    copyright notice, this list of conditions and the following
+//    disclaimer in the documentation and/or other materials provided
+//    with the distribution.
+//  * Neither the name of Open Source Robotics Foundation nor the names of its
+//    contributors may be used to endorse or promote products derived
+//    from this software without specific prior written permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+// "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+// FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
+// COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
+// INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,
+// BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+// LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+// CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+// LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN
+// ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
+// POSSIBILITY OF SUCH DAMAGE.
+
 #ifndef EIGEN_ALIGNEDBOX_H
 #define EIGEN_ALIGNEDBOX_H
 
-namespace Eigen { 
+namespace Eigen {
 
 /** \geometry_module \ingroup Geometry_Module
   *
   *
   * \class AlignedBox
   *
   * \brief An axis aligned box
@@ -227,29 +263,38 @@
   /** Returns an AlignedBox that is the intersection of \a b and \c *this
    * \note If the boxes don't intersect, the resulting box is empty.
    * \sa intersects(), clamp, contains()  */
   EIGEN_DEVICE_FUNC inline AlignedBox intersection(const AlignedBox& b) const
   {return AlignedBox(m_min.cwiseMax(b.m_min), m_max.cwiseMin(b.m_max)); }
 
   /** Returns an AlignedBox that is the union of \a b and \c *this.
-   * \note Merging with an empty box may result in a box bigger than \c *this. 
+   * \note Merging with an empty box may result in a box bigger than \c *this.
    * \sa extend(const AlignedBox&) */
   EIGEN_DEVICE_FUNC inline AlignedBox merged(const AlignedBox& b) const
   { return AlignedBox(m_min.cwiseMin(b.m_min), m_max.cwiseMax(b.m_max)); }
 
   /** Translate \c *this by the vector \a t and returns a reference to \c *this. */
   template<typename Derived>
   EIGEN_DEVICE_FUNC inline AlignedBox& translate(const MatrixBase<Derived>& a_t)
   {
     const typename internal::nested_eval<Derived,2>::type t(a_t.derived());
     m_min += t;
     m_max += t;
     return *this;
   }
 
+  /** \returns a copy of \c *this translated by the vector \a t. */
+  template<typename Derived>
+  EIGEN_DEVICE_FUNC inline AlignedBox translated(const MatrixBase<Derived>& a_t) const
+  {
+    AlignedBox result(m_min, m_max);
+    result.translate(a_t);
+    return result;
+  }
+
   /** \returns the squared distance between the point \a p and the box \c *this,
     * and zero if \a p is inside the box.
     * \sa exteriorDistance(const MatrixBase&), squaredExteriorDistance(const AlignedBox&)
     */
   template<typename Derived>
   EIGEN_DEVICE_FUNC inline Scalar squaredExteriorDistance(const MatrixBase<Derived>& p) const;
 
@@ -261,22 +306,71 @@
 
   /** \returns the distance between the point \a p and the box \c *this,
     * and zero if \a p is inside the box.
     * \sa squaredExteriorDistance(const MatrixBase&), exteriorDistance(const AlignedBox&)
     */
   template<typename Derived>
   EIGEN_DEVICE_FUNC inline NonInteger exteriorDistance(const MatrixBase<Derived>& p) const
-  { EIGEN_USING_STD_MATH(sqrt) return sqrt(NonInteger(squaredExteriorDistance(p))); }
+  { EIGEN_USING_STD(sqrt) return sqrt(NonInteger(squaredExteriorDistance(p))); }
 
   /** \returns the distance between the boxes \a b and \c *this,
     * and zero if the boxes intersect.
     * \sa squaredExteriorDistance(const AlignedBox&), exteriorDistance(const MatrixBase&)
     */
   EIGEN_DEVICE_FUNC inline NonInteger exteriorDistance(const AlignedBox& b) const
-  { EIGEN_USING_STD_MATH(sqrt) return sqrt(NonInteger(squaredExteriorDistance(b))); }
+  { EIGEN_USING_STD(sqrt) return sqrt(NonInteger(squaredExteriorDistance(b))); }
+
+  /**
+   * Specialization of transform for pure translation.
+   */
+  template<int Mode, int Options>
+  EIGEN_DEVICE_FUNC inline void transform(
+      const typename Transform<Scalar, AmbientDimAtCompileTime, Mode, Options>::TranslationType& translation)
+  {
+    this->translate(translation);
+  }
+
+  /**
+   * Transforms this box by \a transform and recomputes it to
+   * still be an axis-aligned box.
+   *
+   * \note This method is provided under BSD license (see the top of this file).
+   */
+  template<int Mode, int Options>
+  EIGEN_DEVICE_FUNC inline void transform(const Transform<Scalar, AmbientDimAtCompileTime, Mode, Options>& transform)
+  {
+    // Only Affine and Isometry transforms are currently supported.
+    EIGEN_STATIC_ASSERT(Mode == Affine || Mode == AffineCompact || Mode == Isometry, THIS_METHOD_IS_ONLY_FOR_SPECIFIC_TRANSFORMATIONS);
+
+    // Method adapted from FCL src/shape/geometric_shapes_utility.cpp#computeBV<AABB, Box>(...)
+    // https://github.com/flexible-collision-library/fcl/blob/fcl-0.4/src/shape/geometric_shapes_utility.cpp#L292
+    //
+    // Here's a nice explanation why it works: https://zeuxcg.org/2010/10/17/aabb-from-obb-with-component-wise-abs/
+
+    // two times rotated extent
+    const VectorType rotated_extent_2 = transform.linear().cwiseAbs() * sizes();
+    // two times new center
+    const VectorType rotated_center_2 = transform.linear() * (this->m_max + this->m_min) +
+        Scalar(2) * transform.translation();
+
+    this->m_max = (rotated_center_2 + rotated_extent_2) / Scalar(2);
+    this->m_min = (rotated_center_2 - rotated_extent_2) / Scalar(2);
+  }
+
+  /**
+   * \returns a copy of \c *this transformed by \a transform and recomputed to
+   * still be an axis-aligned box.
+   */
+  template<int Mode, int Options>
+  EIGEN_DEVICE_FUNC AlignedBox transformed(const Transform<Scalar, AmbientDimAtCompileTime, Mode, Options>& transform) const
+  {
+    AlignedBox result(m_min, m_max);
+    result.transform(transform);
+    return result;
+  }
 
   /** \returns \c *this with scalar type casted to \a NewScalarType
     *
     * Note that if \a NewScalarType is equal to the current scalar type of \c *this
     * then this function smartly returns a const reference to \c *this.
     */
   template<typename NewScalarType>
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Geometry/AngleAxis.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Geometry/AngleAxis.h`

 * *Files 1% similar despite different names*

```diff
@@ -165,16 +165,16 @@
   * 
   * This function implicitly normalizes the quaternion \a q.
   */
 template<typename Scalar>
 template<typename QuatDerived>
 EIGEN_DEVICE_FUNC AngleAxis<Scalar>& AngleAxis<Scalar>::operator=(const QuaternionBase<QuatDerived>& q)
 {
-  EIGEN_USING_STD_MATH(atan2)
-  EIGEN_USING_STD_MATH(abs)
+  EIGEN_USING_STD(atan2)
+  EIGEN_USING_STD(abs)
   Scalar n = q.vec().norm();
   if(n<NumTraits<Scalar>::epsilon())
     n = q.vec().stableNorm();
 
   if (n != Scalar(0))
   {
     m_angle = Scalar(2)*atan2(n, abs(q.w()));
@@ -213,16 +213,16 @@
 
 /** Constructs and \returns an equivalent 3x3 rotation matrix.
   */
 template<typename Scalar>
 typename AngleAxis<Scalar>::Matrix3
 EIGEN_DEVICE_FUNC AngleAxis<Scalar>::toRotationMatrix(void) const
 {
-  EIGEN_USING_STD_MATH(sin)
-  EIGEN_USING_STD_MATH(cos)
+  EIGEN_USING_STD(sin)
+  EIGEN_USING_STD(cos)
   Matrix3 res;
   Vector3 sin_axis  = sin(m_angle) * m_axis;
   Scalar c = cos(m_angle);
   Vector3 cos1_axis = (Scalar(1)-c) * m_axis;
 
   Scalar tmp;
   tmp = cos1_axis.x() * m_axis.y();
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Geometry/EulerAngles.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Geometry/EulerAngles.h`

 * *Files 1% similar despite different names*

```diff
@@ -32,17 +32,17 @@
   * 
   * \sa class AngleAxis
   */
 template<typename Derived>
 EIGEN_DEVICE_FUNC inline Matrix<typename MatrixBase<Derived>::Scalar,3,1>
 MatrixBase<Derived>::eulerAngles(Index a0, Index a1, Index a2) const
 {
-  EIGEN_USING_STD_MATH(atan2)
-  EIGEN_USING_STD_MATH(sin)
-  EIGEN_USING_STD_MATH(cos)
+  EIGEN_USING_STD(atan2)
+  EIGEN_USING_STD(sin)
+  EIGEN_USING_STD(cos)
   /* Implemented from Graphics Gems IV */
   EIGEN_STATIC_ASSERT_MATRIX_SPECIFIC_SIZE(Derived,3,3)
 
   Matrix<Scalar,3,1> res;
   typedef Matrix<typename Derived::Scalar,2,1> Vector2;
 
   const Index odd = ((a0+1)%3 == a1) ? 0 : 1;
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Geometry/Homogeneous.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Geometry/Homogeneous.h`

 * *Files 2% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_HOMOGENEOUS_H
 #define EIGEN_HOMOGENEOUS_H
 
-namespace Eigen { 
+namespace Eigen {
 
 /** \geometry_module \ingroup Geometry_Module
   *
   * \class Homogeneous
   *
   * \brief Expression of one (or a set of) homogeneous vector(s)
   *
@@ -68,17 +68,19 @@
     typedef MatrixBase<Homogeneous> Base;
     EIGEN_DENSE_PUBLIC_INTERFACE(Homogeneous)
 
     EIGEN_DEVICE_FUNC explicit inline Homogeneous(const MatrixType& matrix)
       : m_matrix(matrix)
     {}
 
-    EIGEN_DEVICE_FUNC inline Index rows() const { return m_matrix.rows() + (int(Direction)==Vertical   ? 1 : 0); }
-    EIGEN_DEVICE_FUNC inline Index cols() const { return m_matrix.cols() + (int(Direction)==Horizontal ? 1 : 0); }
-    
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index rows() const EIGEN_NOEXCEPT { return m_matrix.rows() + (int(Direction)==Vertical   ? 1 : 0); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index cols() const EIGEN_NOEXCEPT { return m_matrix.cols() + (int(Direction)==Horizontal ? 1 : 0); }
+
     EIGEN_DEVICE_FUNC const NestedExpression& nestedExpression() const { return m_matrix; }
 
     template<typename Rhs>
     EIGEN_DEVICE_FUNC inline const Product<Homogeneous,Rhs>
     operator* (const MatrixBase<Rhs>& rhs) const
     {
       eigen_assert(int(Direction)==Horizontal);
@@ -258,16 +260,18 @@
   typedef typename remove_all<LhsMatrixType>::type LhsMatrixTypeCleaned;
   typedef typename remove_all<typename LhsMatrixTypeCleaned::Nested>::type LhsMatrixTypeNested;
   EIGEN_DEVICE_FUNC homogeneous_left_product_impl(const Lhs& lhs, const MatrixType& rhs)
     : m_lhs(take_matrix_for_product<Lhs>::run(lhs)),
       m_rhs(rhs)
   {}
 
-  EIGEN_DEVICE_FUNC inline Index rows() const { return m_lhs.rows(); }
-  EIGEN_DEVICE_FUNC inline Index cols() const { return m_rhs.cols(); }
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+  inline Index rows() const EIGEN_NOEXCEPT { return m_lhs.rows(); }
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+  inline Index cols() const EIGEN_NOEXCEPT { return m_rhs.cols(); }
 
   template<typename Dest> EIGEN_DEVICE_FUNC void evalTo(Dest& dst) const
   {
     // FIXME investigate how to allow lazy evaluation of this product when possible
     dst = Block<const LhsMatrixTypeNested,
               LhsMatrixTypeNested::RowsAtCompileTime,
               LhsMatrixTypeNested::ColsAtCompileTime==Dynamic?Dynamic:LhsMatrixTypeNested::ColsAtCompileTime-1>
@@ -296,16 +300,16 @@
   : public ReturnByValue<homogeneous_right_product_impl<Homogeneous<MatrixType,Horizontal>,Rhs> >
 {
   typedef typename remove_all<typename Rhs::Nested>::type RhsNested;
   EIGEN_DEVICE_FUNC homogeneous_right_product_impl(const MatrixType& lhs, const Rhs& rhs)
     : m_lhs(lhs), m_rhs(rhs)
   {}
 
-  EIGEN_DEVICE_FUNC inline Index rows() const { return m_lhs.rows(); }
-  EIGEN_DEVICE_FUNC inline Index cols() const { return m_rhs.cols(); }
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index rows() const EIGEN_NOEXCEPT { return m_lhs.rows(); }
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index cols() const EIGEN_NOEXCEPT { return m_rhs.cols(); }
 
   template<typename Dest> EIGEN_DEVICE_FUNC void evalTo(Dest& dst) const
   {
     // FIXME investigate how to allow lazy evaluation of this product when possible
     dst = m_lhs * Block<const RhsNested,
                         RhsNested::RowsAtCompileTime==Dynamic?Dynamic:RhsNested::RowsAtCompileTime-1,
                         RhsNested::ColsAtCompileTime>
@@ -318,15 +322,15 @@
   typename Rhs::Nested m_rhs;
 };
 
 template<typename ArgType,int Direction>
 struct evaluator_traits<Homogeneous<ArgType,Direction> >
 {
   typedef typename storage_kind_to_evaluator_kind<typename ArgType::StorageKind>::Kind Kind;
-  typedef HomogeneousShape Shape;  
+  typedef HomogeneousShape Shape;
 };
 
 template<> struct AssignmentKind<DenseShape,HomogeneousShape> { typedef Dense2Dense Kind; };
 
 
 template<typename ArgType,int Direction>
 struct unary_evaluator<Homogeneous<ArgType,Direction>, IndexBased>
@@ -410,15 +414,15 @@
  : public evaluator<typename homogeneous_right_product_refactoring_helper<typename Lhs::NestedExpression,Rhs>::Xpr>
 {
   typedef Product<Lhs, Rhs, LazyProduct> XprType;
   typedef homogeneous_right_product_refactoring_helper<typename Lhs::NestedExpression,Rhs> helper;
   typedef typename helper::ConstantBlock ConstantBlock;
   typedef typename helper::Xpr RefactoredXpr;
   typedef evaluator<RefactoredXpr> Base;
-  
+
   EIGEN_DEVICE_FUNC explicit product_evaluator(const XprType& xpr)
     : Base(  xpr.lhs().nestedExpression() .lazyProduct(  xpr.rhs().template topRows<helper::Dim>(xpr.lhs().nestedExpression().cols()) )
             + ConstantBlock(xpr.rhs().row(xpr.rhs().rows()-1),xpr.lhs().rows(), 1) )
   {}
 };
 
 template<typename Lhs, typename RhsArg, int ProductTag>
@@ -463,15 +467,15 @@
  : public evaluator<typename homogeneous_left_product_refactoring_helper<Lhs,typename Rhs::NestedExpression>::Xpr>
 {
   typedef Product<Lhs, Rhs, LazyProduct> XprType;
   typedef homogeneous_left_product_refactoring_helper<Lhs,typename Rhs::NestedExpression> helper;
   typedef typename helper::ConstantBlock ConstantBlock;
   typedef typename helper::Xpr RefactoredXpr;
   typedef evaluator<RefactoredXpr> Base;
-  
+
   EIGEN_DEVICE_FUNC explicit product_evaluator(const XprType& xpr)
     : Base(   xpr.lhs().template leftCols<helper::Dim>(xpr.rhs().nestedExpression().rows()) .lazyProduct( xpr.rhs().nestedExpression() )
             + ConstantBlock(xpr.lhs().col(xpr.lhs().cols()-1),1,xpr.rhs().cols()) )
   {}
 };
 
 template<typename Scalar, int Dim, int Mode,int Options, typename RhsArg, int ProductTag>
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Geometry/Hyperplane.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Geometry/Hyperplane.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Geometry/OrthoMethods.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Geometry/OrthoMethods.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Geometry/ParametrizedLine.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Geometry/ParametrizedLine.h`

 * *Files 1% similar despite different names*

```diff
@@ -83,15 +83,15 @@
   {
     VectorType diff = p - origin();
     return (diff - direction().dot(diff) * direction()).squaredNorm();
   }
   /** \returns the distance of a point \a p to its projection onto the line \c *this.
     * \sa squaredDistance()
     */
-  EIGEN_DEVICE_FUNC RealScalar distance(const VectorType& p) const { EIGEN_USING_STD_MATH(sqrt) return sqrt(squaredDistance(p)); }
+  EIGEN_DEVICE_FUNC RealScalar distance(const VectorType& p) const { EIGEN_USING_STD(sqrt) return sqrt(squaredDistance(p)); }
 
   /** \returns the projection of a point \a p onto the line \c *this. */
   EIGEN_DEVICE_FUNC VectorType projection(const VectorType& p) const
   { return origin() + direction().dot(p-origin()) * direction(); }
 
   EIGEN_DEVICE_FUNC VectorType pointAt(const Scalar& t) const;
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Geometry/Quaternion.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Geometry/Quaternion.h`

 * *Files 2% similar despite different names*

```diff
@@ -137,15 +137,15 @@
     * \sa angularDistance()
     */
   template<class OtherDerived> EIGEN_DEVICE_FUNC inline Scalar dot(const QuaternionBase<OtherDerived>& other) const { return coeffs().dot(other.coeffs()); }
 
   template<class OtherDerived> EIGEN_DEVICE_FUNC Scalar angularDistance(const QuaternionBase<OtherDerived>& other) const;
 
   /** \returns an equivalent 3x3 rotation matrix */
-  EIGEN_DEVICE_FUNC Matrix3 toRotationMatrix() const;
+  EIGEN_DEVICE_FUNC inline Matrix3 toRotationMatrix() const;
 
   /** \returns the quaternion which transform \a a into \a b through a rotation */
   template<typename Derived1, typename Derived2>
   EIGEN_DEVICE_FUNC Derived& setFromTwoVectors(const MatrixBase<Derived1>& a, const MatrixBase<Derived2>& b);
 
   template<class OtherDerived> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Quaternion<Scalar> operator* (const QuaternionBase<OtherDerived>& q) const;
   template<class OtherDerived> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& operator*= (const QuaternionBase<OtherDerived>& q);
@@ -556,16 +556,16 @@
 }
 
 /** Set \c *this from an angle-axis \a aa and returns a reference to \c *this
   */
 template<class Derived>
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& QuaternionBase<Derived>::operator=(const AngleAxisType& aa)
 {
-  EIGEN_USING_STD_MATH(cos)
-  EIGEN_USING_STD_MATH(sin)
+  EIGEN_USING_STD(cos)
+  EIGEN_USING_STD(sin)
   Scalar ha = Scalar(0.5)*aa.angle(); // Scalar(0.5) to suppress precision loss warnings
   this->w() = cos(ha);
   this->vec() = sin(ha) * aa.axis();
   return derived();
 }
 
 /** Set \c *this from the expression \a xpr:
@@ -633,15 +633,15 @@
   * Note that the two input vectors do \b not have to be normalized, and
   * do not need to have the same norm.
   */
 template<class Derived>
 template<typename Derived1, typename Derived2>
 EIGEN_DEVICE_FUNC inline Derived& QuaternionBase<Derived>::setFromTwoVectors(const MatrixBase<Derived1>& a, const MatrixBase<Derived2>& b)
 {
-  EIGEN_USING_STD_MATH(sqrt)
+  EIGEN_USING_STD(sqrt)
   Vector3 v0 = a.normalized();
   Vector3 v1 = b.normalized();
   Scalar c = v1.dot(v0);
 
   // if dot == -1, vectors are nearly opposites
   // => accurately compute the rotation axis by computing the
   //    intersection of the two planes. This is done by solving:
@@ -674,17 +674,17 @@
 /** \returns a random unit quaternion following a uniform distribution law on SO(3)
   *
   * \note The implementation is based on http://planning.cs.uiuc.edu/node198.html
   */
 template<typename Scalar, int Options>
 EIGEN_DEVICE_FUNC Quaternion<Scalar,Options> Quaternion<Scalar,Options>::UnitRandom()
 {
-  EIGEN_USING_STD_MATH(sqrt)
-  EIGEN_USING_STD_MATH(sin)
-  EIGEN_USING_STD_MATH(cos)
+  EIGEN_USING_STD(sqrt)
+  EIGEN_USING_STD(sin)
+  EIGEN_USING_STD(cos)
   const Scalar u1 = internal::random<Scalar>(0, 1),
                u2 = internal::random<Scalar>(0, 2*EIGEN_PI),
                u3 = internal::random<Scalar>(0, 2*EIGEN_PI);
   const Scalar a = sqrt(Scalar(1) - u1),
                b = sqrt(u1);
   return Quaternion (a * sin(u2), a * cos(u2), b * sin(u3), b * cos(u3));
 }
@@ -759,15 +759,15 @@
   * \sa dot()
   */
 template <class Derived>
 template <class OtherDerived>
 EIGEN_DEVICE_FUNC inline typename internal::traits<Derived>::Scalar
 QuaternionBase<Derived>::angularDistance(const QuaternionBase<OtherDerived>& other) const
 {
-  EIGEN_USING_STD_MATH(atan2)
+  EIGEN_USING_STD(atan2)
   Quaternion<Scalar> d = (*this) * other.conjugate();
   return Scalar(2) * atan2( d.vec().norm(), numext::abs(d.w()) );
 }
 
  
     
 /** \returns the spherical linear interpolation between the two quaternions
@@ -777,16 +777,16 @@
   * see also http://en.wikipedia.org/wiki/Slerp.
   */
 template <class Derived>
 template <class OtherDerived>
 EIGEN_DEVICE_FUNC Quaternion<typename internal::traits<Derived>::Scalar>
 QuaternionBase<Derived>::slerp(const Scalar& t, const QuaternionBase<OtherDerived>& other) const
 {
-  EIGEN_USING_STD_MATH(acos)
-  EIGEN_USING_STD_MATH(sin)
+  EIGEN_USING_STD(acos)
+  EIGEN_USING_STD(sin)
   const Scalar one = Scalar(1) - NumTraits<Scalar>::epsilon();
   Scalar d = this->dot(other);
   Scalar absD = numext::abs(d);
 
   Scalar scale0;
   Scalar scale1;
 
@@ -815,15 +815,15 @@
 template<typename Other>
 struct quaternionbase_assign_impl<Other,3,3>
 {
   typedef typename Other::Scalar Scalar;
   template<class Derived> EIGEN_DEVICE_FUNC static inline void run(QuaternionBase<Derived>& q, const Other& a_mat)
   {
     const typename internal::nested_eval<Other,2>::type mat(a_mat);
-    EIGEN_USING_STD_MATH(sqrt)
+    EIGEN_USING_STD(sqrt)
     // This algorithm comes from  "Quaternion Calculus and Fast Animation",
     // Ken Shoemake, 1987 SIGGRAPH course notes
     Scalar t = mat.trace();
     if (t > Scalar(0))
     {
       t = sqrt(t + Scalar(1.0));
       q.w() = Scalar(0.5)*t;
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Geometry/Rotation2D.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Geometry/Rotation2D.h`

 * *Files 2% similar despite different names*

```diff
@@ -171,28 +171,28 @@
   * In other words, this function extract the rotation angle
   * from the rotation matrix.
   */
 template<typename Scalar>
 template<typename Derived>
 EIGEN_DEVICE_FUNC Rotation2D<Scalar>& Rotation2D<Scalar>::fromRotationMatrix(const MatrixBase<Derived>& mat)
 {
-  EIGEN_USING_STD_MATH(atan2)
+  EIGEN_USING_STD(atan2)
   EIGEN_STATIC_ASSERT(Derived::RowsAtCompileTime==2 && Derived::ColsAtCompileTime==2,YOU_MADE_A_PROGRAMMING_MISTAKE)
   m_angle = atan2(mat.coeff(1,0), mat.coeff(0,0));
   return *this;
 }
 
 /** Constructs and \returns an equivalent 2x2 rotation matrix.
   */
 template<typename Scalar>
 typename Rotation2D<Scalar>::Matrix2
 EIGEN_DEVICE_FUNC Rotation2D<Scalar>::toRotationMatrix(void) const
 {
-  EIGEN_USING_STD_MATH(sin)
-  EIGEN_USING_STD_MATH(cos)
+  EIGEN_USING_STD(sin)
+  EIGEN_USING_STD(cos)
   Scalar sinA = sin(m_angle);
   Scalar cosA = cos(m_angle);
   return (Matrix2() << cosA, -sinA, sinA, cosA).finished();
 }
 
 } // end namespace Eigen
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Geometry/RotationBase.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Geometry/RotationBase.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Geometry/Scaling.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Geometry/Scaling.h`

 * *Files 0% similar despite different names*

```diff
@@ -10,15 +10,15 @@
 #ifndef EIGEN_SCALING_H
 #define EIGEN_SCALING_H
 
 namespace Eigen { 
 
 /** \geometry_module \ingroup Geometry_Module
   *
-  * \class Scaling
+  * \class UniformScaling
   *
   * \brief Represents a generic uniform scaling transformation
   *
   * \tparam _Scalar the scalar type, i.e., the type of the coefficients.
   *
   * This class represent a uniform scaling transformation. It is the return
   * type of Scaling(Scalar), and most of the time this is the only way it
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Geometry/Transform.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Geometry/Transform.h`

 * *Files 1% similar despite different names*

```diff
@@ -8,15 +8,15 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_TRANSFORM_H
 #define EIGEN_TRANSFORM_H
 
-namespace Eigen { 
+namespace Eigen {
 
 namespace internal {
 
 template<typename Transform>
 struct transform_traits
 {
   enum
@@ -43,15 +43,15 @@
           int HDim,
           int OtherRows=Other::RowsAtCompileTime,
           int OtherCols=Other::ColsAtCompileTime>
 struct transform_left_product_impl;
 
 template< typename Lhs,
           typename Rhs,
-          bool AnyProjective = 
+          bool AnyProjective =
             transform_traits<Lhs>::IsProjective ||
             transform_traits<Rhs>::IsProjective>
 struct transform_transform_product_impl;
 
 template< typename Other,
           int Mode,
           int Options,
@@ -219,17 +219,17 @@
   /** type of the matrix used to represent the transformation */
   typedef typename internal::make_proper_matrix_type<Scalar,Rows,HDim,Options>::type MatrixType;
   /** constified MatrixType */
   typedef const MatrixType ConstMatrixType;
   /** type of the matrix used to represent the linear part of the transformation */
   typedef Matrix<Scalar,Dim,Dim,Options> LinearMatrixType;
   /** type of read/write reference to the linear part of the transformation */
-  typedef Block<MatrixType,Dim,Dim,int(Mode)==(AffineCompact) && (Options&RowMajor)==0> LinearPart;
+  typedef Block<MatrixType,Dim,Dim,int(Mode)==(AffineCompact) && (int(Options)&RowMajor)==0> LinearPart;
   /** type of read reference to the linear part of the transformation */
-  typedef const Block<ConstMatrixType,Dim,Dim,int(Mode)==(AffineCompact) && (Options&RowMajor)==0> ConstLinearPart;
+  typedef const Block<ConstMatrixType,Dim,Dim,int(Mode)==(AffineCompact) && (int(Options)&RowMajor)==0> ConstLinearPart;
   /** type of read/write reference to the affine part of the transformation */
   typedef typename internal::conditional<int(Mode)==int(AffineCompact),
                               MatrixType&,
                               Block<MatrixType,Dim,HDim> >::type AffinePart;
   /** type of read reference to the affine part of the transformation */
   typedef typename internal::conditional<int(Mode)==int(AffineCompact),
                               const MatrixType&,
@@ -238,15 +238,15 @@
   typedef Matrix<Scalar,Dim,1> VectorType;
   /** type of a read/write reference to the translation part of the rotation */
   typedef Block<MatrixType,Dim,1,!(internal::traits<MatrixType>::Flags & RowMajorBit)> TranslationPart;
   /** type of a read reference to the translation part of the rotation */
   typedef const Block<ConstMatrixType,Dim,1,!(internal::traits<MatrixType>::Flags & RowMajorBit)> ConstTranslationPart;
   /** corresponding translation type */
   typedef Translation<Scalar,Dim> TranslationType;
-  
+
   // this intermediate enum is needed to avoid an ICE with gcc 3.4 and 4.0
   enum { TransformTimeDiagonalMode = ((Mode==int(Isometry))?Affine:int(Mode)) };
   /** The return type of the product between a diagonal matrix and a transform */
   typedef Transform<Scalar,Dim,TransformTimeDiagonalMode> TransformTimeDiagonalReturnType;
 
 protected:
 
@@ -298,15 +298,15 @@
   {
     EIGEN_STATIC_ASSERT((internal::is_same<Scalar,typename OtherDerived::Scalar>::value),
       YOU_MIXED_DIFFERENT_NUMERIC_TYPES__YOU_NEED_TO_USE_THE_CAST_METHOD_OF_MATRIXBASE_TO_CAST_NUMERIC_TYPES_EXPLICITLY);
 
     internal::transform_construct_from_matrix<OtherDerived,Mode,Options,Dim,HDim>::run(this, other.derived());
     return *this;
   }
-  
+
   template<int OtherOptions>
   EIGEN_DEVICE_FUNC inline Transform(const Transform<Scalar,Dim,Mode,OtherOptions>& other)
   {
     check_template_params();
     // only the options change, we can directly copy the matrices
     m_matrix = other.matrix();
   }
@@ -370,17 +370,17 @@
   inline Transform(const QMatrix& other);
   inline Transform& operator=(const QMatrix& other);
   inline QMatrix toQMatrix(void) const;
   inline Transform(const QTransform& other);
   inline Transform& operator=(const QTransform& other);
   inline QTransform toQTransform(void) const;
   #endif
-  
-  EIGEN_DEVICE_FUNC Index rows() const { return int(Mode)==int(Projective) ? m_matrix.cols() : (m_matrix.cols()-1); }
-  EIGEN_DEVICE_FUNC Index cols() const { return m_matrix.cols(); }
+
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index rows() const EIGEN_NOEXCEPT { return int(Mode)==int(Projective) ? m_matrix.cols() : (m_matrix.cols()-1); }
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index cols() const EIGEN_NOEXCEPT { return m_matrix.cols(); }
 
   /** shortcut for m_matrix(row,col);
     * \sa MatrixBase::operator(Index,Index) const */
   EIGEN_DEVICE_FUNC inline Scalar operator() (Index row, Index col) const { return m_matrix(row,col); }
   /** shortcut for m_matrix(row,col);
     * \sa MatrixBase::operator(Index,Index) */
   EIGEN_DEVICE_FUNC inline Scalar& operator() (Index row, Index col) { return m_matrix(row,col); }
@@ -446,30 +446,30 @@
   EIGEN_DEVICE_FUNC inline const typename internal::transform_left_product_impl<OtherDerived,Mode,Options,_Dim,_Dim+1>::ResultType
     operator * (const EigenBase<OtherDerived> &a, const Transform &b)
   { return internal::transform_left_product_impl<OtherDerived,Mode,Options,Dim,HDim>::run(a.derived(),b); }
 
   /** \returns The product expression of a transform \a a times a diagonal matrix \a b
     *
     * The rhs diagonal matrix is interpreted as an affine scaling transformation. The
-    * product results in a Transform of the same type (mode) as the lhs only if the lhs 
+    * product results in a Transform of the same type (mode) as the lhs only if the lhs
     * mode is no isometry. In that case, the returned transform is an affinity.
     */
   template<typename DiagonalDerived>
   EIGEN_DEVICE_FUNC inline const TransformTimeDiagonalReturnType
     operator * (const DiagonalBase<DiagonalDerived> &b) const
   {
     TransformTimeDiagonalReturnType res(*this);
     res.linearExt() *= b;
     return res;
   }
 
   /** \returns The product expression of a diagonal matrix \a a times a transform \a b
     *
     * The lhs diagonal matrix is interpreted as an affine scaling transformation. The
-    * product results in a Transform of the same type (mode) as the lhs only if the lhs 
+    * product results in a Transform of the same type (mode) as the lhs only if the lhs
     * mode is no isometry. In that case, the returned transform is an affinity.
     */
   template<typename DiagonalDerived>
   EIGEN_DEVICE_FUNC friend inline TransformTimeDiagonalReturnType
     operator * (const DiagonalBase<DiagonalDerived> &a, const Transform &b)
   {
     TransformTimeDiagonalReturnType res;
@@ -484,30 +484,30 @@
   EIGEN_DEVICE_FUNC inline Transform& operator*=(const EigenBase<OtherDerived>& other) { return *this = *this * other; }
 
   /** Concatenates two transformations */
   EIGEN_DEVICE_FUNC inline const Transform operator * (const Transform& other) const
   {
     return internal::transform_transform_product_impl<Transform,Transform>::run(*this,other);
   }
-  
+
   #if EIGEN_COMP_ICC
 private:
   // this intermediate structure permits to workaround a bug in ICC 11:
   //   error: template instantiation resulted in unexpected function type of "Eigen::Transform<double, 3, 32, 0>
   //             (const Eigen::Transform<double, 3, 2, 0> &) const"
   //  (the meaning of a name may have changed since the template declaration -- the type of the template is:
   // "Eigen::internal::transform_transform_product_impl<Eigen::Transform<double, 3, 32, 0>,
   //     Eigen::Transform<double, 3, Mode, Options>, <expression>>::ResultType (const Eigen::Transform<double, 3, Mode, Options> &) const")
-  // 
+  //
   template<int OtherMode,int OtherOptions> struct icc_11_workaround
   {
     typedef internal::transform_transform_product_impl<Transform,Transform<Scalar,Dim,OtherMode,OtherOptions> > ProductType;
     typedef typename ProductType::ResultType ResultType;
   };
-  
+
 public:
   /** Concatenates two different transformations */
   template<int OtherMode,int OtherOptions>
   inline typename icc_11_workaround<OtherMode,OtherOptions>::ResultType
     operator * (const Transform<Scalar,Dim,OtherMode,OtherOptions>& other) const
   {
     typedef typename icc_11_workaround<OtherMode,OtherOptions>::ProductType ProductType;
@@ -532,15 +532,15 @@
    */
   EIGEN_DEVICE_FUNC static const Transform Identity()
   {
     return Transform(MatrixType::Identity());
   }
 
   template<typename OtherDerived>
-  EIGEN_DEVICE_FUNC 
+  EIGEN_DEVICE_FUNC
   inline Transform& scale(const MatrixBase<OtherDerived> &other);
 
   template<typename OtherDerived>
   EIGEN_DEVICE_FUNC
   inline Transform& prescale(const MatrixBase<OtherDerived> &other);
 
   EIGEN_DEVICE_FUNC inline Transform& scale(const Scalar& s);
@@ -562,26 +562,26 @@
   EIGEN_DEVICE_FUNC
   inline Transform& prerotate(const RotationType& rotation);
 
   EIGEN_DEVICE_FUNC Transform& shear(const Scalar& sx, const Scalar& sy);
   EIGEN_DEVICE_FUNC Transform& preshear(const Scalar& sx, const Scalar& sy);
 
   EIGEN_DEVICE_FUNC inline Transform& operator=(const TranslationType& t);
-  
+
   EIGEN_DEVICE_FUNC
   inline Transform& operator*=(const TranslationType& t) { return translate(t.vector()); }
-  
+
   EIGEN_DEVICE_FUNC inline Transform operator*(const TranslationType& t) const;
 
-  EIGEN_DEVICE_FUNC 
+  EIGEN_DEVICE_FUNC
   inline Transform& operator=(const UniformScaling<Scalar>& t);
-  
+
   EIGEN_DEVICE_FUNC
   inline Transform& operator*=(const UniformScaling<Scalar>& s) { return scale(s.factor()); }
-  
+
   EIGEN_DEVICE_FUNC
   inline TransformTimeDiagonalReturnType operator*(const UniformScaling<Scalar>& s) const
   {
     TransformTimeDiagonalReturnType res = *this;
     res.scale(s.factor());
     return res;
   }
@@ -676,15 +676,15 @@
   EIGEN_DEVICE_FUNC inline const Block<MatrixType,int(Mode)==int(Projective)?HDim:Dim,1> translationExt() const
   { return m_matrix.template block<int(Mode)==int(Projective)?HDim:Dim,1>(0,Dim); }
 
 
   #ifdef EIGEN_TRANSFORM_PLUGIN
   #include EIGEN_TRANSFORM_PLUGIN
   #endif
-  
+
 protected:
   #ifndef EIGEN_PARSED_BY_DOXYGEN
     EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE void check_template_params()
     {
       EIGEN_STATIC_ASSERT((Options & (DontAlign|RowMajor)) == Options, INVALID_MATRIX_TEMPLATE_PARAMETERS)
     }
   #endif
@@ -1044,15 +1044,15 @@
 
 namespace internal {
 template<int Mode> struct transform_rotation_impl {
   template<typename TransformType>
   EIGEN_DEVICE_FUNC static inline
   const typename TransformType::LinearMatrixType run(const TransformType& t)
   {
-    typedef typename TransformType::LinearMatrixType LinearMatrixType; 
+    typedef typename TransformType::LinearMatrixType LinearMatrixType;
     LinearMatrixType result;
     t.computeRotationScaling(&result, (LinearMatrixType*)0);
     return result;
   }
 };
 template<> struct transform_rotation_impl<Isometry> {
   template<typename TransformType>
@@ -1093,24 +1093,25 @@
   *
   * \sa computeScalingRotation(), rotation(), class SVD
   */
 template<typename Scalar, int Dim, int Mode, int Options>
 template<typename RotationMatrixType, typename ScalingMatrixType>
 EIGEN_DEVICE_FUNC void Transform<Scalar,Dim,Mode,Options>::computeRotationScaling(RotationMatrixType *rotation, ScalingMatrixType *scaling) const
 {
+  // Note that JacobiSVD is faster than BDCSVD for small matrices.
   JacobiSVD<LinearMatrixType> svd(linear(), ComputeFullU | ComputeFullV);
 
-  Scalar x = (svd.matrixU() * svd.matrixV().adjoint()).determinant(); // so x has absolute value 1
+  Scalar x = (svd.matrixU() * svd.matrixV().adjoint()).determinant() < Scalar(0) ? Scalar(-1) : Scalar(1); // so x has absolute value 1
   VectorType sv(svd.singularValues());
-  sv.coeffRef(0) *= x;
+  sv.coeffRef(Dim-1) *= x;
   if(scaling) *scaling = svd.matrixV() * sv.asDiagonal() * svd.matrixV().adjoint();
   if(rotation)
   {
     LinearMatrixType m(svd.matrixU());
-    m.col(0) /= x;
+    m.col(Dim-1) *= x;
     *rotation = m * svd.matrixV().adjoint();
   }
 }
 
 /** decomposes the linear part of the transformation as a product scaling x rotation, the scaling being
   * not necessarily positive.
   *
@@ -1122,24 +1123,25 @@
   *
   * \sa computeRotationScaling(), rotation(), class SVD
   */
 template<typename Scalar, int Dim, int Mode, int Options>
 template<typename ScalingMatrixType, typename RotationMatrixType>
 EIGEN_DEVICE_FUNC void Transform<Scalar,Dim,Mode,Options>::computeScalingRotation(ScalingMatrixType *scaling, RotationMatrixType *rotation) const
 {
+  // Note that JacobiSVD is faster than BDCSVD for small matrices.
   JacobiSVD<LinearMatrixType> svd(linear(), ComputeFullU | ComputeFullV);
 
-  Scalar x = (svd.matrixU() * svd.matrixV().adjoint()).determinant(); // so x has absolute value 1
+  Scalar x = (svd.matrixU() * svd.matrixV().adjoint()).determinant() < Scalar(0) ? Scalar(-1) : Scalar(1); // so x has absolute value 1
   VectorType sv(svd.singularValues());
-  sv.coeffRef(0) *= x;
+  sv.coeffRef(Dim-1) *= x;
   if(scaling) *scaling = svd.matrixU() * sv.asDiagonal() * svd.matrixU().adjoint();
   if(rotation)
   {
     LinearMatrixType m(svd.matrixU());
-    m.col(0) /= x;
+    m.col(Dim-1) *= x;
     *rotation = m * svd.matrixV().adjoint();
   }
 }
 
 /** Convenient method to set \c *this from a position, orientation and scale
   * of a 3D object.
   */
@@ -1171,15 +1173,15 @@
 };
 
 template<>
 struct transform_make_affine<AffineCompact>
 {
   template<typename MatrixType> EIGEN_DEVICE_FUNC static void run(MatrixType &) { }
 };
-    
+
 // selector needed to avoid taking the inverse of a 3x4 matrix
 template<typename TransformType, int Mode=TransformType::Mode>
 struct projective_transform_inverse
 {
   EIGEN_DEVICE_FUNC static inline void run(const TransformType&, TransformType&)
   {}
 };
@@ -1312,74 +1314,74 @@
 /**********************************************************
 ***   Specializations of operator* with rhs EigenBase   ***
 **********************************************************/
 
 template<int LhsMode,int RhsMode>
 struct transform_product_result
 {
-  enum 
-  { 
+  enum
+  {
     Mode =
       (LhsMode == (int)Projective    || RhsMode == (int)Projective    ) ? Projective :
       (LhsMode == (int)Affine        || RhsMode == (int)Affine        ) ? Affine :
       (LhsMode == (int)AffineCompact || RhsMode == (int)AffineCompact ) ? AffineCompact :
       (LhsMode == (int)Isometry      || RhsMode == (int)Isometry      ) ? Isometry : Projective
   };
 };
 
 template< typename TransformType, typename MatrixType, int RhsCols>
 struct transform_right_product_impl< TransformType, MatrixType, 0, RhsCols>
 {
   typedef typename MatrixType::PlainObject ResultType;
 
-  static EIGEN_STRONG_INLINE ResultType run(const TransformType& T, const MatrixType& other)
+  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE ResultType run(const TransformType& T, const MatrixType& other)
   {
     return T.matrix() * other;
   }
 };
 
 template< typename TransformType, typename MatrixType, int RhsCols>
 struct transform_right_product_impl< TransformType, MatrixType, 1, RhsCols>
 {
-  enum { 
-    Dim = TransformType::Dim, 
+  enum {
+    Dim = TransformType::Dim,
     HDim = TransformType::HDim,
     OtherRows = MatrixType::RowsAtCompileTime,
     OtherCols = MatrixType::ColsAtCompileTime
   };
 
   typedef typename MatrixType::PlainObject ResultType;
 
-  static EIGEN_STRONG_INLINE ResultType run(const TransformType& T, const MatrixType& other)
+  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE ResultType run(const TransformType& T, const MatrixType& other)
   {
     EIGEN_STATIC_ASSERT(OtherRows==HDim, YOU_MIXED_MATRICES_OF_DIFFERENT_SIZES);
 
     typedef Block<ResultType, Dim, OtherCols, int(MatrixType::RowsAtCompileTime)==Dim> TopLeftLhs;
 
     ResultType res(other.rows(),other.cols());
     TopLeftLhs(res, 0, 0, Dim, other.cols()).noalias() = T.affine() * other;
     res.row(OtherRows-1) = other.row(OtherRows-1);
-    
+
     return res;
   }
 };
 
 template< typename TransformType, typename MatrixType, int RhsCols>
 struct transform_right_product_impl< TransformType, MatrixType, 2, RhsCols>
 {
-  enum { 
-    Dim = TransformType::Dim, 
+  enum {
+    Dim = TransformType::Dim,
     HDim = TransformType::HDim,
     OtherRows = MatrixType::RowsAtCompileTime,
     OtherCols = MatrixType::ColsAtCompileTime
   };
 
   typedef typename MatrixType::PlainObject ResultType;
 
-  static EIGEN_STRONG_INLINE ResultType run(const TransformType& T, const MatrixType& other)
+  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE ResultType run(const TransformType& T, const MatrixType& other)
   {
     EIGEN_STATIC_ASSERT(OtherRows==Dim, YOU_MIXED_MATRICES_OF_DIFFERENT_SIZES);
 
     typedef Block<ResultType, Dim, OtherCols, true> TopLeftLhs;
     ResultType res(Replicate<typename TransformType::ConstTranslationPart, 1, OtherCols>(T.translation(),1,other.cols()));
     TopLeftLhs(res, 0, 0, Dim, other.cols()).noalias() += T.linear() * other;
 
@@ -1396,15 +1398,15 @@
     HDim = TransformType::HDim,
     OtherRows = MatrixType::RowsAtCompileTime,
     WorkingRows = EIGEN_PLAIN_ENUM_MIN(TransformMatrix::RowsAtCompileTime,HDim)
   };
 
   typedef typename MatrixType::PlainObject ResultType;
 
-  static EIGEN_STRONG_INLINE ResultType run(const TransformType& T, const MatrixType& other)
+  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE ResultType run(const TransformType& T, const MatrixType& other)
   {
     EIGEN_STATIC_ASSERT(OtherRows==Dim, YOU_MIXED_MATRICES_OF_DIFFERENT_SIZES);
 
     Matrix<typename ResultType::Scalar, Dim+1, 1> rhs;
     rhs.template head<Dim>() = other; rhs[Dim] = typename ResultType::Scalar(1);
     Matrix<typename ResultType::Scalar, WorkingRows, 1> res(T.matrix() * rhs);
     return res.template head<Dim>();
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Geometry/Translation.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Geometry/Translation.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Geometry/Umeyama.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Geometry/Umeyama.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Geometry/arch/Geometry_SSE.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Geometry/arch/Geometry_SIMD.h`

 * *Files 9% similar despite different names*

```diff
@@ -4,35 +4,37 @@
 // Copyright (C) 2009 Rohit Garg <rpg.314@gmail.com>
 // Copyright (C) 2009-2010 Gael Guennebaud <gael.guennebaud@inria.fr>
 //
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
-#ifndef EIGEN_GEOMETRY_SSE_H
-#define EIGEN_GEOMETRY_SSE_H
+#ifndef EIGEN_GEOMETRY_SIMD_H
+#define EIGEN_GEOMETRY_SIMD_H
 
 namespace Eigen { 
 
 namespace internal {
 
 template<class Derived, class OtherDerived>
-struct quat_product<Architecture::SSE, Derived, OtherDerived, float>
+struct quat_product<Architecture::Target, Derived, OtherDerived, float>
 {
   enum {
     AAlignment = traits<Derived>::Alignment,
     BAlignment = traits<OtherDerived>::Alignment,
     ResAlignment = traits<Quaternion<float> >::Alignment
   };
   static inline Quaternion<float> run(const QuaternionBase<Derived>& _a, const QuaternionBase<OtherDerived>& _b)
   {
     evaluator<typename Derived::Coefficients> ae(_a.coeffs());
     evaluator<typename OtherDerived::Coefficients> be(_b.coeffs());
     Quaternion<float> res;
-    const Packet4f mask = _mm_setr_ps(0.f,0.f,0.f,-0.f);
+    const float neg_zero = numext::bit_cast<float>(0x80000000u);
+    const float arr[4] = {0.f, 0.f, 0.f, neg_zero};
+    const Packet4f mask = ploadu<Packet4f>(arr);
     Packet4f a = ae.template packet<AAlignment,Packet4f>(0);
     Packet4f b = be.template packet<BAlignment,Packet4f>(0);
     Packet4f s1 = pmul(vec4f_swizzle1(a,1,2,0,2),vec4f_swizzle1(b,2,0,1,2));
     Packet4f s2 = pmul(vec4f_swizzle1(a,3,3,3,1),vec4f_swizzle1(b,0,1,2,1));
     pstoret<float,Packet4f,ResAlignment>(
               &res.x(),
               padd(psub(pmul(a,vec4f_swizzle1(b,3,3,3,3)),
@@ -41,32 +43,34 @@
                          pxor(mask,padd(s1,s2))));
     
     return res;
   }
 };
 
 template<class Derived>
-struct quat_conj<Architecture::SSE, Derived, float>
+struct quat_conj<Architecture::Target, Derived, float>
 {
   enum {
     ResAlignment = traits<Quaternion<float> >::Alignment
   };
   static inline Quaternion<float> run(const QuaternionBase<Derived>& q)
   {
     evaluator<typename Derived::Coefficients> qe(q.coeffs());
     Quaternion<float> res;
-    const Packet4f mask = _mm_setr_ps(-0.f,-0.f,-0.f,0.f);
+    const float neg_zero = numext::bit_cast<float>(0x80000000u);
+    const float arr[4] = {neg_zero, neg_zero, neg_zero,0.f};
+    const Packet4f mask = ploadu<Packet4f>(arr);
     pstoret<float,Packet4f,ResAlignment>(&res.x(), pxor(mask, qe.template packet<traits<Derived>::Alignment,Packet4f>(0)));
     return res;
   }
 };
 
 
 template<typename VectorLhs,typename VectorRhs>
-struct cross3_impl<Architecture::SSE,VectorLhs,VectorRhs,float,true>
+struct cross3_impl<Architecture::Target,VectorLhs,VectorRhs,float,true>
 {
   enum {
     ResAlignment = traits<typename plain_matrix_type<VectorLhs>::type>::Alignment
   };
   static inline typename plain_matrix_type<VectorLhs>::type
   run(const VectorLhs& lhs, const VectorRhs& rhs)
   {
@@ -80,27 +84,26 @@
     pstoret<float,Packet4f,ResAlignment>(&res.x(),psub(mul1,mul2));
     return res;
   }
 };
 
 
 
+#if (defined EIGEN_VECTORIZE_SSE) || (EIGEN_ARCH_ARM64)
 
 template<class Derived, class OtherDerived>
-struct quat_product<Architecture::SSE, Derived, OtherDerived, double>
+struct quat_product<Architecture::Target, Derived, OtherDerived, double>
 {
   enum {
     BAlignment = traits<OtherDerived>::Alignment,
     ResAlignment = traits<Quaternion<double> >::Alignment
   };
 
   static inline Quaternion<double> run(const QuaternionBase<Derived>& _a, const QuaternionBase<OtherDerived>& _b)
   {
-  const Packet2d mask = _mm_castsi128_pd(_mm_set_epi32(0x0,0x0,0x80000000,0x0));
-
   Quaternion<double> res;
 
   evaluator<typename Derived::Coefficients> ae(_a.coeffs());
   evaluator<typename OtherDerived::Coefficients> be(_b.coeffs());
 
   const double* a = _a.coeffs().data();
   Packet2d b_xy = be.template packet<BAlignment,Packet2d>(0);
@@ -116,55 +119,50 @@
   /*
    * t1 = ww*xy + yy*zw
    * t2 = zz*xy - xx*zw
    * res.xy = t1 +/- swap(t2)
    */
   t1 = padd(pmul(a_ww, b_xy), pmul(a_yy, b_zw));
   t2 = psub(pmul(a_zz, b_xy), pmul(a_xx, b_zw));
-#ifdef EIGEN_VECTORIZE_SSE3
-  EIGEN_UNUSED_VARIABLE(mask)
-  pstoret<double,Packet2d,ResAlignment>(&res.x(), _mm_addsub_pd(t1, preverse(t2)));
-#else
-  pstoret<double,Packet2d,ResAlignment>(&res.x(), padd(t1, pxor(mask,preverse(t2))));
-#endif
+  pstoret<double,Packet2d,ResAlignment>(&res.x(), paddsub(t1, preverse(t2)));
   
   /*
    * t1 = ww*zw - yy*xy
    * t2 = zz*zw + xx*xy
    * res.zw = t1 -/+ swap(t2) = swap( swap(t1) +/- t2)
    */
   t1 = psub(pmul(a_ww, b_zw), pmul(a_yy, b_xy));
   t2 = padd(pmul(a_zz, b_zw), pmul(a_xx, b_xy));
-#ifdef EIGEN_VECTORIZE_SSE3
-  EIGEN_UNUSED_VARIABLE(mask)
-  pstoret<double,Packet2d,ResAlignment>(&res.z(), preverse(_mm_addsub_pd(preverse(t1), t2)));
-#else
-  pstoret<double,Packet2d,ResAlignment>(&res.z(), psub(t1, pxor(mask,preverse(t2))));
-#endif
+  pstoret<double,Packet2d,ResAlignment>(&res.z(), preverse(paddsub(preverse(t1), t2)));
 
   return res;
 }
 };
 
 template<class Derived>
-struct quat_conj<Architecture::SSE, Derived, double>
+struct quat_conj<Architecture::Target, Derived, double>
 {
   enum {
     ResAlignment = traits<Quaternion<double> >::Alignment
   };
   static inline Quaternion<double> run(const QuaternionBase<Derived>& q)
   {
     evaluator<typename Derived::Coefficients> qe(q.coeffs());
     Quaternion<double> res;
-    const Packet2d mask0 = _mm_setr_pd(-0.,-0.);
-    const Packet2d mask2 = _mm_setr_pd(-0.,0.);
+    const double neg_zero = numext::bit_cast<double>(0x8000000000000000ull);
+    const double arr1[2] = {neg_zero, neg_zero};
+    const double arr2[2] = {neg_zero,  0.0};
+    const Packet2d mask0 = ploadu<Packet2d>(arr1);
+    const Packet2d mask2 = ploadu<Packet2d>(arr2);
     pstoret<double,Packet2d,ResAlignment>(&res.x(), pxor(mask0, qe.template packet<traits<Derived>::Alignment,Packet2d>(0)));
     pstoret<double,Packet2d,ResAlignment>(&res.z(), pxor(mask2, qe.template packet<traits<Derived>::Alignment,Packet2d>(2)));
     return res;
   }
 };
 
+#endif // end EIGEN_VECTORIZE_SSE_OR_EIGEN_ARCH_ARM64
+
 } // end namespace internal
 
 } // end namespace Eigen
 
-#endif // EIGEN_GEOMETRY_SSE_H
+#endif // EIGEN_GEOMETRY_SIMD_H
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Householder/BlockHouseholder.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Householder/BlockHouseholder.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Householder/Householder.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Householder/Householder.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Householder/HouseholderSequence.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Householder/HouseholderSequence.h`

 * *Files 2% similar despite different names*

```diff
@@ -7,15 +7,15 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_HOUSEHOLDER_SEQUENCE_H
 #define EIGEN_HOUSEHOLDER_SEQUENCE_H
 
-namespace Eigen { 
+namespace Eigen {
 
 /** \ingroup Householder_Module
   * \householder_module
   * \class HouseholderSequence
   * \brief Sequence of Householder reflections acting on subspaces with decreasing size
   * \tparam VectorsType type of matrix containing the Householder vectors
   * \tparam CoeffsType  type of vector containing the Householder coefficients
@@ -30,16 +30,16 @@
   * HessenbergDecomposition::matrixQ(), Tridiagonalization::matrixQ(), HouseholderQR::householderQ(),
   * and ColPivHouseholderQR::householderQ() all return a %HouseholderSequence.
   *
   * More precisely, the class %HouseholderSequence represents an \f$ n \times n \f$ matrix \f$ H \f$ of the
   * form \f$ H = \prod_{i=0}^{n-1} H_i \f$ where the i-th Householder reflection is \f$ H_i = I - h_i v_i
   * v_i^* \f$. The i-th Householder coefficient \f$ h_i \f$ is a scalar and the i-th Householder vector \f$
   * v_i \f$ is a vector of the form
-  * \f[ 
-  * v_i = [\underbrace{0, \ldots, 0}_{i-1\mbox{ zeros}}, 1, \underbrace{*, \ldots,*}_{n-i\mbox{ arbitrary entries}} ]. 
+  * \f[
+  * v_i = [\underbrace{0, \ldots, 0}_{i-1\mbox{ zeros}}, 1, \underbrace{*, \ldots,*}_{n-i\mbox{ arbitrary entries}} ].
   * \f]
   * The last \f$ n-i \f$ entries of \f$ v_i \f$ are called the essential part of the Householder vector.
   *
   * Typical usages are listed below, where H is a HouseholderSequence:
   * \code
   * A.applyOnTheRight(H);             // A = A * H
   * A.applyOnTheLeft(H);              // A = H * A
@@ -116,15 +116,15 @@
 
 } // end namespace internal
 
 template<typename VectorsType, typename CoeffsType, int Side> class HouseholderSequence
   : public EigenBase<HouseholderSequence<VectorsType,CoeffsType,Side> >
 {
     typedef typename internal::hseq_side_dependent_impl<VectorsType,CoeffsType,Side>::EssentialVectorType EssentialVectorType;
-  
+
   public:
     enum {
       RowsAtCompileTime = internal::traits<HouseholderSequence>::RowsAtCompileTime,
       ColsAtCompileTime = internal::traits<HouseholderSequence>::ColsAtCompileTime,
       MaxRowsAtCompileTime = internal::traits<HouseholderSequence>::MaxRowsAtCompileTime,
       MaxColsAtCompileTime = internal::traits<HouseholderSequence>::MaxColsAtCompileTime
     };
@@ -194,35 +194,35 @@
         m_reverse(other.m_reverse),
         m_length(other.m_length),
         m_shift(other.m_shift)
     {
     }
 
     /** \brief Number of rows of transformation viewed as a matrix.
-      * \returns Number of rows 
+      * \returns Number of rows
       * \details This equals the dimension of the space that the transformation acts on.
       */
-    EIGEN_DEVICE_FUNC
-    Index rows() const { return Side==OnTheLeft ? m_vectors.rows() : m_vectors.cols(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    Index rows() const EIGEN_NOEXCEPT { return Side==OnTheLeft ? m_vectors.rows() : m_vectors.cols(); }
 
     /** \brief Number of columns of transformation viewed as a matrix.
       * \returns Number of columns
       * \details This equals the dimension of the space that the transformation acts on.
       */
-    EIGEN_DEVICE_FUNC
-    Index cols() const { return rows(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    Index cols() const EIGEN_NOEXCEPT { return rows(); }
 
     /** \brief Essential part of a Householder vector.
       * \param[in]  k  Index of Householder reflection
       * \returns    Vector containing non-trivial entries of k-th Householder vector
       *
       * This function returns the essential part of the Householder vector \f$ v_i \f$. This is a vector of
       * length \f$ n-i \f$ containing the last \f$ n-i \f$ entries of the vector
-      * \f[ 
-      * v_i = [\underbrace{0, \ldots, 0}_{i-1\mbox{ zeros}}, 1, \underbrace{*, \ldots,*}_{n-i\mbox{ arbitrary entries}} ]. 
+      * \f[
+      * v_i = [\underbrace{0, \ldots, 0}_{i-1\mbox{ zeros}}, 1, \underbrace{*, \ldots,*}_{n-i\mbox{ arbitrary entries}} ].
       * \f]
       * The index \f$ i \f$ equals \p k + shift(), corresponding to the k-th column of the matrix \p v
       * passed to the constructor.
       *
       * \sa setShift(), shift()
       */
     EIGEN_DEVICE_FUNC
@@ -377,15 +377,15 @@
         Index blockSize = m_length<Index(2*BlockSize) ? (m_length+1)/2 : Index(BlockSize);
         for(Index i = 0; i < m_length; i+=blockSize)
         {
           Index end = m_reverse ? (std::min)(m_length,i+blockSize) : m_length-i;
           Index k = m_reverse ? i : (std::max)(Index(0),end-blockSize);
           Index bs = end-k;
           Index start = k + m_shift;
-          
+
           typedef Block<typename internal::remove_all<VectorsType>::type,Dynamic,Dynamic> SubVectorsType;
           SubVectorsType sub_vecs1(m_vectors.const_cast_derived(), Side==OnTheRight ? k : start,
                                                                    Side==OnTheRight ? start : k,
                                                                    Side==OnTheRight ? bs : m_vectors.rows()-start,
                                                                    Side==OnTheRight ? m_vectors.cols()-start : bs);
           typename internal::conditional<Side==OnTheRight, Transpose<SubVectorsType>, SubVectorsType&>::type sub_vecs(sub_vecs1);
 
@@ -515,25 +515,25 @@
   typename internal::matrix_type_times_scalar_type<typename VectorsType::Scalar,OtherDerived>::Type
     res(other.template cast<typename internal::matrix_type_times_scalar_type<typename VectorsType::Scalar,OtherDerived>::ResultScalar>());
   h.applyThisOnTheRight(res);
   return res;
 }
 
 /** \ingroup Householder_Module \householder_module
-  * \brief Convenience function for constructing a Householder sequence. 
+  * \brief Convenience function for constructing a Householder sequence.
   * \returns A HouseholderSequence constructed from the specified arguments.
   */
 template<typename VectorsType, typename CoeffsType>
 HouseholderSequence<VectorsType,CoeffsType> householderSequence(const VectorsType& v, const CoeffsType& h)
 {
   return HouseholderSequence<VectorsType,CoeffsType,OnTheLeft>(v, h);
 }
 
 /** \ingroup Householder_Module \householder_module
-  * \brief Convenience function for constructing a Householder sequence. 
+  * \brief Convenience function for constructing a Householder sequence.
   * \returns A HouseholderSequence constructed from the specified arguments.
   * \details This function differs from householderSequence() in that the template argument \p OnTheSide of
   * the constructed HouseholderSequence is set to OnTheRight, instead of the default OnTheLeft.
   */
 template<typename VectorsType, typename CoeffsType>
 HouseholderSequence<VectorsType,CoeffsType,OnTheRight> rightHouseholderSequence(const VectorsType& v, const CoeffsType& h)
 {
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/Jacobi/Jacobi.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/Jacobi/Jacobi.h`

 * *Files 1% similar despite different names*

```diff
@@ -449,15 +449,15 @@
 };
 
 template<typename VectorX, typename VectorY, typename OtherScalar>
 EIGEN_DEVICE_FUNC
 void /*EIGEN_DONT_INLINE*/ apply_rotation_in_the_plane(DenseBase<VectorX>& xpr_x, DenseBase<VectorY>& xpr_y, const JacobiRotation<OtherScalar>& j)
 {
   typedef typename VectorX::Scalar Scalar;
-  const bool Vectorizable =    (VectorX::Flags & VectorY::Flags & PacketAccessBit)
+  const bool Vectorizable =    (int(VectorX::Flags) & int(VectorY::Flags) & PacketAccessBit)
                             && (int(packet_traits<Scalar>::size) == int(packet_traits<OtherScalar>::size));
 
   eigen_assert(xpr_x.size() == xpr_y.size());
   Index size = xpr_x.size();
   Index incrx = xpr_x.derived().innerStride();
   Index incry = xpr_y.derived().innerStride();
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/LU/Determinant.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/LU/Determinant.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/LU/FullPivLU.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/LU/FullPivLU.h`

 * *Files 0% similar despite different names*

```diff
@@ -400,16 +400,18 @@
       eigen_assert(m_isInitialized && "LU is not initialized.");
       eigen_assert(m_lu.rows() == m_lu.cols() && "You can't take the inverse of a non-square matrix!");
       return Inverse<FullPivLU>(*this);
     }
 
     MatrixType reconstructedMatrix() const;
 
-    EIGEN_DEVICE_FUNC inline Index rows() const { return m_lu.rows(); }
-    EIGEN_DEVICE_FUNC inline Index cols() const { return m_lu.cols(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index rows() const EIGEN_NOEXCEPT { return m_lu.rows(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index cols() const EIGEN_NOEXCEPT { return m_lu.cols(); }
 
     #ifndef EIGEN_PARSED_BY_DOXYGEN
     template<typename RhsType, typename DstType>
     void _solve_impl(const RhsType &rhs, DstType &dst) const;
 
     template<bool Conjugate, typename RhsType, typename DstType>
     void _solve_impl_transposed(const RhsType &rhs, DstType &dst) const;
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/LU/InverseImpl.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/LU/InverseImpl.h`

 * *Files 2% similar despite different names*

```diff
@@ -73,18 +73,19 @@
 
 template<typename MatrixType, typename ResultType>
 EIGEN_DEVICE_FUNC 
 inline void compute_inverse_size2_helper(
     const MatrixType& matrix, const typename ResultType::Scalar& invdet,
     ResultType& result)
 {
+  typename ResultType::Scalar temp = matrix.coeff(0,0);
   result.coeffRef(0,0) =  matrix.coeff(1,1) * invdet;
   result.coeffRef(1,0) = -matrix.coeff(1,0) * invdet;
   result.coeffRef(0,1) = -matrix.coeff(0,1) * invdet;
-  result.coeffRef(1,1) =  matrix.coeff(0,0) * invdet;
+  result.coeffRef(1,1) =  temp * invdet;
 }
 
 template<typename MatrixType, typename ResultType>
 struct compute_inverse<MatrixType, ResultType, 2>
 {
   EIGEN_DEVICE_FUNC
   static inline void run(const MatrixType& matrix, ResultType& result)
@@ -139,21 +140,26 @@
 EIGEN_DEVICE_FUNC
 inline void compute_inverse_size3_helper(
     const MatrixType& matrix,
     const typename ResultType::Scalar& invdet,
     const Matrix<typename ResultType::Scalar,3,1>& cofactors_col0,
     ResultType& result)
 {
-  result.row(0) = cofactors_col0 * invdet;
-  result.coeffRef(1,0) =  cofactor_3x3<MatrixType,0,1>(matrix) * invdet;
-  result.coeffRef(1,1) =  cofactor_3x3<MatrixType,1,1>(matrix) * invdet;
+  // Compute cofactors in a way that avoids aliasing issues.
+  typedef typename ResultType::Scalar Scalar;
+  const Scalar c01 = cofactor_3x3<MatrixType,0,1>(matrix) * invdet;
+  const Scalar c11 = cofactor_3x3<MatrixType,1,1>(matrix) * invdet;
+  const Scalar c02 = cofactor_3x3<MatrixType,0,2>(matrix) * invdet;
   result.coeffRef(1,2) =  cofactor_3x3<MatrixType,2,1>(matrix) * invdet;
-  result.coeffRef(2,0) =  cofactor_3x3<MatrixType,0,2>(matrix) * invdet;
   result.coeffRef(2,1) =  cofactor_3x3<MatrixType,1,2>(matrix) * invdet;
   result.coeffRef(2,2) =  cofactor_3x3<MatrixType,2,2>(matrix) * invdet;
+  result.coeffRef(1,0) =  c01;
+  result.coeffRef(1,1) =  c11;
+  result.coeffRef(2,0) =  c02;  
+  result.row(0) = cofactors_col0 * invdet;
 }
 
 template<typename MatrixType, typename ResultType>
 struct compute_inverse<MatrixType, ResultType, 3>
 {
   EIGEN_DEVICE_FUNC
   static inline void run(const MatrixType& matrix, ResultType& result)
@@ -177,22 +183,21 @@
     const MatrixType& matrix,
     const typename MatrixType::RealScalar& absDeterminantThreshold,
     ResultType& inverse,
     typename ResultType::Scalar& determinant,
     bool& invertible
   )
   {
-    using std::abs;
     typedef typename ResultType::Scalar Scalar;
     Matrix<Scalar,3,1> cofactors_col0;
     cofactors_col0.coeffRef(0) =  cofactor_3x3<MatrixType,0,0>(matrix);
     cofactors_col0.coeffRef(1) =  cofactor_3x3<MatrixType,1,0>(matrix);
     cofactors_col0.coeffRef(2) =  cofactor_3x3<MatrixType,2,0>(matrix);
     determinant = (cofactors_col0.cwiseProduct(matrix.col(0))).sum();
-    invertible = abs(determinant) > absDeterminantThreshold;
+    invertible = Eigen::numext::abs(determinant) > absDeterminantThreshold;
     if(!invertible) return;
     const Scalar invdet = Scalar(1) / determinant;
     compute_inverse_size3_helper(matrix, invdet, cofactors_col0, inverse);
   }
 };
 
 /****************************
@@ -269,15 +274,21 @@
     typename ResultType::Scalar& determinant,
     bool& invertible
   )
   {
     using std::abs;
     determinant = matrix.determinant();
     invertible = abs(determinant) > absDeterminantThreshold;
-    if(invertible) compute_inverse<MatrixType, ResultType>::run(matrix, inverse);
+    if(invertible && extract_data(matrix) != extract_data(inverse)) {
+      compute_inverse<MatrixType, ResultType>::run(matrix, inverse);
+    }
+    else if(invertible) {
+      MatrixType matrix_t = matrix;
+      compute_inverse<MatrixType, ResultType>::run(matrix_t, inverse);
+    }
   }
 };
 
 /*************************
 *** MatrixBase methods ***
 *************************/
 
@@ -343,14 +354,16 @@
 
 /** \lu_module
   *
   * Computation of matrix inverse and determinant, with invertibility check.
   *
   * This is only for fixed-size square matrices of size up to 4x4.
   *
+  * Notice that it will trigger a copy of input matrix when trying to do the inverse in place.
+  *
   * \param inverse Reference to the matrix in which to store the inverse.
   * \param determinant Reference to the variable in which to store the determinant.
   * \param invertible Reference to the bool variable in which to store whether the matrix is invertible.
   * \param absDeterminantThreshold Optional parameter controlling the invertibility check.
   *                                The matrix will be declared invertible if the absolute value of its
   *                                determinant is greater than this threshold.
   *
@@ -383,14 +396,16 @@
 
 /** \lu_module
   *
   * Computation of matrix inverse, with invertibility check.
   *
   * This is only for fixed-size square matrices of size up to 4x4.
   *
+  * Notice that it will trigger a copy of input matrix when trying to do the inverse in place.
+  *
   * \param inverse Reference to the matrix in which to store the inverse.
   * \param invertible Reference to the bool variable in which to store whether the matrix is invertible.
   * \param absDeterminantThreshold Optional parameter controlling the invertibility check.
   *                                The matrix will be declared invertible if the absolute value of its
   *                                determinant is greater than this threshold.
   *
   * Example: \include MatrixBase_computeInverseWithCheck.cpp
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/LU/PartialPivLU.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/LU/PartialPivLU.h`

 * *Files 1% similar despite different names*

```diff
@@ -66,15 +66,15 @@
   * This LU decomposition is suitable to invert invertible matrices. It is what MatrixBase::inverse() uses
   * in the general case.
   * On the other hand, it is \b not suitable to determine whether a given matrix is invertible.
   *
   * The data of the LU decomposition can be directly accessed through the methods matrixLU(), permutationP().
   *
   * This class supports the \link InplaceDecomposition inplace decomposition \endlink mechanism.
-  * 
+  *
   * \sa MatrixBase::partialPivLu(), MatrixBase::determinant(), MatrixBase::inverse(), MatrixBase::computeInverse(), class FullPivLU
   */
 template<typename _MatrixType> class PartialPivLU
   : public SolverBase<PartialPivLU<_MatrixType> >
 {
   public:
 
@@ -212,16 +212,16 @@
       *
       * \sa MatrixBase::determinant()
       */
     Scalar determinant() const;
 
     MatrixType reconstructedMatrix() const;
 
-    inline Index rows() const { return m_lu.rows(); }
-    inline Index cols() const { return m_lu.cols(); }
+    EIGEN_CONSTEXPR inline Index rows() const EIGEN_NOEXCEPT { return m_lu.rows(); }
+    EIGEN_CONSTEXPR inline Index cols() const EIGEN_NOEXCEPT { return m_lu.cols(); }
 
     #ifndef EIGEN_PARSED_BY_DOXYGEN
     template<typename RhsType, typename DstType>
     EIGEN_DEVICE_FUNC
     void _solve_impl(const RhsType &rhs, DstType &dst) const {
      /* The decomposition PA = LU can be rewritten as A = P^{-1} L U.
       * So we proceed as follows:
@@ -500,16 +500,21 @@
 };
 
 /** \internal performs the LU decomposition with partial pivoting in-place.
   */
 template<typename MatrixType, typename TranspositionType>
 void partial_lu_inplace(MatrixType& lu, TranspositionType& row_transpositions, typename TranspositionType::StorageIndex& nb_transpositions)
 {
+  // Special-case of zero matrix.
+  if (lu.rows() == 0 || lu.cols() == 0) {
+    nb_transpositions = 0;
+    return;
+  }
   eigen_assert(lu.cols() == row_transpositions.size());
-  eigen_assert((&row_transpositions.coeffRef(1)-&row_transpositions.coeffRef(0)) == 1);
+  eigen_assert(row_transpositions.size() < 2 || (&row_transpositions.coeffRef(1)-&row_transpositions.coeffRef(0)) == 1);
 
   partial_lu_impl
     < typename MatrixType::Scalar, MatrixType::Flags&RowMajorBit?RowMajor:ColMajor,
       typename TranspositionType::StorageIndex,
       EIGEN_SIZE_MIN_PREFER_FIXED(MatrixType::RowsAtCompileTime,MatrixType::ColsAtCompileTime)>
     ::blocked_lu(lu.rows(), lu.cols(), &lu.coeffRef(0,0), lu.outerStride(), &row_transpositions.coeffRef(0), nb_transpositions);
 }
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/LU/PartialPivLU_LAPACKE.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/LU/PartialPivLU_LAPACKE.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/QR/ColPivHouseholderQR.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/QR/ColPivHouseholderQR.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/QR/ColPivHouseholderQR_LAPACKE.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/QR/ColPivHouseholderQR_LAPACKE.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/QR/CompleteOrthogonalDecomposition.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/QR/CompleteOrthogonalDecomposition.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/QR/FullPivHouseholderQR.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/QR/FullPivHouseholderQR.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/QR/HouseholderQR.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/QR/HouseholderQR.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/QR/HouseholderQR_LAPACKE.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/QR/HouseholderQR_LAPACKE.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/SVD/BDCSVD.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/SVD/BDCSVD.h`

 * *Files 2% similar despite different names*

```diff
@@ -204,14 +204,15 @@
   using Base::m_diagSize;
   using Base::m_computeFullU;
   using Base::m_computeFullV;
   using Base::m_computeThinU;
   using Base::m_computeThinV;
   using Base::m_matrixU;
   using Base::m_matrixV;
+  using Base::m_info;
   using Base::m_isInitialized;
   using Base::m_nonzeroSingularValues;
 
 public:  
   int m_numIters;
 }; //end class BDCSVD
 
@@ -252,24 +253,33 @@
   const RealScalar considerZero = (std::numeric_limits<RealScalar>::min)();
   
   //**** step -1 - If the problem is too small, directly falls back to JacobiSVD and return
   if(matrix.cols() < m_algoswap)
   {
     // FIXME this line involves temporaries
     JacobiSVD<MatrixType> jsvd(matrix,computationOptions);
-    if(computeU()) m_matrixU = jsvd.matrixU();
-    if(computeV()) m_matrixV = jsvd.matrixV();
-    m_singularValues = jsvd.singularValues();
-    m_nonzeroSingularValues = jsvd.nonzeroSingularValues();
     m_isInitialized = true;
+    m_info = jsvd.info();
+    if (m_info == Success || m_info == NoConvergence) {
+      if(computeU()) m_matrixU = jsvd.matrixU();
+      if(computeV()) m_matrixV = jsvd.matrixV();
+      m_singularValues = jsvd.singularValues();
+      m_nonzeroSingularValues = jsvd.nonzeroSingularValues();
+    }
     return *this;
   }
   
   //**** step 0 - Copy the input matrix and apply scaling to reduce over/under-flows
-  RealScalar scale = matrix.cwiseAbs().maxCoeff();
+  RealScalar scale = matrix.cwiseAbs().template maxCoeff<PropagateNaN>();
+  if (!(numext::isfinite)(scale)) {
+    m_isInitialized = true;
+    m_info = InvalidInput;
+    return *this;
+  }
+
   if(scale==Literal(0)) scale = Literal(1);
   MatrixX copy;
   if (m_isTranspose) copy = matrix.adjoint()/scale;
   else               copy = matrix/scale;
   
   //**** step 1 - Bidiagonalization
   // FIXME this line involves temporaries
@@ -278,15 +288,19 @@
   //**** step 2 - Divide & Conquer
   m_naiveU.setZero();
   m_naiveV.setZero();
   // FIXME this line involves a temporary matrix
   m_computed.topRows(m_diagSize) = bid.bidiagonal().toDenseMatrix().transpose();
   m_computed.template bottomRows<1>().setZero();
   divide(0, m_diagSize - 1, 0, 0, 0);
-
+  if (m_info != Success && m_info != NoConvergence) {
+    m_isInitialized = true;
+    return *this;
+  }
+    
   //**** step 3 - Copy singular values and vectors
   for (int i=0; i<m_diagSize; i++)
   {
     RealScalar a = abs(m_computed.coeff(i, i));
     m_singularValues.coeffRef(i) = a * scale;
     if (a<considerZero)
     {
@@ -390,15 +404,15 @@
 //@param lastCol : The Index of the last column of the submatrix of m_computed and for m_naiveU; 
 // lastCol + 1 - firstCol is the size of the submatrix.
 //@param firstRowW : The Index of the first row of the matrix W that we are to change. (see the reference paper section 1 for more information on W)
 //@param firstRowW : Same as firstRowW with the column.
 //@param shift : Each time one takes the left submatrix, one must add 1 to the shift. Why? Because! We actually want the last column of the U submatrix 
 // to become the first column (*coeff) and to shift all the other columns to the right. There are more details on the reference paper.
 template<typename MatrixType>
-void BDCSVD<MatrixType>::divide (Eigen::Index firstCol, Eigen::Index lastCol, Eigen::Index firstRowW, Eigen::Index firstColW, Eigen::Index shift)
+void BDCSVD<MatrixType>::divide(Eigen::Index firstCol, Eigen::Index lastCol, Eigen::Index firstRowW, Eigen::Index firstColW, Eigen::Index shift)
 {
   // requires rows = cols + 1;
   using std::pow;
   using std::sqrt;
   using std::abs;
   const Index n = lastCol - firstCol + 1;
   const Index k = n/2;
@@ -410,14 +424,16 @@
   VectorType l, f;
   // We use the other algorithm which is more efficient for small 
   // matrices.
   if (n < m_algoswap)
   {
     // FIXME this line involves temporaries
     JacobiSVD<MatrixXr> b(m_computed.block(firstCol, firstCol, n + 1, n), ComputeFullU | (m_compV ? ComputeFullV : 0));
+    m_info = b.info();
+    if (m_info != Success && m_info != NoConvergence) return;
     if (m_compU)
       m_naiveU.block(firstCol, firstCol, n + 1, n + 1).real() = b.matrixU();
     else 
     {
       m_naiveU.row(0).segment(firstCol, n + 1).real() = b.matrixU().row(0);
       m_naiveU.row(1).segment(firstCol, n + 1).real() = b.matrixU().row(n);
     }
@@ -429,15 +445,17 @@
   // We use the divide and conquer algorithm
   alphaK =  m_computed(firstCol + k, firstCol + k);
   betaK = m_computed(firstCol + k + 1, firstCol + k);
   // The divide must be done in that order in order to have good results. Divide change the data inside the submatrices
   // and the divide of the right submatrice reads one column of the left submatrice. That's why we need to treat the 
   // right submatrix before the left one. 
   divide(k + 1 + firstCol, lastCol, k + 1 + firstRowW, k + 1 + firstColW, shift);
+  if (m_info != Success && m_info != NoConvergence) return;
   divide(firstCol, k - 1 + firstCol, firstRowW, firstColW + 1, shift + 1);
+  if (m_info != Success && m_info != NoConvergence) return;
 
   if (m_compU)
   {
     lambda = m_naiveU(firstCol + k, firstCol + k);
     phi = m_naiveU(firstCol + k + 1, lastCol + 1);
   } 
   else 
@@ -1326,25 +1344,23 @@
 #ifdef EIGEN_BDCSVD_SANITY_CHECKS
   assert(m_naiveU.allFinite());
   assert(m_naiveV.allFinite());
   assert(m_computed.allFinite());
 #endif
 }//end deflation
 
-#if !defined(EIGEN_GPUCC)
 /** \svd_module
   *
   * \return the singular value decomposition of \c *this computed by Divide & Conquer algorithm
   *
   * \sa class BDCSVD
   */
 template<typename Derived>
 BDCSVD<typename MatrixBase<Derived>::PlainObject>
 MatrixBase<Derived>::bdcSvd(unsigned int computationOptions) const
 {
   return BDCSVD<PlainObject>(*this, computationOptions);
 }
-#endif
 
 } // end namespace Eigen
 
 #endif
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/SVD/JacobiSVD.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/SVD/JacobiSVD.h`

 * *Files 2% similar despite different names*

```diff
@@ -108,20 +108,20 @@
   typedef typename MatrixType::Scalar Scalar;
   enum
   {
     RowsAtCompileTime = MatrixType::RowsAtCompileTime,
     ColsAtCompileTime = MatrixType::ColsAtCompileTime,
     MaxRowsAtCompileTime = MatrixType::MaxRowsAtCompileTime,
     MaxColsAtCompileTime = MatrixType::MaxColsAtCompileTime,
-    TrOptions = RowsAtCompileTime==1 ? (MatrixType::Options & ~(RowMajor))
-              : ColsAtCompileTime==1 ? (MatrixType::Options |   RowMajor)
-              : MatrixType::Options
+    Options = MatrixType::Options
   };
-  typedef Matrix<Scalar, ColsAtCompileTime, RowsAtCompileTime, TrOptions, MaxColsAtCompileTime, MaxRowsAtCompileTime>
-          TransposeTypeWithSameStorageOrder;
+
+  typedef typename internal::make_proper_matrix_type<
+    Scalar, ColsAtCompileTime, RowsAtCompileTime, Options, MaxColsAtCompileTime, MaxRowsAtCompileTime
+  >::type TransposeTypeWithSameStorageOrder;
 
   void allocate(const JacobiSVD<MatrixType, FullPivHouseholderQRPreconditioner>& svd)
   {
     if (svd.cols() != m_qr.rows() || svd.rows() != m_qr.cols())
     {
       m_qr.~QRType();
       ::new (&m_qr) QRType(svd.cols(), svd.rows());
@@ -198,21 +198,20 @@
   typedef typename MatrixType::Scalar Scalar;
   enum
   {
     RowsAtCompileTime = MatrixType::RowsAtCompileTime,
     ColsAtCompileTime = MatrixType::ColsAtCompileTime,
     MaxRowsAtCompileTime = MatrixType::MaxRowsAtCompileTime,
     MaxColsAtCompileTime = MatrixType::MaxColsAtCompileTime,
-    TrOptions = RowsAtCompileTime==1 ? (MatrixType::Options & ~(RowMajor))
-              : ColsAtCompileTime==1 ? (MatrixType::Options |   RowMajor)
-              : MatrixType::Options
+    Options = MatrixType::Options
   };
 
-  typedef Matrix<Scalar, ColsAtCompileTime, RowsAtCompileTime, TrOptions, MaxColsAtCompileTime, MaxRowsAtCompileTime>
-          TransposeTypeWithSameStorageOrder;
+  typedef typename internal::make_proper_matrix_type<
+    Scalar, ColsAtCompileTime, RowsAtCompileTime, Options, MaxColsAtCompileTime, MaxRowsAtCompileTime
+  >::type TransposeTypeWithSameStorageOrder;
 
   void allocate(const JacobiSVD<MatrixType, ColPivHouseholderQRPreconditioner>& svd)
   {
     if (svd.cols() != m_qr.rows() || svd.rows() != m_qr.cols())
     {
       m_qr.~QRType();
       ::new (&m_qr) QRType(svd.cols(), svd.rows());
@@ -299,16 +298,17 @@
     RowsAtCompileTime = MatrixType::RowsAtCompileTime,
     ColsAtCompileTime = MatrixType::ColsAtCompileTime,
     MaxRowsAtCompileTime = MatrixType::MaxRowsAtCompileTime,
     MaxColsAtCompileTime = MatrixType::MaxColsAtCompileTime,
     Options = MatrixType::Options
   };
 
-  typedef Matrix<Scalar, ColsAtCompileTime, RowsAtCompileTime, Options, MaxColsAtCompileTime, MaxRowsAtCompileTime>
-          TransposeTypeWithSameStorageOrder;
+  typedef typename internal::make_proper_matrix_type<
+    Scalar, ColsAtCompileTime, RowsAtCompileTime, Options, MaxColsAtCompileTime, MaxRowsAtCompileTime
+  >::type TransposeTypeWithSameStorageOrder;
 
   void allocate(const JacobiSVD<MatrixType, HouseholderQRPreconditioner>& svd)
   {
     if (svd.cols() != m_qr.rows() || svd.rows() != m_qr.cols())
     {
       m_qr.~QRType();
       ::new (&m_qr) QRType(svd.cols(), svd.rows());
@@ -581,14 +581,15 @@
   private:
     void allocate(Index rows, Index cols, unsigned int computationOptions);
 
   protected:
     using Base::m_matrixU;
     using Base::m_matrixV;
     using Base::m_singularValues;
+    using Base::m_info;
     using Base::m_isInitialized;
     using Base::m_isAllocated;
     using Base::m_usePrescribedThreshold;
     using Base::m_computeFullU;
     using Base::m_computeThinU;
     using Base::m_computeFullV;
     using Base::m_computeThinV;
@@ -621,14 +622,15 @@
       computationOptions == m_computationOptions)
   {
     return;
   }
 
   m_rows = rows;
   m_cols = cols;
+  m_info = Success;
   m_isInitialized = false;
   m_isAllocated = true;
   m_computationOptions = computationOptions;
   m_computeFullU = (computationOptions & ComputeFullU) != 0;
   m_computeThinU = (computationOptions & ComputeThinU) != 0;
   m_computeFullV = (computationOptions & ComputeFullV) != 0;
   m_computeThinV = (computationOptions & ComputeThinV) != 0;
@@ -670,15 +672,20 @@
   // only worsening the precision of U and V as we accumulate more rotations
   const RealScalar precision = RealScalar(2) * NumTraits<Scalar>::epsilon();
 
   // limit for denormal numbers to be considered zero in order to avoid infinite loops (see bug 286)
   const RealScalar considerAsZero = (std::numeric_limits<RealScalar>::min)();
 
   // Scaling factor to reduce over/under-flows
-  RealScalar scale = matrix.cwiseAbs().maxCoeff();
+  RealScalar scale = matrix.cwiseAbs().template maxCoeff<PropagateNaN>();
+  if (!(numext::isfinite)(scale)) {
+    m_isInitialized = true;
+    m_info = InvalidInput;
+    return *this;
+  }
   if(scale==RealScalar(0)) scale = RealScalar(1);
   
   /*** step 1. The R-SVD step: we use a QR decomposition to reduce to the case of a square matrix */
 
   if(m_rows!=m_cols)
   {
     m_scaledMatrix = matrix / scale;
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/SVD/JacobiSVD_LAPACKE.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/SVD/JacobiSVD_LAPACKE.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/SVD/SVDBase.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/SVD/SVDBase.h`

 * *Files 13% similar despite different names*

```diff
@@ -47,16 +47,19 @@
  * Singular values are always sorted in decreasing order.
  *
  * 
  * You can ask for only \em thin \a U or \a V to be computed, meaning the following. In case of a rectangular n-by-p matrix, letting \a m be the
  * smaller value among \a n and \a p, there are only \a m singular vectors; the remaining columns of \a U and \a V do not correspond to actual
  * singular vectors. Asking for \em thin \a U or \a V means asking for only their \a m first columns to be formed. So \a U is then a n-by-m matrix,
  * and \a V is then a p-by-m matrix. Notice that thin \a U and \a V are all you need for (least squares) solving.
+ * 
+ * The status of the computation can be retrived using the \a info() method. Unless \a info() returns \a Success, the results should be not
+ * considered well defined.
  *  
- * If the input matrix has inf or nan coefficients, the result of the computation is undefined, but the computation is guaranteed to
+ * If the input matrix has inf or nan coefficients, the result of the computation is undefined, and \a info() will return \a InvalidInput, but the computation is guaranteed to
  * terminate in finite (and reasonable) time.
  * \sa class BDCSVD, class JacobiSVD
  */
 template<typename Derived> class SVDBase
  : public SolverBase<SVDBase<Derived> >
 {
 public: 
@@ -93,15 +96,15 @@
    *
    * The \a m first columns of \a U are the left singular vectors of the matrix being decomposed.
    *
    * This method asserts that you asked for \a U to be computed.
    */
   const MatrixUType& matrixU() const
   {
-    eigen_assert(m_isInitialized && "SVD is not initialized.");
+    _check_compute_assertions();
     eigen_assert(computeU() && "This SVD decomposition didn't compute U. Did you ask for it?");
     return m_matrixU;
   }
 
   /** \returns the \a V matrix.
    *
    * For the SVD decomposition of a n-by-p matrix, letting \a m be the minimum of \a n and \a p,
@@ -109,47 +112,47 @@
    *
    * The \a m first columns of \a V are the right singular vectors of the matrix being decomposed.
    *
    * This method asserts that you asked for \a V to be computed.
    */
   const MatrixVType& matrixV() const
   {
-    eigen_assert(m_isInitialized && "SVD is not initialized.");
+    _check_compute_assertions();
     eigen_assert(computeV() && "This SVD decomposition didn't compute V. Did you ask for it?");
     return m_matrixV;
   }
 
   /** \returns the vector of singular values.
    *
    * For the SVD decomposition of a n-by-p matrix, letting \a m be the minimum of \a n and \a p, the
    * returned vector has size \a m.  Singular values are always sorted in decreasing order.
    */
   const SingularValuesType& singularValues() const
   {
-    eigen_assert(m_isInitialized && "SVD is not initialized.");
+    _check_compute_assertions();
     return m_singularValues;
   }
 
   /** \returns the number of singular values that are not exactly 0 */
   Index nonzeroSingularValues() const
   {
-    eigen_assert(m_isInitialized && "SVD is not initialized.");
+    _check_compute_assertions();
     return m_nonzeroSingularValues;
   }
   
   /** \returns the rank of the matrix of which \c *this is the SVD.
     *
     * \note This method has to determine which singular values should be considered nonzero.
     *       For that, it uses the threshold value that you can control by calling
     *       setThreshold(const RealScalar&).
     */
   inline Index rank() const
   {
     using std::abs;
-    eigen_assert(m_isInitialized && "JacobiSVD is not initialized.");
+    _check_compute_assertions();
     if(m_singularValues.size()==0) return 0;
     RealScalar premultiplied_threshold = numext::maxi<RealScalar>(m_singularValues.coeff(0) * threshold(), (std::numeric_limits<RealScalar>::min)());
     Index i = m_nonzeroSingularValues-1;
     while(i>=0 && m_singularValues.coeff(i) < premultiplied_threshold) --i;
     return i+1;
   }
   
@@ -220,56 +223,74 @@
     * In other words, the returned solution is guaranteed to minimize the Euclidean norm \f$ \Vert A x - b \Vert \f$.
     */
   template<typename Rhs>
   inline const Solve<Derived, Rhs>
   solve(const MatrixBase<Rhs>& b) const;
   #endif
 
+
+  /** \brief Reports whether previous computation was successful.
+   *
+   * \returns \c Success if computation was successful.
+   */
+  EIGEN_DEVICE_FUNC
+  ComputationInfo info() const
+  {
+    eigen_assert(m_isInitialized && "SVD is not initialized.");
+    return m_info;
+  }
+
   #ifndef EIGEN_PARSED_BY_DOXYGEN
   template<typename RhsType, typename DstType>
   void _solve_impl(const RhsType &rhs, DstType &dst) const;
 
   template<bool Conjugate, typename RhsType, typename DstType>
   void _solve_impl_transposed(const RhsType &rhs, DstType &dst) const;
   #endif
 
 protected:
-  
+
   static void check_template_parameters()
   {
     EIGEN_STATIC_ASSERT_NON_INTEGER(Scalar);
   }
 
+  void _check_compute_assertions() const {
+    eigen_assert(m_isInitialized && "SVD is not initialized.");
+  }
+
   template<bool Transpose_, typename Rhs>
   void _check_solve_assertion(const Rhs& b) const {
       EIGEN_ONLY_USED_FOR_DEBUG(b);
-      eigen_assert(m_isInitialized && "SVD is not initialized.");
+      _check_compute_assertions();
       eigen_assert(computeU() && computeV() && "SVDBase::solve(): Both unitaries U and V are required to be computed (thin unitaries suffice).");
       eigen_assert((Transpose_?cols():rows())==b.rows() && "SVDBase::solve(): invalid number of rows of the right hand side matrix b");
   }
-  
+
   // return true if already allocated
   bool allocate(Index rows, Index cols, unsigned int computationOptions) ;
 
   MatrixUType m_matrixU;
   MatrixVType m_matrixV;
   SingularValuesType m_singularValues;
+  ComputationInfo m_info;
   bool m_isInitialized, m_isAllocated, m_usePrescribedThreshold;
   bool m_computeFullU, m_computeThinU;
   bool m_computeFullV, m_computeThinV;
   unsigned int m_computationOptions;
   Index m_nonzeroSingularValues, m_rows, m_cols, m_diagSize;
   RealScalar m_prescribedThreshold;
 
   /** \brief Default Constructor.
    *
    * Default constructor of SVDBase
    */
   SVDBase()
-    : m_isInitialized(false),
+    : m_info(Success),
+      m_isInitialized(false),
       m_isAllocated(false),
       m_usePrescribedThreshold(false),
       m_computeFullU(false),
       m_computeThinU(false),
       m_computeFullV(false),
       m_computeThinV(false),
       m_computationOptions(0),
@@ -323,14 +344,15 @@
       computationOptions == m_computationOptions)
   {
     return true;
   }
 
   m_rows = rows;
   m_cols = cols;
+  m_info = Success;
   m_isInitialized = false;
   m_isAllocated = true;
   m_computationOptions = computationOptions;
   m_computeFullU = (computationOptions & ComputeFullU) != 0;
   m_computeThinU = (computationOptions & ComputeThinU) != 0;
   m_computeFullV = (computationOptions & ComputeFullV) != 0;
   m_computeThinV = (computationOptions & ComputeThinV) != 0;
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/SVD/UpperBidiagonalization.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/SVD/UpperBidiagonalization.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/misc/Image.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/misc/Image.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/misc/Kernel.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/misc/Kernel.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/misc/RealSvd2x2.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/misc/RealSvd2x2.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/misc/blas.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/misc/blas.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/misc/lapack.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/misc/lapack.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/misc/lapacke.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/misc/lapacke.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/plugins/ArrayCwiseBinaryOps.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/plugins/ArrayCwiseBinaryOps.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/plugins/ArrayCwiseUnaryOps.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/plugins/ArrayCwiseUnaryOps.h`

 * *Files 2% similar despite different names*

```diff
@@ -10,14 +10,15 @@
 typedef CwiseUnaryOp<internal::scalar_boolean_not_op<Scalar>, const Derived> BooleanNotReturnType;
 
 typedef CwiseUnaryOp<internal::scalar_exp_op<Scalar>, const Derived> ExpReturnType;
 typedef CwiseUnaryOp<internal::scalar_expm1_op<Scalar>, const Derived> Expm1ReturnType;
 typedef CwiseUnaryOp<internal::scalar_log_op<Scalar>, const Derived> LogReturnType;
 typedef CwiseUnaryOp<internal::scalar_log1p_op<Scalar>, const Derived> Log1pReturnType;
 typedef CwiseUnaryOp<internal::scalar_log10_op<Scalar>, const Derived> Log10ReturnType;
+typedef CwiseUnaryOp<internal::scalar_log2_op<Scalar>, const Derived> Log2ReturnType;
 typedef CwiseUnaryOp<internal::scalar_cos_op<Scalar>, const Derived> CosReturnType;
 typedef CwiseUnaryOp<internal::scalar_sin_op<Scalar>, const Derived> SinReturnType;
 typedef CwiseUnaryOp<internal::scalar_tan_op<Scalar>, const Derived> TanReturnType;
 typedef CwiseUnaryOp<internal::scalar_acos_op<Scalar>, const Derived> AcosReturnType;
 typedef CwiseUnaryOp<internal::scalar_asin_op<Scalar>, const Derived> AsinReturnType;
 typedef CwiseUnaryOp<internal::scalar_atan_op<Scalar>, const Derived> AtanReturnType;
 typedef CwiseUnaryOp<internal::scalar_tanh_op<Scalar>, const Derived> TanhReturnType;
@@ -155,14 +156,26 @@
 EIGEN_DEVICE_FUNC
 inline const Log10ReturnType
 log10() const
 {
   return Log10ReturnType(derived());
 }
 
+/** \returns an expression of the coefficient-wise base-2 logarithm of *this.
+  *
+  * This function computes the coefficient-wise base-2 logarithm.
+  *
+  */
+EIGEN_DEVICE_FUNC
+inline const Log2ReturnType
+log2() const
+{
+  return Log2ReturnType(derived());
+}
+
 /** \returns an expression of the coefficient-wise square root of *this.
   *
   * This function computes the coefficient-wise square root. The function MatrixBase::sqrt() in the
   * unsupported module MatrixFunctions computes the matrix square root.
   *
   * Example: \include Cwise_sqrt.cpp
   * Output: \verbinclude Cwise_sqrt.out
@@ -480,14 +493,53 @@
 EIGEN_DEVICE_FUNC
 inline const CeilReturnType
 ceil() const
 {
   return CeilReturnType(derived());
 }
 
+template<int N> struct ShiftRightXpr {
+  typedef CwiseUnaryOp<internal::scalar_shift_right_op<Scalar, N>, const Derived> Type;
+};
+
+/** \returns an expression of \c *this with the \a Scalar type arithmetically
+  * shifted right by \a N bit positions.
+  *
+  * The template parameter \a N specifies the number of bit positions to shift.
+  * 
+  * \sa shiftLeft()
+  */
+template<int N>
+EIGEN_DEVICE_FUNC
+typename ShiftRightXpr<N>::Type
+shiftRight() const
+{
+  return typename ShiftRightXpr<N>::Type(derived());
+}
+
+
+template<int N> struct ShiftLeftXpr {
+  typedef CwiseUnaryOp<internal::scalar_shift_left_op<Scalar, N>, const Derived> Type;
+};
+
+/** \returns an expression of \c *this with the \a Scalar type logically
+  * shifted left by \a N bit positions.
+  *
+  * The template parameter \a N specifies the number of bit positions to shift.
+  *
+  * \sa shiftRight()
+  */
+template<int N>
+EIGEN_DEVICE_FUNC
+typename ShiftLeftXpr<N>::Type
+shiftLeft() const
+{
+  return typename ShiftLeftXpr<N>::Type(derived());
+}
+
 /** \returns an expression of the coefficient-wise isnan of *this.
   *
   * Example: \include Cwise_isNaN.cpp
   * Output: \verbinclude Cwise_isNaN.out
   *
   * \sa isfinite(), isinf()
   */
```

#### html2text {}

```diff
@@ -8,14 +8,15 @@
 Scalar>, const Derived> InverseReturnType; typedef CwiseUnaryOp
 Scalar>, const Derived> BooleanNotReturnType; typedef CwiseUnaryOp
 Scalar>, const Derived> ExpReturnType; typedef CwiseUnaryOp
 Scalar>, const Derived> Expm1ReturnType; typedef CwiseUnaryOp
 Scalar>, const Derived> LogReturnType; typedef CwiseUnaryOp
 Scalar>, const Derived> Log1pReturnType; typedef CwiseUnaryOp
 Scalar>, const Derived> Log10ReturnType; typedef CwiseUnaryOp
+Scalar>, const Derived> Log2ReturnType; typedef CwiseUnaryOp
 Scalar>, const Derived> CosReturnType; typedef CwiseUnaryOp
 Scalar>, const Derived> SinReturnType; typedef CwiseUnaryOp
 Scalar>, const Derived> TanReturnType; typedef CwiseUnaryOp
 Scalar>, const Derived> AcosReturnType; typedef CwiseUnaryOp
 Scalar>, const Derived> AsinReturnType; typedef CwiseUnaryOp
 Scalar>, const Derived> AtanReturnType; typedef CwiseUnaryOp
 Scalar>, const Derived> TanhReturnType; typedef CwiseUnaryOp
@@ -70,50 +71,53 @@
 functions, log() */ EIGEN_DEVICE_FUNC inline const Log1pReturnType log1p()
 const { return Log1pReturnType(derived()); } /** \returns an expression of the
 coefficient-wise base-10 logarithm of *this. * * This function computes the
 coefficient-wise base-10 logarithm. * * Example: \include Cwise_log10.cpp *
 Output: \verbinclude Cwise_log10.out * * \sa Math_functions, log() */
 EIGEN_DEVICE_FUNC inline const Log10ReturnType log10() const { return
 Log10ReturnType(derived()); } /** \returns an expression of the coefficient-
-wise square root of *this. * * This function computes the coefficient-wise
-square root. The function MatrixBase::sqrt() in the * unsupported module
-MatrixFunctions computes the matrix square root. * * Example: \include
-Cwise_sqrt.cpp * Output: \verbinclude Cwise_sqrt.out * * \sa Math_functions,
-pow(), square() */ EIGEN_DEVICE_FUNC inline const SqrtReturnType sqrt() const
-{ return SqrtReturnType(derived()); } /** \returns an expression of the
-coefficient-wise inverse square root of *this. * * This function computes the
-coefficient-wise inverse square root. * * Example: \include Cwise_sqrt.cpp *
-Output: \verbinclude Cwise_sqrt.out * * \sa pow(), square() */
-EIGEN_DEVICE_FUNC inline const RsqrtReturnType rsqrt() const { return
-RsqrtReturnType(derived()); } /** \returns an expression of the coefficient-
-wise signum of *this. * * This function computes the coefficient-wise signum. *
-* Example: \include Cwise_sign.cpp * Output: \verbinclude Cwise_sign.out * *
-\sa pow(), square() */ EIGEN_DEVICE_FUNC inline const SignReturnType sign()
-const { return SignReturnType(derived()); } /** \returns an expression of the
-coefficient-wise cosine of *this. * * This function computes the coefficient-
-wise cosine. The function MatrixBase::cos() in the * unsupported module
-MatrixFunctions computes the matrix cosine. * * Example: \include Cwise_cos.cpp
-* Output: \verbinclude Cwise_cos.out * * \sa Math_functions, sin(), acos() */
-EIGEN_DEVICE_FUNC inline const CosReturnType cos() const { return CosReturnType
-(derived()); } /** \returns an expression of the coefficient-wise sine of
-*this. * * This function computes the coefficient-wise sine. The function
-MatrixBase::sin() in the * unsupported module MatrixFunctions computes the
-matrix sine. * * Example: \include Cwise_sin.cpp * Output: \verbinclude
-Cwise_sin.out * * \sa Math_functions, cos(), asin() */ EIGEN_DEVICE_FUNC inline
-const SinReturnType sin() const { return SinReturnType(derived()); } /**
-\returns an expression of the coefficient-wise tan of *this. * * Example:
-\include Cwise_tan.cpp * Output: \verbinclude Cwise_tan.out * * \sa Math
-functions, cos(), sin() */ EIGEN_DEVICE_FUNC inline const TanReturnType tan()
-const { return TanReturnType(derived()); } /** \returns an expression of the
-coefficient-wise arc tan of *this. * * Example: \include Cwise_atan.cpp *
-Output: \verbinclude Cwise_atan.out * * \sa Math_functions, tan(), asin(), acos
-() */ EIGEN_DEVICE_FUNC inline const AtanReturnType atan() const { return
-AtanReturnType(derived()); } /** \returns an expression of the coefficient-wise
-arc cosine of *this. * * Example: \include Cwise_acos.cpp * Output:
-\verbinclude Cwise_acos.out * * \sa Math_functions, cos(), asin() */
+wise base-2 logarithm of *this. * * This function computes the coefficient-wise
+base-2 logarithm. * */ EIGEN_DEVICE_FUNC inline const Log2ReturnType log2()
+const { return Log2ReturnType(derived()); } /** \returns an expression of the
+coefficient-wise square root of *this. * * This function computes the
+coefficient-wise square root. The function MatrixBase::sqrt() in the *
+unsupported module MatrixFunctions computes the matrix square root. * *
+Example: \include Cwise_sqrt.cpp * Output: \verbinclude Cwise_sqrt.out * * \sa
+Math_functions, pow(), square() */ EIGEN_DEVICE_FUNC inline const
+SqrtReturnType sqrt() const { return SqrtReturnType(derived()); } /** \returns
+an expression of the coefficient-wise inverse square root of *this. * * This
+function computes the coefficient-wise inverse square root. * * Example:
+\include Cwise_sqrt.cpp * Output: \verbinclude Cwise_sqrt.out * * \sa pow(),
+square() */ EIGEN_DEVICE_FUNC inline const RsqrtReturnType rsqrt() const
+{ return RsqrtReturnType(derived()); } /** \returns an expression of the
+coefficient-wise signum of *this. * * This function computes the coefficient-
+wise signum. * * Example: \include Cwise_sign.cpp * Output: \verbinclude
+Cwise_sign.out * * \sa pow(), square() */ EIGEN_DEVICE_FUNC inline const
+SignReturnType sign() const { return SignReturnType(derived()); } /** \returns
+an expression of the coefficient-wise cosine of *this. * * This function
+computes the coefficient-wise cosine. The function MatrixBase::cos() in the *
+unsupported module MatrixFunctions computes the matrix cosine. * * Example:
+\include Cwise_cos.cpp * Output: \verbinclude Cwise_cos.out * * \sa Math
+functions, sin(), acos() */ EIGEN_DEVICE_FUNC inline const CosReturnType cos()
+const { return CosReturnType(derived()); } /** \returns an expression of the
+coefficient-wise sine of *this. * * This function computes the coefficient-wise
+sine. The function MatrixBase::sin() in the * unsupported module
+MatrixFunctions computes the matrix sine. * * Example: \include Cwise_sin.cpp *
+Output: \verbinclude Cwise_sin.out * * \sa Math_functions, cos(), asin() */
+EIGEN_DEVICE_FUNC inline const SinReturnType sin() const { return SinReturnType
+(derived()); } /** \returns an expression of the coefficient-wise tan of *this.
+* * Example: \include Cwise_tan.cpp * Output: \verbinclude Cwise_tan.out * *
+\sa Math_functions, cos(), sin() */ EIGEN_DEVICE_FUNC inline const
+TanReturnType tan() const { return TanReturnType(derived()); } /** \returns an
+expression of the coefficient-wise arc tan of *this. * * Example: \include
+Cwise_atan.cpp * Output: \verbinclude Cwise_atan.out * * \sa Math_functions,
+tan(), asin(), acos() */ EIGEN_DEVICE_FUNC inline const AtanReturnType atan()
+const { return AtanReturnType(derived()); } /** \returns an expression of the
+coefficient-wise arc cosine of *this. * * Example: \include Cwise_acos.cpp *
+Output: \verbinclude Cwise_acos.out * * \sa Math_functions, cos(), asin() */
 EIGEN_DEVICE_FUNC inline const AcosReturnType acos() const { return
 AcosReturnType(derived()); } /** \returns an expression of the coefficient-wise
 arc sine of *this. * * Example: \include Cwise_asin.cpp * Output: \verbinclude
 Cwise_asin.out * * \sa Math_functions, sin(), acos() */ EIGEN_DEVICE_FUNC
 inline const AsinReturnType asin() const { return AsinReturnType(derived()); }
 /** \returns an expression of the coefficient-wise hyperbolic tan of *this. * *
 Example: \include Cwise_tanh.cpp * Output: \verbinclude Cwise_tanh.out * * \sa
@@ -161,31 +165,43 @@
 } /** \returns an expression of the coefficient-wise floor of *this. * *
 Example: \include Cwise_floor.cpp * Output: \verbinclude Cwise_floor.out * *
 \sa Math_functions, ceil(), round() */ EIGEN_DEVICE_FUNC inline const
 FloorReturnType floor() const { return FloorReturnType(derived()); } /**
 \returns an expression of the coefficient-wise ceil of *this. * * Example:
 \include Cwise_ceil.cpp * Output: \verbinclude Cwise_ceil.out * * \sa Math
 functions, floor(), round() */ EIGEN_DEVICE_FUNC inline const CeilReturnType
-ceil() const { return CeilReturnType(derived()); } /** \returns an expression
-of the coefficient-wise isnan of *this. * * Example: \include Cwise_isNaN.cpp *
-Output: \verbinclude Cwise_isNaN.out * * \sa isfinite(), isinf() */
-EIGEN_DEVICE_FUNC inline const IsNaNReturnType isNaN() const { return
-IsNaNReturnType(derived()); } /** \returns an expression of the coefficient-
-wise isinf of *this. * * Example: \include Cwise_isInf.cpp * Output:
-\verbinclude Cwise_isInf.out * * \sa isnan(), isfinite() */ EIGEN_DEVICE_FUNC
-inline const IsInfReturnType isInf() const { return IsInfReturnType(derived());
-} /** \returns an expression of the coefficient-wise isfinite of *this. * *
-Example: \include Cwise_isFinite.cpp * Output: \verbinclude Cwise_isFinite.out
-* * \sa isnan(), isinf() */ EIGEN_DEVICE_FUNC inline const IsFiniteReturnType
-isFinite() const { return IsFiniteReturnType(derived()); } /** \returns an
-expression of the coefficient-wise ! operator of *this * * \warning this
-operator is for expression of bool only. * * Example: \include
-Cwise_boolean_not.cpp * Output: \verbinclude Cwise_boolean_not.out * * \sa
-operator!=() */ EIGEN_DEVICE_FUNC inline const BooleanNotReturnType operator!()
-const { EIGEN_STATIC_ASSERT((internal::is_same
+ceil() const { return CeilReturnType(derived()); } template struct
+ShiftRightXpr { typedef CwiseUnaryOp
+Scalar, N>, const Derived> Type; }; /** \returns an expression of \c *this with
+the \a Scalar type arithmetically * shifted right by \a N bit positions. * *
+The template parameter \a N specifies the number of bit positions to shift. * *
+\sa shiftLeft() */ template EIGEN_DEVICE_FUNC typename ShiftRightXpr::Type
+shiftRight() const { return typename ShiftRightXpr::Type(derived()); } template
+struct ShiftLeftXpr { typedef CwiseUnaryOp
+Scalar, N>, const Derived> Type; }; /** \returns an expression of \c *this with
+the \a Scalar type logically * shifted left by \a N bit positions. * * The
+template parameter \a N specifies the number of bit positions to shift. * * \sa
+shiftRight() */ template EIGEN_DEVICE_FUNC typename ShiftLeftXpr::Type
+shiftLeft() const { return typename ShiftLeftXpr::Type(derived()); } /**
+\returns an expression of the coefficient-wise isnan of *this. * * Example:
+\include Cwise_isNaN.cpp * Output: \verbinclude Cwise_isNaN.out * * \sa
+isfinite(), isinf() */ EIGEN_DEVICE_FUNC inline const IsNaNReturnType isNaN()
+const { return IsNaNReturnType(derived()); } /** \returns an expression of the
+coefficient-wise isinf of *this. * * Example: \include Cwise_isInf.cpp *
+Output: \verbinclude Cwise_isInf.out * * \sa isnan(), isfinite() */
+EIGEN_DEVICE_FUNC inline const IsInfReturnType isInf() const { return
+IsInfReturnType(derived()); } /** \returns an expression of the coefficient-
+wise isfinite of *this. * * Example: \include Cwise_isFinite.cpp * Output:
+\verbinclude Cwise_isFinite.out * * \sa isnan(), isinf() */ EIGEN_DEVICE_FUNC
+inline const IsFiniteReturnType isFinite() const { return IsFiniteReturnType
+(derived()); } /** \returns an expression of the coefficient-wise ! operator of
+*this * * \warning this operator is for expression of bool only. * * Example:
+\include Cwise_boolean_not.cpp * Output: \verbinclude Cwise_boolean_not.out * *
+\sa operator!=() */ EIGEN_DEVICE_FUNC inline const BooleanNotReturnType
+operator!() const { EIGEN_STATIC_ASSERT((internal::is_same
 Scalar>::value), THIS_METHOD_IS_ONLY_FOR_EXPRESSIONS_OF_BOOL); return
 BooleanNotReturnType(derived()); } // --- SpecialFunctions module --- typedef
 CwiseUnaryOp
 Scalar>, const Derived> LgammaReturnType; typedef CwiseUnaryOp
 Scalar>, const Derived> DigammaReturnType; typedef CwiseUnaryOp
 Scalar>, const Derived> ErfReturnType; typedef CwiseUnaryOp
 Scalar>, const Derived> ErfcReturnType; typedef CwiseUnaryOp
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/plugins/BlockMethods.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/plugins/BlockMethods.h`

 * *Files 0% similar despite different names*

```diff
@@ -1433,11 +1433,10 @@
   return typename internal::conditional<Direction==Vertical,ConstColXpr,ConstRowXpr>::type(derived(),i);
 }
 
 /** \returns the number of subvectors (rows or columns) in the direction \c Direction
   * \sa subVector(Index)
   */
 template<DirectionType Direction>
-EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
 Index subVectors() const
 { return (Direction==Vertical)?cols():rows(); }
-
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/plugins/CommonCwiseBinaryOps.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/plugins/CommonCwiseBinaryOps.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/plugins/CommonCwiseUnaryOps.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/plugins/CommonCwiseUnaryOps.h`

 * *Files 11% similar despite different names*

```diff
@@ -60,57 +60,14 @@
 EIGEN_DEVICE_FUNC
 typename CastXpr<NewType>::Type
 cast() const
 {
   return typename CastXpr<NewType>::Type(derived());
 }
 
-template<int N> struct ShiftRightXpr {
-  typedef CwiseUnaryOp<internal::scalar_shift_right_op<Scalar, N>, const Derived> Type;
-};
-
-/// \returns an expression of \c *this with the \a Scalar type arithmetically
-/// shifted right by \a N bit positions.
-///
-/// The template parameter \a N specifies the number of bit positions to shift.
-///
-EIGEN_DOC_UNARY_ADDONS(cast,conversion function)
-///
-/// \sa class CwiseUnaryOp
-///
-template<int N>
-EIGEN_DEVICE_FUNC
-typename ShiftRightXpr<N>::Type
-shift_right() const
-{
-  return typename ShiftRightXpr<N>::Type(derived());
-}
-
-
-template<int N> struct ShiftLeftXpr {
-  typedef CwiseUnaryOp<internal::scalar_shift_left_op<Scalar, N>, const Derived> Type;
-};
-
-/// \returns an expression of \c *this with the \a Scalar type logically
-/// shifted left by \a N bit positions.
-///
-/// The template parameter \a N specifies the number of bit positions to shift.
-///
-EIGEN_DOC_UNARY_ADDONS(cast,conversion function)
-///
-/// \sa class CwiseUnaryOp
-///
-template<int N>
-EIGEN_DEVICE_FUNC
-typename ShiftLeftXpr<N>::Type
-shift_left() const
-{
-  return typename ShiftLeftXpr<N>::Type(derived());
-}
-
 /// \returns an expression of the complex conjugate of \c *this.
 ///
 EIGEN_DOC_UNARY_ADDONS(conjugate,complex conjugate)
 ///
 /// \sa <a href="group__CoeffwiseMathFunctions.html#cwisetable_conj">Math functions</a>, MatrixBase::adjoint()
 EIGEN_DEVICE_FUNC
 inline ConjugateReturnType
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/plugins/IndexedViewMethods.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/plugins/IndexedViewMethods.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/plugins/MatrixCwiseBinaryOps.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/plugins/MatrixCwiseBinaryOps.h`

 * *Files 2% similar despite different names*

```diff
@@ -35,18 +35,18 @@
   * Example: \include MatrixBase_cwiseEqual.cpp
   * Output: \verbinclude MatrixBase_cwiseEqual.out
   *
   * \sa cwiseNotEqual(), isApprox(), isMuchSmallerThan()
   */
 template<typename OtherDerived>
 EIGEN_DEVICE_FUNC
-inline const CwiseBinaryOp<std::equal_to<Scalar>, const Derived, const OtherDerived>
+inline const CwiseBinaryOp<numext::equal_to<Scalar>, const Derived, const OtherDerived>
 cwiseEqual(const EIGEN_CURRENT_STORAGE_BASE_CLASS<OtherDerived> &other) const
 {
-  return CwiseBinaryOp<std::equal_to<Scalar>, const Derived, const OtherDerived>(derived(), other.derived());
+  return CwiseBinaryOp<numext::equal_to<Scalar>, const Derived, const OtherDerived>(derived(), other.derived());
 }
 
 /** \returns an expression of the coefficient-wise != operator of *this and \a other
   *
   * \warning this performs an exact comparison, which is generally a bad idea with floating-point types.
   * In order to check for equality between two vectors or matrices with floating-point coefficients, it is
   * generally a far better idea to use a fuzzy comparison as provided by isApprox() and
@@ -55,18 +55,18 @@
   * Example: \include MatrixBase_cwiseNotEqual.cpp
   * Output: \verbinclude MatrixBase_cwiseNotEqual.out
   *
   * \sa cwiseEqual(), isApprox(), isMuchSmallerThan()
   */
 template<typename OtherDerived>
 EIGEN_DEVICE_FUNC
-inline const CwiseBinaryOp<std::not_equal_to<Scalar>, const Derived, const OtherDerived>
+inline const CwiseBinaryOp<numext::not_equal_to<Scalar>, const Derived, const OtherDerived>
 cwiseNotEqual(const EIGEN_CURRENT_STORAGE_BASE_CLASS<OtherDerived> &other) const
 {
-  return CwiseBinaryOp<std::not_equal_to<Scalar>, const Derived, const OtherDerived>(derived(), other.derived());
+  return CwiseBinaryOp<numext::not_equal_to<Scalar>, const Derived, const OtherDerived>(derived(), other.derived());
 }
 
 /** \returns an expression of the coefficient-wise min of *this and \a other
   *
   * Example: \include MatrixBase_cwiseMin.cpp
   * Output: \verbinclude MatrixBase_cwiseMin.out
   *
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/plugins/MatrixCwiseUnaryOps.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/plugins/MatrixCwiseUnaryOps.h`

 * *Files 7% similar despite different names*

```diff
@@ -10,14 +10,15 @@
 
 // This file is included into the body of the base classes supporting matrix specific coefficient-wise functions.
 // This include MatrixBase and SparseMatrixBase.
 
 
 typedef CwiseUnaryOp<internal::scalar_abs_op<Scalar>, const Derived> CwiseAbsReturnType;
 typedef CwiseUnaryOp<internal::scalar_abs2_op<Scalar>, const Derived> CwiseAbs2ReturnType;
+typedef CwiseUnaryOp<internal::scalar_arg_op<Scalar>, const Derived> CwiseArgReturnType;
 typedef CwiseUnaryOp<internal::scalar_sqrt_op<Scalar>, const Derived> CwiseSqrtReturnType;
 typedef CwiseUnaryOp<internal::scalar_sign_op<Scalar>, const Derived> CwiseSignReturnType;
 typedef CwiseUnaryOp<internal::scalar_inverse_op<Scalar>, const Derived> CwiseInverseReturnType;
 
 /// \returns an expression of the coefficient-wise absolute value of \c *this
 ///
 /// Example: \include MatrixBase_cwiseAbs.cpp
@@ -78,8 +79,17 @@
 ///
 /// \sa cwiseProduct()
 ///
 EIGEN_DEVICE_FUNC
 inline const CwiseInverseReturnType
 cwiseInverse() const { return CwiseInverseReturnType(derived()); }
 
+/// \returns an expression of the coefficient-wise phase angle of \c *this
+///
+/// Example: \include MatrixBase_cwiseArg.cpp
+/// Output: \verbinclude MatrixBase_cwiseArg.out
+///
+EIGEN_DOC_UNARY_ADDONS(cwiseArg,arg)
 
+EIGEN_DEVICE_FUNC
+inline const CwiseArgReturnType
+cwiseArg() const { return CwiseArgReturnType(derived()); }
```

### Comparing `lightgbm-3.3.5/compile/external_libs/eigen/Eigen/src/plugins/ReshapedMethods.h` & `lightgbm-4.0.0/external_libs/eigen/Eigen/src/plugins/ReshapedMethods.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/fast_double_parser/CMakeLists.txt` & `lightgbm-4.0.0/external_libs/fast_double_parser/CMakeLists.txt`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/fast_double_parser/LICENSE` & `lightgbm-4.0.0/external_libs/fast_double_parser/LICENSE`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/fast_double_parser/LICENSE.BSL` & `lightgbm-4.0.0/external_libs/fast_double_parser/LICENSE.BSL`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/fast_double_parser/include/fast_double_parser.h` & `lightgbm-4.0.0/external_libs/fast_double_parser/include/fast_double_parser.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/fmt/LICENSE.rst` & `lightgbm-4.0.0/external_libs/fmt/LICENSE.rst`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/external_libs/fmt/include/fmt/chrono.h` & `lightgbm-4.0.0/include/LightGBM/utils/common.h`

 * *Files 24% similar despite different names*

```diff
@@ -1,1118 +1,1264 @@
-// Formatting library for C++ - chrono support
-//
-// Copyright (c) 2012 - present, Victor Zverovich
-// All rights reserved.
-//
-// For the license information refer to format.h.
-
-#ifndef FMT_CHRONO_H_
-#define FMT_CHRONO_H_
+/*!
+ * Copyright (c) 2016 Microsoft Corporation. All rights reserved.
+ * Licensed under the MIT License. See LICENSE file in the project root for license information.
+ */
+#ifndef LIGHTGBM_UTILS_COMMON_H_
+#define LIGHTGBM_UTILS_COMMON_H_
 
+#include <LightGBM/utils/json11.h>
+#include <LightGBM/utils/log.h>
+#include <LightGBM/utils/openmp_wrapper.h>
+
+#include <limits>
+#include <string>
+#include <algorithm>
 #include <chrono>
-#include <ctime>
-#include <locale>
+#include <cmath>
+#include <cstdint>
+#include <cstdio>
+#include <cstdlib>
+#include <cstring>
+#include <functional>
+#include <iomanip>
+#include <iterator>
+#include <map>
+#include <memory>
 #include <sstream>
+#include <type_traits>
+#include <unordered_map>
+#include <utility>
+#include <vector>
+
+#define FMT_HEADER_ONLY
+#include "../../../external_libs/fast_double_parser/include/fast_double_parser.h"
+#include "../../../external_libs/fmt/include/fmt/format.h"
+
+#ifdef _MSC_VER
+#include <intrin.h>
+#pragma intrinsic(_BitScanReverse)
+#endif
 
-#include "format.h"
-#include "locale.h"
+#if defined(_MSC_VER)
+#include <malloc.h>
+#elif MM_MALLOC
+#include <mm_malloc.h>
+// https://gcc.gnu.org/onlinedocs/cpp/Common-Predefined-Macros.html
+// https://www.oreilly.com/library/view/mac-os-x/0596003560/ch05s01s02.html
+#elif defined(__GNUC__) && defined(HAVE_MALLOC_H)
+  #include <malloc.h>
+  #define _mm_malloc(a, b) memalign(b, a)
+  #define _mm_free(a) free(a)
+#else
+#include <stdlib.h>
+#define _mm_malloc(a, b) malloc(a)
+#define _mm_free(a) free(a)
+#endif
 
-FMT_BEGIN_NAMESPACE
+namespace LightGBM {
 
-// Enable safe chrono durations, unless explicitly disabled.
-#ifndef FMT_SAFE_DURATION_CAST
-#  define FMT_SAFE_DURATION_CAST 1
-#endif
-#if FMT_SAFE_DURATION_CAST
+namespace Common {
+
+using json11_internal_lightgbm::Json;
+
+/*!
+* Imbues the stream with the C locale.
+*/
+static void C_stringstream(std::stringstream &ss) {
+  ss.imbue(std::locale::classic());
+}
+
+inline static char tolower(char in) {
+  if (in <= 'Z' && in >= 'A')
+    return in - ('Z' - 'z');
+  return in;
+}
+
+inline static std::string Trim(std::string str) {
+  if (str.empty()) {
+    return str;
+  }
+  str.erase(str.find_last_not_of(" \f\n\r\t\v") + 1);
+  str.erase(0, str.find_first_not_of(" \f\n\r\t\v"));
+  return str;
+}
+
+inline static std::string RemoveQuotationSymbol(std::string str) {
+  if (str.empty()) {
+    return str;
+  }
+  str.erase(str.find_last_not_of("'\"") + 1);
+  str.erase(0, str.find_first_not_of("'\""));
+  return str;
+}
 
-// For conversion between std::chrono::durations without undefined
-// behaviour or erroneous results.
-// This is a stripped down version of duration_cast, for inclusion in fmt.
-// See https://github.com/pauldreik/safe_duration_cast
-//
-// Copyright Paul Dreik 2019
-namespace safe_duration_cast {
-
-template <typename To, typename From,
-          FMT_ENABLE_IF(!std::is_same<From, To>::value &&
-                        std::numeric_limits<From>::is_signed ==
-                            std::numeric_limits<To>::is_signed)>
-FMT_CONSTEXPR To lossless_integral_conversion(const From from, int& ec) {
-  ec = 0;
-  using F = std::numeric_limits<From>;
-  using T = std::numeric_limits<To>;
-  static_assert(F::is_integer, "From must be integral");
-  static_assert(T::is_integer, "To must be integral");
-
-  // A and B are both signed, or both unsigned.
-  if (F::digits <= T::digits) {
-    // From fits in To without any problem.
+inline static bool StartsWith(const std::string& str, const std::string prefix) {
+  if (str.substr(0, prefix.size()) == prefix) {
+    return true;
   } else {
-    // From does not always fit in To, resort to a dynamic check.
-    if (from < (T::min)() || from > (T::max)()) {
-      // outside range.
-      ec = 1;
-      return {};
+    return false;
+  }
+}
+
+inline static std::vector<std::string> Split(const char* c_str, char delimiter) {
+  std::vector<std::string> ret;
+  std::string str(c_str);
+  size_t i = 0;
+  size_t pos = 0;
+  while (pos < str.length()) {
+    if (str[pos] == delimiter) {
+      if (i < pos) {
+        ret.push_back(str.substr(i, pos - i));
+      }
+      ++pos;
+      i = pos;
+    } else {
+      ++pos;
     }
   }
-  return static_cast<To>(from);
+  if (i < pos) {
+    ret.push_back(str.substr(i));
+  }
+  return ret;
 }
 
-/**
- * converts From to To, without loss. If the dynamic value of from
- * can't be converted to To without loss, ec is set.
- */
-template <typename To, typename From,
-          FMT_ENABLE_IF(!std::is_same<From, To>::value &&
-                        std::numeric_limits<From>::is_signed !=
-                            std::numeric_limits<To>::is_signed)>
-FMT_CONSTEXPR To lossless_integral_conversion(const From from, int& ec) {
-  ec = 0;
-  using F = std::numeric_limits<From>;
-  using T = std::numeric_limits<To>;
-  static_assert(F::is_integer, "From must be integral");
-  static_assert(T::is_integer, "To must be integral");
-
-  if (detail::const_check(F::is_signed && !T::is_signed)) {
-    // From may be negative, not allowed!
-    if (fmt::detail::is_negative(from)) {
-      ec = 1;
-      return {};
-    }
-    // From is positive. Can it always fit in To?
-    if (F::digits > T::digits &&
-        from > static_cast<From>(detail::max_value<To>())) {
-      ec = 1;
-      return {};
+inline static std::vector<std::string> SplitBrackets(const char* c_str, char left_delimiter, char right_delimiter) {
+  std::vector<std::string> ret;
+  std::string str(c_str);
+  size_t i = 0;
+  size_t pos = 0;
+  bool open = false;
+  while (pos < str.length()) {
+    if (str[pos] == left_delimiter) {
+      open = true;
+      ++pos;
+      i = pos;
+    } else if (str[pos] == right_delimiter && open) {
+      if (i < pos) {
+        ret.push_back(str.substr(i, pos - i));
+      }
+      open = false;
+      ++pos;
+    } else {
+      ++pos;
     }
   }
+  return ret;
+}
 
-  if (!F::is_signed && T::is_signed && F::digits >= T::digits &&
-      from > static_cast<From>(detail::max_value<To>())) {
-    ec = 1;
-    return {};
-  }
-  return static_cast<To>(from);  // Lossless conversion.
-}
-
-template <typename To, typename From,
-          FMT_ENABLE_IF(std::is_same<From, To>::value)>
-FMT_CONSTEXPR To lossless_integral_conversion(const From from, int& ec) {
-  ec = 0;
-  return from;
-}  // function
-
-// clang-format off
-/**
- * converts From to To if possible, otherwise ec is set.
- *
- * input                            |    output
- * ---------------------------------|---------------
- * NaN                              | NaN
- * Inf                              | Inf
- * normal, fits in output           | converted (possibly lossy)
- * normal, does not fit in output   | ec is set
- * subnormal                        | best effort
- * -Inf                             | -Inf
- */
-// clang-format on
-template <typename To, typename From,
-          FMT_ENABLE_IF(!std::is_same<From, To>::value)>
-FMT_CONSTEXPR To safe_float_conversion(const From from, int& ec) {
-  ec = 0;
-  using T = std::numeric_limits<To>;
-  static_assert(std::is_floating_point<From>::value, "From must be floating");
-  static_assert(std::is_floating_point<To>::value, "To must be floating");
-
-  // catch the only happy case
-  if (std::isfinite(from)) {
-    if (from >= T::lowest() && from <= (T::max)()) {
-      return static_cast<To>(from);
-    }
-    // not within range.
-    ec = 1;
-    return {};
-  }
-
-  // nan and inf will be preserved
-  return static_cast<To>(from);
-}  // function
-
-template <typename To, typename From,
-          FMT_ENABLE_IF(std::is_same<From, To>::value)>
-FMT_CONSTEXPR To safe_float_conversion(const From from, int& ec) {
-  ec = 0;
-  static_assert(std::is_floating_point<From>::value, "From must be floating");
-  return from;
+inline static std::vector<std::string> SplitLines(const char* c_str) {
+  std::vector<std::string> ret;
+  std::string str(c_str);
+  size_t i = 0;
+  size_t pos = 0;
+  while (pos < str.length()) {
+    if (str[pos] == '\n' || str[pos] == '\r') {
+      if (i < pos) {
+        ret.push_back(str.substr(i, pos - i));
+      }
+      // skip the line endings
+      while (str[pos] == '\n' || str[pos] == '\r') ++pos;
+      // new begin
+      i = pos;
+    } else {
+      ++pos;
+    }
+  }
+  if (i < pos) {
+    ret.push_back(str.substr(i));
+  }
+  return ret;
 }
 
-/**
- * safe duration cast between integral durations
- */
-template <typename To, typename FromRep, typename FromPeriod,
-          FMT_ENABLE_IF(std::is_integral<FromRep>::value),
-          FMT_ENABLE_IF(std::is_integral<typename To::rep>::value)>
-To safe_duration_cast(std::chrono::duration<FromRep, FromPeriod> from,
-                      int& ec) {
-  using From = std::chrono::duration<FromRep, FromPeriod>;
-  ec = 0;
-  // the basic idea is that we need to convert from count() in the from type
-  // to count() in the To type, by multiplying it with this:
-  struct Factor
-      : std::ratio_divide<typename From::period, typename To::period> {};
-
-  static_assert(Factor::num > 0, "num must be positive");
-  static_assert(Factor::den > 0, "den must be positive");
-
-  // the conversion is like this: multiply from.count() with Factor::num
-  // /Factor::den and convert it to To::rep, all this without
-  // overflow/underflow. let's start by finding a suitable type that can hold
-  // both To, From and Factor::num
-  using IntermediateRep =
-      typename std::common_type<typename From::rep, typename To::rep,
-                                decltype(Factor::num)>::type;
-
-  // safe conversion to IntermediateRep
-  IntermediateRep count =
-      lossless_integral_conversion<IntermediateRep>(from.count(), ec);
-  if (ec) return {};
-  // multiply with Factor::num without overflow or underflow
-  if (detail::const_check(Factor::num != 1)) {
-    const auto max1 = detail::max_value<IntermediateRep>() / Factor::num;
-    if (count > max1) {
-      ec = 1;
-      return {};
-    }
-    const auto min1 =
-        (std::numeric_limits<IntermediateRep>::min)() / Factor::num;
-    if (count < min1) {
-      ec = 1;
-      return {};
-    }
-    count *= Factor::num;
-  }
-
-  if (detail::const_check(Factor::den != 1)) count /= Factor::den;
-  auto tocount = lossless_integral_conversion<typename To::rep>(count, ec);
-  return ec ? To() : To(tocount);
+inline static std::vector<std::string> Split(const char* c_str, const char* delimiters) {
+  std::vector<std::string> ret;
+  std::string str(c_str);
+  size_t i = 0;
+  size_t pos = 0;
+  while (pos < str.length()) {
+    bool met_delimiters = false;
+    for (int j = 0; delimiters[j] != '\0'; ++j) {
+      if (str[pos] == delimiters[j]) {
+        met_delimiters = true;
+        break;
+      }
+    }
+    if (met_delimiters) {
+      if (i < pos) {
+        ret.push_back(str.substr(i, pos - i));
+      }
+      ++pos;
+      i = pos;
+    } else {
+      ++pos;
+    }
+  }
+  if (i < pos) {
+    ret.push_back(str.substr(i));
+  }
+  return ret;
 }
 
-/**
- * safe duration_cast between floating point durations
- */
-template <typename To, typename FromRep, typename FromPeriod,
-          FMT_ENABLE_IF(std::is_floating_point<FromRep>::value),
-          FMT_ENABLE_IF(std::is_floating_point<typename To::rep>::value)>
-To safe_duration_cast(std::chrono::duration<FromRep, FromPeriod> from,
-                      int& ec) {
-  using From = std::chrono::duration<FromRep, FromPeriod>;
-  ec = 0;
-  if (std::isnan(from.count())) {
-    // nan in, gives nan out. easy.
-    return To{std::numeric_limits<typename To::rep>::quiet_NaN()};
-  }
-  // maybe we should also check if from is denormal, and decide what to do about
-  // it.
-
-  // +-inf should be preserved.
-  if (std::isinf(from.count())) {
-    return To{from.count()};
-  }
-
-  // the basic idea is that we need to convert from count() in the from type
-  // to count() in the To type, by multiplying it with this:
-  struct Factor
-      : std::ratio_divide<typename From::period, typename To::period> {};
-
-  static_assert(Factor::num > 0, "num must be positive");
-  static_assert(Factor::den > 0, "den must be positive");
-
-  // the conversion is like this: multiply from.count() with Factor::num
-  // /Factor::den and convert it to To::rep, all this without
-  // overflow/underflow. let's start by finding a suitable type that can hold
-  // both To, From and Factor::num
-  using IntermediateRep =
-      typename std::common_type<typename From::rep, typename To::rep,
-                                decltype(Factor::num)>::type;
-
-  // force conversion of From::rep -> IntermediateRep to be safe,
-  // even if it will never happen be narrowing in this context.
-  IntermediateRep count =
-      safe_float_conversion<IntermediateRep>(from.count(), ec);
-  if (ec) {
-    return {};
-  }
-
-  // multiply with Factor::num without overflow or underflow
-  if (Factor::num != 1) {
-    constexpr auto max1 = detail::max_value<IntermediateRep>() /
-                          static_cast<IntermediateRep>(Factor::num);
-    if (count > max1) {
-      ec = 1;
-      return {};
-    }
-    constexpr auto min1 = std::numeric_limits<IntermediateRep>::lowest() /
-                          static_cast<IntermediateRep>(Factor::num);
-    if (count < min1) {
-      ec = 1;
-      return {};
-    }
-    count *= static_cast<IntermediateRep>(Factor::num);
-  }
-
-  // this can't go wrong, right? den>0 is checked earlier.
-  if (Factor::den != 1) {
-    using common_t = typename std::common_type<IntermediateRep, intmax_t>::type;
-    count /= static_cast<common_t>(Factor::den);
-  }
-
-  // convert to the to type, safely
-  using ToRep = typename To::rep;
-
-  const ToRep tocount = safe_float_conversion<ToRep>(count, ec);
-  if (ec) {
-    return {};
+inline static std::string GetFromParserConfig(std::string config_str, std::string key) {
+  // parser config should follow json format.
+  std::string err;
+  Json config_json = Json::parse(config_str, &err);
+  if (!err.empty()) {
+    Log::Fatal("Invalid parser config: %s. Please check if follow json format.", err.c_str());
   }
-  return To{tocount};
+  return config_json[key].string_value();
 }
-}  // namespace safe_duration_cast
-#endif
 
-// Prevents expansion of a preceding token as a function-style macro.
-// Usage: f FMT_NOMACRO()
-#define FMT_NOMACRO
+inline static std::string SaveToParserConfig(std::string config_str, std::string key, std::string value) {
+  std::string err;
+  Json config_json = Json::parse(config_str, &err);
+  if (!err.empty()) {
+    Log::Fatal("Invalid parser config: %s. Please check if follow json format.", err.c_str());
+  }
+  CHECK(config_json.is_object());
+  std::map<std::string, Json> config_map = config_json.object_items();
+  config_map.insert(std::pair<std::string, Json>(key, Json(value)));
+  return Json(config_map).dump();
+}
 
-namespace detail {
-inline null<> localtime_r FMT_NOMACRO(...) { return null<>(); }
-inline null<> localtime_s(...) { return null<>(); }
-inline null<> gmtime_r(...) { return null<>(); }
-inline null<> gmtime_s(...) { return null<>(); }
-}  // namespace detail
+template<typename T>
+inline static const char* Atoi(const char* p, T* out) {
+  int sign;
+  T value;
+  while (*p == ' ') {
+    ++p;
+  }
+  sign = 1;
+  if (*p == '-') {
+    sign = -1;
+    ++p;
+  } else if (*p == '+') {
+    ++p;
+  }
+  for (value = 0; *p >= '0' && *p <= '9'; ++p) {
+    value = value * 10 + (*p - '0');
+  }
+  *out = static_cast<T>(sign * value);
+  while (*p == ' ') {
+    ++p;
+  }
+  return p;
+}
 
-// Thread-safe replacement for std::localtime
-inline std::tm localtime(std::time_t time) {
-  struct dispatcher {
-    std::time_t time_;
-    std::tm tm_;
+template<typename T>
+inline static double Pow(T base, int power) {
+  if (power < 0) {
+    return 1.0 / Pow(base, -power);
+  } else if (power == 0) {
+    return 1;
+  } else if (power % 2 == 0) {
+    return Pow(base*base, power / 2);
+  } else if (power % 3 == 0) {
+    return Pow(base*base*base, power / 3);
+  } else {
+    return base * Pow(base, power - 1);
+  }
+}
 
-    dispatcher(std::time_t t) : time_(t) {}
+inline static const char* Atof(const char* p, double* out) {
+  int frac;
+  double sign, value, scale;
+  *out = NAN;
+  // Skip leading white space, if any.
+  while (*p == ' ') {
+    ++p;
+  }
+  // Get sign, if any.
+  sign = 1.0;
+  if (*p == '-') {
+    sign = -1.0;
+    ++p;
+  } else if (*p == '+') {
+    ++p;
+  }
+
+  // is a number
+  if ((*p >= '0' && *p <= '9') || *p == '.' || *p == 'e' || *p == 'E') {
+    // Get digits before decimal point or exponent, if any.
+    for (value = 0.0; *p >= '0' && *p <= '9'; ++p) {
+      value = value * 10.0 + (*p - '0');
+    }
+
+    // Get digits after decimal point, if any.
+    if (*p == '.') {
+      double right = 0.0;
+      int nn = 0;
+      ++p;
+      while (*p >= '0' && *p <= '9') {
+        right = (*p - '0') + right * 10.0;
+        ++nn;
+        ++p;
+      }
+      value += right / Pow(10.0, nn);
+    }
 
-    bool run() {
-      using namespace fmt::detail;
-      return handle(localtime_r(&time_, &tm_));
+    // Handle exponent, if any.
+    frac = 0;
+    scale = 1.0;
+    if ((*p == 'e') || (*p == 'E')) {
+      uint32_t expon;
+      // Get sign of exponent, if any.
+      ++p;
+      if (*p == '-') {
+        frac = 1;
+        ++p;
+      } else if (*p == '+') {
+        ++p;
+      }
+      // Get digits of exponent, if any.
+      for (expon = 0; *p >= '0' && *p <= '9'; ++p) {
+        expon = expon * 10 + (*p - '0');
+      }
+      if (expon > 308) expon = 308;
+      // Calculate scaling factor.
+      while (expon >= 50) { scale *= 1E50; expon -= 50; }
+      while (expon >= 8) { scale *= 1E8;  expon -= 8; }
+      while (expon > 0) { scale *= 10.0; expon -= 1; }
+    }
+    // Return signed and scaled floating point result.
+    *out = sign * (frac ? (value / scale) : (value * scale));
+  } else {
+    size_t cnt = 0;
+    while (*(p + cnt) != '\0' && *(p + cnt) != ' '
+           && *(p + cnt) != '\t' && *(p + cnt) != ','
+           && *(p + cnt) != '\n' && *(p + cnt) != '\r'
+           && *(p + cnt) != ':') {
+      ++cnt;
+    }
+    if (cnt > 0) {
+      std::string tmp_str(p, cnt);
+      std::transform(tmp_str.begin(), tmp_str.end(), tmp_str.begin(), Common::tolower);
+      if (tmp_str == std::string("na") || tmp_str == std::string("nan") ||
+          tmp_str == std::string("null")) {
+        *out = NAN;
+      } else if (tmp_str == std::string("inf") || tmp_str == std::string("infinity")) {
+        *out = sign * 1e308;
+      } else {
+        Log::Fatal("Unknown token %s in data file", tmp_str.c_str());
+      }
+      p += cnt;
     }
+  }
 
-    bool handle(std::tm* tm) { return tm != nullptr; }
+  while (*p == ' ') {
+    ++p;
+  }
 
-    bool handle(detail::null<>) {
-      using namespace fmt::detail;
-      return fallback(localtime_s(&tm_, &time_));
-    }
+  return p;
+}
 
-    bool fallback(int res) { return res == 0; }
+// Use fast_double_parse and strtod (if parse failed) to parse double.
+inline static const char* AtofPrecise(const char* p, double* out) {
+  const char* end = fast_double_parser::parse_number(p, out);
 
-#if !FMT_MSC_VER
-    bool fallback(detail::null<>) {
-      using namespace fmt::detail;
-      std::tm* tm = std::localtime(&time_);
-      if (tm) tm_ = *tm;
-      return tm != nullptr;
-    }
-#endif
-  };
-  dispatcher lt(time);
-  // Too big time values may be unsupported.
-  if (!lt.run()) FMT_THROW(format_error("time_t value out of range"));
-  return lt.tm_;
+  if (end != nullptr) {
+    return end;
+  }
+
+  // Rare path: Not in RFC 7159 format. Possible "inf", "nan", etc. Fallback to standard library:
+  char* end2;
+  errno = 0;  // This is Required before calling strtod.
+  *out = std::strtod(p, &end2);  // strtod is locale aware.
+  if (end2 == p) {
+    Log::Fatal("no conversion to double for: %s", p);
+  }
+  if (errno == ERANGE) {
+    Log::Warning("convert to double got underflow or overflow: %s", p);
+  }
+  return end2;
+}
+
+inline static bool AtoiAndCheck(const char* p, int* out) {
+  const char* after = Atoi(p, out);
+  if (*after != '\0') {
+    return false;
+  }
+  return true;
 }
 
-inline std::tm localtime(
-    std::chrono::time_point<std::chrono::system_clock> time_point) {
-  return localtime(std::chrono::system_clock::to_time_t(time_point));
+inline static bool AtofAndCheck(const char* p, double* out) {
+  const char* after = Atof(p, out);
+  if (*after != '\0') {
+    return false;
+  }
+  return true;
 }
 
-// Thread-safe replacement for std::gmtime
-inline std::tm gmtime(std::time_t time) {
-  struct dispatcher {
-    std::time_t time_;
-    std::tm tm_;
+inline static const char* SkipSpaceAndTab(const char* p) {
+  while (*p == ' ' || *p == '\t') {
+    ++p;
+  }
+  return p;
+}
 
-    dispatcher(std::time_t t) : time_(t) {}
+inline static const char* SkipReturn(const char* p) {
+  while (*p == '\n' || *p == '\r' || *p == ' ') {
+    ++p;
+  }
+  return p;
+}
 
-    bool run() {
-      using namespace fmt::detail;
-      return handle(gmtime_r(&time_, &tm_));
-    }
+template<typename T, typename T2>
+inline static std::vector<T2> ArrayCast(const std::vector<T>& arr) {
+  std::vector<T2> ret(arr.size());
+  for (size_t i = 0; i < arr.size(); ++i) {
+    ret[i] = static_cast<T2>(arr[i]);
+  }
+  return ret;
+}
 
-    bool handle(std::tm* tm) { return tm != nullptr; }
+template<typename T, bool is_float>
+struct __StringToTHelper {
+  T operator()(const std::string& str) const {
+    T ret = 0;
+    Atoi(str.c_str(), &ret);
+    return ret;
+  }
+};
 
-    bool handle(detail::null<>) {
-      using namespace fmt::detail;
-      return fallback(gmtime_s(&tm_, &time_));
-    }
+template<typename T>
+struct __StringToTHelper<T, true> {
+  T operator()(const std::string& str) const {
+    return static_cast<T>(std::stod(str));
+  }
+};
+
+template<typename T>
+inline static std::vector<T> StringToArray(const std::string& str, char delimiter) {
+  std::vector<std::string> strs = Split(str.c_str(), delimiter);
+  std::vector<T> ret;
+  ret.reserve(strs.size());
+  __StringToTHelper<T, std::is_floating_point<T>::value> helper;
+  for (const auto& s : strs) {
+    ret.push_back(helper(s));
+  }
+  return ret;
+}
+
+template<typename T>
+inline static std::vector<std::vector<T>> StringToArrayofArrays(
+    const std::string& str, char left_bracket, char right_bracket, char delimiter) {
+  std::vector<std::string> strs = SplitBrackets(str.c_str(), left_bracket, right_bracket);
+  std::vector<std::vector<T>> ret;
+  for (const auto& s : strs) {
+    ret.push_back(StringToArray<T>(s, delimiter));
+  }
+  return ret;
+}
+
+template<typename T>
+inline static std::vector<T> StringToArray(const std::string& str, int n) {
+  if (n == 0) {
+    return std::vector<T>();
+  }
+  std::vector<std::string> strs = Split(str.c_str(), ' ');
+  CHECK_EQ(strs.size(), static_cast<size_t>(n));
+  std::vector<T> ret;
+  ret.reserve(strs.size());
+  __StringToTHelper<T, std::is_floating_point<T>::value> helper;
+  for (const auto& s : strs) {
+    ret.push_back(helper(s));
+  }
+  return ret;
+}
+
+template<typename T, bool is_float>
+struct __StringToTHelperFast {
+  const char* operator()(const char*p, T* out) const {
+    return Atoi(p, out);
+  }
+};
 
-    bool fallback(int res) { return res == 0; }
+template<typename T>
+struct __StringToTHelperFast<T, true> {
+  const char* operator()(const char*p, T* out) const {
+    double tmp = 0.0f;
+    auto ret = Atof(p, &tmp);
+    *out = static_cast<T>(tmp);
+    return ret;
+  }
+};
+
+template<typename T>
+inline static std::vector<T> StringToArrayFast(const std::string& str, int n) {
+  if (n == 0) {
+    return std::vector<T>();
+  }
+  auto p_str = str.c_str();
+  __StringToTHelperFast<T, std::is_floating_point<T>::value> helper;
+  std::vector<T> ret(n);
+  for (int i = 0; i < n; ++i) {
+    p_str = helper(p_str, &ret[i]);
+  }
+  return ret;
+}
 
-#if !FMT_MSC_VER
-    bool fallback(detail::null<>) {
-      std::tm* tm = std::gmtime(&time_);
-      if (tm) tm_ = *tm;
-      return tm != nullptr;
+template<typename T>
+inline static std::string Join(const std::vector<T>& strs, const char* delimiter, const bool force_C_locale = false) {
+  if (strs.empty()) {
+    return std::string("");
+  }
+  std::stringstream str_buf;
+  if (force_C_locale) {
+    C_stringstream(str_buf);
+  }
+  str_buf << std::setprecision(std::numeric_limits<double>::digits10 + 2);
+  str_buf << strs[0];
+  for (size_t i = 1; i < strs.size(); ++i) {
+    str_buf << delimiter;
+    str_buf << strs[i];
+  }
+  return str_buf.str();
+}
+
+template<>
+inline std::string Join<int8_t>(const std::vector<int8_t>& strs, const char* delimiter, const bool force_C_locale) {
+  if (strs.empty()) {
+    return std::string("");
+  }
+  std::stringstream str_buf;
+  if (force_C_locale) {
+    C_stringstream(str_buf);
+  }
+  str_buf << std::setprecision(std::numeric_limits<double>::digits10 + 2);
+  str_buf << static_cast<int16_t>(strs[0]);
+  for (size_t i = 1; i < strs.size(); ++i) {
+    str_buf << delimiter;
+    str_buf << static_cast<int16_t>(strs[i]);
+  }
+  return str_buf.str();
+}
+
+template<typename T>
+inline static std::string Join(const std::vector<T>& strs, size_t start, size_t end, const char* delimiter, const bool force_C_locale = false) {
+  if (end - start <= 0) {
+    return std::string("");
+  }
+  start = std::min(start, static_cast<size_t>(strs.size()) - 1);
+  end = std::min(end, static_cast<size_t>(strs.size()));
+  std::stringstream str_buf;
+  if (force_C_locale) {
+    C_stringstream(str_buf);
+  }
+  str_buf << std::setprecision(std::numeric_limits<double>::digits10 + 2);
+  str_buf << strs[start];
+  for (size_t i = start + 1; i < end; ++i) {
+    str_buf << delimiter;
+    str_buf << strs[i];
+  }
+  return str_buf.str();
+}
+
+inline static int64_t Pow2RoundUp(int64_t x) {
+  int64_t t = 1;
+  for (int i = 0; i < 64; ++i) {
+    if (t >= x) {
+      return t;
     }
-#endif
-  };
-  dispatcher gt(time);
-  // Too big time values may be unsupported.
-  if (!gt.run()) FMT_THROW(format_error("time_t value out of range"));
-  return gt.tm_;
+    t <<= 1;
+  }
+  return 0;
 }
 
-inline std::tm gmtime(
-    std::chrono::time_point<std::chrono::system_clock> time_point) {
-  return gmtime(std::chrono::system_clock::to_time_t(time_point));
+/*!
+ * \brief Do inplace softmax transformation on p_rec
+ * \param p_rec The input/output vector of the values.
+ */
+inline static void Softmax(std::vector<double>* p_rec) {
+  std::vector<double> &rec = *p_rec;
+  double wmax = rec[0];
+  for (size_t i = 1; i < rec.size(); ++i) {
+    wmax = std::max(rec[i], wmax);
+  }
+  double wsum = 0.0f;
+  for (size_t i = 0; i < rec.size(); ++i) {
+    rec[i] = std::exp(rec[i] - wmax);
+    wsum += rec[i];
+  }
+  for (size_t i = 0; i < rec.size(); ++i) {
+    rec[i] /= static_cast<double>(wsum);
+  }
 }
 
-namespace detail {
-inline size_t strftime(char* str, size_t count, const char* format,
-                       const std::tm* time) {
-  return std::strftime(str, count, format, time);
+inline static void Softmax(const double* input, double* output, int len) {
+  double wmax = input[0];
+  for (int i = 1; i < len; ++i) {
+    wmax = std::max(input[i], wmax);
+  }
+  double wsum = 0.0f;
+  for (int i = 0; i < len; ++i) {
+    output[i] = std::exp(input[i] - wmax);
+    wsum += output[i];
+  }
+  for (int i = 0; i < len; ++i) {
+    output[i] /= static_cast<double>(wsum);
+  }
 }
 
-inline size_t strftime(wchar_t* str, size_t count, const wchar_t* format,
-                       const std::tm* time) {
-  return std::wcsftime(str, count, format, time);
+template<typename T>
+std::vector<const T*> ConstPtrInVectorWrapper(const std::vector<std::unique_ptr<T>>& input) {
+  std::vector<const T*> ret;
+  for (auto t = input.begin(); t !=input.end(); ++t) {
+    ret.push_back(t->get());
+  }
+  return ret;
 }
-}  // namespace detail
 
-template <typename Char>
-struct formatter<std::chrono::time_point<std::chrono::system_clock>, Char>
-    : formatter<std::tm, Char> {
-  template <typename FormatContext>
-  auto format(std::chrono::time_point<std::chrono::system_clock> val,
-              FormatContext& ctx) -> decltype(ctx.out()) {
-    std::tm time = localtime(val);
-    return formatter<std::tm, Char>::format(time, ctx);
+template<typename T1, typename T2>
+inline static void SortForPair(std::vector<T1>* keys, std::vector<T2>* values, size_t start, bool is_reverse = false) {
+  std::vector<std::pair<T1, T2>> arr;
+  auto& ref_key = *keys;
+  auto& ref_value = *values;
+  for (size_t i = start; i < keys->size(); ++i) {
+    arr.emplace_back(ref_key[i], ref_value[i]);
   }
-};
+  if (!is_reverse) {
+    std::stable_sort(arr.begin(), arr.end(), [](const std::pair<T1, T2>& a, const std::pair<T1, T2>& b) {
+      return a.first < b.first;
+    });
+  } else {
+    std::stable_sort(arr.begin(), arr.end(), [](const std::pair<T1, T2>& a, const std::pair<T1, T2>& b) {
+      return a.first > b.first;
+    });
+  }
+  for (size_t i = start; i < arr.size(); ++i) {
+    ref_key[i] = arr[i].first;
+    ref_value[i] = arr[i].second;
+  }
+}
 
-template <typename Char> struct formatter<std::tm, Char> {
-  template <typename ParseContext>
-  auto parse(ParseContext& ctx) -> decltype(ctx.begin()) {
-    auto it = ctx.begin();
-    if (it != ctx.end() && *it == ':') ++it;
-    auto end = it;
-    while (end != ctx.end() && *end != '}') ++end;
-    tm_format.reserve(detail::to_unsigned(end - it + 1));
-    tm_format.append(it, end);
-    tm_format.push_back('\0');
-    return end;
+template <typename T>
+inline static std::vector<T*> Vector2Ptr(std::vector<std::vector<T>>* data) {
+  std::vector<T*> ptr(data->size());
+  auto& ref_data = *data;
+  for (size_t i = 0; i < data->size(); ++i) {
+    ptr[i] = ref_data[i].data();
   }
+  return ptr;
+}
 
-  template <typename FormatContext>
-  auto format(const std::tm& tm, FormatContext& ctx) -> decltype(ctx.out()) {
-    basic_memory_buffer<Char> buf;
-    size_t start = buf.size();
-    for (;;) {
-      size_t size = buf.capacity() - start;
-      size_t count = detail::strftime(&buf[start], size, &tm_format[0], &tm);
-      if (count != 0) {
-        buf.resize(start + count);
-        break;
-      }
-      if (size >= tm_format.size() * 256) {
-        // If the buffer is 256 times larger than the format string, assume
-        // that `strftime` gives an empty result. There doesn't seem to be a
-        // better way to distinguish the two cases:
-        // https://github.com/fmtlib/fmt/issues/367
-        break;
-      }
-      const size_t MIN_GROWTH = 10;
-      buf.reserve(buf.capacity() + (size > MIN_GROWTH ? size : MIN_GROWTH));
-    }
-    return std::copy(buf.begin(), buf.end(), ctx.out());
+template <typename T>
+inline static std::vector<int> VectorSize(const std::vector<std::vector<T>>& data) {
+  std::vector<int> ret(data.size());
+  for (size_t i = 0; i < data.size(); ++i) {
+    ret[i] = static_cast<int>(data[i].size());
+  }
+  return ret;
+}
+
+inline static double AvoidInf(double x) {
+  if (std::isnan(x)) {
+    return 0.0;
+  } else if (x >= 1e300) {
+    return 1e300;
+  } else if (x <= -1e300) {
+    return -1e300;
+  } else {
+    return x;
   }
+}
 
-  basic_memory_buffer<Char> tm_format;
-};
+inline static float AvoidInf(float x) {
+  if (std::isnan(x)) {
+    return 0.0f;
+  } else if (x >= 1e38) {
+    return 1e38f;
+  } else if (x <= -1e38) {
+    return -1e38f;
+  } else {
+    return x;
+  }
+}
 
-namespace detail {
-template <typename Period> FMT_CONSTEXPR const char* get_units() {
-  return nullptr;
-}
-template <> FMT_CONSTEXPR const char* get_units<std::atto>() { return "as"; }
-template <> FMT_CONSTEXPR const char* get_units<std::femto>() { return "fs"; }
-template <> FMT_CONSTEXPR const char* get_units<std::pico>() { return "ps"; }
-template <> FMT_CONSTEXPR const char* get_units<std::nano>() { return "ns"; }
-template <> FMT_CONSTEXPR const char* get_units<std::micro>() { return "µs"; }
-template <> FMT_CONSTEXPR const char* get_units<std::milli>() { return "ms"; }
-template <> FMT_CONSTEXPR const char* get_units<std::centi>() { return "cs"; }
-template <> FMT_CONSTEXPR const char* get_units<std::deci>() { return "ds"; }
-template <> FMT_CONSTEXPR const char* get_units<std::ratio<1>>() { return "s"; }
-template <> FMT_CONSTEXPR const char* get_units<std::deca>() { return "das"; }
-template <> FMT_CONSTEXPR const char* get_units<std::hecto>() { return "hs"; }
-template <> FMT_CONSTEXPR const char* get_units<std::kilo>() { return "ks"; }
-template <> FMT_CONSTEXPR const char* get_units<std::mega>() { return "Ms"; }
-template <> FMT_CONSTEXPR const char* get_units<std::giga>() { return "Gs"; }
-template <> FMT_CONSTEXPR const char* get_units<std::tera>() { return "Ts"; }
-template <> FMT_CONSTEXPR const char* get_units<std::peta>() { return "Ps"; }
-template <> FMT_CONSTEXPR const char* get_units<std::exa>() { return "Es"; }
-template <> FMT_CONSTEXPR const char* get_units<std::ratio<60>>() {
-  return "m";
-}
-template <> FMT_CONSTEXPR const char* get_units<std::ratio<3600>>() {
-  return "h";
-}
-
-enum class numeric_system {
-  standard,
-  // Alternative numeric system, e.g. 十二 instead of 12 in ja_JP locale.
-  alternative
-};
+template<typename _Iter> inline
+static typename std::iterator_traits<_Iter>::value_type* IteratorValType(_Iter) {
+  return (0);
+}
+
+template<typename _RanIt, typename _Pr, typename _VTRanIt> inline
+static void ParallelSort(_RanIt _First, _RanIt _Last, _Pr _Pred, _VTRanIt*) {
+  size_t len = _Last - _First;
+  const size_t kMinInnerLen = 1024;
+  int num_threads = OMP_NUM_THREADS();
+  if (len <= kMinInnerLen || num_threads <= 1) {
+    std::sort(_First, _Last, _Pred);
+    return;
+  }
+  size_t inner_size = (len + num_threads - 1) / num_threads;
+  inner_size = std::max(inner_size, kMinInnerLen);
+  num_threads = static_cast<int>((len + inner_size - 1) / inner_size);
+#pragma omp parallel for schedule(static, 1)
+  for (int i = 0; i < num_threads; ++i) {
+    size_t left = inner_size*i;
+    size_t right = left + inner_size;
+    right = std::min(right, len);
+    if (right > left) {
+      std::sort(_First + left, _First + right, _Pred);
+    }
+  }
+  // Buffer for merge.
+  std::vector<_VTRanIt> temp_buf(len);
+  _RanIt buf = temp_buf.begin();
+  size_t s = inner_size;
+  // Recursive merge
+  while (s < len) {
+    int loop_size = static_cast<int>((len + s * 2 - 1) / (s * 2));
+    #pragma omp parallel for schedule(static, 1)
+    for (int i = 0; i < loop_size; ++i) {
+      size_t left = i * 2 * s;
+      size_t mid = left + s;
+      size_t right = mid + s;
+      right = std::min(len, right);
+      if (mid >= right) { continue; }
+      std::copy(_First + left, _First + mid, buf + left);
+      std::merge(buf + left, buf + mid, _First + mid, _First + right, _First + left, _Pred);
+    }
+    s *= 2;
+  }
+}
 
-// Parses a put_time-like format string and invokes handler actions.
-template <typename Char, typename Handler>
-FMT_CONSTEXPR const Char* parse_chrono_format(const Char* begin,
-                                              const Char* end,
-                                              Handler&& handler) {
-  auto ptr = begin;
-  while (ptr != end) {
-    auto c = *ptr;
-    if (c == '}') break;
-    if (c != '%') {
-      ++ptr;
-      continue;
-    }
-    if (begin != ptr) handler.on_text(begin, ptr);
-    ++ptr;  // consume '%'
-    if (ptr == end) FMT_THROW(format_error("invalid format"));
-    c = *ptr++;
-    switch (c) {
-    case '%':
-      handler.on_text(ptr - 1, ptr);
-      break;
-    case 'n': {
-      const Char newline[] = {'\n'};
-      handler.on_text(newline, newline + 1);
-      break;
-    }
-    case 't': {
-      const Char tab[] = {'\t'};
-      handler.on_text(tab, tab + 1);
-      break;
-    }
-    // Day of the week:
-    case 'a':
-      handler.on_abbr_weekday();
-      break;
-    case 'A':
-      handler.on_full_weekday();
-      break;
-    case 'w':
-      handler.on_dec0_weekday(numeric_system::standard);
-      break;
-    case 'u':
-      handler.on_dec1_weekday(numeric_system::standard);
-      break;
-    // Month:
-    case 'b':
-      handler.on_abbr_month();
-      break;
-    case 'B':
-      handler.on_full_month();
-      break;
-    // Hour, minute, second:
-    case 'H':
-      handler.on_24_hour(numeric_system::standard);
-      break;
-    case 'I':
-      handler.on_12_hour(numeric_system::standard);
-      break;
-    case 'M':
-      handler.on_minute(numeric_system::standard);
-      break;
-    case 'S':
-      handler.on_second(numeric_system::standard);
-      break;
-    // Other:
-    case 'c':
-      handler.on_datetime(numeric_system::standard);
-      break;
-    case 'x':
-      handler.on_loc_date(numeric_system::standard);
-      break;
-    case 'X':
-      handler.on_loc_time(numeric_system::standard);
-      break;
-    case 'D':
-      handler.on_us_date();
-      break;
-    case 'F':
-      handler.on_iso_date();
-      break;
-    case 'r':
-      handler.on_12_hour_time();
-      break;
-    case 'R':
-      handler.on_24_hour_time();
-      break;
-    case 'T':
-      handler.on_iso_time();
-      break;
-    case 'p':
-      handler.on_am_pm();
-      break;
-    case 'Q':
-      handler.on_duration_value();
-      break;
-    case 'q':
-      handler.on_duration_unit();
-      break;
-    case 'z':
-      handler.on_utc_offset();
-      break;
-    case 'Z':
-      handler.on_tz_name();
-      break;
-    // Alternative representation:
-    case 'E': {
-      if (ptr == end) FMT_THROW(format_error("invalid format"));
-      c = *ptr++;
-      switch (c) {
-      case 'c':
-        handler.on_datetime(numeric_system::alternative);
-        break;
-      case 'x':
-        handler.on_loc_date(numeric_system::alternative);
-        break;
-      case 'X':
-        handler.on_loc_time(numeric_system::alternative);
-        break;
-      default:
-        FMT_THROW(format_error("invalid format"));
+template<typename _RanIt, typename _Pr> inline
+static void ParallelSort(_RanIt _First, _RanIt _Last, _Pr _Pred) {
+  return ParallelSort(_First, _Last, _Pred, IteratorValType(_First));
+}
+
+// Check that all y[] are in interval [ymin, ymax] (end points included); throws error if not
+template <typename T>
+inline static void CheckElementsIntervalClosed(const T *y, T ymin, T ymax, int ny, const char *callername) {
+  auto fatal_msg = [&y, &ymin, &ymax, &callername](int i) {
+    std::ostringstream os;
+    os << "[%s]: does not tolerate element [#%i = " << y[i] << "] outside [" << ymin << ", " << ymax << "]";
+    Log::Fatal(os.str().c_str(), callername, i);
+  };
+  for (int i = 1; i < ny; i += 2) {
+    if (y[i - 1] < y[i]) {
+      if (y[i - 1] < ymin) {
+        fatal_msg(i - 1);
+      } else if (y[i] > ymax) {
+        fatal_msg(i);
       }
-      break;
-    }
-    case 'O':
-      if (ptr == end) FMT_THROW(format_error("invalid format"));
-      c = *ptr++;
-      switch (c) {
-      case 'w':
-        handler.on_dec0_weekday(numeric_system::alternative);
-        break;
-      case 'u':
-        handler.on_dec1_weekday(numeric_system::alternative);
-        break;
-      case 'H':
-        handler.on_24_hour(numeric_system::alternative);
-        break;
-      case 'I':
-        handler.on_12_hour(numeric_system::alternative);
-        break;
-      case 'M':
-        handler.on_minute(numeric_system::alternative);
-        break;
-      case 'S':
-        handler.on_second(numeric_system::alternative);
-        break;
-      default:
-        FMT_THROW(format_error("invalid format"));
+    } else {
+      if (y[i - 1] > ymax) {
+        fatal_msg(i - 1);
+      } else if (y[i] < ymin) {
+        fatal_msg(i);
       }
-      break;
-    default:
-      FMT_THROW(format_error("invalid format"));
     }
-    begin = ptr;
   }
-  if (begin != ptr) handler.on_text(begin, ptr);
-  return ptr;
+  if (ny & 1) {  // odd
+    if (y[ny - 1] < ymin || y[ny - 1] > ymax) {
+      fatal_msg(ny - 1);
+    }
+  }
+}
+
+// One-pass scan over array w with nw elements: find min, max and sum of elements;
+// this is useful for checking weight requirements.
+template <typename T1, typename T2>
+inline static void ObtainMinMaxSum(const T1 *w, int nw, T1 *mi, T1 *ma, T2 *su) {
+  T1 minw;
+  T1 maxw;
+  T1 sumw;
+  int i;
+  if (nw & 1) {  // odd
+    minw = w[0];
+    maxw = w[0];
+    sumw = w[0];
+    i = 2;
+  } else {  // even
+    if (w[0] < w[1]) {
+      minw = w[0];
+      maxw = w[1];
+    } else {
+      minw = w[1];
+      maxw = w[0];
+    }
+    sumw = w[0] + w[1];
+    i = 3;
+  }
+  for (; i < nw; i += 2) {
+    if (w[i - 1] < w[i]) {
+      minw = std::min(minw, w[i - 1]);
+      maxw = std::max(maxw, w[i]);
+    } else {
+      minw = std::min(minw, w[i]);
+      maxw = std::max(maxw, w[i - 1]);
+    }
+    sumw += w[i - 1] + w[i];
+  }
+  if (mi != nullptr) {
+    *mi = minw;
+  }
+  if (ma != nullptr) {
+    *ma = maxw;
+  }
+  if (su != nullptr) {
+    *su = static_cast<T2>(sumw);
+  }
 }
 
-struct chrono_format_checker {
-  FMT_NORETURN void report_no_date() { FMT_THROW(format_error("no date")); }
+inline static std::vector<uint32_t> EmptyBitset(int n) {
+  int size = n / 32;
+  if (n % 32 != 0) ++size;
+  return std::vector<uint32_t>(size);
+}
 
-  template <typename Char> void on_text(const Char*, const Char*) {}
-  FMT_NORETURN void on_abbr_weekday() { report_no_date(); }
-  FMT_NORETURN void on_full_weekday() { report_no_date(); }
-  FMT_NORETURN void on_dec0_weekday(numeric_system) { report_no_date(); }
-  FMT_NORETURN void on_dec1_weekday(numeric_system) { report_no_date(); }
-  FMT_NORETURN void on_abbr_month() { report_no_date(); }
-  FMT_NORETURN void on_full_month() { report_no_date(); }
-  void on_24_hour(numeric_system) {}
-  void on_12_hour(numeric_system) {}
-  void on_minute(numeric_system) {}
-  void on_second(numeric_system) {}
-  FMT_NORETURN void on_datetime(numeric_system) { report_no_date(); }
-  FMT_NORETURN void on_loc_date(numeric_system) { report_no_date(); }
-  FMT_NORETURN void on_loc_time(numeric_system) { report_no_date(); }
-  FMT_NORETURN void on_us_date() { report_no_date(); }
-  FMT_NORETURN void on_iso_date() { report_no_date(); }
-  void on_12_hour_time() {}
-  void on_24_hour_time() {}
-  void on_iso_time() {}
-  void on_am_pm() {}
-  void on_duration_value() {}
-  void on_duration_unit() {}
-  FMT_NORETURN void on_utc_offset() { report_no_date(); }
-  FMT_NORETURN void on_tz_name() { report_no_date(); }
-};
+template<typename T>
+inline static void InsertBitset(std::vector<uint32_t>* vec, const T val) {
+  auto& ref_v = *vec;
+  int i1 = val / 32;
+  int i2 = val % 32;
+  if (static_cast<int>(vec->size()) < i1 + 1) {
+    vec->resize(i1 + 1, 0);
+  }
+  ref_v[i1] |= (1 << i2);
+}
 
-template <typename T, FMT_ENABLE_IF(std::is_integral<T>::value)>
-inline bool isnan(T) {
-  return false;
+template<typename T>
+inline static std::vector<uint32_t> ConstructBitset(const T* vals, int n) {
+  std::vector<uint32_t> ret;
+  for (int i = 0; i < n; ++i) {
+    int i1 = vals[i] / 32;
+    int i2 = vals[i] % 32;
+    if (static_cast<int>(ret.size()) < i1 + 1) {
+      ret.resize(i1 + 1, 0);
+    }
+    ret[i1] |= (1 << i2);
+  }
+  return ret;
 }
-template <typename T, FMT_ENABLE_IF(std::is_floating_point<T>::value)>
-inline bool isnan(T value) {
-  return std::isnan(value);
+
+template<typename T>
+inline static bool FindInBitset(const uint32_t* bits, int n, T pos) {
+  int i1 = pos / 32;
+  if (i1 >= n) {
+    return false;
+  }
+  int i2 = pos % 32;
+  return (bits[i1] >> i2) & 1;
 }
 
-template <typename T, FMT_ENABLE_IF(std::is_integral<T>::value)>
-inline bool isfinite(T) {
-  return true;
+inline static bool CheckDoubleEqualOrdered(double a, double b) {
+  double upper = std::nextafter(a, INFINITY);
+  return b <= upper;
 }
-template <typename T, FMT_ENABLE_IF(std::is_floating_point<T>::value)>
-inline bool isfinite(T value) {
-  return std::isfinite(value);
-}
-
-// Converts value to int and checks that it's in the range [0, upper).
-template <typename T, FMT_ENABLE_IF(std::is_integral<T>::value)>
-inline int to_nonnegative_int(T value, int upper) {
-  FMT_ASSERT(value >= 0 && value <= upper, "invalid value");
-  (void)upper;
-  return static_cast<int>(value);
-}
-template <typename T, FMT_ENABLE_IF(!std::is_integral<T>::value)>
-inline int to_nonnegative_int(T value, int upper) {
-  FMT_ASSERT(
-      std::isnan(value) || (value >= 0 && value <= static_cast<T>(upper)),
-      "invalid value");
-  (void)upper;
-  return static_cast<int>(value);
-}
-
-template <typename T, FMT_ENABLE_IF(std::is_integral<T>::value)>
-inline T mod(T x, int y) {
-  return x % static_cast<T>(y);
-}
-template <typename T, FMT_ENABLE_IF(std::is_floating_point<T>::value)>
-inline T mod(T x, int y) {
-  return std::fmod(x, static_cast<T>(y));
-}
-
-// If T is an integral type, maps T to its unsigned counterpart, otherwise
-// leaves it unchanged (unlike std::make_unsigned).
-template <typename T, bool INTEGRAL = std::is_integral<T>::value>
-struct make_unsigned_or_unchanged {
-  using type = T;
-};
 
-template <typename T> struct make_unsigned_or_unchanged<T, true> {
-  using type = typename std::make_unsigned<T>::type;
-};
+inline static double GetDoubleUpperBound(double a) {
+  return std::nextafter(a, INFINITY);
+}
 
-#if FMT_SAFE_DURATION_CAST
-// throwing version of safe_duration_cast
-template <typename To, typename FromRep, typename FromPeriod>
-To fmt_safe_duration_cast(std::chrono::duration<FromRep, FromPeriod> from) {
-  int ec;
-  To to = safe_duration_cast::safe_duration_cast<To>(from, ec);
-  if (ec) FMT_THROW(format_error("cannot format duration"));
-  return to;
+inline static size_t GetLine(const char* str) {
+  auto start = str;
+  while (*str != '\0' && *str != '\n' && *str != '\r') {
+    ++str;
+  }
+  return str - start;
 }
-#endif
 
-template <typename Rep, typename Period,
-          FMT_ENABLE_IF(std::is_integral<Rep>::value)>
-inline std::chrono::duration<Rep, std::milli> get_milliseconds(
-    std::chrono::duration<Rep, Period> d) {
-  // this may overflow and/or the result may not fit in the
-  // target type.
-#if FMT_SAFE_DURATION_CAST
-  using CommonSecondsType =
-      typename std::common_type<decltype(d), std::chrono::seconds>::type;
-  const auto d_as_common = fmt_safe_duration_cast<CommonSecondsType>(d);
-  const auto d_as_whole_seconds =
-      fmt_safe_duration_cast<std::chrono::seconds>(d_as_common);
-  // this conversion should be nonproblematic
-  const auto diff = d_as_common - d_as_whole_seconds;
-  const auto ms =
-      fmt_safe_duration_cast<std::chrono::duration<Rep, std::milli>>(diff);
-  return ms;
-#else
-  auto s = std::chrono::duration_cast<std::chrono::seconds>(d);
-  return std::chrono::duration_cast<std::chrono::milliseconds>(d - s);
-#endif
+inline static const char* SkipNewLine(const char* str) {
+  if (*str == '\r') {
+    ++str;
+  }
+  if (*str == '\n') {
+    ++str;
+  }
+  return str;
 }
 
-template <typename Rep, typename Period,
-          FMT_ENABLE_IF(std::is_floating_point<Rep>::value)>
-inline std::chrono::duration<Rep, std::milli> get_milliseconds(
-    std::chrono::duration<Rep, Period> d) {
-  using common_type = typename std::common_type<Rep, std::intmax_t>::type;
-  auto ms = mod(d.count() * static_cast<common_type>(Period::num) /
-                    static_cast<common_type>(Period::den) * 1000,
-                1000);
-  return std::chrono::duration<Rep, std::milli>(static_cast<Rep>(ms));
-}
-
-template <typename Char, typename Rep, typename OutputIt>
-OutputIt format_duration_value(OutputIt out, Rep val, int precision) {
-  const Char pr_f[] = {'{', ':', '.', '{', '}', 'f', '}', 0};
-  if (precision >= 0) return format_to(out, pr_f, val, precision);
-  const Char fp_f[] = {'{', ':', 'g', '}', 0};
-  const Char format[] = {'{', '}', 0};
-  return format_to(out, std::is_floating_point<Rep>::value ? fp_f : format,
-                   val);
-}
-template <typename Char, typename OutputIt>
-OutputIt copy_unit(string_view unit, OutputIt out, Char) {
-  return std::copy(unit.begin(), unit.end(), out);
-}
-
-template <typename OutputIt>
-OutputIt copy_unit(string_view unit, OutputIt out, wchar_t) {
-  // This works when wchar_t is UTF-32 because units only contain characters
-  // that have the same representation in UTF-16 and UTF-32.
-  utf8_to_utf16 u(unit);
-  return std::copy(u.c_str(), u.c_str() + u.size(), out);
-}
-
-template <typename Char, typename Period, typename OutputIt>
-OutputIt format_duration_unit(OutputIt out) {
-  if (const char* unit = get_units<Period>())
-    return copy_unit(string_view(unit), out, Char());
-  const Char num_f[] = {'[', '{', '}', ']', 's', 0};
-  if (const_check(Period::den == 1)) return format_to(out, num_f, Period::num);
-  const Char num_def_f[] = {'[', '{', '}', '/', '{', '}', ']', 's', 0};
-  return format_to(out, num_def_f, Period::num, Period::den);
-}
-
-template <typename FormatContext, typename OutputIt, typename Rep,
-          typename Period>
-struct chrono_formatter {
-  FormatContext& context;
-  OutputIt out;
-  int precision;
-  // rep is unsigned to avoid overflow.
-  using rep =
-      conditional_t<std::is_integral<Rep>::value && sizeof(Rep) < sizeof(int),
-                    unsigned, typename make_unsigned_or_unchanged<Rep>::type>;
-  rep val;
-  using seconds = std::chrono::duration<rep>;
-  seconds s;
-  using milliseconds = std::chrono::duration<rep, std::milli>;
-  bool negative;
-
-  using char_type = typename FormatContext::char_type;
-
-  explicit chrono_formatter(FormatContext& ctx, OutputIt o,
-                            std::chrono::duration<Rep, Period> d)
-      : context(ctx),
-        out(o),
-        val(static_cast<rep>(d.count())),
-        negative(false) {
-    if (d.count() < 0) {
-      val = 0 - val;
-      negative = true;
-    }
-
-    // this may overflow and/or the result may not fit in the
-    // target type.
-#if FMT_SAFE_DURATION_CAST
-    // might need checked conversion (rep!=Rep)
-    auto tmpval = std::chrono::duration<rep, Period>(val);
-    s = fmt_safe_duration_cast<seconds>(tmpval);
-#else
-    s = std::chrono::duration_cast<seconds>(
-        std::chrono::duration<rep, Period>(val));
-#endif
+template <typename T>
+static int Sign(T x) {
+  return (x > T(0)) - (x < T(0));
+}
+
+template <typename T>
+static T SafeLog(T x) {
+  if (x > 0) {
+    return std::log(x);
+  } else {
+    return -INFINITY;
   }
+}
 
-  // returns true if nan or inf, writes to out.
-  bool handle_nan_inf() {
-    if (isfinite(val)) {
+inline bool CheckAllowedJSON(const std::string& s) {
+  unsigned char char_code;
+  for (auto c : s) {
+    char_code = static_cast<unsigned char>(c);
+    if (char_code == 34      // "
+        || char_code == 44   // ,
+        || char_code == 58   // :
+        || char_code == 91   // [
+        || char_code == 93   // ]
+        || char_code == 123  // {
+        || char_code == 125  // }
+        ) {
       return false;
     }
-    if (isnan(val)) {
-      write_nan();
-      return true;
-    }
-    // must be +-inf
-    if (val > 0) {
-      write_pinf();
-    } else {
-      write_ninf();
-    }
-    return true;
   }
+  return true;
+}
 
-  Rep hour() const { return static_cast<Rep>(mod((s.count() / 3600), 24)); }
+inline int RoundInt(double x) {
+  return static_cast<int>(x + 0.5f);
+}
 
-  Rep hour12() const {
-    Rep hour = static_cast<Rep>(mod((s.count() / 3600), 12));
-    return hour <= 0 ? 12 : hour;
-  }
+template <typename T, std::size_t N = 32>
+class AlignmentAllocator {
+ public:
+  typedef T value_type;
+  typedef std::size_t size_type;
+  typedef std::ptrdiff_t difference_type;
+
+  typedef T* pointer;
+  typedef const T* const_pointer;
+
+  typedef T& reference;
+  typedef const T& const_reference;
+
+  inline AlignmentAllocator() throw() {}
+
+  template <typename T2>
+  inline AlignmentAllocator(const AlignmentAllocator<T2, N>&) throw() {}
 
-  Rep minute() const { return static_cast<Rep>(mod((s.count() / 60), 60)); }
-  Rep second() const { return static_cast<Rep>(mod(s.count(), 60)); }
+  inline ~AlignmentAllocator() throw() {}
 
-  std::tm time() const {
-    auto time = std::tm();
-    time.tm_hour = to_nonnegative_int(hour(), 24);
-    time.tm_min = to_nonnegative_int(minute(), 60);
-    time.tm_sec = to_nonnegative_int(second(), 60);
-    return time;
+  inline pointer adress(reference r) {
+    return &r;
   }
 
-  void write_sign() {
-    if (negative) {
-      *out++ = '-';
-      negative = false;
-    }
+  inline const_pointer adress(const_reference r) const {
+    return &r;
   }
 
-  void write(Rep value, int width) {
-    write_sign();
-    if (isnan(value)) return write_nan();
-    uint32_or_64_or_128_t<int> n =
-        to_unsigned(to_nonnegative_int(value, max_value<int>()));
-    int num_digits = detail::count_digits(n);
-    if (width > num_digits) out = std::fill_n(out, width - num_digits, '0');
-    out = format_decimal<char_type>(out, n, num_digits).end;
+  inline pointer allocate(size_type n) {
+    return (pointer)_mm_malloc(n * sizeof(value_type), N);
   }
 
-  void write_nan() { std::copy_n("nan", 3, out); }
-  void write_pinf() { std::copy_n("inf", 3, out); }
-  void write_ninf() { std::copy_n("-inf", 4, out); }
+  inline void deallocate(pointer p, size_type) {
+    _mm_free(p);
+  }
 
-  void format_localized(const tm& time, char format, char modifier = 0) {
-    if (isnan(val)) return write_nan();
-    auto locale = context.locale().template get<std::locale>();
-    auto& facet = std::use_facet<std::time_put<char_type>>(locale);
-    std::basic_ostringstream<char_type> os;
-    os.imbue(locale);
-    facet.put(os, os, ' ', &time, format, modifier);
-    auto str = os.str();
-    std::copy(str.begin(), str.end(), out);
+  inline void construct(pointer p, const value_type& wert) {
+    new (p) value_type(wert);
   }
 
-  void on_text(const char_type* begin, const char_type* end) {
-    std::copy(begin, end, out);
+  inline void destroy(pointer p) {
+    p->~value_type();
   }
 
-  // These are not implemented because durations don't have date information.
-  void on_abbr_weekday() {}
-  void on_full_weekday() {}
-  void on_dec0_weekday(numeric_system) {}
-  void on_dec1_weekday(numeric_system) {}
-  void on_abbr_month() {}
-  void on_full_month() {}
-  void on_datetime(numeric_system) {}
-  void on_loc_date(numeric_system) {}
-  void on_loc_time(numeric_system) {}
-  void on_us_date() {}
-  void on_iso_date() {}
-  void on_utc_offset() {}
-  void on_tz_name() {}
+  inline size_type max_size() const throw() {
+    return size_type(-1) / sizeof(value_type);
+  }
 
-  void on_24_hour(numeric_system ns) {
-    if (handle_nan_inf()) return;
+  template <typename T2>
+  struct rebind {
+    typedef AlignmentAllocator<T2, N> other;
+  };
 
-    if (ns == numeric_system::standard) return write(hour(), 2);
-    auto time = tm();
-    time.tm_hour = to_nonnegative_int(hour(), 24);
-    format_localized(time, 'H', 'O');
+  bool operator!=(const AlignmentAllocator<T, N>& other) const {
+    return !(*this == other);
   }
 
-  void on_12_hour(numeric_system ns) {
-    if (handle_nan_inf()) return;
+  // Returns true if and only if storage allocated from *this
+  // can be deallocated from other, and vice versa.
+  // Always returns true for stateless allocators.
+  bool operator==(const AlignmentAllocator<T, N>&) const {
+    return true;
+  }
+};
 
-    if (ns == numeric_system::standard) return write(hour12(), 2);
-    auto time = tm();
-    time.tm_hour = to_nonnegative_int(hour12(), 12);
-    format_localized(time, 'I', 'O');
+class Timer {
+ public:
+  Timer() {
+#ifdef TIMETAG
+    int num_threads = OMP_NUM_THREADS();
+    start_time_.resize(num_threads);
+    stats_.resize(num_threads);
+#endif  // TIMETAG
   }
 
-  void on_minute(numeric_system ns) {
-    if (handle_nan_inf()) return;
+  ~Timer() { Print(); }
 
-    if (ns == numeric_system::standard) return write(minute(), 2);
-    auto time = tm();
-    time.tm_min = to_nonnegative_int(minute(), 60);
-    format_localized(time, 'M', 'O');
+#ifdef TIMETAG
+  void Start(const std::string& name) {
+    auto tid = omp_get_thread_num();
+    start_time_[tid][name] = std::chrono::steady_clock::now();
   }
 
-  void on_second(numeric_system ns) {
-    if (handle_nan_inf()) return;
+  void Stop(const std::string& name) {
+    auto cur_time = std::chrono::steady_clock::now();
+    auto tid = omp_get_thread_num();
+    if (stats_[tid].find(name) == stats_[tid].end()) {
+      stats_[tid][name] = std::chrono::duration<double, std::milli>(0);
+    }
+    stats_[tid][name] += cur_time - start_time_[tid][name];
+  }
 
-    if (ns == numeric_system::standard) {
-      write(second(), 2);
-#if FMT_SAFE_DURATION_CAST
-      // convert rep->Rep
-      using duration_rep = std::chrono::duration<rep, Period>;
-      using duration_Rep = std::chrono::duration<Rep, Period>;
-      auto tmpval = fmt_safe_duration_cast<duration_Rep>(duration_rep{val});
 #else
-      auto tmpval = std::chrono::duration<Rep, Period>(val);
-#endif
-      auto ms = get_milliseconds(tmpval);
-      if (ms != std::chrono::milliseconds(0)) {
-        *out++ = '.';
-        write(ms.count(), 3);
+  void Start(const std::string&) {}
+
+  void Stop(const std::string&) {}
+#endif  // TIMETAG
+
+  void Print() const {
+#ifdef TIMETAG
+    std::unordered_map<std::string, std::chrono::duration<double, std::milli>>
+        stats(stats_[0].begin(), stats_[0].end());
+    for (size_t i = 1; i < stats_.size(); ++i) {
+      for (auto it = stats_[i].begin(); it != stats_[i].end(); ++it) {
+        if (stats.find(it->first) == stats.end()) {
+          stats[it->first] = it->second;
+        } else {
+          stats[it->first] += it->second;
+        }
       }
-      return;
     }
-    auto time = tm();
-    time.tm_sec = to_nonnegative_int(second(), 60);
-    format_localized(time, 'S', 'O');
-  }
+    std::map<std::string, std::chrono::duration<double, std::milli>> ordered(
+        stats.begin(), stats.end());
+    for (auto it = ordered.begin(); it != ordered.end(); ++it) {
+      Log::Info("%s costs:\t %f", it->first.c_str(), it->second * 1e-3);
+    }
+#endif  // TIMETAG
+  }
+#ifdef TIMETAG
+  std::vector<
+      std::unordered_map<std::string, std::chrono::steady_clock::time_point>>
+      start_time_;
+  std::vector<std::unordered_map<std::string,
+                                 std::chrono::duration<double, std::milli>>>
+      stats_;
+#endif  // TIMETAG
+};
 
-  void on_12_hour_time() {
-    if (handle_nan_inf()) return;
-    format_localized(time(), 'r');
+// Note: this class is not thread-safe, don't use it inside omp blocks
+class FunctionTimer {
+ public:
+#ifdef TIMETAG
+  FunctionTimer(const std::string& name, Timer& timer) : timer_(timer) {
+    timer.Start(name);
+    name_ = name;
   }
 
-  void on_24_hour_time() {
-    if (handle_nan_inf()) {
-      *out++ = ':';
-      handle_nan_inf();
-      return;
-    }
+  ~FunctionTimer() { timer_.Stop(name_); }
 
-    write(hour(), 2);
-    *out++ = ':';
-    write(minute(), 2);
-  }
+ private:
+  std::string name_;
+  Timer& timer_;
+#else
+  FunctionTimer(const std::string&, Timer&) {}
+#endif  // TIMETAG
+};
 
-  void on_iso_time() {
-    on_24_hour_time();
-    *out++ = ':';
-    if (handle_nan_inf()) return;
-    write(second(), 2);
-  }
+}  // namespace Common
 
-  void on_am_pm() {
-    if (handle_nan_inf()) return;
-    format_localized(time(), 'p');
-  }
+extern Common::Timer global_timer;
 
-  void on_duration_value() {
-    if (handle_nan_inf()) return;
-    write_sign();
-    out = format_duration_value<char_type>(out, val, precision);
-  }
 
-  void on_duration_unit() {
-    out = format_duration_unit<char_type, Period>(out);
-  }
-};
-}  // namespace detail
+/*!
+* Provides locale-independent alternatives to Common's methods.
+* Essential to make models robust to locale settings.
+*/
+namespace CommonC {
 
-template <typename Rep, typename Period, typename Char>
-struct formatter<std::chrono::duration<Rep, Period>, Char> {
- private:
-  basic_format_specs<Char> specs;
-  int precision;
-  using arg_ref_type = detail::arg_ref<Char>;
-  arg_ref_type width_ref;
-  arg_ref_type precision_ref;
-  mutable basic_string_view<Char> format_str;
-  using duration = std::chrono::duration<Rep, Period>;
+template<typename T>
+inline static std::string Join(const std::vector<T>& strs, const char* delimiter) {
+  return LightGBM::Common::Join(strs, delimiter, true);
+}
 
-  struct spec_handler {
-    formatter& f;
-    basic_format_parse_context<Char>& context;
-    basic_string_view<Char> format_str;
+template<typename T>
+inline static std::string Join(const std::vector<T>& strs, size_t start, size_t end, const char* delimiter) {
+  return LightGBM::Common::Join(strs, start, end, delimiter, true);
+}
 
-    template <typename Id> FMT_CONSTEXPR arg_ref_type make_arg_ref(Id arg_id) {
-      context.check_arg_id(arg_id);
-      return arg_ref_type(arg_id);
-    }
+inline static const char* Atof(const char* p, double* out) {
+  return LightGBM::Common::Atof(p, out);
+}
 
-    FMT_CONSTEXPR arg_ref_type make_arg_ref(basic_string_view<Char> arg_id) {
-      context.check_arg_id(arg_id);
-      return arg_ref_type(arg_id);
-    }
+template<typename T, bool is_float>
+struct __StringToTHelperFast {
+  const char* operator()(const char*p, T* out) const {
+    return LightGBM::Common::Atoi(p, out);
+  }
+};
 
-    FMT_CONSTEXPR arg_ref_type make_arg_ref(detail::auto_id) {
-      return arg_ref_type(context.next_arg_id());
-    }
+/*!
+* \warning Beware that ``Common::Atof`` in ``__StringToTHelperFast``,
+*          has **less** floating point precision than ``__StringToTHelper``.
+*          Both versions are kept to maintain bit-for-bit the "legacy" LightGBM behaviour in terms of precision.
+*          Check ``StringToArrayFast`` and ``StringToArray`` for more details on this.
+*/
+template<typename T>
+struct __StringToTHelperFast<T, true> {
+  const char* operator()(const char*p, T* out) const {
+    double tmp = 0.0f;
+    auto ret = Atof(p, &tmp);
+    *out = static_cast<T>(tmp);
+    return ret;
+  }
+};
 
-    void on_error(const char* msg) { FMT_THROW(format_error(msg)); }
-    void on_fill(basic_string_view<Char> fill) { f.specs.fill = fill; }
-    void on_align(align_t align) { f.specs.align = align; }
-    void on_width(int width) { f.specs.width = width; }
-    void on_precision(int _precision) { f.precision = _precision; }
-    void end_precision() {}
+template<typename T, bool is_float>
+struct __StringToTHelper {
+  T operator()(const std::string& str) const {
+    T ret = 0;
+    LightGBM::Common::Atoi(str.c_str(), &ret);
+    return ret;
+  }
+};
 
-    template <typename Id> void on_dynamic_width(Id arg_id) {
-      f.width_ref = make_arg_ref(arg_id);
+/*!
+* \warning Beware that ``Common::Atof`` in ``__StringToTHelperFast``,
+*          has **less** floating point precision than ``__StringToTHelper``.
+*          Both versions are kept to maintain bit-for-bit the "legacy" LightGBM behaviour in terms of precision.
+*          Check ``StringToArrayFast`` and ``StringToArray`` for more details on this.
+* \note It is possible that ``fast_double_parser::parse_number`` is faster than ``Common::Atof``.
+*/
+template<typename T>
+struct __StringToTHelper<T, true> {
+  T operator()(const std::string& str) const {
+    double tmp;
+
+    const char* end = Common::AtofPrecise(str.c_str(), &tmp);
+    if (end == str.c_str()) {
+        Log::Fatal("Failed to parse double: %s", str.c_str());
     }
 
-    template <typename Id> void on_dynamic_precision(Id arg_id) {
-      f.precision_ref = make_arg_ref(arg_id);
-    }
-  };
+    return static_cast<T>(tmp);
+  }
+};
 
-  using iterator = typename basic_format_parse_context<Char>::iterator;
-  struct parse_range {
-    iterator begin;
-    iterator end;
-  };
 
-  FMT_CONSTEXPR parse_range do_parse(basic_format_parse_context<Char>& ctx) {
-    auto begin = ctx.begin(), end = ctx.end();
-    if (begin == end || *begin == '}') return {begin, begin};
-    spec_handler handler{*this, ctx, format_str};
-    begin = detail::parse_align(begin, end, handler);
-    if (begin == end) return {begin, begin};
-    begin = detail::parse_width(begin, end, handler);
-    if (begin == end) return {begin, begin};
-    if (*begin == '.') {
-      if (std::is_floating_point<Rep>::value)
-        begin = detail::parse_precision(begin, end, handler);
-      else
-        handler.on_error("precision not allowed for this argument type");
-    }
-    end = parse_chrono_format(begin, end, detail::chrono_format_checker());
-    return {begin, end};
+/*!
+* \warning Beware that due to internal use of ``Common::Atof`` in ``__StringToTHelperFast``,
+*          this method has less precision for floating point numbers than ``StringToArray``,
+*          which calls ``__StringToTHelper``.
+*          As such, ``StringToArrayFast`` and ``StringToArray`` are not equivalent!
+*          Both versions were kept to maintain bit-for-bit the "legacy" LightGBM behaviour in terms of precision.
+*/
+template<typename T>
+inline static std::vector<T> StringToArrayFast(const std::string& str, int n) {
+  if (n == 0) {
+    return std::vector<T>();
+  }
+  auto p_str = str.c_str();
+  __StringToTHelperFast<T, std::is_floating_point<T>::value> helper;
+  std::vector<T> ret(n);
+  for (int i = 0; i < n; ++i) {
+    p_str = helper(p_str, &ret[i]);
+  }
+  return ret;
+}
+
+/*!
+* \warning Do not replace calls to this method by ``StringToArrayFast``.
+*          This method is more precise for floating point numbers.
+*          Check ``StringToArrayFast`` for more details.
+*/
+template<typename T>
+inline static std::vector<T> StringToArray(const std::string& str, int n) {
+  if (n == 0) {
+    return std::vector<T>();
+  }
+  std::vector<std::string> strs = LightGBM::Common::Split(str.c_str(), ' ');
+  CHECK_EQ(strs.size(), static_cast<size_t>(n));
+  std::vector<T> ret;
+  ret.reserve(strs.size());
+  __StringToTHelper<T, std::is_floating_point<T>::value> helper;
+  for (const auto& s : strs) {
+    ret.push_back(helper(s));
+  }
+  return ret;
+}
+
+/*!
+* \warning Do not replace calls to this method by ``StringToArrayFast``.
+*          This method is more precise for floating point numbers.
+*          Check ``StringToArrayFast`` for more details.
+*/
+template<typename T>
+inline static std::vector<T> StringToArray(const std::string& str, char delimiter) {
+  std::vector<std::string> strs = LightGBM::Common::Split(str.c_str(), delimiter);
+  std::vector<T> ret;
+  ret.reserve(strs.size());
+  __StringToTHelper<T, std::is_floating_point<T>::value> helper;
+  for (const auto& s : strs) {
+    ret.push_back(helper(s));
+  }
+  return ret;
+}
+
+/*!
+* Safely formats a value onto a buffer according to a format string and null-terminates it.
+*
+* \note It checks that the full value was written or forcefully aborts.
+*       This safety check serves to prevent incorrect internal API usage.
+*       Correct usage will never incur in this problem:
+*         - The received buffer size shall be sufficient at all times for the input format string and value.
+*/
+template <typename T>
+inline static void format_to_buf(char* buffer, const size_t buf_len, const char* format, const T value) {
+    auto result = fmt::format_to_n(buffer, buf_len, format, value);
+    if (result.size >= buf_len) {
+      Log::Fatal("Numerical conversion failed. Buffer is too small.");
+    }
+    buffer[result.size] = '\0';
+}
+
+template<typename T, bool is_float, bool high_precision>
+struct __TToStringHelper {
+  void operator()(T value, char* buffer, size_t buf_len) const {
+    format_to_buf(buffer, buf_len, "{}", value);
   }
+};
 
- public:
-  formatter() : precision(-1) {}
+template<typename T>
+struct __TToStringHelper<T, true, false> {
+  void operator()(T value, char* buffer, size_t buf_len) const {
+    format_to_buf(buffer, buf_len, "{:g}", value);
+  }
+};
 
-  FMT_CONSTEXPR auto parse(basic_format_parse_context<Char>& ctx)
-      -> decltype(ctx.begin()) {
-    auto range = do_parse(ctx);
-    format_str = basic_string_view<Char>(
-        &*range.begin, detail::to_unsigned(range.end - range.begin));
-    return range.end;
-  }
-
-  template <typename FormatContext>
-  auto format(const duration& d, FormatContext& ctx) -> decltype(ctx.out()) {
-    auto begin = format_str.begin(), end = format_str.end();
-    // As a possible future optimization, we could avoid extra copying if width
-    // is not specified.
-    basic_memory_buffer<Char> buf;
-    auto out = std::back_inserter(buf);
-    detail::handle_dynamic_spec<detail::width_checker>(specs.width, width_ref,
-                                                       ctx);
-    detail::handle_dynamic_spec<detail::precision_checker>(precision,
-                                                           precision_ref, ctx);
-    if (begin == end || *begin == '}') {
-      out = detail::format_duration_value<Char>(out, d.count(), precision);
-      detail::format_duration_unit<Char, Period>(out);
-    } else {
-      detail::chrono_formatter<FormatContext, decltype(out), Rep, Period> f(
-          ctx, out, d);
-      f.precision = precision;
-      parse_chrono_format(begin, end, f);
-    }
-    return detail::write(
-        ctx.out(), basic_string_view<Char>(buf.data(), buf.size()), specs);
+template<typename T>
+struct __TToStringHelper<T, true, true> {
+  void operator()(T value, char* buffer, size_t buf_len) const {
+    format_to_buf(buffer, buf_len, "{:.17g}", value);
   }
 };
 
-FMT_END_NAMESPACE
+/*!
+* Converts an array to a string with with values separated by the space character.
+* This method replaces Common's ``ArrayToString`` and ``ArrayToStringFast`` functionality
+* and is locale-independent.
+* 
+* \note If ``high_precision_output`` is set to true,
+*       floating point values are output with more digits of precision.
+*/
+template<bool high_precision_output = false, typename T>
+inline static std::string ArrayToString(const std::vector<T>& arr, size_t n) {
+  if (arr.empty() || n == 0) {
+    return std::string("");
+  }
+  __TToStringHelper<T, std::is_floating_point<T>::value, high_precision_output> helper;
+  const size_t buf_len = high_precision_output ? 32 : 16;
+  std::vector<char> buffer(buf_len);
+  std::stringstream str_buf;
+  Common::C_stringstream(str_buf);
+  helper(arr[0], buffer.data(), buf_len);
+  str_buf << buffer.data();
+  for (size_t i = 1; i < std::min(n, arr.size()); ++i) {
+    helper(arr[i], buffer.data(), buf_len);
+    str_buf << ' ' << buffer.data();
+  }
+  return str_buf.str();
+}
+
+
+}  // namespace CommonC
+
+
+}  // namespace LightGBM
 
-#endif  // FMT_CHRONO_H_
+#endif  // LIGHTGBM_UTILS_COMMON_H_
```

#### encoding

```diff
@@ -1 +1 @@
-utf-8
+us-ascii
```

### Comparing `lightgbm-3.3.5/compile/external_libs/fmt/include/fmt/color.h` & `lightgbm-4.0.0/external_libs/fmt/include/fmt/color.h`

 * *Files 10% similar despite different names*

```diff
@@ -6,15 +6,23 @@
 // For the license information refer to format.h.
 
 #ifndef FMT_COLOR_H_
 #define FMT_COLOR_H_
 
 #include "format.h"
 
+// __declspec(deprecated) is broken in some MSVC versions.
+#if FMT_MSC_VER
+#  define FMT_DEPRECATED_NONMSVC
+#else
+#  define FMT_DEPRECATED_NONMSVC FMT_DEPRECATED
+#endif
+
 FMT_BEGIN_NAMESPACE
+FMT_MODULE_EXPORT_BEGIN
 
 enum class color : uint32_t {
   alice_blue = 0xF0F8FF,               // rgb(240,248,255)
   antique_white = 0xFAEBD7,            // rgb(250,235,215)
   aqua = 0x00FFFF,                     // rgb(0,255,255)
   aquamarine = 0x7FFFD4,               // rgb(127,255,212)
   azure = 0xF0FFFF,                    // rgb(240,255,255)
@@ -173,17 +181,21 @@
   bright_magenta,
   bright_cyan,
   bright_white
 };
 
 enum class emphasis : uint8_t {
   bold = 1,
-  italic = 1 << 1,
-  underline = 1 << 2,
-  strikethrough = 1 << 3
+  faint = 1 << 1,
+  italic = 1 << 2,
+  underline = 1 << 3,
+  blink = 1 << 4,
+  reverse = 1 << 5,
+  conceal = 1 << 6,
+  strikethrough = 1 << 7,
 };
 
 // rgb is a struct for red, green and blue colors.
 // Using the name "rgb" makes some editors show the color in a tooltip.
 struct rgb {
   FMT_CONSTEXPR rgb() : r(0), g(0), b(0) {}
   FMT_CONSTEXPR rgb(uint8_t r_, uint8_t g_, uint8_t b_) : r(r_), g(g_), b(b_) {}
@@ -194,15 +206,15 @@
         g((uint32_t(hex) >> 8) & 0xFF),
         b(uint32_t(hex) & 0xFF) {}
   uint8_t r;
   uint8_t g;
   uint8_t b;
 };
 
-namespace detail {
+FMT_BEGIN_DETAIL_NAMESPACE
 
 // color is a struct of either a rgb color or a terminal color.
 struct color_type {
   FMT_CONSTEXPR color_type() FMT_NOEXCEPT : is_rgb(), value{} {}
   FMT_CONSTEXPR color_type(color rgb_color) FMT_NOEXCEPT : is_rgb(true),
                                                            value{} {
     value.rgb_color = static_cast<uint32_t>(rgb_color);
@@ -217,17 +229,18 @@
   }
   bool is_rgb;
   union color_union {
     uint8_t term_color;
     uint32_t rgb_color;
   } value;
 };
-}  // namespace detail
 
-// Experimental text formatting support.
+FMT_END_DETAIL_NAMESPACE
+
+/** A text style consisting of foreground and background colors and emphasis. */
 class text_style {
  public:
   FMT_CONSTEXPR text_style(emphasis em = emphasis()) FMT_NOEXCEPT
       : set_foreground_color(),
         set_background_color(),
         ems(em) {}
 
@@ -256,41 +269,22 @@
   }
 
   friend FMT_CONSTEXPR text_style operator|(text_style lhs,
                                             const text_style& rhs) {
     return lhs |= rhs;
   }
 
-  FMT_CONSTEXPR text_style& operator&=(const text_style& rhs) {
-    if (!set_foreground_color) {
-      set_foreground_color = rhs.set_foreground_color;
-      foreground_color = rhs.foreground_color;
-    } else if (rhs.set_foreground_color) {
-      if (!foreground_color.is_rgb || !rhs.foreground_color.is_rgb)
-        FMT_THROW(format_error("can't AND a terminal color"));
-      foreground_color.value.rgb_color &= rhs.foreground_color.value.rgb_color;
-    }
-
-    if (!set_background_color) {
-      set_background_color = rhs.set_background_color;
-      background_color = rhs.background_color;
-    } else if (rhs.set_background_color) {
-      if (!background_color.is_rgb || !rhs.background_color.is_rgb)
-        FMT_THROW(format_error("can't AND a terminal color"));
-      background_color.value.rgb_color &= rhs.background_color.value.rgb_color;
-    }
-
-    ems = static_cast<emphasis>(static_cast<uint8_t>(ems) &
-                                static_cast<uint8_t>(rhs.ems));
-    return *this;
+  FMT_DEPRECATED_NONMSVC FMT_CONSTEXPR text_style& operator&=(
+      const text_style& rhs) {
+    return and_assign(rhs);
   }
 
-  friend FMT_CONSTEXPR text_style operator&(text_style lhs,
-                                            const text_style& rhs) {
-    return lhs &= rhs;
+  FMT_DEPRECATED_NONMSVC friend FMT_CONSTEXPR text_style
+  operator&(text_style lhs, const text_style& rhs) {
+    return lhs.and_assign(rhs);
   }
 
   FMT_CONSTEXPR bool has_foreground() const FMT_NOEXCEPT {
     return set_foreground_color;
   }
   FMT_CONSTEXPR bool has_background() const FMT_NOEXCEPT {
     return set_background_color;
@@ -322,47 +316,76 @@
       set_foreground_color = true;
     } else {
       background_color = text_color;
       set_background_color = true;
     }
   }
 
+  // DEPRECATED!
+  FMT_CONSTEXPR text_style& and_assign(const text_style& rhs) {
+    if (!set_foreground_color) {
+      set_foreground_color = rhs.set_foreground_color;
+      foreground_color = rhs.foreground_color;
+    } else if (rhs.set_foreground_color) {
+      if (!foreground_color.is_rgb || !rhs.foreground_color.is_rgb)
+        FMT_THROW(format_error("can't AND a terminal color"));
+      foreground_color.value.rgb_color &= rhs.foreground_color.value.rgb_color;
+    }
+
+    if (!set_background_color) {
+      set_background_color = rhs.set_background_color;
+      background_color = rhs.background_color;
+    } else if (rhs.set_background_color) {
+      if (!background_color.is_rgb || !rhs.background_color.is_rgb)
+        FMT_THROW(format_error("can't AND a terminal color"));
+      background_color.value.rgb_color &= rhs.background_color.value.rgb_color;
+    }
+
+    ems = static_cast<emphasis>(static_cast<uint8_t>(ems) &
+                                static_cast<uint8_t>(rhs.ems));
+    return *this;
+  }
+
   friend FMT_CONSTEXPR_DECL text_style fg(detail::color_type foreground)
       FMT_NOEXCEPT;
+
   friend FMT_CONSTEXPR_DECL text_style bg(detail::color_type background)
       FMT_NOEXCEPT;
 
   detail::color_type foreground_color;
   detail::color_type background_color;
   bool set_foreground_color;
   bool set_background_color;
   emphasis ems;
 };
 
-FMT_CONSTEXPR text_style fg(detail::color_type foreground) FMT_NOEXCEPT {
-  return text_style(/*is_foreground=*/true, foreground);
+/** Creates a text style from the foreground (text) color. */
+FMT_CONSTEXPR inline text_style fg(detail::color_type foreground) FMT_NOEXCEPT {
+  return text_style(true, foreground);
 }
 
-FMT_CONSTEXPR text_style bg(detail::color_type background) FMT_NOEXCEPT {
-  return text_style(/*is_foreground=*/false, background);
+/** Creates a text style from the background color. */
+FMT_CONSTEXPR inline text_style bg(detail::color_type background) FMT_NOEXCEPT {
+  return text_style(false, background);
 }
 
-FMT_CONSTEXPR text_style operator|(emphasis lhs, emphasis rhs) FMT_NOEXCEPT {
+FMT_CONSTEXPR inline text_style operator|(emphasis lhs,
+                                          emphasis rhs) FMT_NOEXCEPT {
   return text_style(lhs) | rhs;
 }
 
-namespace detail {
+FMT_BEGIN_DETAIL_NAMESPACE
 
 template <typename Char> struct ansi_color_escape {
   FMT_CONSTEXPR ansi_color_escape(detail::color_type text_color,
                                   const char* esc) FMT_NOEXCEPT {
     // If we have a terminal color, we need to output another escape code
     // sequence.
     if (!text_color.is_rgb) {
-      bool is_background = esc == detail::data::background_color;
+      bool is_background = esc == string_view("\x1b[48;2;");
       uint32_t value = text_color.value.term_color;
       // Background ASCII codes are the same as the foreground ones but with
       // 10 more.
       if (is_background) value += 10u;
 
       size_t index = 0;
       buffer[index++] = static_cast<Char>('\x1b');
@@ -386,61 +409,68 @@
     rgb color(text_color.value.rgb_color);
     to_esc(color.r, buffer + 7, ';');
     to_esc(color.g, buffer + 11, ';');
     to_esc(color.b, buffer + 15, 'm');
     buffer[19] = static_cast<Char>(0);
   }
   FMT_CONSTEXPR ansi_color_escape(emphasis em) FMT_NOEXCEPT {
-    uint8_t em_codes[4] = {};
-    uint8_t em_bits = static_cast<uint8_t>(em);
-    if (em_bits & static_cast<uint8_t>(emphasis::bold)) em_codes[0] = 1;
-    if (em_bits & static_cast<uint8_t>(emphasis::italic)) em_codes[1] = 3;
-    if (em_bits & static_cast<uint8_t>(emphasis::underline)) em_codes[2] = 4;
-    if (em_bits & static_cast<uint8_t>(emphasis::strikethrough))
-      em_codes[3] = 9;
+    uint8_t em_codes[num_emphases] = {};
+    if (has_emphasis(em, emphasis::bold)) em_codes[0] = 1;
+    if (has_emphasis(em, emphasis::faint)) em_codes[1] = 2;
+    if (has_emphasis(em, emphasis::italic)) em_codes[2] = 3;
+    if (has_emphasis(em, emphasis::underline)) em_codes[3] = 4;
+    if (has_emphasis(em, emphasis::blink)) em_codes[4] = 5;
+    if (has_emphasis(em, emphasis::reverse)) em_codes[5] = 7;
+    if (has_emphasis(em, emphasis::conceal)) em_codes[6] = 8;
+    if (has_emphasis(em, emphasis::strikethrough)) em_codes[7] = 9;
 
     size_t index = 0;
-    for (int i = 0; i < 4; ++i) {
+    for (size_t i = 0; i < num_emphases; ++i) {
       if (!em_codes[i]) continue;
       buffer[index++] = static_cast<Char>('\x1b');
       buffer[index++] = static_cast<Char>('[');
       buffer[index++] = static_cast<Char>('0' + em_codes[i]);
       buffer[index++] = static_cast<Char>('m');
     }
     buffer[index++] = static_cast<Char>(0);
   }
   FMT_CONSTEXPR operator const Char*() const FMT_NOEXCEPT { return buffer; }
 
   FMT_CONSTEXPR const Char* begin() const FMT_NOEXCEPT { return buffer; }
-  FMT_CONSTEXPR const Char* end() const FMT_NOEXCEPT {
+  FMT_CONSTEXPR_CHAR_TRAITS const Char* end() const FMT_NOEXCEPT {
     return buffer + std::char_traits<Char>::length(buffer);
   }
 
  private:
-  Char buffer[7u + 3u * 4u + 1u];
+  static constexpr size_t num_emphases = 8;
+  Char buffer[7u + 3u * num_emphases + 1u];
 
   static FMT_CONSTEXPR void to_esc(uint8_t c, Char* out,
                                    char delimiter) FMT_NOEXCEPT {
     out[0] = static_cast<Char>('0' + c / 100);
     out[1] = static_cast<Char>('0' + c / 10 % 10);
     out[2] = static_cast<Char>('0' + c % 10);
     out[3] = static_cast<Char>(delimiter);
   }
+  static FMT_CONSTEXPR bool has_emphasis(emphasis em,
+                                         emphasis mask) FMT_NOEXCEPT {
+    return static_cast<uint8_t>(em) & static_cast<uint8_t>(mask);
+  }
 };
 
 template <typename Char>
 FMT_CONSTEXPR ansi_color_escape<Char> make_foreground_color(
     detail::color_type foreground) FMT_NOEXCEPT {
-  return ansi_color_escape<Char>(foreground, detail::data::foreground_color);
+  return ansi_color_escape<Char>(foreground, "\x1b[38;2;");
 }
 
 template <typename Char>
 FMT_CONSTEXPR ansi_color_escape<Char> make_background_color(
     detail::color_type background) FMT_NOEXCEPT {
-  return ansi_color_escape<Char>(background, detail::data::background_color);
+  return ansi_color_escape<Char>(background, "\x1b[48;2;");
 }
 
 template <typename Char>
 FMT_CONSTEXPR ansi_color_escape<Char> make_emphasis(emphasis em) FMT_NOEXCEPT {
   return ansi_color_escape<Char>(em);
 }
 
@@ -451,26 +481,25 @@
 
 template <>
 inline void fputs<wchar_t>(const wchar_t* chars, FILE* stream) FMT_NOEXCEPT {
   std::fputws(chars, stream);
 }
 
 template <typename Char> inline void reset_color(FILE* stream) FMT_NOEXCEPT {
-  fputs(detail::data::reset_color, stream);
+  fputs("\x1b[0m", stream);
 }
 
 template <> inline void reset_color<wchar_t>(FILE* stream) FMT_NOEXCEPT {
-  fputs(detail::data::wreset_color, stream);
+  fputs(L"\x1b[0m", stream);
 }
 
 template <typename Char>
 inline void reset_color(buffer<Char>& buffer) FMT_NOEXCEPT {
-  const char* begin = data::reset_color;
-  const char* end = begin + sizeof(data::reset_color) - 1;
-  buffer.append(begin, end);
+  auto reset_color = string_view("\x1b[0m");
+  buffer.append(reset_color.begin(), reset_color.end());
 }
 
 template <typename Char>
 void vformat_to(buffer<Char>& buf, const text_style& ts,
                 basic_string_view<Char> format_str,
                 basic_format_args<buffer_context<type_identity_t<Char>>> args) {
   bool has_style = false;
@@ -485,18 +514,19 @@
     buf.append(foreground.begin(), foreground.end());
   }
   if (ts.has_background()) {
     has_style = true;
     auto background = detail::make_background_color<Char>(ts.get_background());
     buf.append(background.begin(), background.end());
   }
-  detail::vformat_to(buf, format_str, args);
+  detail::vformat_to(buf, format_str, args, {});
   if (has_style) detail::reset_color<Char>(buf);
 }
-}  // namespace detail
+
+FMT_END_DETAIL_NAMESPACE
 
 template <typename S, typename Char = char_t<S>>
 void vprint(std::FILE* f, const text_style& ts, const S& format,
             basic_format_args<buffer_context<type_identity_t<Char>>> args) {
   basic_memory_buffer<Char> buf;
   detail::vformat_to(buf, ts, to_string_view(format), args);
   buf.push_back(Char(0));
@@ -519,19 +549,23 @@
 void print(std::FILE* f, const text_style& ts, const S& format_str,
            const Args&... args) {
   vprint(f, ts, format_str,
          fmt::make_args_checked<Args...>(format_str, args...));
 }
 
 /**
+  \rst
   Formats a string and prints it to stdout using ANSI escape sequences to
   specify text formatting.
-  Example:
+
+  **Example**::
+
     fmt::print(fmt::emphasis::bold | fg(fmt::color::red),
                "Elapsed time: {0:.2f} seconds", 1.23);
+  \endrst
  */
 template <typename S, typename... Args,
           FMT_ENABLE_IF(detail::is_string<S>::value)>
 void print(const text_style& ts, const S& format_str, const Args&... args) {
   return print(stdout, ts, format_str, args...);
 }
 
@@ -555,27 +589,27 @@
     std::string message = fmt::format(fmt::emphasis::bold | fg(fmt::color::red),
                                       "The answer is {}", 42);
   \endrst
 */
 template <typename S, typename... Args, typename Char = char_t<S>>
 inline std::basic_string<Char> format(const text_style& ts, const S& format_str,
                                       const Args&... args) {
-  return vformat(ts, to_string_view(format_str),
-                 fmt::make_args_checked<Args...>(format_str, args...));
+  return fmt::vformat(ts, to_string_view(format_str),
+                      fmt::make_args_checked<Args...>(format_str, args...));
 }
 
 /**
   Formats a string with the given text_style and writes the output to ``out``.
  */
 template <typename OutputIt, typename Char,
           FMT_ENABLE_IF(detail::is_output_iterator<OutputIt, Char>::value)>
 OutputIt vformat_to(
     OutputIt out, const text_style& ts, basic_string_view<Char> format_str,
     basic_format_args<buffer_context<type_identity_t<Char>>> args) {
-  decltype(detail::get_buffer<Char>(out)) buf(detail::get_buffer_init(out));
+  auto&& buf = detail::get_buffer<Char>(out);
   detail::vformat_to(buf, ts, format_str, args);
   return detail::get_iterator(buf);
 }
 
 /**
   \rst
   Formats arguments with the given text_style, writes the result to the output
@@ -594,10 +628,11 @@
 inline auto format_to(OutputIt out, const text_style& ts, const S& format_str,
                       Args&&... args) ->
     typename std::enable_if<enable, OutputIt>::type {
   return vformat_to(out, ts, to_string_view(format_str),
                     fmt::make_args_checked<Args...>(format_str, args...));
 }
 
+FMT_MODULE_EXPORT_END
 FMT_END_NAMESPACE
 
 #endif  // FMT_COLOR_H_
```

### Comparing `lightgbm-3.3.5/compile/external_libs/fmt/include/fmt/compile.h` & `lightgbm-4.0.0/external_libs/fmt/include/fmt/compile.h`

 * *Files 17% similar despite different names*

```diff
@@ -4,400 +4,223 @@
 // All rights reserved.
 //
 // For the license information refer to format.h.
 
 #ifndef FMT_COMPILE_H_
 #define FMT_COMPILE_H_
 
-#include <vector>
-
 #include "format.h"
 
 FMT_BEGIN_NAMESPACE
 namespace detail {
 
-// A compile-time string which is compiled into fast formatting code.
-class compiled_string {};
-
-template <typename S>
-struct is_compiled_string : std::is_base_of<compiled_string, S> {};
-
-/**
-  \rst
-  Converts a string literal *s* into a format string that will be parsed at
-  compile time and converted into efficient formatting code. Requires C++17
-  ``constexpr if`` compiler support.
-
-  **Example**::
-
-    // Converts 42 into std::string using the most efficient method and no
-    // runtime format string processing.
-    std::string s = fmt::format(FMT_COMPILE("{}"), 42);
-  \endrst
- */
-#define FMT_COMPILE(s) FMT_STRING_IMPL(s, fmt::detail::compiled_string)
+// An output iterator that counts the number of objects written to it and
+// discards them.
+class counting_iterator {
+ private:
+  size_t count_;
 
-template <typename T, typename... Tail>
-const T& first(const T& value, const Tail&...) {
-  return value;
-}
+ public:
+  using iterator_category = std::output_iterator_tag;
+  using difference_type = std::ptrdiff_t;
+  using pointer = void;
+  using reference = void;
+  using _Unchecked_type = counting_iterator;  // Mark iterator as checked.
 
-// Part of a compiled format string. It can be either literal text or a
-// replacement field.
-template <typename Char> struct format_part {
-  enum class kind { arg_index, arg_name, text, replacement };
-
-  struct replacement {
-    arg_ref<Char> arg_id;
-    dynamic_format_specs<Char> specs;
+  struct value_type {
+    template <typename T> void operator=(const T&) {}
   };
 
-  kind part_kind;
-  union value {
-    int arg_index;
-    basic_string_view<Char> str;
-    replacement repl;
-
-    FMT_CONSTEXPR value(int index = 0) : arg_index(index) {}
-    FMT_CONSTEXPR value(basic_string_view<Char> s) : str(s) {}
-    FMT_CONSTEXPR value(replacement r) : repl(r) {}
-  } val;
-  // Position past the end of the argument id.
-  const Char* arg_id_end = nullptr;
-
-  FMT_CONSTEXPR format_part(kind k = kind::arg_index, value v = {})
-      : part_kind(k), val(v) {}
-
-  static FMT_CONSTEXPR format_part make_arg_index(int index) {
-    return format_part(kind::arg_index, index);
-  }
-  static FMT_CONSTEXPR format_part make_arg_name(basic_string_view<Char> name) {
-    return format_part(kind::arg_name, name);
-  }
-  static FMT_CONSTEXPR format_part make_text(basic_string_view<Char> text) {
-    return format_part(kind::text, text);
-  }
-  static FMT_CONSTEXPR format_part make_replacement(replacement repl) {
-    return format_part(kind::replacement, repl);
-  }
-};
+  counting_iterator() : count_(0) {}
 
-template <typename Char> struct part_counter {
-  unsigned num_parts = 0;
+  size_t count() const { return count_; }
 
-  FMT_CONSTEXPR void on_text(const Char* begin, const Char* end) {
-    if (begin != end) ++num_parts;
+  counting_iterator& operator++() {
+    ++count_;
+    return *this;
   }
-
-  FMT_CONSTEXPR int on_arg_id() { return ++num_parts, 0; }
-  FMT_CONSTEXPR int on_arg_id(int) { return ++num_parts, 0; }
-  FMT_CONSTEXPR int on_arg_id(basic_string_view<Char>) {
-    return ++num_parts, 0;
+  counting_iterator operator++(int) {
+    auto it = *this;
+    ++*this;
+    return it;
   }
 
-  FMT_CONSTEXPR void on_replacement_field(int, const Char*) {}
-
-  FMT_CONSTEXPR const Char* on_format_specs(int, const Char* begin,
-                                            const Char* end) {
-    // Find the matching brace.
-    unsigned brace_counter = 0;
-    for (; begin != end; ++begin) {
-      if (*begin == '{') {
-        ++brace_counter;
-      } else if (*begin == '}') {
-        if (brace_counter == 0u) break;
-        --brace_counter;
-      }
-    }
-    return begin;
+  friend counting_iterator operator+(counting_iterator it, difference_type n) {
+    it.count_ += static_cast<size_t>(n);
+    return it;
   }
 
-  FMT_CONSTEXPR void on_error(const char*) {}
+  value_type operator*() const { return {}; }
 };
 
-// Counts the number of parts in a format string.
-template <typename Char>
-FMT_CONSTEXPR unsigned count_parts(basic_string_view<Char> format_str) {
-  part_counter<Char> counter;
-  parse_format_string<true>(format_str, counter);
-  return counter.num_parts;
+template <typename Char, typename InputIt>
+inline counting_iterator copy_str(InputIt begin, InputIt end,
+                                  counting_iterator it) {
+  return it + (end - begin);
 }
 
-template <typename Char, typename PartHandler>
-class format_string_compiler : public error_handler {
- private:
-  using part = format_part<Char>;
+template <typename OutputIt> class truncating_iterator_base {
+ protected:
+  OutputIt out_;
+  size_t limit_;
+  size_t count_ = 0;
+
+  truncating_iterator_base() : out_(), limit_(0) {}
 
-  PartHandler handler_;
-  part part_;
-  basic_string_view<Char> format_str_;
-  basic_format_parse_context<Char> parse_context_;
+  truncating_iterator_base(OutputIt out, size_t limit)
+      : out_(out), limit_(limit) {}
 
  public:
-  FMT_CONSTEXPR format_string_compiler(basic_string_view<Char> format_str,
-                                       PartHandler handler)
-      : handler_(handler),
-        format_str_(format_str),
-        parse_context_(format_str) {}
-
-  FMT_CONSTEXPR void on_text(const Char* begin, const Char* end) {
-    if (begin != end)
-      handler_(part::make_text({begin, to_unsigned(end - begin)}));
-  }
+  using iterator_category = std::output_iterator_tag;
+  using value_type = typename std::iterator_traits<OutputIt>::value_type;
+  using difference_type = std::ptrdiff_t;
+  using pointer = void;
+  using reference = void;
+  using _Unchecked_type =
+      truncating_iterator_base;  // Mark iterator as checked.
+
+  OutputIt base() const { return out_; }
+  size_t count() const { return count_; }
+};
+
+// An output iterator that truncates the output and counts the number of objects
+// written to it.
+template <typename OutputIt,
+          typename Enable = typename std::is_void<
+              typename std::iterator_traits<OutputIt>::value_type>::type>
+class truncating_iterator;
+
+template <typename OutputIt>
+class truncating_iterator<OutputIt, std::false_type>
+    : public truncating_iterator_base<OutputIt> {
+  mutable typename truncating_iterator_base<OutputIt>::value_type blackhole_;
 
-  FMT_CONSTEXPR int on_arg_id() {
-    part_ = part::make_arg_index(parse_context_.next_arg_id());
-    return 0;
-  }
+ public:
+  using value_type = typename truncating_iterator_base<OutputIt>::value_type;
 
-  FMT_CONSTEXPR int on_arg_id(int id) {
-    parse_context_.check_arg_id(id);
-    part_ = part::make_arg_index(id);
-    return 0;
-  }
+  truncating_iterator() = default;
 
-  FMT_CONSTEXPR int on_arg_id(basic_string_view<Char> id) {
-    part_ = part::make_arg_name(id);
-    return 0;
+  truncating_iterator(OutputIt out, size_t limit)
+      : truncating_iterator_base<OutputIt>(out, limit) {}
+
+  truncating_iterator& operator++() {
+    if (this->count_++ < this->limit_) ++this->out_;
+    return *this;
   }
 
-  FMT_CONSTEXPR void on_replacement_field(int, const Char* ptr) {
-    part_.arg_id_end = ptr;
-    handler_(part_);
-  }
-
-  FMT_CONSTEXPR const Char* on_format_specs(int, const Char* begin,
-                                            const Char* end) {
-    auto repl = typename part::replacement();
-    dynamic_specs_handler<basic_format_parse_context<Char>> handler(
-        repl.specs, parse_context_);
-    auto it = parse_format_specs(begin, end, handler);
-    if (*it != '}') on_error("missing '}' in format string");
-    repl.arg_id = part_.part_kind == part::kind::arg_index
-                      ? arg_ref<Char>(part_.val.arg_index)
-                      : arg_ref<Char>(part_.val.str);
-    auto part = part::make_replacement(repl);
-    part.arg_id_end = begin;
-    handler_(part);
+  truncating_iterator operator++(int) {
+    auto it = *this;
+    ++*this;
     return it;
   }
-};
-
-// Compiles a format string and invokes handler(part) for each parsed part.
-template <bool IS_CONSTEXPR, typename Char, typename PartHandler>
-FMT_CONSTEXPR void compile_format_string(basic_string_view<Char> format_str,
-                                         PartHandler handler) {
-  parse_format_string<IS_CONSTEXPR>(
-      format_str,
-      format_string_compiler<Char, PartHandler>(format_str, handler));
-}
-
-template <typename OutputIt, typename Context, typename Id>
-void format_arg(
-    basic_format_parse_context<typename Context::char_type>& parse_ctx,
-    Context& ctx, Id arg_id) {
-  ctx.advance_to(visit_format_arg(
-      arg_formatter<OutputIt, typename Context::char_type>(ctx, &parse_ctx),
-      ctx.arg(arg_id)));
-}
-
-// vformat_to is defined in a subnamespace to prevent ADL.
-namespace cf {
-template <typename Context, typename OutputIt, typename CompiledFormat>
-auto vformat_to(OutputIt out, CompiledFormat& cf,
-                basic_format_args<Context> args) -> typename Context::iterator {
-  using char_type = typename Context::char_type;
-  basic_format_parse_context<char_type> parse_ctx(
-      to_string_view(cf.format_str_));
-  Context ctx(out, args);
-
-  const auto& parts = cf.parts();
-  for (auto part_it = std::begin(parts); part_it != std::end(parts);
-       ++part_it) {
-    const auto& part = *part_it;
-    const auto& value = part.val;
-
-    using format_part_t = format_part<char_type>;
-    switch (part.part_kind) {
-    case format_part_t::kind::text: {
-      const auto text = value.str;
-      auto output = ctx.out();
-      auto&& it = reserve(output, text.size());
-      it = std::copy_n(text.begin(), text.size(), it);
-      ctx.advance_to(output);
-      break;
-    }
 
-    case format_part_t::kind::arg_index:
-      advance_to(parse_ctx, part.arg_id_end);
-      detail::format_arg<OutputIt>(parse_ctx, ctx, value.arg_index);
-      break;
-
-    case format_part_t::kind::arg_name:
-      advance_to(parse_ctx, part.arg_id_end);
-      detail::format_arg<OutputIt>(parse_ctx, ctx, value.str);
-      break;
-
-    case format_part_t::kind::replacement: {
-      const auto& arg_id_value = value.repl.arg_id.val;
-      const auto arg = value.repl.arg_id.kind == arg_id_kind::index
-                           ? ctx.arg(arg_id_value.index)
-                           : ctx.arg(arg_id_value.name);
-
-      auto specs = value.repl.specs;
-
-      handle_dynamic_spec<width_checker>(specs.width, specs.width_ref, ctx);
-      handle_dynamic_spec<precision_checker>(specs.precision,
-                                             specs.precision_ref, ctx);
-
-      error_handler h;
-      numeric_specs_checker<error_handler> checker(h, arg.type());
-      if (specs.align == align::numeric) checker.require_numeric_argument();
-      if (specs.sign != sign::none) checker.check_sign();
-      if (specs.alt) checker.require_numeric_argument();
-      if (specs.precision >= 0) checker.check_precision();
-
-      advance_to(parse_ctx, part.arg_id_end);
-      ctx.advance_to(
-          visit_format_arg(arg_formatter<OutputIt, typename Context::char_type>(
-                               ctx, nullptr, &specs),
-                           arg));
-      break;
-    }
-    }
+  value_type& operator*() const {
+    return this->count_ < this->limit_ ? *this->out_ : blackhole_;
   }
-  return ctx.out();
-}
-}  // namespace cf
-
-struct basic_compiled_format {};
+};
 
-template <typename S, typename = void>
-struct compiled_format_base : basic_compiled_format {
-  using char_type = char_t<S>;
-  using parts_container = std::vector<detail::format_part<char_type>>;
+template <typename OutputIt>
+class truncating_iterator<OutputIt, std::true_type>
+    : public truncating_iterator_base<OutputIt> {
+ public:
+  truncating_iterator() = default;
 
-  parts_container compiled_parts;
+  truncating_iterator(OutputIt out, size_t limit)
+      : truncating_iterator_base<OutputIt>(out, limit) {}
 
-  explicit compiled_format_base(basic_string_view<char_type> format_str) {
-    compile_format_string<false>(format_str,
-                                 [this](const format_part<char_type>& part) {
-                                   compiled_parts.push_back(part);
-                                 });
+  template <typename T> truncating_iterator& operator=(T val) {
+    if (this->count_++ < this->limit_) *this->out_++ = val;
+    return *this;
   }
 
-  const parts_container& parts() const { return compiled_parts; }
+  truncating_iterator& operator++() { return *this; }
+  truncating_iterator& operator++(int) { return *this; }
+  truncating_iterator& operator*() { return *this; }
 };
 
-template <typename Char, unsigned N> struct format_part_array {
-  format_part<Char> data[N] = {};
-  FMT_CONSTEXPR format_part_array() = default;
-};
+// A compile-time string which is compiled into fast formatting code.
+class compiled_string {};
 
-template <typename Char, unsigned N>
-FMT_CONSTEXPR format_part_array<Char, N> compile_to_parts(
-    basic_string_view<Char> format_str) {
-  format_part_array<Char, N> parts;
-  unsigned counter = 0;
-  // This is not a lambda for compatibility with older compilers.
-  struct {
-    format_part<Char>* parts;
-    unsigned* counter;
-    FMT_CONSTEXPR void operator()(const format_part<Char>& part) {
-      parts[(*counter)++] = part;
-    }
-  } collector{parts.data, &counter};
-  compile_format_string<true>(format_str, collector);
-  if (counter < N) {
-    parts.data[counter] =
-        format_part<Char>::make_text(basic_string_view<Char>());
-  }
-  return parts;
-}
+template <typename S>
+struct is_compiled_string : std::is_base_of<compiled_string, S> {};
 
-template <typename T> constexpr const T& constexpr_max(const T& a, const T& b) {
-  return (a < b) ? b : a;
-}
+/**
+  \rst
+  Converts a string literal *s* into a format string that will be parsed at
+  compile time and converted into efficient formatting code. Requires C++17
+  ``constexpr if`` compiler support.
 
-template <typename S>
-struct compiled_format_base<S, enable_if_t<is_compile_string<S>::value>>
-    : basic_compiled_format {
-  using char_type = char_t<S>;
-
-  FMT_CONSTEXPR explicit compiled_format_base(basic_string_view<char_type>) {}
-
-// Workaround for old compilers. Format string compilation will not be
-// performed there anyway.
-#if FMT_USE_CONSTEXPR
-  static FMT_CONSTEXPR_DECL const unsigned num_format_parts =
-      constexpr_max(count_parts(to_string_view(S())), 1u);
+  **Example**::
+
+    // Converts 42 into std::string using the most efficient method and no
+    // runtime format string processing.
+    std::string s = fmt::format(FMT_COMPILE("{}"), 42);
+  \endrst
+ */
+#if defined(__cpp_if_constexpr) && defined(__cpp_return_type_deduction)
+#  define FMT_COMPILE(s) \
+    FMT_STRING_IMPL(s, fmt::detail::compiled_string, explicit)
 #else
-  static const unsigned num_format_parts = 1;
+#  define FMT_COMPILE(s) FMT_STRING(s)
 #endif
 
-  using parts_container = format_part<char_type>[num_format_parts];
-
-  const parts_container& parts() const {
-    static FMT_CONSTEXPR_DECL const auto compiled_parts =
-        compile_to_parts<char_type, num_format_parts>(
-            detail::to_string_view(S()));
-    return compiled_parts.data;
+#if FMT_USE_NONTYPE_TEMPLATE_PARAMETERS
+template <typename Char, size_t N,
+          fmt::detail_exported::fixed_string<Char, N> Str>
+struct udl_compiled_string : compiled_string {
+  using char_type = Char;
+  constexpr operator basic_string_view<char_type>() const {
+    return {Str.data, N - 1};
   }
 };
+#endif
 
-template <typename S, typename... Args>
-class compiled_format : private compiled_format_base<S> {
- public:
-  using typename compiled_format_base<S>::char_type;
-
- private:
-  basic_string_view<char_type> format_str_;
-
-  template <typename Context, typename OutputIt, typename CompiledFormat>
-  friend auto cf::vformat_to(OutputIt out, CompiledFormat& cf,
-                             basic_format_args<Context> args) ->
-      typename Context::iterator;
-
- public:
-  compiled_format() = delete;
-  explicit constexpr compiled_format(basic_string_view<char_type> format_str)
-      : compiled_format_base<S>(format_str), format_str_(format_str) {}
-};
+template <typename T, typename... Tail>
+const T& first(const T& value, const Tail&...) {
+  return value;
+}
 
-#ifdef __cpp_if_constexpr
+#if defined(__cpp_if_constexpr) && defined(__cpp_return_type_deduction)
 template <typename... Args> struct type_list {};
 
 // Returns a reference to the argument at index N from [first, rest...].
 template <int N, typename T, typename... Args>
 constexpr const auto& get([[maybe_unused]] const T& first,
                           [[maybe_unused]] const Args&... rest) {
   static_assert(N < 1 + sizeof...(Args), "index is out of bounds");
   if constexpr (N == 0)
     return first;
   else
-    return get<N - 1>(rest...);
+    return detail::get<N - 1>(rest...);
+}
+
+template <typename Char, typename... Args>
+constexpr int get_arg_index_by_name(basic_string_view<Char> name,
+                                    type_list<Args...>) {
+  return get_arg_index_by_name<Args...>(name);
 }
 
 template <int N, typename> struct get_type_impl;
 
 template <int N, typename... Args> struct get_type_impl<N, type_list<Args...>> {
-  using type = remove_cvref_t<decltype(get<N>(std::declval<Args>()...))>;
+  using type =
+      remove_cvref_t<decltype(detail::get<N>(std::declval<Args>()...))>;
 };
 
 template <int N, typename T>
 using get_type = typename get_type_impl<N, T>::type;
 
 template <typename T> struct is_compiled_format : std::false_type {};
 
 template <typename Char> struct text {
   basic_string_view<Char> data;
   using char_type = Char;
 
   template <typename OutputIt, typename... Args>
-  OutputIt format(OutputIt out, const Args&...) const {
+  constexpr OutputIt format(OutputIt out, const Args&...) const {
     return write<Char>(out, data);
   }
 };
 
 template <typename Char>
 struct is_compiled_format<text<Char>> : std::true_type {};
 
@@ -408,63 +231,103 @@
 }
 
 template <typename Char> struct code_unit {
   Char value;
   using char_type = Char;
 
   template <typename OutputIt, typename... Args>
-  OutputIt format(OutputIt out, const Args&...) const {
+  constexpr OutputIt format(OutputIt out, const Args&...) const {
     return write<Char>(out, value);
   }
 };
 
+// This ensures that the argument type is convertible to `const T&`.
+template <typename T, int N, typename... Args>
+constexpr const T& get_arg_checked(const Args&... args) {
+  const auto& arg = detail::get<N>(args...);
+  if constexpr (detail::is_named_arg<remove_cvref_t<decltype(arg)>>()) {
+    return arg.value;
+  } else {
+    return arg;
+  }
+}
+
 template <typename Char>
 struct is_compiled_format<code_unit<Char>> : std::true_type {};
 
 // A replacement field that refers to argument N.
 template <typename Char, typename T, int N> struct field {
   using char_type = Char;
 
   template <typename OutputIt, typename... Args>
-  OutputIt format(OutputIt out, const Args&... args) const {
-    // This ensures that the argument type is convertile to `const T&`.
-    const T& arg = get<N>(args...);
-    return write<Char>(out, arg);
+  constexpr OutputIt format(OutputIt out, const Args&... args) const {
+    return write<Char>(out, get_arg_checked<T, N>(args...));
   }
 };
 
 template <typename Char, typename T, int N>
 struct is_compiled_format<field<Char, T, N>> : std::true_type {};
 
+// A replacement field that refers to argument with name.
+template <typename Char> struct runtime_named_field {
+  using char_type = Char;
+  basic_string_view<Char> name;
+
+  template <typename OutputIt, typename T>
+  constexpr static bool try_format_argument(
+      OutputIt& out,
+      // [[maybe_unused]] due to unused-but-set-parameter warning in GCC 7,8,9
+      [[maybe_unused]] basic_string_view<Char> arg_name, const T& arg) {
+    if constexpr (is_named_arg<typename std::remove_cv<T>::type>::value) {
+      if (arg_name == arg.name) {
+        out = write<Char>(out, arg.value);
+        return true;
+      }
+    }
+    return false;
+  }
+
+  template <typename OutputIt, typename... Args>
+  constexpr OutputIt format(OutputIt out, const Args&... args) const {
+    bool found = (try_format_argument(out, name, args) || ...);
+    if (!found) {
+      FMT_THROW(format_error("argument with specified name is not found"));
+    }
+    return out;
+  }
+};
+
+template <typename Char>
+struct is_compiled_format<runtime_named_field<Char>> : std::true_type {};
+
 // A replacement field that refers to argument N and has format specifiers.
 template <typename Char, typename T, int N> struct spec_field {
   using char_type = Char;
-  mutable formatter<T, Char> fmt;
+  formatter<T, Char> fmt;
 
   template <typename OutputIt, typename... Args>
-  OutputIt format(OutputIt out, const Args&... args) const {
-    // This ensures that the argument type is convertile to `const T&`.
-    const T& arg = get<N>(args...);
+  constexpr FMT_INLINE OutputIt format(OutputIt out,
+                                       const Args&... args) const {
     const auto& vargs =
-        make_format_args<basic_format_context<OutputIt, Char>>(args...);
+        fmt::make_format_args<basic_format_context<OutputIt, Char>>(args...);
     basic_format_context<OutputIt, Char> ctx(out, vargs);
-    return fmt.format(arg, ctx);
+    return fmt.format(get_arg_checked<T, N>(args...), ctx);
   }
 };
 
 template <typename Char, typename T, int N>
 struct is_compiled_format<spec_field<Char, T, N>> : std::true_type {};
 
 template <typename L, typename R> struct concat {
   L lhs;
   R rhs;
   using char_type = typename L::char_type;
 
   template <typename OutputIt, typename... Args>
-  OutputIt format(OutputIt out, const Args&... args) const {
+  constexpr OutputIt format(OutputIt out, const Args&... args) const {
     out = lhs.format(out, args...);
     return rhs.format(out, args...);
   }
 };
 
 template <typename L, typename R>
 struct is_compiled_format<concat<L, R>> : std::true_type {};
@@ -504,198 +367,276 @@
 
 template <typename T, typename Char> struct parse_specs_result {
   formatter<T, Char> fmt;
   size_t end;
   int next_arg_id;
 };
 
+constexpr int manual_indexing_id = -1;
+
 template <typename T, typename Char>
 constexpr parse_specs_result<T, Char> parse_specs(basic_string_view<Char> str,
-                                                  size_t pos, int arg_id) {
+                                                  size_t pos, int next_arg_id) {
   str.remove_prefix(pos);
-  auto ctx = basic_format_parse_context<Char>(str, {}, arg_id + 1);
+  auto ctx = basic_format_parse_context<Char>(str, {}, next_arg_id);
   auto f = formatter<T, Char>();
   auto end = f.parse(ctx);
-  return {f, pos + (end - str.data()) + 1, ctx.next_arg_id()};
+  return {f, pos + fmt::detail::to_unsigned(end - str.data()) + 1,
+          next_arg_id == 0 ? manual_indexing_id : ctx.next_arg_id()};
+}
+
+template <typename Char> struct arg_id_handler {
+  arg_ref<Char> arg_id;
+
+  constexpr int operator()() {
+    FMT_ASSERT(false, "handler cannot be used with automatic indexing");
+    return 0;
+  }
+  constexpr int operator()(int id) {
+    arg_id = arg_ref<Char>(id);
+    return 0;
+  }
+  constexpr int operator()(basic_string_view<Char> id) {
+    arg_id = arg_ref<Char>(id);
+    return 0;
+  }
+
+  constexpr void on_error(const char* message) {
+    FMT_THROW(format_error(message));
+  }
+};
+
+template <typename Char> struct parse_arg_id_result {
+  arg_ref<Char> arg_id;
+  const Char* arg_id_end;
+};
+
+template <int ID, typename Char>
+constexpr auto parse_arg_id(const Char* begin, const Char* end) {
+  auto handler = arg_id_handler<Char>{arg_ref<Char>{}};
+  auto arg_id_end = parse_arg_id(begin, end, handler);
+  return parse_arg_id_result<Char>{handler.arg_id, arg_id_end};
+}
+
+template <typename T, typename Enable = void> struct field_type {
+  using type = remove_cvref_t<T>;
+};
+
+template <typename T>
+struct field_type<T, enable_if_t<detail::is_named_arg<T>::value>> {
+  using type = remove_cvref_t<decltype(T::value)>;
+};
+
+template <typename T, typename Args, size_t END_POS, int ARG_INDEX, int NEXT_ID,
+          typename S>
+constexpr auto parse_replacement_field_then_tail(S format_str) {
+  using char_type = typename S::char_type;
+  constexpr auto str = basic_string_view<char_type>(format_str);
+  constexpr char_type c = END_POS != str.size() ? str[END_POS] : char_type();
+  if constexpr (c == '}') {
+    return parse_tail<Args, END_POS + 1, NEXT_ID>(
+        field<char_type, typename field_type<T>::type, ARG_INDEX>(),
+        format_str);
+  } else if constexpr (c == ':') {
+    constexpr auto result = parse_specs<typename field_type<T>::type>(
+        str, END_POS + 1, NEXT_ID == manual_indexing_id ? 0 : NEXT_ID);
+    return parse_tail<Args, result.end, result.next_arg_id>(
+        spec_field<char_type, typename field_type<T>::type, ARG_INDEX>{
+            result.fmt},
+        format_str);
+  }
 }
 
 // Compiles a non-empty format string and returns the compiled representation
 // or unknown_format() on unrecognized input.
 template <typename Args, size_t POS, int ID, typename S>
 constexpr auto compile_format_string(S format_str) {
   using char_type = typename S::char_type;
-  constexpr basic_string_view<char_type> str = format_str;
+  constexpr auto str = basic_string_view<char_type>(format_str);
   if constexpr (str[POS] == '{') {
-    if (POS + 1 == str.size())
-      throw format_error("unmatched '{' in format string");
+    if constexpr (POS + 1 == str.size())
+      FMT_THROW(format_error("unmatched '{' in format string"));
     if constexpr (str[POS + 1] == '{') {
       return parse_tail<Args, POS + 2, ID>(make_text(str, POS, 1), format_str);
-    } else if constexpr (str[POS + 1] == '}') {
-      using type = get_type<ID, Args>;
-      return parse_tail<Args, POS + 2, ID + 1>(field<char_type, type, ID>(),
-                                               format_str);
-    } else if constexpr (str[POS + 1] == ':') {
-      using type = get_type<ID, Args>;
-      constexpr auto result = parse_specs<type>(str, POS + 2, ID);
-      return parse_tail<Args, result.end, result.next_arg_id>(
-          spec_field<char_type, type, ID>{result.fmt}, format_str);
+    } else if constexpr (str[POS + 1] == '}' || str[POS + 1] == ':') {
+      static_assert(ID != manual_indexing_id,
+                    "cannot switch from manual to automatic argument indexing");
+      constexpr auto next_id =
+          ID != manual_indexing_id ? ID + 1 : manual_indexing_id;
+      return parse_replacement_field_then_tail<get_type<ID, Args>, Args,
+                                               POS + 1, ID, next_id>(
+          format_str);
     } else {
-      return unknown_format();
+      constexpr auto arg_id_result =
+          parse_arg_id<ID>(str.data() + POS + 1, str.data() + str.size());
+      constexpr auto arg_id_end_pos = arg_id_result.arg_id_end - str.data();
+      constexpr char_type c =
+          arg_id_end_pos != str.size() ? str[arg_id_end_pos] : char_type();
+      static_assert(c == '}' || c == ':', "missing '}' in format string");
+      if constexpr (arg_id_result.arg_id.kind == arg_id_kind::index) {
+        static_assert(
+            ID == manual_indexing_id || ID == 0,
+            "cannot switch from automatic to manual argument indexing");
+        constexpr auto arg_index = arg_id_result.arg_id.val.index;
+        return parse_replacement_field_then_tail<get_type<arg_index, Args>,
+                                                 Args, arg_id_end_pos,
+                                                 arg_index, manual_indexing_id>(
+            format_str);
+      } else if constexpr (arg_id_result.arg_id.kind == arg_id_kind::name) {
+        constexpr auto arg_index =
+            get_arg_index_by_name(arg_id_result.arg_id.val.name, Args{});
+        if constexpr (arg_index != invalid_arg_index) {
+          constexpr auto next_id =
+              ID != manual_indexing_id ? ID + 1 : manual_indexing_id;
+          return parse_replacement_field_then_tail<
+              decltype(get_type<arg_index, Args>::value), Args, arg_id_end_pos,
+              arg_index, next_id>(format_str);
+        } else {
+          if constexpr (c == '}') {
+            return parse_tail<Args, arg_id_end_pos + 1, ID>(
+                runtime_named_field<char_type>{arg_id_result.arg_id.val.name},
+                format_str);
+          } else if constexpr (c == ':') {
+            return unknown_format();  // no type info for specs parsing
+          }
+        }
+      }
     }
   } else if constexpr (str[POS] == '}') {
-    if (POS + 1 == str.size())
-      throw format_error("unmatched '}' in format string");
+    if constexpr (POS + 1 == str.size())
+      FMT_THROW(format_error("unmatched '}' in format string"));
     return parse_tail<Args, POS + 2, ID>(make_text(str, POS, 1), format_str);
   } else {
     constexpr auto end = parse_text(str, POS + 1);
     if constexpr (end - POS > 1) {
       return parse_tail<Args, end, ID>(make_text(str, POS, end - POS),
                                        format_str);
     } else {
       return parse_tail<Args, end, ID>(code_unit<char_type>{str[POS]},
                                        format_str);
     }
   }
 }
 
 template <typename... Args, typename S,
-          FMT_ENABLE_IF(is_compile_string<S>::value ||
-                        detail::is_compiled_string<S>::value)>
+          FMT_ENABLE_IF(detail::is_compiled_string<S>::value)>
 constexpr auto compile(S format_str) {
-  constexpr basic_string_view<typename S::char_type> str = format_str;
+  constexpr auto str = basic_string_view<typename S::char_type>(format_str);
   if constexpr (str.size() == 0) {
     return detail::make_text(str, 0, 0);
   } else {
     constexpr auto result =
         detail::compile_format_string<detail::type_list<Args...>, 0, 0>(
             format_str);
-    if constexpr (std::is_same<remove_cvref_t<decltype(result)>,
-                               detail::unknown_format>()) {
-      return detail::compiled_format<S, Args...>(to_string_view(format_str));
-    } else {
-      return result;
-    }
+    return result;
   }
 }
-#else
-template <typename... Args, typename S,
-          FMT_ENABLE_IF(is_compile_string<S>::value)>
-constexpr auto compile(S format_str) -> detail::compiled_format<S, Args...> {
-  return detail::compiled_format<S, Args...>(to_string_view(format_str));
-}
-#endif  // __cpp_if_constexpr
-
-// Compiles the format string which must be a string literal.
-template <typename... Args, typename Char, size_t N>
-auto compile(const Char (&format_str)[N])
-    -> detail::compiled_format<const Char*, Args...> {
-  return detail::compiled_format<const Char*, Args...>(
-      basic_string_view<Char>(format_str, N - 1));
-}
+#endif  // defined(__cpp_if_constexpr) && defined(__cpp_return_type_deduction)
 }  // namespace detail
 
-// DEPRECATED! use FMT_COMPILE instead.
-template <typename... Args>
-FMT_DEPRECATED auto compile(const Args&... args)
-    -> decltype(detail::compile(args...)) {
-  return detail::compile(args...);
-}
+FMT_MODULE_EXPORT_BEGIN
 
-#if FMT_USE_CONSTEXPR
-#  ifdef __cpp_if_constexpr
+#if defined(__cpp_if_constexpr) && defined(__cpp_return_type_deduction)
 
 template <typename CompiledFormat, typename... Args,
           typename Char = typename CompiledFormat::char_type,
           FMT_ENABLE_IF(detail::is_compiled_format<CompiledFormat>::value)>
 FMT_INLINE std::basic_string<Char> format(const CompiledFormat& cf,
                                           const Args&... args) {
-  basic_memory_buffer<Char> buffer;
-  cf.format(detail::buffer_appender<Char>(buffer), args...);
-  return to_string(buffer);
+  auto s = std::basic_string<Char>();
+  cf.format(std::back_inserter(s), args...);
+  return s;
 }
 
 template <typename OutputIt, typename CompiledFormat, typename... Args,
           FMT_ENABLE_IF(detail::is_compiled_format<CompiledFormat>::value)>
-OutputIt format_to(OutputIt out, const CompiledFormat& cf,
-                   const Args&... args) {
+constexpr FMT_INLINE OutputIt format_to(OutputIt out, const CompiledFormat& cf,
+                                        const Args&... args) {
   return cf.format(out, args...);
 }
-#  endif  // __cpp_if_constexpr
-#endif    // FMT_USE_CONSTEXPR
-
-template <typename CompiledFormat, typename... Args,
-          typename Char = typename CompiledFormat::char_type,
-          FMT_ENABLE_IF(std::is_base_of<detail::basic_compiled_format,
-                                        CompiledFormat>::value)>
-std::basic_string<Char> format(const CompiledFormat& cf, const Args&... args) {
-  basic_memory_buffer<Char> buffer;
-  using context = buffer_context<Char>;
-  detail::cf::vformat_to<context>(detail::buffer_appender<Char>(buffer), cf,
-                                  make_format_args<context>(args...));
-  return to_string(buffer);
-}
 
 template <typename S, typename... Args,
           FMT_ENABLE_IF(detail::is_compiled_string<S>::value)>
 FMT_INLINE std::basic_string<typename S::char_type> format(const S&,
                                                            Args&&... args) {
-#ifdef __cpp_if_constexpr
   if constexpr (std::is_same<typename S::char_type, char>::value) {
-    constexpr basic_string_view<typename S::char_type> str = S();
-    if (str.size() == 2 && str[0] == '{' && str[1] == '}')
-      return fmt::to_string(detail::first(args...));
+    constexpr auto str = basic_string_view<typename S::char_type>(S());
+    if constexpr (str.size() == 2 && str[0] == '{' && str[1] == '}') {
+      const auto& first = detail::first(args...);
+      if constexpr (detail::is_named_arg<
+                        remove_cvref_t<decltype(first)>>::value) {
+        return fmt::to_string(first.value);
+      } else {
+        return fmt::to_string(first);
+      }
+    }
   }
-#endif
   constexpr auto compiled = detail::compile<Args...>(S());
-  return format(compiled, std::forward<Args>(args)...);
-}
-
-template <typename OutputIt, typename CompiledFormat, typename... Args,
-          FMT_ENABLE_IF(std::is_base_of<detail::basic_compiled_format,
-                                        CompiledFormat>::value)>
-OutputIt format_to(OutputIt out, const CompiledFormat& cf,
-                   const Args&... args) {
-  using char_type = typename CompiledFormat::char_type;
-  using context = format_context_t<OutputIt, char_type>;
-  return detail::cf::vformat_to<context>(out, cf,
-                                         make_format_args<context>(args...));
+  if constexpr (std::is_same<remove_cvref_t<decltype(compiled)>,
+                             detail::unknown_format>()) {
+    return format(static_cast<basic_string_view<typename S::char_type>>(S()),
+                  std::forward<Args>(args)...);
+  } else {
+    return format(compiled, std::forward<Args>(args)...);
+  }
 }
 
 template <typename OutputIt, typename S, typename... Args,
           FMT_ENABLE_IF(detail::is_compiled_string<S>::value)>
-OutputIt format_to(OutputIt out, const S&, const Args&... args) {
+FMT_CONSTEXPR OutputIt format_to(OutputIt out, const S&, Args&&... args) {
   constexpr auto compiled = detail::compile<Args...>(S());
-  return format_to(out, compiled, args...);
+  if constexpr (std::is_same<remove_cvref_t<decltype(compiled)>,
+                             detail::unknown_format>()) {
+    return format_to(out,
+                     static_cast<basic_string_view<typename S::char_type>>(S()),
+                     std::forward<Args>(args)...);
+  } else {
+    return format_to(out, compiled, std::forward<Args>(args)...);
+  }
 }
+#endif
 
-template <typename OutputIt, typename CompiledFormat, typename... Args>
-auto format_to_n(OutputIt out, size_t n, const CompiledFormat& cf,
-                 const Args&... args) ->
-    typename std::enable_if<
-        detail::is_output_iterator<OutputIt,
-                                   typename CompiledFormat::char_type>::value &&
-            std::is_base_of<detail::basic_compiled_format,
-                            CompiledFormat>::value,
-        format_to_n_result<OutputIt>>::type {
-  auto it =
-      format_to(detail::truncating_iterator<OutputIt>(out, n), cf, args...);
+template <typename OutputIt, typename S, typename... Args,
+          FMT_ENABLE_IF(detail::is_compiled_string<S>::value)>
+format_to_n_result<OutputIt> format_to_n(OutputIt out, size_t n,
+                                         const S& format_str, Args&&... args) {
+  auto it = format_to(detail::truncating_iterator<OutputIt>(out, n), format_str,
+                      std::forward<Args>(args)...);
   return {it.base(), it.count()};
 }
 
-template <typename OutputIt, typename S, typename... Args,
+template <typename S, typename... Args,
           FMT_ENABLE_IF(detail::is_compiled_string<S>::value)>
-format_to_n_result<OutputIt> format_to_n(OutputIt out, size_t n, const S&,
-                                         const Args&... args) {
-  constexpr auto compiled = detail::compile<Args...>(S());
-  auto it = format_to(detail::truncating_iterator<OutputIt>(out, n), compiled,
-                      args...);
-  return {it.base(), it.count()};
+size_t formatted_size(const S& format_str, const Args&... args) {
+  return format_to(detail::counting_iterator(), format_str, args...).count();
 }
 
-template <typename CompiledFormat, typename... Args>
-size_t formatted_size(const CompiledFormat& cf, const Args&... args) {
-  return format_to(detail::counting_iterator(), cf, args...).count();
+template <typename S, typename... Args,
+          FMT_ENABLE_IF(detail::is_compiled_string<S>::value)>
+void print(std::FILE* f, const S& format_str, const Args&... args) {
+  memory_buffer buffer;
+  format_to(std::back_inserter(buffer), format_str, args...);
+  detail::print(f, {buffer.data(), buffer.size()});
 }
 
+template <typename S, typename... Args,
+          FMT_ENABLE_IF(detail::is_compiled_string<S>::value)>
+void print(const S& format_str, const Args&... args) {
+  print(stdout, format_str, args...);
+}
+
+#if FMT_USE_NONTYPE_TEMPLATE_PARAMETERS
+inline namespace literals {
+template <detail_exported::fixed_string Str>
+constexpr detail::udl_compiled_string<
+    remove_cvref_t<decltype(Str.data[0])>,
+    sizeof(Str.data) / sizeof(decltype(Str.data[0])), Str>
+operator""_cf() {
+  return {};
+}
+}  // namespace literals
+#endif
+
+FMT_MODULE_EXPORT_END
 FMT_END_NAMESPACE
 
 #endif  // FMT_COMPILE_H_
```

### Comparing `lightgbm-3.3.5/compile/external_libs/fmt/include/fmt/core.h` & `lightgbm-4.0.0/external_libs/fmt/include/fmt/core.h`

 * *Files 24% similar despite different names*

```diff
@@ -1,115 +1,142 @@
-// Formatting library for C++ - the core API
+// Formatting library for C++ - the core API for char/UTF-8
 //
 // Copyright (c) 2012 - present, Victor Zverovich
 // All rights reserved.
 //
 // For the license information refer to format.h.
 
 #ifndef FMT_CORE_H_
 #define FMT_CORE_H_
 
-#include <cstdio>  // std::FILE
+#include <cstddef>  // std::byte
+#include <cstdio>   // std::FILE
 #include <cstring>
-#include <functional>
 #include <iterator>
-#include <memory>
+#include <limits>
 #include <string>
 #include <type_traits>
-#include <vector>
 
 // The fmt library version in the form major * 10000 + minor * 100 + patch.
-#define FMT_VERSION 70102
+#define FMT_VERSION 80101
 
-#ifdef __clang__
+#if defined(__clang__) && !defined(__ibmxl__)
 #  define FMT_CLANG_VERSION (__clang_major__ * 100 + __clang_minor__)
 #else
 #  define FMT_CLANG_VERSION 0
 #endif
 
-#if defined(__GNUC__) && !defined(__clang__)
+#if defined(__GNUC__) && !defined(__clang__) && !defined(__INTEL_COMPILER) && \
+    !defined(__NVCOMPILER)
 #  define FMT_GCC_VERSION (__GNUC__ * 100 + __GNUC_MINOR__)
 #else
 #  define FMT_GCC_VERSION 0
 #endif
 
-#if defined(__INTEL_COMPILER)
-#  define FMT_ICC_VERSION __INTEL_COMPILER
-#else
-#  define FMT_ICC_VERSION 0
+#ifndef FMT_GCC_PRAGMA
+// Workaround _Pragma bug https://gcc.gnu.org/bugzilla/show_bug.cgi?id=59884.
+#  if FMT_GCC_VERSION >= 504
+#    define FMT_GCC_PRAGMA(arg) _Pragma(arg)
+#  else
+#    define FMT_GCC_PRAGMA(arg)
+#  endif
 #endif
 
-#if __cplusplus >= 201103L || defined(__GXX_EXPERIMENTAL_CXX0X__)
-#  define FMT_HAS_GXX_CXX11 FMT_GCC_VERSION
+#ifdef __ICL
+#  define FMT_ICC_VERSION __ICL
+#elif defined(__INTEL_COMPILER)
+#  define FMT_ICC_VERSION __INTEL_COMPILER
 #else
-#  define FMT_HAS_GXX_CXX11 0
+#  define FMT_ICC_VERSION 0
 #endif
 
 #ifdef __NVCC__
 #  define FMT_NVCC __NVCC__
 #else
 #  define FMT_NVCC 0
 #endif
 
 #ifdef _MSC_VER
 #  define FMT_MSC_VER _MSC_VER
-#  define FMT_SUPPRESS_MSC_WARNING(n) __pragma(warning(suppress : n))
+#  define FMT_MSC_WARNING(...) __pragma(warning(__VA_ARGS__))
 #else
 #  define FMT_MSC_VER 0
-#  define FMT_SUPPRESS_MSC_WARNING(n)
+#  define FMT_MSC_WARNING(...)
 #endif
 
 #ifdef __has_feature
 #  define FMT_HAS_FEATURE(x) __has_feature(x)
 #else
 #  define FMT_HAS_FEATURE(x) 0
 #endif
 
-#if defined(__has_include) && !defined(__INTELLISENSE__) && \
+#if defined(__has_include) &&                             \
+    (!defined(__INTELLISENSE__) || FMT_MSC_VER > 1900) && \
     (!FMT_ICC_VERSION || FMT_ICC_VERSION >= 1600)
 #  define FMT_HAS_INCLUDE(x) __has_include(x)
 #else
 #  define FMT_HAS_INCLUDE(x) 0
 #endif
 
 #ifdef __has_cpp_attribute
 #  define FMT_HAS_CPP_ATTRIBUTE(x) __has_cpp_attribute(x)
 #else
 #  define FMT_HAS_CPP_ATTRIBUTE(x) 0
 #endif
 
+#ifdef _MSVC_LANG
+#  define FMT_CPLUSPLUS _MSVC_LANG
+#else
+#  define FMT_CPLUSPLUS __cplusplus
+#endif
+
 #define FMT_HAS_CPP14_ATTRIBUTE(attribute) \
-  (__cplusplus >= 201402L && FMT_HAS_CPP_ATTRIBUTE(attribute))
+  (FMT_CPLUSPLUS >= 201402L && FMT_HAS_CPP_ATTRIBUTE(attribute))
 
 #define FMT_HAS_CPP17_ATTRIBUTE(attribute) \
-  (__cplusplus >= 201703L && FMT_HAS_CPP_ATTRIBUTE(attribute))
+  (FMT_CPLUSPLUS >= 201703L && FMT_HAS_CPP_ATTRIBUTE(attribute))
 
 // Check if relaxed C++14 constexpr is supported.
 // GCC doesn't allow throw in constexpr until version 6 (bug 67371).
 #ifndef FMT_USE_CONSTEXPR
 #  define FMT_USE_CONSTEXPR                                           \
-    (FMT_HAS_FEATURE(cxx_relaxed_constexpr) || FMT_MSC_VER >= 1910 || \
+    (FMT_HAS_FEATURE(cxx_relaxed_constexpr) || FMT_MSC_VER >= 1912 || \
      (FMT_GCC_VERSION >= 600 && __cplusplus >= 201402L)) &&           \
         !FMT_NVCC && !FMT_ICC_VERSION
 #endif
 #if FMT_USE_CONSTEXPR
 #  define FMT_CONSTEXPR constexpr
 #  define FMT_CONSTEXPR_DECL constexpr
 #else
-#  define FMT_CONSTEXPR inline
+#  define FMT_CONSTEXPR
 #  define FMT_CONSTEXPR_DECL
 #endif
 
-#ifndef FMT_OVERRIDE
-#  if FMT_HAS_FEATURE(cxx_override_control) || \
-      (FMT_GCC_VERSION >= 408 && FMT_HAS_GXX_CXX11) || FMT_MSC_VER >= 1900
-#    define FMT_OVERRIDE override
-#  else
-#    define FMT_OVERRIDE
+#if ((__cplusplus >= 202002L) &&                              \
+     (!defined(_GLIBCXX_RELEASE) || _GLIBCXX_RELEASE > 9)) || \
+    (__cplusplus >= 201709L && FMT_GCC_VERSION >= 1002)
+#  define FMT_CONSTEXPR20 constexpr
+#else
+#  define FMT_CONSTEXPR20
+#endif
+
+// Check if constexpr std::char_traits<>::compare,length is supported.
+#if defined(__GLIBCXX__)
+#  if __cplusplus >= 201703L && defined(_GLIBCXX_RELEASE) && \
+      _GLIBCXX_RELEASE >= 7  // GCC 7+ libstdc++ has _GLIBCXX_RELEASE.
+#    define FMT_CONSTEXPR_CHAR_TRAITS constexpr
 #  endif
+#elif defined(_LIBCPP_VERSION) && __cplusplus >= 201703L && \
+    _LIBCPP_VERSION >= 4000
+#  define FMT_CONSTEXPR_CHAR_TRAITS constexpr
+#elif FMT_MSC_VER >= 1914 && _MSVC_LANG >= 201703L
+#  define FMT_CONSTEXPR_CHAR_TRAITS constexpr
+#endif
+#ifndef FMT_CONSTEXPR_CHAR_TRAITS
+#  define FMT_CONSTEXPR_CHAR_TRAITS
 #endif
 
 // Check if exceptions are disabled.
 #ifndef FMT_EXCEPTIONS
 #  if (defined(__GNUC__) && !defined(__EXCEPTIONS)) || \
       FMT_MSC_VER && !_HAS_EXCEPTIONS
 #    define FMT_EXCEPTIONS 0
@@ -120,15 +147,15 @@
 
 // Define FMT_USE_NOEXCEPT to make fmt use noexcept (C++11 feature).
 #ifndef FMT_USE_NOEXCEPT
 #  define FMT_USE_NOEXCEPT 0
 #endif
 
 #if FMT_USE_NOEXCEPT || FMT_HAS_FEATURE(cxx_noexcept) || \
-    (FMT_GCC_VERSION >= 408 && FMT_HAS_GXX_CXX11) || FMT_MSC_VER >= 1900
+    FMT_GCC_VERSION >= 408 || FMT_MSC_VER >= 1900
 #  define FMT_DETECTED_NOEXCEPT noexcept
 #  define FMT_HAS_CXX11_NOEXCEPT 1
 #else
 #  define FMT_DETECTED_NOEXCEPT throw()
 #  define FMT_HAS_CXX11_NOEXCEPT 0
 #endif
 
@@ -145,98 +172,106 @@
 #if FMT_EXCEPTIONS && FMT_HAS_CPP_ATTRIBUTE(noreturn) && !FMT_MSC_VER && \
     !FMT_NVCC
 #  define FMT_NORETURN [[noreturn]]
 #else
 #  define FMT_NORETURN
 #endif
 
-#ifndef FMT_DEPRECATED
-#  if FMT_HAS_CPP14_ATTRIBUTE(deprecated) || FMT_MSC_VER >= 1900
-#    define FMT_DEPRECATED [[deprecated]]
+#if __cplusplus == 201103L || __cplusplus == 201402L
+#  if defined(__INTEL_COMPILER) || defined(__PGI)
+#    define FMT_FALLTHROUGH
+#  elif defined(__clang__)
+#    define FMT_FALLTHROUGH [[clang::fallthrough]]
+#  elif FMT_GCC_VERSION >= 700 && \
+      (!defined(__EDG_VERSION__) || __EDG_VERSION__ >= 520)
+#    define FMT_FALLTHROUGH [[gnu::fallthrough]]
 #  else
-#    if (defined(__GNUC__) && !defined(__LCC__)) || defined(__clang__)
-#      define FMT_DEPRECATED __attribute__((deprecated))
-#    elif FMT_MSC_VER
-#      define FMT_DEPRECATED __declspec(deprecated)
-#    else
-#      define FMT_DEPRECATED /* deprecated */
-#    endif
+#    define FMT_FALLTHROUGH
 #  endif
+#elif FMT_HAS_CPP17_ATTRIBUTE(fallthrough)
+#  define FMT_FALLTHROUGH [[fallthrough]]
+#else
+#  define FMT_FALLTHROUGH
 #endif
 
-// Workaround broken [[deprecated]] in the Intel, PGI and NVCC compilers.
-#if FMT_ICC_VERSION || defined(__PGI) || FMT_NVCC
-#  define FMT_DEPRECATED_ALIAS
-#else
-#  define FMT_DEPRECATED_ALIAS FMT_DEPRECATED
+#ifndef FMT_NODISCARD
+#  if FMT_HAS_CPP17_ATTRIBUTE(nodiscard)
+#    define FMT_NODISCARD [[nodiscard]]
+#  else
+#    define FMT_NODISCARD
+#  endif
+#endif
+
+#ifndef FMT_USE_FLOAT
+#  define FMT_USE_FLOAT 1
+#endif
+#ifndef FMT_USE_DOUBLE
+#  define FMT_USE_DOUBLE 1
+#endif
+#ifndef FMT_USE_LONG_DOUBLE
+#  define FMT_USE_LONG_DOUBLE 1
 #endif
 
 #ifndef FMT_INLINE
 #  if FMT_GCC_VERSION || FMT_CLANG_VERSION
 #    define FMT_INLINE inline __attribute__((always_inline))
 #  else
 #    define FMT_INLINE inline
 #  endif
 #endif
 
-#ifndef FMT_USE_INLINE_NAMESPACES
-#  if FMT_HAS_FEATURE(cxx_inline_namespaces) || FMT_GCC_VERSION >= 404 || \
-      (FMT_MSC_VER >= 1900 && !_MANAGED)
-#    define FMT_USE_INLINE_NAMESPACES 1
+#ifndef FMT_DEPRECATED
+#  if FMT_HAS_CPP14_ATTRIBUTE(deprecated) || FMT_MSC_VER >= 1900
+#    define FMT_DEPRECATED [[deprecated]]
 #  else
-#    define FMT_USE_INLINE_NAMESPACES 0
+#    if (defined(__GNUC__) && !defined(__LCC__)) || defined(__clang__)
+#      define FMT_DEPRECATED __attribute__((deprecated))
+#    elif FMT_MSC_VER
+#      define FMT_DEPRECATED __declspec(deprecated)
+#    else
+#      define FMT_DEPRECATED /* deprecated */
+#    endif
 #  endif
 #endif
 
 #ifndef FMT_BEGIN_NAMESPACE
-#  if FMT_USE_INLINE_NAMESPACES
-#    define FMT_INLINE_NAMESPACE inline namespace
-#    define FMT_END_NAMESPACE \
-      }                       \
-      }
-#  else
-#    define FMT_INLINE_NAMESPACE namespace
-#    define FMT_END_NAMESPACE \
-      }                       \
-      using namespace v7;     \
-      }
-#  endif
 #  define FMT_BEGIN_NAMESPACE \
     namespace fmt {           \
-    FMT_INLINE_NAMESPACE v7 {
+    inline namespace v8 {
+#  define FMT_END_NAMESPACE \
+    }                       \
+    }
+#endif
+
+#ifndef FMT_MODULE_EXPORT
+#  define FMT_MODULE_EXPORT
+#  define FMT_MODULE_EXPORT_BEGIN
+#  define FMT_MODULE_EXPORT_END
+#  define FMT_BEGIN_DETAIL_NAMESPACE namespace detail {
+#  define FMT_END_DETAIL_NAMESPACE }
 #endif
 
 #if !defined(FMT_HEADER_ONLY) && defined(_WIN32)
-#  define FMT_CLASS_API FMT_SUPPRESS_MSC_WARNING(4275)
+#  define FMT_CLASS_API FMT_MSC_WARNING(suppress : 4275)
 #  ifdef FMT_EXPORT
 #    define FMT_API __declspec(dllexport)
-#    define FMT_EXTERN_TEMPLATE_API FMT_API
-#    define FMT_EXPORTED
 #  elif defined(FMT_SHARED)
 #    define FMT_API __declspec(dllimport)
-#    define FMT_EXTERN_TEMPLATE_API FMT_API
 #  endif
 #else
 #  define FMT_CLASS_API
+#  if defined(FMT_EXPORT) || defined(FMT_SHARED)
+#    if defined(__GNUC__) || defined(__clang__)
+#      define FMT_API __attribute__((visibility("default")))
+#    endif
+#  endif
 #endif
 #ifndef FMT_API
 #  define FMT_API
 #endif
-#ifndef FMT_EXTERN_TEMPLATE_API
-#  define FMT_EXTERN_TEMPLATE_API
-#endif
-#ifndef FMT_INSTANTIATION_DEF_API
-#  define FMT_INSTANTIATION_DEF_API FMT_API
-#endif
-
-#ifndef FMT_HEADER_ONLY
-#  define FMT_EXTERN extern
-#else
-#  define FMT_EXTERN
-#endif
 
 // libc++ supports string_view in pre-c++17.
 #if (FMT_HAS_INCLUDE(<string_view>) &&                       \
      (__cplusplus > 201402L || defined(_LIBCPP_VERSION))) || \
     (defined(_MSVC_LANG) && _MSVC_LANG > 201402L && _MSC_VER >= 1910)
 #  include <string_view>
 #  define FMT_USE_STRING_VIEW
@@ -244,62 +279,119 @@
 #  include <experimental/string_view>
 #  define FMT_USE_EXPERIMENTAL_STRING_VIEW
 #endif
 
 #ifndef FMT_UNICODE
 #  define FMT_UNICODE !FMT_MSC_VER
 #endif
-#if FMT_UNICODE && FMT_MSC_VER
-#  pragma execution_character_set("utf-8")
+
+#ifndef FMT_CONSTEVAL
+#  if ((FMT_GCC_VERSION >= 1000 || FMT_CLANG_VERSION >= 1101) &&      \
+       __cplusplus > 201703L && !defined(__apple_build_version__)) || \
+      (defined(__cpp_consteval) &&                                    \
+       (!FMT_MSC_VER || _MSC_FULL_VER >= 193030704))
+// consteval is broken in MSVC before VS2022 and Apple clang 13.
+#    define FMT_CONSTEVAL consteval
+#    define FMT_HAS_CONSTEVAL
+#  else
+#    define FMT_CONSTEVAL
+#  endif
+#endif
+
+#ifndef FMT_USE_NONTYPE_TEMPLATE_PARAMETERS
+#  if defined(__cpp_nontype_template_args) &&                \
+      ((FMT_GCC_VERSION >= 903 && __cplusplus >= 201709L) || \
+       __cpp_nontype_template_args >= 201911L)
+#    define FMT_USE_NONTYPE_TEMPLATE_PARAMETERS 1
+#  else
+#    define FMT_USE_NONTYPE_TEMPLATE_PARAMETERS 0
+#  endif
+#endif
+
+// Enable minimal optimizations for more compact code in debug mode.
+FMT_GCC_PRAGMA("GCC push_options")
+#ifndef __OPTIMIZE__
+FMT_GCC_PRAGMA("GCC optimize(\"Og\")")
 #endif
 
 FMT_BEGIN_NAMESPACE
+FMT_MODULE_EXPORT_BEGIN
 
 // Implementations of enable_if_t and other metafunctions for older systems.
-template <bool B, class T = void>
+template <bool B, typename T = void>
 using enable_if_t = typename std::enable_if<B, T>::type;
-template <bool B, class T, class F>
+template <bool B, typename T, typename F>
 using conditional_t = typename std::conditional<B, T, F>::type;
 template <bool B> using bool_constant = std::integral_constant<bool, B>;
 template <typename T>
 using remove_reference_t = typename std::remove_reference<T>::type;
 template <typename T>
 using remove_const_t = typename std::remove_const<T>::type;
 template <typename T>
 using remove_cvref_t = typename std::remove_cv<remove_reference_t<T>>::type;
 template <typename T> struct type_identity { using type = T; };
 template <typename T> using type_identity_t = typename type_identity<T>::type;
 
-struct monostate {};
+struct monostate {
+  constexpr monostate() {}
+};
 
 // An enable_if helper to be used in template parameters which results in much
 // shorter symbols: https://godbolt.org/z/sWw4vP. Extra parentheses are needed
 // to workaround a bug in MSVC 2019 (see #1140 and #1186).
-#define FMT_ENABLE_IF(...) enable_if_t<(__VA_ARGS__), int> = 0
+#ifdef FMT_DOC
+#  define FMT_ENABLE_IF(...)
+#else
+#  define FMT_ENABLE_IF(...) enable_if_t<(__VA_ARGS__), int> = 0
+#endif
 
-namespace detail {
+FMT_BEGIN_DETAIL_NAMESPACE
 
-// A helper function to suppress "conditional expression is constant" warnings.
-template <typename T> constexpr T const_check(T value) { return value; }
+// Suppress "unused variable" warnings with the method described in
+// https://herbsutter.com/2009/10/18/mailbag-shutting-up-compiler-warnings/.
+// (void)var does not work on many Intel compilers.
+template <typename... T> FMT_CONSTEXPR void ignore_unused(const T&...) {}
+
+constexpr FMT_INLINE auto is_constant_evaluated(bool default_value = false)
+    FMT_NOEXCEPT -> bool {
+#ifdef __cpp_lib_is_constant_evaluated
+  ignore_unused(default_value);
+  return std::is_constant_evaluated();
+#else
+  return default_value;
+#endif
+}
+
+// A function to suppress "conditional expression is constant" warnings.
+template <typename T> constexpr FMT_INLINE auto const_check(T value) -> T {
+  return value;
+}
 
 FMT_NORETURN FMT_API void assert_fail(const char* file, int line,
                                       const char* message);
 
 #ifndef FMT_ASSERT
 #  ifdef NDEBUG
 // FMT_ASSERT is not empty to avoid -Werror=empty-body.
-#    define FMT_ASSERT(condition, message) ((void)0)
+#    define FMT_ASSERT(condition, message) \
+      ::fmt::detail::ignore_unused((condition), (message))
 #  else
 #    define FMT_ASSERT(condition, message)                                    \
       ((condition) /* void() fails with -Winvalid-constexpr on clang 4.0.1 */ \
            ? (void)0                                                          \
            : ::fmt::detail::assert_fail(__FILE__, __LINE__, (message)))
 #  endif
 #endif
 
+#ifdef __cpp_lib_byte
+using byte = std::byte;
+#else
+enum class byte : unsigned char {};
+#endif
+
 #if defined(FMT_USE_STRING_VIEW)
 template <typename Char> using std_string_view = std::basic_string_view<Char>;
 #elif defined(FMT_USE_EXPERIMENTAL_STRING_VIEW)
 template <typename Char>
 using std_string_view = std::experimental::basic_string_view<Char>;
 #else
 template <typename T> struct std_string_view {};
@@ -308,46 +400,47 @@
 #ifdef FMT_USE_INT128
 // Do nothing.
 #elif defined(__SIZEOF_INT128__) && !FMT_NVCC && \
     !(FMT_CLANG_VERSION && FMT_MSC_VER)
 #  define FMT_USE_INT128 1
 using int128_t = __int128_t;
 using uint128_t = __uint128_t;
+template <typename T> inline auto convert_for_visit(T value) -> T {
+  return value;
+}
 #else
 #  define FMT_USE_INT128 0
 #endif
 #if !FMT_USE_INT128
-struct int128_t {};
-struct uint128_t {};
+enum class int128_t {};
+enum class uint128_t {};
+// Reduce template instantiations.
+template <typename T> inline auto convert_for_visit(T) -> monostate {
+  return {};
+}
 #endif
 
 // Casts a nonnegative integer to unsigned.
 template <typename Int>
-FMT_CONSTEXPR typename std::make_unsigned<Int>::type to_unsigned(Int value) {
+FMT_CONSTEXPR auto to_unsigned(Int value) ->
+    typename std::make_unsigned<Int>::type {
   FMT_ASSERT(value >= 0, "negative value");
   return static_cast<typename std::make_unsigned<Int>::type>(value);
 }
 
-FMT_SUPPRESS_MSC_WARNING(4566) constexpr unsigned char micro[] = "\u00B5";
+FMT_MSC_WARNING(suppress : 4566) constexpr unsigned char micro[] = "\u00B5";
 
-template <typename Char> constexpr bool is_unicode() {
-  return FMT_UNICODE || sizeof(Char) != 1 ||
-         (sizeof(micro) == 3 && micro[0] == 0xC2 && micro[1] == 0xB5);
+constexpr auto is_utf8() -> bool {
+  // Avoid buggy sign extensions in MSVC's constant evaluation mode.
+  // https://developercommunity.visualstudio.com/t/C-difference-in-behavior-for-unsigned/1233612
+  using uchar = unsigned char;
+  return FMT_UNICODE || (sizeof(micro) == 3 && uchar(micro[0]) == 0xC2 &&
+                         uchar(micro[1]) == 0xB5);
 }
-
-#ifdef __cpp_char8_t
-using char8_type = char8_t;
-#else
-enum char8_type : unsigned char {};
-#endif
-}  // namespace detail
-
-#ifdef FMT_USE_INTERNAL
-namespace internal = detail;  // DEPRECATED
-#endif
+FMT_END_DETAIL_NAMESPACE
 
 /**
   An implementation of ``std::basic_string_view`` for pre-C++17. It provides a
   subset of the API. ``fmt::basic_string_view`` is used for format strings even
   if ``std::string_view`` is available to prevent issues when a library is
   compiled with a different ``-std`` option than the client code (which is not
   recommended).
@@ -370,141 +463,129 @@
 
   /**
     \rst
     Constructs a string reference object from a C string computing
     the size with ``std::char_traits<Char>::length``.
     \endrst
    */
-#if __cplusplus >= 201703L  // C++17's char_traits::length() is constexpr.
-  FMT_CONSTEXPR
-#endif
+  FMT_CONSTEXPR_CHAR_TRAITS
+  FMT_INLINE
   basic_string_view(const Char* s)
-      : data_(s), size_(std::char_traits<Char>::length(s)) {}
+      : data_(s),
+        size_(detail::const_check(std::is_same<Char, char>::value &&
+                                  !detail::is_constant_evaluated(true))
+                  ? std::strlen(reinterpret_cast<const char*>(s))
+                  : std::char_traits<Char>::length(s)) {}
 
   /** Constructs a string reference from a ``std::basic_string`` object. */
   template <typename Traits, typename Alloc>
   FMT_CONSTEXPR basic_string_view(
       const std::basic_string<Char, Traits, Alloc>& s) FMT_NOEXCEPT
       : data_(s.data()),
         size_(s.size()) {}
 
   template <typename S, FMT_ENABLE_IF(std::is_same<
                                       S, detail::std_string_view<Char>>::value)>
   FMT_CONSTEXPR basic_string_view(S s) FMT_NOEXCEPT : data_(s.data()),
                                                       size_(s.size()) {}
 
   /** Returns a pointer to the string data. */
-  constexpr const Char* data() const { return data_; }
+  constexpr auto data() const FMT_NOEXCEPT -> const Char* { return data_; }
 
   /** Returns the string size. */
-  constexpr size_t size() const { return size_; }
+  constexpr auto size() const FMT_NOEXCEPT -> size_t { return size_; }
 
-  constexpr iterator begin() const { return data_; }
-  constexpr iterator end() const { return data_ + size_; }
+  constexpr auto begin() const FMT_NOEXCEPT -> iterator { return data_; }
+  constexpr auto end() const FMT_NOEXCEPT -> iterator { return data_ + size_; }
 
-  constexpr const Char& operator[](size_t pos) const { return data_[pos]; }
+  constexpr auto operator[](size_t pos) const FMT_NOEXCEPT -> const Char& {
+    return data_[pos];
+  }
 
-  FMT_CONSTEXPR void remove_prefix(size_t n) {
+  FMT_CONSTEXPR void remove_prefix(size_t n) FMT_NOEXCEPT {
     data_ += n;
     size_ -= n;
   }
 
   // Lexicographically compare this string reference to other.
-  int compare(basic_string_view other) const {
+  FMT_CONSTEXPR_CHAR_TRAITS auto compare(basic_string_view other) const -> int {
     size_t str_size = size_ < other.size_ ? size_ : other.size_;
     int result = std::char_traits<Char>::compare(data_, other.data_, str_size);
     if (result == 0)
       result = size_ == other.size_ ? 0 : (size_ < other.size_ ? -1 : 1);
     return result;
   }
 
-  friend bool operator==(basic_string_view lhs, basic_string_view rhs) {
+  FMT_CONSTEXPR_CHAR_TRAITS friend auto operator==(basic_string_view lhs,
+                                                   basic_string_view rhs)
+      -> bool {
     return lhs.compare(rhs) == 0;
   }
-  friend bool operator!=(basic_string_view lhs, basic_string_view rhs) {
+  friend auto operator!=(basic_string_view lhs, basic_string_view rhs) -> bool {
     return lhs.compare(rhs) != 0;
   }
-  friend bool operator<(basic_string_view lhs, basic_string_view rhs) {
+  friend auto operator<(basic_string_view lhs, basic_string_view rhs) -> bool {
     return lhs.compare(rhs) < 0;
   }
-  friend bool operator<=(basic_string_view lhs, basic_string_view rhs) {
+  friend auto operator<=(basic_string_view lhs, basic_string_view rhs) -> bool {
     return lhs.compare(rhs) <= 0;
   }
-  friend bool operator>(basic_string_view lhs, basic_string_view rhs) {
+  friend auto operator>(basic_string_view lhs, basic_string_view rhs) -> bool {
     return lhs.compare(rhs) > 0;
   }
-  friend bool operator>=(basic_string_view lhs, basic_string_view rhs) {
+  friend auto operator>=(basic_string_view lhs, basic_string_view rhs) -> bool {
     return lhs.compare(rhs) >= 0;
   }
 };
 
 using string_view = basic_string_view<char>;
-using wstring_view = basic_string_view<wchar_t>;
 
 /** Specifies if ``T`` is a character type. Can be specialized by users. */
 template <typename T> struct is_char : std::false_type {};
 template <> struct is_char<char> : std::true_type {};
-template <> struct is_char<wchar_t> : std::true_type {};
-template <> struct is_char<detail::char8_type> : std::true_type {};
-template <> struct is_char<char16_t> : std::true_type {};
-template <> struct is_char<char32_t> : std::true_type {};
 
-/**
-  \rst
-  Returns a string view of `s`. In order to add custom string type support to
-  {fmt} provide an overload of `to_string_view` for it in the same namespace as
-  the type for the argument-dependent lookup to work.
-
-  **Example**::
-
-    namespace my_ns {
-    inline string_view to_string_view(const my_string& s) {
-      return {s.data(), s.length()};
-    }
-    }
-    std::string message = fmt::format(my_string("The answer is {}"), 42);
-  \endrst
- */
+// Returns a string view of `s`.
 template <typename Char, FMT_ENABLE_IF(is_char<Char>::value)>
-inline basic_string_view<Char> to_string_view(const Char* s) {
+FMT_INLINE auto to_string_view(const Char* s) -> basic_string_view<Char> {
   return s;
 }
-
 template <typename Char, typename Traits, typename Alloc>
-inline basic_string_view<Char> to_string_view(
-    const std::basic_string<Char, Traits, Alloc>& s) {
+inline auto to_string_view(const std::basic_string<Char, Traits, Alloc>& s)
+    -> basic_string_view<Char> {
   return s;
 }
-
 template <typename Char>
-inline basic_string_view<Char> to_string_view(basic_string_view<Char> s) {
+constexpr auto to_string_view(basic_string_view<Char> s)
+    -> basic_string_view<Char> {
   return s;
 }
-
 template <typename Char,
           FMT_ENABLE_IF(!std::is_empty<detail::std_string_view<Char>>::value)>
-inline basic_string_view<Char> to_string_view(detail::std_string_view<Char> s) {
+inline auto to_string_view(detail::std_string_view<Char> s)
+    -> basic_string_view<Char> {
   return s;
 }
 
 // A base class for compile-time strings. It is defined in the fmt namespace to
 // make formatting functions visible via ADL, e.g. format(FMT_STRING("{}"), 42).
 struct compile_string {};
 
 template <typename S>
 struct is_compile_string : std::is_base_of<compile_string, S> {};
 
 template <typename S, FMT_ENABLE_IF(is_compile_string<S>::value)>
-constexpr basic_string_view<typename S::char_type> to_string_view(const S& s) {
-  return s;
+constexpr auto to_string_view(const S& s)
+    -> basic_string_view<typename S::char_type> {
+  return basic_string_view<typename S::char_type>(s);
 }
 
-namespace detail {
+FMT_BEGIN_DETAIL_NAMESPACE
+
 void to_string_view(...);
-using fmt::v7::to_string_view;
+using fmt::to_string_view;
 
 // Specifies whether S is a string type convertible to fmt::basic_string_view.
 // It should be a constexpr function but MSVC 2017 fails to compile it in
 // enable_if and MSVC 2015 fails to compile it as an alias template.
 template <typename S>
 struct is_string : std::is_class<decltype(to_string_view(std::declval<S>()))> {
 };
@@ -523,40 +604,33 @@
                 "FMT_ENFORCE_COMPILE_STRING requires all format strings to use "
                 "FMT_STRING.");
 #endif
 }
 template <typename..., typename S, FMT_ENABLE_IF(is_compile_string<S>::value)>
 void check_format_string(S);
 
+FMT_NORETURN FMT_API void throw_format_error(const char* message);
+
 struct error_handler {
   constexpr error_handler() = default;
   constexpr error_handler(const error_handler&) = default;
 
   // This function is intentionally not constexpr to give a compile-time error.
   FMT_NORETURN FMT_API void on_error(const char* message);
 };
-}  // namespace detail
+FMT_END_DETAIL_NAMESPACE
 
 /** String's character type. */
 template <typename S> using char_t = typename detail::char_t_impl<S>::type;
 
 /**
   \rst
   Parsing context consisting of a format string range being parsed and an
   argument counter for automatic indexing.
-
-  You can use one of the following type aliases for common character types:
-
-  +-----------------------+-------------------------------------+
-  | Type                  | Definition                          |
-  +=======================+=====================================+
-  | format_parse_context  | basic_format_parse_context<char>    |
-  +-----------------------+-------------------------------------+
-  | wformat_parse_context | basic_format_parse_context<wchar_t> |
-  +-----------------------+-------------------------------------+
+  You can use the ``format_parse_context`` type alias for ``char`` instead.
   \endrst
  */
 template <typename Char, typename ErrorHandler = detail::error_handler>
 class basic_format_parse_context : private ErrorHandler {
  private:
   basic_string_view<Char> format_str_;
   int next_arg_id_;
@@ -570,31 +644,35 @@
       int next_arg_id = 0)
       : ErrorHandler(eh), format_str_(format_str), next_arg_id_(next_arg_id) {}
 
   /**
     Returns an iterator to the beginning of the format string range being
     parsed.
    */
-  constexpr iterator begin() const FMT_NOEXCEPT { return format_str_.begin(); }
+  constexpr auto begin() const FMT_NOEXCEPT -> iterator {
+    return format_str_.begin();
+  }
 
   /**
     Returns an iterator past the end of the format string range being parsed.
    */
-  constexpr iterator end() const FMT_NOEXCEPT { return format_str_.end(); }
+  constexpr auto end() const FMT_NOEXCEPT -> iterator {
+    return format_str_.end();
+  }
 
   /** Advances the begin iterator to ``it``. */
   FMT_CONSTEXPR void advance_to(iterator it) {
     format_str_.remove_prefix(detail::to_unsigned(it - begin()));
   }
 
   /**
     Reports an error if using the manual argument indexing; otherwise returns
     the next argument index and switches to the automatic indexing.
    */
-  FMT_CONSTEXPR int next_arg_id() {
+  FMT_CONSTEXPR auto next_arg_id() -> int {
     // Don't check if the argument id is valid to avoid overhead and because it
     // will be checked during formatting anyway.
     if (next_arg_id_ >= 0) return next_arg_id_++;
     on_error("cannot switch from manual to automatic argument indexing");
     return 0;
   }
 
@@ -611,19 +689,18 @@
 
   FMT_CONSTEXPR void check_arg_id(basic_string_view<Char>) {}
 
   FMT_CONSTEXPR void on_error(const char* message) {
     ErrorHandler::on_error(message);
   }
 
-  constexpr ErrorHandler error_handler() const { return *this; }
+  constexpr auto error_handler() const -> ErrorHandler { return *this; }
 };
 
 using format_parse_context = basic_format_parse_context<char>;
-using wformat_parse_context = basic_format_parse_context<wchar_t>;
 
 template <typename Context> class basic_format_arg;
 template <typename Context> class basic_format_args;
 template <typename Context> class dynamic_format_arg_store;
 
 // A formatter for objects of type T.
 template <typename T, typename Char = char, typename Enable = void>
@@ -639,272 +716,339 @@
     std::is_constructible<typename Context::template formatter_type<T>>;
 
 // Checks whether T is a container with contiguous storage.
 template <typename T> struct is_contiguous : std::false_type {};
 template <typename Char>
 struct is_contiguous<std::basic_string<Char>> : std::true_type {};
 
-namespace detail {
+class appender;
+
+FMT_BEGIN_DETAIL_NAMESPACE
+
+template <typename Context, typename T>
+constexpr auto has_const_formatter_impl(T*)
+    -> decltype(typename Context::template formatter_type<T>().format(
+                    std::declval<const T&>(), std::declval<Context&>()),
+                true) {
+  return true;
+}
+template <typename Context>
+constexpr auto has_const_formatter_impl(...) -> bool {
+  return false;
+}
+template <typename T, typename Context>
+constexpr auto has_const_formatter() -> bool {
+  return has_const_formatter_impl<Context>(static_cast<T*>(nullptr));
+}
 
 // Extracts a reference to the container from back_insert_iterator.
 template <typename Container>
-inline Container& get_container(std::back_insert_iterator<Container> it) {
+inline auto get_container(std::back_insert_iterator<Container> it)
+    -> Container& {
   using bi_iterator = std::back_insert_iterator<Container>;
   struct accessor : bi_iterator {
     accessor(bi_iterator iter) : bi_iterator(iter) {}
     using bi_iterator::container;
   };
   return *accessor(it).container;
 }
 
+template <typename Char, typename InputIt, typename OutputIt>
+FMT_CONSTEXPR auto copy_str(InputIt begin, InputIt end, OutputIt out)
+    -> OutputIt {
+  while (begin != end) *out++ = static_cast<Char>(*begin++);
+  return out;
+}
+
+template <typename Char, typename T, typename U,
+          FMT_ENABLE_IF(
+              std::is_same<remove_const_t<T>, U>::value&& is_char<U>::value)>
+FMT_CONSTEXPR auto copy_str(T* begin, T* end, U* out) -> U* {
+  if (is_constant_evaluated()) return copy_str<Char, T*, U*>(begin, end, out);
+  auto size = to_unsigned(end - begin);
+  memcpy(out, begin, size * sizeof(U));
+  return out + size;
+}
+
 /**
   \rst
   A contiguous memory buffer with an optional growing ability. It is an internal
   class and shouldn't be used directly, only via `~fmt::basic_memory_buffer`.
   \endrst
  */
 template <typename T> class buffer {
  private:
   T* ptr_;
   size_t size_;
   size_t capacity_;
 
  protected:
   // Don't initialize ptr_ since it is not accessed to save a few cycles.
-  FMT_SUPPRESS_MSC_WARNING(26495)
+  FMT_MSC_WARNING(suppress : 26495)
   buffer(size_t sz) FMT_NOEXCEPT : size_(sz), capacity_(sz) {}
 
-  buffer(T* p = nullptr, size_t sz = 0, size_t cap = 0) FMT_NOEXCEPT
-      : ptr_(p),
-        size_(sz),
-        capacity_(cap) {}
+  FMT_CONSTEXPR20 buffer(T* p = nullptr, size_t sz = 0,
+                         size_t cap = 0) FMT_NOEXCEPT : ptr_(p),
+                                                        size_(sz),
+                                                        capacity_(cap) {}
 
-  ~buffer() = default;
+  FMT_CONSTEXPR20 ~buffer() = default;
+  buffer(buffer&&) = default;
 
   /** Sets the buffer data and capacity. */
-  void set(T* buf_data, size_t buf_capacity) FMT_NOEXCEPT {
+  FMT_CONSTEXPR void set(T* buf_data, size_t buf_capacity) FMT_NOEXCEPT {
     ptr_ = buf_data;
     capacity_ = buf_capacity;
   }
 
   /** Increases the buffer capacity to hold at least *capacity* elements. */
-  virtual void grow(size_t capacity) = 0;
+  virtual FMT_CONSTEXPR20 void grow(size_t capacity) = 0;
 
  public:
   using value_type = T;
   using const_reference = const T&;
 
   buffer(const buffer&) = delete;
   void operator=(const buffer&) = delete;
 
-  T* begin() FMT_NOEXCEPT { return ptr_; }
-  T* end() FMT_NOEXCEPT { return ptr_ + size_; }
+  auto begin() FMT_NOEXCEPT -> T* { return ptr_; }
+  auto end() FMT_NOEXCEPT -> T* { return ptr_ + size_; }
 
-  const T* begin() const FMT_NOEXCEPT { return ptr_; }
-  const T* end() const FMT_NOEXCEPT { return ptr_ + size_; }
+  auto begin() const FMT_NOEXCEPT -> const T* { return ptr_; }
+  auto end() const FMT_NOEXCEPT -> const T* { return ptr_ + size_; }
 
   /** Returns the size of this buffer. */
-  size_t size() const FMT_NOEXCEPT { return size_; }
+  constexpr auto size() const FMT_NOEXCEPT -> size_t { return size_; }
 
   /** Returns the capacity of this buffer. */
-  size_t capacity() const FMT_NOEXCEPT { return capacity_; }
+  constexpr auto capacity() const FMT_NOEXCEPT -> size_t { return capacity_; }
 
   /** Returns a pointer to the buffer data. */
-  T* data() FMT_NOEXCEPT { return ptr_; }
+  FMT_CONSTEXPR auto data() FMT_NOEXCEPT -> T* { return ptr_; }
 
   /** Returns a pointer to the buffer data. */
-  const T* data() const FMT_NOEXCEPT { return ptr_; }
+  FMT_CONSTEXPR auto data() const FMT_NOEXCEPT -> const T* { return ptr_; }
 
   /** Clears this buffer. */
   void clear() { size_ = 0; }
 
   // Tries resizing the buffer to contain *count* elements. If T is a POD type
   // the new elements may not be initialized.
-  void try_resize(size_t count) {
+  FMT_CONSTEXPR20 void try_resize(size_t count) {
     try_reserve(count);
     size_ = count <= capacity_ ? count : capacity_;
   }
 
   // Tries increasing the buffer capacity to *new_capacity*. It can increase the
   // capacity by a smaller amount than requested but guarantees there is space
   // for at least one additional element either by increasing the capacity or by
   // flushing the buffer if it is full.
-  void try_reserve(size_t new_capacity) {
+  FMT_CONSTEXPR20 void try_reserve(size_t new_capacity) {
     if (new_capacity > capacity_) grow(new_capacity);
   }
 
-  void push_back(const T& value) {
+  FMT_CONSTEXPR20 void push_back(const T& value) {
     try_reserve(size_ + 1);
     ptr_[size_++] = value;
   }
 
   /** Appends data to the end of the buffer. */
   template <typename U> void append(const U* begin, const U* end);
 
-  template <typename I> T& operator[](I index) { return ptr_[index]; }
-  template <typename I> const T& operator[](I index) const {
+  template <typename I> FMT_CONSTEXPR auto operator[](I index) -> T& {
+    return ptr_[index];
+  }
+  template <typename I>
+  FMT_CONSTEXPR auto operator[](I index) const -> const T& {
     return ptr_[index];
   }
 };
 
 struct buffer_traits {
   explicit buffer_traits(size_t) {}
-  size_t count() const { return 0; }
-  size_t limit(size_t size) { return size; }
+  auto count() const -> size_t { return 0; }
+  auto limit(size_t size) -> size_t { return size; }
 };
 
 class fixed_buffer_traits {
  private:
   size_t count_ = 0;
   size_t limit_;
 
  public:
   explicit fixed_buffer_traits(size_t limit) : limit_(limit) {}
-  size_t count() const { return count_; }
-  size_t limit(size_t size) {
-    size_t n = limit_ - count_;
+  auto count() const -> size_t { return count_; }
+  auto limit(size_t size) -> size_t {
+    size_t n = limit_ > count_ ? limit_ - count_ : 0;
     count_ += size;
     return size < n ? size : n;
   }
 };
 
 // A buffer that writes to an output iterator when flushed.
 template <typename OutputIt, typename T, typename Traits = buffer_traits>
 class iterator_buffer final : public Traits, public buffer<T> {
  private:
   OutputIt out_;
   enum { buffer_size = 256 };
   T data_[buffer_size];
 
  protected:
-  void grow(size_t) final FMT_OVERRIDE {
+  FMT_CONSTEXPR20 void grow(size_t) override {
     if (this->size() == buffer_size) flush();
   }
-  void flush();
+
+  void flush() {
+    auto size = this->size();
+    this->clear();
+    out_ = copy_str<T>(data_, data_ + this->limit(size), out_);
+  }
 
  public:
   explicit iterator_buffer(OutputIt out, size_t n = buffer_size)
-      : Traits(n),
-        buffer<T>(data_, 0, n < size_t(buffer_size) ? n : size_t(buffer_size)),
-        out_(out) {}
+      : Traits(n), buffer<T>(data_, 0, buffer_size), out_(out) {}
+  iterator_buffer(iterator_buffer&& other)
+      : Traits(other), buffer<T>(data_, 0, buffer_size), out_(other.out_) {}
   ~iterator_buffer() { flush(); }
 
-  OutputIt out() {
+  auto out() -> OutputIt {
     flush();
     return out_;
   }
-  size_t count() const { return Traits::count() + this->size(); }
+  auto count() const -> size_t { return Traits::count() + this->size(); }
+};
+
+template <typename T>
+class iterator_buffer<T*, T, fixed_buffer_traits> final
+    : public fixed_buffer_traits,
+      public buffer<T> {
+ private:
+  T* out_;
+  enum { buffer_size = 256 };
+  T data_[buffer_size];
+
+ protected:
+  FMT_CONSTEXPR20 void grow(size_t) override {
+    if (this->size() == this->capacity()) flush();
+  }
+
+  void flush() {
+    size_t n = this->limit(this->size());
+    if (this->data() == out_) {
+      out_ += n;
+      this->set(data_, buffer_size);
+    }
+    this->clear();
+  }
+
+ public:
+  explicit iterator_buffer(T* out, size_t n = buffer_size)
+      : fixed_buffer_traits(n), buffer<T>(out, 0, n), out_(out) {}
+  iterator_buffer(iterator_buffer&& other)
+      : fixed_buffer_traits(other),
+        buffer<T>(std::move(other)),
+        out_(other.out_) {
+    if (this->data() != out_) {
+      this->set(data_, buffer_size);
+      this->clear();
+    }
+  }
+  ~iterator_buffer() { flush(); }
+
+  auto out() -> T* {
+    flush();
+    return out_;
+  }
+  auto count() const -> size_t {
+    return fixed_buffer_traits::count() + this->size();
+  }
 };
 
 template <typename T> class iterator_buffer<T*, T> final : public buffer<T> {
  protected:
-  void grow(size_t) final FMT_OVERRIDE {}
+  FMT_CONSTEXPR20 void grow(size_t) override {}
 
  public:
   explicit iterator_buffer(T* out, size_t = 0) : buffer<T>(out, 0, ~size_t()) {}
 
-  T* out() { return &*this->end(); }
+  auto out() -> T* { return &*this->end(); }
 };
 
 // A buffer that writes to a container with the contiguous storage.
 template <typename Container>
 class iterator_buffer<std::back_insert_iterator<Container>,
                       enable_if_t<is_contiguous<Container>::value,
                                   typename Container::value_type>>
     final : public buffer<typename Container::value_type> {
  private:
   Container& container_;
 
  protected:
-  void grow(size_t capacity) final FMT_OVERRIDE {
+  FMT_CONSTEXPR20 void grow(size_t capacity) override {
     container_.resize(capacity);
     this->set(&container_[0], capacity);
   }
 
  public:
   explicit iterator_buffer(Container& c)
       : buffer<typename Container::value_type>(c.size()), container_(c) {}
   explicit iterator_buffer(std::back_insert_iterator<Container> out, size_t = 0)
       : iterator_buffer(get_container(out)) {}
-  std::back_insert_iterator<Container> out() {
+  auto out() -> std::back_insert_iterator<Container> {
     return std::back_inserter(container_);
   }
 };
 
 // A buffer that counts the number of code units written discarding the output.
 template <typename T = char> class counting_buffer final : public buffer<T> {
  private:
   enum { buffer_size = 256 };
   T data_[buffer_size];
   size_t count_ = 0;
 
  protected:
-  void grow(size_t) final FMT_OVERRIDE {
+  FMT_CONSTEXPR20 void grow(size_t) override {
     if (this->size() != buffer_size) return;
     count_ += this->size();
     this->clear();
   }
 
  public:
   counting_buffer() : buffer<T>(data_, 0, buffer_size) {}
 
-  size_t count() { return count_ + this->size(); }
+  auto count() -> size_t { return count_ + this->size(); }
 };
 
-// An output iterator that appends to the buffer.
-// It is used to reduce symbol sizes for the common case.
 template <typename T>
-class buffer_appender : public std::back_insert_iterator<buffer<T>> {
-  using base = std::back_insert_iterator<buffer<T>>;
-
- public:
-  explicit buffer_appender(buffer<T>& buf) : base(buf) {}
-  buffer_appender(base it) : base(it) {}
-
-  buffer_appender& operator++() {
-    base::operator++();
-    return *this;
-  }
-
-  buffer_appender operator++(int) {
-    buffer_appender tmp = *this;
-    ++*this;
-    return tmp;
-  }
-};
+using buffer_appender = conditional_t<std::is_same<T, char>::value, appender,
+                                      std::back_insert_iterator<buffer<T>>>;
 
-// Maps an output iterator into a buffer.
+// Maps an output iterator to a buffer.
 template <typename T, typename OutputIt>
-iterator_buffer<OutputIt, T> get_buffer(OutputIt);
-template <typename T> buffer<T>& get_buffer(buffer_appender<T>);
-
-template <typename OutputIt> OutputIt get_buffer_init(OutputIt out) {
-  return out;
-}
-template <typename T> buffer<T>& get_buffer_init(buffer_appender<T> out) {
-  return get_container(out);
+auto get_buffer(OutputIt out) -> iterator_buffer<OutputIt, T> {
+  return iterator_buffer<OutputIt, T>(out);
 }
 
 template <typename Buffer>
 auto get_iterator(Buffer& buf) -> decltype(buf.out()) {
   return buf.out();
 }
-template <typename T> buffer_appender<T> get_iterator(buffer<T>& buf) {
+template <typename T> auto get_iterator(buffer<T>& buf) -> buffer_appender<T> {
   return buffer_appender<T>(buf);
 }
 
 template <typename T, typename Char = char, typename Enable = void>
 struct fallback_formatter {
   fallback_formatter() = delete;
 };
 
 // Specifies if T has an enabled fallback_formatter specialization.
-template <typename T, typename Context>
+template <typename T, typename Char>
 using has_fallback_formatter =
-    std::is_constructible<fallback_formatter<T, typename Context::char_type>>;
+    std::is_constructible<fallback_formatter<T, Char>>;
 
 struct view {};
 
 template <typename Char, typename T> struct named_arg : view {
   const Char* name;
   const T& value;
   named_arg(const Char* n, const T& v) : name(n), value(v) {}
@@ -921,63 +1065,73 @@
   // +1 to workaround a bug in gcc 7.5 that causes duplicated-branches warning.
   T args_[1 + (NUM_ARGS != 0 ? NUM_ARGS : +1)];
   named_arg_info<Char> named_args_[NUM_NAMED_ARGS];
 
   template <typename... U>
   arg_data(const U&... init) : args_{T(named_args_, NUM_NAMED_ARGS), init...} {}
   arg_data(const arg_data& other) = delete;
-  const T* args() const { return args_ + 1; }
-  named_arg_info<Char>* named_args() { return named_args_; }
+  auto args() const -> const T* { return args_ + 1; }
+  auto named_args() -> named_arg_info<Char>* { return named_args_; }
 };
 
 template <typename T, typename Char, size_t NUM_ARGS>
 struct arg_data<T, Char, NUM_ARGS, 0> {
   // +1 to workaround a bug in gcc 7.5 that causes duplicated-branches warning.
   T args_[NUM_ARGS != 0 ? NUM_ARGS : +1];
 
   template <typename... U>
-  FMT_INLINE arg_data(const U&... init) : args_{init...} {}
-  FMT_INLINE const T* args() const { return args_; }
-  FMT_INLINE std::nullptr_t named_args() { return nullptr; }
+  FMT_CONSTEXPR FMT_INLINE arg_data(const U&... init) : args_{init...} {}
+  FMT_CONSTEXPR FMT_INLINE auto args() const -> const T* { return args_; }
+  FMT_CONSTEXPR FMT_INLINE auto named_args() -> std::nullptr_t {
+    return nullptr;
+  }
 };
 
 template <typename Char>
 inline void init_named_args(named_arg_info<Char>*, int, int) {}
 
-template <typename Char, typename T, typename... Tail>
+template <typename T> struct is_named_arg : std::false_type {};
+template <typename T> struct is_statically_named_arg : std::false_type {};
+
+template <typename T, typename Char>
+struct is_named_arg<named_arg<Char, T>> : std::true_type {};
+
+template <typename Char, typename T, typename... Tail,
+          FMT_ENABLE_IF(!is_named_arg<T>::value)>
 void init_named_args(named_arg_info<Char>* named_args, int arg_count,
                      int named_arg_count, const T&, const Tail&... args) {
   init_named_args(named_args, arg_count + 1, named_arg_count, args...);
 }
 
-template <typename Char, typename T, typename... Tail>
+template <typename Char, typename T, typename... Tail,
+          FMT_ENABLE_IF(is_named_arg<T>::value)>
 void init_named_args(named_arg_info<Char>* named_args, int arg_count,
-                     int named_arg_count, const named_arg<Char, T>& arg,
-                     const Tail&... args) {
+                     int named_arg_count, const T& arg, const Tail&... args) {
   named_args[named_arg_count++] = {arg.name, arg_count};
   init_named_args(named_args, arg_count + 1, named_arg_count, args...);
 }
 
 template <typename... Args>
-FMT_INLINE void init_named_args(std::nullptr_t, int, int, const Args&...) {}
-
-template <typename T> struct is_named_arg : std::false_type {};
-
-template <typename T, typename Char>
-struct is_named_arg<named_arg<Char, T>> : std::true_type {};
+FMT_CONSTEXPR FMT_INLINE void init_named_args(std::nullptr_t, int, int,
+                                              const Args&...) {}
 
-template <bool B = false> constexpr size_t count() { return B ? 1 : 0; }
-template <bool B1, bool B2, bool... Tail> constexpr size_t count() {
+template <bool B = false> constexpr auto count() -> size_t { return B ? 1 : 0; }
+template <bool B1, bool B2, bool... Tail> constexpr auto count() -> size_t {
   return (B1 ? 1 : 0) + count<B2, Tail...>();
 }
 
-template <typename... Args> constexpr size_t count_named_args() {
+template <typename... Args> constexpr auto count_named_args() -> size_t {
   return count<is_named_arg<Args>::value...>();
 }
 
+template <typename... Args>
+constexpr auto count_statically_named_args() -> size_t {
+  return count<is_statically_named_arg<Args>::value...>();
+}
+
 enum class type {
   none_type,
   // Integer types should go first,
   int_type,
   uint_type,
   long_long_type,
   ulong_long_type,
@@ -1025,36 +1179,42 @@
   return t > type::none_type && t <= type::last_integer_type;
 }
 
 constexpr bool is_arithmetic_type(type t) {
   return t > type::none_type && t <= type::last_numeric_type;
 }
 
+struct unformattable {};
+struct unformattable_char : unformattable {};
+struct unformattable_const : unformattable {};
+struct unformattable_pointer : unformattable {};
+
 template <typename Char> struct string_value {
   const Char* data;
   size_t size;
 };
 
 template <typename Char> struct named_arg_value {
   const named_arg_info<Char>* data;
   size_t size;
 };
 
 template <typename Context> struct custom_value {
   using parse_context = typename Context::parse_context_type;
-  const void* value;
-  void (*format)(const void* arg, parse_context& parse_ctx, Context& ctx);
+  void* value;
+  void (*format)(void* arg, parse_context& parse_ctx, Context& ctx);
 };
 
 // A formatting argument value.
 template <typename Context> class value {
  public:
   using char_type = typename Context::char_type;
 
   union {
+    monostate no_value;
     int int_value;
     unsigned uint_value;
     long long long_long_value;
     unsigned long long ulong_long_value;
     int128_t int128_value;
     uint128_t uint128_value;
     bool bool_value;
@@ -1064,202 +1224,317 @@
     long double long_double_value;
     const void* pointer;
     string_value<char_type> string;
     custom_value<Context> custom;
     named_arg_value<char_type> named_args;
   };
 
-  constexpr FMT_INLINE value(int val = 0) : int_value(val) {}
+  constexpr FMT_INLINE value() : no_value() {}
+  constexpr FMT_INLINE value(int val) : int_value(val) {}
   constexpr FMT_INLINE value(unsigned val) : uint_value(val) {}
-  FMT_INLINE value(long long val) : long_long_value(val) {}
-  FMT_INLINE value(unsigned long long val) : ulong_long_value(val) {}
+  constexpr FMT_INLINE value(long long val) : long_long_value(val) {}
+  constexpr FMT_INLINE value(unsigned long long val) : ulong_long_value(val) {}
   FMT_INLINE value(int128_t val) : int128_value(val) {}
   FMT_INLINE value(uint128_t val) : uint128_value(val) {}
-  FMT_INLINE value(float val) : float_value(val) {}
-  FMT_INLINE value(double val) : double_value(val) {}
+  constexpr FMT_INLINE value(float val) : float_value(val) {}
+  constexpr FMT_INLINE value(double val) : double_value(val) {}
   FMT_INLINE value(long double val) : long_double_value(val) {}
-  FMT_INLINE value(bool val) : bool_value(val) {}
-  FMT_INLINE value(char_type val) : char_value(val) {}
-  FMT_INLINE value(const char_type* val) { string.data = val; }
-  FMT_INLINE value(basic_string_view<char_type> val) {
+  constexpr FMT_INLINE value(bool val) : bool_value(val) {}
+  constexpr FMT_INLINE value(char_type val) : char_value(val) {}
+  FMT_CONSTEXPR FMT_INLINE value(const char_type* val) {
+    string.data = val;
+    if (is_constant_evaluated()) string.size = {};
+  }
+  FMT_CONSTEXPR FMT_INLINE value(basic_string_view<char_type> val) {
     string.data = val.data();
     string.size = val.size();
   }
   FMT_INLINE value(const void* val) : pointer(val) {}
   FMT_INLINE value(const named_arg_info<char_type>* args, size_t size)
       : named_args{args, size} {}
 
-  template <typename T> FMT_INLINE value(const T& val) {
-    custom.value = &val;
+  template <typename T> FMT_CONSTEXPR FMT_INLINE value(T& val) {
+    using value_type = remove_cvref_t<T>;
+    custom.value = const_cast<value_type*>(&val);
     // Get the formatter type through the context to allow different contexts
     // have different extension points, e.g. `formatter<T>` for `format` and
     // `printf_formatter<T>` for `printf`.
     custom.format = format_custom_arg<
-        T, conditional_t<has_formatter<T, Context>::value,
-                         typename Context::template formatter_type<T>,
-                         fallback_formatter<T, char_type>>>;
-  }
+        value_type,
+        conditional_t<has_formatter<value_type, Context>::value,
+                      typename Context::template formatter_type<value_type>,
+                      fallback_formatter<value_type, char_type>>>;
+  }
+  value(unformattable);
+  value(unformattable_char);
+  value(unformattable_const);
+  value(unformattable_pointer);
 
  private:
   // Formats an argument of a custom type, such as a user-defined class.
   template <typename T, typename Formatter>
-  static void format_custom_arg(const void* arg,
+  static void format_custom_arg(void* arg,
                                 typename Context::parse_context_type& parse_ctx,
                                 Context& ctx) {
-    Formatter f;
+    auto f = Formatter();
     parse_ctx.advance_to(f.parse(parse_ctx));
-    ctx.advance_to(f.format(*static_cast<const T*>(arg), ctx));
+    using qualified_type =
+        conditional_t<has_const_formatter<T, Context>(), const T, T>;
+    ctx.advance_to(f.format(*static_cast<qualified_type*>(arg), ctx));
   }
 };
 
 template <typename Context, typename T>
-FMT_CONSTEXPR basic_format_arg<Context> make_arg(const T& value);
+FMT_CONSTEXPR auto make_arg(const T& value) -> basic_format_arg<Context>;
 
 // To minimize the number of types we need to deal with, long is translated
 // either to int or to long long depending on its size.
 enum { long_short = sizeof(long) == sizeof(int) };
 using long_type = conditional_t<long_short, int, long long>;
 using ulong_type = conditional_t<long_short, unsigned, unsigned long long>;
 
-struct unformattable {};
-
 // Maps formatting arguments to core types.
+// arg_mapper reports errors by returning unformattable instead of using
+// static_assert because it's used in the is_formattable trait.
 template <typename Context> struct arg_mapper {
   using char_type = typename Context::char_type;
 
-  FMT_CONSTEXPR int map(signed char val) { return val; }
-  FMT_CONSTEXPR unsigned map(unsigned char val) { return val; }
-  FMT_CONSTEXPR int map(short val) { return val; }
-  FMT_CONSTEXPR unsigned map(unsigned short val) { return val; }
-  FMT_CONSTEXPR int map(int val) { return val; }
-  FMT_CONSTEXPR unsigned map(unsigned val) { return val; }
-  FMT_CONSTEXPR long_type map(long val) { return val; }
-  FMT_CONSTEXPR ulong_type map(unsigned long val) { return val; }
-  FMT_CONSTEXPR long long map(long long val) { return val; }
-  FMT_CONSTEXPR unsigned long long map(unsigned long long val) { return val; }
-  FMT_CONSTEXPR int128_t map(int128_t val) { return val; }
-  FMT_CONSTEXPR uint128_t map(uint128_t val) { return val; }
-  FMT_CONSTEXPR bool map(bool val) { return val; }
+  FMT_CONSTEXPR FMT_INLINE auto map(signed char val) -> int { return val; }
+  FMT_CONSTEXPR FMT_INLINE auto map(unsigned char val) -> unsigned {
+    return val;
+  }
+  FMT_CONSTEXPR FMT_INLINE auto map(short val) -> int { return val; }
+  FMT_CONSTEXPR FMT_INLINE auto map(unsigned short val) -> unsigned {
+    return val;
+  }
+  FMT_CONSTEXPR FMT_INLINE auto map(int val) -> int { return val; }
+  FMT_CONSTEXPR FMT_INLINE auto map(unsigned val) -> unsigned { return val; }
+  FMT_CONSTEXPR FMT_INLINE auto map(long val) -> long_type { return val; }
+  FMT_CONSTEXPR FMT_INLINE auto map(unsigned long val) -> ulong_type {
+    return val;
+  }
+  FMT_CONSTEXPR FMT_INLINE auto map(long long val) -> long long { return val; }
+  FMT_CONSTEXPR FMT_INLINE auto map(unsigned long long val)
+      -> unsigned long long {
+    return val;
+  }
+  FMT_CONSTEXPR FMT_INLINE auto map(int128_t val) -> int128_t { return val; }
+  FMT_CONSTEXPR FMT_INLINE auto map(uint128_t val) -> uint128_t { return val; }
+  FMT_CONSTEXPR FMT_INLINE auto map(bool val) -> bool { return val; }
+
+  template <typename T, FMT_ENABLE_IF(std::is_same<T, char>::value ||
+                                      std::is_same<T, char_type>::value)>
+  FMT_CONSTEXPR FMT_INLINE auto map(T val) -> char_type {
+    return val;
+  }
+  template <typename T, enable_if_t<(std::is_same<T, wchar_t>::value ||
+#ifdef __cpp_char8_t
+                                     std::is_same<T, char8_t>::value ||
+#endif
+                                     std::is_same<T, char16_t>::value ||
+                                     std::is_same<T, char32_t>::value) &&
+                                        !std::is_same<T, char_type>::value,
+                                    int> = 0>
+  FMT_CONSTEXPR FMT_INLINE auto map(T) -> unformattable_char {
+    return {};
+  }
 
-  template <typename T, FMT_ENABLE_IF(is_char<T>::value)>
-  FMT_CONSTEXPR char_type map(T val) {
-    static_assert(
-        std::is_same<T, char>::value || std::is_same<T, char_type>::value,
-        "mixing character types is disallowed");
+  FMT_CONSTEXPR FMT_INLINE auto map(float val) -> float { return val; }
+  FMT_CONSTEXPR FMT_INLINE auto map(double val) -> double { return val; }
+  FMT_CONSTEXPR FMT_INLINE auto map(long double val) -> long double {
     return val;
   }
 
-  FMT_CONSTEXPR float map(float val) { return val; }
-  FMT_CONSTEXPR double map(double val) { return val; }
-  FMT_CONSTEXPR long double map(long double val) { return val; }
-
-  FMT_CONSTEXPR const char_type* map(char_type* val) { return val; }
-  FMT_CONSTEXPR const char_type* map(const char_type* val) { return val; }
-  template <typename T, FMT_ENABLE_IF(is_string<T>::value)>
-  FMT_CONSTEXPR basic_string_view<char_type> map(const T& val) {
-    static_assert(std::is_same<char_type, char_t<T>>::value,
-                  "mixing character types is disallowed");
+  FMT_CONSTEXPR FMT_INLINE auto map(char_type* val) -> const char_type* {
+    return val;
+  }
+  FMT_CONSTEXPR FMT_INLINE auto map(const char_type* val) -> const char_type* {
+    return val;
+  }
+  template <typename T,
+            FMT_ENABLE_IF(is_string<T>::value && !std::is_pointer<T>::value &&
+                          std::is_same<char_type, char_t<T>>::value)>
+  FMT_CONSTEXPR FMT_INLINE auto map(const T& val)
+      -> basic_string_view<char_type> {
     return to_string_view(val);
   }
   template <typename T,
+            FMT_ENABLE_IF(is_string<T>::value && !std::is_pointer<T>::value &&
+                          !std::is_same<char_type, char_t<T>>::value)>
+  FMT_CONSTEXPR FMT_INLINE auto map(const T&) -> unformattable_char {
+    return {};
+  }
+  template <typename T,
             FMT_ENABLE_IF(
                 std::is_constructible<basic_string_view<char_type>, T>::value &&
                 !is_string<T>::value && !has_formatter<T, Context>::value &&
-                !has_fallback_formatter<T, Context>::value)>
-  FMT_CONSTEXPR basic_string_view<char_type> map(const T& val) {
+                !has_fallback_formatter<T, char_type>::value)>
+  FMT_CONSTEXPR FMT_INLINE auto map(const T& val)
+      -> basic_string_view<char_type> {
     return basic_string_view<char_type>(val);
   }
   template <
       typename T,
       FMT_ENABLE_IF(
           std::is_constructible<std_string_view<char_type>, T>::value &&
           !std::is_constructible<basic_string_view<char_type>, T>::value &&
           !is_string<T>::value && !has_formatter<T, Context>::value &&
-          !has_fallback_formatter<T, Context>::value)>
-  FMT_CONSTEXPR basic_string_view<char_type> map(const T& val) {
+          !has_fallback_formatter<T, char_type>::value)>
+  FMT_CONSTEXPR FMT_INLINE auto map(const T& val)
+      -> basic_string_view<char_type> {
     return std_string_view<char_type>(val);
   }
-  FMT_CONSTEXPR const char* map(const signed char* val) {
-    static_assert(std::is_same<char_type, char>::value, "invalid string type");
-    return reinterpret_cast<const char*>(val);
-  }
-  FMT_CONSTEXPR const char* map(const unsigned char* val) {
-    static_assert(std::is_same<char_type, char>::value, "invalid string type");
-    return reinterpret_cast<const char*>(val);
-  }
-  FMT_CONSTEXPR const char* map(signed char* val) {
-    const auto* const_val = val;
-    return map(const_val);
-  }
-  FMT_CONSTEXPR const char* map(unsigned char* val) {
-    const auto* const_val = val;
-    return map(const_val);
-  }
-
-  FMT_CONSTEXPR const void* map(void* val) { return val; }
-  FMT_CONSTEXPR const void* map(const void* val) { return val; }
-  FMT_CONSTEXPR const void* map(std::nullptr_t val) { return val; }
-  template <typename T> FMT_CONSTEXPR int map(const T*) {
-    // Formatting of arbitrary pointers is disallowed. If you want to output
-    // a pointer cast it to "void *" or "const void *". In particular, this
-    // forbids formatting of "[const] volatile char *" which is printed as bool
-    // by iostreams.
-    static_assert(!sizeof(T), "formatting of non-void pointers is disallowed");
-    return 0;
+
+  using cstring_result = conditional_t<std::is_same<char_type, char>::value,
+                                       const char*, unformattable_pointer>;
+
+  FMT_DEPRECATED FMT_CONSTEXPR FMT_INLINE auto map(const signed char* val)
+      -> cstring_result {
+    return map(reinterpret_cast<const char*>(val));
+  }
+  FMT_DEPRECATED FMT_CONSTEXPR FMT_INLINE auto map(const unsigned char* val)
+      -> cstring_result {
+    return map(reinterpret_cast<const char*>(val));
+  }
+  FMT_DEPRECATED FMT_CONSTEXPR FMT_INLINE auto map(signed char* val)
+      -> cstring_result {
+    return map(reinterpret_cast<const char*>(val));
+  }
+  FMT_DEPRECATED FMT_CONSTEXPR FMT_INLINE auto map(unsigned char* val)
+      -> cstring_result {
+    return map(reinterpret_cast<const char*>(val));
+  }
+
+  FMT_CONSTEXPR FMT_INLINE auto map(void* val) -> const void* { return val; }
+  FMT_CONSTEXPR FMT_INLINE auto map(const void* val) -> const void* {
+    return val;
+  }
+  FMT_CONSTEXPR FMT_INLINE auto map(std::nullptr_t val) -> const void* {
+    return val;
+  }
+
+  // We use SFINAE instead of a const T* parameter to avoid conflicting with
+  // the C array overload.
+  template <
+      typename T,
+      FMT_ENABLE_IF(
+          std::is_member_pointer<T>::value ||
+          std::is_function<typename std::remove_pointer<T>::type>::value ||
+          (std::is_convertible<const T&, const void*>::value &&
+           !std::is_convertible<const T&, const char_type*>::value))>
+  FMT_CONSTEXPR auto map(const T&) -> unformattable_pointer {
+    return {};
+  }
+
+  template <typename T, std::size_t N,
+            FMT_ENABLE_IF(!std::is_same<T, wchar_t>::value)>
+  FMT_CONSTEXPR FMT_INLINE auto map(const T (&values)[N]) -> const T (&)[N] {
+    return values;
   }
 
   template <typename T,
-            FMT_ENABLE_IF(std::is_enum<T>::value &&
-                          !has_formatter<T, Context>::value &&
-                          !has_fallback_formatter<T, Context>::value)>
-  FMT_CONSTEXPR auto map(const T& val)
+            FMT_ENABLE_IF(
+                std::is_enum<T>::value&& std::is_convertible<T, int>::value &&
+                !has_formatter<T, Context>::value &&
+                !has_fallback_formatter<T, char_type>::value)>
+  FMT_CONSTEXPR FMT_INLINE auto map(const T& val)
       -> decltype(std::declval<arg_mapper>().map(
           static_cast<typename std::underlying_type<T>::type>(val))) {
     return map(static_cast<typename std::underlying_type<T>::type>(val));
   }
-  template <typename T,
-            FMT_ENABLE_IF(!is_string<T>::value && !is_char<T>::value &&
-                          (has_formatter<T, Context>::value ||
-                           has_fallback_formatter<T, Context>::value))>
-  FMT_CONSTEXPR const T& map(const T& val) {
+
+  FMT_CONSTEXPR FMT_INLINE auto map(detail::byte val) -> unsigned {
+    return map(static_cast<unsigned char>(val));
+  }
+
+  template <typename T, typename U = remove_cvref_t<T>>
+  struct formattable
+      : bool_constant<has_const_formatter<U, Context>() ||
+                      !std::is_const<remove_reference_t<T>>::value ||
+                      has_fallback_formatter<U, char_type>::value> {};
+
+#if FMT_MSC_VER != 0 && FMT_MSC_VER < 1910
+  // Workaround a bug in MSVC.
+  template <typename T> FMT_CONSTEXPR FMT_INLINE auto do_map(T&& val) -> T& {
     return val;
   }
+#else
+  template <typename T, FMT_ENABLE_IF(formattable<T>::value)>
+  FMT_CONSTEXPR FMT_INLINE auto do_map(T&& val) -> T& {
+    return val;
+  }
+  template <typename T, FMT_ENABLE_IF(!formattable<T>::value)>
+  FMT_CONSTEXPR FMT_INLINE auto do_map(T&&) -> unformattable_const {
+    return {};
+  }
+#endif
 
-  template <typename T>
-  FMT_CONSTEXPR auto map(const named_arg<char_type, T>& val)
-      -> decltype(std::declval<arg_mapper>().map(val.value)) {
-    return map(val.value);
+  template <typename T, typename U = remove_cvref_t<T>,
+            FMT_ENABLE_IF(!is_string<U>::value && !is_char<U>::value &&
+                          !std::is_array<U>::value &&
+                          (has_formatter<U, Context>::value ||
+                           has_fallback_formatter<U, char_type>::value))>
+  FMT_CONSTEXPR FMT_INLINE auto map(T&& val)
+      -> decltype(this->do_map(std::forward<T>(val))) {
+    return do_map(std::forward<T>(val));
   }
 
-  unformattable map(...) { return {}; }
+  template <typename T, FMT_ENABLE_IF(is_named_arg<T>::value)>
+  FMT_CONSTEXPR FMT_INLINE auto map(const T& named_arg)
+      -> decltype(std::declval<arg_mapper>().map(named_arg.value)) {
+    return map(named_arg.value);
+  }
+
+  auto map(...) -> unformattable { return {}; }
 };
 
 // A type constant after applying arg_mapper<Context>.
 template <typename T, typename Context>
 using mapped_type_constant =
     type_constant<decltype(arg_mapper<Context>().map(std::declval<const T&>())),
                   typename Context::char_type>;
 
 enum { packed_arg_bits = 4 };
 // Maximum number of arguments with packed types.
 enum { max_packed_args = 62 / packed_arg_bits };
 enum : unsigned long long { is_unpacked_bit = 1ULL << 63 };
 enum : unsigned long long { has_named_args_bit = 1ULL << 62 };
-}  // namespace detail
+
+FMT_END_DETAIL_NAMESPACE
+
+// An output iterator that appends to a buffer.
+// It is used to reduce symbol sizes for the common case.
+class appender : public std::back_insert_iterator<detail::buffer<char>> {
+  using base = std::back_insert_iterator<detail::buffer<char>>;
+
+  template <typename T>
+  friend auto get_buffer(appender out) -> detail::buffer<char>& {
+    return detail::get_container(out);
+  }
+
+ public:
+  using std::back_insert_iterator<detail::buffer<char>>::back_insert_iterator;
+  appender(base it) FMT_NOEXCEPT : base(it) {}
+  using _Unchecked_type = appender;  // Mark iterator as checked.
+
+  auto operator++() FMT_NOEXCEPT -> appender& { return *this; }
+
+  auto operator++(int) FMT_NOEXCEPT -> appender { return *this; }
+};
 
 // A formatting argument. It is a trivially copyable/constructible type to
 // allow storage in basic_memory_buffer.
 template <typename Context> class basic_format_arg {
  private:
   detail::value<Context> value_;
   detail::type type_;
 
   template <typename ContextType, typename T>
-  friend FMT_CONSTEXPR basic_format_arg<ContextType> detail::make_arg(
-      const T& value);
+  friend FMT_CONSTEXPR auto detail::make_arg(const T& value)
+      -> basic_format_arg<ContextType>;
 
   template <typename Visitor, typename Ctx>
   friend FMT_CONSTEXPR auto visit_format_arg(Visitor&& vis,
                                              const basic_format_arg<Ctx>& arg)
       -> decltype(vis(0));
 
   friend class basic_format_args<Context>;
@@ -1289,83 +1564,86 @@
 
   constexpr basic_format_arg() : type_(detail::type::none_type) {}
 
   constexpr explicit operator bool() const FMT_NOEXCEPT {
     return type_ != detail::type::none_type;
   }
 
-  detail::type type() const { return type_; }
+  auto type() const -> detail::type { return type_; }
 
-  bool is_integral() const { return detail::is_integral_type(type_); }
-  bool is_arithmetic() const { return detail::is_arithmetic_type(type_); }
+  auto is_integral() const -> bool { return detail::is_integral_type(type_); }
+  auto is_arithmetic() const -> bool {
+    return detail::is_arithmetic_type(type_);
+  }
 };
 
 /**
   \rst
   Visits an argument dispatching to the appropriate visit method based on
   the argument type. For example, if the argument type is ``double`` then
   ``vis(value)`` will be called with the value of type ``double``.
   \endrst
  */
 template <typename Visitor, typename Context>
-FMT_CONSTEXPR_DECL FMT_INLINE auto visit_format_arg(
+FMT_CONSTEXPR FMT_INLINE auto visit_format_arg(
     Visitor&& vis, const basic_format_arg<Context>& arg) -> decltype(vis(0)) {
-  using char_type = typename Context::char_type;
   switch (arg.type_) {
   case detail::type::none_type:
     break;
   case detail::type::int_type:
     return vis(arg.value_.int_value);
   case detail::type::uint_type:
     return vis(arg.value_.uint_value);
   case detail::type::long_long_type:
     return vis(arg.value_.long_long_value);
   case detail::type::ulong_long_type:
     return vis(arg.value_.ulong_long_value);
-#if FMT_USE_INT128
   case detail::type::int128_type:
-    return vis(arg.value_.int128_value);
+    return vis(detail::convert_for_visit(arg.value_.int128_value));
   case detail::type::uint128_type:
-    return vis(arg.value_.uint128_value);
-#else
-  case detail::type::int128_type:
-  case detail::type::uint128_type:
-    break;
-#endif
+    return vis(detail::convert_for_visit(arg.value_.uint128_value));
   case detail::type::bool_type:
     return vis(arg.value_.bool_value);
   case detail::type::char_type:
     return vis(arg.value_.char_value);
   case detail::type::float_type:
     return vis(arg.value_.float_value);
   case detail::type::double_type:
     return vis(arg.value_.double_value);
   case detail::type::long_double_type:
     return vis(arg.value_.long_double_value);
   case detail::type::cstring_type:
     return vis(arg.value_.string.data);
   case detail::type::string_type:
-    return vis(basic_string_view<char_type>(arg.value_.string.data,
-                                            arg.value_.string.size));
+    using sv = basic_string_view<typename Context::char_type>;
+    return vis(sv(arg.value_.string.data, arg.value_.string.size));
   case detail::type::pointer_type:
     return vis(arg.value_.pointer);
   case detail::type::custom_type:
     return vis(typename basic_format_arg<Context>::handle(arg.value_.custom));
   }
   return vis(monostate());
 }
 
-template <typename T> struct formattable : std::false_type {};
+FMT_BEGIN_DETAIL_NAMESPACE
 
-namespace detail {
+template <typename Char, typename InputIt>
+auto copy_str(InputIt begin, InputIt end, appender out) -> appender {
+  get_container(out).append(begin, end);
+  return out;
+}
 
+#if FMT_GCC_VERSION && FMT_GCC_VERSION < 500
 // A workaround for gcc 4.8 to make void_t work in a SFINAE context.
 template <typename... Ts> struct void_t_impl { using type = void; };
 template <typename... Ts>
 using void_t = typename detail::void_t_impl<Ts...>::type;
+#else
+template <typename...> using void_t = void;
+#endif
 
 template <typename It, typename T, typename Enable = void>
 struct is_output_iterator : std::false_type {};
 
 template <typename It, typename T>
 struct is_output_iterator<
     It, T,
@@ -1380,115 +1658,89 @@
     : std::true_type {};
 
 template <typename OutputIt>
 struct is_contiguous_back_insert_iterator : std::false_type {};
 template <typename Container>
 struct is_contiguous_back_insert_iterator<std::back_insert_iterator<Container>>
     : is_contiguous<Container> {};
-template <typename Char>
-struct is_contiguous_back_insert_iterator<buffer_appender<Char>>
-    : std::true_type {};
+template <>
+struct is_contiguous_back_insert_iterator<appender> : std::true_type {};
 
 // A type-erased reference to an std::locale to avoid heavy <locale> include.
 class locale_ref {
  private:
   const void* locale_;  // A type-erased pointer to std::locale.
 
  public:
-  locale_ref() : locale_(nullptr) {}
+  constexpr locale_ref() : locale_(nullptr) {}
   template <typename Locale> explicit locale_ref(const Locale& loc);
 
   explicit operator bool() const FMT_NOEXCEPT { return locale_ != nullptr; }
 
-  template <typename Locale> Locale get() const;
+  template <typename Locale> auto get() const -> Locale;
 };
 
-template <typename> constexpr unsigned long long encode_types() { return 0; }
+template <typename> constexpr auto encode_types() -> unsigned long long {
+  return 0;
+}
 
 template <typename Context, typename Arg, typename... Args>
-constexpr unsigned long long encode_types() {
+constexpr auto encode_types() -> unsigned long long {
   return static_cast<unsigned>(mapped_type_constant<Arg, Context>::value) |
          (encode_types<Context, Args...>() << packed_arg_bits);
 }
 
 template <typename Context, typename T>
-FMT_CONSTEXPR basic_format_arg<Context> make_arg(const T& value) {
+FMT_CONSTEXPR auto make_arg(const T& value) -> basic_format_arg<Context> {
   basic_format_arg<Context> arg;
   arg.type_ = mapped_type_constant<T, Context>::value;
   arg.value_ = arg_mapper<Context>().map(value);
   return arg;
 }
 
-template <typename T> int check(unformattable) {
-  static_assert(
-      formattable<T>(),
-      "Cannot format an argument. To make type T formattable provide a "
-      "formatter<T> specialization: https://fmt.dev/latest/api.html#udt");
-  return 0;
-}
-template <typename T, typename U> inline const U& check(const U& val) {
-  return val;
-}
-
 // The type template parameter is there to avoid an ODR violation when using
 // a fallback formatter in one translation unit and an implicit conversion in
 // another (not recommended).
 template <bool IS_PACKED, typename Context, type, typename T,
           FMT_ENABLE_IF(IS_PACKED)>
-inline value<Context> make_arg(const T& val) {
-  return check<T>(arg_mapper<Context>().map(val));
+FMT_CONSTEXPR FMT_INLINE auto make_arg(T&& val) -> value<Context> {
+  const auto& arg = arg_mapper<Context>().map(std::forward<T>(val));
+
+  constexpr bool formattable_char =
+      !std::is_same<decltype(arg), const unformattable_char&>::value;
+  static_assert(formattable_char, "Mixing character types is disallowed.");
+
+  constexpr bool formattable_const =
+      !std::is_same<decltype(arg), const unformattable_const&>::value;
+  static_assert(formattable_const, "Cannot format a const argument.");
+
+  // Formatting of arbitrary pointers is disallowed. If you want to output
+  // a pointer cast it to "void *" or "const void *". In particular, this
+  // forbids formatting of "[const] volatile char *" which is printed as bool
+  // by iostreams.
+  constexpr bool formattable_pointer =
+      !std::is_same<decltype(arg), const unformattable_pointer&>::value;
+  static_assert(formattable_pointer,
+                "Formatting of non-void pointers is disallowed.");
+
+  constexpr bool formattable =
+      !std::is_same<decltype(arg), const unformattable&>::value;
+  static_assert(
+      formattable,
+      "Cannot format an argument. To make type T formattable provide a "
+      "formatter<T> specialization: https://fmt.dev/latest/api.html#udt");
+  return {arg};
 }
 
 template <bool IS_PACKED, typename Context, type, typename T,
           FMT_ENABLE_IF(!IS_PACKED)>
-inline basic_format_arg<Context> make_arg(const T& value) {
+inline auto make_arg(const T& value) -> basic_format_arg<Context> {
   return make_arg<Context>(value);
 }
-
-template <typename T> struct is_reference_wrapper : std::false_type {};
-template <typename T>
-struct is_reference_wrapper<std::reference_wrapper<T>> : std::true_type {};
-
-template <typename T> const T& unwrap(const T& v) { return v; }
-template <typename T> const T& unwrap(const std::reference_wrapper<T>& v) {
-  return static_cast<const T&>(v);
-}
-
-class dynamic_arg_list {
-  // Workaround for clang's -Wweak-vtables. Unlike for regular classes, for
-  // templates it doesn't complain about inability to deduce single translation
-  // unit for placing vtable. So storage_node_base is made a fake template.
-  template <typename = void> struct node {
-    virtual ~node() = default;
-    std::unique_ptr<node<>> next;
-  };
-
-  template <typename T> struct typed_node : node<> {
-    T value;
-
-    template <typename Arg>
-    FMT_CONSTEXPR typed_node(const Arg& arg) : value(arg) {}
-
-    template <typename Char>
-    FMT_CONSTEXPR typed_node(const basic_string_view<Char>& arg)
-        : value(arg.data(), arg.size()) {}
-  };
-
-  std::unique_ptr<node<>> head_;
-
- public:
-  template <typename T, typename Arg> const T& push(const Arg& arg) {
-    auto new_node = std::unique_ptr<typed_node<T>>(new typed_node<T>(arg));
-    auto& value = new_node->value;
-    new_node->next = std::move(head_);
-    head_ = std::move(new_node);
-    return value;
-  }
-};
-}  // namespace detail
+FMT_END_DETAIL_NAMESPACE
 
 // Formatting context.
 template <typename OutputIt, typename Char> class basic_format_context {
  public:
   /** The character type for the output. */
   using char_type = Char;
 
@@ -1499,54 +1751,67 @@
 
  public:
   using iterator = OutputIt;
   using format_arg = basic_format_arg<basic_format_context>;
   using parse_context_type = basic_format_parse_context<Char>;
   template <typename T> using formatter_type = formatter<T, char_type>;
 
+  basic_format_context(basic_format_context&&) = default;
   basic_format_context(const basic_format_context&) = delete;
   void operator=(const basic_format_context&) = delete;
   /**
    Constructs a ``basic_format_context`` object. References to the arguments are
    stored in the object so make sure they have appropriate lifetimes.
    */
-  basic_format_context(OutputIt out,
-                       basic_format_args<basic_format_context> ctx_args,
-                       detail::locale_ref loc = detail::locale_ref())
+  constexpr basic_format_context(
+      OutputIt out, basic_format_args<basic_format_context> ctx_args,
+      detail::locale_ref loc = detail::locale_ref())
       : out_(out), args_(ctx_args), loc_(loc) {}
 
-  format_arg arg(int id) const { return args_.get(id); }
-  format_arg arg(basic_string_view<char_type> name) { return args_.get(name); }
-  int arg_id(basic_string_view<char_type> name) { return args_.get_id(name); }
-  const basic_format_args<basic_format_context>& args() const { return args_; }
+  constexpr auto arg(int id) const -> format_arg { return args_.get(id); }
+  FMT_CONSTEXPR auto arg(basic_string_view<char_type> name) -> format_arg {
+    return args_.get(name);
+  }
+  FMT_CONSTEXPR auto arg_id(basic_string_view<char_type> name) -> int {
+    return args_.get_id(name);
+  }
+  auto args() const -> const basic_format_args<basic_format_context>& {
+    return args_;
+  }
 
-  detail::error_handler error_handler() { return {}; }
+  FMT_CONSTEXPR auto error_handler() -> detail::error_handler { return {}; }
   void on_error(const char* message) { error_handler().on_error(message); }
 
   // Returns an iterator to the beginning of the output range.
-  iterator out() { return out_; }
+  FMT_CONSTEXPR auto out() -> iterator { return out_; }
 
   // Advances the begin iterator to ``it``.
   void advance_to(iterator it) {
     if (!detail::is_back_insert_iterator<iterator>()) out_ = it;
   }
 
-  detail::locale_ref locale() { return loc_; }
+  FMT_CONSTEXPR auto locale() -> detail::locale_ref { return loc_; }
 };
 
 template <typename Char>
 using buffer_context =
     basic_format_context<detail::buffer_appender<Char>, Char>;
 using format_context = buffer_context<char>;
-using wformat_context = buffer_context<wchar_t>;
 
 // Workaround an alias issue: https://stackoverflow.com/q/62767544/471164.
 #define FMT_BUFFER_CONTEXT(Char) \
   basic_format_context<detail::buffer_appender<Char>, Char>
 
+template <typename T, typename Char = char>
+using is_formattable = bool_constant<
+    !std::is_base_of<detail::unformattable,
+                     decltype(detail::arg_mapper<buffer_context<Char>>().map(
+                         std::declval<T>()))>::value &&
+    !detail::has_fallback_formatter<T, Char>::value>;
+
 /**
   \rst
   An array of references to arguments. It can be implicitly converted into
   `~fmt::basic_format_args` for passing into type-erased formatting functions
   such as `~fmt::vformat`.
   \endrst
  */
@@ -1575,252 +1840,61 @@
       (is_packed ? detail::encode_types<Context, Args...>()
                  : detail::is_unpacked_bit | num_args) |
       (num_named_args != 0
            ? static_cast<unsigned long long>(detail::has_named_args_bit)
            : 0);
 
  public:
-  format_arg_store(const Args&... args)
+  template <typename... T>
+  FMT_CONSTEXPR FMT_INLINE format_arg_store(T&&... args)
       :
 #if FMT_GCC_VERSION && FMT_GCC_VERSION < 409
         basic_format_args<Context>(*this),
 #endif
         data_{detail::make_arg<
             is_packed, Context,
-            detail::mapped_type_constant<Args, Context>::value>(args)...} {
+            detail::mapped_type_constant<remove_cvref_t<T>, Context>::value>(
+            std::forward<T>(args))...} {
     detail::init_named_args(data_.named_args(), 0, 0, args...);
   }
 };
 
 /**
   \rst
   Constructs a `~fmt::format_arg_store` object that contains references to
   arguments and can be implicitly converted to `~fmt::format_args`. `Context`
   can be omitted in which case it defaults to `~fmt::context`.
   See `~fmt::arg` for lifetime considerations.
   \endrst
  */
 template <typename Context = format_context, typename... Args>
-inline format_arg_store<Context, Args...> make_format_args(
-    const Args&... args) {
-  return {args...};
+constexpr auto make_format_args(Args&&... args)
+    -> format_arg_store<Context, remove_cvref_t<Args>...> {
+  return {std::forward<Args>(args)...};
 }
 
 /**
   \rst
-  Constructs a `~fmt::format_arg_store` object that contains references
-  to arguments and can be implicitly converted to `~fmt::format_args`.
-  If ``format_str`` is a compile-time string then `make_args_checked` checks
-  its validity at compile time.
-  \endrst
- */
-template <typename... Args, typename S, typename Char = char_t<S>>
-inline auto make_args_checked(const S& format_str,
-                              const remove_reference_t<Args>&... args)
-    -> format_arg_store<buffer_context<Char>, remove_reference_t<Args>...> {
-  static_assert(
-      detail::count<(
-              std::is_base_of<detail::view, remove_reference_t<Args>>::value &&
-              std::is_reference<Args>::value)...>() == 0,
-      "passing views as lvalues is disallowed");
-  detail::check_format_string<Args...>(format_str);
-  return {args...};
-}
-
-/**
-  \rst
-  Returns a named argument to be used in a formatting function. It should only
-  be used in a call to a formatting function.
+  Returns a named argument to be used in a formatting function.
+  It should only be used in a call to a formatting function or
+  `dynamic_format_arg_store::push_back`.
 
   **Example**::
 
     fmt::print("Elapsed time: {s:.2f} seconds", fmt::arg("s", 1.23));
   \endrst
  */
 template <typename Char, typename T>
-inline detail::named_arg<Char, T> arg(const Char* name, const T& arg) {
+inline auto arg(const Char* name, const T& arg) -> detail::named_arg<Char, T> {
   static_assert(!detail::is_named_arg<T>(), "nested named arguments");
   return {name, arg};
 }
 
 /**
   \rst
-  A dynamic version of `fmt::format_arg_store`.
-  It's equipped with a storage to potentially temporary objects which lifetimes
-  could be shorter than the format arguments object.
-
-  It can be implicitly converted into `~fmt::basic_format_args` for passing
-  into type-erased formatting functions such as `~fmt::vformat`.
-  \endrst
- */
-template <typename Context>
-class dynamic_format_arg_store
-#if FMT_GCC_VERSION && FMT_GCC_VERSION < 409
-    // Workaround a GCC template argument substitution bug.
-    : public basic_format_args<Context>
-#endif
-{
- private:
-  using char_type = typename Context::char_type;
-
-  template <typename T> struct need_copy {
-    static constexpr detail::type mapped_type =
-        detail::mapped_type_constant<T, Context>::value;
-
-    enum {
-      value = !(detail::is_reference_wrapper<T>::value ||
-                std::is_same<T, basic_string_view<char_type>>::value ||
-                std::is_same<T, detail::std_string_view<char_type>>::value ||
-                (mapped_type != detail::type::cstring_type &&
-                 mapped_type != detail::type::string_type &&
-                 mapped_type != detail::type::custom_type))
-    };
-  };
-
-  template <typename T>
-  using stored_type = conditional_t<detail::is_string<T>::value,
-                                    std::basic_string<char_type>, T>;
-
-  // Storage of basic_format_arg must be contiguous.
-  std::vector<basic_format_arg<Context>> data_;
-  std::vector<detail::named_arg_info<char_type>> named_info_;
-
-  // Storage of arguments not fitting into basic_format_arg must grow
-  // without relocation because items in data_ refer to it.
-  detail::dynamic_arg_list dynamic_args_;
-
-  friend class basic_format_args<Context>;
-
-  unsigned long long get_types() const {
-    return detail::is_unpacked_bit | data_.size() |
-           (named_info_.empty()
-                ? 0ULL
-                : static_cast<unsigned long long>(detail::has_named_args_bit));
-  }
-
-  const basic_format_arg<Context>* data() const {
-    return named_info_.empty() ? data_.data() : data_.data() + 1;
-  }
-
-  template <typename T> void emplace_arg(const T& arg) {
-    data_.emplace_back(detail::make_arg<Context>(arg));
-  }
-
-  template <typename T>
-  void emplace_arg(const detail::named_arg<char_type, T>& arg) {
-    if (named_info_.empty()) {
-      constexpr const detail::named_arg_info<char_type>* zero_ptr{nullptr};
-      data_.insert(data_.begin(), {zero_ptr, 0});
-    }
-    data_.emplace_back(detail::make_arg<Context>(detail::unwrap(arg.value)));
-    auto pop_one = [](std::vector<basic_format_arg<Context>>* data) {
-      data->pop_back();
-    };
-    std::unique_ptr<std::vector<basic_format_arg<Context>>, decltype(pop_one)>
-        guard{&data_, pop_one};
-    named_info_.push_back({arg.name, static_cast<int>(data_.size() - 2u)});
-    data_[0].value_.named_args = {named_info_.data(), named_info_.size()};
-    guard.release();
-  }
-
- public:
-  /**
-    \rst
-    Adds an argument into the dynamic store for later passing to a formatting
-    function.
-
-    Note that custom types and string types (but not string views) are copied
-    into the store dynamically allocating memory if necessary.
-
-    **Example**::
-
-      fmt::dynamic_format_arg_store<fmt::format_context> store;
-      store.push_back(42);
-      store.push_back("abc");
-      store.push_back(1.5f);
-      std::string result = fmt::vformat("{} and {} and {}", store);
-    \endrst
-  */
-  template <typename T> void push_back(const T& arg) {
-    if (detail::const_check(need_copy<T>::value))
-      emplace_arg(dynamic_args_.push<stored_type<T>>(arg));
-    else
-      emplace_arg(detail::unwrap(arg));
-  }
-
-  /**
-    \rst
-    Adds a reference to the argument into the dynamic store for later passing to
-    a formatting function. Supports named arguments wrapped in
-    ``std::reference_wrapper`` via ``std::ref()``/``std::cref()``.
-
-    **Example**::
-
-      fmt::dynamic_format_arg_store<fmt::format_context> store;
-      char str[] = "1234567890";
-      store.push_back(std::cref(str));
-      int a1_val{42};
-      auto a1 = fmt::arg("a1_", a1_val);
-      store.push_back(std::cref(a1));
-
-      // Changing str affects the output but only for string and custom types.
-      str[0] = 'X';
-
-      std::string result = fmt::vformat("{} and {a1_}");
-      assert(result == "X234567890 and 42");
-    \endrst
-  */
-  template <typename T> void push_back(std::reference_wrapper<T> arg) {
-    static_assert(
-        detail::is_named_arg<typename std::remove_cv<T>::type>::value ||
-            need_copy<T>::value,
-        "objects of built-in types and string views are always copied");
-    emplace_arg(arg.get());
-  }
-
-  /**
-    Adds named argument into the dynamic store for later passing to a formatting
-    function. ``std::reference_wrapper`` is supported to avoid copying of the
-    argument.
-  */
-  template <typename T>
-  void push_back(const detail::named_arg<char_type, T>& arg) {
-    const char_type* arg_name =
-        dynamic_args_.push<std::basic_string<char_type>>(arg.name).c_str();
-    if (detail::const_check(need_copy<T>::value)) {
-      emplace_arg(
-          fmt::arg(arg_name, dynamic_args_.push<stored_type<T>>(arg.value)));
-    } else {
-      emplace_arg(fmt::arg(arg_name, arg.value));
-    }
-  }
-
-  /** Erase all elements from the store */
-  void clear() {
-    data_.clear();
-    named_info_.clear();
-    dynamic_args_ = detail::dynamic_arg_list();
-  }
-
-  /**
-    \rst
-    Reserves space to store at least *new_cap* arguments including
-    *new_cap_named* named arguments.
-    \endrst
-  */
-  void reserve(size_t new_cap, size_t new_cap_named) {
-    FMT_ASSERT(new_cap >= new_cap_named,
-               "Set of arguments includes set of named arguments");
-    data_.reserve(new_cap);
-    named_info_.reserve(new_cap_named);
-  }
-};
-
-/**
-  \rst
   A view of a collection of formatting arguments. To avoid lifetime issues it
   should only be used as a parameter type in type-erased functions such as
   ``vformat``::
 
     void vlog(string_view format_str, format_args args);  // OK
     format_args args = make_format_args(42);  // Error: dangling reference
   \endrst
@@ -1842,281 +1916,1321 @@
     // locality and reduce compiled code size since storing larger objects
     // may require more code (at least on x86-64) even if the same amount of
     // data is actually copied to stack. It saves ~10% on the bloat test.
     const detail::value<Context>* values_;
     const format_arg* args_;
   };
 
-  bool is_packed() const { return (desc_ & detail::is_unpacked_bit) == 0; }
-  bool has_named_args() const {
+  constexpr auto is_packed() const -> bool {
+    return (desc_ & detail::is_unpacked_bit) == 0;
+  }
+  auto has_named_args() const -> bool {
     return (desc_ & detail::has_named_args_bit) != 0;
   }
 
-  detail::type type(int index) const {
+  FMT_CONSTEXPR auto type(int index) const -> detail::type {
     int shift = index * detail::packed_arg_bits;
     unsigned int mask = (1 << detail::packed_arg_bits) - 1;
     return static_cast<detail::type>((desc_ >> shift) & mask);
   }
 
-  basic_format_args(unsigned long long desc,
-                    const detail::value<Context>* values)
+  constexpr FMT_INLINE basic_format_args(unsigned long long desc,
+                                         const detail::value<Context>* values)
       : desc_(desc), values_(values) {}
-  basic_format_args(unsigned long long desc, const format_arg* args)
+  constexpr basic_format_args(unsigned long long desc, const format_arg* args)
       : desc_(desc), args_(args) {}
 
  public:
-  basic_format_args() : desc_(0) {}
+  constexpr basic_format_args() : desc_(0), args_(nullptr) {}
 
   /**
    \rst
    Constructs a `basic_format_args` object from `~fmt::format_arg_store`.
    \endrst
    */
   template <typename... Args>
-  FMT_INLINE basic_format_args(const format_arg_store<Context, Args...>& store)
-      : basic_format_args(store.desc, store.data_.args()) {}
+  constexpr FMT_INLINE basic_format_args(
+      const format_arg_store<Context, Args...>& store)
+      : basic_format_args(format_arg_store<Context, Args...>::desc,
+                          store.data_.args()) {}
 
   /**
    \rst
    Constructs a `basic_format_args` object from
    `~fmt::dynamic_format_arg_store`.
    \endrst
    */
-  FMT_INLINE basic_format_args(const dynamic_format_arg_store<Context>& store)
+  constexpr FMT_INLINE basic_format_args(
+      const dynamic_format_arg_store<Context>& store)
       : basic_format_args(store.get_types(), store.data()) {}
 
   /**
    \rst
    Constructs a `basic_format_args` object from a dynamic set of arguments.
    \endrst
    */
-  basic_format_args(const format_arg* args, int count)
+  constexpr basic_format_args(const format_arg* args, int count)
       : basic_format_args(detail::is_unpacked_bit | detail::to_unsigned(count),
                           args) {}
 
   /** Returns the argument with the specified id. */
-  format_arg get(int id) const {
+  FMT_CONSTEXPR auto get(int id) const -> format_arg {
     format_arg arg;
     if (!is_packed()) {
       if (id < max_size()) arg = args_[id];
       return arg;
     }
     if (id >= detail::max_packed_args) return arg;
     arg.type_ = type(id);
     if (arg.type_ == detail::type::none_type) return arg;
     arg.value_ = values_[id];
     return arg;
   }
 
-  template <typename Char> format_arg get(basic_string_view<Char> name) const {
+  template <typename Char>
+  auto get(basic_string_view<Char> name) const -> format_arg {
     int id = get_id(name);
     return id >= 0 ? get(id) : format_arg();
   }
 
-  template <typename Char> int get_id(basic_string_view<Char> name) const {
+  template <typename Char>
+  auto get_id(basic_string_view<Char> name) const -> int {
     if (!has_named_args()) return -1;
     const auto& named_args =
         (is_packed() ? values_[-1] : args_[-1].value_).named_args;
     for (size_t i = 0; i < named_args.size; ++i) {
       if (named_args.data[i].name == name) return named_args.data[i].id;
     }
     return -1;
   }
 
-  int max_size() const {
+  auto max_size() const -> int {
     unsigned long long max_packed = detail::max_packed_args;
     return static_cast<int>(is_packed() ? max_packed
                                         : desc_ & ~detail::is_unpacked_bit);
   }
 };
 
-#ifdef FMT_ARM_ABI_COMPATIBILITY
 /** An alias to ``basic_format_args<format_context>``. */
-// Separate types would result in shorter symbols but break ABI compatibility
+// A separate type would result in shorter symbols but break ABI compatibility
 // between clang and gcc on ARM (#1919).
 using format_args = basic_format_args<format_context>;
-using wformat_args = basic_format_args<wformat_context>;
-#else
-// DEPRECATED! These are kept for ABI compatibility.
-// It is a separate type rather than an alias to make symbols readable.
-struct format_args : basic_format_args<format_context> {
-  template <typename... Args>
-  FMT_INLINE format_args(const Args&... args) : basic_format_args(args...) {}
+
+// We cannot use enum classes as bit fields because of a gcc bug
+// https://gcc.gnu.org/bugzilla/show_bug.cgi?id=61414.
+namespace align {
+enum type { none, left, right, center, numeric };
+}
+using align_t = align::type;
+namespace sign {
+enum type { none, minus, plus, space };
+}
+using sign_t = sign::type;
+
+FMT_BEGIN_DETAIL_NAMESPACE
+
+// Workaround an array initialization issue in gcc 4.8.
+template <typename Char> struct fill_t {
+ private:
+  enum { max_size = 4 };
+  Char data_[max_size] = {Char(' '), Char(0), Char(0), Char(0)};
+  unsigned char size_ = 1;
+
+ public:
+  FMT_CONSTEXPR void operator=(basic_string_view<Char> s) {
+    auto size = s.size();
+    if (size > max_size) return throw_format_error("invalid fill");
+    for (size_t i = 0; i < size; ++i) data_[i] = s[i];
+    size_ = static_cast<unsigned char>(size);
+  }
+
+  constexpr auto size() const -> size_t { return size_; }
+  constexpr auto data() const -> const Char* { return data_; }
+
+  FMT_CONSTEXPR auto operator[](size_t index) -> Char& { return data_[index]; }
+  FMT_CONSTEXPR auto operator[](size_t index) const -> const Char& {
+    return data_[index];
+  }
+};
+FMT_END_DETAIL_NAMESPACE
+
+enum class presentation_type : unsigned char {
+  none,
+  // Integer types should go first,
+  dec,             // 'd'
+  oct,             // 'o'
+  hex_lower,       // 'x'
+  hex_upper,       // 'X'
+  bin_lower,       // 'b'
+  bin_upper,       // 'B'
+  hexfloat_lower,  // 'a'
+  hexfloat_upper,  // 'A'
+  exp_lower,       // 'e'
+  exp_upper,       // 'E'
+  fixed_lower,     // 'f'
+  fixed_upper,     // 'F'
+  general_lower,   // 'g'
+  general_upper,   // 'G'
+  chr,             // 'c'
+  string,          // 's'
+  pointer          // 'p'
+};
+
+// Format specifiers for built-in and string types.
+template <typename Char> struct basic_format_specs {
+  int width;
+  int precision;
+  presentation_type type;
+  align_t align : 4;
+  sign_t sign : 3;
+  bool alt : 1;  // Alternate form ('#').
+  bool localized : 1;
+  detail::fill_t<Char> fill;
+
+  constexpr basic_format_specs()
+      : width(0),
+        precision(-1),
+        type(presentation_type::none),
+        align(align::none),
+        sign(sign::none),
+        alt(false),
+        localized(false) {}
+};
+
+using format_specs = basic_format_specs<char>;
+
+FMT_BEGIN_DETAIL_NAMESPACE
+
+enum class arg_id_kind { none, index, name };
+
+// An argument reference.
+template <typename Char> struct arg_ref {
+  FMT_CONSTEXPR arg_ref() : kind(arg_id_kind::none), val() {}
+
+  FMT_CONSTEXPR explicit arg_ref(int index)
+      : kind(arg_id_kind::index), val(index) {}
+  FMT_CONSTEXPR explicit arg_ref(basic_string_view<Char> name)
+      : kind(arg_id_kind::name), val(name) {}
+
+  FMT_CONSTEXPR auto operator=(int idx) -> arg_ref& {
+    kind = arg_id_kind::index;
+    val.index = idx;
+    return *this;
+  }
+
+  arg_id_kind kind;
+  union value {
+    FMT_CONSTEXPR value(int id = 0) : index{id} {}
+    FMT_CONSTEXPR value(basic_string_view<Char> n) : name(n) {}
+
+    int index;
+    basic_string_view<Char> name;
+  } val;
 };
-struct wformat_args : basic_format_args<wformat_context> {
-  using basic_format_args::basic_format_args;
+
+// Format specifiers with width and precision resolved at formatting rather
+// than parsing time to allow re-using the same parsed specifiers with
+// different sets of arguments (precompilation of format strings).
+template <typename Char>
+struct dynamic_format_specs : basic_format_specs<Char> {
+  arg_ref<Char> width_ref;
+  arg_ref<Char> precision_ref;
+};
+
+struct auto_id {};
+
+// A format specifier handler that sets fields in basic_format_specs.
+template <typename Char> class specs_setter {
+ protected:
+  basic_format_specs<Char>& specs_;
+
+ public:
+  explicit FMT_CONSTEXPR specs_setter(basic_format_specs<Char>& specs)
+      : specs_(specs) {}
+
+  FMT_CONSTEXPR specs_setter(const specs_setter& other)
+      : specs_(other.specs_) {}
+
+  FMT_CONSTEXPR void on_align(align_t align) { specs_.align = align; }
+  FMT_CONSTEXPR void on_fill(basic_string_view<Char> fill) {
+    specs_.fill = fill;
+  }
+  FMT_CONSTEXPR void on_sign(sign_t s) { specs_.sign = s; }
+  FMT_CONSTEXPR void on_hash() { specs_.alt = true; }
+  FMT_CONSTEXPR void on_localized() { specs_.localized = true; }
+
+  FMT_CONSTEXPR void on_zero() {
+    if (specs_.align == align::none) specs_.align = align::numeric;
+    specs_.fill[0] = Char('0');
+  }
+
+  FMT_CONSTEXPR void on_width(int width) { specs_.width = width; }
+  FMT_CONSTEXPR void on_precision(int precision) {
+    specs_.precision = precision;
+  }
+  FMT_CONSTEXPR void end_precision() {}
+
+  FMT_CONSTEXPR void on_type(presentation_type type) { specs_.type = type; }
+};
+
+// Format spec handler that saves references to arguments representing dynamic
+// width and precision to be resolved at formatting time.
+template <typename ParseContext>
+class dynamic_specs_handler
+    : public specs_setter<typename ParseContext::char_type> {
+ public:
+  using char_type = typename ParseContext::char_type;
+
+  FMT_CONSTEXPR dynamic_specs_handler(dynamic_format_specs<char_type>& specs,
+                                      ParseContext& ctx)
+      : specs_setter<char_type>(specs), specs_(specs), context_(ctx) {}
+
+  FMT_CONSTEXPR dynamic_specs_handler(const dynamic_specs_handler& other)
+      : specs_setter<char_type>(other),
+        specs_(other.specs_),
+        context_(other.context_) {}
+
+  template <typename Id> FMT_CONSTEXPR void on_dynamic_width(Id arg_id) {
+    specs_.width_ref = make_arg_ref(arg_id);
+  }
+
+  template <typename Id> FMT_CONSTEXPR void on_dynamic_precision(Id arg_id) {
+    specs_.precision_ref = make_arg_ref(arg_id);
+  }
+
+  FMT_CONSTEXPR void on_error(const char* message) {
+    context_.on_error(message);
+  }
+
+ private:
+  dynamic_format_specs<char_type>& specs_;
+  ParseContext& context_;
+
+  using arg_ref_type = arg_ref<char_type>;
+
+  FMT_CONSTEXPR auto make_arg_ref(int arg_id) -> arg_ref_type {
+    context_.check_arg_id(arg_id);
+    return arg_ref_type(arg_id);
+  }
+
+  FMT_CONSTEXPR auto make_arg_ref(auto_id) -> arg_ref_type {
+    return arg_ref_type(context_.next_arg_id());
+  }
+
+  FMT_CONSTEXPR auto make_arg_ref(basic_string_view<char_type> arg_id)
+      -> arg_ref_type {
+    context_.check_arg_id(arg_id);
+    basic_string_view<char_type> format_str(
+        context_.begin(), to_unsigned(context_.end() - context_.begin()));
+    return arg_ref_type(arg_id);
+  }
+};
+
+template <typename Char> constexpr bool is_ascii_letter(Char c) {
+  return (c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z');
+}
+
+// Converts a character to ASCII. Returns a number > 127 on conversion failure.
+template <typename Char, FMT_ENABLE_IF(std::is_integral<Char>::value)>
+constexpr auto to_ascii(Char value) -> Char {
+  return value;
+}
+template <typename Char, FMT_ENABLE_IF(std::is_enum<Char>::value)>
+constexpr auto to_ascii(Char value) ->
+    typename std::underlying_type<Char>::type {
+  return value;
+}
+
+template <typename Char>
+FMT_CONSTEXPR auto code_point_length(const Char* begin) -> int {
+  if (const_check(sizeof(Char) != 1)) return 1;
+  auto lengths =
+      "\1\1\1\1\1\1\1\1\1\1\1\1\1\1\1\1\0\0\0\0\0\0\0\0\2\2\2\2\3\3\4";
+  int len = lengths[static_cast<unsigned char>(*begin) >> 3];
+
+  // Compute the pointer to the next character early so that the next
+  // iteration can start working on the next character. Neither Clang
+  // nor GCC figure out this reordering on their own.
+  return len + !len;
+}
+
+// Return the result via the out param to workaround gcc bug 77539.
+template <bool IS_CONSTEXPR, typename T, typename Ptr = const T*>
+FMT_CONSTEXPR auto find(Ptr first, Ptr last, T value, Ptr& out) -> bool {
+  for (out = first; out != last; ++out) {
+    if (*out == value) return true;
+  }
+  return false;
+}
+
+template <>
+inline auto find<false, char>(const char* first, const char* last, char value,
+                              const char*& out) -> bool {
+  out = static_cast<const char*>(
+      std::memchr(first, value, to_unsigned(last - first)));
+  return out != nullptr;
+}
+
+// Parses the range [begin, end) as an unsigned integer. This function assumes
+// that the range is non-empty and the first character is a digit.
+template <typename Char>
+FMT_CONSTEXPR auto parse_nonnegative_int(const Char*& begin, const Char* end,
+                                         int error_value) noexcept -> int {
+  FMT_ASSERT(begin != end && '0' <= *begin && *begin <= '9', "");
+  unsigned value = 0, prev = 0;
+  auto p = begin;
+  do {
+    prev = value;
+    value = value * 10 + unsigned(*p - '0');
+    ++p;
+  } while (p != end && '0' <= *p && *p <= '9');
+  auto num_digits = p - begin;
+  begin = p;
+  if (num_digits <= std::numeric_limits<int>::digits10)
+    return static_cast<int>(value);
+  // Check for overflow.
+  const unsigned max = to_unsigned((std::numeric_limits<int>::max)());
+  return num_digits == std::numeric_limits<int>::digits10 + 1 &&
+                 prev * 10ull + unsigned(p[-1] - '0') <= max
+             ? static_cast<int>(value)
+             : error_value;
+}
+
+// Parses fill and alignment.
+template <typename Char, typename Handler>
+FMT_CONSTEXPR auto parse_align(const Char* begin, const Char* end,
+                               Handler&& handler) -> const Char* {
+  FMT_ASSERT(begin != end, "");
+  auto align = align::none;
+  auto p = begin + code_point_length(begin);
+  if (p >= end) p = begin;
+  for (;;) {
+    switch (to_ascii(*p)) {
+    case '<':
+      align = align::left;
+      break;
+    case '>':
+      align = align::right;
+      break;
+    case '^':
+      align = align::center;
+      break;
+    default:
+      break;
+    }
+    if (align != align::none) {
+      if (p != begin) {
+        auto c = *begin;
+        if (c == '{')
+          return handler.on_error("invalid fill character '{'"), begin;
+        handler.on_fill(basic_string_view<Char>(begin, to_unsigned(p - begin)));
+        begin = p + 1;
+      } else
+        ++begin;
+      handler.on_align(align);
+      break;
+    } else if (p == begin) {
+      break;
+    }
+    p = begin;
+  }
+  return begin;
+}
+
+template <typename Char> FMT_CONSTEXPR bool is_name_start(Char c) {
+  return ('a' <= c && c <= 'z') || ('A' <= c && c <= 'Z') || '_' == c;
+}
+
+template <typename Char, typename IDHandler>
+FMT_CONSTEXPR auto do_parse_arg_id(const Char* begin, const Char* end,
+                                   IDHandler&& handler) -> const Char* {
+  FMT_ASSERT(begin != end, "");
+  Char c = *begin;
+  if (c >= '0' && c <= '9') {
+    int index = 0;
+    if (c != '0')
+      index =
+          parse_nonnegative_int(begin, end, (std::numeric_limits<int>::max)());
+    else
+      ++begin;
+    if (begin == end || (*begin != '}' && *begin != ':'))
+      handler.on_error("invalid format string");
+    else
+      handler(index);
+    return begin;
+  }
+  if (!is_name_start(c)) {
+    handler.on_error("invalid format string");
+    return begin;
+  }
+  auto it = begin;
+  do {
+    ++it;
+  } while (it != end && (is_name_start(c = *it) || ('0' <= c && c <= '9')));
+  handler(basic_string_view<Char>(begin, to_unsigned(it - begin)));
+  return it;
+}
+
+template <typename Char, typename IDHandler>
+FMT_CONSTEXPR FMT_INLINE auto parse_arg_id(const Char* begin, const Char* end,
+                                           IDHandler&& handler) -> const Char* {
+  Char c = *begin;
+  if (c != '}' && c != ':') return do_parse_arg_id(begin, end, handler);
+  handler();
+  return begin;
+}
+
+template <typename Char, typename Handler>
+FMT_CONSTEXPR auto parse_width(const Char* begin, const Char* end,
+                               Handler&& handler) -> const Char* {
+  using detail::auto_id;
+  struct width_adapter {
+    Handler& handler;
+
+    FMT_CONSTEXPR void operator()() { handler.on_dynamic_width(auto_id()); }
+    FMT_CONSTEXPR void operator()(int id) { handler.on_dynamic_width(id); }
+    FMT_CONSTEXPR void operator()(basic_string_view<Char> id) {
+      handler.on_dynamic_width(id);
+    }
+    FMT_CONSTEXPR void on_error(const char* message) {
+      if (message) handler.on_error(message);
+    }
+  };
+
+  FMT_ASSERT(begin != end, "");
+  if ('0' <= *begin && *begin <= '9') {
+    int width = parse_nonnegative_int(begin, end, -1);
+    if (width != -1)
+      handler.on_width(width);
+    else
+      handler.on_error("number is too big");
+  } else if (*begin == '{') {
+    ++begin;
+    if (begin != end) begin = parse_arg_id(begin, end, width_adapter{handler});
+    if (begin == end || *begin != '}')
+      return handler.on_error("invalid format string"), begin;
+    ++begin;
+  }
+  return begin;
+}
+
+template <typename Char, typename Handler>
+FMT_CONSTEXPR auto parse_precision(const Char* begin, const Char* end,
+                                   Handler&& handler) -> const Char* {
+  using detail::auto_id;
+  struct precision_adapter {
+    Handler& handler;
+
+    FMT_CONSTEXPR void operator()() { handler.on_dynamic_precision(auto_id()); }
+    FMT_CONSTEXPR void operator()(int id) { handler.on_dynamic_precision(id); }
+    FMT_CONSTEXPR void operator()(basic_string_view<Char> id) {
+      handler.on_dynamic_precision(id);
+    }
+    FMT_CONSTEXPR void on_error(const char* message) {
+      if (message) handler.on_error(message);
+    }
+  };
+
+  ++begin;
+  auto c = begin != end ? *begin : Char();
+  if ('0' <= c && c <= '9') {
+    auto precision = parse_nonnegative_int(begin, end, -1);
+    if (precision != -1)
+      handler.on_precision(precision);
+    else
+      handler.on_error("number is too big");
+  } else if (c == '{') {
+    ++begin;
+    if (begin != end)
+      begin = parse_arg_id(begin, end, precision_adapter{handler});
+    if (begin == end || *begin++ != '}')
+      return handler.on_error("invalid format string"), begin;
+  } else {
+    return handler.on_error("missing precision specifier"), begin;
+  }
+  handler.end_precision();
+  return begin;
+}
+
+template <typename Char>
+FMT_CONSTEXPR auto parse_presentation_type(Char type) -> presentation_type {
+  switch (to_ascii(type)) {
+  case 'd':
+    return presentation_type::dec;
+  case 'o':
+    return presentation_type::oct;
+  case 'x':
+    return presentation_type::hex_lower;
+  case 'X':
+    return presentation_type::hex_upper;
+  case 'b':
+    return presentation_type::bin_lower;
+  case 'B':
+    return presentation_type::bin_upper;
+  case 'a':
+    return presentation_type::hexfloat_lower;
+  case 'A':
+    return presentation_type::hexfloat_upper;
+  case 'e':
+    return presentation_type::exp_lower;
+  case 'E':
+    return presentation_type::exp_upper;
+  case 'f':
+    return presentation_type::fixed_lower;
+  case 'F':
+    return presentation_type::fixed_upper;
+  case 'g':
+    return presentation_type::general_lower;
+  case 'G':
+    return presentation_type::general_upper;
+  case 'c':
+    return presentation_type::chr;
+  case 's':
+    return presentation_type::string;
+  case 'p':
+    return presentation_type::pointer;
+  default:
+    return presentation_type::none;
+  }
+}
+
+// Parses standard format specifiers and sends notifications about parsed
+// components to handler.
+template <typename Char, typename SpecHandler>
+FMT_CONSTEXPR FMT_INLINE auto parse_format_specs(const Char* begin,
+                                                 const Char* end,
+                                                 SpecHandler&& handler)
+    -> const Char* {
+  if (1 < end - begin && begin[1] == '}' && is_ascii_letter(*begin) &&
+      *begin != 'L') {
+    presentation_type type = parse_presentation_type(*begin++);
+    if (type == presentation_type::none)
+      handler.on_error("invalid type specifier");
+    handler.on_type(type);
+    return begin;
+  }
+
+  if (begin == end) return begin;
+
+  begin = parse_align(begin, end, handler);
+  if (begin == end) return begin;
+
+  // Parse sign.
+  switch (to_ascii(*begin)) {
+  case '+':
+    handler.on_sign(sign::plus);
+    ++begin;
+    break;
+  case '-':
+    handler.on_sign(sign::minus);
+    ++begin;
+    break;
+  case ' ':
+    handler.on_sign(sign::space);
+    ++begin;
+    break;
+  default:
+    break;
+  }
+  if (begin == end) return begin;
+
+  if (*begin == '#') {
+    handler.on_hash();
+    if (++begin == end) return begin;
+  }
+
+  // Parse zero flag.
+  if (*begin == '0') {
+    handler.on_zero();
+    if (++begin == end) return begin;
+  }
+
+  begin = parse_width(begin, end, handler);
+  if (begin == end) return begin;
+
+  // Parse precision.
+  if (*begin == '.') {
+    begin = parse_precision(begin, end, handler);
+    if (begin == end) return begin;
+  }
+
+  if (*begin == 'L') {
+    handler.on_localized();
+    ++begin;
+  }
+
+  // Parse type.
+  if (begin != end && *begin != '}') {
+    presentation_type type = parse_presentation_type(*begin++);
+    if (type == presentation_type::none)
+      handler.on_error("invalid type specifier");
+    handler.on_type(type);
+  }
+  return begin;
+}
+
+template <typename Char, typename Handler>
+FMT_CONSTEXPR auto parse_replacement_field(const Char* begin, const Char* end,
+                                           Handler&& handler) -> const Char* {
+  struct id_adapter {
+    Handler& handler;
+    int arg_id;
+
+    FMT_CONSTEXPR void operator()() { arg_id = handler.on_arg_id(); }
+    FMT_CONSTEXPR void operator()(int id) { arg_id = handler.on_arg_id(id); }
+    FMT_CONSTEXPR void operator()(basic_string_view<Char> id) {
+      arg_id = handler.on_arg_id(id);
+    }
+    FMT_CONSTEXPR void on_error(const char* message) {
+      if (message) handler.on_error(message);
+    }
+  };
+
+  ++begin;
+  if (begin == end) return handler.on_error("invalid format string"), end;
+  if (*begin == '}') {
+    handler.on_replacement_field(handler.on_arg_id(), begin);
+  } else if (*begin == '{') {
+    handler.on_text(begin, begin + 1);
+  } else {
+    auto adapter = id_adapter{handler, 0};
+    begin = parse_arg_id(begin, end, adapter);
+    Char c = begin != end ? *begin : Char();
+    if (c == '}') {
+      handler.on_replacement_field(adapter.arg_id, begin);
+    } else if (c == ':') {
+      begin = handler.on_format_specs(adapter.arg_id, begin + 1, end);
+      if (begin == end || *begin != '}')
+        return handler.on_error("unknown format specifier"), end;
+    } else {
+      return handler.on_error("missing '}' in format string"), end;
+    }
+  }
+  return begin + 1;
+}
+
+template <bool IS_CONSTEXPR, typename Char, typename Handler>
+FMT_CONSTEXPR FMT_INLINE void parse_format_string(
+    basic_string_view<Char> format_str, Handler&& handler) {
+  // Workaround a name-lookup bug in MSVC's modules implementation.
+  using detail::find;
+
+  auto begin = format_str.data();
+  auto end = begin + format_str.size();
+  if (end - begin < 32) {
+    // Use a simple loop instead of memchr for small strings.
+    const Char* p = begin;
+    while (p != end) {
+      auto c = *p++;
+      if (c == '{') {
+        handler.on_text(begin, p - 1);
+        begin = p = parse_replacement_field(p - 1, end, handler);
+      } else if (c == '}') {
+        if (p == end || *p != '}')
+          return handler.on_error("unmatched '}' in format string");
+        handler.on_text(begin, p);
+        begin = ++p;
+      }
+    }
+    handler.on_text(begin, end);
+    return;
+  }
+  struct writer {
+    FMT_CONSTEXPR void operator()(const Char* pbegin, const Char* pend) {
+      if (pbegin == pend) return;
+      for (;;) {
+        const Char* p = nullptr;
+        if (!find<IS_CONSTEXPR>(pbegin, pend, Char('}'), p))
+          return handler_.on_text(pbegin, pend);
+        ++p;
+        if (p == pend || *p != '}')
+          return handler_.on_error("unmatched '}' in format string");
+        handler_.on_text(pbegin, p);
+        pbegin = p + 1;
+      }
+    }
+    Handler& handler_;
+  } write{handler};
+  while (begin != end) {
+    // Doing two passes with memchr (one for '{' and another for '}') is up to
+    // 2.5x faster than the naive one-pass implementation on big format strings.
+    const Char* p = begin;
+    if (*begin != '{' && !find<IS_CONSTEXPR>(begin + 1, end, Char('{'), p))
+      return write(begin, end);
+    write(begin, p);
+    begin = parse_replacement_field(p, end, handler);
+  }
+}
+
+template <typename T, typename ParseContext>
+FMT_CONSTEXPR auto parse_format_specs(ParseContext& ctx)
+    -> decltype(ctx.begin()) {
+  using char_type = typename ParseContext::char_type;
+  using context = buffer_context<char_type>;
+  using mapped_type = conditional_t<
+      mapped_type_constant<T, context>::value != type::custom_type,
+      decltype(arg_mapper<context>().map(std::declval<const T&>())), T>;
+  auto f = conditional_t<has_formatter<mapped_type, context>::value,
+                         formatter<mapped_type, char_type>,
+                         fallback_formatter<T, char_type>>();
+  return f.parse(ctx);
+}
+
+// A parse context with extra argument id checks. It is only used at compile
+// time because adding checks at runtime would introduce substantial overhead
+// and would be redundant since argument ids are checked when arguments are
+// retrieved anyway.
+template <typename Char, typename ErrorHandler = error_handler>
+class compile_parse_context
+    : public basic_format_parse_context<Char, ErrorHandler> {
+ private:
+  int num_args_;
+  using base = basic_format_parse_context<Char, ErrorHandler>;
+
+ public:
+  explicit FMT_CONSTEXPR compile_parse_context(
+      basic_string_view<Char> format_str,
+      int num_args = (std::numeric_limits<int>::max)(), ErrorHandler eh = {})
+      : base(format_str, eh), num_args_(num_args) {}
+
+  FMT_CONSTEXPR auto next_arg_id() -> int {
+    int id = base::next_arg_id();
+    if (id >= num_args_) this->on_error("argument not found");
+    return id;
+  }
+
+  FMT_CONSTEXPR void check_arg_id(int id) {
+    base::check_arg_id(id);
+    if (id >= num_args_) this->on_error("argument not found");
+  }
+  using base::check_arg_id;
+};
+
+template <typename ErrorHandler>
+FMT_CONSTEXPR void check_int_type_spec(presentation_type type,
+                                       ErrorHandler&& eh) {
+  if (type > presentation_type::bin_upper && type != presentation_type::chr)
+    eh.on_error("invalid type specifier");
+}
+
+// Checks char specs and returns true if the type spec is char (and not int).
+template <typename Char, typename ErrorHandler = error_handler>
+FMT_CONSTEXPR auto check_char_specs(const basic_format_specs<Char>& specs,
+                                    ErrorHandler&& eh = {}) -> bool {
+  if (specs.type != presentation_type::none &&
+      specs.type != presentation_type::chr) {
+    check_int_type_spec(specs.type, eh);
+    return false;
+  }
+  if (specs.align == align::numeric || specs.sign != sign::none || specs.alt)
+    eh.on_error("invalid format specifier for char");
+  return true;
+}
+
+// A floating-point presentation format.
+enum class float_format : unsigned char {
+  general,  // General: exponent notation or fixed point based on magnitude.
+  exp,      // Exponent notation with the default precision of 6, e.g. 1.2e-3.
+  fixed,    // Fixed point with the default precision of 6, e.g. 0.0012.
+  hex
+};
+
+struct float_specs {
+  int precision;
+  float_format format : 8;
+  sign_t sign : 8;
+  bool upper : 1;
+  bool locale : 1;
+  bool binary32 : 1;
+  bool fallback : 1;
+  bool showpoint : 1;
+};
+
+template <typename ErrorHandler = error_handler, typename Char>
+FMT_CONSTEXPR auto parse_float_type_spec(const basic_format_specs<Char>& specs,
+                                         ErrorHandler&& eh = {})
+    -> float_specs {
+  auto result = float_specs();
+  result.showpoint = specs.alt;
+  result.locale = specs.localized;
+  switch (specs.type) {
+  case presentation_type::none:
+    result.format = float_format::general;
+    break;
+  case presentation_type::general_upper:
+    result.upper = true;
+    FMT_FALLTHROUGH;
+  case presentation_type::general_lower:
+    result.format = float_format::general;
+    break;
+  case presentation_type::exp_upper:
+    result.upper = true;
+    FMT_FALLTHROUGH;
+  case presentation_type::exp_lower:
+    result.format = float_format::exp;
+    result.showpoint |= specs.precision != 0;
+    break;
+  case presentation_type::fixed_upper:
+    result.upper = true;
+    FMT_FALLTHROUGH;
+  case presentation_type::fixed_lower:
+    result.format = float_format::fixed;
+    result.showpoint |= specs.precision != 0;
+    break;
+  case presentation_type::hexfloat_upper:
+    result.upper = true;
+    FMT_FALLTHROUGH;
+  case presentation_type::hexfloat_lower:
+    result.format = float_format::hex;
+    break;
+  default:
+    eh.on_error("invalid type specifier");
+    break;
+  }
+  return result;
+}
+
+template <typename ErrorHandler = error_handler>
+FMT_CONSTEXPR auto check_cstring_type_spec(presentation_type type,
+                                           ErrorHandler&& eh = {}) -> bool {
+  if (type == presentation_type::none || type == presentation_type::string)
+    return true;
+  if (type != presentation_type::pointer) eh.on_error("invalid type specifier");
+  return false;
+}
+
+template <typename ErrorHandler = error_handler>
+FMT_CONSTEXPR void check_string_type_spec(presentation_type type,
+                                          ErrorHandler&& eh = {}) {
+  if (type != presentation_type::none && type != presentation_type::string)
+    eh.on_error("invalid type specifier");
+}
+
+template <typename ErrorHandler>
+FMT_CONSTEXPR void check_pointer_type_spec(presentation_type type,
+                                           ErrorHandler&& eh) {
+  if (type != presentation_type::none && type != presentation_type::pointer)
+    eh.on_error("invalid type specifier");
+}
+
+// A parse_format_specs handler that checks if specifiers are consistent with
+// the argument type.
+template <typename Handler> class specs_checker : public Handler {
+ private:
+  detail::type arg_type_;
+
+  FMT_CONSTEXPR void require_numeric_argument() {
+    if (!is_arithmetic_type(arg_type_))
+      this->on_error("format specifier requires numeric argument");
+  }
+
+ public:
+  FMT_CONSTEXPR specs_checker(const Handler& handler, detail::type arg_type)
+      : Handler(handler), arg_type_(arg_type) {}
+
+  FMT_CONSTEXPR void on_align(align_t align) {
+    if (align == align::numeric) require_numeric_argument();
+    Handler::on_align(align);
+  }
+
+  FMT_CONSTEXPR void on_sign(sign_t s) {
+    require_numeric_argument();
+    if (is_integral_type(arg_type_) && arg_type_ != type::int_type &&
+        arg_type_ != type::long_long_type && arg_type_ != type::char_type) {
+      this->on_error("format specifier requires signed argument");
+    }
+    Handler::on_sign(s);
+  }
+
+  FMT_CONSTEXPR void on_hash() {
+    require_numeric_argument();
+    Handler::on_hash();
+  }
+
+  FMT_CONSTEXPR void on_localized() {
+    require_numeric_argument();
+    Handler::on_localized();
+  }
+
+  FMT_CONSTEXPR void on_zero() {
+    require_numeric_argument();
+    Handler::on_zero();
+  }
+
+  FMT_CONSTEXPR void end_precision() {
+    if (is_integral_type(arg_type_) || arg_type_ == type::pointer_type)
+      this->on_error("precision not allowed for this argument type");
+  }
 };
+
+constexpr int invalid_arg_index = -1;
+
+#if FMT_USE_NONTYPE_TEMPLATE_PARAMETERS
+template <int N, typename T, typename... Args, typename Char>
+constexpr auto get_arg_index_by_name(basic_string_view<Char> name) -> int {
+  if constexpr (detail::is_statically_named_arg<T>()) {
+    if (name == T::name) return N;
+  }
+  if constexpr (sizeof...(Args) > 0)
+    return get_arg_index_by_name<N + 1, Args...>(name);
+  (void)name;  // Workaround an MSVC bug about "unused" parameter.
+  return invalid_arg_index;
+}
 #endif
 
-namespace detail {
+template <typename... Args, typename Char>
+FMT_CONSTEXPR auto get_arg_index_by_name(basic_string_view<Char> name) -> int {
+#if FMT_USE_NONTYPE_TEMPLATE_PARAMETERS
+  if constexpr (sizeof...(Args) > 0)
+    return get_arg_index_by_name<0, Args...>(name);
+#endif
+  (void)name;
+  return invalid_arg_index;
+}
 
-template <typename Char, FMT_ENABLE_IF(!std::is_same<Char, char>::value)>
-std::basic_string<Char> vformat(
-    basic_string_view<Char> format_str,
-    basic_format_args<buffer_context<type_identity_t<Char>>> args);
+template <typename Char, typename ErrorHandler, typename... Args>
+class format_string_checker {
+ private:
+  using parse_context_type = compile_parse_context<Char, ErrorHandler>;
+  enum { num_args = sizeof...(Args) };
 
-FMT_API std::string vformat(string_view format_str, format_args args);
+  // Format specifier parsing function.
+  using parse_func = const Char* (*)(parse_context_type&);
+
+  parse_context_type context_;
+  parse_func parse_funcs_[num_args > 0 ? num_args : 1];
+
+ public:
+  explicit FMT_CONSTEXPR format_string_checker(
+      basic_string_view<Char> format_str, ErrorHandler eh)
+      : context_(format_str, num_args, eh),
+        parse_funcs_{&parse_format_specs<Args, parse_context_type>...} {}
+
+  FMT_CONSTEXPR void on_text(const Char*, const Char*) {}
+
+  FMT_CONSTEXPR auto on_arg_id() -> int { return context_.next_arg_id(); }
+  FMT_CONSTEXPR auto on_arg_id(int id) -> int {
+    return context_.check_arg_id(id), id;
+  }
+  FMT_CONSTEXPR auto on_arg_id(basic_string_view<Char> id) -> int {
+#if FMT_USE_NONTYPE_TEMPLATE_PARAMETERS
+    auto index = get_arg_index_by_name<Args...>(id);
+    if (index == invalid_arg_index) on_error("named argument is not found");
+    return context_.check_arg_id(index), index;
+#else
+    (void)id;
+    on_error("compile-time checks for named arguments require C++20 support");
+    return 0;
+#endif
+  }
+
+  FMT_CONSTEXPR void on_replacement_field(int, const Char*) {}
+
+  FMT_CONSTEXPR auto on_format_specs(int id, const Char* begin, const Char*)
+      -> const Char* {
+    context_.advance_to(context_.begin() + (begin - &*context_.begin()));
+    // id >= 0 check is a workaround for gcc 10 bug (#2065).
+    return id >= 0 && id < num_args ? parse_funcs_[id](context_) : begin;
+  }
+
+  FMT_CONSTEXPR void on_error(const char* message) {
+    context_.on_error(message);
+  }
+};
+
+template <typename... Args, typename S,
+          enable_if_t<(is_compile_string<S>::value), int>>
+void check_format_string(S format_str) {
+  FMT_CONSTEXPR auto s = to_string_view(format_str);
+  using checker = format_string_checker<typename S::char_type, error_handler,
+                                        remove_cvref_t<Args>...>;
+  FMT_CONSTEXPR bool invalid_format =
+      (parse_format_string<true>(s, checker(s, {})), true);
+  ignore_unused(invalid_format);
+}
 
 template <typename Char>
 void vformat_to(
-    buffer<Char>& buf, basic_string_view<Char> format_str,
+    buffer<Char>& buf, basic_string_view<Char> fmt,
     basic_format_args<FMT_BUFFER_CONTEXT(type_identity_t<Char>)> args,
-    detail::locale_ref loc = {});
-
-template <typename Char, typename Args,
-          FMT_ENABLE_IF(!std::is_same<Char, char>::value)>
-inline void vprint_mojibake(std::FILE*, basic_string_view<Char>, const Args&) {}
+    locale_ref loc = {});
 
 FMT_API void vprint_mojibake(std::FILE*, string_view, format_args);
 #ifndef _WIN32
 inline void vprint_mojibake(std::FILE*, string_view, format_args) {}
 #endif
-}  // namespace detail
+FMT_END_DETAIL_NAMESPACE
+
+// A formatter specialization for the core types corresponding to detail::type
+// constants.
+template <typename T, typename Char>
+struct formatter<T, Char,
+                 enable_if_t<detail::type_constant<T, Char>::value !=
+                             detail::type::custom_type>> {
+ private:
+  detail::dynamic_format_specs<Char> specs_;
+
+ public:
+  // Parses format specifiers stopping either at the end of the range or at the
+  // terminating '}'.
+  template <typename ParseContext>
+  FMT_CONSTEXPR auto parse(ParseContext& ctx) -> decltype(ctx.begin()) {
+    auto begin = ctx.begin(), end = ctx.end();
+    if (begin == end) return begin;
+    using handler_type = detail::dynamic_specs_handler<ParseContext>;
+    auto type = detail::type_constant<T, Char>::value;
+    auto checker =
+        detail::specs_checker<handler_type>(handler_type(specs_, ctx), type);
+    auto it = detail::parse_format_specs(begin, end, checker);
+    auto eh = ctx.error_handler();
+    switch (type) {
+    case detail::type::none_type:
+      FMT_ASSERT(false, "invalid argument type");
+      break;
+    case detail::type::bool_type:
+      if (specs_.type == presentation_type::none ||
+          specs_.type == presentation_type::string) {
+        break;
+      }
+      FMT_FALLTHROUGH;
+    case detail::type::int_type:
+    case detail::type::uint_type:
+    case detail::type::long_long_type:
+    case detail::type::ulong_long_type:
+    case detail::type::int128_type:
+    case detail::type::uint128_type:
+      detail::check_int_type_spec(specs_.type, eh);
+      break;
+    case detail::type::char_type:
+      detail::check_char_specs(specs_, eh);
+      break;
+    case detail::type::float_type:
+      if (detail::const_check(FMT_USE_FLOAT))
+        detail::parse_float_type_spec(specs_, eh);
+      else
+        FMT_ASSERT(false, "float support disabled");
+      break;
+    case detail::type::double_type:
+      if (detail::const_check(FMT_USE_DOUBLE))
+        detail::parse_float_type_spec(specs_, eh);
+      else
+        FMT_ASSERT(false, "double support disabled");
+      break;
+    case detail::type::long_double_type:
+      if (detail::const_check(FMT_USE_LONG_DOUBLE))
+        detail::parse_float_type_spec(specs_, eh);
+      else
+        FMT_ASSERT(false, "long double support disabled");
+      break;
+    case detail::type::cstring_type:
+      detail::check_cstring_type_spec(specs_.type, eh);
+      break;
+    case detail::type::string_type:
+      detail::check_string_type_spec(specs_.type, eh);
+      break;
+    case detail::type::pointer_type:
+      detail::check_pointer_type_spec(specs_.type, eh);
+      break;
+    case detail::type::custom_type:
+      // Custom format specifiers are checked in parse functions of
+      // formatter specializations.
+      break;
+    }
+    return it;
+  }
+
+  template <typename FormatContext>
+  FMT_CONSTEXPR auto format(const T& val, FormatContext& ctx) const
+      -> decltype(ctx.out());
+};
+
+template <typename Char> struct basic_runtime { basic_string_view<Char> str; };
+
+/** A compile-time format string. */
+template <typename Char, typename... Args> class basic_format_string {
+ private:
+  basic_string_view<Char> str_;
+
+ public:
+  template <typename S,
+            FMT_ENABLE_IF(
+                std::is_convertible<const S&, basic_string_view<Char>>::value)>
+  FMT_CONSTEVAL FMT_INLINE basic_format_string(const S& s) : str_(s) {
+    static_assert(
+        detail::count<
+            (std::is_base_of<detail::view, remove_reference_t<Args>>::value &&
+             std::is_reference<Args>::value)...>() == 0,
+        "passing views as lvalues is disallowed");
+#ifdef FMT_HAS_CONSTEVAL
+    if constexpr (detail::count_named_args<Args...>() ==
+                  detail::count_statically_named_args<Args...>()) {
+      using checker = detail::format_string_checker<Char, detail::error_handler,
+                                                    remove_cvref_t<Args>...>;
+      detail::parse_format_string<true>(str_, checker(s, {}));
+    }
+#else
+    detail::check_format_string<Args...>(s);
+#endif
+  }
+  basic_format_string(basic_runtime<Char> r) : str_(r.str) {}
+
+  FMT_INLINE operator basic_string_view<Char>() const { return str_; }
+};
+
+#if FMT_GCC_VERSION && FMT_GCC_VERSION < 409
+// Workaround broken conversion on older gcc.
+template <typename... Args> using format_string = string_view;
+template <typename S> auto runtime(const S& s) -> basic_string_view<char_t<S>> {
+  return s;
+}
+#else
+template <typename... Args>
+using format_string = basic_format_string<char, type_identity_t<Args>...>;
+/**
+  \rst
+  Creates a runtime format string.
+
+  **Example**::
+
+    // Check format string at runtime instead of compile-time.
+    fmt::print(fmt::runtime("{:d}"), "I am not a number");
+  \endrst
+ */
+template <typename S> auto runtime(const S& s) -> basic_runtime<char_t<S>> {
+  return {{s}};
+}
+#endif
+
+FMT_API auto vformat(string_view fmt, format_args args) -> std::string;
+
+/**
+  \rst
+  Formats ``args`` according to specifications in ``fmt`` and returns the result
+  as a string.
+
+  **Example**::
+
+    #include <fmt/core.h>
+    std::string message = fmt::format("The answer is {}.", 42);
+  \endrst
+*/
+template <typename... T>
+FMT_NODISCARD FMT_INLINE auto format(format_string<T...> fmt, T&&... args)
+    -> std::string {
+  return vformat(fmt, fmt::make_format_args(args...));
+}
 
 /** Formats a string and writes the output to ``out``. */
-// GCC 8 and earlier cannot handle std::back_insert_iterator<Container> with
-// vformat_to<ArgFormatter>(...) overload, so SFINAE on iterator type instead.
-template <typename OutputIt, typename S, typename Char = char_t<S>,
-          bool enable = detail::is_output_iterator<OutputIt, Char>::value>
-auto vformat_to(OutputIt out, const S& format_str,
-                basic_format_args<buffer_context<type_identity_t<Char>>> args)
-    -> typename std::enable_if<enable, OutputIt>::type {
-  decltype(detail::get_buffer<Char>(out)) buf(detail::get_buffer_init(out));
-  detail::vformat_to(buf, to_string_view(format_str), args);
+template <typename OutputIt,
+          FMT_ENABLE_IF(detail::is_output_iterator<OutputIt, char>::value)>
+auto vformat_to(OutputIt out, string_view fmt, format_args args) -> OutputIt {
+  using detail::get_buffer;
+  auto&& buf = get_buffer<char>(out);
+  detail::vformat_to(buf, fmt, args, {});
   return detail::get_iterator(buf);
 }
 
 /**
  \rst
- Formats arguments, writes the result to the output iterator ``out`` and returns
- the iterator past the end of the output range.
+ Formats ``args`` according to specifications in ``fmt``, writes the result to
+ the output iterator ``out`` and returns the iterator past the end of the output
+ range. `format_to` does not append a terminating null character.
 
  **Example**::
 
-   std::vector<char> out;
+   auto out = std::vector<char>();
    fmt::format_to(std::back_inserter(out), "{}", 42);
  \endrst
  */
-// We cannot use FMT_ENABLE_IF because of a bug in gcc 8.3.
-template <typename OutputIt, typename S, typename... Args,
-          bool enable = detail::is_output_iterator<OutputIt, char_t<S>>::value>
-inline auto format_to(OutputIt out, const S& format_str, Args&&... args) ->
-    typename std::enable_if<enable, OutputIt>::type {
-  const auto& vargs = fmt::make_args_checked<Args...>(format_str, args...);
-  return vformat_to(out, to_string_view(format_str), vargs);
+template <typename OutputIt, typename... T,
+          FMT_ENABLE_IF(detail::is_output_iterator<OutputIt, char>::value)>
+FMT_INLINE auto format_to(OutputIt out, format_string<T...> fmt, T&&... args)
+    -> OutputIt {
+  return vformat_to(out, fmt, fmt::make_format_args(args...));
 }
 
 template <typename OutputIt> struct format_to_n_result {
   /** Iterator past the end of the output range. */
   OutputIt out;
   /** Total (not truncated) output size. */
   size_t size;
 };
 
-template <typename OutputIt, typename Char, typename... Args,
-          FMT_ENABLE_IF(detail::is_output_iterator<OutputIt, Char>::value)>
-inline format_to_n_result<OutputIt> vformat_to_n(
-    OutputIt out, size_t n, basic_string_view<Char> format_str,
-    basic_format_args<buffer_context<type_identity_t<Char>>> args) {
-  detail::iterator_buffer<OutputIt, Char, detail::fixed_buffer_traits> buf(out,
-                                                                           n);
-  detail::vformat_to(buf, format_str, args);
+template <typename OutputIt, typename... T,
+          FMT_ENABLE_IF(detail::is_output_iterator<OutputIt, char>::value)>
+auto vformat_to_n(OutputIt out, size_t n, string_view fmt, format_args args)
+    -> format_to_n_result<OutputIt> {
+  using traits = detail::fixed_buffer_traits;
+  auto buf = detail::iterator_buffer<OutputIt, char, traits>(out, n);
+  detail::vformat_to(buf, fmt, args, {});
   return {buf.out(), buf.count()};
 }
 
 /**
- \rst
- Formats arguments, writes up to ``n`` characters of the result to the output
- iterator ``out`` and returns the total output size and the iterator past the
- end of the output range.
- \endrst
+  \rst
+  Formats ``args`` according to specifications in ``fmt``, writes up to ``n``
+  characters of the result to the output iterator ``out`` and returns the total
+  (not truncated) output size and the iterator past the end of the output range.
+  `format_to_n` does not append a terminating null character.
+  \endrst
  */
-template <typename OutputIt, typename S, typename... Args,
-          bool enable = detail::is_output_iterator<OutputIt, char_t<S>>::value>
-inline auto format_to_n(OutputIt out, size_t n, const S& format_str,
-                        const Args&... args) ->
-    typename std::enable_if<enable, format_to_n_result<OutputIt>>::type {
-  const auto& vargs = fmt::make_args_checked<Args...>(format_str, args...);
-  return vformat_to_n(out, n, to_string_view(format_str), vargs);
+template <typename OutputIt, typename... T,
+          FMT_ENABLE_IF(detail::is_output_iterator<OutputIt, char>::value)>
+FMT_INLINE auto format_to_n(OutputIt out, size_t n, format_string<T...> fmt,
+                            T&&... args) -> format_to_n_result<OutputIt> {
+  return vformat_to_n(out, n, fmt, fmt::make_format_args(args...));
 }
 
-/**
-  Returns the number of characters in the output of
-  ``format(format_str, args...)``.
- */
-template <typename... Args>
-inline size_t formatted_size(string_view format_str, Args&&... args) {
-  const auto& vargs = fmt::make_args_checked<Args...>(format_str, args...);
-  detail::counting_buffer<> buf;
-  detail::vformat_to(buf, format_str, vargs);
+/** Returns the number of chars in the output of ``format(fmt, args...)``. */
+template <typename... T>
+FMT_NODISCARD FMT_INLINE auto formatted_size(format_string<T...> fmt,
+                                             T&&... args) -> size_t {
+  auto buf = detail::counting_buffer<>();
+  detail::vformat_to(buf, string_view(fmt), fmt::make_format_args(args...), {});
   return buf.count();
 }
 
-template <typename S, typename Char = char_t<S>>
-FMT_INLINE std::basic_string<Char> vformat(
-    const S& format_str,
-    basic_format_args<buffer_context<type_identity_t<Char>>> args) {
-  return detail::vformat(to_string_view(format_str), args);
-}
+FMT_API void vprint(string_view fmt, format_args args);
+FMT_API void vprint(std::FILE* f, string_view fmt, format_args args);
 
 /**
   \rst
-  Formats arguments and returns the result as a string.
+  Formats ``args`` according to specifications in ``fmt`` and writes the output
+  to ``stdout``.
 
   **Example**::
 
-    #include <fmt/core.h>
-    std::string message = fmt::format("The answer is {}", 42);
+    fmt::print("Elapsed time: {0:.2f} seconds", 1.23);
   \endrst
-*/
-// Pass char_t as a default template parameter instead of using
-// std::basic_string<char_t<S>> to reduce the symbol size.
-template <typename S, typename... Args, typename Char = char_t<S>>
-FMT_INLINE std::basic_string<Char> format(const S& format_str, Args&&... args) {
-  const auto& vargs = fmt::make_args_checked<Args...>(format_str, args...);
-  return detail::vformat(to_string_view(format_str), vargs);
+ */
+template <typename... T>
+FMT_INLINE void print(format_string<T...> fmt, T&&... args) {
+  const auto& vargs = fmt::make_format_args(args...);
+  return detail::is_utf8() ? vprint(fmt, vargs)
+                           : detail::vprint_mojibake(stdout, fmt, vargs);
 }
 
-FMT_API void vprint(string_view, format_args);
-FMT_API void vprint(std::FILE*, string_view, format_args);
-
 /**
   \rst
-  Formats ``args`` according to specifications in ``format_str`` and writes the
-  output to the file ``f``. Strings are assumed to be Unicode-encoded unless the
-  ``FMT_UNICODE`` macro is set to 0.
+  Formats ``args`` according to specifications in ``fmt`` and writes the
+  output to the file ``f``.
 
   **Example**::
 
     fmt::print(stderr, "Don't {}!", "panic");
   \endrst
  */
-template <typename S, typename... Args, typename Char = char_t<S>>
-inline void print(std::FILE* f, const S& format_str, Args&&... args) {
-  const auto& vargs = fmt::make_args_checked<Args...>(format_str, args...);
-  return detail::is_unicode<Char>()
-             ? vprint(f, to_string_view(format_str), vargs)
-             : detail::vprint_mojibake(f, to_string_view(format_str), vargs);
+template <typename... T>
+FMT_INLINE void print(std::FILE* f, format_string<T...> fmt, T&&... args) {
+  const auto& vargs = fmt::make_format_args(args...);
+  return detail::is_utf8() ? vprint(f, fmt, vargs)
+                           : detail::vprint_mojibake(f, fmt, vargs);
 }
 
-/**
-  \rst
-  Formats ``args`` according to specifications in ``format_str`` and writes
-  the output to ``stdout``. Strings are assumed to be Unicode-encoded unless
-  the ``FMT_UNICODE`` macro is set to 0.
-
-  **Example**::
-
-    fmt::print("Elapsed time: {0:.2f} seconds", 1.23);
-  \endrst
- */
-template <typename S, typename... Args, typename Char = char_t<S>>
-inline void print(const S& format_str, Args&&... args) {
-  const auto& vargs = fmt::make_args_checked<Args...>(format_str, args...);
-  return detail::is_unicode<Char>()
-             ? vprint(to_string_view(format_str), vargs)
-             : detail::vprint_mojibake(stdout, to_string_view(format_str),
-                                       vargs);
-}
+FMT_MODULE_EXPORT_END
+FMT_GCC_PRAGMA("GCC pop_options")
 FMT_END_NAMESPACE
 
+#ifdef FMT_HEADER_ONLY
+#  include "format.h"
+#endif
 #endif  // FMT_CORE_H_
```

### Comparing `lightgbm-3.3.5/compile/external_libs/fmt/include/fmt/format-inl.h` & `lightgbm-4.0.0/external_libs/fmt/include/fmt/format-inl.h`

 * *Files 8% similar despite different names*

```diff
@@ -4,16 +4,17 @@
 // All rights reserved.
 //
 // For the license information refer to format.h.
 
 #ifndef FMT_FORMAT_INL_H_
 #define FMT_FORMAT_INL_H_
 
-#include <cassert>
+#include <algorithm>
 #include <cctype>
+#include <cerrno>  // errno
 #include <climits>
 #include <cmath>
 #include <cstdarg>
 #include <cstring>  // std::memmove
 #include <cwchar>
 #include <exception>
 
@@ -23,114 +24,43 @@
 
 #ifdef _WIN32
 #  include <io.h>  // _isatty
 #endif
 
 #include "format.h"
 
-// Dummy implementations of strerror_r and strerror_s called if corresponding
-// system functions are not available.
-inline fmt::detail::null<> strerror_r(int, char*, ...) { return {}; }
-inline fmt::detail::null<> strerror_s(char*, size_t, ...) { return {}; }
-
 FMT_BEGIN_NAMESPACE
 namespace detail {
 
 FMT_FUNC void assert_fail(const char* file, int line, const char* message) {
   // Use unchecked std::fprintf to avoid triggering another assertion when
   // writing to stderr fails
   std::fprintf(stderr, "%s:%d: assertion failed: %s", file, line, message);
   // Chosen instead of std::abort to satisfy Clang in CUDA mode during device
   // code pass.
   std::terminate();
 }
 
+FMT_FUNC void throw_format_error(const char* message) {
+  FMT_THROW(format_error(message));
+}
+
 #ifndef _MSC_VER
 #  define FMT_SNPRINTF snprintf
 #else  // _MSC_VER
 inline int fmt_snprintf(char* buffer, size_t size, const char* format, ...) {
   va_list args;
   va_start(args, format);
   int result = vsnprintf_s(buffer, size, _TRUNCATE, format, args);
   va_end(args);
   return result;
 }
 #  define FMT_SNPRINTF fmt_snprintf
 #endif  // _MSC_VER
 
-// A portable thread-safe version of strerror.
-// Sets buffer to point to a string describing the error code.
-// This can be either a pointer to a string stored in buffer,
-// or a pointer to some static immutable string.
-// Returns one of the following values:
-//   0      - success
-//   ERANGE - buffer is not large enough to store the error message
-//   other  - failure
-// Buffer should be at least of size 1.
-inline int safe_strerror(int error_code, char*& buffer,
-                         size_t buffer_size) FMT_NOEXCEPT {
-  FMT_ASSERT(buffer != nullptr && buffer_size != 0, "invalid buffer");
-
-  class dispatcher {
-   private:
-    int error_code_;
-    char*& buffer_;
-    size_t buffer_size_;
-
-    // A noop assignment operator to avoid bogus warnings.
-    void operator=(const dispatcher&) {}
-
-    // Handle the result of XSI-compliant version of strerror_r.
-    int handle(int result) {
-      // glibc versions before 2.13 return result in errno.
-      return result == -1 ? errno : result;
-    }
-
-    // Handle the result of GNU-specific version of strerror_r.
-    FMT_MAYBE_UNUSED
-    int handle(char* message) {
-      // If the buffer is full then the message is probably truncated.
-      if (message == buffer_ && strlen(buffer_) == buffer_size_ - 1)
-        return ERANGE;
-      buffer_ = message;
-      return 0;
-    }
-
-    // Handle the case when strerror_r is not available.
-    FMT_MAYBE_UNUSED
-    int handle(detail::null<>) {
-      return fallback(strerror_s(buffer_, buffer_size_, error_code_));
-    }
-
-    // Fallback to strerror_s when strerror_r is not available.
-    FMT_MAYBE_UNUSED
-    int fallback(int result) {
-      // If the buffer is full then the message is probably truncated.
-      return result == 0 && strlen(buffer_) == buffer_size_ - 1 ? ERANGE
-                                                                : result;
-    }
-
-#if !FMT_MSC_VER
-    // Fallback to strerror if strerror_r and strerror_s are not available.
-    int fallback(detail::null<>) {
-      errno = 0;
-      buffer_ = strerror(error_code_);
-      return errno;
-    }
-#endif
-
-   public:
-    dispatcher(int err_code, char*& buf, size_t buf_size)
-        : error_code_(err_code), buffer_(buf), buffer_size_(buf_size) {}
-
-    int run() { return handle(strerror_r(error_code_, buffer_, buffer_size_)); }
-  };
-  return dispatcher(error_code, buffer, buffer_size).run();
-}
-
 FMT_FUNC void format_error_code(detail::buffer<char>& out, int error_code,
                                 string_view message) FMT_NOEXCEPT {
   // Report error code making sure that the output fits into
   // inline_buffer_size to avoid dynamic memory allocation and potential
   // bad_alloc.
   out.try_resize(0);
   static const char SEP[] = ": ";
@@ -141,1045 +71,244 @@
   if (detail::is_negative(error_code)) {
     abs_value = 0 - abs_value;
     ++error_code_size;
   }
   error_code_size += detail::to_unsigned(detail::count_digits(abs_value));
   auto it = buffer_appender<char>(out);
   if (message.size() <= inline_buffer_size - error_code_size)
-    format_to(it, "{}{}", message, SEP);
-  format_to(it, "{}{}", ERROR_STR, error_code);
-  assert(out.size() <= inline_buffer_size);
+    format_to(it, FMT_STRING("{}{}"), message, SEP);
+  format_to(it, FMT_STRING("{}{}"), ERROR_STR, error_code);
+  FMT_ASSERT(out.size() <= inline_buffer_size, "");
 }
 
 FMT_FUNC void report_error(format_func func, int error_code,
-                           string_view message) FMT_NOEXCEPT {
+                           const char* message) FMT_NOEXCEPT {
   memory_buffer full_message;
   func(full_message, error_code, message);
   // Don't use fwrite_fully because the latter may throw.
-  (void)std::fwrite(full_message.data(), full_message.size(), 1, stderr);
-  std::fputc('\n', stderr);
+  if (std::fwrite(full_message.data(), full_message.size(), 1, stderr) > 0)
+    std::fputc('\n', stderr);
 }
 
 // A wrapper around fwrite that throws on error.
 inline void fwrite_fully(const void* ptr, size_t size, size_t count,
                          FILE* stream) {
   size_t written = std::fwrite(ptr, size, count, stream);
   if (written < count) FMT_THROW(system_error(errno, "cannot write to file"));
 }
-}  // namespace detail
-
-#if !defined(FMT_STATIC_THOUSANDS_SEPARATOR)
-namespace detail {
 
+#ifndef FMT_STATIC_THOUSANDS_SEPARATOR
 template <typename Locale>
 locale_ref::locale_ref(const Locale& loc) : locale_(&loc) {
   static_assert(std::is_same<Locale, std::locale>::value, "");
 }
 
 template <typename Locale> Locale locale_ref::get() const {
   static_assert(std::is_same<Locale, std::locale>::value, "");
   return locale_ ? *static_cast<const std::locale*>(locale_) : std::locale();
 }
 
-template <typename Char> FMT_FUNC std::string grouping_impl(locale_ref loc) {
-  return std::use_facet<std::numpunct<Char>>(loc.get<std::locale>()).grouping();
-}
-template <typename Char> FMT_FUNC Char thousands_sep_impl(locale_ref loc) {
-  return std::use_facet<std::numpunct<Char>>(loc.get<std::locale>())
-      .thousands_sep();
+template <typename Char>
+FMT_FUNC auto thousands_sep_impl(locale_ref loc) -> thousands_sep_result<Char> {
+  auto& facet = std::use_facet<std::numpunct<Char>>(loc.get<std::locale>());
+  auto grouping = facet.grouping();
+  auto thousands_sep = grouping.empty() ? Char() : facet.thousands_sep();
+  return {std::move(grouping), thousands_sep};
 }
 template <typename Char> FMT_FUNC Char decimal_point_impl(locale_ref loc) {
   return std::use_facet<std::numpunct<Char>>(loc.get<std::locale>())
       .decimal_point();
 }
-}  // namespace detail
 #else
 template <typename Char>
-FMT_FUNC std::string detail::grouping_impl(locale_ref) {
-  return "\03";
+FMT_FUNC auto thousands_sep_impl(locale_ref) -> thousands_sep_result<Char> {
+  return {"\03", FMT_STATIC_THOUSANDS_SEPARATOR};
 }
-template <typename Char> FMT_FUNC Char detail::thousands_sep_impl(locale_ref) {
-  return FMT_STATIC_THOUSANDS_SEPARATOR;
-}
-template <typename Char> FMT_FUNC Char detail::decimal_point_impl(locale_ref) {
+template <typename Char> FMT_FUNC Char decimal_point_impl(locale_ref) {
   return '.';
 }
 #endif
+}  // namespace detail
 
+#if !FMT_MSC_VER
 FMT_API FMT_FUNC format_error::~format_error() FMT_NOEXCEPT = default;
-FMT_API FMT_FUNC system_error::~system_error() FMT_NOEXCEPT = default;
+#endif
 
-FMT_FUNC void system_error::init(int err_code, string_view format_str,
-                                 format_args args) {
-  error_code_ = err_code;
-  memory_buffer buffer;
-  format_system_error(buffer, err_code, vformat(format_str, args));
-  std::runtime_error& base = *this;
-  base = std::runtime_error(to_string(buffer));
+FMT_FUNC std::system_error vsystem_error(int error_code, string_view format_str,
+                                         format_args args) {
+  auto ec = std::error_code(error_code, std::generic_category());
+  return std::system_error(ec, vformat(format_str, args));
 }
 
 namespace detail {
 
 template <> FMT_FUNC int count_digits<4>(detail::fallback_uintptr n) {
   // fallback_uintptr is always stored in little endian.
   int i = static_cast<int>(sizeof(void*)) - 1;
   while (i > 0 && n.value[i] == 0) --i;
   auto char_digits = std::numeric_limits<unsigned char>::digits / 4;
   return i >= 0 ? i * char_digits + count_digits<4, unsigned>(n.value[i]) : 1;
 }
 
-template <typename T>
-const typename basic_data<T>::digit_pair basic_data<T>::digits[] = {
-    {'0', '0'}, {'0', '1'}, {'0', '2'}, {'0', '3'}, {'0', '4'}, {'0', '5'},
-    {'0', '6'}, {'0', '7'}, {'0', '8'}, {'0', '9'}, {'1', '0'}, {'1', '1'},
-    {'1', '2'}, {'1', '3'}, {'1', '4'}, {'1', '5'}, {'1', '6'}, {'1', '7'},
-    {'1', '8'}, {'1', '9'}, {'2', '0'}, {'2', '1'}, {'2', '2'}, {'2', '3'},
-    {'2', '4'}, {'2', '5'}, {'2', '6'}, {'2', '7'}, {'2', '8'}, {'2', '9'},
-    {'3', '0'}, {'3', '1'}, {'3', '2'}, {'3', '3'}, {'3', '4'}, {'3', '5'},
-    {'3', '6'}, {'3', '7'}, {'3', '8'}, {'3', '9'}, {'4', '0'}, {'4', '1'},
-    {'4', '2'}, {'4', '3'}, {'4', '4'}, {'4', '5'}, {'4', '6'}, {'4', '7'},
-    {'4', '8'}, {'4', '9'}, {'5', '0'}, {'5', '1'}, {'5', '2'}, {'5', '3'},
-    {'5', '4'}, {'5', '5'}, {'5', '6'}, {'5', '7'}, {'5', '8'}, {'5', '9'},
-    {'6', '0'}, {'6', '1'}, {'6', '2'}, {'6', '3'}, {'6', '4'}, {'6', '5'},
-    {'6', '6'}, {'6', '7'}, {'6', '8'}, {'6', '9'}, {'7', '0'}, {'7', '1'},
-    {'7', '2'}, {'7', '3'}, {'7', '4'}, {'7', '5'}, {'7', '6'}, {'7', '7'},
-    {'7', '8'}, {'7', '9'}, {'8', '0'}, {'8', '1'}, {'8', '2'}, {'8', '3'},
-    {'8', '4'}, {'8', '5'}, {'8', '6'}, {'8', '7'}, {'8', '8'}, {'8', '9'},
-    {'9', '0'}, {'9', '1'}, {'9', '2'}, {'9', '3'}, {'9', '4'}, {'9', '5'},
-    {'9', '6'}, {'9', '7'}, {'9', '8'}, {'9', '9'}};
-
-template <typename T>
-const char basic_data<T>::hex_digits[] = "0123456789abcdef";
-
-#define FMT_POWERS_OF_10(factor)                                             \
-  factor * 10, (factor)*100, (factor)*1000, (factor)*10000, (factor)*100000, \
-      (factor)*1000000, (factor)*10000000, (factor)*100000000,               \
-      (factor)*1000000000
-
-template <typename T>
-const uint64_t basic_data<T>::powers_of_10_64[] = {
-    1, FMT_POWERS_OF_10(1), FMT_POWERS_OF_10(1000000000ULL),
-    10000000000000000000ULL};
-
-template <typename T>
-const uint32_t basic_data<T>::zero_or_powers_of_10_32[] = {0,
-                                                           FMT_POWERS_OF_10(1)};
-template <typename T>
-const uint64_t basic_data<T>::zero_or_powers_of_10_64[] = {
-    0, FMT_POWERS_OF_10(1), FMT_POWERS_OF_10(1000000000ULL),
-    10000000000000000000ULL};
-
-template <typename T>
-const uint32_t basic_data<T>::zero_or_powers_of_10_32_new[] = {
-    0, 0, FMT_POWERS_OF_10(1)};
-
-template <typename T>
-const uint64_t basic_data<T>::zero_or_powers_of_10_64_new[] = {
-    0, 0, FMT_POWERS_OF_10(1), FMT_POWERS_OF_10(1000000000ULL),
-    10000000000000000000ULL};
+// log10(2) = 0x0.4d104d427de7fbcc...
+static constexpr uint64_t log10_2_significand = 0x4d104d427de7fbcc;
 
-// Normalized 64-bit significands of pow(10, k), for k = -348, -340, ..., 340.
-// These are generated by support/compute-powers.py.
-template <typename T>
-const uint64_t basic_data<T>::grisu_pow10_significands[] = {
-    0xfa8fd5a0081c0288, 0xbaaee17fa23ebf76, 0x8b16fb203055ac76,
-    0xcf42894a5dce35ea, 0x9a6bb0aa55653b2d, 0xe61acf033d1a45df,
-    0xab70fe17c79ac6ca, 0xff77b1fcbebcdc4f, 0xbe5691ef416bd60c,
-    0x8dd01fad907ffc3c, 0xd3515c2831559a83, 0x9d71ac8fada6c9b5,
-    0xea9c227723ee8bcb, 0xaecc49914078536d, 0x823c12795db6ce57,
-    0xc21094364dfb5637, 0x9096ea6f3848984f, 0xd77485cb25823ac7,
-    0xa086cfcd97bf97f4, 0xef340a98172aace5, 0xb23867fb2a35b28e,
-    0x84c8d4dfd2c63f3b, 0xc5dd44271ad3cdba, 0x936b9fcebb25c996,
-    0xdbac6c247d62a584, 0xa3ab66580d5fdaf6, 0xf3e2f893dec3f126,
-    0xb5b5ada8aaff80b8, 0x87625f056c7c4a8b, 0xc9bcff6034c13053,
-    0x964e858c91ba2655, 0xdff9772470297ebd, 0xa6dfbd9fb8e5b88f,
-    0xf8a95fcf88747d94, 0xb94470938fa89bcf, 0x8a08f0f8bf0f156b,
-    0xcdb02555653131b6, 0x993fe2c6d07b7fac, 0xe45c10c42a2b3b06,
-    0xaa242499697392d3, 0xfd87b5f28300ca0e, 0xbce5086492111aeb,
-    0x8cbccc096f5088cc, 0xd1b71758e219652c, 0x9c40000000000000,
-    0xe8d4a51000000000, 0xad78ebc5ac620000, 0x813f3978f8940984,
-    0xc097ce7bc90715b3, 0x8f7e32ce7bea5c70, 0xd5d238a4abe98068,
-    0x9f4f2726179a2245, 0xed63a231d4c4fb27, 0xb0de65388cc8ada8,
-    0x83c7088e1aab65db, 0xc45d1df942711d9a, 0x924d692ca61be758,
-    0xda01ee641a708dea, 0xa26da3999aef774a, 0xf209787bb47d6b85,
-    0xb454e4a179dd1877, 0x865b86925b9bc5c2, 0xc83553c5c8965d3d,
-    0x952ab45cfa97a0b3, 0xde469fbd99a05fe3, 0xa59bc234db398c25,
-    0xf6c69a72a3989f5c, 0xb7dcbf5354e9bece, 0x88fcf317f22241e2,
-    0xcc20ce9bd35c78a5, 0x98165af37b2153df, 0xe2a0b5dc971f303a,
-    0xa8d9d1535ce3b396, 0xfb9b7cd9a4a7443c, 0xbb764c4ca7a44410,
-    0x8bab8eefb6409c1a, 0xd01fef10a657842c, 0x9b10a4e5e9913129,
-    0xe7109bfba19c0c9d, 0xac2820d9623bf429, 0x80444b5e7aa7cf85,
-    0xbf21e44003acdd2d, 0x8e679c2f5e44ff8f, 0xd433179d9c8cb841,
-    0x9e19db92b4e31ba9, 0xeb96bf6ebadf77d9, 0xaf87023b9bf0ee6b,
-};
-
-// Binary exponents of pow(10, k), for k = -348, -340, ..., 340, corresponding
-// to significands above.
-template <typename T>
-const int16_t basic_data<T>::grisu_pow10_exponents[] = {
-    -1220, -1193, -1166, -1140, -1113, -1087, -1060, -1034, -1007, -980, -954,
-    -927,  -901,  -874,  -847,  -821,  -794,  -768,  -741,  -715,  -688, -661,
-    -635,  -608,  -582,  -555,  -529,  -502,  -475,  -449,  -422,  -396, -369,
-    -343,  -316,  -289,  -263,  -236,  -210,  -183,  -157,  -130,  -103, -77,
-    -50,   -24,   3,     30,    56,    83,    109,   136,   162,   189,  216,
-    242,   269,   295,   322,   348,   375,   402,   428,   455,   481,  508,
-    534,   561,   588,   614,   641,   667,   694,   720,   747,   774,  800,
-    827,   853,   880,   907,   933,   960,   986,   1013,  1039,  1066};
-
-template <typename T>
-const divtest_table_entry<uint32_t> basic_data<T>::divtest_table_for_pow5_32[] =
-    {{0x00000001, 0xffffffff}, {0xcccccccd, 0x33333333},
-     {0xc28f5c29, 0x0a3d70a3}, {0x26e978d5, 0x020c49ba},
-     {0x3afb7e91, 0x0068db8b}, {0x0bcbe61d, 0x0014f8b5},
-     {0x68c26139, 0x000431bd}, {0xae8d46a5, 0x0000d6bf},
-     {0x22e90e21, 0x00002af3}, {0x3a2e9c6d, 0x00000897},
-     {0x3ed61f49, 0x000001b7}};
-
-template <typename T>
-const divtest_table_entry<uint64_t> basic_data<T>::divtest_table_for_pow5_64[] =
-    {{0x0000000000000001, 0xffffffffffffffff},
-     {0xcccccccccccccccd, 0x3333333333333333},
-     {0x8f5c28f5c28f5c29, 0x0a3d70a3d70a3d70},
-     {0x1cac083126e978d5, 0x020c49ba5e353f7c},
-     {0xd288ce703afb7e91, 0x0068db8bac710cb2},
-     {0x5d4e8fb00bcbe61d, 0x0014f8b588e368f0},
-     {0x790fb65668c26139, 0x000431bde82d7b63},
-     {0xe5032477ae8d46a5, 0x0000d6bf94d5e57a},
-     {0xc767074b22e90e21, 0x00002af31dc46118},
-     {0x8e47ce423a2e9c6d, 0x0000089705f4136b},
-     {0x4fa7f60d3ed61f49, 0x000001b7cdfd9d7b},
-     {0x0fee64690c913975, 0x00000057f5ff85e5},
-     {0x3662e0e1cf503eb1, 0x000000119799812d},
-     {0xa47a2cf9f6433fbd, 0x0000000384b84d09},
-     {0x54186f653140a659, 0x00000000b424dc35},
-     {0x7738164770402145, 0x0000000024075f3d},
-     {0xe4a4d1417cd9a041, 0x000000000734aca5},
-     {0xc75429d9e5c5200d, 0x000000000170ef54},
-     {0xc1773b91fac10669, 0x000000000049c977},
-     {0x26b172506559ce15, 0x00000000000ec1e4},
-     {0xd489e3a9addec2d1, 0x000000000002f394},
-     {0x90e860bb892c8d5d, 0x000000000000971d},
-     {0x502e79bf1b6f4f79, 0x0000000000001e39},
-     {0xdcd618596be30fe5, 0x000000000000060b}};
-
-template <typename T>
-const uint64_t basic_data<T>::dragonbox_pow10_significands_64[] = {
-    0x81ceb32c4b43fcf5, 0xa2425ff75e14fc32, 0xcad2f7f5359a3b3f,
-    0xfd87b5f28300ca0e, 0x9e74d1b791e07e49, 0xc612062576589ddb,
-    0xf79687aed3eec552, 0x9abe14cd44753b53, 0xc16d9a0095928a28,
-    0xf1c90080baf72cb2, 0x971da05074da7bef, 0xbce5086492111aeb,
-    0xec1e4a7db69561a6, 0x9392ee8e921d5d08, 0xb877aa3236a4b44a,
-    0xe69594bec44de15c, 0x901d7cf73ab0acda, 0xb424dc35095cd810,
-    0xe12e13424bb40e14, 0x8cbccc096f5088cc, 0xafebff0bcb24aaff,
-    0xdbe6fecebdedd5bf, 0x89705f4136b4a598, 0xabcc77118461cefd,
-    0xd6bf94d5e57a42bd, 0x8637bd05af6c69b6, 0xa7c5ac471b478424,
-    0xd1b71758e219652c, 0x83126e978d4fdf3c, 0xa3d70a3d70a3d70b,
-    0xcccccccccccccccd, 0x8000000000000000, 0xa000000000000000,
-    0xc800000000000000, 0xfa00000000000000, 0x9c40000000000000,
-    0xc350000000000000, 0xf424000000000000, 0x9896800000000000,
-    0xbebc200000000000, 0xee6b280000000000, 0x9502f90000000000,
-    0xba43b74000000000, 0xe8d4a51000000000, 0x9184e72a00000000,
-    0xb5e620f480000000, 0xe35fa931a0000000, 0x8e1bc9bf04000000,
-    0xb1a2bc2ec5000000, 0xde0b6b3a76400000, 0x8ac7230489e80000,
-    0xad78ebc5ac620000, 0xd8d726b7177a8000, 0x878678326eac9000,
-    0xa968163f0a57b400, 0xd3c21bcecceda100, 0x84595161401484a0,
-    0xa56fa5b99019a5c8, 0xcecb8f27f4200f3a, 0x813f3978f8940984,
-    0xa18f07d736b90be5, 0xc9f2c9cd04674ede, 0xfc6f7c4045812296,
-    0x9dc5ada82b70b59d, 0xc5371912364ce305, 0xf684df56c3e01bc6,
-    0x9a130b963a6c115c, 0xc097ce7bc90715b3, 0xf0bdc21abb48db20,
-    0x96769950b50d88f4, 0xbc143fa4e250eb31, 0xeb194f8e1ae525fd,
-    0x92efd1b8d0cf37be, 0xb7abc627050305ad, 0xe596b7b0c643c719,
-    0x8f7e32ce7bea5c6f, 0xb35dbf821ae4f38b, 0xe0352f62a19e306e};
+template <typename T = void> struct basic_impl_data {
+  // Normalized 64-bit significands of pow(10, k), for k = -348, -340, ..., 340.
+  // These are generated by support/compute-powers.py.
+  static constexpr uint64_t pow10_significands[87] = {
+      0xfa8fd5a0081c0288, 0xbaaee17fa23ebf76, 0x8b16fb203055ac76,
+      0xcf42894a5dce35ea, 0x9a6bb0aa55653b2d, 0xe61acf033d1a45df,
+      0xab70fe17c79ac6ca, 0xff77b1fcbebcdc4f, 0xbe5691ef416bd60c,
+      0x8dd01fad907ffc3c, 0xd3515c2831559a83, 0x9d71ac8fada6c9b5,
+      0xea9c227723ee8bcb, 0xaecc49914078536d, 0x823c12795db6ce57,
+      0xc21094364dfb5637, 0x9096ea6f3848984f, 0xd77485cb25823ac7,
+      0xa086cfcd97bf97f4, 0xef340a98172aace5, 0xb23867fb2a35b28e,
+      0x84c8d4dfd2c63f3b, 0xc5dd44271ad3cdba, 0x936b9fcebb25c996,
+      0xdbac6c247d62a584, 0xa3ab66580d5fdaf6, 0xf3e2f893dec3f126,
+      0xb5b5ada8aaff80b8, 0x87625f056c7c4a8b, 0xc9bcff6034c13053,
+      0x964e858c91ba2655, 0xdff9772470297ebd, 0xa6dfbd9fb8e5b88f,
+      0xf8a95fcf88747d94, 0xb94470938fa89bcf, 0x8a08f0f8bf0f156b,
+      0xcdb02555653131b6, 0x993fe2c6d07b7fac, 0xe45c10c42a2b3b06,
+      0xaa242499697392d3, 0xfd87b5f28300ca0e, 0xbce5086492111aeb,
+      0x8cbccc096f5088cc, 0xd1b71758e219652c, 0x9c40000000000000,
+      0xe8d4a51000000000, 0xad78ebc5ac620000, 0x813f3978f8940984,
+      0xc097ce7bc90715b3, 0x8f7e32ce7bea5c70, 0xd5d238a4abe98068,
+      0x9f4f2726179a2245, 0xed63a231d4c4fb27, 0xb0de65388cc8ada8,
+      0x83c7088e1aab65db, 0xc45d1df942711d9a, 0x924d692ca61be758,
+      0xda01ee641a708dea, 0xa26da3999aef774a, 0xf209787bb47d6b85,
+      0xb454e4a179dd1877, 0x865b86925b9bc5c2, 0xc83553c5c8965d3d,
+      0x952ab45cfa97a0b3, 0xde469fbd99a05fe3, 0xa59bc234db398c25,
+      0xf6c69a72a3989f5c, 0xb7dcbf5354e9bece, 0x88fcf317f22241e2,
+      0xcc20ce9bd35c78a5, 0x98165af37b2153df, 0xe2a0b5dc971f303a,
+      0xa8d9d1535ce3b396, 0xfb9b7cd9a4a7443c, 0xbb764c4ca7a44410,
+      0x8bab8eefb6409c1a, 0xd01fef10a657842c, 0x9b10a4e5e9913129,
+      0xe7109bfba19c0c9d, 0xac2820d9623bf429, 0x80444b5e7aa7cf85,
+      0xbf21e44003acdd2d, 0x8e679c2f5e44ff8f, 0xd433179d9c8cb841,
+      0x9e19db92b4e31ba9, 0xeb96bf6ebadf77d9, 0xaf87023b9bf0ee6b,
+  };
 
-template <typename T>
-const uint128_wrapper basic_data<T>::dragonbox_pow10_significands_128[] = {
-#if FMT_USE_FULL_CACHE_DRAGONBOX
-    {0xff77b1fcbebcdc4f, 0x25e8e89c13bb0f7b},
-    {0x9faacf3df73609b1, 0x77b191618c54e9ad},
-    {0xc795830d75038c1d, 0xd59df5b9ef6a2418},
-    {0xf97ae3d0d2446f25, 0x4b0573286b44ad1e},
-    {0x9becce62836ac577, 0x4ee367f9430aec33},
-    {0xc2e801fb244576d5, 0x229c41f793cda740},
-    {0xf3a20279ed56d48a, 0x6b43527578c11110},
-    {0x9845418c345644d6, 0x830a13896b78aaaa},
-    {0xbe5691ef416bd60c, 0x23cc986bc656d554},
-    {0xedec366b11c6cb8f, 0x2cbfbe86b7ec8aa9},
-    {0x94b3a202eb1c3f39, 0x7bf7d71432f3d6aa},
-    {0xb9e08a83a5e34f07, 0xdaf5ccd93fb0cc54},
-    {0xe858ad248f5c22c9, 0xd1b3400f8f9cff69},
-    {0x91376c36d99995be, 0x23100809b9c21fa2},
-    {0xb58547448ffffb2d, 0xabd40a0c2832a78b},
-    {0xe2e69915b3fff9f9, 0x16c90c8f323f516d},
-    {0x8dd01fad907ffc3b, 0xae3da7d97f6792e4},
-    {0xb1442798f49ffb4a, 0x99cd11cfdf41779d},
-    {0xdd95317f31c7fa1d, 0x40405643d711d584},
-    {0x8a7d3eef7f1cfc52, 0x482835ea666b2573},
-    {0xad1c8eab5ee43b66, 0xda3243650005eed0},
-    {0xd863b256369d4a40, 0x90bed43e40076a83},
-    {0x873e4f75e2224e68, 0x5a7744a6e804a292},
-    {0xa90de3535aaae202, 0x711515d0a205cb37},
-    {0xd3515c2831559a83, 0x0d5a5b44ca873e04},
-    {0x8412d9991ed58091, 0xe858790afe9486c3},
-    {0xa5178fff668ae0b6, 0x626e974dbe39a873},
-    {0xce5d73ff402d98e3, 0xfb0a3d212dc81290},
-    {0x80fa687f881c7f8e, 0x7ce66634bc9d0b9a},
-    {0xa139029f6a239f72, 0x1c1fffc1ebc44e81},
-    {0xc987434744ac874e, 0xa327ffb266b56221},
-    {0xfbe9141915d7a922, 0x4bf1ff9f0062baa9},
-    {0x9d71ac8fada6c9b5, 0x6f773fc3603db4aa},
-    {0xc4ce17b399107c22, 0xcb550fb4384d21d4},
-    {0xf6019da07f549b2b, 0x7e2a53a146606a49},
-    {0x99c102844f94e0fb, 0x2eda7444cbfc426e},
-    {0xc0314325637a1939, 0xfa911155fefb5309},
-    {0xf03d93eebc589f88, 0x793555ab7eba27cb},
-    {0x96267c7535b763b5, 0x4bc1558b2f3458df},
-    {0xbbb01b9283253ca2, 0x9eb1aaedfb016f17},
-    {0xea9c227723ee8bcb, 0x465e15a979c1cadd},
-    {0x92a1958a7675175f, 0x0bfacd89ec191eca},
-    {0xb749faed14125d36, 0xcef980ec671f667c},
-    {0xe51c79a85916f484, 0x82b7e12780e7401b},
-    {0x8f31cc0937ae58d2, 0xd1b2ecb8b0908811},
-    {0xb2fe3f0b8599ef07, 0x861fa7e6dcb4aa16},
-    {0xdfbdcece67006ac9, 0x67a791e093e1d49b},
-    {0x8bd6a141006042bd, 0xe0c8bb2c5c6d24e1},
-    {0xaecc49914078536d, 0x58fae9f773886e19},
-    {0xda7f5bf590966848, 0xaf39a475506a899f},
-    {0x888f99797a5e012d, 0x6d8406c952429604},
-    {0xaab37fd7d8f58178, 0xc8e5087ba6d33b84},
-    {0xd5605fcdcf32e1d6, 0xfb1e4a9a90880a65},
-    {0x855c3be0a17fcd26, 0x5cf2eea09a550680},
-    {0xa6b34ad8c9dfc06f, 0xf42faa48c0ea481f},
-    {0xd0601d8efc57b08b, 0xf13b94daf124da27},
-    {0x823c12795db6ce57, 0x76c53d08d6b70859},
-    {0xa2cb1717b52481ed, 0x54768c4b0c64ca6f},
-    {0xcb7ddcdda26da268, 0xa9942f5dcf7dfd0a},
-    {0xfe5d54150b090b02, 0xd3f93b35435d7c4d},
-    {0x9efa548d26e5a6e1, 0xc47bc5014a1a6db0},
-    {0xc6b8e9b0709f109a, 0x359ab6419ca1091c},
-    {0xf867241c8cc6d4c0, 0xc30163d203c94b63},
-    {0x9b407691d7fc44f8, 0x79e0de63425dcf1e},
-    {0xc21094364dfb5636, 0x985915fc12f542e5},
-    {0xf294b943e17a2bc4, 0x3e6f5b7b17b2939e},
-    {0x979cf3ca6cec5b5a, 0xa705992ceecf9c43},
-    {0xbd8430bd08277231, 0x50c6ff782a838354},
-    {0xece53cec4a314ebd, 0xa4f8bf5635246429},
-    {0x940f4613ae5ed136, 0x871b7795e136be9a},
-    {0xb913179899f68584, 0x28e2557b59846e40},
-    {0xe757dd7ec07426e5, 0x331aeada2fe589d0},
-    {0x9096ea6f3848984f, 0x3ff0d2c85def7622},
-    {0xb4bca50b065abe63, 0x0fed077a756b53aa},
-    {0xe1ebce4dc7f16dfb, 0xd3e8495912c62895},
-    {0x8d3360f09cf6e4bd, 0x64712dd7abbbd95d},
-    {0xb080392cc4349dec, 0xbd8d794d96aacfb4},
-    {0xdca04777f541c567, 0xecf0d7a0fc5583a1},
-    {0x89e42caaf9491b60, 0xf41686c49db57245},
-    {0xac5d37d5b79b6239, 0x311c2875c522ced6},
-    {0xd77485cb25823ac7, 0x7d633293366b828c},
-    {0x86a8d39ef77164bc, 0xae5dff9c02033198},
-    {0xa8530886b54dbdeb, 0xd9f57f830283fdfd},
-    {0xd267caa862a12d66, 0xd072df63c324fd7c},
-    {0x8380dea93da4bc60, 0x4247cb9e59f71e6e},
-    {0xa46116538d0deb78, 0x52d9be85f074e609},
-    {0xcd795be870516656, 0x67902e276c921f8c},
-    {0x806bd9714632dff6, 0x00ba1cd8a3db53b7},
-    {0xa086cfcd97bf97f3, 0x80e8a40eccd228a5},
-    {0xc8a883c0fdaf7df0, 0x6122cd128006b2ce},
-    {0xfad2a4b13d1b5d6c, 0x796b805720085f82},
-    {0x9cc3a6eec6311a63, 0xcbe3303674053bb1},
-    {0xc3f490aa77bd60fc, 0xbedbfc4411068a9d},
-    {0xf4f1b4d515acb93b, 0xee92fb5515482d45},
-    {0x991711052d8bf3c5, 0x751bdd152d4d1c4b},
-    {0xbf5cd54678eef0b6, 0xd262d45a78a0635e},
-    {0xef340a98172aace4, 0x86fb897116c87c35},
-    {0x9580869f0e7aac0e, 0xd45d35e6ae3d4da1},
-    {0xbae0a846d2195712, 0x8974836059cca10a},
-    {0xe998d258869facd7, 0x2bd1a438703fc94c},
-    {0x91ff83775423cc06, 0x7b6306a34627ddd0},
-    {0xb67f6455292cbf08, 0x1a3bc84c17b1d543},
-    {0xe41f3d6a7377eeca, 0x20caba5f1d9e4a94},
-    {0x8e938662882af53e, 0x547eb47b7282ee9d},
-    {0xb23867fb2a35b28d, 0xe99e619a4f23aa44},
-    {0xdec681f9f4c31f31, 0x6405fa00e2ec94d5},
-    {0x8b3c113c38f9f37e, 0xde83bc408dd3dd05},
-    {0xae0b158b4738705e, 0x9624ab50b148d446},
-    {0xd98ddaee19068c76, 0x3badd624dd9b0958},
-    {0x87f8a8d4cfa417c9, 0xe54ca5d70a80e5d7},
-    {0xa9f6d30a038d1dbc, 0x5e9fcf4ccd211f4d},
-    {0xd47487cc8470652b, 0x7647c32000696720},
-    {0x84c8d4dfd2c63f3b, 0x29ecd9f40041e074},
-    {0xa5fb0a17c777cf09, 0xf468107100525891},
-    {0xcf79cc9db955c2cc, 0x7182148d4066eeb5},
-    {0x81ac1fe293d599bf, 0xc6f14cd848405531},
-    {0xa21727db38cb002f, 0xb8ada00e5a506a7d},
-    {0xca9cf1d206fdc03b, 0xa6d90811f0e4851d},
-    {0xfd442e4688bd304a, 0x908f4a166d1da664},
-    {0x9e4a9cec15763e2e, 0x9a598e4e043287ff},
-    {0xc5dd44271ad3cdba, 0x40eff1e1853f29fe},
-    {0xf7549530e188c128, 0xd12bee59e68ef47d},
-    {0x9a94dd3e8cf578b9, 0x82bb74f8301958cf},
-    {0xc13a148e3032d6e7, 0xe36a52363c1faf02},
-    {0xf18899b1bc3f8ca1, 0xdc44e6c3cb279ac2},
-    {0x96f5600f15a7b7e5, 0x29ab103a5ef8c0ba},
-    {0xbcb2b812db11a5de, 0x7415d448f6b6f0e8},
-    {0xebdf661791d60f56, 0x111b495b3464ad22},
-    {0x936b9fcebb25c995, 0xcab10dd900beec35},
-    {0xb84687c269ef3bfb, 0x3d5d514f40eea743},
-    {0xe65829b3046b0afa, 0x0cb4a5a3112a5113},
-    {0x8ff71a0fe2c2e6dc, 0x47f0e785eaba72ac},
-    {0xb3f4e093db73a093, 0x59ed216765690f57},
-    {0xe0f218b8d25088b8, 0x306869c13ec3532d},
-    {0x8c974f7383725573, 0x1e414218c73a13fc},
-    {0xafbd2350644eeacf, 0xe5d1929ef90898fb},
-    {0xdbac6c247d62a583, 0xdf45f746b74abf3a},
-    {0x894bc396ce5da772, 0x6b8bba8c328eb784},
-    {0xab9eb47c81f5114f, 0x066ea92f3f326565},
-    {0xd686619ba27255a2, 0xc80a537b0efefebe},
-    {0x8613fd0145877585, 0xbd06742ce95f5f37},
-    {0xa798fc4196e952e7, 0x2c48113823b73705},
-    {0xd17f3b51fca3a7a0, 0xf75a15862ca504c6},
-    {0x82ef85133de648c4, 0x9a984d73dbe722fc},
-    {0xa3ab66580d5fdaf5, 0xc13e60d0d2e0ebbb},
-    {0xcc963fee10b7d1b3, 0x318df905079926a9},
-    {0xffbbcfe994e5c61f, 0xfdf17746497f7053},
-    {0x9fd561f1fd0f9bd3, 0xfeb6ea8bedefa634},
-    {0xc7caba6e7c5382c8, 0xfe64a52ee96b8fc1},
-    {0xf9bd690a1b68637b, 0x3dfdce7aa3c673b1},
-    {0x9c1661a651213e2d, 0x06bea10ca65c084f},
-    {0xc31bfa0fe5698db8, 0x486e494fcff30a63},
-    {0xf3e2f893dec3f126, 0x5a89dba3c3efccfb},
-    {0x986ddb5c6b3a76b7, 0xf89629465a75e01d},
-    {0xbe89523386091465, 0xf6bbb397f1135824},
-    {0xee2ba6c0678b597f, 0x746aa07ded582e2d},
-    {0x94db483840b717ef, 0xa8c2a44eb4571cdd},
-    {0xba121a4650e4ddeb, 0x92f34d62616ce414},
-    {0xe896a0d7e51e1566, 0x77b020baf9c81d18},
-    {0x915e2486ef32cd60, 0x0ace1474dc1d122f},
-    {0xb5b5ada8aaff80b8, 0x0d819992132456bb},
-    {0xe3231912d5bf60e6, 0x10e1fff697ed6c6a},
-    {0x8df5efabc5979c8f, 0xca8d3ffa1ef463c2},
-    {0xb1736b96b6fd83b3, 0xbd308ff8a6b17cb3},
-    {0xddd0467c64bce4a0, 0xac7cb3f6d05ddbdf},
-    {0x8aa22c0dbef60ee4, 0x6bcdf07a423aa96c},
-    {0xad4ab7112eb3929d, 0x86c16c98d2c953c7},
-    {0xd89d64d57a607744, 0xe871c7bf077ba8b8},
-    {0x87625f056c7c4a8b, 0x11471cd764ad4973},
-    {0xa93af6c6c79b5d2d, 0xd598e40d3dd89bd0},
-    {0xd389b47879823479, 0x4aff1d108d4ec2c4},
-    {0x843610cb4bf160cb, 0xcedf722a585139bb},
-    {0xa54394fe1eedb8fe, 0xc2974eb4ee658829},
-    {0xce947a3da6a9273e, 0x733d226229feea33},
-    {0x811ccc668829b887, 0x0806357d5a3f5260},
-    {0xa163ff802a3426a8, 0xca07c2dcb0cf26f8},
-    {0xc9bcff6034c13052, 0xfc89b393dd02f0b6},
-    {0xfc2c3f3841f17c67, 0xbbac2078d443ace3},
-    {0x9d9ba7832936edc0, 0xd54b944b84aa4c0e},
-    {0xc5029163f384a931, 0x0a9e795e65d4df12},
-    {0xf64335bcf065d37d, 0x4d4617b5ff4a16d6},
-    {0x99ea0196163fa42e, 0x504bced1bf8e4e46},
-    {0xc06481fb9bcf8d39, 0xe45ec2862f71e1d7},
-    {0xf07da27a82c37088, 0x5d767327bb4e5a4d},
-    {0x964e858c91ba2655, 0x3a6a07f8d510f870},
-    {0xbbe226efb628afea, 0x890489f70a55368c},
-    {0xeadab0aba3b2dbe5, 0x2b45ac74ccea842f},
-    {0x92c8ae6b464fc96f, 0x3b0b8bc90012929e},
-    {0xb77ada0617e3bbcb, 0x09ce6ebb40173745},
-    {0xe55990879ddcaabd, 0xcc420a6a101d0516},
-    {0x8f57fa54c2a9eab6, 0x9fa946824a12232e},
-    {0xb32df8e9f3546564, 0x47939822dc96abfa},
-    {0xdff9772470297ebd, 0x59787e2b93bc56f8},
-    {0x8bfbea76c619ef36, 0x57eb4edb3c55b65b},
-    {0xaefae51477a06b03, 0xede622920b6b23f2},
-    {0xdab99e59958885c4, 0xe95fab368e45ecee},
-    {0x88b402f7fd75539b, 0x11dbcb0218ebb415},
-    {0xaae103b5fcd2a881, 0xd652bdc29f26a11a},
-    {0xd59944a37c0752a2, 0x4be76d3346f04960},
-    {0x857fcae62d8493a5, 0x6f70a4400c562ddc},
-    {0xa6dfbd9fb8e5b88e, 0xcb4ccd500f6bb953},
-    {0xd097ad07a71f26b2, 0x7e2000a41346a7a8},
-    {0x825ecc24c873782f, 0x8ed400668c0c28c9},
-    {0xa2f67f2dfa90563b, 0x728900802f0f32fb},
-    {0xcbb41ef979346bca, 0x4f2b40a03ad2ffba},
-    {0xfea126b7d78186bc, 0xe2f610c84987bfa9},
-    {0x9f24b832e6b0f436, 0x0dd9ca7d2df4d7ca},
-    {0xc6ede63fa05d3143, 0x91503d1c79720dbc},
-    {0xf8a95fcf88747d94, 0x75a44c6397ce912b},
-    {0x9b69dbe1b548ce7c, 0xc986afbe3ee11abb},
-    {0xc24452da229b021b, 0xfbe85badce996169},
-    {0xf2d56790ab41c2a2, 0xfae27299423fb9c4},
-    {0x97c560ba6b0919a5, 0xdccd879fc967d41b},
-    {0xbdb6b8e905cb600f, 0x5400e987bbc1c921},
-    {0xed246723473e3813, 0x290123e9aab23b69},
-    {0x9436c0760c86e30b, 0xf9a0b6720aaf6522},
-    {0xb94470938fa89bce, 0xf808e40e8d5b3e6a},
-    {0xe7958cb87392c2c2, 0xb60b1d1230b20e05},
-    {0x90bd77f3483bb9b9, 0xb1c6f22b5e6f48c3},
-    {0xb4ecd5f01a4aa828, 0x1e38aeb6360b1af4},
-    {0xe2280b6c20dd5232, 0x25c6da63c38de1b1},
-    {0x8d590723948a535f, 0x579c487e5a38ad0f},
-    {0xb0af48ec79ace837, 0x2d835a9df0c6d852},
-    {0xdcdb1b2798182244, 0xf8e431456cf88e66},
-    {0x8a08f0f8bf0f156b, 0x1b8e9ecb641b5900},
-    {0xac8b2d36eed2dac5, 0xe272467e3d222f40},
-    {0xd7adf884aa879177, 0x5b0ed81dcc6abb10},
-    {0x86ccbb52ea94baea, 0x98e947129fc2b4ea},
-    {0xa87fea27a539e9a5, 0x3f2398d747b36225},
-    {0xd29fe4b18e88640e, 0x8eec7f0d19a03aae},
-    {0x83a3eeeef9153e89, 0x1953cf68300424ad},
-    {0xa48ceaaab75a8e2b, 0x5fa8c3423c052dd8},
-    {0xcdb02555653131b6, 0x3792f412cb06794e},
-    {0x808e17555f3ebf11, 0xe2bbd88bbee40bd1},
-    {0xa0b19d2ab70e6ed6, 0x5b6aceaeae9d0ec5},
-    {0xc8de047564d20a8b, 0xf245825a5a445276},
-    {0xfb158592be068d2e, 0xeed6e2f0f0d56713},
-    {0x9ced737bb6c4183d, 0x55464dd69685606c},
-    {0xc428d05aa4751e4c, 0xaa97e14c3c26b887},
-    {0xf53304714d9265df, 0xd53dd99f4b3066a9},
-    {0x993fe2c6d07b7fab, 0xe546a8038efe402a},
-    {0xbf8fdb78849a5f96, 0xde98520472bdd034},
-    {0xef73d256a5c0f77c, 0x963e66858f6d4441},
-    {0x95a8637627989aad, 0xdde7001379a44aa9},
-    {0xbb127c53b17ec159, 0x5560c018580d5d53},
-    {0xe9d71b689dde71af, 0xaab8f01e6e10b4a7},
-    {0x9226712162ab070d, 0xcab3961304ca70e9},
-    {0xb6b00d69bb55c8d1, 0x3d607b97c5fd0d23},
-    {0xe45c10c42a2b3b05, 0x8cb89a7db77c506b},
-    {0x8eb98a7a9a5b04e3, 0x77f3608e92adb243},
-    {0xb267ed1940f1c61c, 0x55f038b237591ed4},
-    {0xdf01e85f912e37a3, 0x6b6c46dec52f6689},
-    {0x8b61313bbabce2c6, 0x2323ac4b3b3da016},
-    {0xae397d8aa96c1b77, 0xabec975e0a0d081b},
-    {0xd9c7dced53c72255, 0x96e7bd358c904a22},
-    {0x881cea14545c7575, 0x7e50d64177da2e55},
-    {0xaa242499697392d2, 0xdde50bd1d5d0b9ea},
-    {0xd4ad2dbfc3d07787, 0x955e4ec64b44e865},
-    {0x84ec3c97da624ab4, 0xbd5af13bef0b113f},
-    {0xa6274bbdd0fadd61, 0xecb1ad8aeacdd58f},
-    {0xcfb11ead453994ba, 0x67de18eda5814af3},
-    {0x81ceb32c4b43fcf4, 0x80eacf948770ced8},
-    {0xa2425ff75e14fc31, 0xa1258379a94d028e},
-    {0xcad2f7f5359a3b3e, 0x096ee45813a04331},
-    {0xfd87b5f28300ca0d, 0x8bca9d6e188853fd},
-    {0x9e74d1b791e07e48, 0x775ea264cf55347e},
-    {0xc612062576589dda, 0x95364afe032a819e},
-    {0xf79687aed3eec551, 0x3a83ddbd83f52205},
-    {0x9abe14cd44753b52, 0xc4926a9672793543},
-    {0xc16d9a0095928a27, 0x75b7053c0f178294},
-    {0xf1c90080baf72cb1, 0x5324c68b12dd6339},
-    {0x971da05074da7bee, 0xd3f6fc16ebca5e04},
-    {0xbce5086492111aea, 0x88f4bb1ca6bcf585},
-    {0xec1e4a7db69561a5, 0x2b31e9e3d06c32e6},
-    {0x9392ee8e921d5d07, 0x3aff322e62439fd0},
-    {0xb877aa3236a4b449, 0x09befeb9fad487c3},
-    {0xe69594bec44de15b, 0x4c2ebe687989a9b4},
-    {0x901d7cf73ab0acd9, 0x0f9d37014bf60a11},
-    {0xb424dc35095cd80f, 0x538484c19ef38c95},
-    {0xe12e13424bb40e13, 0x2865a5f206b06fba},
-    {0x8cbccc096f5088cb, 0xf93f87b7442e45d4},
-    {0xafebff0bcb24aafe, 0xf78f69a51539d749},
-    {0xdbe6fecebdedd5be, 0xb573440e5a884d1c},
-    {0x89705f4136b4a597, 0x31680a88f8953031},
-    {0xabcc77118461cefc, 0xfdc20d2b36ba7c3e},
-    {0xd6bf94d5e57a42bc, 0x3d32907604691b4d},
-    {0x8637bd05af6c69b5, 0xa63f9a49c2c1b110},
-    {0xa7c5ac471b478423, 0x0fcf80dc33721d54},
-    {0xd1b71758e219652b, 0xd3c36113404ea4a9},
-    {0x83126e978d4fdf3b, 0x645a1cac083126ea},
-    {0xa3d70a3d70a3d70a, 0x3d70a3d70a3d70a4},
-    {0xcccccccccccccccc, 0xcccccccccccccccd},
-    {0x8000000000000000, 0x0000000000000000},
-    {0xa000000000000000, 0x0000000000000000},
-    {0xc800000000000000, 0x0000000000000000},
-    {0xfa00000000000000, 0x0000000000000000},
-    {0x9c40000000000000, 0x0000000000000000},
-    {0xc350000000000000, 0x0000000000000000},
-    {0xf424000000000000, 0x0000000000000000},
-    {0x9896800000000000, 0x0000000000000000},
-    {0xbebc200000000000, 0x0000000000000000},
-    {0xee6b280000000000, 0x0000000000000000},
-    {0x9502f90000000000, 0x0000000000000000},
-    {0xba43b74000000000, 0x0000000000000000},
-    {0xe8d4a51000000000, 0x0000000000000000},
-    {0x9184e72a00000000, 0x0000000000000000},
-    {0xb5e620f480000000, 0x0000000000000000},
-    {0xe35fa931a0000000, 0x0000000000000000},
-    {0x8e1bc9bf04000000, 0x0000000000000000},
-    {0xb1a2bc2ec5000000, 0x0000000000000000},
-    {0xde0b6b3a76400000, 0x0000000000000000},
-    {0x8ac7230489e80000, 0x0000000000000000},
-    {0xad78ebc5ac620000, 0x0000000000000000},
-    {0xd8d726b7177a8000, 0x0000000000000000},
-    {0x878678326eac9000, 0x0000000000000000},
-    {0xa968163f0a57b400, 0x0000000000000000},
-    {0xd3c21bcecceda100, 0x0000000000000000},
-    {0x84595161401484a0, 0x0000000000000000},
-    {0xa56fa5b99019a5c8, 0x0000000000000000},
-    {0xcecb8f27f4200f3a, 0x0000000000000000},
-    {0x813f3978f8940984, 0x4000000000000000},
-    {0xa18f07d736b90be5, 0x5000000000000000},
-    {0xc9f2c9cd04674ede, 0xa400000000000000},
-    {0xfc6f7c4045812296, 0x4d00000000000000},
-    {0x9dc5ada82b70b59d, 0xf020000000000000},
-    {0xc5371912364ce305, 0x6c28000000000000},
-    {0xf684df56c3e01bc6, 0xc732000000000000},
-    {0x9a130b963a6c115c, 0x3c7f400000000000},
-    {0xc097ce7bc90715b3, 0x4b9f100000000000},
-    {0xf0bdc21abb48db20, 0x1e86d40000000000},
-    {0x96769950b50d88f4, 0x1314448000000000},
-    {0xbc143fa4e250eb31, 0x17d955a000000000},
-    {0xeb194f8e1ae525fd, 0x5dcfab0800000000},
-    {0x92efd1b8d0cf37be, 0x5aa1cae500000000},
-    {0xb7abc627050305ad, 0xf14a3d9e40000000},
-    {0xe596b7b0c643c719, 0x6d9ccd05d0000000},
-    {0x8f7e32ce7bea5c6f, 0xe4820023a2000000},
-    {0xb35dbf821ae4f38b, 0xdda2802c8a800000},
-    {0xe0352f62a19e306e, 0xd50b2037ad200000},
-    {0x8c213d9da502de45, 0x4526f422cc340000},
-    {0xaf298d050e4395d6, 0x9670b12b7f410000},
-    {0xdaf3f04651d47b4c, 0x3c0cdd765f114000},
-    {0x88d8762bf324cd0f, 0xa5880a69fb6ac800},
-    {0xab0e93b6efee0053, 0x8eea0d047a457a00},
-    {0xd5d238a4abe98068, 0x72a4904598d6d880},
-    {0x85a36366eb71f041, 0x47a6da2b7f864750},
-    {0xa70c3c40a64e6c51, 0x999090b65f67d924},
-    {0xd0cf4b50cfe20765, 0xfff4b4e3f741cf6d},
-    {0x82818f1281ed449f, 0xbff8f10e7a8921a4},
-    {0xa321f2d7226895c7, 0xaff72d52192b6a0d},
-    {0xcbea6f8ceb02bb39, 0x9bf4f8a69f764490},
-    {0xfee50b7025c36a08, 0x02f236d04753d5b4},
-    {0x9f4f2726179a2245, 0x01d762422c946590},
-    {0xc722f0ef9d80aad6, 0x424d3ad2b7b97ef5},
-    {0xf8ebad2b84e0d58b, 0xd2e0898765a7deb2},
-    {0x9b934c3b330c8577, 0x63cc55f49f88eb2f},
-    {0xc2781f49ffcfa6d5, 0x3cbf6b71c76b25fb},
-    {0xf316271c7fc3908a, 0x8bef464e3945ef7a},
-    {0x97edd871cfda3a56, 0x97758bf0e3cbb5ac},
-    {0xbde94e8e43d0c8ec, 0x3d52eeed1cbea317},
-    {0xed63a231d4c4fb27, 0x4ca7aaa863ee4bdd},
-    {0x945e455f24fb1cf8, 0x8fe8caa93e74ef6a},
-    {0xb975d6b6ee39e436, 0xb3e2fd538e122b44},
-    {0xe7d34c64a9c85d44, 0x60dbbca87196b616},
-    {0x90e40fbeea1d3a4a, 0xbc8955e946fe31cd},
-    {0xb51d13aea4a488dd, 0x6babab6398bdbe41},
-    {0xe264589a4dcdab14, 0xc696963c7eed2dd1},
-    {0x8d7eb76070a08aec, 0xfc1e1de5cf543ca2},
-    {0xb0de65388cc8ada8, 0x3b25a55f43294bcb},
-    {0xdd15fe86affad912, 0x49ef0eb713f39ebe},
-    {0x8a2dbf142dfcc7ab, 0x6e3569326c784337},
-    {0xacb92ed9397bf996, 0x49c2c37f07965404},
-    {0xd7e77a8f87daf7fb, 0xdc33745ec97be906},
-    {0x86f0ac99b4e8dafd, 0x69a028bb3ded71a3},
-    {0xa8acd7c0222311bc, 0xc40832ea0d68ce0c},
-    {0xd2d80db02aabd62b, 0xf50a3fa490c30190},
-    {0x83c7088e1aab65db, 0x792667c6da79e0fa},
-    {0xa4b8cab1a1563f52, 0x577001b891185938},
-    {0xcde6fd5e09abcf26, 0xed4c0226b55e6f86},
-    {0x80b05e5ac60b6178, 0x544f8158315b05b4},
-    {0xa0dc75f1778e39d6, 0x696361ae3db1c721},
-    {0xc913936dd571c84c, 0x03bc3a19cd1e38e9},
-    {0xfb5878494ace3a5f, 0x04ab48a04065c723},
-    {0x9d174b2dcec0e47b, 0x62eb0d64283f9c76},
-    {0xc45d1df942711d9a, 0x3ba5d0bd324f8394},
-    {0xf5746577930d6500, 0xca8f44ec7ee36479},
-    {0x9968bf6abbe85f20, 0x7e998b13cf4e1ecb},
-    {0xbfc2ef456ae276e8, 0x9e3fedd8c321a67e},
-    {0xefb3ab16c59b14a2, 0xc5cfe94ef3ea101e},
-    {0x95d04aee3b80ece5, 0xbba1f1d158724a12},
-    {0xbb445da9ca61281f, 0x2a8a6e45ae8edc97},
-    {0xea1575143cf97226, 0xf52d09d71a3293bd},
-    {0x924d692ca61be758, 0x593c2626705f9c56},
-    {0xb6e0c377cfa2e12e, 0x6f8b2fb00c77836c},
-    {0xe498f455c38b997a, 0x0b6dfb9c0f956447},
-    {0x8edf98b59a373fec, 0x4724bd4189bd5eac},
-    {0xb2977ee300c50fe7, 0x58edec91ec2cb657},
-    {0xdf3d5e9bc0f653e1, 0x2f2967b66737e3ed},
-    {0x8b865b215899f46c, 0xbd79e0d20082ee74},
-    {0xae67f1e9aec07187, 0xecd8590680a3aa11},
-    {0xda01ee641a708de9, 0xe80e6f4820cc9495},
-    {0x884134fe908658b2, 0x3109058d147fdcdd},
-    {0xaa51823e34a7eede, 0xbd4b46f0599fd415},
-    {0xd4e5e2cdc1d1ea96, 0x6c9e18ac7007c91a},
-    {0x850fadc09923329e, 0x03e2cf6bc604ddb0},
-    {0xa6539930bf6bff45, 0x84db8346b786151c},
-    {0xcfe87f7cef46ff16, 0xe612641865679a63},
-    {0x81f14fae158c5f6e, 0x4fcb7e8f3f60c07e},
-    {0xa26da3999aef7749, 0xe3be5e330f38f09d},
-    {0xcb090c8001ab551c, 0x5cadf5bfd3072cc5},
-    {0xfdcb4fa002162a63, 0x73d9732fc7c8f7f6},
-    {0x9e9f11c4014dda7e, 0x2867e7fddcdd9afa},
-    {0xc646d63501a1511d, 0xb281e1fd541501b8},
-    {0xf7d88bc24209a565, 0x1f225a7ca91a4226},
-    {0x9ae757596946075f, 0x3375788de9b06958},
-    {0xc1a12d2fc3978937, 0x0052d6b1641c83ae},
-    {0xf209787bb47d6b84, 0xc0678c5dbd23a49a},
-    {0x9745eb4d50ce6332, 0xf840b7ba963646e0},
-    {0xbd176620a501fbff, 0xb650e5a93bc3d898},
-    {0xec5d3fa8ce427aff, 0xa3e51f138ab4cebe},
-    {0x93ba47c980e98cdf, 0xc66f336c36b10137},
-    {0xb8a8d9bbe123f017, 0xb80b0047445d4184},
-    {0xe6d3102ad96cec1d, 0xa60dc059157491e5},
-    {0x9043ea1ac7e41392, 0x87c89837ad68db2f},
-    {0xb454e4a179dd1877, 0x29babe4598c311fb},
-    {0xe16a1dc9d8545e94, 0xf4296dd6fef3d67a},
-    {0x8ce2529e2734bb1d, 0x1899e4a65f58660c},
-    {0xb01ae745b101e9e4, 0x5ec05dcff72e7f8f},
-    {0xdc21a1171d42645d, 0x76707543f4fa1f73},
-    {0x899504ae72497eba, 0x6a06494a791c53a8},
-    {0xabfa45da0edbde69, 0x0487db9d17636892},
-    {0xd6f8d7509292d603, 0x45a9d2845d3c42b6},
-    {0x865b86925b9bc5c2, 0x0b8a2392ba45a9b2},
-    {0xa7f26836f282b732, 0x8e6cac7768d7141e},
-    {0xd1ef0244af2364ff, 0x3207d795430cd926},
-    {0x8335616aed761f1f, 0x7f44e6bd49e807b8},
-    {0xa402b9c5a8d3a6e7, 0x5f16206c9c6209a6},
-    {0xcd036837130890a1, 0x36dba887c37a8c0f},
-    {0x802221226be55a64, 0xc2494954da2c9789},
-    {0xa02aa96b06deb0fd, 0xf2db9baa10b7bd6c},
-    {0xc83553c5c8965d3d, 0x6f92829494e5acc7},
-    {0xfa42a8b73abbf48c, 0xcb772339ba1f17f9},
-    {0x9c69a97284b578d7, 0xff2a760414536efb},
-    {0xc38413cf25e2d70d, 0xfef5138519684aba},
-    {0xf46518c2ef5b8cd1, 0x7eb258665fc25d69},
-    {0x98bf2f79d5993802, 0xef2f773ffbd97a61},
-    {0xbeeefb584aff8603, 0xaafb550ffacfd8fa},
-    {0xeeaaba2e5dbf6784, 0x95ba2a53f983cf38},
-    {0x952ab45cfa97a0b2, 0xdd945a747bf26183},
-    {0xba756174393d88df, 0x94f971119aeef9e4},
-    {0xe912b9d1478ceb17, 0x7a37cd5601aab85d},
-    {0x91abb422ccb812ee, 0xac62e055c10ab33a},
-    {0xb616a12b7fe617aa, 0x577b986b314d6009},
-    {0xe39c49765fdf9d94, 0xed5a7e85fda0b80b},
-    {0x8e41ade9fbebc27d, 0x14588f13be847307},
-    {0xb1d219647ae6b31c, 0x596eb2d8ae258fc8},
-    {0xde469fbd99a05fe3, 0x6fca5f8ed9aef3bb},
-    {0x8aec23d680043bee, 0x25de7bb9480d5854},
-    {0xada72ccc20054ae9, 0xaf561aa79a10ae6a},
-    {0xd910f7ff28069da4, 0x1b2ba1518094da04},
-    {0x87aa9aff79042286, 0x90fb44d2f05d0842},
-    {0xa99541bf57452b28, 0x353a1607ac744a53},
-    {0xd3fa922f2d1675f2, 0x42889b8997915ce8},
-    {0x847c9b5d7c2e09b7, 0x69956135febada11},
-    {0xa59bc234db398c25, 0x43fab9837e699095},
-    {0xcf02b2c21207ef2e, 0x94f967e45e03f4bb},
-    {0x8161afb94b44f57d, 0x1d1be0eebac278f5},
-    {0xa1ba1ba79e1632dc, 0x6462d92a69731732},
-    {0xca28a291859bbf93, 0x7d7b8f7503cfdcfe},
-    {0xfcb2cb35e702af78, 0x5cda735244c3d43e},
-    {0x9defbf01b061adab, 0x3a0888136afa64a7},
-    {0xc56baec21c7a1916, 0x088aaa1845b8fdd0},
-    {0xf6c69a72a3989f5b, 0x8aad549e57273d45},
-    {0x9a3c2087a63f6399, 0x36ac54e2f678864b},
-    {0xc0cb28a98fcf3c7f, 0x84576a1bb416a7dd},
-    {0xf0fdf2d3f3c30b9f, 0x656d44a2a11c51d5},
-    {0x969eb7c47859e743, 0x9f644ae5a4b1b325},
-    {0xbc4665b596706114, 0x873d5d9f0dde1fee},
-    {0xeb57ff22fc0c7959, 0xa90cb506d155a7ea},
-    {0x9316ff75dd87cbd8, 0x09a7f12442d588f2},
-    {0xb7dcbf5354e9bece, 0x0c11ed6d538aeb2f},
-    {0xe5d3ef282a242e81, 0x8f1668c8a86da5fa},
-    {0x8fa475791a569d10, 0xf96e017d694487bc},
-    {0xb38d92d760ec4455, 0x37c981dcc395a9ac},
-    {0xe070f78d3927556a, 0x85bbe253f47b1417},
-    {0x8c469ab843b89562, 0x93956d7478ccec8e},
-    {0xaf58416654a6babb, 0x387ac8d1970027b2},
-    {0xdb2e51bfe9d0696a, 0x06997b05fcc0319e},
-    {0x88fcf317f22241e2, 0x441fece3bdf81f03},
-    {0xab3c2fddeeaad25a, 0xd527e81cad7626c3},
-    {0xd60b3bd56a5586f1, 0x8a71e223d8d3b074},
-    {0x85c7056562757456, 0xf6872d5667844e49},
-    {0xa738c6bebb12d16c, 0xb428f8ac016561db},
-    {0xd106f86e69d785c7, 0xe13336d701beba52},
-    {0x82a45b450226b39c, 0xecc0024661173473},
-    {0xa34d721642b06084, 0x27f002d7f95d0190},
-    {0xcc20ce9bd35c78a5, 0x31ec038df7b441f4},
-    {0xff290242c83396ce, 0x7e67047175a15271},
-    {0x9f79a169bd203e41, 0x0f0062c6e984d386},
-    {0xc75809c42c684dd1, 0x52c07b78a3e60868},
-    {0xf92e0c3537826145, 0xa7709a56ccdf8a82},
-    {0x9bbcc7a142b17ccb, 0x88a66076400bb691},
-    {0xc2abf989935ddbfe, 0x6acff893d00ea435},
-    {0xf356f7ebf83552fe, 0x0583f6b8c4124d43},
-    {0x98165af37b2153de, 0xc3727a337a8b704a},
-    {0xbe1bf1b059e9a8d6, 0x744f18c0592e4c5c},
-    {0xeda2ee1c7064130c, 0x1162def06f79df73},
-    {0x9485d4d1c63e8be7, 0x8addcb5645ac2ba8},
-    {0xb9a74a0637ce2ee1, 0x6d953e2bd7173692},
-    {0xe8111c87c5c1ba99, 0xc8fa8db6ccdd0437},
-    {0x910ab1d4db9914a0, 0x1d9c9892400a22a2},
-    {0xb54d5e4a127f59c8, 0x2503beb6d00cab4b},
-    {0xe2a0b5dc971f303a, 0x2e44ae64840fd61d},
-    {0x8da471a9de737e24, 0x5ceaecfed289e5d2},
-    {0xb10d8e1456105dad, 0x7425a83e872c5f47},
-    {0xdd50f1996b947518, 0xd12f124e28f77719},
-    {0x8a5296ffe33cc92f, 0x82bd6b70d99aaa6f},
-    {0xace73cbfdc0bfb7b, 0x636cc64d1001550b},
-    {0xd8210befd30efa5a, 0x3c47f7e05401aa4e},
-    {0x8714a775e3e95c78, 0x65acfaec34810a71},
-    {0xa8d9d1535ce3b396, 0x7f1839a741a14d0d},
-    {0xd31045a8341ca07c, 0x1ede48111209a050},
-    {0x83ea2b892091e44d, 0x934aed0aab460432},
-    {0xa4e4b66b68b65d60, 0xf81da84d5617853f},
-    {0xce1de40642e3f4b9, 0x36251260ab9d668e},
-    {0x80d2ae83e9ce78f3, 0xc1d72b7c6b426019},
-    {0xa1075a24e4421730, 0xb24cf65b8612f81f},
-    {0xc94930ae1d529cfc, 0xdee033f26797b627},
-    {0xfb9b7cd9a4a7443c, 0x169840ef017da3b1},
-    {0x9d412e0806e88aa5, 0x8e1f289560ee864e},
-    {0xc491798a08a2ad4e, 0xf1a6f2bab92a27e2},
-    {0xf5b5d7ec8acb58a2, 0xae10af696774b1db},
-    {0x9991a6f3d6bf1765, 0xacca6da1e0a8ef29},
-    {0xbff610b0cc6edd3f, 0x17fd090a58d32af3},
-    {0xeff394dcff8a948e, 0xddfc4b4cef07f5b0},
-    {0x95f83d0a1fb69cd9, 0x4abdaf101564f98e},
-    {0xbb764c4ca7a4440f, 0x9d6d1ad41abe37f1},
-    {0xea53df5fd18d5513, 0x84c86189216dc5ed},
-    {0x92746b9be2f8552c, 0x32fd3cf5b4e49bb4},
-    {0xb7118682dbb66a77, 0x3fbc8c33221dc2a1},
-    {0xe4d5e82392a40515, 0x0fabaf3feaa5334a},
-    {0x8f05b1163ba6832d, 0x29cb4d87f2a7400e},
-    {0xb2c71d5bca9023f8, 0x743e20e9ef511012},
-    {0xdf78e4b2bd342cf6, 0x914da9246b255416},
-    {0x8bab8eefb6409c1a, 0x1ad089b6c2f7548e},
-    {0xae9672aba3d0c320, 0xa184ac2473b529b1},
-    {0xda3c0f568cc4f3e8, 0xc9e5d72d90a2741e},
-    {0x8865899617fb1871, 0x7e2fa67c7a658892},
-    {0xaa7eebfb9df9de8d, 0xddbb901b98feeab7},
-    {0xd51ea6fa85785631, 0x552a74227f3ea565},
-    {0x8533285c936b35de, 0xd53a88958f87275f},
-    {0xa67ff273b8460356, 0x8a892abaf368f137},
-    {0xd01fef10a657842c, 0x2d2b7569b0432d85},
-    {0x8213f56a67f6b29b, 0x9c3b29620e29fc73},
-    {0xa298f2c501f45f42, 0x8349f3ba91b47b8f},
-    {0xcb3f2f7642717713, 0x241c70a936219a73},
-    {0xfe0efb53d30dd4d7, 0xed238cd383aa0110},
-    {0x9ec95d1463e8a506, 0xf4363804324a40aa},
-    {0xc67bb4597ce2ce48, 0xb143c6053edcd0d5},
-    {0xf81aa16fdc1b81da, 0xdd94b7868e94050a},
-    {0x9b10a4e5e9913128, 0xca7cf2b4191c8326},
-    {0xc1d4ce1f63f57d72, 0xfd1c2f611f63a3f0},
-    {0xf24a01a73cf2dccf, 0xbc633b39673c8cec},
-    {0x976e41088617ca01, 0xd5be0503e085d813},
-    {0xbd49d14aa79dbc82, 0x4b2d8644d8a74e18},
-    {0xec9c459d51852ba2, 0xddf8e7d60ed1219e},
-    {0x93e1ab8252f33b45, 0xcabb90e5c942b503},
-    {0xb8da1662e7b00a17, 0x3d6a751f3b936243},
-    {0xe7109bfba19c0c9d, 0x0cc512670a783ad4},
-    {0x906a617d450187e2, 0x27fb2b80668b24c5},
-    {0xb484f9dc9641e9da, 0xb1f9f660802dedf6},
-    {0xe1a63853bbd26451, 0x5e7873f8a0396973},
-    {0x8d07e33455637eb2, 0xdb0b487b6423e1e8},
-    {0xb049dc016abc5e5f, 0x91ce1a9a3d2cda62},
-    {0xdc5c5301c56b75f7, 0x7641a140cc7810fb},
-    {0x89b9b3e11b6329ba, 0xa9e904c87fcb0a9d},
-    {0xac2820d9623bf429, 0x546345fa9fbdcd44},
-    {0xd732290fbacaf133, 0xa97c177947ad4095},
-    {0x867f59a9d4bed6c0, 0x49ed8eabcccc485d},
-    {0xa81f301449ee8c70, 0x5c68f256bfff5a74},
-    {0xd226fc195c6a2f8c, 0x73832eec6fff3111},
-    {0x83585d8fd9c25db7, 0xc831fd53c5ff7eab},
-    {0xa42e74f3d032f525, 0xba3e7ca8b77f5e55},
-    {0xcd3a1230c43fb26f, 0x28ce1bd2e55f35eb},
-    {0x80444b5e7aa7cf85, 0x7980d163cf5b81b3},
-    {0xa0555e361951c366, 0xd7e105bcc332621f},
-    {0xc86ab5c39fa63440, 0x8dd9472bf3fefaa7},
-    {0xfa856334878fc150, 0xb14f98f6f0feb951},
-    {0x9c935e00d4b9d8d2, 0x6ed1bf9a569f33d3},
-    {0xc3b8358109e84f07, 0x0a862f80ec4700c8},
-    {0xf4a642e14c6262c8, 0xcd27bb612758c0fa},
-    {0x98e7e9cccfbd7dbd, 0x8038d51cb897789c},
-    {0xbf21e44003acdd2c, 0xe0470a63e6bd56c3},
-    {0xeeea5d5004981478, 0x1858ccfce06cac74},
-    {0x95527a5202df0ccb, 0x0f37801e0c43ebc8},
-    {0xbaa718e68396cffd, 0xd30560258f54e6ba},
-    {0xe950df20247c83fd, 0x47c6b82ef32a2069},
-    {0x91d28b7416cdd27e, 0x4cdc331d57fa5441},
-    {0xb6472e511c81471d, 0xe0133fe4adf8e952},
-    {0xe3d8f9e563a198e5, 0x58180fddd97723a6},
-    {0x8e679c2f5e44ff8f, 0x570f09eaa7ea7648},
-    {0xb201833b35d63f73, 0x2cd2cc6551e513da},
-    {0xde81e40a034bcf4f, 0xf8077f7ea65e58d1},
-    {0x8b112e86420f6191, 0xfb04afaf27faf782},
-    {0xadd57a27d29339f6, 0x79c5db9af1f9b563},
-    {0xd94ad8b1c7380874, 0x18375281ae7822bc},
-    {0x87cec76f1c830548, 0x8f2293910d0b15b5},
-    {0xa9c2794ae3a3c69a, 0xb2eb3875504ddb22},
-    {0xd433179d9c8cb841, 0x5fa60692a46151eb},
-    {0x849feec281d7f328, 0xdbc7c41ba6bcd333},
-    {0xa5c7ea73224deff3, 0x12b9b522906c0800},
-    {0xcf39e50feae16bef, 0xd768226b34870a00},
-    {0x81842f29f2cce375, 0xe6a1158300d46640},
-    {0xa1e53af46f801c53, 0x60495ae3c1097fd0},
-    {0xca5e89b18b602368, 0x385bb19cb14bdfc4},
-    {0xfcf62c1dee382c42, 0x46729e03dd9ed7b5},
-    {0x9e19db92b4e31ba9, 0x6c07a2c26a8346d1},
-    {0xc5a05277621be293, 0xc7098b7305241885},
-    {0xf70867153aa2db38, 0xb8cbee4fc66d1ea7}
-#else
-    {0xff77b1fcbebcdc4f, 0x25e8e89c13bb0f7b},
-    {0xce5d73ff402d98e3, 0xfb0a3d212dc81290},
-    {0xa6b34ad8c9dfc06f, 0xf42faa48c0ea481f},
-    {0x86a8d39ef77164bc, 0xae5dff9c02033198},
-    {0xd98ddaee19068c76, 0x3badd624dd9b0958},
-    {0xafbd2350644eeacf, 0xe5d1929ef90898fb},
-    {0x8df5efabc5979c8f, 0xca8d3ffa1ef463c2},
-    {0xe55990879ddcaabd, 0xcc420a6a101d0516},
-    {0xb94470938fa89bce, 0xf808e40e8d5b3e6a},
-    {0x95a8637627989aad, 0xdde7001379a44aa9},
-    {0xf1c90080baf72cb1, 0x5324c68b12dd6339},
-    {0xc350000000000000, 0x0000000000000000},
-    {0x9dc5ada82b70b59d, 0xf020000000000000},
-    {0xfee50b7025c36a08, 0x02f236d04753d5b4},
-    {0xcde6fd5e09abcf26, 0xed4c0226b55e6f86},
-    {0xa6539930bf6bff45, 0x84db8346b786151c},
-    {0x865b86925b9bc5c2, 0x0b8a2392ba45a9b2},
-    {0xd910f7ff28069da4, 0x1b2ba1518094da04},
-    {0xaf58416654a6babb, 0x387ac8d1970027b2},
-    {0x8da471a9de737e24, 0x5ceaecfed289e5d2},
-    {0xe4d5e82392a40515, 0x0fabaf3feaa5334a},
-    {0xb8da1662e7b00a17, 0x3d6a751f3b936243},
-    {0x95527a5202df0ccb, 0x0f37801e0c43ebc8}
+#if FMT_GCC_VERSION && FMT_GCC_VERSION < 409
+#  pragma GCC diagnostic push
+#  pragma GCC diagnostic ignored "-Wnarrowing"
 #endif
+  // Binary exponents of pow(10, k), for k = -348, -340, ..., 340, corresponding
+  // to significands above.
+  static constexpr int16_t pow10_exponents[87] = {
+      -1220, -1193, -1166, -1140, -1113, -1087, -1060, -1034, -1007, -980, -954,
+      -927,  -901,  -874,  -847,  -821,  -794,  -768,  -741,  -715,  -688, -661,
+      -635,  -608,  -582,  -555,  -529,  -502,  -475,  -449,  -422,  -396, -369,
+      -343,  -316,  -289,  -263,  -236,  -210,  -183,  -157,  -130,  -103, -77,
+      -50,   -24,   3,     30,    56,    83,    109,   136,   162,   189,  216,
+      242,   269,   295,   322,   348,   375,   402,   428,   455,   481,  508,
+      534,   561,   588,   614,   641,   667,   694,   720,   747,   774,  800,
+      827,   853,   880,   907,   933,   960,   986,   1013,  1039,  1066};
+#if FMT_GCC_VERSION && FMT_GCC_VERSION < 409
+#  pragma GCC diagnostic pop
+#endif
+
+  static constexpr uint64_t power_of_10_64[20] = {
+      1, FMT_POWERS_OF_10(1ULL), FMT_POWERS_OF_10(1000000000ULL),
+      10000000000000000000ULL};
 };
 
-#if !FMT_USE_FULL_CACHE_DRAGONBOX
-template <typename T>
-const uint64_t basic_data<T>::powers_of_5_64[] = {
-    0x0000000000000001, 0x0000000000000005, 0x0000000000000019,
-    0x000000000000007d, 0x0000000000000271, 0x0000000000000c35,
-    0x0000000000003d09, 0x000000000001312d, 0x000000000005f5e1,
-    0x00000000001dcd65, 0x00000000009502f9, 0x0000000002e90edd,
-    0x000000000e8d4a51, 0x0000000048c27395, 0x000000016bcc41e9,
-    0x000000071afd498d, 0x0000002386f26fc1, 0x000000b1a2bc2ec5,
-    0x000003782dace9d9, 0x00001158e460913d, 0x000056bc75e2d631,
-    0x0001b1ae4d6e2ef5, 0x000878678326eac9, 0x002a5a058fc295ed,
-    0x00d3c21bcecceda1, 0x0422ca8b0a00a425, 0x14adf4b7320334b9};
+// This is a struct rather than an alias to avoid shadowing warnings in gcc.
+struct impl_data : basic_impl_data<> {};
 
+#if __cplusplus < 201703L
 template <typename T>
-const uint32_t basic_data<T>::dragonbox_pow10_recovery_errors[] = {
-    0x50001400, 0x54044100, 0x54014555, 0x55954415, 0x54115555, 0x00000001,
-    0x50000000, 0x00104000, 0x54010004, 0x05004001, 0x55555544, 0x41545555,
-    0x54040551, 0x15445545, 0x51555514, 0x10000015, 0x00101100, 0x01100015,
-    0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x04450514, 0x45414110,
-    0x55555145, 0x50544050, 0x15040155, 0x11054140, 0x50111514, 0x11451454,
-    0x00400541, 0x00000000, 0x55555450, 0x10056551, 0x10054011, 0x55551014,
-    0x69514555, 0x05151109, 0x00155555};
+constexpr uint64_t basic_impl_data<T>::pow10_significands[];
+template <typename T> constexpr int16_t basic_impl_data<T>::pow10_exponents[];
+template <typename T> constexpr uint64_t basic_impl_data<T>::power_of_10_64[];
 #endif
 
-template <typename T>
-const char basic_data<T>::foreground_color[] = "\x1b[38;2;";
-template <typename T>
-const char basic_data<T>::background_color[] = "\x1b[48;2;";
-template <typename T> const char basic_data<T>::reset_color[] = "\x1b[0m";
-template <typename T> const wchar_t basic_data<T>::wreset_color[] = L"\x1b[0m";
-template <typename T> const char basic_data<T>::signs[] = {0, '-', '+', ' '};
-template <typename T>
-const char basic_data<T>::left_padding_shifts[] = {31, 31, 0, 1, 0};
-template <typename T>
-const char basic_data<T>::right_padding_shifts[] = {0, 31, 0, 1, 0};
-
 template <typename T> struct bits {
   static FMT_CONSTEXPR_DECL const int value =
       static_cast<int>(sizeof(T) * std::numeric_limits<unsigned char>::digits);
 };
 
-class fp;
-template <int SHIFT = 0> fp normalize(fp value);
+// Returns the number of significand bits in Float excluding the implicit bit.
+template <typename Float> constexpr int num_significand_bits() {
+  // Subtract 1 to account for an implicit most significant bit in the
+  // normalized form.
+  return std::numeric_limits<Float>::digits - 1;
+}
 
-// Lower (upper) boundary is a value half way between a floating-point value
-// and its predecessor (successor). Boundaries have the same exponent as the
-// value so only significands are stored.
-struct boundaries {
-  uint64_t lower;
-  uint64_t upper;
-};
+// A floating-point number f * pow(2, e).
+struct fp {
+  uint64_t f;
+  int e;
 
-// A handmade floating-point number f * pow(2, e).
-class fp {
- private:
-  using significand_type = uint64_t;
+  static constexpr const int num_significand_bits = bits<decltype(f)>::value;
 
-  template <typename Float>
-  using is_supported_float = bool_constant<sizeof(Float) == sizeof(uint64_t) ||
-                                           sizeof(Float) == sizeof(uint32_t)>;
+  constexpr fp() : f(0), e(0) {}
+  constexpr fp(uint64_t f_val, int e_val) : f(f_val), e(e_val) {}
 
- public:
-  significand_type f;
-  int e;
+  // Constructs fp from an IEEE754 floating-point number. It is a template to
+  // prevent compile errors on systems where n is not IEEE754.
+  template <typename Float> explicit FMT_CONSTEXPR fp(Float n) { assign(n); }
 
-  // All sizes are in bits.
-  // Subtract 1 to account for an implicit most significant bit in the
-  // normalized form.
-  static FMT_CONSTEXPR_DECL const int double_significand_size =
-      std::numeric_limits<double>::digits - 1;
-  static FMT_CONSTEXPR_DECL const uint64_t implicit_bit =
-      1ULL << double_significand_size;
-  static FMT_CONSTEXPR_DECL const int significand_size =
-      bits<significand_type>::value;
-
-  fp() : f(0), e(0) {}
-  fp(uint64_t f_val, int e_val) : f(f_val), e(e_val) {}
-
-  // Constructs fp from an IEEE754 double. It is a template to prevent compile
-  // errors on platforms where double is not IEEE754.
-  template <typename Double> explicit fp(Double d) { assign(d); }
+  template <typename Float>
+  using is_supported = bool_constant<sizeof(Float) == sizeof(uint64_t) ||
+                                     sizeof(Float) == sizeof(uint32_t)>;
 
   // Assigns d to this and return true iff predecessor is closer than successor.
-  template <typename Float, FMT_ENABLE_IF(is_supported_float<Float>::value)>
-  bool assign(Float d) {
+  template <typename Float, FMT_ENABLE_IF(is_supported<Float>::value)>
+  FMT_CONSTEXPR bool assign(Float n) {
     // Assume float is in the format [sign][exponent][significand].
-    using limits = std::numeric_limits<Float>;
-    const int float_significand_size = limits::digits - 1;
-    const int exponent_size =
-        bits<Float>::value - float_significand_size - 1;  // -1 for sign
-    const uint64_t float_implicit_bit = 1ULL << float_significand_size;
-    const uint64_t significand_mask = float_implicit_bit - 1;
-    const uint64_t exponent_mask = (~0ULL >> 1) & ~significand_mask;
-    const int exponent_bias = (1 << exponent_size) - limits::max_exponent - 1;
+    const int num_float_significand_bits =
+        detail::num_significand_bits<Float>();
+    const uint64_t implicit_bit = 1ULL << num_float_significand_bits;
+    const uint64_t significand_mask = implicit_bit - 1;
     constexpr bool is_double = sizeof(Float) == sizeof(uint64_t);
-    auto u = bit_cast<conditional_t<is_double, uint64_t, uint32_t>>(d);
+    auto u = bit_cast<conditional_t<is_double, uint64_t, uint32_t>>(n);
     f = u & significand_mask;
+    const uint64_t exponent_mask = (~0ULL >> 1) & ~significand_mask;
     int biased_e =
-        static_cast<int>((u & exponent_mask) >> float_significand_size);
-    // Predecessor is closer if d is a normalized power of 2 (f == 0) other than
-    // the smallest normalized number (biased_e > 1).
+        static_cast<int>((u & exponent_mask) >> num_float_significand_bits);
+    // The predecessor is closer if n is a normalized power of 2 (f == 0) other
+    // than the smallest normalized number (biased_e > 1).
     bool is_predecessor_closer = f == 0 && biased_e > 1;
     if (biased_e != 0)
-      f += float_implicit_bit;
+      f += implicit_bit;
     else
       biased_e = 1;  // Subnormals use biased exponent 1 (min exponent).
-    e = biased_e - exponent_bias - float_significand_size;
+    const int exponent_bias = std::numeric_limits<Float>::max_exponent - 1;
+    e = biased_e - exponent_bias - num_float_significand_bits;
     return is_predecessor_closer;
   }
 
-  template <typename Float, FMT_ENABLE_IF(!is_supported_float<Float>::value)>
+  template <typename Float, FMT_ENABLE_IF(!is_supported<Float>::value)>
   bool assign(Float) {
-    *this = fp();
+    FMT_ASSERT(false, "");
     return false;
   }
 };
 
 // Normalizes the value converted from double and multiplied by (1 << SHIFT).
-template <int SHIFT> fp normalize(fp value) {
+template <int SHIFT = 0> FMT_CONSTEXPR fp normalize(fp value) {
   // Handle subnormals.
-  const auto shifted_implicit_bit = fp::implicit_bit << SHIFT;
+  const uint64_t implicit_bit = 1ULL << num_significand_bits<double>();
+  const auto shifted_implicit_bit = implicit_bit << SHIFT;
   while ((value.f & shifted_implicit_bit) == 0) {
     value.f <<= 1;
     --value.e;
   }
   // Subtract 1 to account for hidden bit.
   const auto offset =
-      fp::significand_size - fp::double_significand_size - SHIFT - 1;
+      fp::num_significand_bits - num_significand_bits<double>() - SHIFT - 1;
   value.f <<= offset;
   value.e -= offset;
   return value;
 }
 
 inline bool operator==(fp x, fp y) { return x.f == y.f && x.e == y.e; }
 
 // Computes lhs * rhs / pow(2, 64) rounded to nearest with half-up tie breaking.
-inline uint64_t multiply(uint64_t lhs, uint64_t rhs) {
+FMT_CONSTEXPR inline uint64_t multiply(uint64_t lhs, uint64_t rhs) {
 #if FMT_USE_INT128
   auto product = static_cast<__uint128_t>(lhs) * rhs;
   auto f = static_cast<uint64_t>(product >> 64);
   return (static_cast<uint64_t>(product) & (1ULL << 63)) != 0 ? f + 1 : f;
 #else
   // Multiply 32-bit parts of significands.
   uint64_t mask = (1ULL << 32) - 1;
@@ -1188,51 +317,56 @@
   uint64_t ac = a * c, bc = b * c, ad = a * d, bd = b * d;
   // Compute mid 64-bit of result and round.
   uint64_t mid = (bd >> 32) + (ad & mask) + (bc & mask) + (1U << 31);
   return ac + (ad >> 32) + (bc >> 32) + (mid >> 32);
 #endif
 }
 
-inline fp operator*(fp x, fp y) { return {multiply(x.f, y.f), x.e + y.e + 64}; }
+FMT_CONSTEXPR inline fp operator*(fp x, fp y) {
+  return {multiply(x.f, y.f), x.e + y.e + 64};
+}
 
 // Returns a cached power of 10 `c_k = c_k.f * pow(2, c_k.e)` such that its
 // (binary) exponent satisfies `min_exponent <= c_k.e <= min_exponent + 28`.
-inline fp get_cached_power(int min_exponent, int& pow10_exponent) {
+FMT_CONSTEXPR inline fp get_cached_power(int min_exponent,
+                                         int& pow10_exponent) {
   const int shift = 32;
-  const auto significand = static_cast<int64_t>(data::log10_2_significand);
+  const auto significand = static_cast<int64_t>(log10_2_significand);
   int index = static_cast<int>(
-      ((min_exponent + fp::significand_size - 1) * (significand >> shift) +
+      ((min_exponent + fp::num_significand_bits - 1) * (significand >> shift) +
        ((int64_t(1) << shift) - 1))  // ceil
       >> 32                          // arithmetic shift
   );
   // Decimal exponent of the first (smallest) cached power of 10.
   const int first_dec_exp = -348;
   // Difference between 2 consecutive decimal exponents in cached powers of 10.
   const int dec_exp_step = 8;
   index = (index - first_dec_exp - 1) / dec_exp_step + 1;
   pow10_exponent = first_dec_exp + index * dec_exp_step;
-  return {data::grisu_pow10_significands[index],
-          data::grisu_pow10_exponents[index]};
+  return {impl_data::pow10_significands[index],
+          impl_data::pow10_exponents[index]};
 }
 
 // A simple accumulator to hold the sums of terms in bigint::square if uint128_t
 // is not available.
 struct accumulator {
   uint64_t lower;
   uint64_t upper;
 
-  accumulator() : lower(0), upper(0) {}
-  explicit operator uint32_t() const { return static_cast<uint32_t>(lower); }
+  constexpr accumulator() : lower(0), upper(0) {}
+  constexpr explicit operator uint32_t() const {
+    return static_cast<uint32_t>(lower);
+  }
 
-  void operator+=(uint64_t n) {
+  FMT_CONSTEXPR void operator+=(uint64_t n) {
     lower += n;
     if (lower < n) ++upper;
   }
-  void operator>>=(int shift) {
-    assert(shift == 32);
+  FMT_CONSTEXPR void operator>>=(int shift) {
+    FMT_ASSERT(shift == 32, "");
     (void)shift;
     lower = (upper << 32) | (lower >> 32);
     upper >>= 32;
   }
 };
 
 class bigint {
@@ -1241,57 +375,61 @@
   // 0 being the least significant one.
   using bigit = uint32_t;
   using double_bigit = uint64_t;
   enum { bigits_capacity = 32 };
   basic_memory_buffer<bigit, bigits_capacity> bigits_;
   int exp_;
 
-  bigit operator[](int index) const { return bigits_[to_unsigned(index)]; }
-  bigit& operator[](int index) { return bigits_[to_unsigned(index)]; }
+  FMT_CONSTEXPR20 bigit operator[](int index) const {
+    return bigits_[to_unsigned(index)];
+  }
+  FMT_CONSTEXPR20 bigit& operator[](int index) {
+    return bigits_[to_unsigned(index)];
+  }
 
   static FMT_CONSTEXPR_DECL const int bigit_bits = bits<bigit>::value;
 
   friend struct formatter<bigint>;
 
-  void subtract_bigits(int index, bigit other, bigit& borrow) {
+  FMT_CONSTEXPR20 void subtract_bigits(int index, bigit other, bigit& borrow) {
     auto result = static_cast<double_bigit>((*this)[index]) - other - borrow;
     (*this)[index] = static_cast<bigit>(result);
     borrow = static_cast<bigit>(result >> (bigit_bits * 2 - 1));
   }
 
-  void remove_leading_zeros() {
+  FMT_CONSTEXPR20 void remove_leading_zeros() {
     int num_bigits = static_cast<int>(bigits_.size()) - 1;
     while (num_bigits > 0 && (*this)[num_bigits] == 0) --num_bigits;
     bigits_.resize(to_unsigned(num_bigits + 1));
   }
 
   // Computes *this -= other assuming aligned bigints and *this >= other.
-  void subtract_aligned(const bigint& other) {
+  FMT_CONSTEXPR20 void subtract_aligned(const bigint& other) {
     FMT_ASSERT(other.exp_ >= exp_, "unaligned bigints");
     FMT_ASSERT(compare(*this, other) >= 0, "");
     bigit borrow = 0;
     int i = other.exp_ - exp_;
     for (size_t j = 0, n = other.bigits_.size(); j != n; ++i, ++j)
       subtract_bigits(i, other.bigits_[j], borrow);
     while (borrow > 0) subtract_bigits(i, 0, borrow);
     remove_leading_zeros();
   }
 
-  void multiply(uint32_t value) {
+  FMT_CONSTEXPR20 void multiply(uint32_t value) {
     const double_bigit wide_value = value;
     bigit carry = 0;
     for (size_t i = 0, n = bigits_.size(); i < n; ++i) {
       double_bigit result = bigits_[i] * wide_value + carry;
       bigits_[i] = static_cast<bigit>(result);
       carry = static_cast<bigit>(result >> bigit_bits);
     }
     if (carry != 0) bigits_.push_back(carry);
   }
 
-  void multiply(uint64_t value) {
+  FMT_CONSTEXPR20 void multiply(uint64_t value) {
     const bigit mask = ~bigit(0);
     const double_bigit lower = value & mask;
     const double_bigit upper = value >> bigit_bits;
     double_bigit carry = 0;
     for (size_t i = 0, n = bigits_.size(); i < n; ++i) {
       double_bigit result = bigits_[i] * lower + (carry & mask);
       carry =
@@ -1301,63 +439,67 @@
     while (carry != 0) {
       bigits_.push_back(carry & mask);
       carry >>= bigit_bits;
     }
   }
 
  public:
-  bigint() : exp_(0) {}
+  FMT_CONSTEXPR20 bigint() : exp_(0) {}
   explicit bigint(uint64_t n) { assign(n); }
-  ~bigint() { assert(bigits_.capacity() <= bigits_capacity); }
+  FMT_CONSTEXPR20 ~bigint() {
+    FMT_ASSERT(bigits_.capacity() <= bigits_capacity, "");
+  }
 
   bigint(const bigint&) = delete;
   void operator=(const bigint&) = delete;
 
-  void assign(const bigint& other) {
+  FMT_CONSTEXPR20 void assign(const bigint& other) {
     auto size = other.bigits_.size();
     bigits_.resize(size);
     auto data = other.bigits_.data();
     std::copy(data, data + size, make_checked(bigits_.data(), size));
     exp_ = other.exp_;
   }
 
-  void assign(uint64_t n) {
+  FMT_CONSTEXPR20 void assign(uint64_t n) {
     size_t num_bigits = 0;
     do {
       bigits_[num_bigits++] = n & ~bigit(0);
       n >>= bigit_bits;
     } while (n != 0);
     bigits_.resize(num_bigits);
     exp_ = 0;
   }
 
-  int num_bigits() const { return static_cast<int>(bigits_.size()) + exp_; }
+  FMT_CONSTEXPR20 int num_bigits() const {
+    return static_cast<int>(bigits_.size()) + exp_;
+  }
 
-  FMT_NOINLINE bigint& operator<<=(int shift) {
-    assert(shift >= 0);
+  FMT_NOINLINE FMT_CONSTEXPR20 bigint& operator<<=(int shift) {
+    FMT_ASSERT(shift >= 0, "");
     exp_ += shift / bigit_bits;
     shift %= bigit_bits;
     if (shift == 0) return *this;
     bigit carry = 0;
     for (size_t i = 0, n = bigits_.size(); i < n; ++i) {
       bigit c = bigits_[i] >> (bigit_bits - shift);
       bigits_[i] = (bigits_[i] << shift) + carry;
       carry = c;
     }
     if (carry != 0) bigits_.push_back(carry);
     return *this;
   }
 
-  template <typename Int> bigint& operator*=(Int value) {
+  template <typename Int> FMT_CONSTEXPR20 bigint& operator*=(Int value) {
     FMT_ASSERT(value > 0, "");
     multiply(uint32_or_64_or_128_t<Int>(value));
     return *this;
   }
 
-  friend int compare(const bigint& lhs, const bigint& rhs) {
+  friend FMT_CONSTEXPR20 int compare(const bigint& lhs, const bigint& rhs) {
     int num_lhs_bigits = lhs.num_bigits(), num_rhs_bigits = rhs.num_bigits();
     if (num_lhs_bigits != num_rhs_bigits)
       return num_lhs_bigits > num_rhs_bigits ? 1 : -1;
     int i = static_cast<int>(lhs.bigits_.size()) - 1;
     int j = static_cast<int>(rhs.bigits_.size()) - 1;
     int end = i - j;
     if (end < 0) end = 0;
@@ -1366,16 +508,16 @@
       if (lhs_bigit != rhs_bigit) return lhs_bigit > rhs_bigit ? 1 : -1;
     }
     if (i != j) return i > j ? 1 : -1;
     return 0;
   }
 
   // Returns compare(lhs1 + lhs2, rhs).
-  friend int add_compare(const bigint& lhs1, const bigint& lhs2,
-                         const bigint& rhs) {
+  friend FMT_CONSTEXPR20 int add_compare(const bigint& lhs1, const bigint& lhs2,
+                                         const bigint& rhs) {
     int max_lhs_bigits = (std::max)(lhs1.num_bigits(), lhs2.num_bigits());
     int num_rhs_bigits = rhs.num_bigits();
     if (max_lhs_bigits + 1 < num_rhs_bigits) return -1;
     if (max_lhs_bigits > num_rhs_bigits) return 1;
     auto get_bigit = [](const bigint& n, int i) -> bigit {
       return i >= n.exp_ && i < n.num_bigits() ? n[i - n.exp_] : 0;
     };
@@ -1390,16 +532,16 @@
       if (borrow > 1) return -1;
       borrow <<= bigit_bits;
     }
     return borrow != 0 ? -1 : 0;
   }
 
   // Assigns pow(10, exp) to this bigint.
-  void assign_pow10(int exp) {
-    assert(exp >= 0);
+  FMT_CONSTEXPR20 void assign_pow10(int exp) {
+    FMT_ASSERT(exp >= 0, "");
     if (exp == 0) return assign(1);
     // Find the top bit.
     int bitmask = 1;
     while (exp >= bitmask) bitmask <<= 1;
     bitmask >>= 1;
     // pow(10, exp) = pow(5, exp) * pow(2, exp). First compute pow(5, exp) by
     // repeated squaring and multiplication.
@@ -1409,18 +551,18 @@
       square();
       if ((exp & bitmask) != 0) *this *= 5;
       bitmask >>= 1;
     }
     *this <<= exp;  // Multiply by pow(2, exp) by shifting.
   }
 
-  void square() {
-    basic_memory_buffer<bigit, bigits_capacity> n(std::move(bigits_));
+  FMT_CONSTEXPR20 void square() {
     int num_bigits = static_cast<int>(bigits_.size());
     int num_result_bigits = 2 * num_bigits;
+    basic_memory_buffer<bigit, bigits_capacity> n(std::move(bigits_));
     bigits_.resize(to_unsigned(num_result_bigits));
     using accumulator_t = conditional_t<FMT_USE_INT128, uint128_t, accumulator>;
     auto sum = accumulator_t();
     for (int bigit_index = 0; bigit_index < num_bigits; ++bigit_index) {
       // Compute bigit at position bigit_index of the result by adding
       // cross-product terms n[i] * n[j] such that i + j == bigit_index.
       for (int i = 0, j = bigit_index; j >= 0; ++i, --j) {
@@ -1434,35 +576,34 @@
     for (int bigit_index = num_bigits; bigit_index < num_result_bigits;
          ++bigit_index) {
       for (int j = num_bigits - 1, i = bigit_index - j; i < num_bigits;)
         sum += static_cast<double_bigit>(n[i++]) * n[j--];
       (*this)[bigit_index] = static_cast<bigit>(sum);
       sum >>= bits<bigit>::value;
     }
-    --num_result_bigits;
     remove_leading_zeros();
     exp_ *= 2;
   }
 
   // If this bigint has a bigger exponent than other, adds trailing zero to make
   // exponents equal. This simplifies some operations such as subtraction.
-  void align(const bigint& other) {
+  FMT_CONSTEXPR20 void align(const bigint& other) {
     int exp_difference = exp_ - other.exp_;
     if (exp_difference <= 0) return;
     int num_bigits = static_cast<int>(bigits_.size());
     bigits_.resize(to_unsigned(num_bigits + exp_difference));
     for (int i = num_bigits - 1, j = i + exp_difference; i >= 0; --i, --j)
       bigits_[j] = bigits_[i];
     std::uninitialized_fill_n(bigits_.data(), exp_difference, 0);
     exp_ -= exp_difference;
   }
 
   // Divides this bignum by divisor, assigning the remainder to this and
   // returning the quotient.
-  int divmod_assign(const bigint& divisor) {
+  FMT_CONSTEXPR20 int divmod_assign(const bigint& divisor) {
     FMT_ASSERT(this != &divisor, "");
     if (compare(*this, divisor) < 0) return 0;
     FMT_ASSERT(divisor.bigits_[divisor.bigits_.size() - 1u] != 0, "");
     align(divisor);
     int quotient = 0;
     do {
       subtract_aligned(divisor);
@@ -1474,16 +615,17 @@
 
 enum class round_direction { unknown, up, down };
 
 // Given the divisor (normally a power of 10), the remainder = v % divisor for
 // some number v and the error, returns whether v should be rounded up, down, or
 // whether the rounding direction can't be determined due to error.
 // error should be less than divisor / 2.
-inline round_direction get_round_direction(uint64_t divisor, uint64_t remainder,
-                                           uint64_t error) {
+FMT_CONSTEXPR inline round_direction get_round_direction(uint64_t divisor,
+                                                         uint64_t remainder,
+                                                         uint64_t error) {
   FMT_ASSERT(remainder < divisor, "");  // divisor - remainder won't overflow.
   FMT_ASSERT(error < divisor, "");      // divisor - error won't overflow.
   FMT_ASSERT(error < divisor - error, "");  // error * 2 won't overflow.
   // Round down if (remainder + error) * 2 <= divisor.
   if (remainder <= divisor - remainder && error * 2 <= divisor - remainder * 2)
     return round_direction::down;
   // Round up if (remainder - error) * 2 >= divisor.
@@ -1498,34 +640,92 @@
 enum result {
   more,  // Generate more digits.
   done,  // Done generating digits.
   error  // Digit generation cancelled due to an error.
 };
 }
 
+struct gen_digits_handler {
+  char* buf;
+  int size;
+  int precision;
+  int exp10;
+  bool fixed;
+
+  FMT_CONSTEXPR digits::result on_digit(char digit, uint64_t divisor,
+                                        uint64_t remainder, uint64_t error,
+                                        bool integral) {
+    FMT_ASSERT(remainder < divisor, "");
+    buf[size++] = digit;
+    if (!integral && error >= remainder) return digits::error;
+    if (size < precision) return digits::more;
+    if (!integral) {
+      // Check if error * 2 < divisor with overflow prevention.
+      // The check is not needed for the integral part because error = 1
+      // and divisor > (1 << 32) there.
+      if (error >= divisor || error >= divisor - error) return digits::error;
+    } else {
+      FMT_ASSERT(error == 1 && divisor > 2, "");
+    }
+    auto dir = get_round_direction(divisor, remainder, error);
+    if (dir != round_direction::up)
+      return dir == round_direction::down ? digits::done : digits::error;
+    ++buf[size - 1];
+    for (int i = size - 1; i > 0 && buf[i] > '9'; --i) {
+      buf[i] = '0';
+      ++buf[i - 1];
+    }
+    if (buf[0] > '9') {
+      buf[0] = '1';
+      if (fixed)
+        buf[size++] = '0';
+      else
+        ++exp10;
+    }
+    return digits::done;
+  }
+};
+
 // Generates output using the Grisu digit-gen algorithm.
 // error: the size of the region (lower, upper) outside of which numbers
 // definitely do not round to value (Delta in Grisu3).
-template <typename Handler>
-FMT_ALWAYS_INLINE digits::result grisu_gen_digits(fp value, uint64_t error,
-                                                  int& exp, Handler& handler) {
+FMT_INLINE FMT_CONSTEXPR20 digits::result grisu_gen_digits(
+    fp value, uint64_t error, int& exp, gen_digits_handler& handler) {
   const fp one(1ULL << -value.e, value.e);
   // The integral part of scaled value (p1 in Grisu) = value / one. It cannot be
   // zero because it contains a product of two 64-bit numbers with MSB set (due
   // to normalization) - 1, shifted right by at most 60 bits.
   auto integral = static_cast<uint32_t>(value.f >> -one.e);
   FMT_ASSERT(integral != 0, "");
   FMT_ASSERT(integral == value.f >> -one.e, "");
   // The fractional part of scaled value (p2 in Grisu) c = value % one.
   uint64_t fractional = value.f & (one.f - 1);
   exp = count_digits(integral);  // kappa in Grisu.
-  // Divide by 10 to prevent overflow.
-  auto result = handler.on_start(data::powers_of_10_64[exp - 1] << -one.e,
-                                 value.f / 10, error * 10, exp);
-  if (result != digits::more) return result;
+  // Non-fixed formats require at least one digit and no precision adjustment.
+  if (handler.fixed) {
+    // Adjust fixed precision by exponent because it is relative to decimal
+    // point.
+    int precision_offset = exp + handler.exp10;
+    if (precision_offset > 0 &&
+        handler.precision > max_value<int>() - precision_offset) {
+      FMT_THROW(format_error("number is too big"));
+    }
+    handler.precision += precision_offset;
+    // Check if precision is satisfied just by leading zeros, e.g.
+    // format("{:.2f}", 0.001) gives "0.00" without generating any digits.
+    if (handler.precision <= 0) {
+      if (handler.precision < 0) return digits::done;
+      // Divide by 10 to prevent overflow.
+      uint64_t divisor = impl_data::power_of_10_64[exp - 1] << -one.e;
+      auto dir = get_round_direction(divisor, value.f / 10, error * 10);
+      if (dir == round_direction::unknown) return digits::error;
+      handler.buf[handler.size++] = dir == round_direction::up ? '1' : '0';
+      return digits::done;
+    }
+  }
   // Generate digits for the integral part. This can produce up to 10 digits.
   do {
     uint32_t digit = 0;
     auto divmod_integral = [&](uint32_t divisor) {
       digit = integral / divisor;
       integral %= divisor;
     };
@@ -1564,94 +764,83 @@
       integral = 0;
       break;
     default:
       FMT_ASSERT(false, "invalid number of digits");
     }
     --exp;
     auto remainder = (static_cast<uint64_t>(integral) << -one.e) + fractional;
-    result = handler.on_digit(static_cast<char>('0' + digit),
-                              data::powers_of_10_64[exp] << -one.e, remainder,
-                              error, exp, true);
+    auto result = handler.on_digit(static_cast<char>('0' + digit),
+                                   impl_data::power_of_10_64[exp] << -one.e,
+                                   remainder, error, true);
     if (result != digits::more) return result;
   } while (exp > 0);
   // Generate digits for the fractional part.
   for (;;) {
     fractional *= 10;
     error *= 10;
     char digit = static_cast<char>('0' + (fractional >> -one.e));
     fractional &= one.f - 1;
     --exp;
-    result = handler.on_digit(digit, one.f, fractional, error, exp, false);
+    auto result = handler.on_digit(digit, one.f, fractional, error, false);
     if (result != digits::more) return result;
   }
 }
 
-// The fixed precision digit handler.
-struct fixed_handler {
-  char* buf;
-  int size;
-  int precision;
-  int exp10;
-  bool fixed;
+// A 128-bit integer type used internally,
+struct uint128_wrapper {
+  uint128_wrapper() = default;
 
-  digits::result on_start(uint64_t divisor, uint64_t remainder, uint64_t error,
-                          int& exp) {
-    // Non-fixed formats require at least one digit and no precision adjustment.
-    if (!fixed) return digits::more;
-    // Adjust fixed precision by exponent because it is relative to decimal
-    // point.
-    precision += exp + exp10;
-    // Check if precision is satisfied just by leading zeros, e.g.
-    // format("{:.2f}", 0.001) gives "0.00" without generating any digits.
-    if (precision > 0) return digits::more;
-    if (precision < 0) return digits::done;
-    auto dir = get_round_direction(divisor, remainder, error);
-    if (dir == round_direction::unknown) return digits::error;
-    buf[size++] = dir == round_direction::up ? '1' : '0';
-    return digits::done;
+#if FMT_USE_INT128
+  uint128_t internal_;
+
+  constexpr uint128_wrapper(uint64_t high, uint64_t low) FMT_NOEXCEPT
+      : internal_{static_cast<uint128_t>(low) |
+                  (static_cast<uint128_t>(high) << 64)} {}
+
+  constexpr uint128_wrapper(uint128_t u) : internal_{u} {}
+
+  constexpr uint64_t high() const FMT_NOEXCEPT {
+    return uint64_t(internal_ >> 64);
   }
+  constexpr uint64_t low() const FMT_NOEXCEPT { return uint64_t(internal_); }
 
-  digits::result on_digit(char digit, uint64_t divisor, uint64_t remainder,
-                          uint64_t error, int, bool integral) {
-    FMT_ASSERT(remainder < divisor, "");
-    buf[size++] = digit;
-    if (!integral && error >= remainder) return digits::error;
-    if (size < precision) return digits::more;
-    if (!integral) {
-      // Check if error * 2 < divisor with overflow prevention.
-      // The check is not needed for the integral part because error = 1
-      // and divisor > (1 << 32) there.
-      if (error >= divisor || error >= divisor - error) return digits::error;
-    } else {
-      FMT_ASSERT(error == 1 && divisor > 2, "");
-    }
-    auto dir = get_round_direction(divisor, remainder, error);
-    if (dir != round_direction::up)
-      return dir == round_direction::down ? digits::done : digits::error;
-    ++buf[size - 1];
-    for (int i = size - 1; i > 0 && buf[i] > '9'; --i) {
-      buf[i] = '0';
-      ++buf[i - 1];
-    }
-    if (buf[0] > '9') {
-      buf[0] = '1';
-      if (fixed)
-        buf[size++] = '0';
-      else
-        ++exp10;
-    }
-    return digits::done;
+  uint128_wrapper& operator+=(uint64_t n) FMT_NOEXCEPT {
+    internal_ += n;
+    return *this;
+  }
+#else
+  uint64_t high_;
+  uint64_t low_;
+
+  constexpr uint128_wrapper(uint64_t high, uint64_t low) FMT_NOEXCEPT
+      : high_{high},
+        low_{low} {}
+
+  constexpr uint64_t high() const FMT_NOEXCEPT { return high_; }
+  constexpr uint64_t low() const FMT_NOEXCEPT { return low_; }
+
+  uint128_wrapper& operator+=(uint64_t n) FMT_NOEXCEPT {
+#  if defined(_MSC_VER) && defined(_M_X64)
+    unsigned char carry = _addcarry_u64(0, low_, n, &low_);
+    _addcarry_u64(carry, high_, 0, &high_);
+    return *this;
+#  else
+    uint64_t sum = low_ + n;
+    high_ += (sum < low_ ? 1 : 0);
+    low_ = sum;
+    return *this;
+#  endif
   }
+#endif
 };
 
 // Implementation of Dragonbox algorithm: https://github.com/jk-jeon/dragonbox.
 namespace dragonbox {
 // Computes 128-bit result of multiplication of two 64-bit unsigned integers.
-FMT_SAFEBUFFERS inline uint128_wrapper umul128(uint64_t x,
-                                               uint64_t y) FMT_NOEXCEPT {
+inline uint128_wrapper umul128(uint64_t x, uint64_t y) FMT_NOEXCEPT {
 #if FMT_USE_INT128
   return static_cast<uint128_t>(x) * static_cast<uint128_t>(y);
 #elif defined(_MSC_VER) && defined(_M_X64)
   uint128_wrapper result;
   result.low_ = _umul128(x, y, &result.high_);
   return result;
 #else
@@ -1671,45 +860,42 @@
 
   return {ac + (intermediate >> 32) + (ad >> 32) + (bc >> 32),
           (intermediate << 32) + (bd & mask)};
 #endif
 }
 
 // Computes upper 64 bits of multiplication of two 64-bit unsigned integers.
-FMT_SAFEBUFFERS inline uint64_t umul128_upper64(uint64_t x,
-                                                uint64_t y) FMT_NOEXCEPT {
+inline uint64_t umul128_upper64(uint64_t x, uint64_t y) FMT_NOEXCEPT {
 #if FMT_USE_INT128
   auto p = static_cast<uint128_t>(x) * static_cast<uint128_t>(y);
   return static_cast<uint64_t>(p >> 64);
 #elif defined(_MSC_VER) && defined(_M_X64)
   return __umulh(x, y);
 #else
   return umul128(x, y).high();
 #endif
 }
 
 // Computes upper 64 bits of multiplication of a 64-bit unsigned integer and a
 // 128-bit unsigned integer.
-FMT_SAFEBUFFERS inline uint64_t umul192_upper64(uint64_t x, uint128_wrapper y)
-    FMT_NOEXCEPT {
+inline uint64_t umul192_upper64(uint64_t x, uint128_wrapper y) FMT_NOEXCEPT {
   uint128_wrapper g0 = umul128(x, y.high());
   g0 += umul128_upper64(x, y.low());
   return g0.high();
 }
 
 // Computes upper 32 bits of multiplication of a 32-bit unsigned integer and a
 // 64-bit unsigned integer.
 inline uint32_t umul96_upper32(uint32_t x, uint64_t y) FMT_NOEXCEPT {
   return static_cast<uint32_t>(umul128_upper64(x, y));
 }
 
 // Computes middle 64 bits of multiplication of a 64-bit unsigned integer and a
 // 128-bit unsigned integer.
-FMT_SAFEBUFFERS inline uint64_t umul192_middle64(uint64_t x, uint128_wrapper y)
-    FMT_NOEXCEPT {
+inline uint64_t umul192_middle64(uint64_t x, uint128_wrapper y) FMT_NOEXCEPT {
   uint64_t g01 = x * y.high();
   uint64_t g10 = umul128_upper64(x, y.low());
   return g01 + g10;
 }
 
 // Computes lower 64 bits of multiplication of a 32-bit unsigned integer and a
 // 64-bit unsigned integer.
@@ -1718,16 +904,15 @@
 }
 
 // Computes floor(log10(pow(2, e))) for e in [-1700, 1700] using the method from
 // https://fmt.dev/papers/Grisu-Exact.pdf#page=5, section 3.4.
 inline int floor_log10_pow2(int e) FMT_NOEXCEPT {
   FMT_ASSERT(e <= 1700 && e >= -1700, "too large exponent");
   const int shift = 22;
-  return (e * static_cast<int>(data::log10_2_significand >> (64 - shift))) >>
-         shift;
+  return (e * static_cast<int>(log10_2_significand >> (64 - shift))) >> shift;
 }
 
 // Various fast log computations.
 inline int floor_log2_pow10(int e) FMT_NOEXCEPT {
   FMT_ASSERT(e <= 1233 && e >= -1233, "too large exponent");
   const uint64_t log2_10_integer_part = 3;
   const uint64_t log2_10_fractional_digits = 0x5269e12f346e2bf9;
@@ -1737,16 +922,15 @@
                   (log2_10_fractional_digits >> (64 - shift_amount)))) >>
          shift_amount;
 }
 inline int floor_log10_pow2_minus_log10_4_over_3(int e) FMT_NOEXCEPT {
   FMT_ASSERT(e <= 1700 && e >= -1700, "too large exponent");
   const uint64_t log10_4_over_3_fractional_digits = 0x1ffbfc2bbc780375;
   const int shift_amount = 22;
-  return (e * static_cast<int>(data::log10_2_significand >>
-                               (64 - shift_amount)) -
+  return (e * static_cast<int>(log10_2_significand >> (64 - shift_amount)) -
           static_cast<int>(log10_4_over_3_fractional_digits >>
                            (64 - shift_amount))) >>
          shift_amount;
 }
 
 // Returns true iff x is divisible by pow(2, exp).
 inline bool divisible_by_power_of_2(uint32_t x, int exp) FMT_NOEXCEPT {
@@ -1764,24 +948,60 @@
 #ifdef FMT_BUILTIN_CTZLL
   return FMT_BUILTIN_CTZLL(x) >= exp;
 #else
   return exp < num_bits<uint64_t>() && x == ((x >> exp) << exp);
 #endif
 }
 
+// Table entry type for divisibility test.
+template <typename T> struct divtest_table_entry {
+  T mod_inv;
+  T max_quotient;
+};
+
 // Returns true iff x is divisible by pow(5, exp).
 inline bool divisible_by_power_of_5(uint32_t x, int exp) FMT_NOEXCEPT {
   FMT_ASSERT(exp <= 10, "too large exponent");
-  return x * data::divtest_table_for_pow5_32[exp].mod_inv <=
-         data::divtest_table_for_pow5_32[exp].max_quotient;
+  static constexpr const divtest_table_entry<uint32_t> divtest_table[] = {
+      {0x00000001, 0xffffffff}, {0xcccccccd, 0x33333333},
+      {0xc28f5c29, 0x0a3d70a3}, {0x26e978d5, 0x020c49ba},
+      {0x3afb7e91, 0x0068db8b}, {0x0bcbe61d, 0x0014f8b5},
+      {0x68c26139, 0x000431bd}, {0xae8d46a5, 0x0000d6bf},
+      {0x22e90e21, 0x00002af3}, {0x3a2e9c6d, 0x00000897},
+      {0x3ed61f49, 0x000001b7}};
+  return x * divtest_table[exp].mod_inv <= divtest_table[exp].max_quotient;
 }
 inline bool divisible_by_power_of_5(uint64_t x, int exp) FMT_NOEXCEPT {
   FMT_ASSERT(exp <= 23, "too large exponent");
-  return x * data::divtest_table_for_pow5_64[exp].mod_inv <=
-         data::divtest_table_for_pow5_64[exp].max_quotient;
+  static constexpr const divtest_table_entry<uint64_t> divtest_table[] = {
+      {0x0000000000000001, 0xffffffffffffffff},
+      {0xcccccccccccccccd, 0x3333333333333333},
+      {0x8f5c28f5c28f5c29, 0x0a3d70a3d70a3d70},
+      {0x1cac083126e978d5, 0x020c49ba5e353f7c},
+      {0xd288ce703afb7e91, 0x0068db8bac710cb2},
+      {0x5d4e8fb00bcbe61d, 0x0014f8b588e368f0},
+      {0x790fb65668c26139, 0x000431bde82d7b63},
+      {0xe5032477ae8d46a5, 0x0000d6bf94d5e57a},
+      {0xc767074b22e90e21, 0x00002af31dc46118},
+      {0x8e47ce423a2e9c6d, 0x0000089705f4136b},
+      {0x4fa7f60d3ed61f49, 0x000001b7cdfd9d7b},
+      {0x0fee64690c913975, 0x00000057f5ff85e5},
+      {0x3662e0e1cf503eb1, 0x000000119799812d},
+      {0xa47a2cf9f6433fbd, 0x0000000384b84d09},
+      {0x54186f653140a659, 0x00000000b424dc35},
+      {0x7738164770402145, 0x0000000024075f3d},
+      {0xe4a4d1417cd9a041, 0x000000000734aca5},
+      {0xc75429d9e5c5200d, 0x000000000170ef54},
+      {0xc1773b91fac10669, 0x000000000049c977},
+      {0x26b172506559ce15, 0x00000000000ec1e4},
+      {0xd489e3a9addec2d1, 0x000000000002f394},
+      {0x90e860bb892c8d5d, 0x000000000000971d},
+      {0x502e79bf1b6f4f79, 0x0000000000001e39},
+      {0xdcd618596be30fe5, 0x000000000000060b}};
+  return x * divtest_table[exp].mod_inv <= divtest_table[exp].max_quotient;
 }
 
 // Replaces n by floor(n / pow(5, N)) returning true if and only if n is
 // divisible by pow(5, N).
 // Precondition: n <= 2 * pow(5, N + 1).
 template <int N>
 bool check_divisibility_and_divide_by_pow5(uint32_t& n) FMT_NOEXCEPT {
@@ -1827,15 +1047,42 @@
 template <> struct cache_accessor<float> {
   using carrier_uint = float_info<float>::carrier_uint;
   using cache_entry_type = uint64_t;
 
   static uint64_t get_cached_power(int k) FMT_NOEXCEPT {
     FMT_ASSERT(k >= float_info<float>::min_k && k <= float_info<float>::max_k,
                "k is out of range");
-    return data::dragonbox_pow10_significands_64[k - float_info<float>::min_k];
+    static constexpr const uint64_t pow10_significands[] = {
+        0x81ceb32c4b43fcf5, 0xa2425ff75e14fc32, 0xcad2f7f5359a3b3f,
+        0xfd87b5f28300ca0e, 0x9e74d1b791e07e49, 0xc612062576589ddb,
+        0xf79687aed3eec552, 0x9abe14cd44753b53, 0xc16d9a0095928a28,
+        0xf1c90080baf72cb2, 0x971da05074da7bef, 0xbce5086492111aeb,
+        0xec1e4a7db69561a6, 0x9392ee8e921d5d08, 0xb877aa3236a4b44a,
+        0xe69594bec44de15c, 0x901d7cf73ab0acda, 0xb424dc35095cd810,
+        0xe12e13424bb40e14, 0x8cbccc096f5088cc, 0xafebff0bcb24aaff,
+        0xdbe6fecebdedd5bf, 0x89705f4136b4a598, 0xabcc77118461cefd,
+        0xd6bf94d5e57a42bd, 0x8637bd05af6c69b6, 0xa7c5ac471b478424,
+        0xd1b71758e219652c, 0x83126e978d4fdf3c, 0xa3d70a3d70a3d70b,
+        0xcccccccccccccccd, 0x8000000000000000, 0xa000000000000000,
+        0xc800000000000000, 0xfa00000000000000, 0x9c40000000000000,
+        0xc350000000000000, 0xf424000000000000, 0x9896800000000000,
+        0xbebc200000000000, 0xee6b280000000000, 0x9502f90000000000,
+        0xba43b74000000000, 0xe8d4a51000000000, 0x9184e72a00000000,
+        0xb5e620f480000000, 0xe35fa931a0000000, 0x8e1bc9bf04000000,
+        0xb1a2bc2ec5000000, 0xde0b6b3a76400000, 0x8ac7230489e80000,
+        0xad78ebc5ac620000, 0xd8d726b7177a8000, 0x878678326eac9000,
+        0xa968163f0a57b400, 0xd3c21bcecceda100, 0x84595161401484a0,
+        0xa56fa5b99019a5c8, 0xcecb8f27f4200f3a, 0x813f3978f8940984,
+        0xa18f07d736b90be5, 0xc9f2c9cd04674ede, 0xfc6f7c4045812296,
+        0x9dc5ada82b70b59d, 0xc5371912364ce305, 0xf684df56c3e01bc6,
+        0x9a130b963a6c115c, 0xc097ce7bc90715b3, 0xf0bdc21abb48db20,
+        0x96769950b50d88f4, 0xbc143fa4e250eb31, 0xeb194f8e1ae525fd,
+        0x92efd1b8d0cf37be, 0xb7abc627050305ad, 0xe596b7b0c643c719,
+        0x8f7e32ce7bea5c6f, 0xb35dbf821ae4f38b, 0xe0352f62a19e306e};
+    return pow10_significands[k - float_info<float>::min_k];
   }
 
   static carrier_uint compute_mul(carrier_uint u,
                                   const cache_entry_type& cache) FMT_NOEXCEPT {
     return umul96_upper32(u, cache);
   }
 
@@ -1881,36 +1128,704 @@
   using carrier_uint = float_info<double>::carrier_uint;
   using cache_entry_type = uint128_wrapper;
 
   static uint128_wrapper get_cached_power(int k) FMT_NOEXCEPT {
     FMT_ASSERT(k >= float_info<double>::min_k && k <= float_info<double>::max_k,
                "k is out of range");
 
+    static constexpr const uint128_wrapper pow10_significands[] = {
 #if FMT_USE_FULL_CACHE_DRAGONBOX
-    return data::dragonbox_pow10_significands_128[k -
-                                                  float_info<double>::min_k];
+      {0xff77b1fcbebcdc4f, 0x25e8e89c13bb0f7b},
+      {0x9faacf3df73609b1, 0x77b191618c54e9ad},
+      {0xc795830d75038c1d, 0xd59df5b9ef6a2418},
+      {0xf97ae3d0d2446f25, 0x4b0573286b44ad1e},
+      {0x9becce62836ac577, 0x4ee367f9430aec33},
+      {0xc2e801fb244576d5, 0x229c41f793cda740},
+      {0xf3a20279ed56d48a, 0x6b43527578c11110},
+      {0x9845418c345644d6, 0x830a13896b78aaaa},
+      {0xbe5691ef416bd60c, 0x23cc986bc656d554},
+      {0xedec366b11c6cb8f, 0x2cbfbe86b7ec8aa9},
+      {0x94b3a202eb1c3f39, 0x7bf7d71432f3d6aa},
+      {0xb9e08a83a5e34f07, 0xdaf5ccd93fb0cc54},
+      {0xe858ad248f5c22c9, 0xd1b3400f8f9cff69},
+      {0x91376c36d99995be, 0x23100809b9c21fa2},
+      {0xb58547448ffffb2d, 0xabd40a0c2832a78b},
+      {0xe2e69915b3fff9f9, 0x16c90c8f323f516d},
+      {0x8dd01fad907ffc3b, 0xae3da7d97f6792e4},
+      {0xb1442798f49ffb4a, 0x99cd11cfdf41779d},
+      {0xdd95317f31c7fa1d, 0x40405643d711d584},
+      {0x8a7d3eef7f1cfc52, 0x482835ea666b2573},
+      {0xad1c8eab5ee43b66, 0xda3243650005eed0},
+      {0xd863b256369d4a40, 0x90bed43e40076a83},
+      {0x873e4f75e2224e68, 0x5a7744a6e804a292},
+      {0xa90de3535aaae202, 0x711515d0a205cb37},
+      {0xd3515c2831559a83, 0x0d5a5b44ca873e04},
+      {0x8412d9991ed58091, 0xe858790afe9486c3},
+      {0xa5178fff668ae0b6, 0x626e974dbe39a873},
+      {0xce5d73ff402d98e3, 0xfb0a3d212dc81290},
+      {0x80fa687f881c7f8e, 0x7ce66634bc9d0b9a},
+      {0xa139029f6a239f72, 0x1c1fffc1ebc44e81},
+      {0xc987434744ac874e, 0xa327ffb266b56221},
+      {0xfbe9141915d7a922, 0x4bf1ff9f0062baa9},
+      {0x9d71ac8fada6c9b5, 0x6f773fc3603db4aa},
+      {0xc4ce17b399107c22, 0xcb550fb4384d21d4},
+      {0xf6019da07f549b2b, 0x7e2a53a146606a49},
+      {0x99c102844f94e0fb, 0x2eda7444cbfc426e},
+      {0xc0314325637a1939, 0xfa911155fefb5309},
+      {0xf03d93eebc589f88, 0x793555ab7eba27cb},
+      {0x96267c7535b763b5, 0x4bc1558b2f3458df},
+      {0xbbb01b9283253ca2, 0x9eb1aaedfb016f17},
+      {0xea9c227723ee8bcb, 0x465e15a979c1cadd},
+      {0x92a1958a7675175f, 0x0bfacd89ec191eca},
+      {0xb749faed14125d36, 0xcef980ec671f667c},
+      {0xe51c79a85916f484, 0x82b7e12780e7401b},
+      {0x8f31cc0937ae58d2, 0xd1b2ecb8b0908811},
+      {0xb2fe3f0b8599ef07, 0x861fa7e6dcb4aa16},
+      {0xdfbdcece67006ac9, 0x67a791e093e1d49b},
+      {0x8bd6a141006042bd, 0xe0c8bb2c5c6d24e1},
+      {0xaecc49914078536d, 0x58fae9f773886e19},
+      {0xda7f5bf590966848, 0xaf39a475506a899f},
+      {0x888f99797a5e012d, 0x6d8406c952429604},
+      {0xaab37fd7d8f58178, 0xc8e5087ba6d33b84},
+      {0xd5605fcdcf32e1d6, 0xfb1e4a9a90880a65},
+      {0x855c3be0a17fcd26, 0x5cf2eea09a550680},
+      {0xa6b34ad8c9dfc06f, 0xf42faa48c0ea481f},
+      {0xd0601d8efc57b08b, 0xf13b94daf124da27},
+      {0x823c12795db6ce57, 0x76c53d08d6b70859},
+      {0xa2cb1717b52481ed, 0x54768c4b0c64ca6f},
+      {0xcb7ddcdda26da268, 0xa9942f5dcf7dfd0a},
+      {0xfe5d54150b090b02, 0xd3f93b35435d7c4d},
+      {0x9efa548d26e5a6e1, 0xc47bc5014a1a6db0},
+      {0xc6b8e9b0709f109a, 0x359ab6419ca1091c},
+      {0xf867241c8cc6d4c0, 0xc30163d203c94b63},
+      {0x9b407691d7fc44f8, 0x79e0de63425dcf1e},
+      {0xc21094364dfb5636, 0x985915fc12f542e5},
+      {0xf294b943e17a2bc4, 0x3e6f5b7b17b2939e},
+      {0x979cf3ca6cec5b5a, 0xa705992ceecf9c43},
+      {0xbd8430bd08277231, 0x50c6ff782a838354},
+      {0xece53cec4a314ebd, 0xa4f8bf5635246429},
+      {0x940f4613ae5ed136, 0x871b7795e136be9a},
+      {0xb913179899f68584, 0x28e2557b59846e40},
+      {0xe757dd7ec07426e5, 0x331aeada2fe589d0},
+      {0x9096ea6f3848984f, 0x3ff0d2c85def7622},
+      {0xb4bca50b065abe63, 0x0fed077a756b53aa},
+      {0xe1ebce4dc7f16dfb, 0xd3e8495912c62895},
+      {0x8d3360f09cf6e4bd, 0x64712dd7abbbd95d},
+      {0xb080392cc4349dec, 0xbd8d794d96aacfb4},
+      {0xdca04777f541c567, 0xecf0d7a0fc5583a1},
+      {0x89e42caaf9491b60, 0xf41686c49db57245},
+      {0xac5d37d5b79b6239, 0x311c2875c522ced6},
+      {0xd77485cb25823ac7, 0x7d633293366b828c},
+      {0x86a8d39ef77164bc, 0xae5dff9c02033198},
+      {0xa8530886b54dbdeb, 0xd9f57f830283fdfd},
+      {0xd267caa862a12d66, 0xd072df63c324fd7c},
+      {0x8380dea93da4bc60, 0x4247cb9e59f71e6e},
+      {0xa46116538d0deb78, 0x52d9be85f074e609},
+      {0xcd795be870516656, 0x67902e276c921f8c},
+      {0x806bd9714632dff6, 0x00ba1cd8a3db53b7},
+      {0xa086cfcd97bf97f3, 0x80e8a40eccd228a5},
+      {0xc8a883c0fdaf7df0, 0x6122cd128006b2ce},
+      {0xfad2a4b13d1b5d6c, 0x796b805720085f82},
+      {0x9cc3a6eec6311a63, 0xcbe3303674053bb1},
+      {0xc3f490aa77bd60fc, 0xbedbfc4411068a9d},
+      {0xf4f1b4d515acb93b, 0xee92fb5515482d45},
+      {0x991711052d8bf3c5, 0x751bdd152d4d1c4b},
+      {0xbf5cd54678eef0b6, 0xd262d45a78a0635e},
+      {0xef340a98172aace4, 0x86fb897116c87c35},
+      {0x9580869f0e7aac0e, 0xd45d35e6ae3d4da1},
+      {0xbae0a846d2195712, 0x8974836059cca10a},
+      {0xe998d258869facd7, 0x2bd1a438703fc94c},
+      {0x91ff83775423cc06, 0x7b6306a34627ddd0},
+      {0xb67f6455292cbf08, 0x1a3bc84c17b1d543},
+      {0xe41f3d6a7377eeca, 0x20caba5f1d9e4a94},
+      {0x8e938662882af53e, 0x547eb47b7282ee9d},
+      {0xb23867fb2a35b28d, 0xe99e619a4f23aa44},
+      {0xdec681f9f4c31f31, 0x6405fa00e2ec94d5},
+      {0x8b3c113c38f9f37e, 0xde83bc408dd3dd05},
+      {0xae0b158b4738705e, 0x9624ab50b148d446},
+      {0xd98ddaee19068c76, 0x3badd624dd9b0958},
+      {0x87f8a8d4cfa417c9, 0xe54ca5d70a80e5d7},
+      {0xa9f6d30a038d1dbc, 0x5e9fcf4ccd211f4d},
+      {0xd47487cc8470652b, 0x7647c32000696720},
+      {0x84c8d4dfd2c63f3b, 0x29ecd9f40041e074},
+      {0xa5fb0a17c777cf09, 0xf468107100525891},
+      {0xcf79cc9db955c2cc, 0x7182148d4066eeb5},
+      {0x81ac1fe293d599bf, 0xc6f14cd848405531},
+      {0xa21727db38cb002f, 0xb8ada00e5a506a7d},
+      {0xca9cf1d206fdc03b, 0xa6d90811f0e4851d},
+      {0xfd442e4688bd304a, 0x908f4a166d1da664},
+      {0x9e4a9cec15763e2e, 0x9a598e4e043287ff},
+      {0xc5dd44271ad3cdba, 0x40eff1e1853f29fe},
+      {0xf7549530e188c128, 0xd12bee59e68ef47d},
+      {0x9a94dd3e8cf578b9, 0x82bb74f8301958cf},
+      {0xc13a148e3032d6e7, 0xe36a52363c1faf02},
+      {0xf18899b1bc3f8ca1, 0xdc44e6c3cb279ac2},
+      {0x96f5600f15a7b7e5, 0x29ab103a5ef8c0ba},
+      {0xbcb2b812db11a5de, 0x7415d448f6b6f0e8},
+      {0xebdf661791d60f56, 0x111b495b3464ad22},
+      {0x936b9fcebb25c995, 0xcab10dd900beec35},
+      {0xb84687c269ef3bfb, 0x3d5d514f40eea743},
+      {0xe65829b3046b0afa, 0x0cb4a5a3112a5113},
+      {0x8ff71a0fe2c2e6dc, 0x47f0e785eaba72ac},
+      {0xb3f4e093db73a093, 0x59ed216765690f57},
+      {0xe0f218b8d25088b8, 0x306869c13ec3532d},
+      {0x8c974f7383725573, 0x1e414218c73a13fc},
+      {0xafbd2350644eeacf, 0xe5d1929ef90898fb},
+      {0xdbac6c247d62a583, 0xdf45f746b74abf3a},
+      {0x894bc396ce5da772, 0x6b8bba8c328eb784},
+      {0xab9eb47c81f5114f, 0x066ea92f3f326565},
+      {0xd686619ba27255a2, 0xc80a537b0efefebe},
+      {0x8613fd0145877585, 0xbd06742ce95f5f37},
+      {0xa798fc4196e952e7, 0x2c48113823b73705},
+      {0xd17f3b51fca3a7a0, 0xf75a15862ca504c6},
+      {0x82ef85133de648c4, 0x9a984d73dbe722fc},
+      {0xa3ab66580d5fdaf5, 0xc13e60d0d2e0ebbb},
+      {0xcc963fee10b7d1b3, 0x318df905079926a9},
+      {0xffbbcfe994e5c61f, 0xfdf17746497f7053},
+      {0x9fd561f1fd0f9bd3, 0xfeb6ea8bedefa634},
+      {0xc7caba6e7c5382c8, 0xfe64a52ee96b8fc1},
+      {0xf9bd690a1b68637b, 0x3dfdce7aa3c673b1},
+      {0x9c1661a651213e2d, 0x06bea10ca65c084f},
+      {0xc31bfa0fe5698db8, 0x486e494fcff30a63},
+      {0xf3e2f893dec3f126, 0x5a89dba3c3efccfb},
+      {0x986ddb5c6b3a76b7, 0xf89629465a75e01d},
+      {0xbe89523386091465, 0xf6bbb397f1135824},
+      {0xee2ba6c0678b597f, 0x746aa07ded582e2d},
+      {0x94db483840b717ef, 0xa8c2a44eb4571cdd},
+      {0xba121a4650e4ddeb, 0x92f34d62616ce414},
+      {0xe896a0d7e51e1566, 0x77b020baf9c81d18},
+      {0x915e2486ef32cd60, 0x0ace1474dc1d122f},
+      {0xb5b5ada8aaff80b8, 0x0d819992132456bb},
+      {0xe3231912d5bf60e6, 0x10e1fff697ed6c6a},
+      {0x8df5efabc5979c8f, 0xca8d3ffa1ef463c2},
+      {0xb1736b96b6fd83b3, 0xbd308ff8a6b17cb3},
+      {0xddd0467c64bce4a0, 0xac7cb3f6d05ddbdf},
+      {0x8aa22c0dbef60ee4, 0x6bcdf07a423aa96c},
+      {0xad4ab7112eb3929d, 0x86c16c98d2c953c7},
+      {0xd89d64d57a607744, 0xe871c7bf077ba8b8},
+      {0x87625f056c7c4a8b, 0x11471cd764ad4973},
+      {0xa93af6c6c79b5d2d, 0xd598e40d3dd89bd0},
+      {0xd389b47879823479, 0x4aff1d108d4ec2c4},
+      {0x843610cb4bf160cb, 0xcedf722a585139bb},
+      {0xa54394fe1eedb8fe, 0xc2974eb4ee658829},
+      {0xce947a3da6a9273e, 0x733d226229feea33},
+      {0x811ccc668829b887, 0x0806357d5a3f5260},
+      {0xa163ff802a3426a8, 0xca07c2dcb0cf26f8},
+      {0xc9bcff6034c13052, 0xfc89b393dd02f0b6},
+      {0xfc2c3f3841f17c67, 0xbbac2078d443ace3},
+      {0x9d9ba7832936edc0, 0xd54b944b84aa4c0e},
+      {0xc5029163f384a931, 0x0a9e795e65d4df12},
+      {0xf64335bcf065d37d, 0x4d4617b5ff4a16d6},
+      {0x99ea0196163fa42e, 0x504bced1bf8e4e46},
+      {0xc06481fb9bcf8d39, 0xe45ec2862f71e1d7},
+      {0xf07da27a82c37088, 0x5d767327bb4e5a4d},
+      {0x964e858c91ba2655, 0x3a6a07f8d510f870},
+      {0xbbe226efb628afea, 0x890489f70a55368c},
+      {0xeadab0aba3b2dbe5, 0x2b45ac74ccea842f},
+      {0x92c8ae6b464fc96f, 0x3b0b8bc90012929e},
+      {0xb77ada0617e3bbcb, 0x09ce6ebb40173745},
+      {0xe55990879ddcaabd, 0xcc420a6a101d0516},
+      {0x8f57fa54c2a9eab6, 0x9fa946824a12232e},
+      {0xb32df8e9f3546564, 0x47939822dc96abfa},
+      {0xdff9772470297ebd, 0x59787e2b93bc56f8},
+      {0x8bfbea76c619ef36, 0x57eb4edb3c55b65b},
+      {0xaefae51477a06b03, 0xede622920b6b23f2},
+      {0xdab99e59958885c4, 0xe95fab368e45ecee},
+      {0x88b402f7fd75539b, 0x11dbcb0218ebb415},
+      {0xaae103b5fcd2a881, 0xd652bdc29f26a11a},
+      {0xd59944a37c0752a2, 0x4be76d3346f04960},
+      {0x857fcae62d8493a5, 0x6f70a4400c562ddc},
+      {0xa6dfbd9fb8e5b88e, 0xcb4ccd500f6bb953},
+      {0xd097ad07a71f26b2, 0x7e2000a41346a7a8},
+      {0x825ecc24c873782f, 0x8ed400668c0c28c9},
+      {0xa2f67f2dfa90563b, 0x728900802f0f32fb},
+      {0xcbb41ef979346bca, 0x4f2b40a03ad2ffba},
+      {0xfea126b7d78186bc, 0xe2f610c84987bfa9},
+      {0x9f24b832e6b0f436, 0x0dd9ca7d2df4d7ca},
+      {0xc6ede63fa05d3143, 0x91503d1c79720dbc},
+      {0xf8a95fcf88747d94, 0x75a44c6397ce912b},
+      {0x9b69dbe1b548ce7c, 0xc986afbe3ee11abb},
+      {0xc24452da229b021b, 0xfbe85badce996169},
+      {0xf2d56790ab41c2a2, 0xfae27299423fb9c4},
+      {0x97c560ba6b0919a5, 0xdccd879fc967d41b},
+      {0xbdb6b8e905cb600f, 0x5400e987bbc1c921},
+      {0xed246723473e3813, 0x290123e9aab23b69},
+      {0x9436c0760c86e30b, 0xf9a0b6720aaf6522},
+      {0xb94470938fa89bce, 0xf808e40e8d5b3e6a},
+      {0xe7958cb87392c2c2, 0xb60b1d1230b20e05},
+      {0x90bd77f3483bb9b9, 0xb1c6f22b5e6f48c3},
+      {0xb4ecd5f01a4aa828, 0x1e38aeb6360b1af4},
+      {0xe2280b6c20dd5232, 0x25c6da63c38de1b1},
+      {0x8d590723948a535f, 0x579c487e5a38ad0f},
+      {0xb0af48ec79ace837, 0x2d835a9df0c6d852},
+      {0xdcdb1b2798182244, 0xf8e431456cf88e66},
+      {0x8a08f0f8bf0f156b, 0x1b8e9ecb641b5900},
+      {0xac8b2d36eed2dac5, 0xe272467e3d222f40},
+      {0xd7adf884aa879177, 0x5b0ed81dcc6abb10},
+      {0x86ccbb52ea94baea, 0x98e947129fc2b4ea},
+      {0xa87fea27a539e9a5, 0x3f2398d747b36225},
+      {0xd29fe4b18e88640e, 0x8eec7f0d19a03aae},
+      {0x83a3eeeef9153e89, 0x1953cf68300424ad},
+      {0xa48ceaaab75a8e2b, 0x5fa8c3423c052dd8},
+      {0xcdb02555653131b6, 0x3792f412cb06794e},
+      {0x808e17555f3ebf11, 0xe2bbd88bbee40bd1},
+      {0xa0b19d2ab70e6ed6, 0x5b6aceaeae9d0ec5},
+      {0xc8de047564d20a8b, 0xf245825a5a445276},
+      {0xfb158592be068d2e, 0xeed6e2f0f0d56713},
+      {0x9ced737bb6c4183d, 0x55464dd69685606c},
+      {0xc428d05aa4751e4c, 0xaa97e14c3c26b887},
+      {0xf53304714d9265df, 0xd53dd99f4b3066a9},
+      {0x993fe2c6d07b7fab, 0xe546a8038efe402a},
+      {0xbf8fdb78849a5f96, 0xde98520472bdd034},
+      {0xef73d256a5c0f77c, 0x963e66858f6d4441},
+      {0x95a8637627989aad, 0xdde7001379a44aa9},
+      {0xbb127c53b17ec159, 0x5560c018580d5d53},
+      {0xe9d71b689dde71af, 0xaab8f01e6e10b4a7},
+      {0x9226712162ab070d, 0xcab3961304ca70e9},
+      {0xb6b00d69bb55c8d1, 0x3d607b97c5fd0d23},
+      {0xe45c10c42a2b3b05, 0x8cb89a7db77c506b},
+      {0x8eb98a7a9a5b04e3, 0x77f3608e92adb243},
+      {0xb267ed1940f1c61c, 0x55f038b237591ed4},
+      {0xdf01e85f912e37a3, 0x6b6c46dec52f6689},
+      {0x8b61313bbabce2c6, 0x2323ac4b3b3da016},
+      {0xae397d8aa96c1b77, 0xabec975e0a0d081b},
+      {0xd9c7dced53c72255, 0x96e7bd358c904a22},
+      {0x881cea14545c7575, 0x7e50d64177da2e55},
+      {0xaa242499697392d2, 0xdde50bd1d5d0b9ea},
+      {0xd4ad2dbfc3d07787, 0x955e4ec64b44e865},
+      {0x84ec3c97da624ab4, 0xbd5af13bef0b113f},
+      {0xa6274bbdd0fadd61, 0xecb1ad8aeacdd58f},
+      {0xcfb11ead453994ba, 0x67de18eda5814af3},
+      {0x81ceb32c4b43fcf4, 0x80eacf948770ced8},
+      {0xa2425ff75e14fc31, 0xa1258379a94d028e},
+      {0xcad2f7f5359a3b3e, 0x096ee45813a04331},
+      {0xfd87b5f28300ca0d, 0x8bca9d6e188853fd},
+      {0x9e74d1b791e07e48, 0x775ea264cf55347e},
+      {0xc612062576589dda, 0x95364afe032a819e},
+      {0xf79687aed3eec551, 0x3a83ddbd83f52205},
+      {0x9abe14cd44753b52, 0xc4926a9672793543},
+      {0xc16d9a0095928a27, 0x75b7053c0f178294},
+      {0xf1c90080baf72cb1, 0x5324c68b12dd6339},
+      {0x971da05074da7bee, 0xd3f6fc16ebca5e04},
+      {0xbce5086492111aea, 0x88f4bb1ca6bcf585},
+      {0xec1e4a7db69561a5, 0x2b31e9e3d06c32e6},
+      {0x9392ee8e921d5d07, 0x3aff322e62439fd0},
+      {0xb877aa3236a4b449, 0x09befeb9fad487c3},
+      {0xe69594bec44de15b, 0x4c2ebe687989a9b4},
+      {0x901d7cf73ab0acd9, 0x0f9d37014bf60a11},
+      {0xb424dc35095cd80f, 0x538484c19ef38c95},
+      {0xe12e13424bb40e13, 0x2865a5f206b06fba},
+      {0x8cbccc096f5088cb, 0xf93f87b7442e45d4},
+      {0xafebff0bcb24aafe, 0xf78f69a51539d749},
+      {0xdbe6fecebdedd5be, 0xb573440e5a884d1c},
+      {0x89705f4136b4a597, 0x31680a88f8953031},
+      {0xabcc77118461cefc, 0xfdc20d2b36ba7c3e},
+      {0xd6bf94d5e57a42bc, 0x3d32907604691b4d},
+      {0x8637bd05af6c69b5, 0xa63f9a49c2c1b110},
+      {0xa7c5ac471b478423, 0x0fcf80dc33721d54},
+      {0xd1b71758e219652b, 0xd3c36113404ea4a9},
+      {0x83126e978d4fdf3b, 0x645a1cac083126ea},
+      {0xa3d70a3d70a3d70a, 0x3d70a3d70a3d70a4},
+      {0xcccccccccccccccc, 0xcccccccccccccccd},
+      {0x8000000000000000, 0x0000000000000000},
+      {0xa000000000000000, 0x0000000000000000},
+      {0xc800000000000000, 0x0000000000000000},
+      {0xfa00000000000000, 0x0000000000000000},
+      {0x9c40000000000000, 0x0000000000000000},
+      {0xc350000000000000, 0x0000000000000000},
+      {0xf424000000000000, 0x0000000000000000},
+      {0x9896800000000000, 0x0000000000000000},
+      {0xbebc200000000000, 0x0000000000000000},
+      {0xee6b280000000000, 0x0000000000000000},
+      {0x9502f90000000000, 0x0000000000000000},
+      {0xba43b74000000000, 0x0000000000000000},
+      {0xe8d4a51000000000, 0x0000000000000000},
+      {0x9184e72a00000000, 0x0000000000000000},
+      {0xb5e620f480000000, 0x0000000000000000},
+      {0xe35fa931a0000000, 0x0000000000000000},
+      {0x8e1bc9bf04000000, 0x0000000000000000},
+      {0xb1a2bc2ec5000000, 0x0000000000000000},
+      {0xde0b6b3a76400000, 0x0000000000000000},
+      {0x8ac7230489e80000, 0x0000000000000000},
+      {0xad78ebc5ac620000, 0x0000000000000000},
+      {0xd8d726b7177a8000, 0x0000000000000000},
+      {0x878678326eac9000, 0x0000000000000000},
+      {0xa968163f0a57b400, 0x0000000000000000},
+      {0xd3c21bcecceda100, 0x0000000000000000},
+      {0x84595161401484a0, 0x0000000000000000},
+      {0xa56fa5b99019a5c8, 0x0000000000000000},
+      {0xcecb8f27f4200f3a, 0x0000000000000000},
+      {0x813f3978f8940984, 0x4000000000000000},
+      {0xa18f07d736b90be5, 0x5000000000000000},
+      {0xc9f2c9cd04674ede, 0xa400000000000000},
+      {0xfc6f7c4045812296, 0x4d00000000000000},
+      {0x9dc5ada82b70b59d, 0xf020000000000000},
+      {0xc5371912364ce305, 0x6c28000000000000},
+      {0xf684df56c3e01bc6, 0xc732000000000000},
+      {0x9a130b963a6c115c, 0x3c7f400000000000},
+      {0xc097ce7bc90715b3, 0x4b9f100000000000},
+      {0xf0bdc21abb48db20, 0x1e86d40000000000},
+      {0x96769950b50d88f4, 0x1314448000000000},
+      {0xbc143fa4e250eb31, 0x17d955a000000000},
+      {0xeb194f8e1ae525fd, 0x5dcfab0800000000},
+      {0x92efd1b8d0cf37be, 0x5aa1cae500000000},
+      {0xb7abc627050305ad, 0xf14a3d9e40000000},
+      {0xe596b7b0c643c719, 0x6d9ccd05d0000000},
+      {0x8f7e32ce7bea5c6f, 0xe4820023a2000000},
+      {0xb35dbf821ae4f38b, 0xdda2802c8a800000},
+      {0xe0352f62a19e306e, 0xd50b2037ad200000},
+      {0x8c213d9da502de45, 0x4526f422cc340000},
+      {0xaf298d050e4395d6, 0x9670b12b7f410000},
+      {0xdaf3f04651d47b4c, 0x3c0cdd765f114000},
+      {0x88d8762bf324cd0f, 0xa5880a69fb6ac800},
+      {0xab0e93b6efee0053, 0x8eea0d047a457a00},
+      {0xd5d238a4abe98068, 0x72a4904598d6d880},
+      {0x85a36366eb71f041, 0x47a6da2b7f864750},
+      {0xa70c3c40a64e6c51, 0x999090b65f67d924},
+      {0xd0cf4b50cfe20765, 0xfff4b4e3f741cf6d},
+      {0x82818f1281ed449f, 0xbff8f10e7a8921a4},
+      {0xa321f2d7226895c7, 0xaff72d52192b6a0d},
+      {0xcbea6f8ceb02bb39, 0x9bf4f8a69f764490},
+      {0xfee50b7025c36a08, 0x02f236d04753d5b4},
+      {0x9f4f2726179a2245, 0x01d762422c946590},
+      {0xc722f0ef9d80aad6, 0x424d3ad2b7b97ef5},
+      {0xf8ebad2b84e0d58b, 0xd2e0898765a7deb2},
+      {0x9b934c3b330c8577, 0x63cc55f49f88eb2f},
+      {0xc2781f49ffcfa6d5, 0x3cbf6b71c76b25fb},
+      {0xf316271c7fc3908a, 0x8bef464e3945ef7a},
+      {0x97edd871cfda3a56, 0x97758bf0e3cbb5ac},
+      {0xbde94e8e43d0c8ec, 0x3d52eeed1cbea317},
+      {0xed63a231d4c4fb27, 0x4ca7aaa863ee4bdd},
+      {0x945e455f24fb1cf8, 0x8fe8caa93e74ef6a},
+      {0xb975d6b6ee39e436, 0xb3e2fd538e122b44},
+      {0xe7d34c64a9c85d44, 0x60dbbca87196b616},
+      {0x90e40fbeea1d3a4a, 0xbc8955e946fe31cd},
+      {0xb51d13aea4a488dd, 0x6babab6398bdbe41},
+      {0xe264589a4dcdab14, 0xc696963c7eed2dd1},
+      {0x8d7eb76070a08aec, 0xfc1e1de5cf543ca2},
+      {0xb0de65388cc8ada8, 0x3b25a55f43294bcb},
+      {0xdd15fe86affad912, 0x49ef0eb713f39ebe},
+      {0x8a2dbf142dfcc7ab, 0x6e3569326c784337},
+      {0xacb92ed9397bf996, 0x49c2c37f07965404},
+      {0xd7e77a8f87daf7fb, 0xdc33745ec97be906},
+      {0x86f0ac99b4e8dafd, 0x69a028bb3ded71a3},
+      {0xa8acd7c0222311bc, 0xc40832ea0d68ce0c},
+      {0xd2d80db02aabd62b, 0xf50a3fa490c30190},
+      {0x83c7088e1aab65db, 0x792667c6da79e0fa},
+      {0xa4b8cab1a1563f52, 0x577001b891185938},
+      {0xcde6fd5e09abcf26, 0xed4c0226b55e6f86},
+      {0x80b05e5ac60b6178, 0x544f8158315b05b4},
+      {0xa0dc75f1778e39d6, 0x696361ae3db1c721},
+      {0xc913936dd571c84c, 0x03bc3a19cd1e38e9},
+      {0xfb5878494ace3a5f, 0x04ab48a04065c723},
+      {0x9d174b2dcec0e47b, 0x62eb0d64283f9c76},
+      {0xc45d1df942711d9a, 0x3ba5d0bd324f8394},
+      {0xf5746577930d6500, 0xca8f44ec7ee36479},
+      {0x9968bf6abbe85f20, 0x7e998b13cf4e1ecb},
+      {0xbfc2ef456ae276e8, 0x9e3fedd8c321a67e},
+      {0xefb3ab16c59b14a2, 0xc5cfe94ef3ea101e},
+      {0x95d04aee3b80ece5, 0xbba1f1d158724a12},
+      {0xbb445da9ca61281f, 0x2a8a6e45ae8edc97},
+      {0xea1575143cf97226, 0xf52d09d71a3293bd},
+      {0x924d692ca61be758, 0x593c2626705f9c56},
+      {0xb6e0c377cfa2e12e, 0x6f8b2fb00c77836c},
+      {0xe498f455c38b997a, 0x0b6dfb9c0f956447},
+      {0x8edf98b59a373fec, 0x4724bd4189bd5eac},
+      {0xb2977ee300c50fe7, 0x58edec91ec2cb657},
+      {0xdf3d5e9bc0f653e1, 0x2f2967b66737e3ed},
+      {0x8b865b215899f46c, 0xbd79e0d20082ee74},
+      {0xae67f1e9aec07187, 0xecd8590680a3aa11},
+      {0xda01ee641a708de9, 0xe80e6f4820cc9495},
+      {0x884134fe908658b2, 0x3109058d147fdcdd},
+      {0xaa51823e34a7eede, 0xbd4b46f0599fd415},
+      {0xd4e5e2cdc1d1ea96, 0x6c9e18ac7007c91a},
+      {0x850fadc09923329e, 0x03e2cf6bc604ddb0},
+      {0xa6539930bf6bff45, 0x84db8346b786151c},
+      {0xcfe87f7cef46ff16, 0xe612641865679a63},
+      {0x81f14fae158c5f6e, 0x4fcb7e8f3f60c07e},
+      {0xa26da3999aef7749, 0xe3be5e330f38f09d},
+      {0xcb090c8001ab551c, 0x5cadf5bfd3072cc5},
+      {0xfdcb4fa002162a63, 0x73d9732fc7c8f7f6},
+      {0x9e9f11c4014dda7e, 0x2867e7fddcdd9afa},
+      {0xc646d63501a1511d, 0xb281e1fd541501b8},
+      {0xf7d88bc24209a565, 0x1f225a7ca91a4226},
+      {0x9ae757596946075f, 0x3375788de9b06958},
+      {0xc1a12d2fc3978937, 0x0052d6b1641c83ae},
+      {0xf209787bb47d6b84, 0xc0678c5dbd23a49a},
+      {0x9745eb4d50ce6332, 0xf840b7ba963646e0},
+      {0xbd176620a501fbff, 0xb650e5a93bc3d898},
+      {0xec5d3fa8ce427aff, 0xa3e51f138ab4cebe},
+      {0x93ba47c980e98cdf, 0xc66f336c36b10137},
+      {0xb8a8d9bbe123f017, 0xb80b0047445d4184},
+      {0xe6d3102ad96cec1d, 0xa60dc059157491e5},
+      {0x9043ea1ac7e41392, 0x87c89837ad68db2f},
+      {0xb454e4a179dd1877, 0x29babe4598c311fb},
+      {0xe16a1dc9d8545e94, 0xf4296dd6fef3d67a},
+      {0x8ce2529e2734bb1d, 0x1899e4a65f58660c},
+      {0xb01ae745b101e9e4, 0x5ec05dcff72e7f8f},
+      {0xdc21a1171d42645d, 0x76707543f4fa1f73},
+      {0x899504ae72497eba, 0x6a06494a791c53a8},
+      {0xabfa45da0edbde69, 0x0487db9d17636892},
+      {0xd6f8d7509292d603, 0x45a9d2845d3c42b6},
+      {0x865b86925b9bc5c2, 0x0b8a2392ba45a9b2},
+      {0xa7f26836f282b732, 0x8e6cac7768d7141e},
+      {0xd1ef0244af2364ff, 0x3207d795430cd926},
+      {0x8335616aed761f1f, 0x7f44e6bd49e807b8},
+      {0xa402b9c5a8d3a6e7, 0x5f16206c9c6209a6},
+      {0xcd036837130890a1, 0x36dba887c37a8c0f},
+      {0x802221226be55a64, 0xc2494954da2c9789},
+      {0xa02aa96b06deb0fd, 0xf2db9baa10b7bd6c},
+      {0xc83553c5c8965d3d, 0x6f92829494e5acc7},
+      {0xfa42a8b73abbf48c, 0xcb772339ba1f17f9},
+      {0x9c69a97284b578d7, 0xff2a760414536efb},
+      {0xc38413cf25e2d70d, 0xfef5138519684aba},
+      {0xf46518c2ef5b8cd1, 0x7eb258665fc25d69},
+      {0x98bf2f79d5993802, 0xef2f773ffbd97a61},
+      {0xbeeefb584aff8603, 0xaafb550ffacfd8fa},
+      {0xeeaaba2e5dbf6784, 0x95ba2a53f983cf38},
+      {0x952ab45cfa97a0b2, 0xdd945a747bf26183},
+      {0xba756174393d88df, 0x94f971119aeef9e4},
+      {0xe912b9d1478ceb17, 0x7a37cd5601aab85d},
+      {0x91abb422ccb812ee, 0xac62e055c10ab33a},
+      {0xb616a12b7fe617aa, 0x577b986b314d6009},
+      {0xe39c49765fdf9d94, 0xed5a7e85fda0b80b},
+      {0x8e41ade9fbebc27d, 0x14588f13be847307},
+      {0xb1d219647ae6b31c, 0x596eb2d8ae258fc8},
+      {0xde469fbd99a05fe3, 0x6fca5f8ed9aef3bb},
+      {0x8aec23d680043bee, 0x25de7bb9480d5854},
+      {0xada72ccc20054ae9, 0xaf561aa79a10ae6a},
+      {0xd910f7ff28069da4, 0x1b2ba1518094da04},
+      {0x87aa9aff79042286, 0x90fb44d2f05d0842},
+      {0xa99541bf57452b28, 0x353a1607ac744a53},
+      {0xd3fa922f2d1675f2, 0x42889b8997915ce8},
+      {0x847c9b5d7c2e09b7, 0x69956135febada11},
+      {0xa59bc234db398c25, 0x43fab9837e699095},
+      {0xcf02b2c21207ef2e, 0x94f967e45e03f4bb},
+      {0x8161afb94b44f57d, 0x1d1be0eebac278f5},
+      {0xa1ba1ba79e1632dc, 0x6462d92a69731732},
+      {0xca28a291859bbf93, 0x7d7b8f7503cfdcfe},
+      {0xfcb2cb35e702af78, 0x5cda735244c3d43e},
+      {0x9defbf01b061adab, 0x3a0888136afa64a7},
+      {0xc56baec21c7a1916, 0x088aaa1845b8fdd0},
+      {0xf6c69a72a3989f5b, 0x8aad549e57273d45},
+      {0x9a3c2087a63f6399, 0x36ac54e2f678864b},
+      {0xc0cb28a98fcf3c7f, 0x84576a1bb416a7dd},
+      {0xf0fdf2d3f3c30b9f, 0x656d44a2a11c51d5},
+      {0x969eb7c47859e743, 0x9f644ae5a4b1b325},
+      {0xbc4665b596706114, 0x873d5d9f0dde1fee},
+      {0xeb57ff22fc0c7959, 0xa90cb506d155a7ea},
+      {0x9316ff75dd87cbd8, 0x09a7f12442d588f2},
+      {0xb7dcbf5354e9bece, 0x0c11ed6d538aeb2f},
+      {0xe5d3ef282a242e81, 0x8f1668c8a86da5fa},
+      {0x8fa475791a569d10, 0xf96e017d694487bc},
+      {0xb38d92d760ec4455, 0x37c981dcc395a9ac},
+      {0xe070f78d3927556a, 0x85bbe253f47b1417},
+      {0x8c469ab843b89562, 0x93956d7478ccec8e},
+      {0xaf58416654a6babb, 0x387ac8d1970027b2},
+      {0xdb2e51bfe9d0696a, 0x06997b05fcc0319e},
+      {0x88fcf317f22241e2, 0x441fece3bdf81f03},
+      {0xab3c2fddeeaad25a, 0xd527e81cad7626c3},
+      {0xd60b3bd56a5586f1, 0x8a71e223d8d3b074},
+      {0x85c7056562757456, 0xf6872d5667844e49},
+      {0xa738c6bebb12d16c, 0xb428f8ac016561db},
+      {0xd106f86e69d785c7, 0xe13336d701beba52},
+      {0x82a45b450226b39c, 0xecc0024661173473},
+      {0xa34d721642b06084, 0x27f002d7f95d0190},
+      {0xcc20ce9bd35c78a5, 0x31ec038df7b441f4},
+      {0xff290242c83396ce, 0x7e67047175a15271},
+      {0x9f79a169bd203e41, 0x0f0062c6e984d386},
+      {0xc75809c42c684dd1, 0x52c07b78a3e60868},
+      {0xf92e0c3537826145, 0xa7709a56ccdf8a82},
+      {0x9bbcc7a142b17ccb, 0x88a66076400bb691},
+      {0xc2abf989935ddbfe, 0x6acff893d00ea435},
+      {0xf356f7ebf83552fe, 0x0583f6b8c4124d43},
+      {0x98165af37b2153de, 0xc3727a337a8b704a},
+      {0xbe1bf1b059e9a8d6, 0x744f18c0592e4c5c},
+      {0xeda2ee1c7064130c, 0x1162def06f79df73},
+      {0x9485d4d1c63e8be7, 0x8addcb5645ac2ba8},
+      {0xb9a74a0637ce2ee1, 0x6d953e2bd7173692},
+      {0xe8111c87c5c1ba99, 0xc8fa8db6ccdd0437},
+      {0x910ab1d4db9914a0, 0x1d9c9892400a22a2},
+      {0xb54d5e4a127f59c8, 0x2503beb6d00cab4b},
+      {0xe2a0b5dc971f303a, 0x2e44ae64840fd61d},
+      {0x8da471a9de737e24, 0x5ceaecfed289e5d2},
+      {0xb10d8e1456105dad, 0x7425a83e872c5f47},
+      {0xdd50f1996b947518, 0xd12f124e28f77719},
+      {0x8a5296ffe33cc92f, 0x82bd6b70d99aaa6f},
+      {0xace73cbfdc0bfb7b, 0x636cc64d1001550b},
+      {0xd8210befd30efa5a, 0x3c47f7e05401aa4e},
+      {0x8714a775e3e95c78, 0x65acfaec34810a71},
+      {0xa8d9d1535ce3b396, 0x7f1839a741a14d0d},
+      {0xd31045a8341ca07c, 0x1ede48111209a050},
+      {0x83ea2b892091e44d, 0x934aed0aab460432},
+      {0xa4e4b66b68b65d60, 0xf81da84d5617853f},
+      {0xce1de40642e3f4b9, 0x36251260ab9d668e},
+      {0x80d2ae83e9ce78f3, 0xc1d72b7c6b426019},
+      {0xa1075a24e4421730, 0xb24cf65b8612f81f},
+      {0xc94930ae1d529cfc, 0xdee033f26797b627},
+      {0xfb9b7cd9a4a7443c, 0x169840ef017da3b1},
+      {0x9d412e0806e88aa5, 0x8e1f289560ee864e},
+      {0xc491798a08a2ad4e, 0xf1a6f2bab92a27e2},
+      {0xf5b5d7ec8acb58a2, 0xae10af696774b1db},
+      {0x9991a6f3d6bf1765, 0xacca6da1e0a8ef29},
+      {0xbff610b0cc6edd3f, 0x17fd090a58d32af3},
+      {0xeff394dcff8a948e, 0xddfc4b4cef07f5b0},
+      {0x95f83d0a1fb69cd9, 0x4abdaf101564f98e},
+      {0xbb764c4ca7a4440f, 0x9d6d1ad41abe37f1},
+      {0xea53df5fd18d5513, 0x84c86189216dc5ed},
+      {0x92746b9be2f8552c, 0x32fd3cf5b4e49bb4},
+      {0xb7118682dbb66a77, 0x3fbc8c33221dc2a1},
+      {0xe4d5e82392a40515, 0x0fabaf3feaa5334a},
+      {0x8f05b1163ba6832d, 0x29cb4d87f2a7400e},
+      {0xb2c71d5bca9023f8, 0x743e20e9ef511012},
+      {0xdf78e4b2bd342cf6, 0x914da9246b255416},
+      {0x8bab8eefb6409c1a, 0x1ad089b6c2f7548e},
+      {0xae9672aba3d0c320, 0xa184ac2473b529b1},
+      {0xda3c0f568cc4f3e8, 0xc9e5d72d90a2741e},
+      {0x8865899617fb1871, 0x7e2fa67c7a658892},
+      {0xaa7eebfb9df9de8d, 0xddbb901b98feeab7},
+      {0xd51ea6fa85785631, 0x552a74227f3ea565},
+      {0x8533285c936b35de, 0xd53a88958f87275f},
+      {0xa67ff273b8460356, 0x8a892abaf368f137},
+      {0xd01fef10a657842c, 0x2d2b7569b0432d85},
+      {0x8213f56a67f6b29b, 0x9c3b29620e29fc73},
+      {0xa298f2c501f45f42, 0x8349f3ba91b47b8f},
+      {0xcb3f2f7642717713, 0x241c70a936219a73},
+      {0xfe0efb53d30dd4d7, 0xed238cd383aa0110},
+      {0x9ec95d1463e8a506, 0xf4363804324a40aa},
+      {0xc67bb4597ce2ce48, 0xb143c6053edcd0d5},
+      {0xf81aa16fdc1b81da, 0xdd94b7868e94050a},
+      {0x9b10a4e5e9913128, 0xca7cf2b4191c8326},
+      {0xc1d4ce1f63f57d72, 0xfd1c2f611f63a3f0},
+      {0xf24a01a73cf2dccf, 0xbc633b39673c8cec},
+      {0x976e41088617ca01, 0xd5be0503e085d813},
+      {0xbd49d14aa79dbc82, 0x4b2d8644d8a74e18},
+      {0xec9c459d51852ba2, 0xddf8e7d60ed1219e},
+      {0x93e1ab8252f33b45, 0xcabb90e5c942b503},
+      {0xb8da1662e7b00a17, 0x3d6a751f3b936243},
+      {0xe7109bfba19c0c9d, 0x0cc512670a783ad4},
+      {0x906a617d450187e2, 0x27fb2b80668b24c5},
+      {0xb484f9dc9641e9da, 0xb1f9f660802dedf6},
+      {0xe1a63853bbd26451, 0x5e7873f8a0396973},
+      {0x8d07e33455637eb2, 0xdb0b487b6423e1e8},
+      {0xb049dc016abc5e5f, 0x91ce1a9a3d2cda62},
+      {0xdc5c5301c56b75f7, 0x7641a140cc7810fb},
+      {0x89b9b3e11b6329ba, 0xa9e904c87fcb0a9d},
+      {0xac2820d9623bf429, 0x546345fa9fbdcd44},
+      {0xd732290fbacaf133, 0xa97c177947ad4095},
+      {0x867f59a9d4bed6c0, 0x49ed8eabcccc485d},
+      {0xa81f301449ee8c70, 0x5c68f256bfff5a74},
+      {0xd226fc195c6a2f8c, 0x73832eec6fff3111},
+      {0x83585d8fd9c25db7, 0xc831fd53c5ff7eab},
+      {0xa42e74f3d032f525, 0xba3e7ca8b77f5e55},
+      {0xcd3a1230c43fb26f, 0x28ce1bd2e55f35eb},
+      {0x80444b5e7aa7cf85, 0x7980d163cf5b81b3},
+      {0xa0555e361951c366, 0xd7e105bcc332621f},
+      {0xc86ab5c39fa63440, 0x8dd9472bf3fefaa7},
+      {0xfa856334878fc150, 0xb14f98f6f0feb951},
+      {0x9c935e00d4b9d8d2, 0x6ed1bf9a569f33d3},
+      {0xc3b8358109e84f07, 0x0a862f80ec4700c8},
+      {0xf4a642e14c6262c8, 0xcd27bb612758c0fa},
+      {0x98e7e9cccfbd7dbd, 0x8038d51cb897789c},
+      {0xbf21e44003acdd2c, 0xe0470a63e6bd56c3},
+      {0xeeea5d5004981478, 0x1858ccfce06cac74},
+      {0x95527a5202df0ccb, 0x0f37801e0c43ebc8},
+      {0xbaa718e68396cffd, 0xd30560258f54e6ba},
+      {0xe950df20247c83fd, 0x47c6b82ef32a2069},
+      {0x91d28b7416cdd27e, 0x4cdc331d57fa5441},
+      {0xb6472e511c81471d, 0xe0133fe4adf8e952},
+      {0xe3d8f9e563a198e5, 0x58180fddd97723a6},
+      {0x8e679c2f5e44ff8f, 0x570f09eaa7ea7648},
+      {0xb201833b35d63f73, 0x2cd2cc6551e513da},
+      {0xde81e40a034bcf4f, 0xf8077f7ea65e58d1},
+      {0x8b112e86420f6191, 0xfb04afaf27faf782},
+      {0xadd57a27d29339f6, 0x79c5db9af1f9b563},
+      {0xd94ad8b1c7380874, 0x18375281ae7822bc},
+      {0x87cec76f1c830548, 0x8f2293910d0b15b5},
+      {0xa9c2794ae3a3c69a, 0xb2eb3875504ddb22},
+      {0xd433179d9c8cb841, 0x5fa60692a46151eb},
+      {0x849feec281d7f328, 0xdbc7c41ba6bcd333},
+      {0xa5c7ea73224deff3, 0x12b9b522906c0800},
+      {0xcf39e50feae16bef, 0xd768226b34870a00},
+      {0x81842f29f2cce375, 0xe6a1158300d46640},
+      {0xa1e53af46f801c53, 0x60495ae3c1097fd0},
+      {0xca5e89b18b602368, 0x385bb19cb14bdfc4},
+      {0xfcf62c1dee382c42, 0x46729e03dd9ed7b5},
+      {0x9e19db92b4e31ba9, 0x6c07a2c26a8346d1},
+      {0xc5a05277621be293, 0xc7098b7305241885},
+      { 0xf70867153aa2db38,
+        0xb8cbee4fc66d1ea7 }
 #else
+      {0xff77b1fcbebcdc4f, 0x25e8e89c13bb0f7b},
+      {0xce5d73ff402d98e3, 0xfb0a3d212dc81290},
+      {0xa6b34ad8c9dfc06f, 0xf42faa48c0ea481f},
+      {0x86a8d39ef77164bc, 0xae5dff9c02033198},
+      {0xd98ddaee19068c76, 0x3badd624dd9b0958},
+      {0xafbd2350644eeacf, 0xe5d1929ef90898fb},
+      {0x8df5efabc5979c8f, 0xca8d3ffa1ef463c2},
+      {0xe55990879ddcaabd, 0xcc420a6a101d0516},
+      {0xb94470938fa89bce, 0xf808e40e8d5b3e6a},
+      {0x95a8637627989aad, 0xdde7001379a44aa9},
+      {0xf1c90080baf72cb1, 0x5324c68b12dd6339},
+      {0xc350000000000000, 0x0000000000000000},
+      {0x9dc5ada82b70b59d, 0xf020000000000000},
+      {0xfee50b7025c36a08, 0x02f236d04753d5b4},
+      {0xcde6fd5e09abcf26, 0xed4c0226b55e6f86},
+      {0xa6539930bf6bff45, 0x84db8346b786151c},
+      {0x865b86925b9bc5c2, 0x0b8a2392ba45a9b2},
+      {0xd910f7ff28069da4, 0x1b2ba1518094da04},
+      {0xaf58416654a6babb, 0x387ac8d1970027b2},
+      {0x8da471a9de737e24, 0x5ceaecfed289e5d2},
+      {0xe4d5e82392a40515, 0x0fabaf3feaa5334a},
+      {0xb8da1662e7b00a17, 0x3d6a751f3b936243},
+      { 0x95527a5202df0ccb,
+        0x0f37801e0c43ebc8 }
+#endif
+    };
+
+#if FMT_USE_FULL_CACHE_DRAGONBOX
+    return pow10_significands[k - float_info<double>::min_k];
+#else
+    static constexpr const uint64_t powers_of_5_64[] = {
+        0x0000000000000001, 0x0000000000000005, 0x0000000000000019,
+        0x000000000000007d, 0x0000000000000271, 0x0000000000000c35,
+        0x0000000000003d09, 0x000000000001312d, 0x000000000005f5e1,
+        0x00000000001dcd65, 0x00000000009502f9, 0x0000000002e90edd,
+        0x000000000e8d4a51, 0x0000000048c27395, 0x000000016bcc41e9,
+        0x000000071afd498d, 0x0000002386f26fc1, 0x000000b1a2bc2ec5,
+        0x000003782dace9d9, 0x00001158e460913d, 0x000056bc75e2d631,
+        0x0001b1ae4d6e2ef5, 0x000878678326eac9, 0x002a5a058fc295ed,
+        0x00d3c21bcecceda1, 0x0422ca8b0a00a425, 0x14adf4b7320334b9};
+
+    static constexpr const uint32_t pow10_recovery_errors[] = {
+        0x50001400, 0x54044100, 0x54014555, 0x55954415, 0x54115555, 0x00000001,
+        0x50000000, 0x00104000, 0x54010004, 0x05004001, 0x55555544, 0x41545555,
+        0x54040551, 0x15445545, 0x51555514, 0x10000015, 0x00101100, 0x01100015,
+        0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x04450514, 0x45414110,
+        0x55555145, 0x50544050, 0x15040155, 0x11054140, 0x50111514, 0x11451454,
+        0x00400541, 0x00000000, 0x55555450, 0x10056551, 0x10054011, 0x55551014,
+        0x69514555, 0x05151109, 0x00155555};
+
     static const int compression_ratio = 27;
 
     // Compute base index.
     int cache_index = (k - float_info<double>::min_k) / compression_ratio;
     int kb = cache_index * compression_ratio + float_info<double>::min_k;
     int offset = k - kb;
 
     // Get base cache.
-    uint128_wrapper base_cache =
-        data::dragonbox_pow10_significands_128[cache_index];
+    uint128_wrapper base_cache = pow10_significands[cache_index];
     if (offset == 0) return base_cache;
 
     // Compute the required amount of bit-shift.
     int alpha = floor_log2_pow10(kb + offset) - floor_log2_pow10(kb) - offset;
     FMT_ASSERT(alpha > 0 && alpha < 64, "shifting error detected");
 
     // Try to recover the real cache.
-    uint64_t pow5 = data::powers_of_5_64[offset];
+    uint64_t pow5 = powers_of_5_64[offset];
     uint128_wrapper recovered_cache = umul128(base_cache.high(), pow5);
     uint128_wrapper middle_low =
         umul128(base_cache.low() - (kb < 0 ? 1u : 0u), pow5);
 
     recovered_cache += middle_low.high();
 
     uint64_t high_to_middle = recovered_cache.high() << (64 - alpha);
@@ -1920,15 +1835,15 @@
         uint128_wrapper{(recovered_cache.low() >> alpha) | high_to_middle,
                         ((middle_low.low() >> alpha) | middle_to_low)};
 
     if (kb < 0) recovered_cache += 1;
 
     // Get error.
     int error_idx = (k - float_info<double>::min_k) / 16;
-    uint32_t error = (data::dragonbox_pow10_recovery_errors[error_idx] >>
+    uint32_t error = (pow10_recovery_errors[error_idx] >>
                       ((k - float_info<double>::min_k) % 16) * 2) &
                      0x3;
 
     // Add the error back.
     FMT_ASSERT(recovered_cache.low() + error >= recovered_cache.low(), "");
     return {recovered_cache.high(), recovered_cache.low() + error};
 #endif
@@ -2006,15 +1921,15 @@
   // Both exponents are nonnegative.
   if (exponent >= float_info<T>::case_fc_lower_threshold) return true;
   // Exponent for 2 is negative.
   return divisible_by_power_of_2(two_f, minus_k - exponent + 1);
 }
 
 // Remove trailing zeros from n and return the number of zeros removed (float)
-FMT_ALWAYS_INLINE int remove_trailing_zeros(uint32_t& n) FMT_NOEXCEPT {
+FMT_INLINE int remove_trailing_zeros(uint32_t& n) FMT_NOEXCEPT {
 #ifdef FMT_BUILTIN_CTZ
   int t = FMT_BUILTIN_CTZ(n);
 #else
   int t = ctz(n);
 #endif
   if (t > float_info<float>::max_trailing_zeros)
     t = float_info<float>::max_trailing_zeros;
@@ -2034,15 +1949,15 @@
     ++s;
   }
   n >>= s;
   return s;
 }
 
 // Removes trailing zeros and returns the number of zeros removed (double)
-FMT_ALWAYS_INLINE int remove_trailing_zeros(uint64_t& n) FMT_NOEXCEPT {
+FMT_INLINE int remove_trailing_zeros(uint64_t& n) FMT_NOEXCEPT {
 #ifdef FMT_BUILTIN_CTZLL
   int t = FMT_BUILTIN_CTZLL(n);
 #else
   int t = ctzll(n);
 #endif
   if (t > float_info<double>::max_trailing_zeros)
     t = float_info<double>::max_trailing_zeros;
@@ -2120,16 +2035,15 @@
 
   n = (remainder >> 7) + quotient * 10ull;
   return 7;
 }
 
 // The main algorithm for shorter interval case
 template <class T>
-FMT_ALWAYS_INLINE FMT_SAFEBUFFERS decimal_fp<T> shorter_interval_case(
-    int exponent) FMT_NOEXCEPT {
+FMT_INLINE decimal_fp<T> shorter_interval_case(int exponent) FMT_NOEXCEPT {
   decimal_fp<T> ret_value;
   // Compute k and beta
   const int minus_k = floor_log10_pow2_minus_log10_4_over_3(exponent);
   const int beta_minus_1 = exponent + floor_log2_pow10(-minus_k);
 
   // Compute xi and zi
   using cache_entry_type = typename cache_accessor<T>::cache_entry_type;
@@ -2167,16 +2081,15 @@
                                 : ret_value.significand - 1;
   } else if (ret_value.significand < xi) {
     ++ret_value.significand;
   }
   return ret_value;
 }
 
-template <typename T>
-FMT_SAFEBUFFERS decimal_fp<T> to_decimal(T x) FMT_NOEXCEPT {
+template <typename T> decimal_fp<T> to_decimal(T x) FMT_NOEXCEPT {
   // Step 1: integer promotion & Schubfach multiplier calculation.
 
   using carrier_uint = typename float_info<T>::carrier_uint;
   using cache_entry_type = typename cache_accessor<T>::cache_entry_type;
   auto br = bit_cast<carrier_uint>(x);
 
   // Extract significand bits and exponent bits.
@@ -2302,32 +2215,29 @@
     ret_value.significand +=
         small_division_by_pow10<float_info<T>::kappa>(dist);
   }
   return ret_value;
 }
 }  // namespace dragonbox
 
-// Formats value using a variation of the Fixed-Precision Positive
-// Floating-Point Printout ((FPP)^2) algorithm by Steele & White:
-// https://fmt.dev/p372-steele.pdf.
-template <typename Double>
-void fallback_format(Double d, int num_digits, bool binary32, buffer<char>& buf,
-                     int& exp10) {
+// Formats a floating-point number using a variation of the Fixed-Precision
+// Positive Floating-Point Printout ((FPP)^2) algorithm by Steele & White:
+// https://fmt.dev/papers/p372-steele.pdf.
+FMT_CONSTEXPR20 inline void format_dragon(fp value, bool is_predecessor_closer,
+                                          int num_digits, buffer<char>& buf,
+                                          int& exp10) {
   bigint numerator;    // 2 * R in (FPP)^2.
   bigint denominator;  // 2 * S in (FPP)^2.
   // lower and upper are differences between value and corresponding boundaries.
   bigint lower;             // (M^- in (FPP)^2).
   bigint upper_store;       // upper's value if different from lower.
   bigint* upper = nullptr;  // (M^+ in (FPP)^2).
-  fp value;
   // Shift numerator and denominator by an extra bit or two (if lower boundary
   // is closer) to make lower and upper integers. This eliminates multiplication
   // by 2 during later computations.
-  const bool is_predecessor_closer =
-      binary32 ? value.assign(static_cast<float>(d)) : value.assign(d);
   int shift = is_predecessor_closer ? 2 : 1;
   uint64_t significand = value.f << shift;
   if (value.e >= 0) {
     numerator.assign(significand);
     numerator <<= value.e;
     lower.assign(1);
     lower <<= value.e;
@@ -2389,17 +2299,17 @@
       lower *= 10;
       if (upper != &lower) *upper *= 10;
     }
   }
   // Generate the given number of digits.
   exp10 -= num_digits - 1;
   if (num_digits == 0) {
-    buf.try_resize(1);
     denominator *= 10;
-    buf[0] = add_compare(numerator, numerator, denominator) > 0 ? '1' : '0';
+    auto digit = add_compare(numerator, numerator, denominator) > 0 ? '1' : '0';
+    buf.push_back(digit);
     return;
   }
   buf.try_resize(to_unsigned(num_digits));
   for (int i = 0; i < num_digits - 1; ++i) {
     int digit = numerator.divmod_assign(denominator);
     buf[i] = static_cast<char>('0' + digit);
     numerator *= 10;
@@ -2422,76 +2332,90 @@
       return;
     }
     ++digit;
   }
   buf[num_digits - 1] = static_cast<char>('0' + digit);
 }
 
-template <typename T>
-int format_float(T value, int precision, float_specs specs, buffer<char>& buf) {
-  static_assert(!std::is_same<T, float>::value, "");
+template <typename Float>
+FMT_HEADER_ONLY_CONSTEXPR20 int format_float(Float value, int precision,
+                                             float_specs specs,
+                                             buffer<char>& buf) {
+  // float is passed as double to reduce the number of instantiations.
+  static_assert(!std::is_same<Float, float>::value, "");
   FMT_ASSERT(value >= 0, "value is negative");
 
   const bool fixed = specs.format == float_format::fixed;
   if (value <= 0) {  // <= instead of == to silence a warning.
     if (precision <= 0 || !fixed) {
       buf.push_back('0');
       return 0;
     }
     buf.try_resize(to_unsigned(precision));
-    std::uninitialized_fill_n(buf.data(), precision, '0');
+    fill_n(buf.data(), precision, '0');
     return -precision;
   }
 
-  if (!specs.use_grisu) return snprintf_float(value, precision, specs, buf);
+  if (specs.fallback) return snprintf_float(value, precision, specs, buf);
 
-  if (precision < 0) {
+  if (!is_constant_evaluated() && precision < 0) {
     // Use Dragonbox for the shortest format.
     if (specs.binary32) {
       auto dec = dragonbox::to_decimal(static_cast<float>(value));
       write<char>(buffer_appender<char>(buf), dec.significand);
       return dec.exponent;
     }
     auto dec = dragonbox::to_decimal(static_cast<double>(value));
     write<char>(buffer_appender<char>(buf), dec.significand);
     return dec.exponent;
   }
 
-  // Use Grisu + Dragon4 for the given precision:
-  // https://www.cs.tufts.edu/~nr/cs257/archive/florian-loitsch/printf.pdf.
   int exp = 0;
-  const int min_exp = -60;  // alpha in Grisu.
-  int cached_exp10 = 0;     // K in Grisu.
-  fp normalized = normalize(fp(value));
-  const auto cached_pow = get_cached_power(
-      min_exp - (normalized.e + fp::significand_size), cached_exp10);
-  normalized = normalized * cached_pow;
-  // Limit precision to the maximum possible number of significant digits in an
-  // IEEE754 double because we don't need to generate zeros.
-  const int max_double_digits = 767;
-  if (precision > max_double_digits) precision = max_double_digits;
-  fixed_handler handler{buf.data(), 0, precision, -cached_exp10, fixed};
-  if (grisu_gen_digits(normalized, 1, exp, handler) == digits::error) {
-    exp += handler.size - cached_exp10 - 1;
-    fallback_format(value, handler.precision, specs.binary32, buf, exp);
-  } else {
-    exp += handler.exp10;
-    buf.try_resize(to_unsigned(handler.size));
+  bool use_dragon = true;
+  if (is_fast_float<Float>()) {
+    // Use Grisu + Dragon4 for the given precision:
+    // https://www.cs.tufts.edu/~nr/cs257/archive/florian-loitsch/printf.pdf.
+    const int min_exp = -60;  // alpha in Grisu.
+    int cached_exp10 = 0;     // K in Grisu.
+    fp normalized = normalize(fp(value));
+    const auto cached_pow = get_cached_power(
+        min_exp - (normalized.e + fp::num_significand_bits), cached_exp10);
+    normalized = normalized * cached_pow;
+    gen_digits_handler handler{buf.data(), 0, precision, -cached_exp10, fixed};
+    if (grisu_gen_digits(normalized, 1, exp, handler) != digits::error &&
+        !is_constant_evaluated()) {
+      exp += handler.exp10;
+      buf.try_resize(to_unsigned(handler.size));
+      use_dragon = false;
+    } else {
+      exp += handler.size - cached_exp10 - 1;
+      precision = handler.precision;
+    }
+  }
+  if (use_dragon) {
+    auto f = fp();
+    bool is_predecessor_closer =
+        specs.binary32 ? f.assign(static_cast<float>(value)) : f.assign(value);
+    // Limit precision to the maximum possible number of significant digits in
+    // an IEEE754 double because we don't need to generate zeros.
+    const int max_double_digits = 767;
+    if (precision > max_double_digits) precision = max_double_digits;
+    format_dragon(f, is_predecessor_closer, precision, buf, exp);
   }
   if (!fixed && !specs.showpoint) {
     // Remove trailing zeros.
     auto num_digits = buf.size();
     while (num_digits > 0 && buf[num_digits - 1] == '0') {
       --num_digits;
       ++exp;
     }
     buf.try_resize(num_digits);
   }
   return exp;
-}  // namespace detail
+}
 
 template <typename T>
 int snprintf_float(T value, int precision, float_specs specs,
                    buffer<char>& buf) {
   // Buffer capacity must be non-zero, otherwise MSVC's vsnprintf_s will fail.
   FMT_ASSERT(buf.capacity() > buf.size(), "empty buffer");
   static_assert(!std::is_same<T, float>::value, "");
@@ -2567,19 +2491,19 @@
     }
     // Find and parse the exponent.
     auto end = begin + size, exp_pos = end;
     do {
       --exp_pos;
     } while (*exp_pos != 'e');
     char sign = exp_pos[1];
-    assert(sign == '+' || sign == '-');
+    FMT_ASSERT(sign == '+' || sign == '-', "");
     int exp = 0;
     auto p = exp_pos + 2;  // Skip 'e' and sign.
     do {
-      assert(is_digit(*p));
+      FMT_ASSERT(is_digit(*p), "");
       exp = exp * 10 + (*p++ - '0');
     } while (p != end);
     if (sign == '-') exp = -exp;
     int fraction_size = 0;
     if (exp_pos != begin + 1) {
       // Remove trailing zeros.
       auto fraction_end = exp_pos - 1;
@@ -2588,201 +2512,119 @@
       fraction_size = static_cast<int>(fraction_end - begin - 1);
       std::memmove(begin + 1, begin + 2, to_unsigned(fraction_size));
     }
     buf.try_resize(to_unsigned(fraction_size) + offset + 1);
     return exp - fraction_size;
   }
 }
-
-// A public domain branchless UTF-8 decoder by Christopher Wellons:
-// https://github.com/skeeto/branchless-utf8
-/* Decode the next character, c, from buf, reporting errors in e.
- *
- * Since this is a branchless decoder, four bytes will be read from the
- * buffer regardless of the actual length of the next character. This
- * means the buffer _must_ have at least three bytes of zero padding
- * following the end of the data stream.
- *
- * Errors are reported in e, which will be non-zero if the parsed
- * character was somehow invalid: invalid byte sequence, non-canonical
- * encoding, or a surrogate half.
- *
- * The function returns a pointer to the next character. When an error
- * occurs, this pointer will be a guess that depends on the particular
- * error, but it will always advance at least one byte.
- */
-inline const char* utf8_decode(const char* buf, uint32_t* c, int* e) {
-  static const int masks[] = {0x00, 0x7f, 0x1f, 0x0f, 0x07};
-  static const uint32_t mins[] = {4194304, 0, 128, 2048, 65536};
-  static const int shiftc[] = {0, 18, 12, 6, 0};
-  static const int shifte[] = {0, 6, 4, 2, 0};
-
-  int len = code_point_length(buf);
-  const char* next = buf + len;
-
-  // Assume a four-byte character and load four bytes. Unused bits are
-  // shifted out.
-  auto s = reinterpret_cast<const unsigned char*>(buf);
-  *c = uint32_t(s[0] & masks[len]) << 18;
-  *c |= uint32_t(s[1] & 0x3f) << 12;
-  *c |= uint32_t(s[2] & 0x3f) << 6;
-  *c |= uint32_t(s[3] & 0x3f) << 0;
-  *c >>= shiftc[len];
-
-  // Accumulate the various error conditions.
-  *e = (*c < mins[len]) << 6;       // non-canonical encoding
-  *e |= ((*c >> 11) == 0x1b) << 7;  // surrogate half?
-  *e |= (*c > 0x10FFFF) << 8;       // out of range?
-  *e |= (s[1] & 0xc0) >> 2;
-  *e |= (s[2] & 0xc0) >> 4;
-  *e |= (s[3]) >> 6;
-  *e ^= 0x2a;  // top two bits of each tail byte correct?
-  *e >>= shifte[len];
-
-  return next;
-}
-
-struct stringifier {
-  template <typename T> FMT_INLINE std::string operator()(T value) const {
-    return to_string(value);
-  }
-  std::string operator()(basic_format_arg<format_context>::handle h) const {
-    memory_buffer buf;
-    format_parse_context parse_ctx({});
-    format_context format_ctx(buffer_appender<char>(buf), {}, {});
-    h.format(parse_ctx, format_ctx);
-    return to_string(buf);
-  }
-};
 }  // namespace detail
 
 template <> struct formatter<detail::bigint> {
-  format_parse_context::iterator parse(format_parse_context& ctx) {
+  FMT_CONSTEXPR format_parse_context::iterator parse(
+      format_parse_context& ctx) {
     return ctx.begin();
   }
 
   format_context::iterator format(const detail::bigint& n,
                                   format_context& ctx) {
     auto out = ctx.out();
     bool first = true;
     for (auto i = n.bigits_.size(); i > 0; --i) {
       auto value = n.bigits_[i - 1u];
       if (first) {
-        out = format_to(out, "{:x}", value);
+        out = format_to(out, FMT_STRING("{:x}"), value);
         first = false;
         continue;
       }
-      out = format_to(out, "{:08x}", value);
+      out = format_to(out, FMT_STRING("{:08x}"), value);
     }
     if (n.exp_ > 0)
-      out = format_to(out, "p{}", n.exp_ * detail::bigint::bigit_bits);
+      out = format_to(out, FMT_STRING("p{}"),
+                      n.exp_ * detail::bigint::bigit_bits);
     return out;
   }
 };
 
 FMT_FUNC detail::utf8_to_utf16::utf8_to_utf16(string_view s) {
-  auto transcode = [this](const char* p) {
-    auto cp = uint32_t();
-    auto error = 0;
-    p = utf8_decode(p, &cp, &error);
-    if (error != 0) FMT_THROW(std::runtime_error("invalid utf8"));
+  for_each_codepoint(s, [this](uint32_t cp, string_view) {
+    if (cp == invalid_code_point) FMT_THROW(std::runtime_error("invalid utf8"));
     if (cp <= 0xFFFF) {
       buffer_.push_back(static_cast<wchar_t>(cp));
     } else {
       cp -= 0x10000;
       buffer_.push_back(static_cast<wchar_t>(0xD800 + (cp >> 10)));
       buffer_.push_back(static_cast<wchar_t>(0xDC00 + (cp & 0x3FF)));
     }
-    return p;
-  };
-  auto p = s.data();
-  const size_t block_size = 4;  // utf8_decode always reads blocks of 4 chars.
-  if (s.size() >= block_size) {
-    for (auto end = p + s.size() - block_size + 1; p < end;) p = transcode(p);
-  }
-  if (auto num_chars_left = s.data() + s.size() - p) {
-    char buf[2 * block_size - 1] = {};
-    memcpy(buf, p, to_unsigned(num_chars_left));
-    p = buf;
-    do {
-      p = transcode(p);
-    } while (p - buf < num_chars_left);
-  }
+    return true;
+  });
   buffer_.push_back(0);
 }
 
 FMT_FUNC void format_system_error(detail::buffer<char>& out, int error_code,
-                                  string_view message) FMT_NOEXCEPT {
+                                  const char* message) FMT_NOEXCEPT {
   FMT_TRY {
-    memory_buffer buf;
-    buf.resize(inline_buffer_size);
-    for (;;) {
-      char* system_message = &buf[0];
-      int result =
-          detail::safe_strerror(error_code, system_message, buf.size());
-      if (result == 0) {
-        format_to(detail::buffer_appender<char>(out), "{}: {}", message,
-                  system_message);
-        return;
-      }
-      if (result != ERANGE)
-        break;  // Can't get error message, report error code instead.
-      buf.resize(buf.size() * 2);
-    }
+    auto ec = std::error_code(error_code, std::generic_category());
+    write(std::back_inserter(out), std::system_error(ec, message).what());
+    return;
   }
   FMT_CATCH(...) {}
   format_error_code(out, error_code, message);
 }
 
-FMT_FUNC void detail::error_handler::on_error(const char* message) {
-  FMT_THROW(format_error(message));
-}
-
 FMT_FUNC void report_system_error(int error_code,
-                                  fmt::string_view message) FMT_NOEXCEPT {
+                                  const char* message) FMT_NOEXCEPT {
   report_error(format_system_error, error_code, message);
 }
 
-FMT_FUNC std::string detail::vformat(string_view format_str, format_args args) {
-  if (format_str.size() == 2 && equal2(format_str.data(), "{}")) {
-    auto arg = args.get(0);
-    if (!arg) error_handler().on_error("argument not found");
-    return visit_format_arg(stringifier(), arg);
-  }
-  memory_buffer buffer;
-  detail::vformat_to(buffer, format_str, args);
+// DEPRECATED!
+// This function is defined here and not inline for ABI compatiblity.
+FMT_FUNC void detail::error_handler::on_error(const char* message) {
+  throw_format_error(message);
+}
+
+FMT_FUNC std::string vformat(string_view fmt, format_args args) {
+  // Don't optimize the "{}" case to keep the binary size small and because it
+  // can be better optimized in fmt::format anyway.
+  auto buffer = memory_buffer();
+  detail::vformat_to(buffer, fmt, args);
   return to_string(buffer);
 }
 
 #ifdef _WIN32
 namespace detail {
 using dword = conditional_t<sizeof(long) == 4, unsigned long, unsigned>;
 extern "C" __declspec(dllimport) int __stdcall WriteConsoleW(  //
     void*, const void*, dword, dword*, void*);
 }  // namespace detail
 #endif
 
-FMT_FUNC void vprint(std::FILE* f, string_view format_str, format_args args) {
-  memory_buffer buffer;
-  detail::vformat_to(buffer, format_str,
-                     basic_format_args<buffer_context<char>>(args));
+namespace detail {
+FMT_FUNC void print(std::FILE* f, string_view text) {
 #ifdef _WIN32
   auto fd = _fileno(f);
   if (_isatty(fd)) {
-    detail::utf8_to_utf16 u16(string_view(buffer.data(), buffer.size()));
+    detail::utf8_to_utf16 u16(string_view(text.data(), text.size()));
     auto written = detail::dword();
-    if (!detail::WriteConsoleW(reinterpret_cast<void*>(_get_osfhandle(fd)),
-                               u16.c_str(), static_cast<uint32_t>(u16.size()),
-                               &written, nullptr)) {
-      FMT_THROW(format_error("failed to write to console"));
+    if (detail::WriteConsoleW(reinterpret_cast<void*>(_get_osfhandle(fd)),
+                              u16.c_str(), static_cast<uint32_t>(u16.size()),
+                              &written, nullptr)) {
+      return;
     }
-    return;
+    // Fallback to fwrite on failure. It can happen if the output has been
+    // redirected to NUL.
   }
 #endif
-  detail::fwrite_fully(buffer.data(), 1, buffer.size(), f);
+  detail::fwrite_fully(text.data(), 1, text.size(), f);
+}
+}  // namespace detail
+
+FMT_FUNC void vprint(std::FILE* f, string_view format_str, format_args args) {
+  memory_buffer buffer;
+  detail::vformat_to(buffer, format_str, args);
+  detail::print(f, {buffer.data(), buffer.size()});
 }
 
 #ifdef _WIN32
 // Print assuming legacy (non-Unicode) encoding.
 FMT_FUNC void detail::vprint_mojibake(std::FILE* f, string_view format_str,
                                       format_args args) {
   memory_buffer buffer;
```

### Comparing `lightgbm-3.3.5/compile/external_libs/fmt/include/fmt/format.h` & `lightgbm-4.0.0/external_libs/fmt/include/fmt/format.h`

 * *Files 14% similar despite different names*

```diff
@@ -29,30 +29,32 @@
  source code, you may redistribute such embedded portions in such object form
  without including the above copyright and permission notices.
  */
 
 #ifndef FMT_FORMAT_H_
 #define FMT_FORMAT_H_
 
-#include <algorithm>
-#include <cerrno>
-#include <cmath>
-#include <cstdint>
-#include <limits>
-#include <memory>
-#include <stdexcept>
+#include <cmath>         // std::signbit
+#include <cstdint>       // uint32_t
+#include <limits>        // std::numeric_limits
+#include <memory>        // std::uninitialized_copy
+#include <stdexcept>     // std::runtime_error
+#include <system_error>  // std::system_error
+#include <utility>       // std::swap
+
+#ifdef __cpp_lib_bit_cast
+#  include <bit>  // std::bitcast
+#endif
 
 #include "core.h"
 
-#ifdef __INTEL_COMPILER
-#  define FMT_ICC_VERSION __INTEL_COMPILER
-#elif defined(__ICL)
-#  define FMT_ICC_VERSION __ICL
+#if FMT_GCC_VERSION
+#  define FMT_GCC_VISIBILITY_HIDDEN __attribute__((visibility("hidden")))
 #else
-#  define FMT_ICC_VERSION 0
+#  define FMT_GCC_VISIBILITY_HIDDEN
 #endif
 
 #ifdef __NVCC__
 #  define FMT_CUDA_VERSION (__CUDACC_VER_MAJOR__ * 100 + __CUDACC_VER_MINOR__)
 #else
 #  define FMT_CUDA_VERSION 0
 #endif
@@ -65,38 +67,18 @@
 
 #if FMT_GCC_VERSION || FMT_CLANG_VERSION
 #  define FMT_NOINLINE __attribute__((noinline))
 #else
 #  define FMT_NOINLINE
 #endif
 
-#if __cplusplus == 201103L || __cplusplus == 201402L
-#  if defined(__INTEL_COMPILER) || defined(__PGI)
-#    define FMT_FALLTHROUGH
-#  elif defined(__clang__)
-#    define FMT_FALLTHROUGH [[clang::fallthrough]]
-#  elif FMT_GCC_VERSION >= 700 && \
-      (!defined(__EDG_VERSION__) || __EDG_VERSION__ >= 520)
-#    define FMT_FALLTHROUGH [[gnu::fallthrough]]
-#  else
-#    define FMT_FALLTHROUGH
-#  endif
-#elif FMT_HAS_CPP17_ATTRIBUTE(fallthrough) || \
-    (defined(_MSVC_LANG) && _MSVC_LANG >= 201703L)
-#  define FMT_FALLTHROUGH [[fallthrough]]
+#if FMT_MSC_VER
+#  define FMT_MSC_DEFAULT = default
 #else
-#  define FMT_FALLTHROUGH
-#endif
-
-#ifndef FMT_MAYBE_UNUSED
-#  if FMT_HAS_CPP17_ATTRIBUTE(maybe_unused)
-#    define FMT_MAYBE_UNUSED [[maybe_unused]]
-#  else
-#    define FMT_MAYBE_UNUSED
-#  endif
+#  define FMT_MSC_DEFAULT
 #endif
 
 #ifndef FMT_THROW
 #  if FMT_EXCEPTIONS
 #    if FMT_MSC_VER || FMT_NVCC
 FMT_BEGIN_NAMESPACE
 namespace detail {
@@ -109,152 +91,146 @@
 }  // namespace detail
 FMT_END_NAMESPACE
 #      define FMT_THROW(x) detail::do_throw(x)
 #    else
 #      define FMT_THROW(x) throw x
 #    endif
 #  else
-#    define FMT_THROW(x)              \
-      do {                            \
-        static_cast<void>(sizeof(x)); \
-        FMT_ASSERT(false, "");        \
+#    define FMT_THROW(x)               \
+      do {                             \
+        FMT_ASSERT(false, (x).what()); \
       } while (false)
 #  endif
 #endif
 
 #if FMT_EXCEPTIONS
 #  define FMT_TRY try
 #  define FMT_CATCH(x) catch (x)
 #else
 #  define FMT_TRY if (true)
 #  define FMT_CATCH(x) if (false)
 #endif
 
+#ifndef FMT_MAYBE_UNUSED
+#  if FMT_HAS_CPP17_ATTRIBUTE(maybe_unused)
+#    define FMT_MAYBE_UNUSED [[maybe_unused]]
+#  else
+#    define FMT_MAYBE_UNUSED
+#  endif
+#endif
+
+// Workaround broken [[deprecated]] in the Intel, PGI and NVCC compilers.
+#if FMT_ICC_VERSION || defined(__PGI) || FMT_NVCC
+#  define FMT_DEPRECATED_ALIAS
+#else
+#  define FMT_DEPRECATED_ALIAS FMT_DEPRECATED
+#endif
+
 #ifndef FMT_USE_USER_DEFINED_LITERALS
 // EDG based compilers (Intel, NVIDIA, Elbrus, etc), GCC and MSVC support UDLs.
 #  if (FMT_HAS_FEATURE(cxx_user_literals) || FMT_GCC_VERSION >= 407 || \
        FMT_MSC_VER >= 1900) &&                                         \
       (!defined(__EDG_VERSION__) || __EDG_VERSION__ >= /* UDL feature */ 480)
 #    define FMT_USE_USER_DEFINED_LITERALS 1
 #  else
 #    define FMT_USE_USER_DEFINED_LITERALS 0
 #  endif
 #endif
 
-#ifndef FMT_USE_UDL_TEMPLATE
-// EDG frontend based compilers (icc, nvcc, PGI, etc) and GCC < 6.4 do not
-// properly support UDL templates and GCC >= 9 warns about them.
-#  if FMT_USE_USER_DEFINED_LITERALS &&                         \
-      (!defined(__EDG_VERSION__) || __EDG_VERSION__ >= 501) && \
-      ((FMT_GCC_VERSION >= 604 && __cplusplus >= 201402L) ||   \
-       FMT_CLANG_VERSION >= 304) &&                            \
-      !defined(__PGI) && !defined(__NVCC__)
-#    define FMT_USE_UDL_TEMPLATE 1
-#  else
-#    define FMT_USE_UDL_TEMPLATE 0
-#  endif
-#endif
-
-#ifndef FMT_USE_FLOAT
-#  define FMT_USE_FLOAT 1
-#endif
-
-#ifndef FMT_USE_DOUBLE
-#  define FMT_USE_DOUBLE 1
-#endif
-
-#ifndef FMT_USE_LONG_DOUBLE
-#  define FMT_USE_LONG_DOUBLE 1
-#endif
-
 // Defining FMT_REDUCE_INT_INSTANTIATIONS to 1, will reduce the number of
-// int_writer template instances to just one by only using the largest integer
-// type. This results in a reduction in binary size but will cause a decrease in
-// integer formatting performance.
+// integer formatter template instantiations to just one by only using the
+// largest integer type. This results in a reduction in binary size but will
+// cause a decrease in integer formatting performance.
 #if !defined(FMT_REDUCE_INT_INSTANTIATIONS)
 #  define FMT_REDUCE_INT_INSTANTIATIONS 0
 #endif
 
 // __builtin_clz is broken in clang with Microsoft CodeGen:
-// https://github.com/fmtlib/fmt/issues/519
-#if (FMT_GCC_VERSION || FMT_HAS_BUILTIN(__builtin_clz)) && !FMT_MSC_VER
-#  define FMT_BUILTIN_CLZ(n) __builtin_clz(n)
-#endif
-#if (FMT_GCC_VERSION || FMT_HAS_BUILTIN(__builtin_clzll)) && !FMT_MSC_VER
-#  define FMT_BUILTIN_CLZLL(n) __builtin_clzll(n)
-#endif
-#if (FMT_GCC_VERSION || FMT_HAS_BUILTIN(__builtin_ctz))
-#  define FMT_BUILTIN_CTZ(n) __builtin_ctz(n)
+// https://github.com/fmtlib/fmt/issues/519.
+#if !FMT_MSC_VER
+#  if FMT_HAS_BUILTIN(__builtin_clz) || FMT_GCC_VERSION || FMT_ICC_VERSION
+#    define FMT_BUILTIN_CLZ(n) __builtin_clz(n)
+#  endif
+#  if FMT_HAS_BUILTIN(__builtin_clzll) || FMT_GCC_VERSION || FMT_ICC_VERSION
+#    define FMT_BUILTIN_CLZLL(n) __builtin_clzll(n)
+#  endif
 #endif
-#if (FMT_GCC_VERSION || FMT_HAS_BUILTIN(__builtin_ctzll))
-#  define FMT_BUILTIN_CTZLL(n) __builtin_ctzll(n)
+
+// __builtin_ctz is broken in Intel Compiler Classic on Windows:
+// https://github.com/fmtlib/fmt/issues/2510.
+#ifndef __ICL
+#  if FMT_HAS_BUILTIN(__builtin_ctz) || FMT_GCC_VERSION || FMT_ICC_VERSION
+#    define FMT_BUILTIN_CTZ(n) __builtin_ctz(n)
+#  endif
+#  if FMT_HAS_BUILTIN(__builtin_ctzll) || FMT_GCC_VERSION || FMT_ICC_VERSION
+#    define FMT_BUILTIN_CTZLL(n) __builtin_ctzll(n)
+#  endif
 #endif
 
 #if FMT_MSC_VER
 #  include <intrin.h>  // _BitScanReverse[64], _BitScanForward[64], _umul128
 #endif
 
 // Some compilers masquerade as both MSVC and GCC-likes or otherwise support
 // __builtin_clz and __builtin_clzll, so only define FMT_BUILTIN_CLZ using the
 // MSVC intrinsics if the clz and clzll builtins are not available.
-#if FMT_MSC_VER && !defined(FMT_BUILTIN_CLZLL) && \
-    !defined(FMT_BUILTIN_CTZLL) && !defined(_MANAGED)
+#if FMT_MSC_VER && !defined(FMT_BUILTIN_CLZLL) && !defined(FMT_BUILTIN_CTZLL)
 FMT_BEGIN_NAMESPACE
 namespace detail {
 // Avoid Clang with Microsoft CodeGen's -Wunknown-pragmas warning.
-#  ifndef __clang__
+#  if !defined(__clang__)
 #    pragma intrinsic(_BitScanForward)
 #    pragma intrinsic(_BitScanReverse)
-#  endif
-#  if defined(_WIN64) && !defined(__clang__)
-#    pragma intrinsic(_BitScanForward64)
-#    pragma intrinsic(_BitScanReverse64)
+#    if defined(_WIN64)
+#      pragma intrinsic(_BitScanForward64)
+#      pragma intrinsic(_BitScanReverse64)
+#    endif
 #  endif
 
-inline int clz(uint32_t x) {
+inline auto clz(uint32_t x) -> int {
   unsigned long r = 0;
   _BitScanReverse(&r, x);
   FMT_ASSERT(x != 0, "");
   // Static analysis complains about using uninitialized data
   // "r", but the only way that can happen is if "x" is 0,
   // which the callers guarantee to not happen.
-  FMT_SUPPRESS_MSC_WARNING(6102)
+  FMT_MSC_WARNING(suppress : 6102)
   return 31 ^ static_cast<int>(r);
 }
 #  define FMT_BUILTIN_CLZ(n) detail::clz(n)
 
-inline int clzll(uint64_t x) {
+inline auto clzll(uint64_t x) -> int {
   unsigned long r = 0;
 #  ifdef _WIN64
   _BitScanReverse64(&r, x);
 #  else
   // Scan the high 32 bits.
   if (_BitScanReverse(&r, static_cast<uint32_t>(x >> 32))) return 63 ^ (r + 32);
   // Scan the low 32 bits.
   _BitScanReverse(&r, static_cast<uint32_t>(x));
 #  endif
   FMT_ASSERT(x != 0, "");
-  FMT_SUPPRESS_MSC_WARNING(6102)  // Suppress a bogus static analysis warning.
+  FMT_MSC_WARNING(suppress : 6102)  // Suppress a bogus static analysis warning.
   return 63 ^ static_cast<int>(r);
 }
 #  define FMT_BUILTIN_CLZLL(n) detail::clzll(n)
 
-inline int ctz(uint32_t x) {
+inline auto ctz(uint32_t x) -> int {
   unsigned long r = 0;
   _BitScanForward(&r, x);
   FMT_ASSERT(x != 0, "");
-  FMT_SUPPRESS_MSC_WARNING(6102)  // Suppress a bogus static analysis warning.
+  FMT_MSC_WARNING(suppress : 6102)  // Suppress a bogus static analysis warning.
   return static_cast<int>(r);
 }
 #  define FMT_BUILTIN_CTZ(n) detail::ctz(n)
 
-inline int ctzll(uint64_t x) {
+inline auto ctzll(uint64_t x) -> int {
   unsigned long r = 0;
   FMT_ASSERT(x != 0, "");
-  FMT_SUPPRESS_MSC_WARNING(6102)  // Suppress a bogus static analysis warning.
+  FMT_MSC_WARNING(suppress : 6102)  // Suppress a bogus static analysis warning.
 #  ifdef _WIN64
   _BitScanForward64(&r, x);
 #  else
   // Scan the low 32 bits.
   if (_BitScanForward(&r, static_cast<uint32_t>(x))) return static_cast<int>(r);
   // Scan the high 32 bits.
   _BitScanForward(&r, static_cast<uint32_t>(x >> 32));
@@ -263,76 +239,118 @@
   return static_cast<int>(r);
 }
 #  define FMT_BUILTIN_CTZLL(n) detail::ctzll(n)
 }  // namespace detail
 FMT_END_NAMESPACE
 #endif
 
-// Enable the deprecated numeric alignment.
-#ifndef FMT_DEPRECATED_NUMERIC_ALIGN
-#  define FMT_DEPRECATED_NUMERIC_ALIGN 0
+#ifdef FMT_HEADER_ONLY
+#  define FMT_HEADER_ONLY_CONSTEXPR20 FMT_CONSTEXPR20
+#else
+#  define FMT_HEADER_ONLY_CONSTEXPR20
 #endif
 
 FMT_BEGIN_NAMESPACE
 namespace detail {
 
-// An equivalent of `*reinterpret_cast<Dest*>(&source)` that doesn't have
-// undefined behavior (e.g. due to type aliasing).
-// Example: uint64_t d = bit_cast<uint64_t>(2.718);
-template <typename Dest, typename Source>
-inline Dest bit_cast(const Source& source) {
-  static_assert(sizeof(Dest) == sizeof(Source), "size mismatch");
-  Dest dest;
-  std::memcpy(&dest, &source, sizeof(dest));
-  return dest;
+template <typename Streambuf> class formatbuf : public Streambuf {
+ private:
+  using char_type = typename Streambuf::char_type;
+  using streamsize = decltype(std::declval<Streambuf>().sputn(nullptr, 0));
+  using int_type = typename Streambuf::int_type;
+  using traits_type = typename Streambuf::traits_type;
+
+  buffer<char_type>& buffer_;
+
+ public:
+  explicit formatbuf(buffer<char_type>& buf) : buffer_(buf) {}
+
+ protected:
+  // The put area is always empty. This makes the implementation simpler and has
+  // the advantage that the streambuf and the buffer are always in sync and
+  // sputc never writes into uninitialized memory. A disadvantage is that each
+  // call to sputc always results in a (virtual) call to overflow. There is no
+  // disadvantage here for sputn since this always results in a call to xsputn.
+
+  auto overflow(int_type ch) -> int_type override {
+    if (!traits_type::eq_int_type(ch, traits_type::eof()))
+      buffer_.push_back(static_cast<char_type>(ch));
+    return ch;
+  }
+
+  auto xsputn(const char_type* s, streamsize count) -> streamsize override {
+    buffer_.append(s, s + count);
+    return count;
+  }
+};
+
+// Implementation of std::bit_cast for pre-C++20.
+template <typename To, typename From>
+FMT_CONSTEXPR20 auto bit_cast(const From& from) -> To {
+  static_assert(sizeof(To) == sizeof(From), "size mismatch");
+#ifdef __cpp_lib_bit_cast
+  if (is_constant_evaluated()) return std::bit_cast<To>(from);
+#endif
+  auto to = To();
+  std::memcpy(&to, &from, sizeof(to));
+  return to;
 }
 
-inline bool is_big_endian() {
-  const auto u = 1u;
+inline auto is_big_endian() -> bool {
+#ifdef _WIN32
+  return false;
+#elif defined(__BIG_ENDIAN__)
+  return true;
+#elif defined(__BYTE_ORDER__) && defined(__ORDER_BIG_ENDIAN__)
+  return __BYTE_ORDER__ == __ORDER_BIG_ENDIAN__;
+#else
   struct bytes {
-    char data[sizeof(u)];
+    char data[sizeof(int)];
   };
-  return bit_cast<bytes>(u).data[0] == 0;
+  return bit_cast<bytes>(1).data[0] == 0;
+#endif
 }
 
 // A fallback implementation of uintptr_t for systems that lack it.
 struct fallback_uintptr {
   unsigned char value[sizeof(void*)];
 
   fallback_uintptr() = default;
   explicit fallback_uintptr(const void* p) {
     *this = bit_cast<fallback_uintptr>(p);
-    if (is_big_endian()) {
+    if (const_check(is_big_endian())) {
       for (size_t i = 0, j = sizeof(void*) - 1; i < j; ++i, --j)
         std::swap(value[i], value[j]);
     }
   }
 };
 #ifdef UINTPTR_MAX
 using uintptr_t = ::uintptr_t;
-inline uintptr_t to_uintptr(const void* p) { return bit_cast<uintptr_t>(p); }
+inline auto to_uintptr(const void* p) -> uintptr_t {
+  return bit_cast<uintptr_t>(p);
+}
 #else
 using uintptr_t = fallback_uintptr;
-inline fallback_uintptr to_uintptr(const void* p) {
+inline auto to_uintptr(const void* p) -> fallback_uintptr {
   return fallback_uintptr(p);
 }
 #endif
 
 // Returns the largest possible value for type T. Same as
 // std::numeric_limits<T>::max() but shorter and not affected by the max macro.
-template <typename T> constexpr T max_value() {
+template <typename T> constexpr auto max_value() -> T {
   return (std::numeric_limits<T>::max)();
 }
-template <typename T> constexpr int num_bits() {
+template <typename T> constexpr auto num_bits() -> int {
   return std::numeric_limits<T>::digits;
 }
 // std::numeric_limits<T>::digits may return 0 for 128-bit ints.
-template <> constexpr int num_bits<int128_t>() { return 128; }
-template <> constexpr int num_bits<uint128_t>() { return 128; }
-template <> constexpr int num_bits<fallback_uintptr>() {
+template <> constexpr auto num_bits<int128_t>() -> int { return 128; }
+template <> constexpr auto num_bits<uint128_t>() -> int { return 128; }
+template <> constexpr auto num_bits<fallback_uintptr>() -> int {
   return static_cast<int>(sizeof(void*) *
                           std::numeric_limits<unsigned char>::digits);
 }
 
 FMT_INLINE void assume(bool condition) {
   (void)condition;
 #if FMT_HAS_BUILTIN(__builtin_assume)
@@ -342,307 +360,312 @@
 
 // An approximation of iterator_t for pre-C++20 systems.
 template <typename T>
 using iterator_t = decltype(std::begin(std::declval<T&>()));
 template <typename T> using sentinel_t = decltype(std::end(std::declval<T&>()));
 
 // A workaround for std::string not having mutable data() until C++17.
-template <typename Char> inline Char* get_data(std::basic_string<Char>& s) {
+template <typename Char>
+inline auto get_data(std::basic_string<Char>& s) -> Char* {
   return &s[0];
 }
 template <typename Container>
-inline typename Container::value_type* get_data(Container& c) {
+inline auto get_data(Container& c) -> typename Container::value_type* {
   return c.data();
 }
 
 #if defined(_SECURE_SCL) && _SECURE_SCL
 // Make a checked iterator to avoid MSVC warnings.
 template <typename T> using checked_ptr = stdext::checked_array_iterator<T*>;
-template <typename T> checked_ptr<T> make_checked(T* p, size_t size) {
+template <typename T>
+constexpr auto make_checked(T* p, size_t size) -> checked_ptr<T> {
   return {p, size};
 }
 #else
 template <typename T> using checked_ptr = T*;
-template <typename T> inline T* make_checked(T* p, size_t) { return p; }
+template <typename T> constexpr auto make_checked(T* p, size_t) -> T* {
+  return p;
+}
 #endif
 
+// Attempts to reserve space for n extra characters in the output range.
+// Returns a pointer to the reserved range or a reference to it.
 template <typename Container, FMT_ENABLE_IF(is_contiguous<Container>::value)>
-#if FMT_CLANG_VERSION
+#if FMT_CLANG_VERSION >= 307 && !FMT_ICC_VERSION
 __attribute__((no_sanitize("undefined")))
 #endif
-inline checked_ptr<typename Container::value_type>
-reserve(std::back_insert_iterator<Container> it, size_t n) {
+inline auto
+reserve(std::back_insert_iterator<Container> it, size_t n)
+    -> checked_ptr<typename Container::value_type> {
   Container& c = get_container(it);
   size_t size = c.size();
   c.resize(size + n);
   return make_checked(get_data(c) + size, n);
 }
 
 template <typename T>
-inline buffer_appender<T> reserve(buffer_appender<T> it, size_t n) {
+inline auto reserve(buffer_appender<T> it, size_t n) -> buffer_appender<T> {
   buffer<T>& buf = get_container(it);
   buf.try_reserve(buf.size() + n);
   return it;
 }
 
-template <typename Iterator> inline Iterator& reserve(Iterator& it, size_t) {
+template <typename Iterator>
+constexpr auto reserve(Iterator& it, size_t) -> Iterator& {
   return it;
 }
 
+template <typename OutputIt>
+using reserve_iterator =
+    remove_reference_t<decltype(reserve(std::declval<OutputIt&>(), 0))>;
+
 template <typename T, typename OutputIt>
-constexpr T* to_pointer(OutputIt, size_t) {
+constexpr auto to_pointer(OutputIt, size_t) -> T* {
   return nullptr;
 }
-template <typename T> T* to_pointer(buffer_appender<T> it, size_t n) {
+template <typename T> auto to_pointer(buffer_appender<T> it, size_t n) -> T* {
   buffer<T>& buf = get_container(it);
   auto size = buf.size();
   if (buf.capacity() < size + n) return nullptr;
   buf.try_resize(size + n);
   return buf.data() + size;
 }
 
 template <typename Container, FMT_ENABLE_IF(is_contiguous<Container>::value)>
-inline std::back_insert_iterator<Container> base_iterator(
-    std::back_insert_iterator<Container>& it,
-    checked_ptr<typename Container::value_type>) {
+inline auto base_iterator(std::back_insert_iterator<Container>& it,
+                          checked_ptr<typename Container::value_type>)
+    -> std::back_insert_iterator<Container> {
   return it;
 }
 
 template <typename Iterator>
-inline Iterator base_iterator(Iterator, Iterator it) {
+constexpr auto base_iterator(Iterator, Iterator it) -> Iterator {
   return it;
 }
 
-// An output iterator that counts the number of objects written to it and
-// discards them.
-class counting_iterator {
- private:
-  size_t count_;
-
- public:
-  using iterator_category = std::output_iterator_tag;
-  using difference_type = std::ptrdiff_t;
-  using pointer = void;
-  using reference = void;
-  using _Unchecked_type = counting_iterator;  // Mark iterator as checked.
-
-  struct value_type {
-    template <typename T> void operator=(const T&) {}
-  };
-
-  counting_iterator() : count_(0) {}
-
-  size_t count() const { return count_; }
-
-  counting_iterator& operator++() {
-    ++count_;
-    return *this;
-  }
-  counting_iterator operator++(int) {
-    auto it = *this;
-    ++*this;
-    return it;
-  }
-
-  friend counting_iterator operator+(counting_iterator it, difference_type n) {
-    it.count_ += static_cast<size_t>(n);
-    return it;
-  }
-
-  value_type operator*() const { return {}; }
-};
-
-template <typename OutputIt> class truncating_iterator_base {
- protected:
-  OutputIt out_;
-  size_t limit_;
-  size_t count_;
-
-  truncating_iterator_base(OutputIt out, size_t limit)
-      : out_(out), limit_(limit), count_(0) {}
-
- public:
-  using iterator_category = std::output_iterator_tag;
-  using value_type = typename std::iterator_traits<OutputIt>::value_type;
-  using difference_type = void;
-  using pointer = void;
-  using reference = void;
-  using _Unchecked_type =
-      truncating_iterator_base;  // Mark iterator as checked.
-
-  OutputIt base() const { return out_; }
-  size_t count() const { return count_; }
-};
-
-// An output iterator that truncates the output and counts the number of objects
-// written to it.
-template <typename OutputIt,
-          typename Enable = typename std::is_void<
-              typename std::iterator_traits<OutputIt>::value_type>::type>
-class truncating_iterator;
-
-template <typename OutputIt>
-class truncating_iterator<OutputIt, std::false_type>
-    : public truncating_iterator_base<OutputIt> {
-  mutable typename truncating_iterator_base<OutputIt>::value_type blackhole_;
-
- public:
-  using value_type = typename truncating_iterator_base<OutputIt>::value_type;
-
-  truncating_iterator(OutputIt out, size_t limit)
-      : truncating_iterator_base<OutputIt>(out, limit) {}
-
-  truncating_iterator& operator++() {
-    if (this->count_++ < this->limit_) ++this->out_;
-    return *this;
-  }
-
-  truncating_iterator operator++(int) {
-    auto it = *this;
-    ++*this;
-    return it;
-  }
-
-  value_type& operator*() const {
-    return this->count_ < this->limit_ ? *this->out_ : blackhole_;
+// <algorithm> is spectacularly slow to compile in C++20 so use a simple fill_n
+// instead (#1998).
+template <typename OutputIt, typename Size, typename T>
+FMT_CONSTEXPR auto fill_n(OutputIt out, Size count, const T& value)
+    -> OutputIt {
+  for (Size i = 0; i < count; ++i) *out++ = value;
+  return out;
+}
+template <typename T, typename Size>
+FMT_CONSTEXPR20 auto fill_n(T* out, Size count, char value) -> T* {
+  if (is_constant_evaluated()) {
+    return fill_n<T*, Size, T>(out, count, value);
   }
-};
+  std::memset(out, value, to_unsigned(count));
+  return out + count;
+}
 
-template <typename OutputIt>
-class truncating_iterator<OutputIt, std::true_type>
-    : public truncating_iterator_base<OutputIt> {
- public:
-  truncating_iterator(OutputIt out, size_t limit)
-      : truncating_iterator_base<OutputIt>(out, limit) {}
+#ifdef __cpp_char8_t
+using char8_type = char8_t;
+#else
+enum char8_type : unsigned char {};
+#endif
 
-  template <typename T> truncating_iterator& operator=(T val) {
-    if (this->count_++ < this->limit_) *this->out_++ = val;
-    return *this;
+template <typename OutChar, typename InputIt, typename OutputIt>
+FMT_CONSTEXPR FMT_NOINLINE auto copy_str_noinline(InputIt begin, InputIt end,
+                                                  OutputIt out) -> OutputIt {
+  return copy_str<OutChar>(begin, end, out);
+}
+
+// A public domain branchless UTF-8 decoder by Christopher Wellons:
+// https://github.com/skeeto/branchless-utf8
+/* Decode the next character, c, from s, reporting errors in e.
+ *
+ * Since this is a branchless decoder, four bytes will be read from the
+ * buffer regardless of the actual length of the next character. This
+ * means the buffer _must_ have at least three bytes of zero padding
+ * following the end of the data stream.
+ *
+ * Errors are reported in e, which will be non-zero if the parsed
+ * character was somehow invalid: invalid byte sequence, non-canonical
+ * encoding, or a surrogate half.
+ *
+ * The function returns a pointer to the next character. When an error
+ * occurs, this pointer will be a guess that depends on the particular
+ * error, but it will always advance at least one byte.
+ */
+FMT_CONSTEXPR inline auto utf8_decode(const char* s, uint32_t* c, int* e)
+    -> const char* {
+  constexpr const int masks[] = {0x00, 0x7f, 0x1f, 0x0f, 0x07};
+  constexpr const uint32_t mins[] = {4194304, 0, 128, 2048, 65536};
+  constexpr const int shiftc[] = {0, 18, 12, 6, 0};
+  constexpr const int shifte[] = {0, 6, 4, 2, 0};
+
+  int len = code_point_length(s);
+  const char* next = s + len;
+
+  // Assume a four-byte character and load four bytes. Unused bits are
+  // shifted out.
+  *c = uint32_t(s[0] & masks[len]) << 18;
+  *c |= uint32_t(s[1] & 0x3f) << 12;
+  *c |= uint32_t(s[2] & 0x3f) << 6;
+  *c |= uint32_t(s[3] & 0x3f) << 0;
+  *c >>= shiftc[len];
+
+  // Accumulate the various error conditions.
+  using uchar = unsigned char;
+  *e = (*c < mins[len]) << 6;       // non-canonical encoding
+  *e |= ((*c >> 11) == 0x1b) << 7;  // surrogate half?
+  *e |= (*c > 0x10FFFF) << 8;       // out of range?
+  *e |= (uchar(s[1]) & 0xc0) >> 2;
+  *e |= (uchar(s[2]) & 0xc0) >> 4;
+  *e |= uchar(s[3]) >> 6;
+  *e ^= 0x2a;  // top two bits of each tail byte correct?
+  *e >>= shifte[len];
+
+  return next;
+}
+
+constexpr uint32_t invalid_code_point = ~uint32_t();
+
+// Invokes f(cp, sv) for every code point cp in s with sv being the string view
+// corresponding to the code point. cp is invalid_code_point on error.
+template <typename F>
+FMT_CONSTEXPR void for_each_codepoint(string_view s, F f) {
+  auto decode = [f](const char* buf_ptr, const char* ptr) {
+    auto cp = uint32_t();
+    auto error = 0;
+    auto end = utf8_decode(buf_ptr, &cp, &error);
+    bool result = f(error ? invalid_code_point : cp,
+                    string_view(ptr, to_unsigned(end - buf_ptr)));
+    return result ? end : nullptr;
+  };
+  auto p = s.data();
+  const size_t block_size = 4;  // utf8_decode always reads blocks of 4 chars.
+  if (s.size() >= block_size) {
+    for (auto end = p + s.size() - block_size + 1; p < end;) {
+      p = decode(p, p);
+      if (!p) return;
+    }
+  }
+  if (auto num_chars_left = s.data() + s.size() - p) {
+    char buf[2 * block_size - 1] = {};
+    copy_str<char>(p, p + num_chars_left, buf);
+    const char* buf_ptr = buf;
+    do {
+      auto end = decode(buf_ptr, p);
+      if (!end) return;
+      p += end - buf_ptr;
+      buf_ptr = end;
+    } while (buf_ptr - buf < num_chars_left);
   }
-
-  truncating_iterator& operator++() { return *this; }
-  truncating_iterator& operator++(int) { return *this; }
-  truncating_iterator& operator*() { return *this; }
-};
+}
 
 template <typename Char>
-inline size_t count_code_points(basic_string_view<Char> s) {
+inline auto compute_width(basic_string_view<Char> s) -> size_t {
   return s.size();
 }
 
-// Counts the number of code points in a UTF-8 string.
-inline size_t count_code_points(basic_string_view<char> s) {
-  const char* data = s.data();
+// Computes approximate display width of a UTF-8 string.
+FMT_CONSTEXPR inline size_t compute_width(string_view s) {
   size_t num_code_points = 0;
-  for (size_t i = 0, size = s.size(); i != size; ++i) {
-    if ((data[i] & 0xc0) != 0x80) ++num_code_points;
-  }
+  // It is not a lambda for compatibility with C++14.
+  struct count_code_points {
+    size_t* count;
+    FMT_CONSTEXPR auto operator()(uint32_t cp, string_view) const -> bool {
+      *count += detail::to_unsigned(
+          1 +
+          (cp >= 0x1100 &&
+           (cp <= 0x115f ||  // Hangul Jamo init. consonants
+            cp == 0x2329 ||  // LEFT-POINTING ANGLE BRACKET
+            cp == 0x232a ||  // RIGHT-POINTING ANGLE BRACKET
+            // CJK ... Yi except IDEOGRAPHIC HALF FILL SPACE:
+            (cp >= 0x2e80 && cp <= 0xa4cf && cp != 0x303f) ||
+            (cp >= 0xac00 && cp <= 0xd7a3) ||    // Hangul Syllables
+            (cp >= 0xf900 && cp <= 0xfaff) ||    // CJK Compatibility Ideographs
+            (cp >= 0xfe10 && cp <= 0xfe19) ||    // Vertical Forms
+            (cp >= 0xfe30 && cp <= 0xfe6f) ||    // CJK Compatibility Forms
+            (cp >= 0xff00 && cp <= 0xff60) ||    // Fullwidth Forms
+            (cp >= 0xffe0 && cp <= 0xffe6) ||    // Fullwidth Forms
+            (cp >= 0x20000 && cp <= 0x2fffd) ||  // CJK
+            (cp >= 0x30000 && cp <= 0x3fffd) ||
+            // Miscellaneous Symbols and Pictographs + Emoticons:
+            (cp >= 0x1f300 && cp <= 0x1f64f) ||
+            // Supplemental Symbols and Pictographs:
+            (cp >= 0x1f900 && cp <= 0x1f9ff))));
+      return true;
+    }
+  };
+  for_each_codepoint(s, count_code_points{&num_code_points});
   return num_code_points;
 }
 
-inline size_t count_code_points(basic_string_view<char8_type> s) {
-  return count_code_points(basic_string_view<char>(
+inline auto compute_width(basic_string_view<char8_type> s) -> size_t {
+  return compute_width(basic_string_view<char>(
       reinterpret_cast<const char*>(s.data()), s.size()));
 }
 
 template <typename Char>
-inline size_t code_point_index(basic_string_view<Char> s, size_t n) {
+inline auto code_point_index(basic_string_view<Char> s, size_t n) -> size_t {
   size_t size = s.size();
   return n < size ? n : size;
 }
 
 // Calculates the index of the nth code point in a UTF-8 string.
-inline size_t code_point_index(basic_string_view<char8_type> s, size_t n) {
+inline auto code_point_index(basic_string_view<char8_type> s, size_t n)
+    -> size_t {
   const char8_type* data = s.data();
   size_t num_code_points = 0;
   for (size_t i = 0, size = s.size(); i != size; ++i) {
-    if ((data[i] & 0xc0) != 0x80 && ++num_code_points > n) {
-      return i;
-    }
+    if ((data[i] & 0xc0) != 0x80 && ++num_code_points > n) return i;
   }
   return s.size();
 }
 
-template <typename InputIt, typename OutChar>
-using needs_conversion = bool_constant<
-    std::is_same<typename std::iterator_traits<InputIt>::value_type,
-                 char>::value &&
-    std::is_same<OutChar, char8_type>::value>;
-
-template <typename OutChar, typename InputIt, typename OutputIt,
-          FMT_ENABLE_IF(!needs_conversion<InputIt, OutChar>::value)>
-OutputIt copy_str(InputIt begin, InputIt end, OutputIt it) {
-  return std::copy(begin, end, it);
-}
-
-template <typename OutChar, typename InputIt, typename OutputIt,
-          FMT_ENABLE_IF(needs_conversion<InputIt, OutChar>::value)>
-OutputIt copy_str(InputIt begin, InputIt end, OutputIt it) {
-  return std::transform(begin, end, it,
-                        [](char c) { return static_cast<char8_type>(c); });
-}
-
-template <typename Char, typename InputIt>
-inline counting_iterator copy_str(InputIt begin, InputIt end,
-                                  counting_iterator it) {
-  return it + (end - begin);
-}
-
-template <typename T>
-using is_fast_float = bool_constant<std::numeric_limits<T>::is_iec559 &&
-                                    sizeof(T) <= sizeof(double)>;
+template <typename T, bool = std::is_floating_point<T>::value>
+struct is_fast_float : bool_constant<std::numeric_limits<T>::is_iec559 &&
+                                     sizeof(T) <= sizeof(double)> {};
+template <typename T> struct is_fast_float<T, false> : std::false_type {};
 
 #ifndef FMT_USE_FULL_CACHE_DRAGONBOX
 #  define FMT_USE_FULL_CACHE_DRAGONBOX 0
 #endif
 
 template <typename T>
 template <typename U>
 void buffer<T>::append(const U* begin, const U* end) {
-  do {
+  while (begin != end) {
     auto count = to_unsigned(end - begin);
     try_reserve(size_ + count);
     auto free_cap = capacity_ - size_;
     if (free_cap < count) count = free_cap;
     std::uninitialized_copy_n(begin, count, make_checked(ptr_ + size_, count));
     size_ += count;
     begin += count;
-  } while (begin != end);
+  }
 }
 
-template <typename OutputIt, typename T, typename Traits>
-void iterator_buffer<OutputIt, T, Traits>::flush() {
-  out_ = std::copy_n(data_, this->limit(this->size()), out_);
-  this->clear();
-}
+template <typename T, typename Enable = void>
+struct is_locale : std::false_type {};
+template <typename T>
+struct is_locale<T, void_t<decltype(T::classic())>> : std::true_type {};
 }  // namespace detail
 
+FMT_MODULE_EXPORT_BEGIN
+
 // The number of characters to store in the basic_memory_buffer object itself
 // to avoid dynamic memory allocation.
 enum { inline_buffer_size = 500 };
 
 /**
   \rst
   A dynamically growing memory buffer for trivially copyable/constructible types
   with the first ``SIZE`` elements stored in the object itself.
 
-  You can use one of the following type aliases for common character types:
-
-  +----------------+------------------------------+
-  | Type           | Definition                   |
-  +================+==============================+
-  | memory_buffer  | basic_memory_buffer<char>    |
-  +----------------+------------------------------+
-  | wmemory_buffer | basic_memory_buffer<wchar_t> |
-  +----------------+------------------------------+
+  You can use the ``memory_buffer`` type alias for ``char`` instead.
 
   **Example**::
 
-     fmt::memory_buffer out;
-     format_to(out, "The answer is {}.", 42);
+     auto out = fmt::memory_buffer();
+     format_to(std::back_inserter(out), "The answer is {}.", 42);
 
   This will append the following output to the ``out`` object:
 
   .. code-block:: none
 
      The answer is 42.
 
@@ -655,42 +678,51 @@
  private:
   T store_[SIZE];
 
   // Don't inherit from Allocator avoid generating type_info for it.
   Allocator alloc_;
 
   // Deallocate memory allocated by the buffer.
-  void deallocate() {
+  FMT_CONSTEXPR20 void deallocate() {
     T* data = this->data();
     if (data != store_) alloc_.deallocate(data, this->capacity());
   }
 
  protected:
-  void grow(size_t size) final FMT_OVERRIDE;
+  FMT_CONSTEXPR20 void grow(size_t size) override;
 
  public:
   using value_type = T;
   using const_reference = const T&;
 
-  explicit basic_memory_buffer(const Allocator& alloc = Allocator())
+  FMT_CONSTEXPR20 explicit basic_memory_buffer(
+      const Allocator& alloc = Allocator())
       : alloc_(alloc) {
     this->set(store_, SIZE);
+    if (detail::is_constant_evaluated()) {
+      detail::fill_n(store_, SIZE, T{});
+    }
   }
-  ~basic_memory_buffer() { deallocate(); }
+  FMT_CONSTEXPR20 ~basic_memory_buffer() { deallocate(); }
 
  private:
   // Move data from other to this buffer.
-  void move(basic_memory_buffer& other) {
+  FMT_CONSTEXPR20 void move(basic_memory_buffer& other) {
     alloc_ = std::move(other.alloc_);
     T* data = other.data();
     size_t size = other.size(), capacity = other.capacity();
     if (data == other.store_) {
       this->set(store_, capacity);
-      std::uninitialized_copy(other.store_, other.store_ + size,
-                              detail::make_checked(store_, capacity));
+      if (detail::is_constant_evaluated()) {
+        detail::copy_str<T>(other.store_, other.store_ + size,
+                            detail::make_checked(store_, capacity));
+      } else {
+        std::uninitialized_copy(other.store_, other.store_ + size,
+                                detail::make_checked(store_, capacity));
+      }
     } else {
       this->set(data, capacity);
       // Set pointer to the inline array so that delete is not called
       // when deallocating.
       other.set(other.store_, 0);
     }
     this->resize(size);
@@ -699,522 +731,476 @@
  public:
   /**
     \rst
     Constructs a :class:`fmt::basic_memory_buffer` object moving the content
     of the other object to it.
     \endrst
    */
-  basic_memory_buffer(basic_memory_buffer&& other) FMT_NOEXCEPT { move(other); }
+  FMT_CONSTEXPR20 basic_memory_buffer(basic_memory_buffer&& other)
+      FMT_NOEXCEPT {
+    move(other);
+  }
 
   /**
     \rst
     Moves the content of the other ``basic_memory_buffer`` object to this one.
     \endrst
    */
-  basic_memory_buffer& operator=(basic_memory_buffer&& other) FMT_NOEXCEPT {
+  auto operator=(basic_memory_buffer&& other) FMT_NOEXCEPT
+      -> basic_memory_buffer& {
     FMT_ASSERT(this != &other, "");
     deallocate();
     move(other);
     return *this;
   }
 
   // Returns a copy of the allocator associated with this buffer.
-  Allocator get_allocator() const { return alloc_; }
+  auto get_allocator() const -> Allocator { return alloc_; }
 
   /**
     Resizes the buffer to contain *count* elements. If T is a POD type new
     elements may not be initialized.
    */
-  void resize(size_t count) { this->try_resize(count); }
+  FMT_CONSTEXPR20 void resize(size_t count) { this->try_resize(count); }
 
   /** Increases the buffer capacity to *new_capacity*. */
   void reserve(size_t new_capacity) { this->try_reserve(new_capacity); }
 
   // Directly append data into the buffer
   using detail::buffer<T>::append;
   template <typename ContiguousRange>
   void append(const ContiguousRange& range) {
     append(range.data(), range.data() + range.size());
   }
 };
 
 template <typename T, size_t SIZE, typename Allocator>
-void basic_memory_buffer<T, SIZE, Allocator>::grow(size_t size) {
+FMT_CONSTEXPR20 void basic_memory_buffer<T, SIZE, Allocator>::grow(
+    size_t size) {
 #ifdef FMT_FUZZ
   if (size > 5000) throw std::runtime_error("fuzz mode - won't grow that much");
 #endif
+  const size_t max_size = std::allocator_traits<Allocator>::max_size(alloc_);
   size_t old_capacity = this->capacity();
   size_t new_capacity = old_capacity + old_capacity / 2;
-  if (size > new_capacity) new_capacity = size;
+  if (size > new_capacity)
+    new_capacity = size;
+  else if (new_capacity > max_size)
+    new_capacity = size > max_size ? size : max_size;
   T* old_data = this->data();
   T* new_data =
       std::allocator_traits<Allocator>::allocate(alloc_, new_capacity);
   // The following code doesn't throw, so the raw pointer above doesn't leak.
   std::uninitialized_copy(old_data, old_data + this->size(),
                           detail::make_checked(new_data, new_capacity));
   this->set(new_data, new_capacity);
   // deallocate must not throw according to the standard, but even if it does,
   // the buffer already uses the new storage and will deallocate it in
   // destructor.
   if (old_data != store_) alloc_.deallocate(old_data, old_capacity);
 }
 
 using memory_buffer = basic_memory_buffer<char>;
-using wmemory_buffer = basic_memory_buffer<wchar_t>;
 
 template <typename T, size_t SIZE, typename Allocator>
 struct is_contiguous<basic_memory_buffer<T, SIZE, Allocator>> : std::true_type {
 };
 
+namespace detail {
+FMT_API void print(std::FILE*, string_view);
+}
+
 /** A formatting error such as invalid format string. */
 FMT_CLASS_API
 class FMT_API format_error : public std::runtime_error {
  public:
   explicit format_error(const char* message) : std::runtime_error(message) {}
   explicit format_error(const std::string& message)
       : std::runtime_error(message) {}
   format_error(const format_error&) = default;
   format_error& operator=(const format_error&) = default;
   format_error(format_error&&) = default;
   format_error& operator=(format_error&&) = default;
-  ~format_error() FMT_NOEXCEPT FMT_OVERRIDE;
+  ~format_error() FMT_NOEXCEPT override FMT_MSC_DEFAULT;
 };
 
-namespace detail {
+/**
+  \rst
+  Constructs a `~fmt::format_arg_store` object that contains references
+  to arguments and can be implicitly converted to `~fmt::format_args`.
+  If ``fmt`` is a compile-time string then `make_args_checked` checks
+  its validity at compile time.
+  \endrst
+ */
+template <typename... Args, typename S, typename Char = char_t<S>>
+FMT_INLINE auto make_args_checked(const S& fmt,
+                                  const remove_reference_t<Args>&... args)
+    -> format_arg_store<buffer_context<Char>, remove_reference_t<Args>...> {
+  static_assert(
+      detail::count<(
+              std::is_base_of<detail::view, remove_reference_t<Args>>::value &&
+              std::is_reference<Args>::value)...>() == 0,
+      "passing views as lvalues is disallowed");
+  detail::check_format_string<Args...>(fmt);
+  return {args...};
+}
+
+// compile-time support
+namespace detail_exported {
+#if FMT_USE_NONTYPE_TEMPLATE_PARAMETERS
+template <typename Char, size_t N> struct fixed_string {
+  constexpr fixed_string(const Char (&str)[N]) {
+    detail::copy_str<Char, const Char*, Char*>(static_cast<const Char*>(str),
+                                               str + N, data);
+  }
+  Char data[N]{};
+};
+#endif
+
+// Converts a compile-time string to basic_string_view.
+template <typename Char, size_t N>
+constexpr auto compile_string_to_view(const Char (&s)[N])
+    -> basic_string_view<Char> {
+  // Remove trailing NUL character if needed. Won't be present if this is used
+  // with a raw character array (i.e. not defined as a string).
+  return {s, N - (std::char_traits<Char>::to_int_type(s[N - 1]) == 0 ? 1 : 0)};
+}
+template <typename Char>
+constexpr auto compile_string_to_view(detail::std_string_view<Char> s)
+    -> basic_string_view<Char> {
+  return {s.data(), s.size()};
+}
+}  // namespace detail_exported
+
+FMT_BEGIN_DETAIL_NAMESPACE
+
+template <typename T> struct is_integral : std::is_integral<T> {};
+template <> struct is_integral<int128_t> : std::true_type {};
+template <> struct is_integral<uint128_t> : std::true_type {};
 
 template <typename T>
 using is_signed =
     std::integral_constant<bool, std::numeric_limits<T>::is_signed ||
                                      std::is_same<T, int128_t>::value>;
 
 // Returns true if value is negative, false otherwise.
 // Same as `value < 0` but doesn't produce warnings if T is an unsigned type.
 template <typename T, FMT_ENABLE_IF(is_signed<T>::value)>
-FMT_CONSTEXPR bool is_negative(T value) {
+FMT_CONSTEXPR auto is_negative(T value) -> bool {
   return value < 0;
 }
 template <typename T, FMT_ENABLE_IF(!is_signed<T>::value)>
-FMT_CONSTEXPR bool is_negative(T) {
+FMT_CONSTEXPR auto is_negative(T) -> bool {
   return false;
 }
 
 template <typename T, FMT_ENABLE_IF(std::is_floating_point<T>::value)>
-FMT_CONSTEXPR bool is_supported_floating_point(T) {
+FMT_CONSTEXPR auto is_supported_floating_point(T) -> uint16_t {
   return (std::is_same<T, float>::value && FMT_USE_FLOAT) ||
          (std::is_same<T, double>::value && FMT_USE_DOUBLE) ||
          (std::is_same<T, long double>::value && FMT_USE_LONG_DOUBLE);
 }
 
 // Smallest of uint32_t, uint64_t, uint128_t that is large enough to
 // represent all values of an integral type T.
 template <typename T>
 using uint32_or_64_or_128_t =
     conditional_t<num_bits<T>() <= 32 && !FMT_REDUCE_INT_INSTANTIATIONS,
                   uint32_t,
                   conditional_t<num_bits<T>() <= 64, uint64_t, uint128_t>>;
+template <typename T>
+using uint64_or_128_t = conditional_t<num_bits<T>() <= 64, uint64_t, uint128_t>;
 
-// 128-bit integer type used internally
-struct FMT_EXTERN_TEMPLATE_API uint128_wrapper {
-  uint128_wrapper() = default;
-
-#if FMT_USE_INT128
-  uint128_t internal_;
-
-  uint128_wrapper(uint64_t high, uint64_t low) FMT_NOEXCEPT
-      : internal_{static_cast<uint128_t>(low) |
-                  (static_cast<uint128_t>(high) << 64)} {}
-
-  uint128_wrapper(uint128_t u) : internal_{u} {}
-
-  uint64_t high() const FMT_NOEXCEPT { return uint64_t(internal_ >> 64); }
-  uint64_t low() const FMT_NOEXCEPT { return uint64_t(internal_); }
-
-  uint128_wrapper& operator+=(uint64_t n) FMT_NOEXCEPT {
-    internal_ += n;
-    return *this;
-  }
-#else
-  uint64_t high_;
-  uint64_t low_;
-
-  uint128_wrapper(uint64_t high, uint64_t low) FMT_NOEXCEPT : high_{high},
-                                                              low_{low} {}
-
-  uint64_t high() const FMT_NOEXCEPT { return high_; }
-  uint64_t low() const FMT_NOEXCEPT { return low_; }
+#define FMT_POWERS_OF_10(factor)                                             \
+  factor * 10, (factor)*100, (factor)*1000, (factor)*10000, (factor)*100000, \
+      (factor)*1000000, (factor)*10000000, (factor)*100000000,               \
+      (factor)*1000000000
 
-  uint128_wrapper& operator+=(uint64_t n) FMT_NOEXCEPT {
-#  if defined(_MSC_VER) && defined(_M_X64)
-    unsigned char carry = _addcarry_u64(0, low_, n, &low_);
-    _addcarry_u64(carry, high_, 0, &high_);
-    return *this;
-#  else
-    uint64_t sum = low_ + n;
-    high_ += (sum < low_ ? 1 : 0);
-    low_ = sum;
-    return *this;
-#  endif
-  }
-#endif
-};
-
-// Table entry type for divisibility test used internally
-template <typename T> struct FMT_EXTERN_TEMPLATE_API divtest_table_entry {
-  T mod_inv;
-  T max_quotient;
-};
-
-// Static data is placed in this class template for the header-only config.
-template <typename T = void> struct FMT_EXTERN_TEMPLATE_API basic_data {
-  static const uint64_t powers_of_10_64[];
-  static const uint32_t zero_or_powers_of_10_32_new[];
-  static const uint64_t zero_or_powers_of_10_64_new[];
-  static const uint64_t grisu_pow10_significands[];
-  static const int16_t grisu_pow10_exponents[];
-  static const divtest_table_entry<uint32_t> divtest_table_for_pow5_32[];
-  static const divtest_table_entry<uint64_t> divtest_table_for_pow5_64[];
-  static const uint64_t dragonbox_pow10_significands_64[];
-  static const uint128_wrapper dragonbox_pow10_significands_128[];
-  // log10(2) = 0x0.4d104d427de7fbcc...
-  static const uint64_t log10_2_significand = 0x4d104d427de7fbcc;
-#if !FMT_USE_FULL_CACHE_DRAGONBOX
-  static const uint64_t powers_of_5_64[];
-  static const uint32_t dragonbox_pow10_recovery_errors[];
-#endif
-  // GCC generates slightly better code for pairs than chars.
-  using digit_pair = char[2];
-  static const digit_pair digits[];
-  static const char hex_digits[];
-  static const char foreground_color[];
-  static const char background_color[];
-  static const char reset_color[5];
-  static const wchar_t wreset_color[5];
-  static const char signs[];
-  static const char left_padding_shifts[5];
-  static const char right_padding_shifts[5];
-
-  // DEPRECATED! These are for ABI compatibility.
-  static const uint32_t zero_or_powers_of_10_32[];
-  static const uint64_t zero_or_powers_of_10_64[];
-};
-
-// Maps bsr(n) to ceil(log10(pow(2, bsr(n) + 1) - 1)).
-// This is a function instead of an array to workaround a bug in GCC10 (#1810).
-FMT_INLINE uint16_t bsr2log10(int bsr) {
-  static constexpr uint16_t data[] = {
-      1,  1,  1,  2,  2,  2,  3,  3,  3,  4,  4,  4,  4,  5,  5,  5,
-      6,  6,  6,  7,  7,  7,  7,  8,  8,  8,  9,  9,  9,  10, 10, 10,
-      10, 11, 11, 11, 12, 12, 12, 13, 13, 13, 13, 14, 14, 14, 15, 15,
-      15, 16, 16, 16, 16, 17, 17, 17, 18, 18, 18, 19, 19, 19, 19, 20};
-  return data[bsr];
+// Converts value in the range [0, 100) to a string.
+constexpr const char* digits2(size_t value) {
+  // GCC generates slightly better code when value is pointer-size.
+  return &"0001020304050607080910111213141516171819"
+         "2021222324252627282930313233343536373839"
+         "4041424344454647484950515253545556575859"
+         "6061626364656667686970717273747576777879"
+         "8081828384858687888990919293949596979899"[value * 2];
 }
 
-#ifndef FMT_EXPORTED
-FMT_EXTERN template struct basic_data<void>;
+// Sign is a template parameter to workaround a bug in gcc 4.8.
+template <typename Char, typename Sign> constexpr Char sign(Sign s) {
+#if !FMT_GCC_VERSION || FMT_GCC_VERSION >= 604
+  static_assert(std::is_same<Sign, sign_t>::value, "");
 #endif
-
-// This is a struct rather than an alias to avoid shadowing warnings in gcc.
-struct data : basic_data<> {};
-
-#ifdef FMT_BUILTIN_CLZLL
-// Returns the number of decimal digits in n. Leading zeros are not counted
-// except for n == 0 in which case count_digits returns 1.
-inline int count_digits(uint64_t n) {
-  // https://github.com/fmtlib/format-benchmark/blob/master/digits10
-  auto t = bsr2log10(FMT_BUILTIN_CLZLL(n | 1) ^ 63);
-  return t - (n < data::zero_or_powers_of_10_64_new[t]);
+  return static_cast<Char>("\0-+ "[s]);
 }
-#else
-// Fallback version of count_digits used when __builtin_clz is not available.
-inline int count_digits(uint64_t n) {
+
+template <typename T> FMT_CONSTEXPR auto count_digits_fallback(T n) -> int {
   int count = 1;
   for (;;) {
     // Integer division is slow so do it for a group of four digits instead
     // of for every digit. The idea comes from the talk by Alexandrescu
     // "Three Optimization Tips for C++". See speed-test for a comparison.
     if (n < 10) return count;
     if (n < 100) return count + 1;
     if (n < 1000) return count + 2;
     if (n < 10000) return count + 3;
     n /= 10000u;
     count += 4;
   }
 }
-#endif
-
 #if FMT_USE_INT128
-inline int count_digits(uint128_t n) {
-  int count = 1;
-  for (;;) {
-    // Integer division is slow so do it for a group of four digits instead
-    // of for every digit. The idea comes from the talk by Alexandrescu
-    // "Three Optimization Tips for C++". See speed-test for a comparison.
-    if (n < 10) return count;
-    if (n < 100) return count + 1;
-    if (n < 1000) return count + 2;
-    if (n < 10000) return count + 3;
-    n /= 10000U;
-    count += 4;
-  }
+FMT_CONSTEXPR inline auto count_digits(uint128_t n) -> int {
+  return count_digits_fallback(n);
 }
 #endif
 
-// Counts the number of digits in n. BITS = log2(radix).
-template <unsigned BITS, typename UInt> inline int count_digits(UInt n) {
-  int num_digits = 0;
-  do {
-    ++num_digits;
-  } while ((n >>= BITS) != 0);
-  return num_digits;
+#ifdef FMT_BUILTIN_CLZLL
+// It is a separate function rather than a part of count_digits to workaround
+// the lack of static constexpr in constexpr functions.
+inline auto do_count_digits(uint64_t n) -> int {
+  // This has comparable performance to the version by Kendall Willets
+  // (https://github.com/fmtlib/format-benchmark/blob/master/digits10)
+  // but uses smaller tables.
+  // Maps bsr(n) to ceil(log10(pow(2, bsr(n) + 1) - 1)).
+  static constexpr uint8_t bsr2log10[] = {
+      1,  1,  1,  2,  2,  2,  3,  3,  3,  4,  4,  4,  4,  5,  5,  5,
+      6,  6,  6,  7,  7,  7,  7,  8,  8,  8,  9,  9,  9,  10, 10, 10,
+      10, 11, 11, 11, 12, 12, 12, 13, 13, 13, 13, 14, 14, 14, 15, 15,
+      15, 16, 16, 16, 16, 17, 17, 17, 18, 18, 18, 19, 19, 19, 19, 20};
+  auto t = bsr2log10[FMT_BUILTIN_CLZLL(n | 1) ^ 63];
+  static constexpr const uint64_t zero_or_powers_of_10[] = {
+      0, 0, FMT_POWERS_OF_10(1U), FMT_POWERS_OF_10(1000000000ULL),
+      10000000000000000000ULL};
+  return t - (n < zero_or_powers_of_10[t]);
 }
+#endif
 
-template <> int count_digits<4>(detail::fallback_uintptr n);
-
-#if FMT_GCC_VERSION || FMT_CLANG_VERSION
-#  define FMT_ALWAYS_INLINE inline __attribute__((always_inline))
-#elif FMT_MSC_VER
-#  define FMT_ALWAYS_INLINE __forceinline
-#else
-#  define FMT_ALWAYS_INLINE inline
+// Returns the number of decimal digits in n. Leading zeros are not counted
+// except for n == 0 in which case count_digits returns 1.
+FMT_CONSTEXPR20 inline auto count_digits(uint64_t n) -> int {
+#ifdef FMT_BUILTIN_CLZLL
+  if (!is_constant_evaluated()) {
+    return do_count_digits(n);
+  }
 #endif
+  return count_digits_fallback(n);
+}
 
-// To suppress unnecessary security cookie checks
-#if FMT_MSC_VER && !FMT_CLANG_VERSION
-#  define FMT_SAFEBUFFERS __declspec(safebuffers)
-#else
-#  define FMT_SAFEBUFFERS
+// Counts the number of digits in n. BITS = log2(radix).
+template <int BITS, typename UInt>
+FMT_CONSTEXPR auto count_digits(UInt n) -> int {
+#ifdef FMT_BUILTIN_CLZ
+  if (num_bits<UInt>() == 32)
+    return (FMT_BUILTIN_CLZ(static_cast<uint32_t>(n) | 1) ^ 31) / BITS + 1;
 #endif
+  // Lambda avoids unreachable code warnings from NVHPC.
+  return [](UInt m) {
+    int num_digits = 0;
+    do {
+      ++num_digits;
+    } while ((m >>= BITS) != 0);
+    return num_digits;
+  }(n);
+}
+
+template <> auto count_digits<4>(detail::fallback_uintptr n) -> int;
 
 #ifdef FMT_BUILTIN_CLZ
-// Optional version of count_digits for better performance on 32-bit platforms.
-inline int count_digits(uint32_t n) {
-  auto t = bsr2log10(FMT_BUILTIN_CLZ(n | 1) ^ 31);
-  return t - (n < data::zero_or_powers_of_10_32_new[t]);
+// It is a separate function rather than a part of count_digits to workaround
+// the lack of static constexpr in constexpr functions.
+FMT_INLINE auto do_count_digits(uint32_t n) -> int {
+// An optimization by Kendall Willets from https://bit.ly/3uOIQrB.
+// This increments the upper 32 bits (log10(T) - 1) when >= T is added.
+#  define FMT_INC(T) (((sizeof(#  T) - 1ull) << 32) - T)
+  static constexpr uint64_t table[] = {
+      FMT_INC(0),          FMT_INC(0),          FMT_INC(0),           // 8
+      FMT_INC(10),         FMT_INC(10),         FMT_INC(10),          // 64
+      FMT_INC(100),        FMT_INC(100),        FMT_INC(100),         // 512
+      FMT_INC(1000),       FMT_INC(1000),       FMT_INC(1000),        // 4096
+      FMT_INC(10000),      FMT_INC(10000),      FMT_INC(10000),       // 32k
+      FMT_INC(100000),     FMT_INC(100000),     FMT_INC(100000),      // 256k
+      FMT_INC(1000000),    FMT_INC(1000000),    FMT_INC(1000000),     // 2048k
+      FMT_INC(10000000),   FMT_INC(10000000),   FMT_INC(10000000),    // 16M
+      FMT_INC(100000000),  FMT_INC(100000000),  FMT_INC(100000000),   // 128M
+      FMT_INC(1000000000), FMT_INC(1000000000), FMT_INC(1000000000),  // 1024M
+      FMT_INC(1000000000), FMT_INC(1000000000)                        // 4B
+  };
+  auto inc = table[FMT_BUILTIN_CLZ(n | 1) ^ 31];
+  return static_cast<int>((n + inc) >> 32);
 }
 #endif
 
-template <typename Int> constexpr int digits10() FMT_NOEXCEPT {
-  return std::numeric_limits<Int>::digits10;
+// Optional version of count_digits for better performance on 32-bit platforms.
+FMT_CONSTEXPR20 inline auto count_digits(uint32_t n) -> int {
+#ifdef FMT_BUILTIN_CLZ
+  if (!is_constant_evaluated()) {
+    return do_count_digits(n);
+  }
+#endif
+  return count_digits_fallback(n);
 }
-template <> constexpr int digits10<int128_t>() FMT_NOEXCEPT { return 38; }
-template <> constexpr int digits10<uint128_t>() FMT_NOEXCEPT { return 38; }
 
-template <typename Char> FMT_API std::string grouping_impl(locale_ref loc);
-template <typename Char> inline std::string grouping(locale_ref loc) {
-  return grouping_impl<char>(loc);
+template <typename Int> constexpr auto digits10() FMT_NOEXCEPT -> int {
+  return std::numeric_limits<Int>::digits10;
 }
-template <> inline std::string grouping<wchar_t>(locale_ref loc) {
-  return grouping_impl<wchar_t>(loc);
+template <> constexpr auto digits10<int128_t>() FMT_NOEXCEPT -> int {
+  return 38;
 }
+template <> constexpr auto digits10<uint128_t>() FMT_NOEXCEPT -> int {
+  return 38;
+}
+
+template <typename Char> struct thousands_sep_result {
+  std::string grouping;
+  Char thousands_sep;
+};
 
-template <typename Char> FMT_API Char thousands_sep_impl(locale_ref loc);
-template <typename Char> inline Char thousands_sep(locale_ref loc) {
-  return Char(thousands_sep_impl<char>(loc));
+template <typename Char>
+FMT_API auto thousands_sep_impl(locale_ref loc) -> thousands_sep_result<Char>;
+template <typename Char>
+inline auto thousands_sep(locale_ref loc) -> thousands_sep_result<Char> {
+  auto result = thousands_sep_impl<char>(loc);
+  return {result.grouping, Char(result.thousands_sep)};
 }
-template <> inline wchar_t thousands_sep(locale_ref loc) {
+template <>
+inline auto thousands_sep(locale_ref loc) -> thousands_sep_result<wchar_t> {
   return thousands_sep_impl<wchar_t>(loc);
 }
 
-template <typename Char> FMT_API Char decimal_point_impl(locale_ref loc);
-template <typename Char> inline Char decimal_point(locale_ref loc) {
+template <typename Char>
+FMT_API auto decimal_point_impl(locale_ref loc) -> Char;
+template <typename Char> inline auto decimal_point(locale_ref loc) -> Char {
   return Char(decimal_point_impl<char>(loc));
 }
-template <> inline wchar_t decimal_point(locale_ref loc) {
+template <> inline auto decimal_point(locale_ref loc) -> wchar_t {
   return decimal_point_impl<wchar_t>(loc);
 }
 
 // Compares two characters for equality.
-template <typename Char> bool equal2(const Char* lhs, const char* rhs) {
-  return lhs[0] == rhs[0] && lhs[1] == rhs[1];
+template <typename Char> auto equal2(const Char* lhs, const char* rhs) -> bool {
+  return lhs[0] == Char(rhs[0]) && lhs[1] == Char(rhs[1]);
 }
-inline bool equal2(const char* lhs, const char* rhs) {
+inline auto equal2(const char* lhs, const char* rhs) -> bool {
   return memcmp(lhs, rhs, 2) == 0;
 }
 
 // Copies two characters from src to dst.
-template <typename Char> void copy2(Char* dst, const char* src) {
+template <typename Char>
+FMT_CONSTEXPR20 FMT_INLINE void copy2(Char* dst, const char* src) {
+  if (!is_constant_evaluated() && sizeof(Char) == sizeof(char)) {
+    memcpy(dst, src, 2);
+    return;
+  }
   *dst++ = static_cast<Char>(*src++);
   *dst = static_cast<Char>(*src);
 }
-FMT_INLINE void copy2(char* dst, const char* src) { memcpy(dst, src, 2); }
 
 template <typename Iterator> struct format_decimal_result {
   Iterator begin;
   Iterator end;
 };
 
 // Formats a decimal unsigned integer value writing into out pointing to a
 // buffer of specified size. The caller must ensure that the buffer is large
 // enough.
 template <typename Char, typename UInt>
-inline format_decimal_result<Char*> format_decimal(Char* out, UInt value,
-                                                   int size) {
+FMT_CONSTEXPR20 auto format_decimal(Char* out, UInt value, int size)
+    -> format_decimal_result<Char*> {
   FMT_ASSERT(size >= count_digits(value), "invalid digit count");
   out += size;
   Char* end = out;
   while (value >= 100) {
     // Integer division is slow so do it for a group of two digits instead
     // of for every digit. The idea comes from the talk by Alexandrescu
     // "Three Optimization Tips for C++". See speed-test for a comparison.
     out -= 2;
-    copy2(out, data::digits[value % 100]);
+    copy2(out, digits2(static_cast<size_t>(value % 100)));
     value /= 100;
   }
   if (value < 10) {
     *--out = static_cast<Char>('0' + value);
     return {out, end};
   }
   out -= 2;
-  copy2(out, data::digits[value]);
+  copy2(out, digits2(static_cast<size_t>(value)));
   return {out, end};
 }
 
 template <typename Char, typename UInt, typename Iterator,
           FMT_ENABLE_IF(!std::is_pointer<remove_cvref_t<Iterator>>::value)>
-inline format_decimal_result<Iterator> format_decimal(Iterator out, UInt value,
-                                                      int size) {
+inline auto format_decimal(Iterator out, UInt value, int size)
+    -> format_decimal_result<Iterator> {
   // Buffer is large enough to hold all digits (digits10 + 1).
   Char buffer[digits10<UInt>() + 1];
   auto end = format_decimal(buffer, value, size).end;
-  return {out, detail::copy_str<Char>(buffer, end, out)};
+  return {out, detail::copy_str_noinline<Char>(buffer, end, out)};
 }
 
 template <unsigned BASE_BITS, typename Char, typename UInt>
-inline Char* format_uint(Char* buffer, UInt value, int num_digits,
-                         bool upper = false) {
+FMT_CONSTEXPR auto format_uint(Char* buffer, UInt value, int num_digits,
+                               bool upper = false) -> Char* {
   buffer += num_digits;
   Char* end = buffer;
   do {
-    const char* digits = upper ? "0123456789ABCDEF" : data::hex_digits;
+    const char* digits = upper ? "0123456789ABCDEF" : "0123456789abcdef";
     unsigned digit = (value & ((1 << BASE_BITS) - 1));
     *--buffer = static_cast<Char>(BASE_BITS < 4 ? static_cast<char>('0' + digit)
                                                 : digits[digit]);
   } while ((value >>= BASE_BITS) != 0);
   return end;
 }
 
 template <unsigned BASE_BITS, typename Char>
-Char* format_uint(Char* buffer, detail::fallback_uintptr n, int num_digits,
-                  bool = false) {
+auto format_uint(Char* buffer, detail::fallback_uintptr n, int num_digits,
+                 bool = false) -> Char* {
   auto char_digits = std::numeric_limits<unsigned char>::digits / 4;
   int start = (num_digits + char_digits - 1) / char_digits - 1;
   if (int start_digits = num_digits % char_digits) {
     unsigned value = n.value[start--];
     buffer = format_uint<BASE_BITS>(buffer, value, start_digits);
   }
   for (; start >= 0; --start) {
     unsigned value = n.value[start];
     buffer += char_digits;
     auto p = buffer;
     for (int i = 0; i < char_digits; ++i) {
       unsigned digit = (value & ((1 << BASE_BITS) - 1));
-      *--p = static_cast<Char>(data::hex_digits[digit]);
+      *--p = static_cast<Char>("0123456789abcdef"[digit]);
       value >>= BASE_BITS;
     }
   }
   return buffer;
 }
 
 template <unsigned BASE_BITS, typename Char, typename It, typename UInt>
-inline It format_uint(It out, UInt value, int num_digits, bool upper = false) {
+inline auto format_uint(It out, UInt value, int num_digits, bool upper = false)
+    -> It {
   if (auto ptr = to_pointer<Char>(out, to_unsigned(num_digits))) {
     format_uint<BASE_BITS>(ptr, value, num_digits, upper);
     return out;
   }
   // Buffer should be large enough to hold all digits (digits / BASE_BITS + 1).
   char buffer[num_bits<UInt>() / BASE_BITS + 1];
   format_uint<BASE_BITS>(buffer, value, num_digits, upper);
-  return detail::copy_str<Char>(buffer, buffer + num_digits, out);
+  return detail::copy_str_noinline<Char>(buffer, buffer + num_digits, out);
 }
 
 // A converter from UTF-8 to UTF-16.
 class utf8_to_utf16 {
  private:
-  wmemory_buffer buffer_;
+  basic_memory_buffer<wchar_t> buffer_;
 
  public:
   FMT_API explicit utf8_to_utf16(string_view s);
-  operator wstring_view() const { return {&buffer_[0], size()}; }
-  size_t size() const { return buffer_.size() - 1; }
-  const wchar_t* c_str() const { return &buffer_[0]; }
-  std::wstring str() const { return {&buffer_[0], size()}; }
+  operator basic_string_view<wchar_t>() const { return {&buffer_[0], size()}; }
+  auto size() const -> size_t { return buffer_.size() - 1; }
+  auto c_str() const -> const wchar_t* { return &buffer_[0]; }
+  auto str() const -> std::wstring { return {&buffer_[0], size()}; }
 };
 
-template <typename T = void> struct null {};
-
-// Workaround an array initialization issue in gcc 4.8.
-template <typename Char> struct fill_t {
- private:
-  enum { max_size = 4 };
-  Char data_[max_size];
-  unsigned char size_;
-
- public:
-  FMT_CONSTEXPR void operator=(basic_string_view<Char> s) {
-    auto size = s.size();
-    if (size > max_size) {
-      FMT_THROW(format_error("invalid fill"));
-      return;
-    }
-    for (size_t i = 0; i < size; ++i) data_[i] = s[i];
-    size_ = static_cast<unsigned char>(size);
-  }
-
-  size_t size() const { return size_; }
-  const Char* data() const { return data_; }
-
-  FMT_CONSTEXPR Char& operator[](size_t index) { return data_[index]; }
-  FMT_CONSTEXPR const Char& operator[](size_t index) const {
-    return data_[index];
-  }
-
-  static FMT_CONSTEXPR fill_t<Char> make() {
-    auto fill = fill_t<Char>();
-    fill[0] = Char(' ');
-    fill.size_ = 1;
-    return fill;
-  }
-};
-}  // namespace detail
-
-// We cannot use enum classes as bit fields because of a gcc bug
-// https://gcc.gnu.org/bugzilla/show_bug.cgi?id=61414.
-namespace align {
-enum type { none, left, right, center, numeric };
-}
-using align_t = align::type;
-
-namespace sign {
-enum type { none, minus, plus, space };
-}
-using sign_t = sign::type;
-
-// Format specifiers for built-in and string types.
-template <typename Char> struct basic_format_specs {
-  int width;
-  int precision;
-  char type;
-  align_t align : 4;
-  sign_t sign : 3;
-  bool alt : 1;  // Alternate form ('#').
-  detail::fill_t<Char> fill;
-
-  constexpr basic_format_specs()
-      : width(0),
-        precision(-1),
-        type(0),
-        align(align::none),
-        sign(sign::none),
-        alt(false),
-        fill(detail::fill_t<Char>::make()) {}
-};
-
-using format_specs = basic_format_specs<char>;
-
-namespace detail {
 namespace dragonbox {
 
 // Type-specific information that Dragonbox uses.
 template <class T> struct float_info;
 
 template <> struct float_info<float> {
   using carrier_uint = uint32_t;
@@ -1270,585 +1256,602 @@
 
 template <typename T> struct decimal_fp {
   using significand_type = typename float_info<T>::carrier_uint;
   significand_type significand;
   int exponent;
 };
 
-template <typename T> decimal_fp<T> to_decimal(T x) FMT_NOEXCEPT;
+template <typename T>
+FMT_API auto to_decimal(T x) FMT_NOEXCEPT -> decimal_fp<T>;
 }  // namespace dragonbox
 
 template <typename T>
-constexpr typename dragonbox::float_info<T>::carrier_uint exponent_mask() {
+constexpr auto exponent_mask() ->
+    typename dragonbox::float_info<T>::carrier_uint {
   using uint = typename dragonbox::float_info<T>::carrier_uint;
   return ((uint(1) << dragonbox::float_info<T>::exponent_bits) - 1)
          << dragonbox::float_info<T>::significand_bits;
 }
 
-// A floating-point presentation format.
-enum class float_format : unsigned char {
-  general,  // General: exponent notation or fixed point based on magnitude.
-  exp,      // Exponent notation with the default precision of 6, e.g. 1.2e-3.
-  fixed,    // Fixed point with the default precision of 6, e.g. 0.0012.
-  hex
-};
-
-struct float_specs {
-  int precision;
-  float_format format : 8;
-  sign_t sign : 8;
-  bool upper : 1;
-  bool locale : 1;
-  bool binary32 : 1;
-  bool use_grisu : 1;
-  bool showpoint : 1;
-};
-
 // Writes the exponent exp in the form "[+-]d{2,3}" to buffer.
-template <typename Char, typename It> It write_exponent(int exp, It it) {
+template <typename Char, typename It>
+FMT_CONSTEXPR auto write_exponent(int exp, It it) -> It {
   FMT_ASSERT(-10000 < exp && exp < 10000, "exponent out of range");
   if (exp < 0) {
     *it++ = static_cast<Char>('-');
     exp = -exp;
   } else {
     *it++ = static_cast<Char>('+');
   }
   if (exp >= 100) {
-    const char* top = data::digits[exp / 100];
+    const char* top = digits2(to_unsigned(exp / 100));
     if (exp >= 1000) *it++ = static_cast<Char>(top[0]);
     *it++ = static_cast<Char>(top[1]);
     exp %= 100;
   }
-  const char* d = data::digits[exp];
+  const char* d = digits2(to_unsigned(exp));
   *it++ = static_cast<Char>(d[0]);
   *it++ = static_cast<Char>(d[1]);
   return it;
 }
 
 template <typename T>
-int format_float(T value, int precision, float_specs specs, buffer<char>& buf);
+FMT_HEADER_ONLY_CONSTEXPR20 auto format_float(T value, int precision,
+                                              float_specs specs,
+                                              buffer<char>& buf) -> int;
 
 // Formats a floating-point number with snprintf.
 template <typename T>
-int snprintf_float(T value, int precision, float_specs specs,
-                   buffer<char>& buf);
-
-template <typename T> T promote_float(T value) { return value; }
-inline double promote_float(float value) { return static_cast<double>(value); }
-
-template <typename Handler>
-FMT_CONSTEXPR void handle_int_type_spec(char spec, Handler&& handler) {
-  switch (spec) {
-  case 0:
-  case 'd':
-    handler.on_dec();
-    break;
-  case 'x':
-  case 'X':
-    handler.on_hex();
-    break;
-  case 'b':
-  case 'B':
-    handler.on_bin();
-    break;
-  case 'o':
-    handler.on_oct();
-    break;
-#ifdef FMT_DEPRECATED_N_SPECIFIER
-  case 'n':
-#endif
-  case 'L':
-    handler.on_num();
-    break;
-  case 'c':
-    handler.on_chr();
-    break;
-  default:
-    handler.on_error();
-  }
-}
+auto snprintf_float(T value, int precision, float_specs specs,
+                    buffer<char>& buf) -> int;
 
-template <typename ErrorHandler = error_handler, typename Char>
-FMT_CONSTEXPR float_specs parse_float_type_spec(
-    const basic_format_specs<Char>& specs, ErrorHandler&& eh = {}) {
-  auto result = float_specs();
-  result.showpoint = specs.alt;
-  switch (specs.type) {
-  case 0:
-    result.format = float_format::general;
-    result.showpoint |= specs.precision > 0;
-    break;
-  case 'G':
-    result.upper = true;
-    FMT_FALLTHROUGH;
-  case 'g':
-    result.format = float_format::general;
-    break;
-  case 'E':
-    result.upper = true;
-    FMT_FALLTHROUGH;
-  case 'e':
-    result.format = float_format::exp;
-    result.showpoint |= specs.precision != 0;
-    break;
-  case 'F':
-    result.upper = true;
-    FMT_FALLTHROUGH;
-  case 'f':
-    result.format = float_format::fixed;
-    result.showpoint |= specs.precision != 0;
-    break;
-  case 'A':
-    result.upper = true;
-    FMT_FALLTHROUGH;
-  case 'a':
-    result.format = float_format::hex;
-    break;
-#ifdef FMT_DEPRECATED_N_SPECIFIER
-  case 'n':
-#endif
-  case 'L':
-    result.locale = true;
-    break;
-  default:
-    eh.on_error("invalid type specifier");
-    break;
-  }
-  return result;
-}
-
-template <typename Char, typename Handler>
-FMT_CONSTEXPR void handle_char_specs(const basic_format_specs<Char>* specs,
-                                     Handler&& handler) {
-  if (!specs) return handler.on_char();
-  if (specs->type && specs->type != 'c') return handler.on_int();
-  if (specs->align == align::numeric || specs->sign != sign::none || specs->alt)
-    handler.on_error("invalid format specifier for char");
-  handler.on_char();
-}
-
-template <typename Char, typename Handler>
-FMT_CONSTEXPR void handle_cstring_type_spec(Char spec, Handler&& handler) {
-  if (spec == 0 || spec == 's')
-    handler.on_string();
-  else if (spec == 'p')
-    handler.on_pointer();
-  else
-    handler.on_error("invalid type specifier");
-}
-
-template <typename Char, typename ErrorHandler>
-FMT_CONSTEXPR void check_string_type_spec(Char spec, ErrorHandler&& eh) {
-  if (spec != 0 && spec != 's') eh.on_error("invalid type specifier");
+template <typename T> constexpr auto promote_float(T value) -> T {
+  return value;
 }
-
-template <typename Char, typename ErrorHandler>
-FMT_CONSTEXPR void check_pointer_type_spec(Char spec, ErrorHandler&& eh) {
-  if (spec != 0 && spec != 'p') eh.on_error("invalid type specifier");
+constexpr auto promote_float(float value) -> double {
+  return static_cast<double>(value);
 }
 
-template <typename ErrorHandler> class int_type_checker : private ErrorHandler {
- public:
-  FMT_CONSTEXPR explicit int_type_checker(ErrorHandler eh) : ErrorHandler(eh) {}
-
-  FMT_CONSTEXPR void on_dec() {}
-  FMT_CONSTEXPR void on_hex() {}
-  FMT_CONSTEXPR void on_bin() {}
-  FMT_CONSTEXPR void on_oct() {}
-  FMT_CONSTEXPR void on_num() {}
-  FMT_CONSTEXPR void on_chr() {}
-
-  FMT_CONSTEXPR void on_error() {
-    ErrorHandler::on_error("invalid type specifier");
-  }
-};
-
-template <typename ErrorHandler>
-class char_specs_checker : public ErrorHandler {
- private:
-  char type_;
-
- public:
-  FMT_CONSTEXPR char_specs_checker(char type, ErrorHandler eh)
-      : ErrorHandler(eh), type_(type) {}
-
-  FMT_CONSTEXPR void on_int() {
-    handle_int_type_spec(type_, int_type_checker<ErrorHandler>(*this));
-  }
-  FMT_CONSTEXPR void on_char() {}
-};
-
-template <typename ErrorHandler>
-class cstring_type_checker : public ErrorHandler {
- public:
-  FMT_CONSTEXPR explicit cstring_type_checker(ErrorHandler eh)
-      : ErrorHandler(eh) {}
-
-  FMT_CONSTEXPR void on_string() {}
-  FMT_CONSTEXPR void on_pointer() {}
-};
-
 template <typename OutputIt, typename Char>
-FMT_NOINLINE OutputIt fill(OutputIt it, size_t n, const fill_t<Char>& fill) {
+FMT_NOINLINE FMT_CONSTEXPR auto fill(OutputIt it, size_t n,
+                                     const fill_t<Char>& fill) -> OutputIt {
   auto fill_size = fill.size();
-  if (fill_size == 1) return std::fill_n(it, n, fill[0]);
-  for (size_t i = 0; i < n; ++i) it = std::copy_n(fill.data(), fill_size, it);
+  if (fill_size == 1) return detail::fill_n(it, n, fill[0]);
+  auto data = fill.data();
+  for (size_t i = 0; i < n; ++i)
+    it = copy_str<Char>(data, data + fill_size, it);
   return it;
 }
 
 // Writes the output of f, padded according to format specifications in specs.
 // size: output size in code units.
 // width: output display width in (terminal) column positions.
 template <align::type align = align::left, typename OutputIt, typename Char,
           typename F>
-inline OutputIt write_padded(OutputIt out,
-                             const basic_format_specs<Char>& specs, size_t size,
-                             size_t width, F&& f) {
+FMT_CONSTEXPR auto write_padded(OutputIt out,
+                                const basic_format_specs<Char>& specs,
+                                size_t size, size_t width, F&& f) -> OutputIt {
   static_assert(align == align::left || align == align::right, "");
   unsigned spec_width = to_unsigned(specs.width);
   size_t padding = spec_width > width ? spec_width - width : 0;
-  auto* shifts = align == align::left ? data::left_padding_shifts
-                                      : data::right_padding_shifts;
+  // Shifts are encoded as string literals because static constexpr is not
+  // supported in constexpr functions.
+  auto* shifts = align == align::left ? "\x1f\x1f\x00\x01" : "\x00\x1f\x00\x01";
   size_t left_padding = padding >> shifts[specs.align];
+  size_t right_padding = padding - left_padding;
   auto it = reserve(out, size + padding * specs.fill.size());
-  it = fill(it, left_padding, specs.fill);
+  if (left_padding != 0) it = fill(it, left_padding, specs.fill);
   it = f(it);
-  it = fill(it, padding - left_padding, specs.fill);
+  if (right_padding != 0) it = fill(it, right_padding, specs.fill);
   return base_iterator(out, it);
 }
 
 template <align::type align = align::left, typename OutputIt, typename Char,
           typename F>
-inline OutputIt write_padded(OutputIt out,
-                             const basic_format_specs<Char>& specs, size_t size,
-                             F&& f) {
+constexpr auto write_padded(OutputIt out, const basic_format_specs<Char>& specs,
+                            size_t size, F&& f) -> OutputIt {
   return write_padded<align>(out, specs, size, size, f);
 }
 
+template <align::type align = align::left, typename Char, typename OutputIt>
+FMT_CONSTEXPR auto write_bytes(OutputIt out, string_view bytes,
+                               const basic_format_specs<Char>& specs)
+    -> OutputIt {
+  return write_padded<align>(
+      out, specs, bytes.size(), [bytes](reserve_iterator<OutputIt> it) {
+        const char* data = bytes.data();
+        return copy_str<Char>(data, data + bytes.size(), it);
+      });
+}
+
+template <typename Char, typename OutputIt, typename UIntPtr>
+auto write_ptr(OutputIt out, UIntPtr value,
+               const basic_format_specs<Char>* specs) -> OutputIt {
+  int num_digits = count_digits<4>(value);
+  auto size = to_unsigned(num_digits) + size_t(2);
+  auto write = [=](reserve_iterator<OutputIt> it) {
+    *it++ = static_cast<Char>('0');
+    *it++ = static_cast<Char>('x');
+    return format_uint<4, Char>(it, value, num_digits);
+  };
+  return specs ? write_padded<align::right>(out, *specs, size, write)
+               : base_iterator(out, write(reserve(out, size)));
+}
+
 template <typename Char, typename OutputIt>
-OutputIt write_bytes(OutputIt out, string_view bytes,
-                     const basic_format_specs<Char>& specs) {
-  using iterator = remove_reference_t<decltype(reserve(out, 0))>;
-  return write_padded(out, specs, bytes.size(), [bytes](iterator it) {
-    const char* data = bytes.data();
-    return copy_str<Char>(data, data + bytes.size(), it);
+FMT_CONSTEXPR auto write_char(OutputIt out, Char value,
+                              const basic_format_specs<Char>& specs)
+    -> OutputIt {
+  return write_padded(out, specs, 1, [=](reserve_iterator<OutputIt> it) {
+    *it++ = value;
+    return it;
   });
 }
+template <typename Char, typename OutputIt>
+FMT_CONSTEXPR auto write(OutputIt out, Char value,
+                         const basic_format_specs<Char>& specs,
+                         locale_ref loc = {}) -> OutputIt {
+  return check_char_specs(specs)
+             ? write_char(out, value, specs)
+             : write(out, static_cast<int>(value), specs, loc);
+}
 
 // Data for write_int that doesn't depend on output iterator type. It is used to
 // avoid template code bloat.
 template <typename Char> struct write_int_data {
   size_t size;
   size_t padding;
 
-  write_int_data(int num_digits, string_view prefix,
-                 const basic_format_specs<Char>& specs)
-      : size(prefix.size() + to_unsigned(num_digits)), padding(0) {
+  FMT_CONSTEXPR write_int_data(int num_digits, unsigned prefix,
+                               const basic_format_specs<Char>& specs)
+      : size((prefix >> 24) + to_unsigned(num_digits)), padding(0) {
     if (specs.align == align::numeric) {
       auto width = to_unsigned(specs.width);
       if (width > size) {
         padding = width - size;
         size = width;
       }
     } else if (specs.precision > num_digits) {
-      size = prefix.size() + to_unsigned(specs.precision);
+      size = (prefix >> 24) + to_unsigned(specs.precision);
       padding = to_unsigned(specs.precision - num_digits);
     }
   }
 };
 
 // Writes an integer in the format
 //   <left-padding><prefix><numeric-padding><digits><right-padding>
-// where <digits> are written by f(it).
-template <typename OutputIt, typename Char, typename F>
-OutputIt write_int(OutputIt out, int num_digits, string_view prefix,
-                   const basic_format_specs<Char>& specs, F f) {
+// where <digits> are written by write_digits(it).
+// prefix contains chars in three lower bytes and the size in the fourth byte.
+template <typename OutputIt, typename Char, typename W>
+FMT_CONSTEXPR FMT_INLINE auto write_int(OutputIt out, int num_digits,
+                                        unsigned prefix,
+                                        const basic_format_specs<Char>& specs,
+                                        W write_digits) -> OutputIt {
+  // Slightly faster check for specs.width == 0 && specs.precision == -1.
+  if ((specs.width | (specs.precision + 1)) == 0) {
+    auto it = reserve(out, to_unsigned(num_digits) + (prefix >> 24));
+    if (prefix != 0) {
+      for (unsigned p = prefix & 0xffffff; p != 0; p >>= 8)
+        *it++ = static_cast<Char>(p & 0xff);
+    }
+    return base_iterator(out, write_digits(it));
+  }
   auto data = write_int_data<Char>(num_digits, prefix, specs);
-  using iterator = remove_reference_t<decltype(reserve(out, 0))>;
-  return write_padded<align::right>(out, specs, data.size, [=](iterator it) {
-    if (prefix.size() != 0)
-      it = copy_str<Char>(prefix.begin(), prefix.end(), it);
-    it = std::fill_n(it, data.padding, static_cast<Char>('0'));
-    return f(it);
-  });
-}
-
-template <typename StrChar, typename Char, typename OutputIt>
-OutputIt write(OutputIt out, basic_string_view<StrChar> s,
-               const basic_format_specs<Char>& specs) {
-  auto data = s.data();
-  auto size = s.size();
-  if (specs.precision >= 0 && to_unsigned(specs.precision) < size)
-    size = code_point_index(s, to_unsigned(specs.precision));
-  auto width = specs.width != 0
-                   ? count_code_points(basic_string_view<StrChar>(data, size))
-                   : 0;
-  using iterator = remove_reference_t<decltype(reserve(out, 0))>;
-  return write_padded(out, specs, size, width, [=](iterator it) {
-    return copy_str<Char>(data, data + size, it);
-  });
-}
+  return write_padded<align::right>(
+      out, specs, data.size, [=](reserve_iterator<OutputIt> it) {
+        for (unsigned p = prefix & 0xffffff; p != 0; p >>= 8)
+          *it++ = static_cast<Char>(p & 0xff);
+        it = detail::fill_n(it, data.padding, static_cast<Char>('0'));
+        return write_digits(it);
+      });
+}
+
+template <typename Char> class digit_grouping {
+ private:
+  thousands_sep_result<Char> sep_;
+
+  struct next_state {
+    std::string::const_iterator group;
+    int pos;
+  };
+  next_state initial_state() const { return {sep_.grouping.begin(), 0}; }
 
-// The handle_int_type_spec handler that writes an integer.
-template <typename OutputIt, typename Char, typename UInt> struct int_writer {
-  OutputIt out;
-  locale_ref locale;
-  const basic_format_specs<Char>& specs;
-  UInt abs_value;
-  char prefix[4];
-  unsigned prefix_size;
+  // Returns the next digit group separator position.
+  int next(next_state& state) const {
+    if (!sep_.thousands_sep) return max_value<int>();
+    if (state.group == sep_.grouping.end())
+      return state.pos += sep_.grouping.back();
+    if (*state.group <= 0 || *state.group == max_value<char>())
+      return max_value<int>();
+    state.pos += *state.group++;
+    return state.pos;
+  }
 
-  using iterator =
-      remove_reference_t<decltype(reserve(std::declval<OutputIt&>(), 0))>;
+ public:
+  explicit digit_grouping(locale_ref loc, bool localized = true) {
+    if (localized)
+      sep_ = thousands_sep<Char>(loc);
+    else
+      sep_.thousands_sep = Char();
+  }
+  explicit digit_grouping(thousands_sep_result<Char> sep) : sep_(sep) {}
 
-  string_view get_prefix() const { return string_view(prefix, prefix_size); }
+  Char separator() const { return sep_.thousands_sep; }
 
-  template <typename Int>
-  int_writer(OutputIt output, locale_ref loc, Int value,
-             const basic_format_specs<Char>& s)
-      : out(output),
-        locale(loc),
-        specs(s),
-        abs_value(static_cast<UInt>(value)),
-        prefix_size(0) {
-    static_assert(std::is_same<uint32_or_64_or_128_t<Int>, UInt>::value, "");
-    if (is_negative(value)) {
-      prefix[0] = '-';
-      ++prefix_size;
-      abs_value = 0 - abs_value;
-    } else if (specs.sign != sign::none && specs.sign != sign::minus) {
-      prefix[0] = specs.sign == sign::plus ? '+' : ' ';
-      ++prefix_size;
+  int count_separators(int num_digits) const {
+    int count = 0;
+    auto state = initial_state();
+    while (num_digits > next(state)) ++count;
+    return count;
+  }
+
+  // Applies grouping to digits and write the output to out.
+  template <typename Out, typename C>
+  Out apply(Out out, basic_string_view<C> digits) const {
+    auto num_digits = static_cast<int>(digits.size());
+    auto separators = basic_memory_buffer<int>();
+    separators.push_back(0);
+    auto state = initial_state();
+    while (int i = next(state)) {
+      if (i >= num_digits) break;
+      separators.push_back(i);
+    }
+    for (int i = 0, sep_index = static_cast<int>(separators.size() - 1);
+         i < num_digits; ++i) {
+      if (num_digits - i == separators[sep_index]) {
+        *out++ = separator();
+        --sep_index;
+      }
+      *out++ = static_cast<Char>(digits[to_unsigned(i)]);
     }
+    return out;
   }
+};
+
+template <typename OutputIt, typename UInt, typename Char>
+auto write_int_localized(OutputIt out, UInt value, unsigned prefix,
+                         const basic_format_specs<Char>& specs,
+                         const digit_grouping<Char>& grouping) -> OutputIt {
+  static_assert(std::is_same<uint64_or_128_t<UInt>, UInt>::value, "");
+  int num_digits = count_digits(value);
+  char digits[40];
+  format_decimal(digits, value, num_digits);
+  unsigned size = to_unsigned((prefix != 0 ? 1 : 0) + num_digits +
+                              grouping.count_separators(num_digits));
+  return write_padded<align::right>(
+      out, specs, size, size, [&](reserve_iterator<OutputIt> it) {
+        if (prefix != 0) *it++ = static_cast<Char>(prefix);
+        return grouping.apply(it, string_view(digits, to_unsigned(num_digits)));
+      });
+}
+
+template <typename OutputIt, typename UInt, typename Char>
+auto write_int_localized(OutputIt& out, UInt value, unsigned prefix,
+                         const basic_format_specs<Char>& specs, locale_ref loc)
+    -> bool {
+  auto grouping = digit_grouping<Char>(loc);
+  out = write_int_localized(out, value, prefix, specs, grouping);
+  return true;
+}
+
+FMT_CONSTEXPR inline void prefix_append(unsigned& prefix, unsigned value) {
+  prefix |= prefix != 0 ? value << 8 : value;
+  prefix += (1u + (value > 0xff ? 1 : 0)) << 24;
+}
+
+template <typename UInt> struct write_int_arg {
+  UInt abs_value;
+  unsigned prefix;
+};
 
-  void on_dec() {
+template <typename T>
+FMT_CONSTEXPR auto make_write_int_arg(T value, sign_t sign)
+    -> write_int_arg<uint32_or_64_or_128_t<T>> {
+  auto prefix = 0u;
+  auto abs_value = static_cast<uint32_or_64_or_128_t<T>>(value);
+  if (is_negative(value)) {
+    prefix = 0x01000000 | '-';
+    abs_value = 0 - abs_value;
+  } else {
+    constexpr const unsigned prefixes[4] = {0, 0, 0x1000000u | '+',
+                                            0x1000000u | ' '};
+    prefix = prefixes[sign];
+  }
+  return {abs_value, prefix};
+}
+
+template <typename Char, typename OutputIt, typename T>
+FMT_CONSTEXPR FMT_INLINE auto write_int(OutputIt out, write_int_arg<T> arg,
+                                        const basic_format_specs<Char>& specs,
+                                        locale_ref loc) -> OutputIt {
+  static_assert(std::is_same<T, uint32_or_64_or_128_t<T>>::value, "");
+  auto abs_value = arg.abs_value;
+  auto prefix = arg.prefix;
+  switch (specs.type) {
+  case presentation_type::none:
+  case presentation_type::dec: {
+    if (specs.localized &&
+        write_int_localized(out, static_cast<uint64_or_128_t<T>>(abs_value),
+                            prefix, specs, loc)) {
+      return out;
+    }
     auto num_digits = count_digits(abs_value);
-    out = write_int(
-        out, num_digits, get_prefix(), specs, [this, num_digits](iterator it) {
+    return write_int(
+        out, num_digits, prefix, specs, [=](reserve_iterator<OutputIt> it) {
           return format_decimal<Char>(it, abs_value, num_digits).end;
         });
   }
-
-  void on_hex() {
-    if (specs.alt) {
-      prefix[prefix_size++] = '0';
-      prefix[prefix_size++] = specs.type;
-    }
+  case presentation_type::hex_lower:
+  case presentation_type::hex_upper: {
+    bool upper = specs.type == presentation_type::hex_upper;
+    if (specs.alt)
+      prefix_append(prefix, unsigned(upper ? 'X' : 'x') << 8 | '0');
     int num_digits = count_digits<4>(abs_value);
-    out = write_int(out, num_digits, get_prefix(), specs,
-                    [this, num_digits](iterator it) {
-                      return format_uint<4, Char>(it, abs_value, num_digits,
-                                                  specs.type != 'x');
-                    });
+    return write_int(
+        out, num_digits, prefix, specs, [=](reserve_iterator<OutputIt> it) {
+          return format_uint<4, Char>(it, abs_value, num_digits, upper);
+        });
   }
-
-  void on_bin() {
-    if (specs.alt) {
-      prefix[prefix_size++] = '0';
-      prefix[prefix_size++] = static_cast<char>(specs.type);
-    }
+  case presentation_type::bin_lower:
+  case presentation_type::bin_upper: {
+    bool upper = specs.type == presentation_type::bin_upper;
+    if (specs.alt)
+      prefix_append(prefix, unsigned(upper ? 'B' : 'b') << 8 | '0');
     int num_digits = count_digits<1>(abs_value);
-    out = write_int(out, num_digits, get_prefix(), specs,
-                    [this, num_digits](iterator it) {
-                      return format_uint<1, Char>(it, abs_value, num_digits);
-                    });
+    return write_int(out, num_digits, prefix, specs,
+                     [=](reserve_iterator<OutputIt> it) {
+                       return format_uint<1, Char>(it, abs_value, num_digits);
+                     });
   }
-
-  void on_oct() {
+  case presentation_type::oct: {
     int num_digits = count_digits<3>(abs_value);
-    if (specs.alt && specs.precision <= num_digits && abs_value != 0) {
-      // Octal prefix '0' is counted as a digit, so only add it if precision
-      // is not greater than the number of digits.
-      prefix[prefix_size++] = '0';
-    }
-    out = write_int(out, num_digits, get_prefix(), specs,
-                    [this, num_digits](iterator it) {
-                      return format_uint<3, Char>(it, abs_value, num_digits);
-                    });
-  }
-
-  enum { sep_size = 1 };
-
-  void on_num() {
-    std::string groups = grouping<Char>(locale);
-    if (groups.empty()) return on_dec();
-    auto sep = thousands_sep<Char>(locale);
-    if (!sep) return on_dec();
-    int num_digits = count_digits(abs_value);
-    int size = num_digits, n = num_digits;
-    std::string::const_iterator group = groups.cbegin();
-    while (group != groups.cend() && n > *group && *group > 0 &&
-           *group != max_value<char>()) {
-      size += sep_size;
-      n -= *group;
-      ++group;
-    }
-    if (group == groups.cend()) size += sep_size * ((n - 1) / groups.back());
-    char digits[40];
-    format_decimal(digits, abs_value, num_digits);
-    basic_memory_buffer<Char> buffer;
-    size += static_cast<int>(prefix_size);
-    const auto usize = to_unsigned(size);
-    buffer.resize(usize);
-    basic_string_view<Char> s(&sep, sep_size);
-    // Index of a decimal digit with the least significant digit having index 0.
-    int digit_index = 0;
-    group = groups.cbegin();
-    auto p = buffer.data() + size - 1;
-    for (int i = num_digits - 1; i > 0; --i) {
-      *p-- = static_cast<Char>(digits[i]);
-      if (*group <= 0 || ++digit_index % *group != 0 ||
-          *group == max_value<char>())
-        continue;
-      if (group + 1 != groups.cend()) {
-        digit_index = 0;
-        ++group;
-      }
-      std::uninitialized_copy(s.data(), s.data() + s.size(),
-                              make_checked(p, s.size()));
-      p -= s.size();
-    }
-    *p-- = static_cast<Char>(*digits);
-    if (prefix_size != 0) *p = static_cast<Char>('-');
-    auto data = buffer.data();
-    out = write_padded<align::right>(
-        out, specs, usize, usize,
-        [=](iterator it) { return copy_str<Char>(data, data + size, it); });
+    // Octal prefix '0' is counted as a digit, so only add it if precision
+    // is not greater than the number of digits.
+    if (specs.alt && specs.precision <= num_digits && abs_value != 0)
+      prefix_append(prefix, '0');
+    return write_int(out, num_digits, prefix, specs,
+                     [=](reserve_iterator<OutputIt> it) {
+                       return format_uint<3, Char>(it, abs_value, num_digits);
+                     });
   }
-
-  void on_chr() { *out++ = static_cast<Char>(abs_value); }
-
-  FMT_NORETURN void on_error() {
-    FMT_THROW(format_error("invalid type specifier"));
+  case presentation_type::chr:
+    return write_char(out, static_cast<Char>(abs_value), specs);
+  default:
+    throw_format_error("invalid type specifier");
   }
-};
+  return out;
+}
+template <typename Char, typename OutputIt, typename T>
+FMT_CONSTEXPR FMT_NOINLINE auto write_int_noinline(
+    OutputIt out, write_int_arg<T> arg, const basic_format_specs<Char>& specs,
+    locale_ref loc) -> OutputIt {
+  return write_int(out, arg, specs, loc);
+}
+template <typename Char, typename OutputIt, typename T,
+          FMT_ENABLE_IF(is_integral<T>::value &&
+                        !std::is_same<T, bool>::value &&
+                        std::is_same<OutputIt, buffer_appender<Char>>::value)>
+FMT_CONSTEXPR FMT_INLINE auto write(OutputIt out, T value,
+                                    const basic_format_specs<Char>& specs,
+                                    locale_ref loc) -> OutputIt {
+  return write_int_noinline(out, make_write_int_arg(value, specs.sign), specs,
+                            loc);
+}
+// An inlined version of write used in format string compilation.
+template <typename Char, typename OutputIt, typename T,
+          FMT_ENABLE_IF(is_integral<T>::value &&
+                        !std::is_same<T, bool>::value &&
+                        !std::is_same<OutputIt, buffer_appender<Char>>::value)>
+FMT_CONSTEXPR FMT_INLINE auto write(OutputIt out, T value,
+                                    const basic_format_specs<Char>& specs,
+                                    locale_ref loc) -> OutputIt {
+  return write_int(out, make_write_int_arg(value, specs.sign), specs, loc);
+}
 
 template <typename Char, typename OutputIt>
-OutputIt write_nonfinite(OutputIt out, bool isinf,
-                         const basic_format_specs<Char>& specs,
-                         const float_specs& fspecs) {
+FMT_CONSTEXPR auto write(OutputIt out, basic_string_view<Char> s,
+                         const basic_format_specs<Char>& specs) -> OutputIt {
+  auto data = s.data();
+  auto size = s.size();
+  if (specs.precision >= 0 && to_unsigned(specs.precision) < size)
+    size = code_point_index(s, to_unsigned(specs.precision));
+  auto width =
+      specs.width != 0 ? compute_width(basic_string_view<Char>(data, size)) : 0;
+  return write_padded(out, specs, size, width,
+                      [=](reserve_iterator<OutputIt> it) {
+                        return copy_str<Char>(data, data + size, it);
+                      });
+}
+template <typename Char, typename OutputIt>
+FMT_CONSTEXPR auto write(OutputIt out,
+                         basic_string_view<type_identity_t<Char>> s,
+                         const basic_format_specs<Char>& specs, locale_ref)
+    -> OutputIt {
+  check_string_type_spec(specs.type);
+  return write(out, s, specs);
+}
+template <typename Char, typename OutputIt>
+FMT_CONSTEXPR auto write(OutputIt out, const Char* s,
+                         const basic_format_specs<Char>& specs, locale_ref)
+    -> OutputIt {
+  return check_cstring_type_spec(specs.type)
+             ? write(out, basic_string_view<Char>(s), specs, {})
+             : write_ptr<Char>(out, to_uintptr(s), &specs);
+}
+
+template <typename Char, typename OutputIt>
+FMT_CONSTEXPR20 auto write_nonfinite(OutputIt out, bool isinf,
+                                     basic_format_specs<Char> specs,
+                                     const float_specs& fspecs) -> OutputIt {
   auto str =
       isinf ? (fspecs.upper ? "INF" : "inf") : (fspecs.upper ? "NAN" : "nan");
   constexpr size_t str_size = 3;
   auto sign = fspecs.sign;
   auto size = str_size + (sign ? 1 : 0);
-  using iterator = remove_reference_t<decltype(reserve(out, 0))>;
-  return write_padded(out, specs, size, [=](iterator it) {
-    if (sign) *it++ = static_cast<Char>(data::signs[sign]);
+  // Replace '0'-padding with space for non-finite values.
+  const bool is_zero_fill =
+      specs.fill.size() == 1 && *specs.fill.data() == static_cast<Char>('0');
+  if (is_zero_fill) specs.fill[0] = static_cast<Char>(' ');
+  return write_padded(out, specs, size, [=](reserve_iterator<OutputIt> it) {
+    if (sign) *it++ = detail::sign<Char>(sign);
     return copy_str<Char>(str, str + str_size, it);
   });
 }
 
 // A decimal floating-point number significand * pow(10, exp).
 struct big_decimal_fp {
   const char* significand;
   int significand_size;
   int exponent;
 };
 
-inline int get_significand_size(const big_decimal_fp& fp) {
+constexpr auto get_significand_size(const big_decimal_fp& fp) -> int {
   return fp.significand_size;
 }
 template <typename T>
-inline int get_significand_size(const dragonbox::decimal_fp<T>& fp) {
+inline auto get_significand_size(const dragonbox::decimal_fp<T>& fp) -> int {
   return count_digits(fp.significand);
 }
 
 template <typename Char, typename OutputIt>
-inline OutputIt write_significand(OutputIt out, const char* significand,
-                                  int& significand_size) {
+constexpr auto write_significand(OutputIt out, const char* significand,
+                                 int significand_size) -> OutputIt {
   return copy_str<Char>(significand, significand + significand_size, out);
 }
 template <typename Char, typename OutputIt, typename UInt>
-inline OutputIt write_significand(OutputIt out, UInt significand,
-                                  int significand_size) {
+inline auto write_significand(OutputIt out, UInt significand,
+                              int significand_size) -> OutputIt {
   return format_decimal<Char>(out, significand, significand_size).end;
 }
+template <typename Char, typename OutputIt, typename T, typename Grouping>
+FMT_CONSTEXPR20 auto write_significand(OutputIt out, T significand,
+                                       int significand_size, int exponent,
+                                       const Grouping& grouping) -> OutputIt {
+  if (!grouping.separator()) {
+    out = write_significand<Char>(out, significand, significand_size);
+    return detail::fill_n(out, exponent, static_cast<Char>('0'));
+  }
+  auto buffer = memory_buffer();
+  write_significand<char>(appender(buffer), significand, significand_size);
+  detail::fill_n(appender(buffer), exponent, '0');
+  return grouping.apply(out, string_view(buffer.data(), buffer.size()));
+}
 
 template <typename Char, typename UInt,
           FMT_ENABLE_IF(std::is_integral<UInt>::value)>
-inline Char* write_significand(Char* out, UInt significand,
-                               int significand_size, int integral_size,
-                               Char decimal_point) {
+inline auto write_significand(Char* out, UInt significand, int significand_size,
+                              int integral_size, Char decimal_point) -> Char* {
   if (!decimal_point)
     return format_decimal(out, significand, significand_size).end;
-  auto end = format_decimal(out + 1, significand, significand_size).end;
-  if (integral_size == 1)
-    out[0] = out[1];
-  else
-    std::copy_n(out + 1, integral_size, out);
-  out[integral_size] = decimal_point;
+  out += significand_size + 1;
+  Char* end = out;
+  int floating_size = significand_size - integral_size;
+  for (int i = floating_size / 2; i > 0; --i) {
+    out -= 2;
+    copy2(out, digits2(significand % 100));
+    significand /= 100;
+  }
+  if (floating_size % 2 != 0) {
+    *--out = static_cast<Char>('0' + significand % 10);
+    significand /= 10;
+  }
+  *--out = decimal_point;
+  format_decimal(out - integral_size, significand, integral_size);
   return end;
 }
 
 template <typename OutputIt, typename UInt, typename Char,
           FMT_ENABLE_IF(!std::is_pointer<remove_cvref_t<OutputIt>>::value)>
-inline OutputIt write_significand(OutputIt out, UInt significand,
-                                  int significand_size, int integral_size,
-                                  Char decimal_point) {
+inline auto write_significand(OutputIt out, UInt significand,
+                              int significand_size, int integral_size,
+                              Char decimal_point) -> OutputIt {
   // Buffer is large enough to hold digits (digits10 + 1) and a decimal point.
   Char buffer[digits10<UInt>() + 2];
   auto end = write_significand(buffer, significand, significand_size,
                                integral_size, decimal_point);
-  return detail::copy_str<Char>(buffer, end, out);
+  return detail::copy_str_noinline<Char>(buffer, end, out);
 }
 
 template <typename OutputIt, typename Char>
-inline OutputIt write_significand(OutputIt out, const char* significand,
-                                  int significand_size, int integral_size,
-                                  Char decimal_point) {
-  out = detail::copy_str<Char>(significand, significand + integral_size, out);
+FMT_CONSTEXPR auto write_significand(OutputIt out, const char* significand,
+                                     int significand_size, int integral_size,
+                                     Char decimal_point) -> OutputIt {
+  out = detail::copy_str_noinline<Char>(significand,
+                                        significand + integral_size, out);
   if (!decimal_point) return out;
   *out++ = decimal_point;
-  return detail::copy_str<Char>(significand + integral_size,
-                                significand + significand_size, out);
+  return detail::copy_str_noinline<Char>(significand + integral_size,
+                                         significand + significand_size, out);
 }
 
-template <typename OutputIt, typename DecimalFP, typename Char>
-OutputIt write_float(OutputIt out, const DecimalFP& fp,
-                     const basic_format_specs<Char>& specs, float_specs fspecs,
-                     Char decimal_point) {
+template <typename OutputIt, typename Char, typename T, typename Grouping>
+FMT_CONSTEXPR20 auto write_significand(OutputIt out, T significand,
+                                       int significand_size, int integral_size,
+                                       Char decimal_point,
+                                       const Grouping& grouping) -> OutputIt {
+  if (!grouping.separator()) {
+    return write_significand(out, significand, significand_size, integral_size,
+                             decimal_point);
+  }
+  auto buffer = basic_memory_buffer<Char>();
+  write_significand(buffer_appender<Char>(buffer), significand,
+                    significand_size, integral_size, decimal_point);
+  grouping.apply(
+      out, basic_string_view<Char>(buffer.data(), to_unsigned(integral_size)));
+  return detail::copy_str_noinline<Char>(buffer.data() + integral_size,
+                                         buffer.end(), out);
+}
+
+template <typename OutputIt, typename DecimalFP, typename Char,
+          typename Grouping = digit_grouping<Char>>
+FMT_CONSTEXPR20 auto do_write_float(OutputIt out, const DecimalFP& fp,
+                                    const basic_format_specs<Char>& specs,
+                                    float_specs fspecs, locale_ref loc)
+    -> OutputIt {
   auto significand = fp.significand;
   int significand_size = get_significand_size(fp);
-  static const Char zero = static_cast<Char>('0');
+  constexpr Char zero = static_cast<Char>('0');
   auto sign = fspecs.sign;
   size_t size = to_unsigned(significand_size) + (sign ? 1 : 0);
-  using iterator = remove_reference_t<decltype(reserve(out, 0))>;
+  using iterator = reserve_iterator<OutputIt>;
+
+  Char decimal_point =
+      fspecs.locale ? detail::decimal_point<Char>(loc) : static_cast<Char>('.');
 
   int output_exp = fp.exponent + significand_size - 1;
   auto use_exp_format = [=]() {
     if (fspecs.format == float_format::exp) return true;
     if (fspecs.format != float_format::general) return false;
     // Use the fixed notation if the exponent is in [exp_lower, exp_upper),
     // e.g. 0.0001 instead of 1e-04. Otherwise use the exponent notation.
     const int exp_lower = -4, exp_upper = 16;
     return output_exp < exp_lower ||
            output_exp >= (fspecs.precision > 0 ? fspecs.precision : exp_upper);
   };
   if (use_exp_format()) {
     int num_zeros = 0;
     if (fspecs.showpoint) {
-      num_zeros = (std::max)(fspecs.precision - significand_size, 0);
+      num_zeros = fspecs.precision - significand_size;
+      if (num_zeros < 0) num_zeros = 0;
       size += to_unsigned(num_zeros);
     } else if (significand_size == 1) {
       decimal_point = Char();
     }
     auto abs_output_exp = output_exp >= 0 ? output_exp : -output_exp;
     int exp_digits = 2;
     if (abs_output_exp >= 100) exp_digits = abs_output_exp >= 1000 ? 4 : 3;
 
     size += to_unsigned((decimal_point ? 1 : 0) + 2 + exp_digits);
     char exp_char = fspecs.upper ? 'E' : 'e';
     auto write = [=](iterator it) {
-      if (sign) *it++ = static_cast<Char>(data::signs[sign]);
+      if (sign) *it++ = detail::sign<Char>(sign);
       // Insert a decimal point after the first digit and add an exponent.
       it = write_significand(it, significand, significand_size, 1,
                              decimal_point);
-      if (num_zeros > 0) it = std::fill_n(it, num_zeros, zero);
+      if (num_zeros > 0) it = detail::fill_n(it, num_zeros, zero);
       *it++ = static_cast<Char>(exp_char);
       return write_exponent<Char>(output_exp, it);
     };
     return specs.width > 0 ? write_padded<align::right>(out, specs, size, write)
                            : base_iterator(out, write(reserve(out, size)));
   }
 
@@ -1859,194 +1862,238 @@
     int num_zeros = fspecs.precision - exp;
 #ifdef FMT_FUZZ
     if (num_zeros > 5000)
       throw std::runtime_error("fuzz mode - avoiding excessive cpu use");
 #endif
     if (fspecs.showpoint) {
       if (num_zeros <= 0 && fspecs.format != float_format::fixed) num_zeros = 1;
-      if (num_zeros > 0) size += to_unsigned(num_zeros);
+      if (num_zeros > 0) size += to_unsigned(num_zeros) + 1;
     }
+    auto grouping = Grouping(loc, fspecs.locale);
+    size += to_unsigned(grouping.count_separators(significand_size));
     return write_padded<align::right>(out, specs, size, [&](iterator it) {
-      if (sign) *it++ = static_cast<Char>(data::signs[sign]);
-      it = write_significand<Char>(it, significand, significand_size);
-      it = std::fill_n(it, fp.exponent, zero);
+      if (sign) *it++ = detail::sign<Char>(sign);
+      it = write_significand<Char>(it, significand, significand_size,
+                                   fp.exponent, grouping);
       if (!fspecs.showpoint) return it;
       *it++ = decimal_point;
-      return num_zeros > 0 ? std::fill_n(it, num_zeros, zero) : it;
+      return num_zeros > 0 ? detail::fill_n(it, num_zeros, zero) : it;
     });
   } else if (exp > 0) {
     // 1234e-2 -> 12.34[0+]
     int num_zeros = fspecs.showpoint ? fspecs.precision - significand_size : 0;
     size += 1 + to_unsigned(num_zeros > 0 ? num_zeros : 0);
+    auto grouping = Grouping(loc, fspecs.locale);
+    size += to_unsigned(grouping.count_separators(significand_size));
     return write_padded<align::right>(out, specs, size, [&](iterator it) {
-      if (sign) *it++ = static_cast<Char>(data::signs[sign]);
+      if (sign) *it++ = detail::sign<Char>(sign);
       it = write_significand(it, significand, significand_size, exp,
-                             decimal_point);
-      return num_zeros > 0 ? std::fill_n(it, num_zeros, zero) : it;
+                             decimal_point, grouping);
+      return num_zeros > 0 ? detail::fill_n(it, num_zeros, zero) : it;
     });
   }
   // 1234e-6 -> 0.001234
   int num_zeros = -exp;
   if (significand_size == 0 && fspecs.precision >= 0 &&
       fspecs.precision < num_zeros) {
     num_zeros = fspecs.precision;
   }
-  size += 2 + to_unsigned(num_zeros);
+  bool pointy = num_zeros != 0 || significand_size != 0 || fspecs.showpoint;
+  size += 1 + (pointy ? 1 : 0) + to_unsigned(num_zeros);
   return write_padded<align::right>(out, specs, size, [&](iterator it) {
-    if (sign) *it++ = static_cast<Char>(data::signs[sign]);
+    if (sign) *it++ = detail::sign<Char>(sign);
     *it++ = zero;
-    if (num_zeros == 0 && significand_size == 0 && !fspecs.showpoint) return it;
+    if (!pointy) return it;
     *it++ = decimal_point;
-    it = std::fill_n(it, num_zeros, zero);
+    it = detail::fill_n(it, num_zeros, zero);
     return write_significand<Char>(it, significand, significand_size);
   });
 }
 
+template <typename Char> class fallback_digit_grouping {
+ public:
+  constexpr fallback_digit_grouping(locale_ref, bool) {}
+
+  constexpr Char separator() const { return Char(); }
+
+  constexpr int count_separators(int) const { return 0; }
+
+  template <typename Out, typename C>
+  constexpr Out apply(Out out, basic_string_view<C>) const {
+    return out;
+  }
+};
+
+template <typename OutputIt, typename DecimalFP, typename Char>
+FMT_CONSTEXPR20 auto write_float(OutputIt out, const DecimalFP& fp,
+                                 const basic_format_specs<Char>& specs,
+                                 float_specs fspecs, locale_ref loc)
+    -> OutputIt {
+  if (is_constant_evaluated()) {
+    return do_write_float<OutputIt, DecimalFP, Char,
+                          fallback_digit_grouping<Char>>(out, fp, specs, fspecs,
+                                                         loc);
+  } else {
+    return do_write_float(out, fp, specs, fspecs, loc);
+  }
+}
+
+template <typename T, FMT_ENABLE_IF(std::is_floating_point<T>::value)>
+FMT_CONSTEXPR20 bool isinf(T value) {
+  if (is_constant_evaluated()) {
+#if defined(__cpp_if_constexpr)
+    if constexpr (std::numeric_limits<double>::is_iec559) {
+      auto bits = detail::bit_cast<uint64_t>(static_cast<double>(value));
+      constexpr auto significand_bits =
+          dragonbox::float_info<double>::significand_bits;
+      return (bits & exponent_mask<double>()) &&
+             !(bits & ((uint64_t(1) << significand_bits) - 1));
+    }
+#endif
+  }
+  return std::isinf(value);
+}
+
+template <typename T, FMT_ENABLE_IF(std::is_floating_point<T>::value)>
+FMT_CONSTEXPR20 bool isfinite(T value) {
+  if (is_constant_evaluated()) {
+#if defined(__cpp_if_constexpr)
+    if constexpr (std::numeric_limits<double>::is_iec559) {
+      auto bits = detail::bit_cast<uint64_t>(static_cast<double>(value));
+      return (bits & exponent_mask<double>()) != exponent_mask<double>();
+    }
+#endif
+  }
+  return std::isfinite(value);
+}
+
+template <typename T, FMT_ENABLE_IF(std::is_floating_point<T>::value)>
+FMT_INLINE FMT_CONSTEXPR bool signbit(T value) {
+  if (is_constant_evaluated()) {
+#ifdef __cpp_if_constexpr
+    if constexpr (std::numeric_limits<double>::is_iec559) {
+      auto bits = detail::bit_cast<uint64_t>(static_cast<double>(value));
+      return (bits & (uint64_t(1) << (num_bits<uint64_t>() - 1))) != 0;
+    }
+#endif
+  }
+  return std::signbit(value);
+}
+
 template <typename Char, typename OutputIt, typename T,
           FMT_ENABLE_IF(std::is_floating_point<T>::value)>
-OutputIt write(OutputIt out, T value, basic_format_specs<Char> specs,
-               locale_ref loc = {}) {
+FMT_CONSTEXPR20 auto write(OutputIt out, T value,
+                           basic_format_specs<Char> specs, locale_ref loc = {})
+    -> OutputIt {
   if (const_check(!is_supported_floating_point(value))) return out;
   float_specs fspecs = parse_float_type_spec(specs);
   fspecs.sign = specs.sign;
-  if (std::signbit(value)) {  // value < 0 is false for NaN so use signbit.
+  if (detail::signbit(value)) {  // value < 0 is false for NaN so use signbit.
     fspecs.sign = sign::minus;
     value = -value;
   } else if (fspecs.sign == sign::minus) {
     fspecs.sign = sign::none;
   }
 
-  if (!std::isfinite(value))
-    return write_nonfinite(out, std::isinf(value), specs, fspecs);
+  if (!detail::isfinite(value))
+    return write_nonfinite(out, detail::isinf(value), specs, fspecs);
 
   if (specs.align == align::numeric && fspecs.sign) {
     auto it = reserve(out, 1);
-    *it++ = static_cast<Char>(data::signs[fspecs.sign]);
+    *it++ = detail::sign<Char>(fspecs.sign);
     out = base_iterator(out, it);
     fspecs.sign = sign::none;
     if (specs.width != 0) --specs.width;
   }
 
   memory_buffer buffer;
   if (fspecs.format == float_format::hex) {
-    if (fspecs.sign) buffer.push_back(data::signs[fspecs.sign]);
+    if (fspecs.sign) buffer.push_back(detail::sign<char>(fspecs.sign));
     snprintf_float(promote_float(value), specs.precision, fspecs, buffer);
-    return write_bytes(out, {buffer.data(), buffer.size()}, specs);
+    return write_bytes<align::right>(out, {buffer.data(), buffer.size()},
+                                     specs);
   }
-  int precision = specs.precision >= 0 || !specs.type ? specs.precision : 6;
+  int precision = specs.precision >= 0 || specs.type == presentation_type::none
+                      ? specs.precision
+                      : 6;
   if (fspecs.format == float_format::exp) {
     if (precision == max_value<int>())
-      FMT_THROW(format_error("number is too big"));
+      throw_format_error("number is too big");
     else
       ++precision;
   }
   if (const_check(std::is_same<T, float>())) fspecs.binary32 = true;
-  fspecs.use_grisu = is_fast_float<T>();
+  if (!is_fast_float<T>()) fspecs.fallback = true;
   int exp = format_float(promote_float(value), precision, fspecs, buffer);
   fspecs.precision = precision;
-  Char point =
-      fspecs.locale ? decimal_point<Char>(loc) : static_cast<Char>('.');
   auto fp = big_decimal_fp{buffer.data(), static_cast<int>(buffer.size()), exp};
-  return write_float(out, fp, specs, fspecs, point);
+  return write_float(out, fp, specs, fspecs, loc);
 }
 
 template <typename Char, typename OutputIt, typename T,
           FMT_ENABLE_IF(is_fast_float<T>::value)>
-OutputIt write(OutputIt out, T value) {
+FMT_CONSTEXPR20 auto write(OutputIt out, T value) -> OutputIt {
+  if (is_constant_evaluated()) {
+    return write(out, value, basic_format_specs<Char>());
+  }
+
   if (const_check(!is_supported_floating_point(value))) return out;
 
   using floaty = conditional_t<std::is_same<T, long double>::value, double, T>;
   using uint = typename dragonbox::float_info<floaty>::carrier_uint;
   auto bits = bit_cast<uint>(value);
 
   auto fspecs = float_specs();
-  auto sign_bit = bits & (uint(1) << (num_bits<uint>() - 1));
-  if (sign_bit != 0) {
+  if (detail::signbit(value)) {
     fspecs.sign = sign::minus;
     value = -value;
   }
 
-  static const auto specs = basic_format_specs<Char>();
+  constexpr auto specs = basic_format_specs<Char>();
   uint mask = exponent_mask<floaty>();
   if ((bits & mask) == mask)
     return write_nonfinite(out, std::isinf(value), specs, fspecs);
 
   auto dec = dragonbox::to_decimal(static_cast<floaty>(value));
-  return write_float(out, dec, specs, fspecs, static_cast<Char>('.'));
+  return write_float(out, dec, specs, fspecs, {});
 }
 
 template <typename Char, typename OutputIt, typename T,
           FMT_ENABLE_IF(std::is_floating_point<T>::value &&
                         !is_fast_float<T>::value)>
-inline OutputIt write(OutputIt out, T value) {
+inline auto write(OutputIt out, T value) -> OutputIt {
   return write(out, value, basic_format_specs<Char>());
 }
 
 template <typename Char, typename OutputIt>
-OutputIt write_char(OutputIt out, Char value,
-                    const basic_format_specs<Char>& specs) {
-  using iterator = remove_reference_t<decltype(reserve(out, 0))>;
-  return write_padded(out, specs, 1, [=](iterator it) {
-    *it++ = value;
-    return it;
-  });
-}
-
-template <typename Char, typename OutputIt, typename UIntPtr>
-OutputIt write_ptr(OutputIt out, UIntPtr value,
-                   const basic_format_specs<Char>* specs) {
-  int num_digits = count_digits<4>(value);
-  auto size = to_unsigned(num_digits) + size_t(2);
-  using iterator = remove_reference_t<decltype(reserve(out, 0))>;
-  auto write = [=](iterator it) {
-    *it++ = static_cast<Char>('0');
-    *it++ = static_cast<Char>('x');
-    return format_uint<4, Char>(it, value, num_digits);
-  };
-  return specs ? write_padded<align::right>(out, *specs, size, write)
-               : base_iterator(out, write(reserve(out, size)));
-}
-
-template <typename T> struct is_integral : std::is_integral<T> {};
-template <> struct is_integral<int128_t> : std::true_type {};
-template <> struct is_integral<uint128_t> : std::true_type {};
-
-template <typename Char, typename OutputIt>
-OutputIt write(OutputIt out, monostate) {
+auto write(OutputIt out, monostate, basic_format_specs<Char> = {},
+           locale_ref = {}) -> OutputIt {
   FMT_ASSERT(false, "");
   return out;
 }
 
-template <typename Char, typename OutputIt,
-          FMT_ENABLE_IF(!std::is_same<Char, char>::value)>
-OutputIt write(OutputIt out, string_view value) {
-  auto it = reserve(out, value.size());
-  it = copy_str<Char>(value.begin(), value.end(), it);
-  return base_iterator(out, it);
-}
-
 template <typename Char, typename OutputIt>
-OutputIt write(OutputIt out, basic_string_view<Char> value) {
+FMT_CONSTEXPR auto write(OutputIt out, basic_string_view<Char> value)
+    -> OutputIt {
   auto it = reserve(out, value.size());
-  it = std::copy(value.begin(), value.end(), it);
+  it = copy_str_noinline<Char>(value.begin(), value.end(), it);
   return base_iterator(out, it);
 }
 
-template <typename Char>
-buffer_appender<Char> write(buffer_appender<Char> out,
-                            basic_string_view<Char> value) {
-  get_container(out).append(value.begin(), value.end());
-  return out;
+template <typename Char, typename OutputIt, typename T,
+          FMT_ENABLE_IF(is_string<T>::value)>
+constexpr auto write(OutputIt out, const T& value) -> OutputIt {
+  return write<Char>(out, to_string_view(value));
 }
 
 template <typename Char, typename OutputIt, typename T,
           FMT_ENABLE_IF(is_integral<T>::value &&
                         !std::is_same<T, bool>::value &&
                         !std::is_same<T, Char>::value)>
-OutputIt write(OutputIt out, T value) {
+FMT_CONSTEXPR auto write(OutputIt out, T value) -> OutputIt {
   auto abs_value = static_cast<uint32_or_64_or_128_t<T>>(value);
   bool negative = is_negative(value);
   // Don't do -abs_value since it trips unsigned-integer-overflow sanitizer.
   if (negative) abs_value = ~abs_value + 1;
   int num_digits = count_digits(abs_value);
   auto size = (negative ? 1 : 0) + static_cast<size_t>(num_digits);
   auto it = reserve(out, size);
@@ -2056,1307 +2103,419 @@
     return out;
   }
   if (negative) *it++ = static_cast<Char>('-');
   it = format_decimal<Char>(it, abs_value, num_digits).end;
   return base_iterator(out, it);
 }
 
-template <typename Char, typename OutputIt>
-OutputIt write(OutputIt out, bool value) {
-  return write<Char>(out, string_view(value ? "true" : "false"));
+// FMT_ENABLE_IF() condition separated to workaround an MSVC bug.
+template <
+    typename Char, typename OutputIt, typename T,
+    bool check =
+        std::is_enum<T>::value && !std::is_same<T, Char>::value &&
+        mapped_type_constant<T, basic_format_context<OutputIt, Char>>::value !=
+            type::custom_type,
+    FMT_ENABLE_IF(check)>
+FMT_CONSTEXPR auto write(OutputIt out, T value) -> OutputIt {
+  return write<Char>(
+      out, static_cast<typename std::underlying_type<T>::type>(value));
+}
+
+template <typename Char, typename OutputIt, typename T,
+          FMT_ENABLE_IF(std::is_same<T, bool>::value)>
+FMT_CONSTEXPR auto write(OutputIt out, T value,
+                         const basic_format_specs<Char>& specs = {},
+                         locale_ref = {}) -> OutputIt {
+  return specs.type != presentation_type::none &&
+                 specs.type != presentation_type::string
+             ? write(out, value ? 1 : 0, specs, {})
+             : write_bytes(out, value ? "true" : "false", specs);
 }
 
 template <typename Char, typename OutputIt>
-OutputIt write(OutputIt out, Char value) {
+FMT_CONSTEXPR auto write(OutputIt out, Char value) -> OutputIt {
   auto it = reserve(out, 1);
   *it++ = value;
   return base_iterator(out, it);
 }
 
 template <typename Char, typename OutputIt>
-OutputIt write(OutputIt out, const Char* value) {
+FMT_CONSTEXPR_CHAR_TRAITS auto write(OutputIt out, const Char* value)
+    -> OutputIt {
   if (!value) {
-    FMT_THROW(format_error("string pointer is null"));
+    throw_format_error("string pointer is null");
   } else {
-    auto length = std::char_traits<Char>::length(value);
-    out = write(out, basic_string_view<Char>(value, length));
+    out = write(out, basic_string_view<Char>(value));
   }
   return out;
 }
 
-template <typename Char, typename OutputIt>
-OutputIt write(OutputIt out, const void* value) {
-  return write_ptr<Char>(out, to_uintptr(value), nullptr);
+template <typename Char, typename OutputIt, typename T,
+          FMT_ENABLE_IF(std::is_same<T, void>::value)>
+auto write(OutputIt out, const T* value,
+           const basic_format_specs<Char>& specs = {}, locale_ref = {})
+    -> OutputIt {
+  check_pointer_type_spec(specs.type, error_handler());
+  return write_ptr<Char>(out, to_uintptr(value), &specs);
 }
 
-template <typename Char, typename OutputIt, typename T>
-auto write(OutputIt out, const T& value) -> typename std::enable_if<
-    mapped_type_constant<T, basic_format_context<OutputIt, Char>>::value ==
-        type::custom_type,
-    OutputIt>::type {
-  using context_type = basic_format_context<OutputIt, Char>;
+// A write overload that handles implicit conversions.
+template <typename Char, typename OutputIt, typename T,
+          typename Context = basic_format_context<OutputIt, Char>>
+FMT_CONSTEXPR auto write(OutputIt out, const T& value) -> enable_if_t<
+    std::is_class<T>::value && !is_string<T>::value &&
+        !std::is_same<T, Char>::value &&
+        !std::is_same<const T&,
+                      decltype(arg_mapper<Context>().map(value))>::value,
+    OutputIt> {
+  return write<Char>(out, arg_mapper<Context>().map(value));
+}
+
+template <typename Char, typename OutputIt, typename T,
+          typename Context = basic_format_context<OutputIt, Char>>
+FMT_CONSTEXPR auto write(OutputIt out, const T& value)
+    -> enable_if_t<mapped_type_constant<T, Context>::value == type::custom_type,
+                   OutputIt> {
   using formatter_type =
-      conditional_t<has_formatter<T, context_type>::value,
-                    typename context_type::template formatter_type<T>,
+      conditional_t<has_formatter<T, Context>::value,
+                    typename Context::template formatter_type<T>,
                     fallback_formatter<T, Char>>;
-  context_type ctx(out, {}, {});
+  auto ctx = Context(out, {}, {});
   return formatter_type().format(value, ctx);
 }
 
 // An argument visitor that formats the argument and writes it via the output
 // iterator. It's a class and not a generic lambda for compatibility with C++11.
-template <typename OutputIt, typename Char> struct default_arg_formatter {
-  using context = basic_format_context<OutputIt, Char>;
+template <typename Char> struct default_arg_formatter {
+  using iterator = buffer_appender<Char>;
+  using context = buffer_context<Char>;
 
-  OutputIt out;
+  iterator out;
   basic_format_args<context> args;
   locale_ref loc;
 
-  template <typename T> OutputIt operator()(T value) {
+  template <typename T> auto operator()(T value) -> iterator {
     return write<Char>(out, value);
   }
-
-  OutputIt operator()(typename basic_format_arg<context>::handle handle) {
+  auto operator()(typename basic_format_arg<context>::handle h) -> iterator {
     basic_format_parse_context<Char> parse_ctx({});
-    basic_format_context<OutputIt, Char> format_ctx(out, args, loc);
-    handle.format(parse_ctx, format_ctx);
+    context format_ctx(out, args, loc);
+    h.format(parse_ctx, format_ctx);
     return format_ctx.out();
   }
 };
 
-template <typename OutputIt, typename Char,
-          typename ErrorHandler = error_handler>
-class arg_formatter_base {
- public:
-  using iterator = OutputIt;
-  using char_type = Char;
-  using format_specs = basic_format_specs<Char>;
-
- private:
-  iterator out_;
-  locale_ref locale_;
-  format_specs* specs_;
-
-  // Attempts to reserve space for n extra characters in the output range.
-  // Returns a pointer to the reserved range or a reference to out_.
-  auto reserve(size_t n) -> decltype(detail::reserve(out_, n)) {
-    return detail::reserve(out_, n);
-  }
-
-  using reserve_iterator = remove_reference_t<decltype(
-      detail::reserve(std::declval<iterator&>(), 0))>;
+template <typename Char> struct arg_formatter {
+  using iterator = buffer_appender<Char>;
+  using context = buffer_context<Char>;
 
-  template <typename T> void write_int(T value, const format_specs& spec) {
-    using uint_type = uint32_or_64_or_128_t<T>;
-    int_writer<iterator, Char, uint_type> w(out_, locale_, value, spec);
-    handle_int_type_spec(spec.type, w);
-    out_ = w.out;
-  }
-
-  void write(char value) {
-    auto&& it = reserve(1);
-    *it++ = value;
-  }
-
-  template <typename Ch, FMT_ENABLE_IF(std::is_same<Ch, Char>::value)>
-  void write(Ch value) {
-    out_ = detail::write<Char>(out_, value);
-  }
-
-  void write(string_view value) {
-    auto&& it = reserve(value.size());
-    it = copy_str<Char>(value.begin(), value.end(), it);
-  }
-  void write(wstring_view value) {
-    static_assert(std::is_same<Char, wchar_t>::value, "");
-    auto&& it = reserve(value.size());
-    it = std::copy(value.begin(), value.end(), it);
-  }
-
-  template <typename Ch>
-  void write(const Ch* s, size_t size, const format_specs& specs) {
-    auto width = specs.width != 0
-                     ? count_code_points(basic_string_view<Ch>(s, size))
-                     : 0;
-    out_ = write_padded(out_, specs, size, width, [=](reserve_iterator it) {
-      return copy_str<Char>(s, s + size, it);
-    });
-  }
-
-  template <typename Ch>
-  void write(basic_string_view<Ch> s, const format_specs& specs = {}) {
-    out_ = detail::write(out_, s, specs);
-  }
-
-  void write_pointer(const void* p) {
-    out_ = write_ptr<char_type>(out_, to_uintptr(p), specs_);
-  }
-
-  struct char_spec_handler : ErrorHandler {
-    arg_formatter_base& formatter;
-    Char value;
-
-    char_spec_handler(arg_formatter_base& f, Char val)
-        : formatter(f), value(val) {}
-
-    void on_int() {
-      // char is only formatted as int if there are specs.
-      formatter.write_int(static_cast<int>(value), *formatter.specs_);
-    }
-    void on_char() {
-      if (formatter.specs_)
-        formatter.out_ = write_char(formatter.out_, value, *formatter.specs_);
-      else
-        formatter.write(value);
-    }
-  };
-
-  struct cstring_spec_handler : error_handler {
-    arg_formatter_base& formatter;
-    const Char* value;
-
-    cstring_spec_handler(arg_formatter_base& f, const Char* val)
-        : formatter(f), value(val) {}
-
-    void on_string() { formatter.write(value); }
-    void on_pointer() { formatter.write_pointer(value); }
-  };
-
- protected:
-  iterator out() { return out_; }
-  format_specs* specs() { return specs_; }
-
-  void write(bool value) {
-    if (specs_)
-      write(string_view(value ? "true" : "false"), *specs_);
-    else
-      out_ = detail::write<Char>(out_, value);
-  }
-
-  void write(const Char* value) {
-    if (!value) {
-      FMT_THROW(format_error("string pointer is null"));
-    } else {
-      auto length = std::char_traits<char_type>::length(value);
-      basic_string_view<char_type> sv(value, length);
-      specs_ ? write(sv, *specs_) : write(sv);
-    }
-  }
-
- public:
-  arg_formatter_base(OutputIt out, format_specs* s, locale_ref loc)
-      : out_(out), locale_(loc), specs_(s) {}
-
-  iterator operator()(monostate) {
-    FMT_ASSERT(false, "invalid argument type");
-    return out_;
-  }
-
-  template <typename T, FMT_ENABLE_IF(is_integral<T>::value)>
-  FMT_INLINE iterator operator()(T value) {
-    if (specs_)
-      write_int(value, *specs_);
-    else
-      out_ = detail::write<Char>(out_, value);
-    return out_;
-  }
-
-  iterator operator()(Char value) {
-    handle_char_specs(specs_,
-                      char_spec_handler(*this, static_cast<Char>(value)));
-    return out_;
-  }
-
-  iterator operator()(bool value) {
-    if (specs_ && specs_->type) return (*this)(value ? 1 : 0);
-    write(value != 0);
-    return out_;
-  }
-
-  template <typename T, FMT_ENABLE_IF(std::is_floating_point<T>::value)>
-  iterator operator()(T value) {
-    auto specs = specs_ ? *specs_ : format_specs();
-    if (const_check(is_supported_floating_point(value)))
-      out_ = detail::write(out_, value, specs, locale_);
-    else
-      FMT_ASSERT(false, "unsupported float argument type");
-    return out_;
-  }
-
-  iterator operator()(const Char* value) {
-    if (!specs_) return write(value), out_;
-    handle_cstring_type_spec(specs_->type, cstring_spec_handler(*this, value));
-    return out_;
-  }
-
-  iterator operator()(basic_string_view<Char> value) {
-    if (specs_) {
-      check_string_type_spec(specs_->type, error_handler());
-      write(value, *specs_);
-    } else {
-      write(value);
-    }
-    return out_;
-  }
+  iterator out;
+  const basic_format_specs<Char>& specs;
+  locale_ref locale;
 
-  iterator operator()(const void* value) {
-    if (specs_) check_pointer_type_spec(specs_->type, error_handler());
-    write_pointer(value);
-    return out_;
+  template <typename T>
+  FMT_CONSTEXPR FMT_INLINE auto operator()(T value) -> iterator {
+    return detail::write(out, value, specs, locale);
+  }
+  auto operator()(typename basic_format_arg<context>::handle) -> iterator {
+    // User-defined types are handled separately because they require access
+    // to the parse context.
+    return out;
   }
 };
 
-/** The default argument formatter. */
-template <typename OutputIt, typename Char>
-class arg_formatter : public arg_formatter_base<OutputIt, Char> {
- private:
-  using char_type = Char;
-  using base = arg_formatter_base<OutputIt, Char>;
-  using context_type = basic_format_context<OutputIt, Char>;
-
-  context_type& ctx_;
-  basic_format_parse_context<char_type>* parse_ctx_;
-  const Char* ptr_;
-
- public:
-  using iterator = typename base::iterator;
-  using format_specs = typename base::format_specs;
-
-  /**
-    \rst
-    Constructs an argument formatter object.
-    *ctx* is a reference to the formatting context,
-    *specs* contains format specifier information for standard argument types.
-    \endrst
-   */
-  explicit arg_formatter(
-      context_type& ctx,
-      basic_format_parse_context<char_type>* parse_ctx = nullptr,
-      format_specs* specs = nullptr, const Char* ptr = nullptr)
-      : base(ctx.out(), specs, ctx.locale()),
-        ctx_(ctx),
-        parse_ctx_(parse_ctx),
-        ptr_(ptr) {}
-
-  using base::operator();
-
-  /** Formats an argument of a user-defined type. */
-  iterator operator()(typename basic_format_arg<context_type>::handle handle) {
-    if (ptr_) advance_to(*parse_ctx_, ptr_);
-    handle.format(*parse_ctx_, ctx_);
-    return ctx_.out();
+template <typename Char> struct custom_formatter {
+  basic_format_parse_context<Char>& parse_ctx;
+  buffer_context<Char>& ctx;
+
+  void operator()(
+      typename basic_format_arg<buffer_context<Char>>::handle h) const {
+    h.format(parse_ctx, ctx);
   }
-};
-
-template <typename Char> FMT_CONSTEXPR bool is_name_start(Char c) {
-  return ('a' <= c && c <= 'z') || ('A' <= c && c <= 'Z') || '_' == c;
-}
-
-// Parses the range [begin, end) as an unsigned integer. This function assumes
-// that the range is non-empty and the first character is a digit.
-template <typename Char, typename ErrorHandler>
-FMT_CONSTEXPR int parse_nonnegative_int(const Char*& begin, const Char* end,
-                                        ErrorHandler&& eh) {
-  FMT_ASSERT(begin != end && '0' <= *begin && *begin <= '9', "");
-  unsigned value = 0;
-  // Convert to unsigned to prevent a warning.
-  constexpr unsigned max_int = max_value<int>();
-  unsigned big = max_int / 10;
-  do {
-    // Check for overflow.
-    if (value > big) {
-      value = max_int + 1;
-      break;
-    }
-    value = value * 10 + unsigned(*begin - '0');
-    ++begin;
-  } while (begin != end && '0' <= *begin && *begin <= '9');
-  if (value > max_int) eh.on_error("number is too big");
-  return static_cast<int>(value);
-}
-
-template <typename Context> class custom_formatter {
- private:
-  using char_type = typename Context::char_type;
-
-  basic_format_parse_context<char_type>& parse_ctx_;
-  Context& ctx_;
-
- public:
-  explicit custom_formatter(basic_format_parse_context<char_type>& parse_ctx,
-                            Context& ctx)
-      : parse_ctx_(parse_ctx), ctx_(ctx) {}
-
-  void operator()(typename basic_format_arg<Context>::handle h) const {
-    h.format(parse_ctx_, ctx_);
-  }
-
   template <typename T> void operator()(T) const {}
 };
 
 template <typename T>
 using is_integer =
     bool_constant<is_integral<T>::value && !std::is_same<T, bool>::value &&
                   !std::is_same<T, char>::value &&
                   !std::is_same<T, wchar_t>::value>;
 
 template <typename ErrorHandler> class width_checker {
  public:
   explicit FMT_CONSTEXPR width_checker(ErrorHandler& eh) : handler_(eh) {}
 
   template <typename T, FMT_ENABLE_IF(is_integer<T>::value)>
-  FMT_CONSTEXPR unsigned long long operator()(T value) {
+  FMT_CONSTEXPR auto operator()(T value) -> unsigned long long {
     if (is_negative(value)) handler_.on_error("negative width");
     return static_cast<unsigned long long>(value);
   }
 
   template <typename T, FMT_ENABLE_IF(!is_integer<T>::value)>
-  FMT_CONSTEXPR unsigned long long operator()(T) {
+  FMT_CONSTEXPR auto operator()(T) -> unsigned long long {
     handler_.on_error("width is not integer");
     return 0;
   }
 
  private:
   ErrorHandler& handler_;
 };
 
 template <typename ErrorHandler> class precision_checker {
  public:
   explicit FMT_CONSTEXPR precision_checker(ErrorHandler& eh) : handler_(eh) {}
 
   template <typename T, FMT_ENABLE_IF(is_integer<T>::value)>
-  FMT_CONSTEXPR unsigned long long operator()(T value) {
+  FMT_CONSTEXPR auto operator()(T value) -> unsigned long long {
     if (is_negative(value)) handler_.on_error("negative precision");
     return static_cast<unsigned long long>(value);
   }
 
   template <typename T, FMT_ENABLE_IF(!is_integer<T>::value)>
-  FMT_CONSTEXPR unsigned long long operator()(T) {
+  FMT_CONSTEXPR auto operator()(T) -> unsigned long long {
     handler_.on_error("precision is not integer");
     return 0;
   }
 
  private:
   ErrorHandler& handler_;
 };
 
-// A format specifier handler that sets fields in basic_format_specs.
-template <typename Char> class specs_setter {
- public:
-  explicit FMT_CONSTEXPR specs_setter(basic_format_specs<Char>& specs)
-      : specs_(specs) {}
-
-  FMT_CONSTEXPR specs_setter(const specs_setter& other)
-      : specs_(other.specs_) {}
-
-  FMT_CONSTEXPR void on_align(align_t align) { specs_.align = align; }
-  FMT_CONSTEXPR void on_fill(basic_string_view<Char> fill) {
-    specs_.fill = fill;
-  }
-  FMT_CONSTEXPR void on_plus() { specs_.sign = sign::plus; }
-  FMT_CONSTEXPR void on_minus() { specs_.sign = sign::minus; }
-  FMT_CONSTEXPR void on_space() { specs_.sign = sign::space; }
-  FMT_CONSTEXPR void on_hash() { specs_.alt = true; }
-
-  FMT_CONSTEXPR void on_zero() {
-    specs_.align = align::numeric;
-    specs_.fill[0] = Char('0');
-  }
-
-  FMT_CONSTEXPR void on_width(int width) { specs_.width = width; }
-  FMT_CONSTEXPR void on_precision(int precision) {
-    specs_.precision = precision;
-  }
-  FMT_CONSTEXPR void end_precision() {}
-
-  FMT_CONSTEXPR void on_type(Char type) {
-    specs_.type = static_cast<char>(type);
-  }
-
- protected:
-  basic_format_specs<Char>& specs_;
-};
-
-template <typename ErrorHandler> class numeric_specs_checker {
- public:
-  FMT_CONSTEXPR numeric_specs_checker(ErrorHandler& eh, detail::type arg_type)
-      : error_handler_(eh), arg_type_(arg_type) {}
-
-  FMT_CONSTEXPR void require_numeric_argument() {
-    if (!is_arithmetic_type(arg_type_))
-      error_handler_.on_error("format specifier requires numeric argument");
-  }
-
-  FMT_CONSTEXPR void check_sign() {
-    require_numeric_argument();
-    if (is_integral_type(arg_type_) && arg_type_ != type::int_type &&
-        arg_type_ != type::long_long_type && arg_type_ != type::char_type) {
-      error_handler_.on_error("format specifier requires signed argument");
-    }
-  }
-
-  FMT_CONSTEXPR void check_precision() {
-    if (is_integral_type(arg_type_) || arg_type_ == type::pointer_type)
-      error_handler_.on_error("precision not allowed for this argument type");
-  }
-
- private:
-  ErrorHandler& error_handler_;
-  detail::type arg_type_;
-};
-
-// A format specifier handler that checks if specifiers are consistent with the
-// argument type.
-template <typename Handler> class specs_checker : public Handler {
- private:
-  numeric_specs_checker<Handler> checker_;
-
-  // Suppress an MSVC warning about using this in initializer list.
-  FMT_CONSTEXPR Handler& error_handler() { return *this; }
-
- public:
-  FMT_CONSTEXPR specs_checker(const Handler& handler, detail::type arg_type)
-      : Handler(handler), checker_(error_handler(), arg_type) {}
-
-  FMT_CONSTEXPR specs_checker(const specs_checker& other)
-      : Handler(other), checker_(error_handler(), other.arg_type_) {}
-
-  FMT_CONSTEXPR void on_align(align_t align) {
-    if (align == align::numeric) checker_.require_numeric_argument();
-    Handler::on_align(align);
-  }
-
-  FMT_CONSTEXPR void on_plus() {
-    checker_.check_sign();
-    Handler::on_plus();
-  }
-
-  FMT_CONSTEXPR void on_minus() {
-    checker_.check_sign();
-    Handler::on_minus();
-  }
-
-  FMT_CONSTEXPR void on_space() {
-    checker_.check_sign();
-    Handler::on_space();
-  }
-
-  FMT_CONSTEXPR void on_hash() {
-    checker_.require_numeric_argument();
-    Handler::on_hash();
-  }
-
-  FMT_CONSTEXPR void on_zero() {
-    checker_.require_numeric_argument();
-    Handler::on_zero();
-  }
-
-  FMT_CONSTEXPR void end_precision() { checker_.check_precision(); }
-};
-
 template <template <typename> class Handler, typename FormatArg,
           typename ErrorHandler>
-FMT_CONSTEXPR int get_dynamic_spec(FormatArg arg, ErrorHandler eh) {
+FMT_CONSTEXPR auto get_dynamic_spec(FormatArg arg, ErrorHandler eh) -> int {
   unsigned long long value = visit_format_arg(Handler<ErrorHandler>(eh), arg);
   if (value > to_unsigned(max_value<int>())) eh.on_error("number is too big");
   return static_cast<int>(value);
 }
 
-struct auto_id {};
-
 template <typename Context, typename ID>
-FMT_CONSTEXPR typename Context::format_arg get_arg(Context& ctx, ID id) {
+FMT_CONSTEXPR auto get_arg(Context& ctx, ID id) ->
+    typename Context::format_arg {
   auto arg = ctx.arg(id);
   if (!arg) ctx.on_error("argument not found");
   return arg;
 }
 
 // The standard format specifier handler with checking.
-template <typename ParseContext, typename Context>
-class specs_handler : public specs_setter<typename Context::char_type> {
- public:
-  using char_type = typename Context::char_type;
-
-  FMT_CONSTEXPR specs_handler(basic_format_specs<char_type>& specs,
-                              ParseContext& parse_ctx, Context& ctx)
-      : specs_setter<char_type>(specs),
-        parse_context_(parse_ctx),
-        context_(ctx) {}
-
-  template <typename Id> FMT_CONSTEXPR void on_dynamic_width(Id arg_id) {
-    this->specs_.width = get_dynamic_spec<width_checker>(
-        get_arg(arg_id), context_.error_handler());
-  }
-
-  template <typename Id> FMT_CONSTEXPR void on_dynamic_precision(Id arg_id) {
-    this->specs_.precision = get_dynamic_spec<precision_checker>(
-        get_arg(arg_id), context_.error_handler());
-  }
-
-  void on_error(const char* message) { context_.on_error(message); }
-
+template <typename Char> class specs_handler : public specs_setter<Char> {
  private:
+  basic_format_parse_context<Char>& parse_context_;
+  buffer_context<Char>& context_;
+
   // This is only needed for compatibility with gcc 4.4.
-  using format_arg = typename Context::format_arg;
+  using format_arg = basic_format_arg<buffer_context<Char>>;
 
-  FMT_CONSTEXPR format_arg get_arg(auto_id) {
+  FMT_CONSTEXPR auto get_arg(auto_id) -> format_arg {
     return detail::get_arg(context_, parse_context_.next_arg_id());
   }
 
-  FMT_CONSTEXPR format_arg get_arg(int arg_id) {
+  FMT_CONSTEXPR auto get_arg(int arg_id) -> format_arg {
     parse_context_.check_arg_id(arg_id);
     return detail::get_arg(context_, arg_id);
   }
 
-  FMT_CONSTEXPR format_arg get_arg(basic_string_view<char_type> arg_id) {
+  FMT_CONSTEXPR auto get_arg(basic_string_view<Char> arg_id) -> format_arg {
     parse_context_.check_arg_id(arg_id);
     return detail::get_arg(context_, arg_id);
   }
 
-  ParseContext& parse_context_;
-  Context& context_;
-};
-
-enum class arg_id_kind { none, index, name };
-
-// An argument reference.
-template <typename Char> struct arg_ref {
-  FMT_CONSTEXPR arg_ref() : kind(arg_id_kind::none), val() {}
-
-  FMT_CONSTEXPR explicit arg_ref(int index)
-      : kind(arg_id_kind::index), val(index) {}
-  FMT_CONSTEXPR explicit arg_ref(basic_string_view<Char> name)
-      : kind(arg_id_kind::name), val(name) {}
-
-  FMT_CONSTEXPR arg_ref& operator=(int idx) {
-    kind = arg_id_kind::index;
-    val.index = idx;
-    return *this;
-  }
-
-  arg_id_kind kind;
-  union value {
-    FMT_CONSTEXPR value(int id = 0) : index{id} {}
-    FMT_CONSTEXPR value(basic_string_view<Char> n) : name(n) {}
-
-    int index;
-    basic_string_view<Char> name;
-  } val;
-};
-
-// Format specifiers with width and precision resolved at formatting rather
-// than parsing time to allow re-using the same parsed specifiers with
-// different sets of arguments (precompilation of format strings).
-template <typename Char>
-struct dynamic_format_specs : basic_format_specs<Char> {
-  arg_ref<Char> width_ref;
-  arg_ref<Char> precision_ref;
-};
-
-// Format spec handler that saves references to arguments representing dynamic
-// width and precision to be resolved at formatting time.
-template <typename ParseContext>
-class dynamic_specs_handler
-    : public specs_setter<typename ParseContext::char_type> {
  public:
-  using char_type = typename ParseContext::char_type;
-
-  FMT_CONSTEXPR dynamic_specs_handler(dynamic_format_specs<char_type>& specs,
-                                      ParseContext& ctx)
-      : specs_setter<char_type>(specs), specs_(specs), context_(ctx) {}
-
-  FMT_CONSTEXPR dynamic_specs_handler(const dynamic_specs_handler& other)
-      : specs_setter<char_type>(other),
-        specs_(other.specs_),
-        context_(other.context_) {}
+  FMT_CONSTEXPR specs_handler(basic_format_specs<Char>& specs,
+                              basic_format_parse_context<Char>& parse_ctx,
+                              buffer_context<Char>& ctx)
+      : specs_setter<Char>(specs), parse_context_(parse_ctx), context_(ctx) {}
 
   template <typename Id> FMT_CONSTEXPR void on_dynamic_width(Id arg_id) {
-    specs_.width_ref = make_arg_ref(arg_id);
+    this->specs_.width = get_dynamic_spec<width_checker>(
+        get_arg(arg_id), context_.error_handler());
   }
 
   template <typename Id> FMT_CONSTEXPR void on_dynamic_precision(Id arg_id) {
-    specs_.precision_ref = make_arg_ref(arg_id);
-  }
-
-  FMT_CONSTEXPR void on_error(const char* message) {
-    context_.on_error(message);
-  }
-
- private:
-  using arg_ref_type = arg_ref<char_type>;
-
-  FMT_CONSTEXPR arg_ref_type make_arg_ref(int arg_id) {
-    context_.check_arg_id(arg_id);
-    return arg_ref_type(arg_id);
-  }
-
-  FMT_CONSTEXPR arg_ref_type make_arg_ref(auto_id) {
-    return arg_ref_type(context_.next_arg_id());
-  }
-
-  FMT_CONSTEXPR arg_ref_type make_arg_ref(basic_string_view<char_type> arg_id) {
-    context_.check_arg_id(arg_id);
-    basic_string_view<char_type> format_str(
-        context_.begin(), to_unsigned(context_.end() - context_.begin()));
-    return arg_ref_type(arg_id);
-  }
-
-  dynamic_format_specs<char_type>& specs_;
-  ParseContext& context_;
-};
-
-template <typename Char, typename IDHandler>
-FMT_CONSTEXPR const Char* parse_arg_id(const Char* begin, const Char* end,
-                                       IDHandler&& handler) {
-  FMT_ASSERT(begin != end, "");
-  Char c = *begin;
-  if (c == '}' || c == ':') {
-    handler();
-    return begin;
-  }
-  if (c >= '0' && c <= '9') {
-    int index = 0;
-    if (c != '0')
-      index = parse_nonnegative_int(begin, end, handler);
-    else
-      ++begin;
-    if (begin == end || (*begin != '}' && *begin != ':'))
-      handler.on_error("invalid format string");
-    else
-      handler(index);
-    return begin;
-  }
-  if (!is_name_start(c)) {
-    handler.on_error("invalid format string");
-    return begin;
-  }
-  auto it = begin;
-  do {
-    ++it;
-  } while (it != end && (is_name_start(c = *it) || ('0' <= c && c <= '9')));
-  handler(basic_string_view<Char>(begin, to_unsigned(it - begin)));
-  return it;
-}
-
-// Adapts SpecHandler to IDHandler API for dynamic width.
-template <typename SpecHandler, typename Char> struct width_adapter {
-  explicit FMT_CONSTEXPR width_adapter(SpecHandler& h) : handler(h) {}
-
-  FMT_CONSTEXPR void operator()() { handler.on_dynamic_width(auto_id()); }
-  FMT_CONSTEXPR void operator()(int id) { handler.on_dynamic_width(id); }
-  FMT_CONSTEXPR void operator()(basic_string_view<Char> id) {
-    handler.on_dynamic_width(id);
-  }
-
-  FMT_CONSTEXPR void on_error(const char* message) {
-    handler.on_error(message);
-  }
-
-  SpecHandler& handler;
-};
-
-// Adapts SpecHandler to IDHandler API for dynamic precision.
-template <typename SpecHandler, typename Char> struct precision_adapter {
-  explicit FMT_CONSTEXPR precision_adapter(SpecHandler& h) : handler(h) {}
-
-  FMT_CONSTEXPR void operator()() { handler.on_dynamic_precision(auto_id()); }
-  FMT_CONSTEXPR void operator()(int id) { handler.on_dynamic_precision(id); }
-  FMT_CONSTEXPR void operator()(basic_string_view<Char> id) {
-    handler.on_dynamic_precision(id);
-  }
-
-  FMT_CONSTEXPR void on_error(const char* message) {
-    handler.on_error(message);
+    this->specs_.precision = get_dynamic_spec<precision_checker>(
+        get_arg(arg_id), context_.error_handler());
   }
 
-  SpecHandler& handler;
+  void on_error(const char* message) { context_.on_error(message); }
 };
 
-template <typename Char>
-FMT_CONSTEXPR int code_point_length(const Char* begin) {
-  if (const_check(sizeof(Char) != 1)) return 1;
-  constexpr char lengths[] = {1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
-                              0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 3, 3, 4, 0};
-  int len = lengths[static_cast<unsigned char>(*begin) >> 3];
-
-  // Compute the pointer to the next character early so that the next
-  // iteration can start working on the next character. Neither Clang
-  // nor GCC figure out this reordering on their own.
-  return len + !len;
-}
-
-template <typename Char> constexpr bool is_ascii_letter(Char c) {
-  return (c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z');
-}
-
-// Converts a character to ASCII. Returns a number > 127 on conversion failure.
-template <typename Char, FMT_ENABLE_IF(std::is_integral<Char>::value)>
-constexpr Char to_ascii(Char value) {
-  return value;
-}
-template <typename Char, FMT_ENABLE_IF(std::is_enum<Char>::value)>
-constexpr typename std::underlying_type<Char>::type to_ascii(Char value) {
-  return value;
-}
-
-// Parses fill and alignment.
-template <typename Char, typename Handler>
-FMT_CONSTEXPR const Char* parse_align(const Char* begin, const Char* end,
-                                      Handler&& handler) {
-  FMT_ASSERT(begin != end, "");
-  auto align = align::none;
-  auto p = begin + code_point_length(begin);
-  if (p >= end) p = begin;
-  for (;;) {
-    switch (to_ascii(*p)) {
-    case '<':
-      align = align::left;
-      break;
-    case '>':
-      align = align::right;
-      break;
-#if FMT_DEPRECATED_NUMERIC_ALIGN
-    case '=':
-      align = align::numeric;
-      break;
-#endif
-    case '^':
-      align = align::center;
-      break;
-    }
-    if (align != align::none) {
-      if (p != begin) {
-        auto c = *begin;
-        if (c == '{')
-          return handler.on_error("invalid fill character '{'"), begin;
-        handler.on_fill(basic_string_view<Char>(begin, to_unsigned(p - begin)));
-        begin = p + 1;
-      } else
-        ++begin;
-      handler.on_align(align);
-      break;
-    } else if (p == begin) {
-      break;
-    }
-    p = begin;
-  }
-  return begin;
-}
-
-template <typename Char, typename Handler>
-FMT_CONSTEXPR const Char* parse_width(const Char* begin, const Char* end,
-                                      Handler&& handler) {
-  FMT_ASSERT(begin != end, "");
-  if ('0' <= *begin && *begin <= '9') {
-    handler.on_width(parse_nonnegative_int(begin, end, handler));
-  } else if (*begin == '{') {
-    ++begin;
-    if (begin != end)
-      begin = parse_arg_id(begin, end, width_adapter<Handler, Char>(handler));
-    if (begin == end || *begin != '}')
-      return handler.on_error("invalid format string"), begin;
-    ++begin;
-  }
-  return begin;
-}
-
-template <typename Char, typename Handler>
-FMT_CONSTEXPR const Char* parse_precision(const Char* begin, const Char* end,
-                                          Handler&& handler) {
-  ++begin;
-  auto c = begin != end ? *begin : Char();
-  if ('0' <= c && c <= '9') {
-    handler.on_precision(parse_nonnegative_int(begin, end, handler));
-  } else if (c == '{') {
-    ++begin;
-    if (begin != end) {
-      begin =
-          parse_arg_id(begin, end, precision_adapter<Handler, Char>(handler));
-    }
-    if (begin == end || *begin++ != '}')
-      return handler.on_error("invalid format string"), begin;
-  } else {
-    return handler.on_error("missing precision specifier"), begin;
-  }
-  handler.end_precision();
-  return begin;
-}
-
-// Parses standard format specifiers and sends notifications about parsed
-// components to handler.
-template <typename Char, typename SpecHandler>
-FMT_CONSTEXPR const Char* parse_format_specs(const Char* begin, const Char* end,
-                                             SpecHandler&& handler) {
-  if (begin == end) return begin;
-
-  begin = parse_align(begin, end, handler);
-  if (begin == end) return begin;
-
-  // Parse sign.
-  switch (to_ascii(*begin)) {
-  case '+':
-    handler.on_plus();
-    ++begin;
+template <template <typename> class Handler, typename Context>
+FMT_CONSTEXPR void handle_dynamic_spec(int& value,
+                                       arg_ref<typename Context::char_type> ref,
+                                       Context& ctx) {
+  switch (ref.kind) {
+  case arg_id_kind::none:
     break;
-  case '-':
-    handler.on_minus();
-    ++begin;
+  case arg_id_kind::index:
+    value = detail::get_dynamic_spec<Handler>(ctx.arg(ref.val.index),
+                                              ctx.error_handler());
     break;
-  case ' ':
-    handler.on_space();
-    ++begin;
+  case arg_id_kind::name:
+    value = detail::get_dynamic_spec<Handler>(ctx.arg(ref.val.name),
+                                              ctx.error_handler());
     break;
   }
-  if (begin == end) return begin;
-
-  if (*begin == '#') {
-    handler.on_hash();
-    if (++begin == end) return begin;
-  }
+}
 
-  // Parse zero flag.
-  if (*begin == '0') {
-    handler.on_zero();
-    if (++begin == end) return begin;
-  }
+#define FMT_STRING_IMPL(s, base, explicit)                                 \
+  [] {                                                                     \
+    /* Use the hidden visibility as a workaround for a GCC bug (#1973). */ \
+    /* Use a macro-like name to avoid shadowing warnings. */               \
+    struct FMT_GCC_VISIBILITY_HIDDEN FMT_COMPILE_STRING : base {           \
+      using char_type = fmt::remove_cvref_t<decltype(s[0])>;               \
+      FMT_MAYBE_UNUSED FMT_CONSTEXPR explicit                              \
+      operator fmt::basic_string_view<char_type>() const {                 \
+        return fmt::detail_exported::compile_string_to_view<char_type>(s); \
+      }                                                                    \
+    };                                                                     \
+    return FMT_COMPILE_STRING();                                           \
+  }()
 
-  begin = parse_width(begin, end, handler);
-  if (begin == end) return begin;
+/**
+  \rst
+  Constructs a compile-time format string from a string literal *s*.
 
-  // Parse precision.
-  if (*begin == '.') {
-    begin = parse_precision(begin, end, handler);
-  }
+  **Example**::
 
-  // Parse type.
-  if (begin != end && *begin != '}') handler.on_type(*begin++);
-  return begin;
-}
+    // A compile-time error because 'd' is an invalid specifier for strings.
+    std::string s = fmt::format(FMT_STRING("{:d}"), "foo");
+  \endrst
+ */
+#define FMT_STRING(s) FMT_STRING_IMPL(s, fmt::compile_string, )
 
-// Return the result via the out param to workaround gcc bug 77539.
-template <bool IS_CONSTEXPR, typename T, typename Ptr = const T*>
-FMT_CONSTEXPR bool find(Ptr first, Ptr last, T value, Ptr& out) {
-  for (out = first; out != last; ++out) {
-    if (*out == value) return true;
-  }
-  return false;
-}
+#if FMT_USE_USER_DEFINED_LITERALS
+template <typename Char> struct udl_formatter {
+  basic_string_view<Char> str;
 
-template <>
-inline bool find<false, char>(const char* first, const char* last, char value,
-                              const char*& out) {
-  out = static_cast<const char*>(
-      std::memchr(first, value, detail::to_unsigned(last - first)));
-  return out != nullptr;
-}
-
-template <typename Handler, typename Char> struct id_adapter {
-  Handler& handler;
-  int arg_id;
-
-  FMT_CONSTEXPR void operator()() { arg_id = handler.on_arg_id(); }
-  FMT_CONSTEXPR void operator()(int id) { arg_id = handler.on_arg_id(id); }
-  FMT_CONSTEXPR void operator()(basic_string_view<Char> id) {
-    arg_id = handler.on_arg_id(id);
-  }
-  FMT_CONSTEXPR void on_error(const char* message) {
-    handler.on_error(message);
+  template <typename... T>
+  auto operator()(T&&... args) const -> std::basic_string<Char> {
+    return vformat(str, fmt::make_args_checked<T...>(str, args...));
   }
 };
 
-template <typename Char, typename Handler>
-FMT_CONSTEXPR const Char* parse_replacement_field(const Char* begin,
-                                                  const Char* end,
-                                                  Handler&& handler) {
-  ++begin;
-  if (begin == end) return handler.on_error("invalid format string"), end;
-  if (*begin == '}') {
-    handler.on_replacement_field(handler.on_arg_id(), begin);
-  } else if (*begin == '{') {
-    handler.on_text(begin, begin + 1);
-  } else {
-    auto adapter = id_adapter<Handler, Char>{handler, 0};
-    begin = parse_arg_id(begin, end, adapter);
-    Char c = begin != end ? *begin : Char();
-    if (c == '}') {
-      handler.on_replacement_field(adapter.arg_id, begin);
-    } else if (c == ':') {
-      begin = handler.on_format_specs(adapter.arg_id, begin + 1, end);
-      if (begin == end || *begin != '}')
-        return handler.on_error("unknown format specifier"), end;
-    } else {
-      return handler.on_error("missing '}' in format string"), end;
-    }
-  }
-  return begin + 1;
-}
+#  if FMT_USE_NONTYPE_TEMPLATE_PARAMETERS
+template <typename T, typename Char, size_t N,
+          fmt::detail_exported::fixed_string<Char, N> Str>
+struct statically_named_arg : view {
+  static constexpr auto name = Str.data;
 
-template <bool IS_CONSTEXPR, typename Char, typename Handler>
-FMT_CONSTEXPR_DECL FMT_INLINE void parse_format_string(
-    basic_string_view<Char> format_str, Handler&& handler) {
-  auto begin = format_str.data();
-  auto end = begin + format_str.size();
-  if (end - begin < 32) {
-    // Use a simple loop instead of memchr for small strings.
-    const Char* p = begin;
-    while (p != end) {
-      auto c = *p++;
-      if (c == '{') {
-        handler.on_text(begin, p - 1);
-        begin = p = parse_replacement_field(p - 1, end, handler);
-      } else if (c == '}') {
-        if (p == end || *p != '}')
-          return handler.on_error("unmatched '}' in format string");
-        handler.on_text(begin, p);
-        begin = ++p;
-      }
-    }
-    handler.on_text(begin, end);
-    return;
-  }
-  struct writer {
-    FMT_CONSTEXPR void operator()(const Char* pbegin, const Char* pend) {
-      if (pbegin == pend) return;
-      for (;;) {
-        const Char* p = nullptr;
-        if (!find<IS_CONSTEXPR>(pbegin, pend, '}', p))
-          return handler_.on_text(pbegin, pend);
-        ++p;
-        if (p == pend || *p != '}')
-          return handler_.on_error("unmatched '}' in format string");
-        handler_.on_text(pbegin, p);
-        pbegin = p + 1;
-      }
-    }
-    Handler& handler_;
-  } write{handler};
-  while (begin != end) {
-    // Doing two passes with memchr (one for '{' and another for '}') is up to
-    // 2.5x faster than the naive one-pass implementation on big format strings.
-    const Char* p = begin;
-    if (*begin != '{' && !find<IS_CONSTEXPR>(begin + 1, end, '{', p))
-      return write(begin, end);
-    write(begin, p);
-    begin = parse_replacement_field(p, end, handler);
-  }
-}
-
-template <typename T, typename ParseContext>
-FMT_CONSTEXPR const typename ParseContext::char_type* parse_format_specs(
-    ParseContext& ctx) {
-  using char_type = typename ParseContext::char_type;
-  using context = buffer_context<char_type>;
-  using mapped_type =
-      conditional_t<detail::mapped_type_constant<T, context>::value !=
-                        type::custom_type,
-                    decltype(arg_mapper<context>().map(std::declval<T>())), T>;
-  auto f = conditional_t<has_formatter<mapped_type, context>::value,
-                         formatter<mapped_type, char_type>,
-                         detail::fallback_formatter<T, char_type>>();
-  return f.parse(ctx);
-}
-
-template <typename OutputIt, typename Char, typename Context>
-struct format_handler : detail::error_handler {
-  basic_format_parse_context<Char> parse_context;
-  Context context;
-
-  format_handler(OutputIt out, basic_string_view<Char> str,
-                 basic_format_args<Context> format_args, detail::locale_ref loc)
-      : parse_context(str), context(out, format_args, loc) {}
-
-  void on_text(const Char* begin, const Char* end) {
-    auto size = to_unsigned(end - begin);
-    auto out = context.out();
-    auto&& it = reserve(out, size);
-    it = std::copy_n(begin, size, it);
-    context.advance_to(out);
-  }
-
-  int on_arg_id() { return parse_context.next_arg_id(); }
-  int on_arg_id(int id) { return parse_context.check_arg_id(id), id; }
-  int on_arg_id(basic_string_view<Char> id) {
-    int arg_id = context.arg_id(id);
-    if (arg_id < 0) on_error("argument not found");
-    return arg_id;
-  }
-
-  FMT_INLINE void on_replacement_field(int id, const Char*) {
-    auto arg = get_arg(context, id);
-    context.advance_to(visit_format_arg(
-        default_arg_formatter<OutputIt, Char>{context.out(), context.args(),
-                                              context.locale()},
-        arg));
-  }
-
-  const Char* on_format_specs(int id, const Char* begin, const Char* end) {
-    auto arg = get_arg(context, id);
-    if (arg.type() == type::custom_type) {
-      advance_to(parse_context, begin);
-      visit_format_arg(custom_formatter<Context>(parse_context, context), arg);
-      return parse_context.begin();
-    }
-    auto specs = basic_format_specs<Char>();
-    if (begin + 1 < end && begin[1] == '}' && is_ascii_letter(*begin)) {
-      specs.type = static_cast<char>(*begin++);
-    } else {
-      using parse_context_t = basic_format_parse_context<Char>;
-      specs_checker<specs_handler<parse_context_t, Context>> handler(
-          specs_handler<parse_context_t, Context>(specs, parse_context,
-                                                  context),
-          arg.type());
-      begin = parse_format_specs(begin, end, handler);
-      if (begin == end || *begin != '}')
-        on_error("missing '}' in format string");
-    }
-    context.advance_to(visit_format_arg(
-        arg_formatter<OutputIt, Char>(context, &parse_context, &specs), arg));
-    return begin;
-  }
+  const T& value;
+  statically_named_arg(const T& v) : value(v) {}
 };
 
-// A parse context with extra argument id checks. It is only used at compile
-// time because adding checks at runtime would introduce substantial overhead
-// and would be redundant since argument ids are checked when arguments are
-// retrieved anyway.
-template <typename Char, typename ErrorHandler = error_handler>
-class compile_parse_context
-    : public basic_format_parse_context<Char, ErrorHandler> {
- private:
-  int num_args_;
-  using base = basic_format_parse_context<Char, ErrorHandler>;
-
- public:
-  explicit FMT_CONSTEXPR compile_parse_context(
-      basic_string_view<Char> format_str, int num_args = max_value<int>(),
-      ErrorHandler eh = {})
-      : base(format_str, eh), num_args_(num_args) {}
+template <typename T, typename Char, size_t N,
+          fmt::detail_exported::fixed_string<Char, N> Str>
+struct is_named_arg<statically_named_arg<T, Char, N, Str>> : std::true_type {};
 
-  FMT_CONSTEXPR int next_arg_id() {
-    int id = base::next_arg_id();
-    if (id >= num_args_) this->on_error("argument not found");
-    return id;
-  }
+template <typename T, typename Char, size_t N,
+          fmt::detail_exported::fixed_string<Char, N> Str>
+struct is_statically_named_arg<statically_named_arg<T, Char, N, Str>>
+    : std::true_type {};
 
-  FMT_CONSTEXPR void check_arg_id(int id) {
-    base::check_arg_id(id);
-    if (id >= num_args_) this->on_error("argument not found");
+template <typename Char, size_t N,
+          fmt::detail_exported::fixed_string<Char, N> Str>
+struct udl_arg {
+  template <typename T> auto operator=(T&& value) const {
+    return statically_named_arg<T, Char, N, Str>(std::forward<T>(value));
   }
-  using base::check_arg_id;
 };
+#  else
+template <typename Char> struct udl_arg {
+  const Char* str;
 
-template <typename Char, typename ErrorHandler, typename... Args>
-class format_string_checker {
- public:
-  explicit FMT_CONSTEXPR format_string_checker(
-      basic_string_view<Char> format_str, ErrorHandler eh)
-      : context_(format_str, num_args, eh),
-        parse_funcs_{&parse_format_specs<Args, parse_context_type>...} {}
-
-  FMT_CONSTEXPR void on_text(const Char*, const Char*) {}
-
-  FMT_CONSTEXPR int on_arg_id() { return context_.next_arg_id(); }
-  FMT_CONSTEXPR int on_arg_id(int id) { return context_.check_arg_id(id), id; }
-  FMT_CONSTEXPR int on_arg_id(basic_string_view<Char>) {
-    on_error("compile-time checks don't support named arguments");
-    return 0;
-  }
-
-  FMT_CONSTEXPR void on_replacement_field(int, const Char*) {}
-
-  FMT_CONSTEXPR const Char* on_format_specs(int id, const Char* begin,
-                                            const Char*) {
-    advance_to(context_, begin);
-    return id < num_args ? parse_funcs_[id](context_) : begin;
-  }
-
-  FMT_CONSTEXPR void on_error(const char* message) {
-    context_.on_error(message);
+  template <typename T> auto operator=(T&& value) const -> named_arg<Char, T> {
+    return {str, std::forward<T>(value)};
   }
-
- private:
-  using parse_context_type = compile_parse_context<Char, ErrorHandler>;
-  enum { num_args = sizeof...(Args) };
-
-  // Format specifier parsing function.
-  using parse_func = const Char* (*)(parse_context_type&);
-
-  parse_context_type context_;
-  parse_func parse_funcs_[num_args > 0 ? num_args : 1];
 };
+#  endif
+#endif  // FMT_USE_USER_DEFINED_LITERALS
 
-// Converts string literals to basic_string_view.
-template <typename Char, size_t N>
-FMT_CONSTEXPR basic_string_view<Char> compile_string_to_view(
-    const Char (&s)[N]) {
-  // Remove trailing null character if needed. Won't be present if this is used
-  // with raw character array (i.e. not defined as a string).
-  return {s,
-          N - ((std::char_traits<Char>::to_int_type(s[N - 1]) == 0) ? 1 : 0)};
-}
-
-// Converts string_view to basic_string_view.
-template <typename Char>
-FMT_CONSTEXPR basic_string_view<Char> compile_string_to_view(
-    const std_string_view<Char>& s) {
-  return {s.data(), s.size()};
-}
-
-#define FMT_STRING_IMPL(s, base)                                  \
-  [] {                                                            \
-    /* Use a macro-like name to avoid shadowing warnings. */      \
-    struct FMT_COMPILE_STRING : base {                            \
-      using char_type = fmt::remove_cvref_t<decltype(s[0])>;      \
-      FMT_MAYBE_UNUSED FMT_CONSTEXPR                              \
-      operator fmt::basic_string_view<char_type>() const {        \
-        return fmt::detail::compile_string_to_view<char_type>(s); \
-      }                                                           \
-    };                                                            \
-    return FMT_COMPILE_STRING();                                  \
-  }()
-
-/**
-  \rst
-  Constructs a compile-time format string from a string literal *s*.
-
-  **Example**::
-
-    // A compile-time error because 'd' is an invalid specifier for strings.
-    std::string s = fmt::format(FMT_STRING("{:d}"), "foo");
-  \endrst
- */
-#define FMT_STRING(s) FMT_STRING_IMPL(s, fmt::compile_string)
-
-template <typename... Args, typename S,
-          enable_if_t<(is_compile_string<S>::value), int>>
-void check_format_string(S format_str) {
-  FMT_CONSTEXPR_DECL auto s = to_string_view(format_str);
-  using checker = format_string_checker<typename S::char_type, error_handler,
-                                        remove_cvref_t<Args>...>;
-  FMT_CONSTEXPR_DECL bool invalid_format =
-      (parse_format_string<true>(s, checker(s, {})), true);
-  (void)invalid_format;
-}
-
-template <template <typename> class Handler, typename Context>
-void handle_dynamic_spec(int& value, arg_ref<typename Context::char_type> ref,
-                         Context& ctx) {
-  switch (ref.kind) {
-  case arg_id_kind::none:
-    break;
-  case arg_id_kind::index:
-    value = detail::get_dynamic_spec<Handler>(ctx.arg(ref.val.index),
-                                              ctx.error_handler());
-    break;
-  case arg_id_kind::name:
-    value = detail::get_dynamic_spec<Handler>(ctx.arg(ref.val.name),
-                                              ctx.error_handler());
-    break;
-  }
+template <typename Locale, typename Char>
+auto vformat(const Locale& loc, basic_string_view<Char> format_str,
+             basic_format_args<buffer_context<type_identity_t<Char>>> args)
+    -> std::basic_string<Char> {
+  basic_memory_buffer<Char> buffer;
+  detail::vformat_to(buffer, format_str, args, detail::locale_ref(loc));
+  return {buffer.data(), buffer.size()};
 }
 
-using format_func = void (*)(detail::buffer<char>&, int, string_view);
+using format_func = void (*)(detail::buffer<char>&, int, const char*);
 
 FMT_API void format_error_code(buffer<char>& out, int error_code,
                                string_view message) FMT_NOEXCEPT;
 
 FMT_API void report_error(format_func func, int error_code,
-                          string_view message) FMT_NOEXCEPT;
-}  // namespace detail
+                          const char* message) FMT_NOEXCEPT;
+FMT_END_DETAIL_NAMESPACE
 
-template <typename OutputIt, typename Char>
-using arg_formatter FMT_DEPRECATED_ALIAS =
-    detail::arg_formatter<OutputIt, Char>;
+FMT_API auto vsystem_error(int error_code, string_view format_str,
+                           format_args args) -> std::system_error;
 
 /**
- An error returned by an operating system or a language runtime,
- for example a file opening error.
-*/
-FMT_CLASS_API
-class FMT_API system_error : public std::runtime_error {
- private:
-  void init(int err_code, string_view format_str, format_args args);
-
- protected:
-  int error_code_;
-
-  system_error() : std::runtime_error(""), error_code_(0) {}
+ \rst
+ Constructs :class:`std::system_error` with a message formatted with
+ ``fmt::format(fmt, args...)``.
+  *error_code* is a system error code as given by ``errno``.
 
- public:
-  /**
-   \rst
-   Constructs a :class:`fmt::system_error` object with a description
-   formatted with `fmt::format_system_error`. *message* and additional
-   arguments passed into the constructor are formatted similarly to
-   `fmt::format`.
-
-   **Example**::
-
-     // This throws a system_error with the description
-     //   cannot open file 'madeup': No such file or directory
-     // or similar (system message may vary).
-     const char *filename = "madeup";
-     std::FILE *file = std::fopen(filename, "r");
-     if (!file)
-       throw fmt::system_error(errno, "cannot open file '{}'", filename);
-   \endrst
-  */
-  template <typename... Args>
-  system_error(int error_code, string_view message, const Args&... args)
-      : std::runtime_error("") {
-    init(error_code, message, make_format_args(args...));
-  }
-  system_error(const system_error&) = default;
-  system_error& operator=(const system_error&) = default;
-  system_error(system_error&&) = default;
-  system_error& operator=(system_error&&) = default;
-  ~system_error() FMT_NOEXCEPT FMT_OVERRIDE;
+ **Example**::
 
-  int error_code() const { return error_code_; }
-};
+   // This throws std::system_error with the description
+   //   cannot open file 'madeup': No such file or directory
+   // or similar (system message may vary).
+   const char* filename = "madeup";
+   std::FILE* file = std::fopen(filename, "r");
+   if (!file)
+     throw fmt::system_error(errno, "cannot open file '{}'", filename);
+ \endrst
+*/
+template <typename... T>
+auto system_error(int error_code, format_string<T...> fmt, T&&... args)
+    -> std::system_error {
+  return vsystem_error(error_code, fmt, fmt::make_format_args(args...));
+}
 
 /**
   \rst
-  Formats an error returned by an operating system or a language runtime,
-  for example a file opening error, and writes it to *out* in the following
-  form:
+  Formats an error message for an error returned by an operating system or a
+  language runtime, for example a file opening error, and writes it to *out*.
+  The format is the same as the one used by ``std::system_error(ec, message)``
+  where ``ec`` is ``std::error_code(error_code, std::generic_category()})``.
+  It is implementation-defined but normally looks like:
 
   .. parsed-literal::
      *<message>*: *<system-message>*
 
-  where *<message>* is the passed message and *<system-message>* is
-  the system message corresponding to the error code.
+  where *<message>* is the passed message and *<system-message>* is the system
+  message corresponding to the error code.
   *error_code* is a system error code as given by ``errno``.
-  If *error_code* is not a valid error code such as -1, the system message
-  may look like "Unknown error -1" and is platform-dependent.
   \endrst
  */
 FMT_API void format_system_error(detail::buffer<char>& out, int error_code,
-                                 string_view message) FMT_NOEXCEPT;
+                                 const char* message) FMT_NOEXCEPT;
 
 // Reports a system error without throwing an exception.
 // Can be used to report errors from destructors.
 FMT_API void report_system_error(int error_code,
-                                 string_view message) FMT_NOEXCEPT;
+                                 const char* message) FMT_NOEXCEPT;
 
 /** Fast integer formatter. */
 class format_int {
  private:
   // Buffer should be large enough to hold all digits (digits10 + 1),
   // a sign and a null character.
   enum { buffer_size = std::numeric_limits<unsigned long long>::digits10 + 3 };
   mutable char buffer_[buffer_size];
   char* str_;
 
-  template <typename UInt> char* format_unsigned(UInt value) {
+  template <typename UInt> auto format_unsigned(UInt value) -> char* {
     auto n = static_cast<detail::uint32_or_64_or_128_t<UInt>>(value);
     return detail::format_decimal(buffer_, n, buffer_size - 1).begin;
   }
 
-  template <typename Int> char* format_signed(Int value) {
+  template <typename Int> auto format_signed(Int value) -> char* {
     auto abs_value = static_cast<detail::uint32_or_64_or_128_t<Int>>(value);
     bool negative = value < 0;
     if (negative) abs_value = 0 - abs_value;
     auto begin = format_unsigned(abs_value);
     if (negative) *--begin = '-';
     return begin;
   }
@@ -3367,161 +2526,96 @@
   explicit format_int(long long value) : str_(format_signed(value)) {}
   explicit format_int(unsigned value) : str_(format_unsigned(value)) {}
   explicit format_int(unsigned long value) : str_(format_unsigned(value)) {}
   explicit format_int(unsigned long long value)
       : str_(format_unsigned(value)) {}
 
   /** Returns the number of characters written to the output buffer. */
-  size_t size() const {
+  auto size() const -> size_t {
     return detail::to_unsigned(buffer_ - str_ + buffer_size - 1);
   }
 
   /**
     Returns a pointer to the output buffer content. No terminating null
     character is appended.
    */
-  const char* data() const { return str_; }
+  auto data() const -> const char* { return str_; }
 
   /**
     Returns a pointer to the output buffer content with terminating null
     character appended.
    */
-  const char* c_str() const {
+  auto c_str() const -> const char* {
     buffer_[buffer_size - 1] = '\0';
     return str_;
   }
 
   /**
     \rst
     Returns the content of the output buffer as an ``std::string``.
     \endrst
    */
-  std::string str() const { return std::string(str_, size()); }
+  auto str() const -> std::string { return std::string(str_, size()); }
 };
 
-// A formatter specialization for the core types corresponding to detail::type
-// constants.
 template <typename T, typename Char>
-struct formatter<T, Char,
-                 enable_if_t<detail::type_constant<T, Char>::value !=
-                             detail::type::custom_type>> {
-  FMT_CONSTEXPR formatter() = default;
-
-  // Parses format specifiers stopping either at the end of the range or at the
-  // terminating '}'.
-  template <typename ParseContext>
-  FMT_CONSTEXPR auto parse(ParseContext& ctx) -> decltype(ctx.begin()) {
-    using handler_type = detail::dynamic_specs_handler<ParseContext>;
-    auto type = detail::type_constant<T, Char>::value;
-    detail::specs_checker<handler_type> handler(handler_type(specs_, ctx),
-                                                type);
-    auto it = parse_format_specs(ctx.begin(), ctx.end(), handler);
-    auto eh = ctx.error_handler();
-    switch (type) {
-    case detail::type::none_type:
-      FMT_ASSERT(false, "invalid argument type");
-      break;
-    case detail::type::int_type:
-    case detail::type::uint_type:
-    case detail::type::long_long_type:
-    case detail::type::ulong_long_type:
-    case detail::type::int128_type:
-    case detail::type::uint128_type:
-    case detail::type::bool_type:
-      handle_int_type_spec(specs_.type,
-                           detail::int_type_checker<decltype(eh)>(eh));
-      break;
-    case detail::type::char_type:
-      handle_char_specs(
-          &specs_, detail::char_specs_checker<decltype(eh)>(specs_.type, eh));
-      break;
-    case detail::type::float_type:
-      if (detail::const_check(FMT_USE_FLOAT))
-        detail::parse_float_type_spec(specs_, eh);
-      else
-        FMT_ASSERT(false, "float support disabled");
-      break;
-    case detail::type::double_type:
-      if (detail::const_check(FMT_USE_DOUBLE))
-        detail::parse_float_type_spec(specs_, eh);
-      else
-        FMT_ASSERT(false, "double support disabled");
-      break;
-    case detail::type::long_double_type:
-      if (detail::const_check(FMT_USE_LONG_DOUBLE))
-        detail::parse_float_type_spec(specs_, eh);
-      else
-        FMT_ASSERT(false, "long double support disabled");
-      break;
-    case detail::type::cstring_type:
-      detail::handle_cstring_type_spec(
-          specs_.type, detail::cstring_type_checker<decltype(eh)>(eh));
-      break;
-    case detail::type::string_type:
-      detail::check_string_type_spec(specs_.type, eh);
-      break;
-    case detail::type::pointer_type:
-      detail::check_pointer_type_spec(specs_.type, eh);
-      break;
-    case detail::type::custom_type:
-      // Custom format specifiers should be checked in parse functions of
-      // formatter specializations.
-      break;
-    }
-    return it;
-  }
-
-  template <typename FormatContext>
-  auto format(const T& val, FormatContext& ctx) -> decltype(ctx.out()) {
-    detail::handle_dynamic_spec<detail::width_checker>(specs_.width,
-                                                       specs_.width_ref, ctx);
+template <typename FormatContext>
+FMT_CONSTEXPR FMT_INLINE auto
+formatter<T, Char,
+          enable_if_t<detail::type_constant<T, Char>::value !=
+                      detail::type::custom_type>>::format(const T& val,
+                                                          FormatContext& ctx)
+    const -> decltype(ctx.out()) {
+  if (specs_.width_ref.kind != detail::arg_id_kind::none ||
+      specs_.precision_ref.kind != detail::arg_id_kind::none) {
+    auto specs = specs_;
+    detail::handle_dynamic_spec<detail::width_checker>(specs.width,
+                                                       specs.width_ref, ctx);
     detail::handle_dynamic_spec<detail::precision_checker>(
-        specs_.precision, specs_.precision_ref, ctx);
-    using af = detail::arg_formatter<typename FormatContext::iterator,
-                                     typename FormatContext::char_type>;
-    return visit_format_arg(af(ctx, nullptr, &specs_),
-                            detail::make_arg<FormatContext>(val));
+        specs.precision, specs.precision_ref, ctx);
+    return detail::write<Char>(ctx.out(), val, specs, ctx.locale());
   }
+  return detail::write<Char>(ctx.out(), val, specs_, ctx.locale());
+}
 
- private:
-  detail::dynamic_format_specs<Char> specs_;
-};
-
-#define FMT_FORMAT_AS(Type, Base)                                             \
-  template <typename Char>                                                    \
-  struct formatter<Type, Char> : formatter<Base, Char> {                      \
-    template <typename FormatContext>                                         \
-    auto format(Type const& val, FormatContext& ctx) -> decltype(ctx.out()) { \
-      return formatter<Base, Char>::format(val, ctx);                         \
-    }                                                                         \
+#define FMT_FORMAT_AS(Type, Base)                                        \
+  template <typename Char>                                               \
+  struct formatter<Type, Char> : formatter<Base, Char> {                 \
+    template <typename FormatContext>                                    \
+    auto format(Type const& val, FormatContext& ctx) const               \
+        -> decltype(ctx.out()) {                                         \
+      return formatter<Base, Char>::format(static_cast<Base>(val), ctx); \
+    }                                                                    \
   }
 
 FMT_FORMAT_AS(signed char, int);
 FMT_FORMAT_AS(unsigned char, unsigned);
 FMT_FORMAT_AS(short, int);
 FMT_FORMAT_AS(unsigned short, unsigned);
 FMT_FORMAT_AS(long, long long);
 FMT_FORMAT_AS(unsigned long, unsigned long long);
 FMT_FORMAT_AS(Char*, const Char*);
 FMT_FORMAT_AS(std::basic_string<Char>, basic_string_view<Char>);
 FMT_FORMAT_AS(std::nullptr_t, const void*);
+FMT_FORMAT_AS(detail::byte, unsigned char);
 FMT_FORMAT_AS(detail::std_string_view<Char>, basic_string_view<Char>);
 
 template <typename Char>
 struct formatter<void*, Char> : formatter<const void*, Char> {
   template <typename FormatContext>
-  auto format(void* val, FormatContext& ctx) -> decltype(ctx.out()) {
+  auto format(void* val, FormatContext& ctx) const -> decltype(ctx.out()) {
     return formatter<const void*, Char>::format(val, ctx);
   }
 };
 
 template <typename Char, size_t N>
 struct formatter<Char[N], Char> : formatter<basic_string_view<Char>, Char> {
   template <typename FormatContext>
-  auto format(const Char* val, FormatContext& ctx) -> decltype(ctx.out()) {
+  FMT_CONSTEXPR auto format(const Char* val, FormatContext& ctx) const
+      -> decltype(ctx.out()) {
     return formatter<basic_string_view<Char>, Char>::format(val, ctx);
   }
 };
 
 // A formatter for types known only at run time such as variant alternatives.
 //
 // Usage:
@@ -3532,91 +2626,69 @@
 //       return visit([&](const auto& val) {
 //           return dynamic_formatter<>::format(val, ctx);
 //       }, v);
 //     }
 //   };
 template <typename Char = char> class dynamic_formatter {
  private:
+  detail::dynamic_format_specs<Char> specs_;
+  const Char* format_str_;
+
   struct null_handler : detail::error_handler {
     void on_align(align_t) {}
-    void on_plus() {}
-    void on_minus() {}
-    void on_space() {}
+    void on_sign(sign_t) {}
     void on_hash() {}
   };
 
+  template <typename Context> void handle_specs(Context& ctx) {
+    detail::handle_dynamic_spec<detail::width_checker>(specs_.width,
+                                                       specs_.width_ref, ctx);
+    detail::handle_dynamic_spec<detail::precision_checker>(
+        specs_.precision, specs_.precision_ref, ctx);
+  }
+
  public:
   template <typename ParseContext>
-  auto parse(ParseContext& ctx) -> decltype(ctx.begin()) {
+  FMT_CONSTEXPR auto parse(ParseContext& ctx) -> decltype(ctx.begin()) {
     format_str_ = ctx.begin();
     // Checks are deferred to formatting time when the argument type is known.
     detail::dynamic_specs_handler<ParseContext> handler(specs_, ctx);
-    return parse_format_specs(ctx.begin(), ctx.end(), handler);
+    return detail::parse_format_specs(ctx.begin(), ctx.end(), handler);
   }
 
   template <typename T, typename FormatContext>
   auto format(const T& val, FormatContext& ctx) -> decltype(ctx.out()) {
     handle_specs(ctx);
     detail::specs_checker<null_handler> checker(
         null_handler(), detail::mapped_type_constant<T, FormatContext>::value);
     checker.on_align(specs_.align);
-    switch (specs_.sign) {
-    case sign::none:
-      break;
-    case sign::plus:
-      checker.on_plus();
-      break;
-    case sign::minus:
-      checker.on_minus();
-      break;
-    case sign::space:
-      checker.on_space();
-      break;
-    }
+    if (specs_.sign != sign::none) checker.on_sign(specs_.sign);
     if (specs_.alt) checker.on_hash();
     if (specs_.precision >= 0) checker.end_precision();
-    using af = detail::arg_formatter<typename FormatContext::iterator,
-                                     typename FormatContext::char_type>;
-    visit_format_arg(af(ctx, nullptr, &specs_),
-                     detail::make_arg<FormatContext>(val));
-    return ctx.out();
+    return detail::write<Char>(ctx.out(), val, specs_, ctx.locale());
   }
-
- private:
-  template <typename Context> void handle_specs(Context& ctx) {
-    detail::handle_dynamic_spec<detail::width_checker>(specs_.width,
-                                                       specs_.width_ref, ctx);
-    detail::handle_dynamic_spec<detail::precision_checker>(
-        specs_.precision, specs_.precision_ref, ctx);
-  }
-
-  detail::dynamic_format_specs<Char> specs_;
-  const Char* format_str_;
 };
 
-template <typename Char, typename ErrorHandler>
-FMT_CONSTEXPR void advance_to(
-    basic_format_parse_context<Char, ErrorHandler>& ctx, const Char* p) {
-  ctx.advance_to(ctx.begin() + (p - &*ctx.begin()));
-}
-
 /**
   \rst
   Converts ``p`` to ``const void*`` for pointer formatting.
 
   **Example**::
 
     auto s = fmt::format("{}", fmt::ptr(p));
   \endrst
  */
-template <typename T> inline const void* ptr(const T* p) { return p; }
-template <typename T> inline const void* ptr(const std::unique_ptr<T>& p) {
+template <typename T> auto ptr(T p) -> const void* {
+  static_assert(std::is_pointer<T>::value, "");
+  return detail::bit_cast<const void*>(p);
+}
+template <typename T> auto ptr(const std::unique_ptr<T>& p) -> const void* {
   return p.get();
 }
-template <typename T> inline const void* ptr(const std::shared_ptr<T>& p) {
+template <typename T> auto ptr(const std::shared_ptr<T>& p) -> const void* {
   return p.get();
 }
 
 class bytes {
  private:
   string_view data_;
   friend struct formatter<bytes>;
@@ -3646,84 +2718,156 @@
                                                        specs_.width_ref, ctx);
     detail::handle_dynamic_spec<detail::precision_checker>(
         specs_.precision, specs_.precision_ref, ctx);
     return detail::write_bytes(ctx.out(), b.data_, specs_);
   }
 };
 
-template <typename It, typename Sentinel, typename Char>
-struct arg_join : detail::view {
+// group_digits_view is not derived from view because it copies the argument.
+template <typename T> struct group_digits_view { T value; };
+
+/**
+  \rst
+  Returns a view that formats an integer value using ',' as a locale-independent
+  thousands separator.
+
+  **Example**::
+
+    fmt::print("{}", fmt::group_digits(12345));
+    // Output: "12,345"
+  \endrst
+ */
+template <typename T> auto group_digits(T value) -> group_digits_view<T> {
+  return {value};
+}
+
+template <typename T> struct formatter<group_digits_view<T>> : formatter<T> {
+ private:
+  detail::dynamic_format_specs<char> specs_;
+
+ public:
+  template <typename ParseContext>
+  FMT_CONSTEXPR auto parse(ParseContext& ctx) -> decltype(ctx.begin()) {
+    using handler_type = detail::dynamic_specs_handler<ParseContext>;
+    detail::specs_checker<handler_type> handler(handler_type(specs_, ctx),
+                                                detail::type::int_type);
+    auto it = parse_format_specs(ctx.begin(), ctx.end(), handler);
+    detail::check_string_type_spec(specs_.type, ctx.error_handler());
+    return it;
+  }
+
+  template <typename FormatContext>
+  auto format(group_digits_view<T> t, FormatContext& ctx)
+      -> decltype(ctx.out()) {
+    detail::handle_dynamic_spec<detail::width_checker>(specs_.width,
+                                                       specs_.width_ref, ctx);
+    detail::handle_dynamic_spec<detail::precision_checker>(
+        specs_.precision, specs_.precision_ref, ctx);
+    return detail::write_int_localized(
+        ctx.out(), static_cast<detail::uint64_or_128_t<T>>(t.value), 0, specs_,
+        detail::digit_grouping<char>({"\3", ','}));
+  }
+};
+
+template <typename It, typename Sentinel, typename Char = char>
+struct join_view : detail::view {
   It begin;
   Sentinel end;
   basic_string_view<Char> sep;
 
-  arg_join(It b, Sentinel e, basic_string_view<Char> s)
+  join_view(It b, Sentinel e, basic_string_view<Char> s)
       : begin(b), end(e), sep(s) {}
 };
 
 template <typename It, typename Sentinel, typename Char>
-struct formatter<arg_join<It, Sentinel, Char>, Char>
-    : formatter<typename std::iterator_traits<It>::value_type, Char> {
+using arg_join FMT_DEPRECATED_ALIAS = join_view<It, Sentinel, Char>;
+
+template <typename It, typename Sentinel, typename Char>
+struct formatter<join_view<It, Sentinel, Char>, Char> {
+ private:
+  using value_type =
+#ifdef __cpp_lib_ranges
+      std::iter_value_t<It>;
+#else
+      typename std::iterator_traits<It>::value_type;
+#endif
+  using context = buffer_context<Char>;
+  using mapper = detail::arg_mapper<context>;
+
+  template <typename T, FMT_ENABLE_IF(has_formatter<T, context>::value)>
+  static auto map(const T& value) -> const T& {
+    return value;
+  }
+  template <typename T, FMT_ENABLE_IF(!has_formatter<T, context>::value)>
+  static auto map(const T& value) -> decltype(mapper().map(value)) {
+    return mapper().map(value);
+  }
+
+  using formatter_type =
+      conditional_t<is_formattable<value_type, Char>::value,
+                    formatter<remove_cvref_t<decltype(map(
+                                  std::declval<const value_type&>()))>,
+                              Char>,
+                    detail::fallback_formatter<value_type, Char>>;
+
+  formatter_type value_formatter_;
+
+ public:
+  template <typename ParseContext>
+  FMT_CONSTEXPR auto parse(ParseContext& ctx) -> decltype(ctx.begin()) {
+    return value_formatter_.parse(ctx);
+  }
+
   template <typename FormatContext>
-  auto format(const arg_join<It, Sentinel, Char>& value, FormatContext& ctx)
+  auto format(const join_view<It, Sentinel, Char>& value, FormatContext& ctx)
       -> decltype(ctx.out()) {
-    using base = formatter<typename std::iterator_traits<It>::value_type, Char>;
     auto it = value.begin;
     auto out = ctx.out();
     if (it != value.end) {
-      out = base::format(*it++, ctx);
+      out = value_formatter_.format(map(*it), ctx);
+      ++it;
       while (it != value.end) {
-        out = std::copy(value.sep.begin(), value.sep.end(), out);
+        out = detail::copy_str<Char>(value.sep.begin(), value.sep.end(), out);
         ctx.advance_to(out);
-        out = base::format(*it++, ctx);
+        out = value_formatter_.format(map(*it), ctx);
+        ++it;
       }
     }
     return out;
   }
 };
 
 /**
-  Returns an object that formats the iterator range `[begin, end)` with elements
+  Returns a view that formats the iterator range `[begin, end)` with elements
   separated by `sep`.
  */
 template <typename It, typename Sentinel>
-arg_join<It, Sentinel, char> join(It begin, Sentinel end, string_view sep) {
-  return {begin, end, sep};
-}
-
-template <typename It, typename Sentinel>
-arg_join<It, Sentinel, wchar_t> join(It begin, Sentinel end, wstring_view sep) {
+auto join(It begin, Sentinel end, string_view sep) -> join_view<It, Sentinel> {
   return {begin, end, sep};
 }
 
 /**
   \rst
-  Returns an object that formats `range` with elements separated by `sep`.
+  Returns a view that formats `range` with elements separated by `sep`.
 
   **Example**::
 
     std::vector<int> v = {1, 2, 3};
     fmt::print("{}", fmt::join(v, ", "));
     // Output: "1, 2, 3"
 
   ``fmt::join`` applies passed format specifiers to the range elements::
 
     fmt::print("{:02}", fmt::join(v, ", "));
     // Output: "01, 02, 03"
   \endrst
  */
 template <typename Range>
-arg_join<detail::iterator_t<Range>, detail::sentinel_t<Range>, char> join(
-    Range&& range, string_view sep) {
-  return join(std::begin(range), std::end(range), sep);
-}
-
-template <typename Range>
-arg_join<detail::iterator_t<Range>, detail::sentinel_t<Range>, wchar_t> join(
-    Range&& range, wstring_view sep) {
+auto join(Range&& range, string_view sep)
+    -> join_view<detail::iterator_t<Range>, detail::sentinel_t<Range>> {
   return join(std::begin(range), std::end(range), sep);
 }
 
 /**
   \rst
   Converts *value* to ``std::string`` using the default format for type *T*.
 
@@ -3731,237 +2875,229 @@
 
     #include <fmt/format.h>
 
     std::string answer = fmt::to_string(42);
   \endrst
  */
 template <typename T, FMT_ENABLE_IF(!std::is_integral<T>::value)>
-inline std::string to_string(const T& value) {
-  std::string result;
+inline auto to_string(const T& value) -> std::string {
+  auto result = std::string();
   detail::write<char>(std::back_inserter(result), value);
   return result;
 }
 
 template <typename T, FMT_ENABLE_IF(std::is_integral<T>::value)>
-inline std::string to_string(T value) {
-  // The buffer should be large enough to store the number including the sign or
-  // "false" for bool.
+FMT_NODISCARD inline auto to_string(T value) -> std::string {
+  // The buffer should be large enough to store the number including the sign
+  // or "false" for bool.
   constexpr int max_size = detail::digits10<T>() + 2;
   char buffer[max_size > 5 ? static_cast<unsigned>(max_size) : 5];
   char* begin = buffer;
   return std::string(begin, detail::write<char>(begin, value));
 }
 
-/**
-  Converts *value* to ``std::wstring`` using the default format for type *T*.
- */
-template <typename T> inline std::wstring to_wstring(const T& value) {
-  return format(L"{}", value);
-}
-
 template <typename Char, size_t SIZE>
-std::basic_string<Char> to_string(const basic_memory_buffer<Char, SIZE>& buf) {
+FMT_NODISCARD auto to_string(const basic_memory_buffer<Char, SIZE>& buf)
+    -> std::basic_string<Char> {
   auto size = buf.size();
   detail::assume(size < std::basic_string<Char>().max_size());
   return std::basic_string<Char>(buf.data(), size);
 }
 
+FMT_BEGIN_DETAIL_NAMESPACE
+
 template <typename Char>
-void detail::vformat_to(
-    detail::buffer<Char>& buf, basic_string_view<Char> format_str,
-    basic_format_args<buffer_context<type_identity_t<Char>>> args,
-    detail::locale_ref loc) {
-  using iterator = typename buffer_context<Char>::iterator;
+void vformat_to(
+    buffer<Char>& buf, basic_string_view<Char> fmt,
+    basic_format_args<FMT_BUFFER_CONTEXT(type_identity_t<Char>)> args,
+    locale_ref loc) {
+  // workaround for msvc bug regarding name-lookup in module
+  // link names into function scope
+  using detail::arg_formatter;
+  using detail::buffer_appender;
+  using detail::custom_formatter;
+  using detail::default_arg_formatter;
+  using detail::get_arg;
+  using detail::locale_ref;
+  using detail::parse_format_specs;
+  using detail::specs_checker;
+  using detail::specs_handler;
+  using detail::to_unsigned;
+  using detail::type;
+  using detail::write;
   auto out = buffer_appender<Char>(buf);
-  if (format_str.size() == 2 && equal2(format_str.data(), "{}")) {
+  if (fmt.size() == 2 && equal2(fmt.data(), "{}")) {
     auto arg = args.get(0);
     if (!arg) error_handler().on_error("argument not found");
-    visit_format_arg(default_arg_formatter<iterator, Char>{out, args, loc},
-                     arg);
+    visit_format_arg(default_arg_formatter<Char>{out, args, loc}, arg);
     return;
   }
-  format_handler<iterator, Char, buffer_context<Char>> h(out, format_str, args,
-                                                         loc);
-  parse_format_string<false>(format_str, h);
+
+  struct format_handler : error_handler {
+    basic_format_parse_context<Char> parse_context;
+    buffer_context<Char> context;
+
+    format_handler(buffer_appender<Char> out, basic_string_view<Char> str,
+                   basic_format_args<buffer_context<Char>> args, locale_ref loc)
+        : parse_context(str), context(out, args, loc) {}
+
+    void on_text(const Char* begin, const Char* end) {
+      auto text = basic_string_view<Char>(begin, to_unsigned(end - begin));
+      context.advance_to(write<Char>(context.out(), text));
+    }
+
+    FMT_CONSTEXPR auto on_arg_id() -> int {
+      return parse_context.next_arg_id();
+    }
+    FMT_CONSTEXPR auto on_arg_id(int id) -> int {
+      return parse_context.check_arg_id(id), id;
+    }
+    FMT_CONSTEXPR auto on_arg_id(basic_string_view<Char> id) -> int {
+      int arg_id = context.arg_id(id);
+      if (arg_id < 0) on_error("argument not found");
+      return arg_id;
+    }
+
+    FMT_INLINE void on_replacement_field(int id, const Char*) {
+      auto arg = get_arg(context, id);
+      context.advance_to(visit_format_arg(
+          default_arg_formatter<Char>{context.out(), context.args(),
+                                      context.locale()},
+          arg));
+    }
+
+    auto on_format_specs(int id, const Char* begin, const Char* end)
+        -> const Char* {
+      auto arg = get_arg(context, id);
+      if (arg.type() == type::custom_type) {
+        parse_context.advance_to(parse_context.begin() +
+                                 (begin - &*parse_context.begin()));
+        visit_format_arg(custom_formatter<Char>{parse_context, context}, arg);
+        return parse_context.begin();
+      }
+      auto specs = basic_format_specs<Char>();
+      specs_checker<specs_handler<Char>> handler(
+          specs_handler<Char>(specs, parse_context, context), arg.type());
+      begin = parse_format_specs(begin, end, handler);
+      if (begin == end || *begin != '}')
+        on_error("missing '}' in format string");
+      auto f = arg_formatter<Char>{context.out(), specs, context.locale()};
+      context.advance_to(visit_format_arg(f, arg));
+      return begin;
+    }
+  };
+  detail::parse_format_string<false>(fmt, format_handler(out, fmt, args, loc));
 }
 
 #ifndef FMT_HEADER_ONLY
-extern template void detail::vformat_to(detail::buffer<char>&, string_view,
-                                        basic_format_args<format_context>,
-                                        detail::locale_ref);
-namespace detail {
-
-extern template FMT_API std::string grouping_impl<char>(locale_ref loc);
-extern template FMT_API std::string grouping_impl<wchar_t>(locale_ref loc);
-extern template FMT_API char thousands_sep_impl<char>(locale_ref loc);
-extern template FMT_API wchar_t thousands_sep_impl<wchar_t>(locale_ref loc);
-extern template FMT_API char decimal_point_impl(locale_ref loc);
-extern template FMT_API wchar_t decimal_point_impl(locale_ref loc);
-extern template int format_float<double>(double value, int precision,
-                                         float_specs specs, buffer<char>& buf);
-extern template int format_float<long double>(long double value, int precision,
-                                              float_specs specs,
-                                              buffer<char>& buf);
-int snprintf_float(float value, int precision, float_specs specs,
-                   buffer<char>& buf) = delete;
-extern template int snprintf_float<double>(double value, int precision,
-                                           float_specs specs,
-                                           buffer<char>& buf);
-extern template int snprintf_float<long double>(long double value,
-                                                int precision,
-                                                float_specs specs,
-                                                buffer<char>& buf);
-}  // namespace detail
-#endif
-
-template <typename S, typename Char = char_t<S>,
-          FMT_ENABLE_IF(detail::is_string<S>::value)>
-inline void vformat_to(
-    detail::buffer<Char>& buf, const S& format_str,
-    basic_format_args<FMT_BUFFER_CONTEXT(type_identity_t<Char>)> args) {
-  return detail::vformat_to(buf, to_string_view(format_str), args);
-}
-
-template <typename S, typename... Args, size_t SIZE = inline_buffer_size,
-          typename Char = enable_if_t<detail::is_string<S>::value, char_t<S>>>
-inline typename buffer_context<Char>::iterator format_to(
-    basic_memory_buffer<Char, SIZE>& buf, const S& format_str, Args&&... args) {
-  const auto& vargs = fmt::make_args_checked<Args...>(format_str, args...);
-  detail::vformat_to(buf, to_string_view(format_str), vargs);
-  return detail::buffer_appender<Char>(buf);
-}
-
-template <typename OutputIt, typename Char = char>
-using format_context_t = basic_format_context<OutputIt, Char>;
-
-template <typename OutputIt, typename Char = char>
-using format_args_t = basic_format_args<format_context_t<OutputIt, Char>>;
-
-template <typename OutputIt, typename Char = typename OutputIt::value_type>
-using format_to_n_context FMT_DEPRECATED_ALIAS = buffer_context<Char>;
-
-template <typename OutputIt, typename Char = typename OutputIt::value_type>
-using format_to_n_args FMT_DEPRECATED_ALIAS =
-    basic_format_args<buffer_context<Char>>;
-
-template <typename OutputIt, typename Char, typename... Args>
-FMT_DEPRECATED format_arg_store<buffer_context<Char>, Args...>
-make_format_to_n_args(const Args&... args) {
-  return format_arg_store<buffer_context<Char>, Args...>(args...);
-}
-
-template <typename Char, enable_if_t<(!std::is_same<Char, char>::value), int>>
-std::basic_string<Char> detail::vformat(
-    basic_string_view<Char> format_str,
-    basic_format_args<buffer_context<type_identity_t<Char>>> args) {
-  basic_memory_buffer<Char> buffer;
-  detail::vformat_to(buffer, format_str, args);
-  return to_string(buffer);
-}
+extern template FMT_API auto thousands_sep_impl<char>(locale_ref)
+    -> thousands_sep_result<char>;
+extern template FMT_API auto thousands_sep_impl<wchar_t>(locale_ref)
+    -> thousands_sep_result<wchar_t>;
+extern template FMT_API auto decimal_point_impl(locale_ref) -> char;
+extern template FMT_API auto decimal_point_impl(locale_ref) -> wchar_t;
+extern template auto format_float<double>(double value, int precision,
+                                          float_specs specs, buffer<char>& buf)
+    -> int;
+extern template auto format_float<long double>(long double value, int precision,
+                                               float_specs specs,
+                                               buffer<char>& buf) -> int;
+void snprintf_float(float, int, float_specs, buffer<char>&) = delete;
+extern template auto snprintf_float<double>(double value, int precision,
+                                            float_specs specs,
+                                            buffer<char>& buf) -> int;
+extern template auto snprintf_float<long double>(long double value,
+                                                 int precision,
+                                                 float_specs specs,
+                                                 buffer<char>& buf) -> int;
+#endif  // FMT_HEADER_ONLY
 
-template <typename Char, FMT_ENABLE_IF(std::is_same<Char, wchar_t>::value)>
-void vprint(std::FILE* f, basic_string_view<Char> format_str,
-            wformat_args args) {
-  wmemory_buffer buffer;
-  detail::vformat_to(buffer, format_str, args);
-  buffer.push_back(L'\0');
-  if (std::fputws(buffer.data(), f) == -1)
-    FMT_THROW(system_error(errno, "cannot write to file"));
-}
-
-template <typename Char, FMT_ENABLE_IF(std::is_same<Char, wchar_t>::value)>
-void vprint(basic_string_view<Char> format_str, wformat_args args) {
-  vprint(stdout, format_str, args);
-}
+FMT_END_DETAIL_NAMESPACE
 
 #if FMT_USE_USER_DEFINED_LITERALS
-namespace detail {
-
-#  if FMT_USE_UDL_TEMPLATE
-template <typename Char, Char... CHARS> class udl_formatter {
- public:
-  template <typename... Args>
-  std::basic_string<Char> operator()(Args&&... args) const {
-    static FMT_CONSTEXPR_DECL Char s[] = {CHARS..., '\0'};
-    return format(FMT_STRING(s), std::forward<Args>(args)...);
-  }
-};
-#  else
-template <typename Char> struct udl_formatter {
-  basic_string_view<Char> str;
-
-  template <typename... Args>
-  std::basic_string<Char> operator()(Args&&... args) const {
-    return format(str, std::forward<Args>(args)...);
-  }
-};
-#  endif  // FMT_USE_UDL_TEMPLATE
-
-template <typename Char> struct udl_arg {
-  const Char* str;
-
-  template <typename T> named_arg<Char, T> operator=(T&& value) const {
-    return {str, std::forward<T>(value)};
-  }
-};
-}  // namespace detail
-
 inline namespace literals {
-#  if FMT_USE_UDL_TEMPLATE
-#    pragma GCC diagnostic push
-#    pragma GCC diagnostic ignored "-Wpedantic"
-#    if FMT_CLANG_VERSION
-#      pragma GCC diagnostic ignored "-Wgnu-string-literal-operator-template"
-#    endif
-template <typename Char, Char... CHARS>
-FMT_CONSTEXPR detail::udl_formatter<Char, CHARS...> operator""_format() {
-  return {};
-}
-#    pragma GCC diagnostic pop
-#  else
-/**
-  \rst
-  User-defined literal equivalent of :func:`fmt::format`.
-
-  **Example**::
-
-    using namespace fmt::literals;
-    std::string message = "The answer is {}"_format(42);
-  \endrst
- */
-FMT_CONSTEXPR detail::udl_formatter<char> operator"" _format(const char* s,
-                                                             size_t n) {
-  return {{s, n}};
-}
-FMT_CONSTEXPR detail::udl_formatter<wchar_t> operator"" _format(
-    const wchar_t* s, size_t n) {
-  return {{s, n}};
-}
-#  endif  // FMT_USE_UDL_TEMPLATE
-
 /**
   \rst
   User-defined literal equivalent of :func:`fmt::arg`.
 
   **Example**::
 
     using namespace fmt::literals;
     fmt::print("Elapsed time: {s:.2f} seconds", "s"_a=1.23);
   \endrst
  */
-FMT_CONSTEXPR detail::udl_arg<char> operator"" _a(const char* s, size_t) {
-  return {s};
+#  if FMT_USE_NONTYPE_TEMPLATE_PARAMETERS
+template <detail_exported::fixed_string Str>
+constexpr auto operator""_a()
+    -> detail::udl_arg<remove_cvref_t<decltype(Str.data[0])>,
+                       sizeof(Str.data) / sizeof(decltype(Str.data[0])), Str> {
+  return {};
 }
-FMT_CONSTEXPR detail::udl_arg<wchar_t> operator"" _a(const wchar_t* s, size_t) {
+#  else
+constexpr auto operator"" _a(const char* s, size_t) -> detail::udl_arg<char> {
   return {s};
 }
+#  endif
+
+// DEPRECATED!
+// User-defined literal equivalent of fmt::format.
+FMT_DEPRECATED constexpr auto operator"" _format(const char* s, size_t n)
+    -> detail::udl_formatter<char> {
+  return {{s, n}};
+}
 }  // namespace literals
 #endif  // FMT_USE_USER_DEFINED_LITERALS
+
+template <typename Locale, FMT_ENABLE_IF(detail::is_locale<Locale>::value)>
+inline auto vformat(const Locale& loc, string_view fmt, format_args args)
+    -> std::string {
+  return detail::vformat(loc, fmt, args);
+}
+
+template <typename Locale, typename... T,
+          FMT_ENABLE_IF(detail::is_locale<Locale>::value)>
+inline auto format(const Locale& loc, format_string<T...> fmt, T&&... args)
+    -> std::string {
+  return vformat(loc, string_view(fmt), fmt::make_format_args(args...));
+}
+
+template <typename... T, size_t SIZE, typename Allocator>
+FMT_DEPRECATED auto format_to(basic_memory_buffer<char, SIZE, Allocator>& buf,
+                              format_string<T...> fmt, T&&... args)
+    -> appender {
+  detail::vformat_to(buf, string_view(fmt), fmt::make_format_args(args...));
+  return appender(buf);
+}
+
+template <typename OutputIt, typename Locale,
+          FMT_ENABLE_IF(detail::is_output_iterator<OutputIt, char>::value&&
+                            detail::is_locale<Locale>::value)>
+auto vformat_to(OutputIt out, const Locale& loc, string_view fmt,
+                format_args args) -> OutputIt {
+  using detail::get_buffer;
+  auto&& buf = get_buffer<char>(out);
+  detail::vformat_to(buf, fmt, args, detail::locale_ref(loc));
+  return detail::get_iterator(buf);
+}
+
+template <typename OutputIt, typename Locale, typename... T,
+          FMT_ENABLE_IF(detail::is_output_iterator<OutputIt, char>::value&&
+                            detail::is_locale<Locale>::value)>
+FMT_INLINE auto format_to(OutputIt out, const Locale& loc,
+                          format_string<T...> fmt, T&&... args) -> OutputIt {
+  return vformat_to(out, loc, fmt, fmt::make_format_args(args...));
+}
+
+FMT_MODULE_EXPORT_END
 FMT_END_NAMESPACE
 
+#ifdef FMT_DEPRECATED_INCLUDE_XCHAR
+#  include "xchar.h"
+#endif
+
 #ifdef FMT_HEADER_ONLY
 #  define FMT_FUNC inline
 #  include "format-inl.h"
 #else
 #  define FMT_FUNC
 #endif
```

### Comparing `lightgbm-3.3.5/compile/external_libs/fmt/include/fmt/os.h` & `lightgbm-4.0.0/external_libs/fmt/include/fmt/os.h`

 * *Files 6% similar despite different names*

```diff
@@ -4,42 +4,41 @@
 // All rights reserved.
 //
 // For the license information refer to format.h.
 
 #ifndef FMT_OS_H_
 #define FMT_OS_H_
 
-#if defined(__MINGW32__) || defined(__CYGWIN__)
-// Workaround MinGW bug https://sourceforge.net/p/mingw/bugs/2024/.
-#  undef __STRICT_ANSI__
-#endif
-
 #include <cerrno>
-#include <clocale>  // for locale_t
+#include <clocale>  // locale_t
 #include <cstddef>
 #include <cstdio>
-#include <cstdlib>  // for strtod_l
+#include <cstdlib>       // strtod_l
+#include <system_error>  // std::system_error
 
 #if defined __APPLE__ || defined(__FreeBSD__)
 #  include <xlocale.h>  // for LC_NUMERIC_MASK on OS X
 #endif
 
 #include "format.h"
 
+#ifndef FMT_USE_FCNTL
 // UWP doesn't provide _pipe.
-#if FMT_HAS_INCLUDE("winapifamily.h")
-#  include <winapifamily.h>
-#endif
-#if (FMT_HAS_INCLUDE(<fcntl.h>) || defined(__APPLE__) || \
-     defined(__linux__)) &&                              \
-    (!defined(WINAPI_FAMILY) || (WINAPI_FAMILY == WINAPI_FAMILY_DESKTOP_APP))
-#  include <fcntl.h>  // for O_RDONLY
-#  define FMT_USE_FCNTL 1
-#else
-#  define FMT_USE_FCNTL 0
+#  if FMT_HAS_INCLUDE("winapifamily.h")
+#    include <winapifamily.h>
+#  endif
+#  if (FMT_HAS_INCLUDE(<fcntl.h>) || defined(__APPLE__) || \
+       defined(__linux__)) &&                              \
+      (!defined(WINAPI_FAMILY) ||                          \
+       (WINAPI_FAMILY == WINAPI_FAMILY_DESKTOP_APP))
+#    include <fcntl.h>  // for O_RDONLY
+#    define FMT_USE_FCNTL 1
+#  else
+#    define FMT_USE_FCNTL 0
+#  endif
 #endif
 
 #ifndef FMT_POSIX
 #  if defined(_WIN32) && !defined(__MINGW32__)
 // Fix warnings about deprecated symbols.
 #    define FMT_POSIX(call) _##call
 #  else
@@ -70,14 +69,15 @@
 #else
 #  define FMT_RETRY_VAL(result, expression, error_result) result = (expression)
 #endif
 
 #define FMT_RETRY(result, expression) FMT_RETRY_VAL(result, expression, -1)
 
 FMT_BEGIN_NAMESPACE
+FMT_MODULE_EXPORT_BEGIN
 
 /**
   \rst
   A reference to a null-terminated string. It can be constructed from a C
   string or ``std::string``.
 
   You can use one of the following type aliases for common character types:
@@ -118,97 +118,115 @@
   /** Returns the pointer to a C string. */
   const Char* c_str() const { return data_; }
 };
 
 using cstring_view = basic_cstring_view<char>;
 using wcstring_view = basic_cstring_view<wchar_t>;
 
-// An error code.
-class error_code {
- private:
-  int value_;
-
- public:
-  explicit error_code(int value = 0) FMT_NOEXCEPT : value_(value) {}
+template <typename Char> struct formatter<std::error_code, Char> {
+  template <typename ParseContext>
+  FMT_CONSTEXPR auto parse(ParseContext& ctx) -> decltype(ctx.begin()) {
+    return ctx.begin();
+  }
 
-  int get() const FMT_NOEXCEPT { return value_; }
+  template <typename FormatContext>
+  FMT_CONSTEXPR auto format(const std::error_code& ec, FormatContext& ctx) const
+      -> decltype(ctx.out()) {
+    auto out = ctx.out();
+    out = detail::write_bytes(out, ec.category().name(),
+                              basic_format_specs<Char>());
+    out = detail::write<Char>(out, Char(':'));
+    out = detail::write<Char>(out, ec.value());
+    return out;
+  }
 };
 
 #ifdef _WIN32
-namespace detail {
+FMT_API const std::error_category& system_category() FMT_NOEXCEPT;
+
+FMT_BEGIN_DETAIL_NAMESPACE
 // A converter from UTF-16 to UTF-8.
 // It is only provided for Windows since other systems support UTF-8 natively.
 class utf16_to_utf8 {
  private:
   memory_buffer buffer_;
 
  public:
   utf16_to_utf8() {}
-  FMT_API explicit utf16_to_utf8(wstring_view s);
+  FMT_API explicit utf16_to_utf8(basic_string_view<wchar_t> s);
   operator string_view() const { return string_view(&buffer_[0], size()); }
   size_t size() const { return buffer_.size() - 1; }
   const char* c_str() const { return &buffer_[0]; }
   std::string str() const { return std::string(&buffer_[0], size()); }
 
   // Performs conversion returning a system error code instead of
   // throwing exception on conversion error. This method may still throw
   // in case of memory allocation error.
-  FMT_API int convert(wstring_view s);
+  FMT_API int convert(basic_string_view<wchar_t> s);
 };
 
 FMT_API void format_windows_error(buffer<char>& out, int error_code,
-                                  string_view message) FMT_NOEXCEPT;
-}  // namespace detail
+                                  const char* message) FMT_NOEXCEPT;
+FMT_END_DETAIL_NAMESPACE
 
-/** A Windows error. */
-class windows_error : public system_error {
- private:
-  FMT_API void init(int error_code, string_view format_str, format_args args);
+FMT_API std::system_error vwindows_error(int error_code, string_view format_str,
+                                         format_args args);
 
- public:
-  /**
-   \rst
-   Constructs a :class:`fmt::windows_error` object with the description
-   of the form
-
-   .. parsed-literal::
-     *<message>*: *<system-message>*
-
-   where *<message>* is the formatted message and *<system-message>* is the
-   system message corresponding to the error code.
-   *error_code* is a Windows error code as given by ``GetLastError``.
-   If *error_code* is not a valid error code such as -1, the system message
-   will look like "error -1".
-
-   **Example**::
-
-     // This throws a windows_error with the description
-     //   cannot open file 'madeup': The system cannot find the file specified.
-     // or similar (system message may vary).
-     const char *filename = "madeup";
-     LPOFSTRUCT of = LPOFSTRUCT();
-     HFILE file = OpenFile(filename, &of, OF_READ);
-     if (file == HFILE_ERROR) {
-       throw fmt::windows_error(GetLastError(),
-                                "cannot open file '{}'", filename);
-     }
-   \endrst
-  */
-  template <typename... Args>
-  windows_error(int error_code, string_view message, const Args&... args) {
-    init(error_code, message, make_format_args(args...));
-  }
-};
+/**
+ \rst
+ Constructs a :class:`std::system_error` object with the description
+ of the form
+
+ .. parsed-literal::
+   *<message>*: *<system-message>*
+
+ where *<message>* is the formatted message and *<system-message>* is the
+ system message corresponding to the error code.
+ *error_code* is a Windows error code as given by ``GetLastError``.
+ If *error_code* is not a valid error code such as -1, the system message
+ will look like "error -1".
+
+ **Example**::
+
+   // This throws a system_error with the description
+   //   cannot open file 'madeup': The system cannot find the file specified.
+   // or similar (system message may vary).
+   const char *filename = "madeup";
+   LPOFSTRUCT of = LPOFSTRUCT();
+   HFILE file = OpenFile(filename, &of, OF_READ);
+   if (file == HFILE_ERROR) {
+     throw fmt::windows_error(GetLastError(),
+                              "cannot open file '{}'", filename);
+   }
+ \endrst
+*/
+template <typename... Args>
+std::system_error windows_error(int error_code, string_view message,
+                                const Args&... args) {
+  return vwindows_error(error_code, message, fmt::make_format_args(args...));
+}
 
 // Reports a Windows error without throwing an exception.
 // Can be used to report errors from destructors.
 FMT_API void report_windows_error(int error_code,
-                                  string_view message) FMT_NOEXCEPT;
+                                  const char* message) FMT_NOEXCEPT;
+#else
+inline const std::error_category& system_category() FMT_NOEXCEPT {
+  return std::system_category();
+}
 #endif  // _WIN32
 
+// std::system is not available on some platforms such as iOS (#2248).
+#ifdef __OSX__
+template <typename S, typename... Args, typename Char = char_t<S>>
+void say(const S& format_str, Args&&... args) {
+  std::system(format("say \"{}\"", format(format_str, args...)).c_str());
+}
+#endif
+
 // A buffered file.
 class buffered_file {
  private:
   FILE* file_;
 
   friend class file;
 
@@ -251,15 +269,15 @@
 
   void vprint(string_view format_str, format_args args) {
     fmt::vprint(file_, format_str, args);
   }
 
   template <typename... Args>
   inline void print(string_view format_str, const Args&... args) {
-    vprint(format_str, make_format_args(args...));
+    vprint(format_str, fmt::make_format_args(args...));
   }
 };
 
 #if FMT_USE_FCNTL
 // A file. Closed file is represented by a file object with descriptor -1.
 // Methods that are not declared with FMT_NOEXCEPT may throw
 // fmt::system_error in case of failure. Note that some errors such as
@@ -276,30 +294,32 @@
  public:
   // Possible values for the oflag argument to the constructor.
   enum {
     RDONLY = FMT_POSIX(O_RDONLY),  // Open for reading only.
     WRONLY = FMT_POSIX(O_WRONLY),  // Open for writing only.
     RDWR = FMT_POSIX(O_RDWR),      // Open for reading and writing.
     CREATE = FMT_POSIX(O_CREAT),   // Create if the file doesn't exist.
-    APPEND = FMT_POSIX(O_APPEND)   // Open in append mode.
+    APPEND = FMT_POSIX(O_APPEND),  // Open in append mode.
+    TRUNC = FMT_POSIX(O_TRUNC)     // Truncate the content of the file.
   };
 
   // Constructs a file object which doesn't represent any file.
   file() FMT_NOEXCEPT : fd_(-1) {}
 
   // Opens a file and constructs a file object representing this file.
   FMT_API file(cstring_view path, int oflag);
 
  public:
   file(const file&) = delete;
   void operator=(const file&) = delete;
 
   file(file&& other) FMT_NOEXCEPT : fd_(other.fd_) { other.fd_ = -1; }
 
-  file& operator=(file&& other) FMT_NOEXCEPT {
+  // Move assignment is not noexcept because close may throw.
+  file& operator=(file&& other) {
     close();
     fd_ = other.fd_;
     other.fd_ = -1;
     return *this;
   }
 
   // Destroys the object closing the file it represents if any.
@@ -327,107 +347,133 @@
 
   // Makes fd be the copy of this file descriptor, closing fd first if
   // necessary.
   FMT_API void dup2(int fd);
 
   // Makes fd be the copy of this file descriptor, closing fd first if
   // necessary.
-  FMT_API void dup2(int fd, error_code& ec) FMT_NOEXCEPT;
+  FMT_API void dup2(int fd, std::error_code& ec) FMT_NOEXCEPT;
 
   // Creates a pipe setting up read_end and write_end file objects for reading
   // and writing respectively.
   FMT_API static void pipe(file& read_end, file& write_end);
 
   // Creates a buffered_file object associated with this file and detaches
   // this file object from the file.
   FMT_API buffered_file fdopen(const char* mode);
 };
 
 // Returns the memory page size.
 long getpagesize();
 
-namespace detail {
+FMT_BEGIN_DETAIL_NAMESPACE
 
 struct buffer_size {
+  buffer_size() = default;
   size_t value = 0;
   buffer_size operator=(size_t val) const {
     auto bs = buffer_size();
     bs.value = val;
     return bs;
   }
 };
 
 struct ostream_params {
-  int oflag = file::WRONLY | file::CREATE;
+  int oflag = file::WRONLY | file::CREATE | file::TRUNC;
   size_t buffer_size = BUFSIZ > 32768 ? BUFSIZ : 32768;
 
   ostream_params() {}
 
   template <typename... T>
-  ostream_params(T... params, int oflag) : ostream_params(params...) {
-    this->oflag = oflag;
+  ostream_params(T... params, int new_oflag) : ostream_params(params...) {
+    oflag = new_oflag;
   }
 
   template <typename... T>
   ostream_params(T... params, detail::buffer_size bs)
       : ostream_params(params...) {
     this->buffer_size = bs.value;
   }
+
+// Intel has a bug that results in failure to deduce a constructor
+// for empty parameter packs.
+#  if defined(__INTEL_COMPILER) && __INTEL_COMPILER < 2000
+  ostream_params(int new_oflag) : oflag(new_oflag) {}
+  ostream_params(detail::buffer_size bs) : buffer_size(bs.value) {}
+#  endif
 };
-}  // namespace detail
 
-static constexpr detail::buffer_size buffer_size;
+FMT_END_DETAIL_NAMESPACE
+
+// Added {} below to work around default constructor error known to
+// occur in Xcode versions 7.2.1 and 8.2.1.
+constexpr detail::buffer_size buffer_size{};
 
-// A fast output stream which is not thread-safe.
-class ostream final : private detail::buffer<char> {
+/** A fast output stream which is not thread-safe. */
+class FMT_API ostream final : private detail::buffer<char> {
  private:
   file file_;
 
-  void flush() {
-    if (size() == 0) return;
-    file_.write(data(), size());
-    clear();
-  }
-
-  void grow(size_t) final;
+  void grow(size_t) override;
 
   ostream(cstring_view path, const detail::ostream_params& params)
       : file_(path, params.oflag) {
     set(new char[params.buffer_size], params.buffer_size);
   }
 
  public:
   ostream(ostream&& other)
       : detail::buffer<char>(other.data(), other.size(), other.capacity()),
         file_(std::move(other.file_)) {
+    other.clear();
     other.set(nullptr, 0);
   }
   ~ostream() {
     flush();
     delete[] data();
   }
 
+  void flush() {
+    if (size() == 0) return;
+    file_.write(data(), size());
+    clear();
+  }
+
   template <typename... T>
   friend ostream output_file(cstring_view path, T... params);
 
   void close() {
     flush();
     file_.close();
   }
 
-  template <typename S, typename... Args>
-  void print(const S& format_str, const Args&... args) {
-    format_to(detail::buffer_appender<char>(*this), format_str, args...);
+  /**
+    Formats ``args`` according to specifications in ``fmt`` and writes the
+    output to the file.
+   */
+  template <typename... T> void print(format_string<T...> fmt, T&&... args) {
+    vformat_to(detail::buffer_appender<char>(*this), fmt,
+               fmt::make_format_args(args...));
   }
 };
 
 /**
-  Opens a file for writing. Supported parameters passed in `params`:
-  * ``<integer>``: Output flags (``file::WRONLY | file::CREATE`` by default)
+  \rst
+  Opens a file for writing. Supported parameters passed in *params*:
+
+  * ``<integer>``: Flags passed to `open
+    <https://pubs.opengroup.org/onlinepubs/007904875/functions/open.html>`_
+    (``file::WRONLY | file::CREATE`` by default)
   * ``buffer_size=<integer>``: Output buffer size
+
+  **Example**::
+
+    auto out = fmt::output_file("guide.txt");
+    out.print("Don't {}", "Panic");
+  \endrst
  */
 template <typename... T>
 inline ostream output_file(cstring_view path, T... params) {
   return {path, detail::ostream_params(params...)};
 }
 #endif  // FMT_USE_FCNTL
 
@@ -462,19 +508,20 @@
   }
   ~locale() { freelocale(locale_); }
 
   type get() const { return locale_; }
 
   // Converts string to floating-point number and advances str past the end
   // of the parsed input.
-  double strtod(const char*& str) const {
+  FMT_DEPRECATED double strtod(const char*& str) const {
     char* end = nullptr;
     double result = strtod_l(str, &end, locale_);
     str = end;
     return result;
   }
 };
 using Locale FMT_DEPRECATED_ALIAS = locale;
 #endif  // FMT_LOCALE
+FMT_MODULE_EXPORT_END
 FMT_END_NAMESPACE
 
 #endif  // FMT_OS_H_
```

### Comparing `lightgbm-3.3.5/compile/external_libs/fmt/include/fmt/printf.h` & `lightgbm-4.0.0/external_libs/fmt/include/fmt/printf.h`

 * *Files 18% similar despite different names*

```diff
@@ -6,19 +6,62 @@
 // For the license information refer to format.h.
 
 #ifndef FMT_PRINTF_H_
 #define FMT_PRINTF_H_
 
 #include <algorithm>  // std::max
 #include <limits>     // std::numeric_limits
+#include <ostream>
 
-#include "ostream.h"
+#include "format.h"
 
 FMT_BEGIN_NAMESPACE
-namespace detail {
+FMT_MODULE_EXPORT_BEGIN
+
+template <typename T> struct printf_formatter { printf_formatter() = delete; };
+
+template <typename Char>
+class basic_printf_parse_context : public basic_format_parse_context<Char> {
+  using basic_format_parse_context<Char>::basic_format_parse_context;
+};
+
+template <typename OutputIt, typename Char> class basic_printf_context {
+ private:
+  OutputIt out_;
+  basic_format_args<basic_printf_context> args_;
+
+ public:
+  using char_type = Char;
+  using format_arg = basic_format_arg<basic_printf_context>;
+  using parse_context_type = basic_printf_parse_context<Char>;
+  template <typename T> using formatter_type = printf_formatter<T>;
+
+  /**
+    \rst
+    Constructs a ``printf_context`` object. References to the arguments are
+    stored in the context object so make sure they have appropriate lifetimes.
+    \endrst
+   */
+  basic_printf_context(OutputIt out,
+                       basic_format_args<basic_printf_context> args)
+      : out_(out), args_(args) {}
+
+  OutputIt out() { return out_; }
+  void advance_to(OutputIt it) { out_ = it; }
+
+  detail::locale_ref locale() { return {}; }
+
+  format_arg arg(int id) const { return args_.get(id); }
+
+  FMT_CONSTEXPR void on_error(const char* message) {
+    detail::error_handler().on_error(message);
+  }
+};
+
+FMT_BEGIN_DETAIL_NAMESPACE
 
 // Checks if a value fits in int - used to avoid warnings about comparing
 // signed and unsigned integers.
 template <bool IsSigned> struct int_checker {
   template <typename T> static bool fits_in_int(T value) {
     unsigned max = max_value<int>();
     return value <= max;
@@ -174,228 +217,96 @@
   template <typename T, FMT_ENABLE_IF(!std::is_integral<T>::value)>
   unsigned operator()(T) {
     FMT_THROW(format_error("width is not integer"));
     return 0;
   }
 };
 
-template <typename Char, typename Context>
-void vprintf(buffer<Char>& buf, basic_string_view<Char> format,
-             basic_format_args<Context> args) {
-  Context(buffer_appender<Char>(buf), format, args).format();
-}
-}  // namespace detail
-
-// For printing into memory_buffer.
-template <typename Char, typename Context>
-FMT_DEPRECATED void printf(detail::buffer<Char>& buf,
-                           basic_string_view<Char> format,
-                           basic_format_args<Context> args) {
-  return detail::vprintf(buf, format, args);
-}
-using detail::vprintf;
-
-template <typename Char>
-class basic_printf_parse_context : public basic_format_parse_context<Char> {
-  using basic_format_parse_context<Char>::basic_format_parse_context;
-};
-template <typename OutputIt, typename Char> class basic_printf_context;
-
-/**
-  \rst
-  The ``printf`` argument formatter.
-  \endrst
- */
+// The ``printf`` argument formatter.
 template <typename OutputIt, typename Char>
-class printf_arg_formatter : public detail::arg_formatter_base<OutputIt, Char> {
- public:
-  using iterator = OutputIt;
-
+class printf_arg_formatter : public arg_formatter<Char> {
  private:
-  using char_type = Char;
-  using base = detail::arg_formatter_base<OutputIt, Char>;
+  using base = arg_formatter<Char>;
   using context_type = basic_printf_context<OutputIt, Char>;
+  using format_specs = basic_format_specs<Char>;
 
   context_type& context_;
 
-  void write_null_pointer(char) {
-    this->specs()->type = 0;
-    this->write("(nil)");
-  }
-
-  void write_null_pointer(wchar_t) {
-    this->specs()->type = 0;
-    this->write(L"(nil)");
+  OutputIt write_null_pointer(bool is_string = false) {
+    auto s = this->specs;
+    s.type = presentation_type::none;
+    return write_bytes(this->out, is_string ? "(null)" : "(nil)", s);
   }
 
  public:
-  using format_specs = typename base::format_specs;
+  printf_arg_formatter(OutputIt iter, format_specs& s, context_type& ctx)
+      : base{iter, s, locale_ref()}, context_(ctx) {}
 
-  /**
-    \rst
-    Constructs an argument formatter object.
-    *buffer* is a reference to the output buffer and *specs* contains format
-    specifier information for standard argument types.
-    \endrst
-   */
-  printf_arg_formatter(iterator iter, format_specs& specs, context_type& ctx)
-      : base(iter, &specs, detail::locale_ref()), context_(ctx) {}
+  OutputIt operator()(monostate value) { return base::operator()(value); }
 
-  template <typename T, FMT_ENABLE_IF(fmt::detail::is_integral<T>::value)>
-  iterator operator()(T value) {
-    // MSVC2013 fails to compile separate overloads for bool and char_type so
-    // use std::is_same instead.
-    if (std::is_same<T, bool>::value) {
-      format_specs& fmt_specs = *this->specs();
-      if (fmt_specs.type != 's') return base::operator()(value ? 1 : 0);
-      fmt_specs.type = 0;
-      this->write(value != 0);
-    } else if (std::is_same<T, char_type>::value) {
-      format_specs& fmt_specs = *this->specs();
-      if (fmt_specs.type && fmt_specs.type != 'c')
+  template <typename T, FMT_ENABLE_IF(detail::is_integral<T>::value)>
+  OutputIt operator()(T value) {
+    // MSVC2013 fails to compile separate overloads for bool and Char so use
+    // std::is_same instead.
+    if (std::is_same<T, Char>::value) {
+      format_specs fmt_specs = this->specs;
+      if (fmt_specs.type != presentation_type::none &&
+          fmt_specs.type != presentation_type::chr) {
         return (*this)(static_cast<int>(value));
+      }
       fmt_specs.sign = sign::none;
       fmt_specs.alt = false;
       fmt_specs.fill[0] = ' ';  // Ignore '0' flag for char types.
       // align::numeric needs to be overwritten here since the '0' flag is
       // ignored for non-numeric types
       if (fmt_specs.align == align::none || fmt_specs.align == align::numeric)
         fmt_specs.align = align::right;
-      return base::operator()(value);
-    } else {
-      return base::operator()(value);
+      return write<Char>(this->out, static_cast<Char>(value), fmt_specs);
     }
-    return this->out();
+    return base::operator()(value);
   }
 
   template <typename T, FMT_ENABLE_IF(std::is_floating_point<T>::value)>
-  iterator operator()(T value) {
+  OutputIt operator()(T value) {
     return base::operator()(value);
   }
 
   /** Formats a null-terminated C string. */
-  iterator operator()(const char* value) {
-    if (value)
-      base::operator()(value);
-    else if (this->specs()->type == 'p')
-      write_null_pointer(char_type());
-    else
-      this->write("(null)");
-    return this->out();
+  OutputIt operator()(const char* value) {
+    if (value) return base::operator()(value);
+    return write_null_pointer(this->specs.type != presentation_type::pointer);
   }
 
   /** Formats a null-terminated wide C string. */
-  iterator operator()(const wchar_t* value) {
-    if (value)
-      base::operator()(value);
-    else if (this->specs()->type == 'p')
-      write_null_pointer(char_type());
-    else
-      this->write(L"(null)");
-    return this->out();
+  OutputIt operator()(const wchar_t* value) {
+    if (value) return base::operator()(value);
+    return write_null_pointer(this->specs.type != presentation_type::pointer);
   }
 
-  iterator operator()(basic_string_view<char_type> value) {
+  OutputIt operator()(basic_string_view<Char> value) {
     return base::operator()(value);
   }
 
-  iterator operator()(monostate value) { return base::operator()(value); }
-
   /** Formats a pointer. */
-  iterator operator()(const void* value) {
-    if (value) return base::operator()(value);
-    this->specs()->type = 0;
-    write_null_pointer(char_type());
-    return this->out();
+  OutputIt operator()(const void* value) {
+    return value ? base::operator()(value) : write_null_pointer();
   }
 
   /** Formats an argument of a custom (user-defined) type. */
-  iterator operator()(typename basic_format_arg<context_type>::handle handle) {
-    handle.format(context_.parse_context(), context_);
-    return this->out();
+  OutputIt operator()(typename basic_format_arg<context_type>::handle handle) {
+    auto parse_ctx =
+        basic_printf_parse_context<Char>(basic_string_view<Char>());
+    handle.format(parse_ctx, context_);
+    return this->out;
   }
 };
 
-template <typename T> struct printf_formatter {
-  printf_formatter() = delete;
-
-  template <typename ParseContext>
-  auto parse(ParseContext& ctx) -> decltype(ctx.begin()) {
-    return ctx.begin();
-  }
-
-  template <typename FormatContext>
-  auto format(const T& value, FormatContext& ctx) -> decltype(ctx.out()) {
-    detail::format_value(detail::get_container(ctx.out()), value);
-    return ctx.out();
-  }
-};
-
-/**
- This template formats data and writes the output through an output iterator.
- */
-template <typename OutputIt, typename Char> class basic_printf_context {
- public:
-  /** The character type for the output. */
-  using char_type = Char;
-  using iterator = OutputIt;
-  using format_arg = basic_format_arg<basic_printf_context>;
-  using parse_context_type = basic_printf_parse_context<Char>;
-  template <typename T> using formatter_type = printf_formatter<T>;
-
- private:
-  using format_specs = basic_format_specs<char_type>;
-
-  OutputIt out_;
-  basic_format_args<basic_printf_context> args_;
-  parse_context_type parse_ctx_;
-
-  static void parse_flags(format_specs& specs, const Char*& it,
-                          const Char* end);
-
-  // Returns the argument with specified index or, if arg_index is -1, the next
-  // argument.
-  format_arg get_arg(int arg_index = -1);
-
-  // Parses argument index, flags and width and returns the argument index.
-  int parse_header(const Char*& it, const Char* end, format_specs& specs);
-
- public:
-  /**
-   \rst
-   Constructs a ``printf_context`` object. References to the arguments are
-   stored in the context object so make sure they have appropriate lifetimes.
-   \endrst
-   */
-  basic_printf_context(OutputIt out, basic_string_view<char_type> format_str,
-                       basic_format_args<basic_printf_context> args)
-      : out_(out), args_(args), parse_ctx_(format_str) {}
-
-  OutputIt out() { return out_; }
-  void advance_to(OutputIt it) { out_ = it; }
-
-  detail::locale_ref locale() { return {}; }
-
-  format_arg arg(int id) const { return args_.get(id); }
-
-  parse_context_type& parse_context() { return parse_ctx_; }
-
-  FMT_CONSTEXPR void on_error(const char* message) {
-    parse_ctx_.on_error(message);
-  }
-
-  /** Formats stored arguments and writes the output to the range. */
-  template <typename ArgFormatter = printf_arg_formatter<OutputIt, Char>>
-  OutputIt format();
-};
-
-template <typename OutputIt, typename Char>
-void basic_printf_context<OutputIt, Char>::parse_flags(format_specs& specs,
-                                                       const Char*& it,
-                                                       const Char* end) {
+template <typename Char>
+void parse_flags(basic_format_specs<Char>& specs, const Char*& it,
+                 const Char* end) {
   for (; it != end; ++it) {
     switch (*it) {
     case '-':
       specs.align = align::left;
       break;
     case '+':
       specs.sign = sign::plus;
@@ -413,130 +324,138 @@
       break;
     default:
       return;
     }
   }
 }
 
-template <typename OutputIt, typename Char>
-typename basic_printf_context<OutputIt, Char>::format_arg
-basic_printf_context<OutputIt, Char>::get_arg(int arg_index) {
-  if (arg_index < 0)
-    arg_index = parse_ctx_.next_arg_id();
-  else
-    parse_ctx_.check_arg_id(--arg_index);
-  return detail::get_arg(*this, arg_index);
-}
-
-template <typename OutputIt, typename Char>
-int basic_printf_context<OutputIt, Char>::parse_header(const Char*& it,
-                                                       const Char* end,
-                                                       format_specs& specs) {
+template <typename Char, typename GetArg>
+int parse_header(const Char*& it, const Char* end,
+                 basic_format_specs<Char>& specs, GetArg get_arg) {
   int arg_index = -1;
-  char_type c = *it;
+  Char c = *it;
   if (c >= '0' && c <= '9') {
     // Parse an argument index (if followed by '$') or a width possibly
     // preceded with '0' flag(s).
-    detail::error_handler eh;
-    int value = parse_nonnegative_int(it, end, eh);
+    int value = parse_nonnegative_int(it, end, -1);
     if (it != end && *it == '$') {  // value is an argument index
       ++it;
-      arg_index = value;
+      arg_index = value != -1 ? value : max_value<int>();
     } else {
       if (c == '0') specs.fill[0] = '0';
       if (value != 0) {
         // Nonzero value means that we parsed width and don't need to
         // parse it or flags again, so return now.
+        if (value == -1) FMT_THROW(format_error("number is too big"));
         specs.width = value;
         return arg_index;
       }
     }
   }
   parse_flags(specs, it, end);
   // Parse width.
   if (it != end) {
     if (*it >= '0' && *it <= '9') {
-      detail::error_handler eh;
-      specs.width = parse_nonnegative_int(it, end, eh);
+      specs.width = parse_nonnegative_int(it, end, -1);
+      if (specs.width == -1) FMT_THROW(format_error("number is too big"));
     } else if (*it == '*') {
       ++it;
       specs.width = static_cast<int>(visit_format_arg(
-          detail::printf_width_handler<char_type>(specs), get_arg()));
+          detail::printf_width_handler<Char>(specs), get_arg(-1)));
     }
   }
   return arg_index;
 }
 
-template <typename OutputIt, typename Char>
-template <typename ArgFormatter>
-OutputIt basic_printf_context<OutputIt, Char>::format() {
-  auto out = this->out();
-  const Char* start = parse_ctx_.begin();
-  const Char* end = parse_ctx_.end();
+template <typename Char, typename Context>
+void vprintf(buffer<Char>& buf, basic_string_view<Char> format,
+             basic_format_args<Context> args) {
+  using OutputIt = buffer_appender<Char>;
+  auto out = OutputIt(buf);
+  auto context = basic_printf_context<OutputIt, Char>(out, args);
+  auto parse_ctx = basic_printf_parse_context<Char>(format);
+
+  // Returns the argument with specified index or, if arg_index is -1, the next
+  // argument.
+  auto get_arg = [&](int arg_index) {
+    if (arg_index < 0)
+      arg_index = parse_ctx.next_arg_id();
+    else
+      parse_ctx.check_arg_id(--arg_index);
+    return detail::get_arg(context, arg_index);
+  };
+
+  const Char* start = parse_ctx.begin();
+  const Char* end = parse_ctx.end();
   auto it = start;
   while (it != end) {
-    char_type c = *it++;
-    if (c != '%') continue;
+    if (!detail::find<false, Char>(it, end, '%', it)) {
+      it = end;  // detail::find leaves it == nullptr if it doesn't find '%'
+      break;
+    }
+    Char c = *it++;
     if (it != end && *it == c) {
-      out = std::copy(start, it, out);
+      out = detail::write(
+          out, basic_string_view<Char>(start, detail::to_unsigned(it - start)));
       start = ++it;
       continue;
     }
-    out = std::copy(start, it - 1, out);
+    out = detail::write(out, basic_string_view<Char>(
+                                 start, detail::to_unsigned(it - 1 - start)));
 
-    format_specs specs;
+    basic_format_specs<Char> specs;
     specs.align = align::right;
 
     // Parse argument index, flags and width.
-    int arg_index = parse_header(it, end, specs);
-    if (arg_index == 0) on_error("argument not found");
+    int arg_index = parse_header(it, end, specs, get_arg);
+    if (arg_index == 0) parse_ctx.on_error("argument not found");
 
     // Parse precision.
     if (it != end && *it == '.') {
       ++it;
       c = it != end ? *it : 0;
       if ('0' <= c && c <= '9') {
-        detail::error_handler eh;
-        specs.precision = parse_nonnegative_int(it, end, eh);
+        specs.precision = parse_nonnegative_int(it, end, 0);
       } else if (c == '*') {
         ++it;
         specs.precision = static_cast<int>(
-            visit_format_arg(detail::printf_precision_handler(), get_arg()));
+            visit_format_arg(detail::printf_precision_handler(), get_arg(-1)));
       } else {
         specs.precision = 0;
       }
     }
 
-    format_arg arg = get_arg(arg_index);
+    auto arg = get_arg(arg_index);
     // For d, i, o, u, x, and X conversion specifiers, if a precision is
     // specified, the '0' flag is ignored
     if (specs.precision >= 0 && arg.is_integral())
       specs.fill[0] =
           ' ';  // Ignore '0' flag for non-numeric types or if '-' present.
     if (specs.precision >= 0 && arg.type() == detail::type::cstring_type) {
       auto str = visit_format_arg(detail::get_cstring<Char>(), arg);
       auto str_end = str + specs.precision;
       auto nul = std::find(str, str_end, Char());
-      arg = detail::make_arg<basic_printf_context>(basic_string_view<Char>(
-          str,
-          detail::to_unsigned(nul != str_end ? nul - str : specs.precision)));
+      arg = detail::make_arg<basic_printf_context<OutputIt, Char>>(
+          basic_string_view<Char>(
+              str, detail::to_unsigned(nul != str_end ? nul - str
+                                                      : specs.precision)));
     }
     if (specs.alt && visit_format_arg(detail::is_zero_int(), arg))
       specs.alt = false;
     if (specs.fill[0] == '0') {
       if (arg.is_arithmetic() && specs.align != align::left)
         specs.align = align::numeric;
       else
         specs.fill[0] = ' ';  // Ignore '0' flag for non-numeric types or if '-'
                               // flag is also present.
     }
 
     // Parse length and convert the argument to the required type.
     c = it != end ? *it++ : 0;
-    char_type t = it != end ? *it : 0;
+    Char t = it != end ? *it : 0;
     using detail::convert_arg;
     switch (c) {
     case 'h':
       if (t == 'h') {
         ++it;
         t = it != end ? *it : 0;
         convert_arg<signed char>(arg, t);
@@ -569,36 +488,42 @@
     default:
       --it;
       convert_arg<void>(arg, c);
     }
 
     // Parse type.
     if (it == end) FMT_THROW(format_error("invalid format string"));
-    specs.type = static_cast<char>(*it++);
+    char type = static_cast<char>(*it++);
     if (arg.is_integral()) {
       // Normalize type.
-      switch (specs.type) {
+      switch (type) {
       case 'i':
       case 'u':
-        specs.type = 'd';
+        type = 'd';
         break;
       case 'c':
-        visit_format_arg(detail::char_converter<basic_printf_context>(arg),
-                         arg);
+        visit_format_arg(
+            detail::char_converter<basic_printf_context<OutputIt, Char>>(arg),
+            arg);
         break;
       }
     }
+    specs.type = parse_presentation_type(type);
+    if (specs.type == presentation_type::none)
+      parse_ctx.on_error("invalid type specifier");
 
     start = it;
 
     // Format argument.
-    out = visit_format_arg(ArgFormatter(out, specs, *this), arg);
+    out = visit_format_arg(
+        detail::printf_arg_formatter<OutputIt, Char>(out, specs, context), arg);
   }
-  return std::copy(start, it, out);
+  detail::write(out, basic_string_view<Char>(start, to_unsigned(it - start)));
 }
+FMT_END_DETAIL_NAMESPACE
 
 template <typename Char>
 using basic_printf_context_t =
     basic_printf_context<detail::buffer_appender<Char>, Char>;
 
 using printf_context = basic_printf_context_t<char>;
 using wprintf_context = basic_printf_context_t<wchar_t>;
@@ -608,63 +533,65 @@
 
 /**
   \rst
   Constructs an `~fmt::format_arg_store` object that contains references to
   arguments and can be implicitly converted to `~fmt::printf_args`.
   \endrst
  */
-template <typename... Args>
-inline format_arg_store<printf_context, Args...> make_printf_args(
-    const Args&... args) {
+template <typename... T>
+inline auto make_printf_args(const T&... args)
+    -> format_arg_store<printf_context, T...> {
   return {args...};
 }
 
 /**
   \rst
   Constructs an `~fmt::format_arg_store` object that contains references to
   arguments and can be implicitly converted to `~fmt::wprintf_args`.
   \endrst
  */
-template <typename... Args>
-inline format_arg_store<wprintf_context, Args...> make_wprintf_args(
-    const Args&... args) {
+template <typename... T>
+inline auto make_wprintf_args(const T&... args)
+    -> format_arg_store<wprintf_context, T...> {
   return {args...};
 }
 
 template <typename S, typename Char = char_t<S>>
-inline std::basic_string<Char> vsprintf(
-    const S& format,
-    basic_format_args<basic_printf_context_t<type_identity_t<Char>>> args) {
+inline auto vsprintf(
+    const S& fmt,
+    basic_format_args<basic_printf_context_t<type_identity_t<Char>>> args)
+    -> std::basic_string<Char> {
   basic_memory_buffer<Char> buffer;
-  vprintf(buffer, to_string_view(format), args);
+  vprintf(buffer, to_string_view(fmt), args);
   return to_string(buffer);
 }
 
 /**
   \rst
   Formats arguments and returns the result as a string.
 
   **Example**::
 
     std::string message = fmt::sprintf("The answer is %d", 42);
   \endrst
 */
-template <typename S, typename... Args,
+template <typename S, typename... T,
           typename Char = enable_if_t<detail::is_string<S>::value, char_t<S>>>
-inline std::basic_string<Char> sprintf(const S& format, const Args&... args) {
+inline auto sprintf(const S& fmt, const T&... args) -> std::basic_string<Char> {
   using context = basic_printf_context_t<Char>;
-  return vsprintf(to_string_view(format), make_format_args<context>(args...));
+  return vsprintf(to_string_view(fmt), fmt::make_format_args<context>(args...));
 }
 
 template <typename S, typename Char = char_t<S>>
-inline int vfprintf(
-    std::FILE* f, const S& format,
-    basic_format_args<basic_printf_context_t<type_identity_t<Char>>> args) {
+inline auto vfprintf(
+    std::FILE* f, const S& fmt,
+    basic_format_args<basic_printf_context_t<type_identity_t<Char>>> args)
+    -> int {
   basic_memory_buffer<Char> buffer;
-  vprintf(buffer, to_string_view(format), args);
+  vprintf(buffer, to_string_view(fmt), args);
   size_t size = buffer.size();
   return std::fwrite(buffer.data(), sizeof(Char), size, f) < size
              ? -1
              : static_cast<int>(size);
 }
 
 /**
@@ -672,80 +599,59 @@
   Prints formatted data to the file *f*.
 
   **Example**::
 
     fmt::fprintf(stderr, "Don't %s!", "panic");
   \endrst
  */
-template <typename S, typename... Args,
-          typename Char = enable_if_t<detail::is_string<S>::value, char_t<S>>>
-inline int fprintf(std::FILE* f, const S& format, const Args&... args) {
+template <typename S, typename... T, typename Char = char_t<S>>
+inline auto fprintf(std::FILE* f, const S& fmt, const T&... args) -> int {
   using context = basic_printf_context_t<Char>;
-  return vfprintf(f, to_string_view(format),
-                  make_format_args<context>(args...));
+  return vfprintf(f, to_string_view(fmt),
+                  fmt::make_format_args<context>(args...));
 }
 
 template <typename S, typename Char = char_t<S>>
-inline int vprintf(
-    const S& format,
-    basic_format_args<basic_printf_context_t<type_identity_t<Char>>> args) {
-  return vfprintf(stdout, to_string_view(format), args);
+inline auto vprintf(
+    const S& fmt,
+    basic_format_args<basic_printf_context_t<type_identity_t<Char>>> args)
+    -> int {
+  return vfprintf(stdout, to_string_view(fmt), args);
 }
 
 /**
   \rst
   Prints formatted data to ``stdout``.
 
   **Example**::
 
     fmt::printf("Elapsed time: %.2f seconds", 1.23);
   \endrst
  */
-template <typename S, typename... Args,
-          FMT_ENABLE_IF(detail::is_string<S>::value)>
-inline int printf(const S& format_str, const Args&... args) {
-  using context = basic_printf_context_t<char_t<S>>;
-  return vprintf(to_string_view(format_str),
-                 make_format_args<context>(args...));
+template <typename S, typename... T, FMT_ENABLE_IF(detail::is_string<S>::value)>
+inline auto printf(const S& fmt, const T&... args) -> int {
+  return vprintf(
+      to_string_view(fmt),
+      fmt::make_format_args<basic_printf_context_t<char_t<S>>>(args...));
 }
 
 template <typename S, typename Char = char_t<S>>
-inline int vfprintf(
-    std::basic_ostream<Char>& os, const S& format,
-    basic_format_args<basic_printf_context_t<type_identity_t<Char>>> args) {
+FMT_DEPRECATED auto vfprintf(
+    std::basic_ostream<Char>& os, const S& fmt,
+    basic_format_args<basic_printf_context_t<type_identity_t<Char>>> args)
+    -> int {
   basic_memory_buffer<Char> buffer;
-  vprintf(buffer, to_string_view(format), args);
-  detail::write_buffer(os, buffer);
+  vprintf(buffer, to_string_view(fmt), args);
+  os.write(buffer.data(), static_cast<std::streamsize>(buffer.size()));
   return static_cast<int>(buffer.size());
 }
-
-/** Formats arguments and writes the output to the range. */
-template <typename ArgFormatter, typename Char,
-          typename Context =
-              basic_printf_context<typename ArgFormatter::iterator, Char>>
-typename ArgFormatter::iterator vprintf(
-    detail::buffer<Char>& out, basic_string_view<Char> format_str,
-    basic_format_args<type_identity_t<Context>> args) {
-  typename ArgFormatter::iterator iter(out);
-  Context(iter, format_str, args).template format<ArgFormatter>();
-  return iter;
+template <typename S, typename... T, typename Char = char_t<S>>
+FMT_DEPRECATED auto fprintf(std::basic_ostream<Char>& os, const S& fmt,
+                            const T&... args) -> int {
+  return vfprintf(os, to_string_view(fmt),
+                  fmt::make_format_args<basic_printf_context_t<Char>>(args...));
 }
 
-/**
-  \rst
-  Prints formatted data to the stream *os*.
-
-  **Example**::
-
-    fmt::fprintf(cerr, "Don't %s!", "panic");
-  \endrst
- */
-template <typename S, typename... Args, typename Char = char_t<S>>
-inline int fprintf(std::basic_ostream<Char>& os, const S& format_str,
-                   const Args&... args) {
-  using context = basic_printf_context_t<Char>;
-  return vfprintf(os, to_string_view(format_str),
-                  make_format_args<context>(args...));
-}
+FMT_MODULE_EXPORT_END
 FMT_END_NAMESPACE
 
 #endif  // FMT_PRINTF_H_
```

### Comparing `lightgbm-3.3.5/compile/include/LightGBM/application.h` & `lightgbm-4.0.0/include/LightGBM/application.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/include/LightGBM/boosting.h` & `lightgbm-4.0.0/include/LightGBM/boosting.h`

 * *Files 2% similar despite different names*

```diff
@@ -309,15 +309,19 @@
   * \param format Format of model
   * \param config config for boosting
   * \param filename name of model file, if existing will continue to train from this model
   * \return The boosting object
   */
   static Boosting* CreateBoosting(const std::string& type, const char* filename);
 
+  virtual std::string GetLoadedParam() const = 0;
+
   virtual bool IsLinear() const { return false; }
+
+  virtual std::string ParserConfigStr() const = 0;
 };
 
 class GBDTBase : public Boosting {
  public:
   virtual double GetLeafValue(int tree_idx, int leaf_idx) const = 0;
   virtual void SetLeafValue(int tree_idx, int leaf_idx, double val) = 0;
 };
```

### Comparing `lightgbm-3.3.5/compile/include/LightGBM/c_api.h` & `lightgbm-4.0.0/include/LightGBM/c_api.h`

 * *Files 5% similar despite different names*

```diff
@@ -19,21 +19,21 @@
 #include <cstdint>
 #include <cstdio>
 #include <cstring>
 #else
 #include <stdint.h>
 #include <stdio.h>
 #include <string.h>
-#include <stdbool.h>
 #endif
 
 
 typedef void* DatasetHandle;  /*!< \brief Handle of dataset. */
 typedef void* BoosterHandle;  /*!< \brief Handle of booster. */
 typedef void* FastConfigHandle; /*!< \brief Handle of FastConfig. */
+typedef void* ByteBufferHandle; /*!< \brief Handle of ByteBuffer. */
 
 #define C_API_DTYPE_FLOAT32 (0)  /*!< \brief float32 (single precision float). */
 #define C_API_DTYPE_FLOAT64 (1)  /*!< \brief float64 (double precision float). */
 #define C_API_DTYPE_INT32   (2)  /*!< \brief int32. */
 #define C_API_DTYPE_INT64   (3)  /*!< \brief int64. */
 
 #define C_API_PREDICT_NORMAL     (0)  /*!< \brief Normal prediction, with transform (if needed). */
@@ -50,14 +50,25 @@
 /*!
  * \brief Get string message of the last error.
  * \return Error information
  */
 LIGHTGBM_C_EXPORT const char* LGBM_GetLastError();
 
 /*!
+ * \brief Dump all parameter names with their aliases to JSON.
+ * \param buffer_len String buffer length, if ``buffer_len < out_len``, you should re-allocate buffer
+ * \param[out] out_len Actual output length
+ * \param[out] out_str JSON format string of parameters, should pre-allocate memory
+ * \return 0 when succeed, -1 when failure happens
+ */
+LIGHTGBM_C_EXPORT int LGBM_DumpParamAliases(int64_t buffer_len,
+                                            int64_t* out_len,
+                                            char* out_str);
+
+/*!
  * \brief Register a callback function for log redirecting.
  * \param callback The callback function to register
  * \return 0 when succeed, -1 when failure happens
  */
 LIGHTGBM_C_EXPORT int LGBM_RegisterLogCallback(void (*callback)(const char*));
 
 /*!
@@ -82,14 +93,30 @@
  * \return 0 when succeed, -1 when failure happens
  */
 LIGHTGBM_C_EXPORT int LGBM_SampleIndices(int32_t num_total_row,
                                          const char* parameters,
                                          void* out,
                                          int32_t* out_len);
 
+/*!
+ * \brief Get a ByteBuffer value at an index.
+ * \param handle Handle of byte buffer to be read
+ * \param index Index of value to return
+ * \param[out] out_val Byte value at index to return
+ * \return 0 when succeed, -1 when failure happens
+ */
+LIGHTGBM_C_EXPORT int LGBM_ByteBufferGetAt(ByteBufferHandle handle, int32_t index, uint8_t* out_val);
+
+/*!
+ * \brief Free space for byte buffer.
+ * \param handle Handle of byte buffer to be freed
+ * \return 0 when succeed, -1 when failure happens
+ */
+LIGHTGBM_C_EXPORT int LGBM_ByteBufferFree(ByteBufferHandle handle);
+
 /* --- start Dataset interface */
 
 /*!
  * \brief Load dataset from file (like LightGBM CLI version does).
  * \param filename The name of the file
  * \param parameters Additional parameters
  * \param reference Used to align bin mapper with other dataset, nullptr means isn't used
@@ -104,25 +131,27 @@
 /*!
  * \brief Allocate the space for dataset and bucket feature bins according to sampled data.
  * \param sample_data Sampled data, grouped by the column
  * \param sample_indices Indices of sampled data
  * \param ncol Number of columns
  * \param num_per_col Size of each sampling column
  * \param num_sample_row Number of sampled rows
- * \param num_total_row Number of total rows
+ * \param num_local_row Total number of rows local to machine
+ * \param num_dist_row Number of total distributed rows
  * \param parameters Additional parameters
  * \param[out] out Created dataset
  * \return 0 when succeed, -1 when failure happens
  */
 LIGHTGBM_C_EXPORT int LGBM_DatasetCreateFromSampledColumn(double** sample_data,
                                                           int** sample_indices,
                                                           int32_t ncol,
                                                           const int* num_per_col,
                                                           int32_t num_sample_row,
-                                                          int32_t num_total_row,
+                                                          int32_t num_local_row,
+                                                          int64_t num_dist_row,
                                                           const char* parameters,
                                                           DatasetHandle* out);
 
 /*!
  * \brief Allocate the space for dataset and bucket feature bins according to reference dataset.
  * \param reference Used to align bin mapper with other dataset
  * \param num_total_row Number of total rows
@@ -130,14 +159,50 @@
  * \return 0 when succeed, -1 when failure happens
  */
 LIGHTGBM_C_EXPORT int LGBM_DatasetCreateByReference(const DatasetHandle reference,
                                                     int64_t num_total_row,
                                                     DatasetHandle* out);
 
 /*!
+ * \brief Initialize the Dataset for streaming.
+ * \param dataset Handle of dataset
+ * \param has_weights Whether the dataset has Metadata weights
+ * \param has_init_scores Whether the dataset has Metadata initial scores
+ * \param has_queries Whether the dataset has Metadata queries/groups
+ * \param nclasses Number of initial score classes
+ * \param nthreads Number of external threads that will use the PushRows APIs
+ * \param omp_max_threads Maximum number of OpenMP threads (-1 for default)
+ * \return 0 when succeed, -1 when failure happens
+ */
+LIGHTGBM_C_EXPORT int LGBM_DatasetInitStreaming(DatasetHandle dataset,
+                                                int32_t has_weights,
+                                                int32_t has_init_scores,
+                                                int32_t has_queries,
+                                                int32_t nclasses,
+                                                int32_t nthreads,
+                                                int32_t omp_max_threads);
+
+/*!
+ * \brief Allocate the space for dataset and bucket feature bins according to serialized reference dataset.
+ * \param ref_buffer A binary representation of the dataset schema (feature groups, bins, etc.)
+ * \param ref_buffer_size The size of the reference array in bytes
+ * \param num_row Number of total rows the dataset will contain
+ * \param num_classes Number of classes (will be used only in case of multiclass and specifying initial scores)
+ * \param parameters Additional parameters
+ * \param[out] out Created dataset
+ * \return 0 when succeed, -1 when failure happens
+ */
+LIGHTGBM_C_EXPORT int LGBM_DatasetCreateFromSerializedReference(const void* ref_buffer,
+                                                                int32_t ref_buffer_size,
+                                                                int64_t num_row,
+                                                                int32_t num_classes,
+                                                                const char* parameters,
+                                                                DatasetHandle* out);
+
+/*!
  * \brief Push data to existing dataset, if ``nrow + start_row == num_total_row``, will call ``dataset->FinishLoad``.
  * \param dataset Handle of dataset
  * \param data Pointer to the data space
  * \param data_type Type of ``data`` pointer, can be ``C_API_DTYPE_FLOAT32`` or ``C_API_DTYPE_FLOAT64``
  * \param nrow Number of rows
  * \param ncol Number of columns
  * \param start_row Row start index
@@ -147,14 +212,46 @@
                                            const void* data,
                                            int data_type,
                                            int32_t nrow,
                                            int32_t ncol,
                                            int32_t start_row);
 
 /*!
+ * \brief Push data to existing dataset.
+ *        The general flow for a streaming scenario is:
+ *        1. create Dataset "schema" (e.g. ``LGBM_DatasetCreateFromSampledColumn``)
+ *        2. init them for thread-safe streaming (``LGBM_DatasetInitStreaming``)
+ *        3. push data (``LGBM_DatasetPushRowsWithMetadata`` or ``LGBM_DatasetPushRowsByCSRWithMetadata``)
+ *        4. call ``LGBM_DatasetMarkFinished``
+ * \param dataset Handle of dataset
+ * \param data Pointer to the data space
+ * \param data_type Type of ``data`` pointer, can be ``C_API_DTYPE_FLOAT32`` or ``C_API_DTYPE_FLOAT64``
+ * \param nrow Number of rows
+ * \param ncol Number of feature columns
+ * \param start_row Row start index, i.e., the index at which to start inserting data
+ * \param label Pointer to array with nrow labels
+ * \param weight Optional pointer to array with nrow weights
+ * \param init_score Optional pointer to array with nrow*nclasses initial scores, in column format
+ * \param query Optional pointer to array with nrow query values
+ * \param tid The id of the calling thread, from 0...N-1 threads
+ * \return 0 when succeed, -1 when failure happens
+ */
+LIGHTGBM_C_EXPORT int LGBM_DatasetPushRowsWithMetadata(DatasetHandle dataset,
+                                                       const void* data,
+                                                       int data_type,
+                                                       int32_t nrow,
+                                                       int32_t ncol,
+                                                       int32_t start_row,
+                                                       const float* label,
+                                                       const float* weight,
+                                                       const double* init_score,
+                                                       const int32_t* query,
+                                                       int32_t tid);
+
+/*!
  * \brief Push data to existing dataset, if ``nrow + start_row == num_total_row``, will call ``dataset->FinishLoad``.
  * \param dataset Handle of dataset
  * \param indptr Pointer to row headers
  * \param indptr_type Type of ``indptr``, can be ``C_API_DTYPE_INT32`` or ``C_API_DTYPE_INT64``
  * \param indices Pointer to column indices
  * \param data Pointer to the data space
  * \param data_type Type of ``data`` pointer, can be ``C_API_DTYPE_FLOAT32`` or ``C_API_DTYPE_FLOAT64``
@@ -172,14 +269,63 @@
                                                 int data_type,
                                                 int64_t nindptr,
                                                 int64_t nelem,
                                                 int64_t num_col,
                                                 int64_t start_row);
 
 /*!
+ * \brief Push CSR data to existing dataset. (See ``LGBM_DatasetPushRowsWithMetadata`` for more details.)
+ * \param dataset Handle of dataset
+ * \param indptr Pointer to row headers
+ * \param indptr_type Type of ``indptr``, can be ``C_API_DTYPE_INT32`` or ``C_API_DTYPE_INT64``
+ * \param indices Pointer to column indices
+ * \param data Pointer to the data space
+ * \param data_type Type of ``data`` pointer, can be ``C_API_DTYPE_FLOAT32`` or ``C_API_DTYPE_FLOAT64``
+ * \param nindptr Number of rows in the matrix + 1
+ * \param nelem Number of nonzero elements in the matrix
+ * \param start_row Row start index
+ * \param label Pointer to array with nindptr-1 labels
+ * \param weight Optional pointer to array with nindptr-1 weights
+ * \param init_score Optional pointer to array with (nindptr-1)*nclasses initial scores, in column format
+ * \param query Optional pointer to array with nindptr-1 query values
+ * \param tid The id of the calling thread, from 0...N-1 threads
+ * \return 0 when succeed, -1 when failure happens
+ */
+LIGHTGBM_C_EXPORT int LGBM_DatasetPushRowsByCSRWithMetadata(DatasetHandle dataset,
+                                                            const void* indptr,
+                                                            int indptr_type,
+                                                            const int32_t* indices,
+                                                            const void* data,
+                                                            int data_type,
+                                                            int64_t nindptr,
+                                                            int64_t nelem,
+                                                            int64_t start_row,
+                                                            const float* label,
+                                                            const float* weight,
+                                                            const double* init_score,
+                                                            const int32_t* query,
+                                                            int32_t tid);
+
+/*!
+ * \brief Set whether or not the Dataset waits for a manual MarkFinished call or calls FinishLoad on itself automatically.
+ *        Set to 1 for streaming scenario, and use ``LGBM_DatasetMarkFinished`` to manually finish the Dataset.
+ * \param dataset Handle of dataset
+ * \param wait Whether to wait or not (1 or 0)
+ * \return 0 when succeed, -1 when failure happens
+ */
+LIGHTGBM_C_EXPORT int LGBM_DatasetSetWaitForManualFinish(DatasetHandle dataset, int wait);
+
+/*!
+ * \brief Mark the Dataset as complete by calling ``dataset->FinishLoad``.
+ * \param dataset Handle of dataset
+ * \return 0 when succeed, -1 when failure happens
+ */
+LIGHTGBM_C_EXPORT int LGBM_DatasetMarkFinished(DatasetHandle dataset);
+
+/*!
  * \brief Create a dataset from CSR format.
  * \param indptr Pointer to row headers
  * \param indptr_type Type of ``indptr``, can be ``C_API_DTYPE_INT32`` or ``C_API_DTYPE_INT64``
  * \param indices Pointer to column indices
  * \param data Pointer to the data space
  * \param data_type Type of ``data`` pointer, can be ``C_API_DTYPE_FLOAT32`` or ``C_API_DTYPE_FLOAT64``
  * \param nindptr Number of rows in the matrix + 1
@@ -349,14 +495,25 @@
  * \param filename The name of the file
  * \return 0 when succeed, -1 when failure happens
  */
 LIGHTGBM_C_EXPORT int LGBM_DatasetSaveBinary(DatasetHandle handle,
                                              const char* filename);
 
 /*!
+ * \brief Create a dataset schema representation as a binary byte array (excluding data).
+ * \param handle Handle of dataset
+ * \param[out] out The output byte array
+ * \param[out] out_len The length of the output byte array (returned for convenience)
+ * \return 0 when succeed, -1 when failure happens
+ */
+LIGHTGBM_C_EXPORT int LGBM_DatasetSerializeReferenceToBinary(DatasetHandle handle,
+                                                             ByteBufferHandle* out,
+                                                             int32_t* out_len);
+
+/*!
  * \brief Save dataset to text file, intended for debugging use only.
  * \param handle Handle of dataset
  * \param filename The name of the file
  * \return 0 when succeed, -1 when failure happens
  */
 LIGHTGBM_C_EXPORT int LGBM_DatasetDumpText(DatasetHandle handle,
                                            const char* filename);
@@ -419,31 +576,42 @@
  * \param[out] out The address to hold number of features
  * \return 0 when succeed, -1 when failure happens
  */
 LIGHTGBM_C_EXPORT int LGBM_DatasetGetNumFeature(DatasetHandle handle,
                                                 int* out);
 
 /*!
+ * \brief Get number of bins for feature.
+ * \param handle Handle of dataset
+ * \param feature Index of the feature
+ * \param[out] out The address to hold number of bins
+ * \return 0 when succeed, -1 when failure happens
+ */
+LIGHTGBM_C_EXPORT int LGBM_DatasetGetFeatureNumBin(DatasetHandle handle,
+                                                   int feature,
+                                                   int* out);
+
+/*!
  * \brief Add features from ``source`` to ``target``.
  * \param target The handle of the dataset to add features to
  * \param source The handle of the dataset to take features from
  * \return 0 when succeed, -1 when failure happens
  */
 LIGHTGBM_C_EXPORT int LGBM_DatasetAddFeaturesFrom(DatasetHandle target,
                                                   DatasetHandle source);
 
 /* --- start Booster interfaces */
 
 /*!
-* \brief Get boolean representing whether booster is fitting linear trees.
+* \brief Get int representing whether booster is fitting linear trees.
 * \param handle Handle of booster
 * \param[out] out The address to hold linear trees indicator
 * \return 0 when succeed, -1 when failure happens
 */
-LIGHTGBM_C_EXPORT int LGBM_BoosterGetLinear(BoosterHandle handle, bool* out);
+LIGHTGBM_C_EXPORT int LGBM_BoosterGetLinear(BoosterHandle handle, int* out);
 
 /*!
  * \brief Create a new boosting learner.
  * \param train_data Training dataset
  * \param parameters Parameters in format 'key1=value1 key2=value2'
  * \param[out] out Handle of created booster
  * \return 0 when succeed, -1 when failure happens
@@ -471,14 +639,28 @@
  * \return 0 when succeed, -1 when failure happens
  */
 LIGHTGBM_C_EXPORT int LGBM_BoosterLoadModelFromString(const char* model_str,
                                                       int* out_num_iterations,
                                                       BoosterHandle* out);
 
 /*!
+ * \brief Get parameters as JSON string.
+ * \param handle Handle of booster
+ * \param buffer_len Allocated space for string
+ * \param[out] out_len Actual size of string
+ * \param[out] out_str JSON string containing parameters
+ * \return 0 when succeed, -1 when failure happens
+ */
+LIGHTGBM_C_EXPORT int LGBM_BoosterGetLoadedParam(BoosterHandle handle,
+                                                 int64_t buffer_len,
+                                                 int64_t* out_len,
+                                                 char* out_str);
+
+
+/*!
  * \brief Free space for booster.
  * \param handle Handle of booster to be freed
  * \return 0 when succeed, -1 when failure happens
  */
 LIGHTGBM_C_EXPORT int LGBM_BoosterFree(BoosterHandle handle);
 
 /*!
@@ -558,14 +740,17 @@
                                         const int32_t* leaf_preds,
                                         int32_t nrow,
                                         int32_t ncol);
 
 /*!
  * \brief Update the model by specifying gradient and Hessian directly
  *        (this can be used to support customized loss functions).
+ * \note
+ * The length of the arrays referenced by ``grad`` and ``hess`` must be equal to
+ * ``num_class * num_train_data``, this is not verified by the library, the caller must ensure this.
  * \param handle Handle of booster
  * \param grad The first order derivative (gradient) statistics
  * \param hess The second order derivative (Hessian) statistics
  * \param[out] is_finished 1 means the update was successfully finished (cannot split any more), 0 indicates failure
  * \return 0 when succeed, -1 when failure happens
  */
 LIGHTGBM_C_EXPORT int LGBM_BoosterUpdateOneIterCustom(BoosterHandle handle,
@@ -651,14 +836,25 @@
                                                   const int len,
                                                   int* out_len,
                                                   const size_t buffer_len,
                                                   size_t* out_buffer_len,
                                                   char** out_strs);
 
 /*!
+ * \brief Check that the feature names of the data match the ones used to train the booster.
+ * \param handle Handle of booster
+ * \param data_names Array with the feature names in the data
+ * \param data_num_features Number of features in the data
+ * \return 0 when succeed, -1 when failure happens
+ */
+LIGHTGBM_C_EXPORT int LGBM_BoosterValidateFeatureNames(BoosterHandle handle,
+                                                       const char** data_names,
+                                                       int data_num_features);
+
+/*!
  * \brief Get number of features.
  * \param handle Handle of booster
  * \param[out] out_len Total number of features
  * \return 0 when succeed, -1 when failure happens
  */
 LIGHTGBM_C_EXPORT int LGBM_BoosterGetNumFeature(BoosterHandle handle,
                                                 int* out_len);
@@ -813,24 +1009,24 @@
  * Call ``LGBM_BoosterFreePredictSparse`` to deallocate resources.
  * \param handle Handle of booster
  * \param indptr Pointer to row headers for CSR or column headers for CSC
  * \param indptr_type Type of ``indptr``, can be ``C_API_DTYPE_INT32`` or ``C_API_DTYPE_INT64``
  * \param indices Pointer to column indices for CSR or row indices for CSC
  * \param data Pointer to the data space
  * \param data_type Type of ``data`` pointer, can be ``C_API_DTYPE_FLOAT32`` or ``C_API_DTYPE_FLOAT64``
- * \param nindptr Number of rows in the matrix + 1
+ * \param nindptr Number of entries in ``indptr``
  * \param nelem Number of nonzero elements in the matrix
  * \param num_col_or_row Number of columns for CSR or number of rows for CSC
  * \param predict_type What should be predicted, only feature contributions supported currently
  *   - ``C_API_PREDICT_CONTRIB``: feature contributions (SHAP values)
  * \param start_iteration Start index of the iteration to predict
  * \param num_iteration Number of iterations for prediction, <= 0 means no limit
  * \param parameter Other parameters for prediction, e.g. early stopping for prediction
  * \param matrix_type Type of matrix input and output, can be ``C_API_MATRIX_TYPE_CSR`` or ``C_API_MATRIX_TYPE_CSC``
- * \param[out] out_len Length of output indices and data
+ * \param[out] out_len Length of output data and output indptr (pointer to an array with two entries where to write them)
  * \param[out] out_indptr Pointer to output row headers for CSR or column headers for CSC
  * \param[out] out_indices Pointer to sparse column indices for CSR or row indices for CSC
  * \param[out] out_data Pointer to sparse data space
  * \return 0 when succeed, -1 when failure happens
  */
 LIGHTGBM_C_EXPORT int LGBM_BoosterPredictSparseOutput(BoosterHandle handle,
                                                       const void* indptr,
@@ -1357,15 +1553,21 @@
 static char* LastErrorMsg() { static THREAD_LOCAL char err_msg[512] = "Everything is fine"; return err_msg; }
 
 #ifdef _MSC_VER
   #pragma warning(disable : 4996)
 #endif
 /*!
  * \brief Set string message of the last error.
+ * \note
+ * This will call unsafe ``sprintf`` when compiled using C standards before C99.
  * \param msg Error message
  */
 INLINE_FUNCTION void LGBM_SetLastError(const char* msg) {
+#if !defined(__cplusplus) && (!defined(__STDC__) || (__STDC_VERSION__ < 199901L))
+  sprintf(LastErrorMsg(), "%s", msg);  /* NOLINT(runtime/printf) */
+#else
   const int err_buf_len = 512;
   snprintf(LastErrorMsg(), err_buf_len, "%s", msg);
+#endif
 }
 
 #endif  /* LIGHTGBM_C_API_H_ */
```

### Comparing `lightgbm-3.3.5/compile/include/LightGBM/config.h` & `lightgbm-4.0.0/include/LightGBM/config.h`

 * *Files 3% similar despite different names*

```diff
@@ -74,20 +74,32 @@
   * \param out Value will assign to out if key exists
   * \return True if key exists
   */
   inline static bool GetBool(
     const std::unordered_map<std::string, std::string>& params,
     const std::string& name, bool* out);
 
-  static void KV2Map(std::unordered_map<std::string, std::string>* params, const char* kv);
+  /*!
+  * \brief Sort aliases by length and then alphabetically
+  * \param x Alias 1
+  * \param y Alias 2
+  * \return true if x has higher priority than y
+  */
+  inline static bool SortAlias(const std::string& x, const std::string& y);
+
+  static void KeepFirstValues(const std::unordered_map<std::string, std::vector<std::string>>& params, std::unordered_map<std::string, std::string>* out);
+  static void KV2Map(std::unordered_map<std::string, std::vector<std::string>>* params, const char* kv);
+  static void SetVerbosity(const std::unordered_map<std::string, std::vector<std::string>>& params);
   static std::unordered_map<std::string, std::string> Str2Map(const char* parameters);
 
+  #ifndef __NVCC__
   #pragma region Parameters
 
   #pragma region Core Parameters
+  #endif  // __NVCC__
 
   // [no-save]
   // [doc-only]
   // alias = config_file
   // desc = path of config file
   // desc = **Note**: can be used only in CLI version
   std::string config = "";
@@ -137,35 +149,43 @@
   // descl2 = ``rank_xendcg`` is faster than and achieves the similar performance as ``lambdarank``
   // descl2 = label should be ``int`` type, and larger number represents the higher relevance (e.g. 0:bad, 1:fair, 2:good, 3:perfect)
   std::string objective = "regression";
 
   // [doc-only]
   // type = enum
   // alias = boosting_type, boost
-  // options = gbdt, rf, dart, goss
+  // options = gbdt, rf, dart
   // desc = ``gbdt``, traditional Gradient Boosting Decision Tree, aliases: ``gbrt``
   // desc = ``rf``, Random Forest, aliases: ``random_forest``
   // desc = ``dart``, `Dropouts meet Multiple Additive Regression Trees <https://arxiv.org/abs/1505.01866>`__
-  // desc = ``goss``, Gradient-based One-Side Sampling
   // descl2 = **Note**: internally, LightGBM uses ``gbdt`` mode for the first ``1 / learning_rate`` iterations
   std::string boosting = "gbdt";
 
+  // [doc-only]
+  // type = enum
+  // options = bagging, goss
+  // desc = ``bagging``, Randomly Bagging Sampling
+  // descl2 = **Note**: ``bagging`` is only effective when ``bagging_freq > 0`` and ``bagging_fraction < 1.0``
+  // desc = ``goss``, Gradient-based One-Side Sampling
+  // desc = *New in 4.0.0*
+  std::string data_sample_strategy = "bagging";
+
   // alias = train, train_data, train_data_file, data_filename
   // desc = path of training data, LightGBM will train from this data
   // desc = **Note**: can be used only in CLI version
   std::string data = "";
 
   // alias = test, valid_data, valid_data_file, test_data, test_data_file, valid_filenames
   // default = ""
   // desc = path(s) of validation/test data, LightGBM will output metrics for these data
   // desc = support multiple validation data, separated by ``,``
   // desc = **Note**: can be used only in CLI version
   std::vector<std::string> valid;
 
-  // alias = num_iteration, n_iter, num_tree, num_trees, num_round, num_rounds, num_boost_round, n_estimators, max_iter
+  // alias = num_iteration, n_iter, num_tree, num_trees, num_round, num_rounds, nrounds, num_boost_round, n_estimators, max_iter
   // check = >=0
   // desc = number of boosting iterations
   // desc = **Note**: internally, LightGBM constructs ``num_class * num_iterations`` trees for multi-class classification problems
   int num_iterations = 100;
 
   // alias = shrinkage_rate, eta
   // check = >0.0
@@ -188,28 +208,32 @@
   // desc = ``feature``, feature parallel tree learner, aliases: ``feature_parallel``
   // desc = ``data``, data parallel tree learner, aliases: ``data_parallel``
   // desc = ``voting``, voting parallel tree learner, aliases: ``voting_parallel``
   // desc = refer to `Distributed Learning Guide <./Parallel-Learning-Guide.rst>`__ to get more details
   std::string tree_learner = "serial";
 
   // alias = num_thread, nthread, nthreads, n_jobs
+  // desc = used only in ``train``, ``prediction`` and ``refit`` tasks or in correspondent functions of language-specific packages
   // desc = number of threads for LightGBM
   // desc = ``0`` means default number of threads in OpenMP
   // desc = for the best speed, set this to the number of **real CPU cores**, not the number of threads (most CPUs use `hyper-threading <https://en.wikipedia.org/wiki/Hyper-threading>`__ to generate 2 threads per CPU core)
   // desc = do not set it too large if your dataset is small (for instance, do not use 64 threads for a dataset with 10,000 rows)
   // desc = be aware a task manager or any similar CPU monitoring tool might report that cores not being fully utilized. **This is normal**
   // desc = for distributed learning, do not use all CPU cores because this will cause poor performance for the network communication
   // desc = **Note**: please **don't** change this during training, especially when running multiple jobs simultaneously by external packages, otherwise it may cause undesirable errors
   int num_threads = 0;
 
   // [doc-only]
   // type = enum
   // options = cpu, gpu, cuda
   // alias = device
-  // desc = device for the tree learning, you can use GPU to achieve the faster learning
+  // desc = device for the tree learning
+  // desc = ``cpu`` supports all LightGBM functionality and is portable across the widest range of operating systems and hardware
+  // desc = ``cuda`` offers faster training than ``gpu`` or ``cpu``, but only works on GPUs supporting CUDA
+  // desc = ``gpu`` can be faster than ``cpu`` and works on a wider range of GPUs than CUDA
   // desc = **Note**: it is recommended to use the smaller ``max_bin`` (e.g. 63) to get the better speed up
   // desc = **Note**: for the faster speed, GPU uses 32-bit float point to sum up by default, so this may affect the accuracy for some tasks. You can set ``gpu_use_dp=true`` to enable 64-bit float point, but it will slow down the training
   // desc = **Note**: refer to `Installation Guide <./Installation-Guide.rst#build-gpu-version>`__ to build LightGBM with GPU support
   std::string device_type = "cpu";
 
   // [doc-only]
   // alias = random_seed, random_state
@@ -223,17 +247,19 @@
   // desc = setting this to ``true`` should ensure the stable results when using the same data and the same parameters (and different ``num_threads``)
   // desc = when you use the different seeds, different LightGBM versions, the binaries compiled by different compilers, or in different systems, the results are expected to be different
   // desc = you can `raise issues <https://github.com/microsoft/LightGBM/issues>`__ in LightGBM GitHub repo when you meet the unstable results
   // desc = **Note**: setting this to ``true`` may slow down the training
   // desc = **Note**: to avoid potential instability due to numerical issues, please set ``force_col_wise=true`` or ``force_row_wise=true`` when setting ``deterministic=true``
   bool deterministic = false;
 
+  #ifndef __NVCC__
   #pragma endregion
 
   #pragma region Learning Control Parameters
+  #endif  // __NVCC__
 
   // desc = used only with ``cpu`` device type
   // desc = set this to ``true`` to force col-wise histogram building
   // desc = enabling this is recommended when:
   // descl2 = the number of columns is large, or the total number of bins is large
   // descl2 = ``num_threads`` is large, e.g. ``> 20``
   // descl2 = you want to reduce memory cost
@@ -242,15 +268,15 @@
   bool force_col_wise = false;
 
   // desc = used only with ``cpu`` device type
   // desc = set this to ``true`` to force row-wise histogram building
   // desc = enabling this is recommended when:
   // descl2 = the number of data points is large, and the total number of bins is relatively small
   // descl2 = ``num_threads`` is relatively small, e.g. ``<= 16``
-  // descl2 = you want to use small ``bagging_fraction`` or ``goss`` boosting to speed up
+  // descl2 = you want to use small ``bagging_fraction`` or ``goss`` sample strategy to speed up
   // desc = **Note**: setting this to ``true`` will double the memory cost for Dataset object. If you have not enough memory, you can try setting ``force_col_wise=true``
   // desc = **Note**: when both ``force_col_wise`` and ``force_row_wise`` are ``false``, LightGBM will firstly try them both, and then use the faster one. To remove the overhead of testing set the faster one to ``true`` manually
   // desc = **Note**: this parameter cannot be used at the same time with ``force_col_wise``, choose only one of them
   bool force_row_wise = false;
 
   // alias = hist_pool_size
   // desc = max cache size in MB for historical histogram
@@ -304,15 +330,15 @@
   // desc = **Note**: if both ``pos_bagging_fraction`` and ``neg_bagging_fraction`` are set to ``1.0``,  balanced bagging is disabled
   // desc = **Note**: if balanced bagging is enabled, ``bagging_fraction`` will be ignored
   double neg_bagging_fraction = 1.0;
 
   // alias = subsample_freq
   // desc = frequency for bagging
   // desc = ``0`` means disable bagging; ``k`` means perform bagging at every ``k`` iteration. Every ``k``-th iteration, LightGBM will randomly select ``bagging_fraction * 100 %`` of the data to use for the next ``k`` iterations
-  // desc = **Note**: to enable bagging, ``bagging_fraction`` should be set to value smaller than ``1.0`` as well
+  // desc = **Note**: bagging is only effective when ``0.0 < bagging_fraction < 1.0``
   int bagging_freq = 0;
 
   // alias = bagging_fraction_seed
   // desc = random seed for bagging
   int bagging_seed = 3;
 
   // alias = sub_feature, colsample_bytree
@@ -520,15 +546,15 @@
 
   // check = >= 0.0
   // desc = controls smoothing applied to tree nodes
   // desc = helps prevent overfitting on leaves with few samples
   // desc = if set to zero, no smoothing is applied
   // desc = if ``path_smooth > 0`` then ``min_data_in_leaf`` must be at least ``2``
   // desc = larger values give stronger regularization
-  // descl2 = the weight of each node is ``(n / path_smooth) * w + w_p / (n / path_smooth + 1)``, where ``n`` is the number of samples in the node, ``w`` is the optimal node weight to minimise the loss (approximately ``-sum_gradients / sum_hessians``), and ``w_p`` is the weight of the parent node
+  // descl2 = the weight of each node is ``w * (n / path_smooth) / (n / path_smooth + 1) + w_p / (n / path_smooth + 1)``, where ``n`` is the number of samples in the node, ``w`` is the optimal node weight to minimise the loss (approximately ``-sum_gradients / sum_hessians``), and ``w_p`` is the weight of the parent node
   // descl2 = note that the parent output ``w_p`` itself has smoothing applied, unless it is the root node, so that the smoothing effect accumulates with the tree depth
   double path_smooth = 0;
 
   // desc = controls which features can appear in the same branch
   // desc = by default interaction constraints are disabled, to enable them you can specify
   // descl2 = for CLI, lists separated by commas, e.g. ``[0,1,2],[2,3]``
   // descl2 = for Python-package, list of lists, e.g. ``[[0, 1, 2], [2, 3]]``
@@ -563,24 +589,55 @@
   // [no-save]
   // alias = save_period
   // desc = frequency of saving model file snapshot
   // desc = set this to positive value to enable this function. For example, the model file will be snapshotted at each iteration if ``snapshot_freq=1``
   // desc = **Note**: can be used only in CLI version
   int snapshot_freq = -1;
 
+  // [no-save]
+  // desc = whether to use gradient quantization when training
+  // desc = enabling this will discretize (quantize) the gradients and hessians into bins of ``num_grad_quant_bins``
+  // desc = with quantized training, most arithmetics in the training process will be integer operations
+  // desc = gradient quantization can accelerate training, with little accuracy drop in most cases
+  // desc = **Note**: can be used only with ``device_type = cpu``
+  // desc = *New in version 4.0.0*
+  bool use_quantized_grad = false;
+
+  // [no-save]
+  // desc = number of bins to quantization gradients and hessians
+  // desc = with more bins, the quantized training will be closer to full precision training
+  // desc = **Note**: can be used only with ``device_type = cpu``
+  // desc = *New in 4.0.0*
+  int num_grad_quant_bins = 4;
+
+  // [no-save]
+  // desc = whether to renew the leaf values with original gradients when quantized training
+  // desc = renewing is very helpful for good quantized training accuracy for ranking objectives
+  // desc = **Note**: can be used only with ``device_type = cpu``
+  // desc = *New in 4.0.0*
+  bool quant_train_renew_leaf = false;
+
+  // [no-save]
+  // desc = whether to use stochastic rounding in gradient quantization
+  // desc = *New in 4.0.0*
+  bool stochastic_rounding = true;
+
+  #ifndef __NVCC__
   #pragma endregion
 
   #pragma region IO Parameters
 
   #pragma region Dataset Parameters
+  #endif  // __NVCC__
 
   // alias = linear_trees
   // desc = fit piecewise linear gradient boosting tree
   // descl2 = tree splits are chosen in the usual way, but the model at each leaf is linear instead of constant
   // descl2 = the linear model at each leaf includes all the numerical features in that leaf's branch
+  // descl2 = the first tree has constant leaf values
   // descl2 = categorical features are used for splits as normal but are not used in the linear models
   // descl2 = missing values should not be encoded as ``0``. Use ``np.nan`` for Python, ``NA`` for the CLI, and ``NA``, ``NA_real_``, or ``NA_integer_`` for R
   // descl2 = it is recommended to rescale data before training so that features have similar mean and standard deviation
   // descl2 = **Note**: only works with CPU and ``serial`` tree learner
   // descl2 = **Note**: ``regression_l1`` objective is not supported with linear tree boosting
   // descl2 = **Note**: setting ``linear_tree=true`` significantly increases the memory use of LightGBM
   // descl2 = **Note**: if you specify ``monotone_constraints``, constraints will be enforced when choosing the split points, but not when fitting the linear models on leaves
@@ -665,14 +722,15 @@
   // type = int or string
   // alias = weight
   // desc = used to specify the weight column
   // desc = use number for index, e.g. ``weight=0`` means column\_0 is the weight
   // desc = add a prefix ``name:`` for column name, e.g. ``weight=name:weight``
   // desc = **Note**: works only in case of loading data directly from text file
   // desc = **Note**: index starts from ``0`` and it doesn't count the label column when passing type is ``int``, e.g. when label is column\_0, and weight is column\_1, the correct parameter is ``weight=0``
+  // desc = **Note**: weights should be non-negative
   std::string weight_column = "";
 
   // type = int or string
   // alias = group, group_id, query_column, query, query_id
   // desc = used to specify the query/group id column
   // desc = use number for index, e.g. ``query=0`` means column\_0 is the query id
   // desc = add a prefix ``name:`` for column name, e.g. ``query=name:query_id``
@@ -692,20 +750,21 @@
   std::string ignore_column = "";
 
   // type = multi-int or string
   // alias = cat_feature, categorical_column, cat_column, categorical_features
   // desc = used to specify categorical features
   // desc = use number for index, e.g. ``categorical_feature=0,1,2`` means column\_0, column\_1 and column\_2 are categorical features
   // desc = add a prefix ``name:`` for column name, e.g. ``categorical_feature=name:c1,c2,c3`` means c1, c2 and c3 are categorical features
-  // desc = **Note**: only supports categorical with ``int`` type (not applicable for data represented as pandas DataFrame in Python-package)
+  // desc = **Note**: all values will be cast to ``int32`` (integer codes will be extracted from pandas categoricals in the Python-package)
   // desc = **Note**: index starts from ``0`` and it doesn't count the label column when passing type is ``int``
   // desc = **Note**: all values should be less than ``Int32.MaxValue`` (2147483647)
   // desc = **Note**: using large values could be memory consuming. Tree decision rule works best when categorical features are presented by consecutive integers starting from zero
   // desc = **Note**: all negative values will be treated as **missing values**
   // desc = **Note**: the output cannot be monotonically constrained with respect to a categorical feature
+  // desc = **Note**: floating point numbers in categorical features will be rounded towards 0
   std::string categorical_feature = "";
 
   // desc = path to a ``.json`` file that specifies bin upper bounds for some or all features
   // desc = ``.json`` file should contain an array of objects, each containing the word ``feature`` (integer feature index) and ``bin_upper_bound`` (array of thresholds for binning)
   // desc = see `this file <https://github.com/microsoft/LightGBM/tree/master/examples/regression/forced_bins.json>`__ as an example
   std::string forcedbins_filename = "";
 
@@ -716,17 +775,25 @@
   // desc = **Note**: can be used only in CLI version; for language-specific packages you can use the correspondent function
   bool save_binary = false;
 
   // desc = use precise floating point number parsing for text parser (e.g. CSV, TSV, LibSVM input)
   // desc = **Note**: setting this to ``true`` may lead to much slower text parsing
   bool precise_float_parser = false;
 
+  // desc = path to a ``.json`` file that specifies customized parser initialized configuration
+  // desc = see `lightgbm-transform <https://github.com/microsoft/lightgbm-transform>`__ for usage examples
+  // desc = **Note**: ``lightgbm-transform`` is not maintained by LightGBM's maintainers. Bug reports or feature requests should go to `issues page <https://github.com/microsoft/lightgbm-transform/issues>`__
+  // desc = *New in 4.0.0*
+  std::string parser_config_file = "";
+
+  #ifndef __NVCC__
   #pragma endregion
 
   #pragma region Predict Parameters
+  #endif  // __NVCC__
 
   // [no-save]
   // desc = used only in ``prediction`` task
   // desc = used to specify from which iteration to start the prediction
   // desc = ``<= 0`` means from the first iteration
   int start_iteration_predict = 0;
 
@@ -766,14 +833,15 @@
   // desc = if ``true``, LightGBM will attempt to predict on whatever data you provide. This is dangerous because you might get incorrect predictions, but you could use it in situations where it is difficult or expensive to generate some features and you are very confident that they were never chosen for splits in the model
   // desc = **Note**: be very careful setting this parameter to ``true``
   bool predict_disable_shape_check = false;
 
   // [no-save]
   // desc = used only in ``prediction`` task
   // desc = used only in ``classification`` and ``ranking`` applications
+  // desc = used only for predicting normal or raw scores
   // desc = if ``true``, will use early-stopping to speed up the prediction. May affect the accuracy
   // desc = **Note**: cannot be used with ``rf`` boosting type or custom objective function
   bool pred_early_stop = false;
 
   // [no-save]
   // desc = used only in ``prediction`` task
   // desc = the frequency of checking early-stopping prediction
@@ -787,17 +855,19 @@
   // [no-save]
   // alias = predict_result, prediction_result, predict_name, prediction_name, pred_name, name_pred
   // desc = used only in ``prediction`` task
   // desc = filename of prediction result
   // desc = **Note**: can be used only in CLI version
   std::string output_result = "LightGBM_predict_result.txt";
 
+  #ifndef __NVCC__
   #pragma endregion
 
   #pragma region Convert Parameters
+  #endif  // __NVCC__
 
   // [no-save]
   // desc = used only in ``convert_model`` task
   // desc = only ``cpp`` is supported yet; for conversion model to other languages consider using `m2cgen <https://github.com/BayesWitnesses/m2cgen>`__ utility
   // desc = if ``convert_model_language`` is set and ``task=train``, the model will be also converted
   // desc = **Note**: can be used only in CLI version
   std::string convert_model_language = "";
@@ -805,19 +875,21 @@
   // [no-save]
   // alias = convert_model_file
   // desc = used only in ``convert_model`` task
   // desc = output filename of converted model
   // desc = **Note**: can be used only in CLI version
   std::string convert_model = "gbdt_prediction.cpp";
 
+  #ifndef __NVCC__
   #pragma endregion
 
   #pragma endregion
 
   #pragma region Objective Parameters
+  #endif  // __NVCC__
 
   // desc = used only in ``rank_xendcg`` objective
   // desc = random seed for objectives, if random process is needed
   int objective_seed = 5;
 
   // check = >0
   // alias = num_classes
@@ -889,17 +961,19 @@
   // type = multi-double
   // default = 0,1,3,7,15,31,63,...,2^30-1
   // desc = used only in ``lambdarank`` application
   // desc = relevant gain for labels. For example, the gain of label ``2`` is ``3`` in case of default label gains
   // desc = separate by ``,``
   std::vector<double> label_gain;
 
+  #ifndef __NVCC__
   #pragma endregion
 
   #pragma region Metric Parameters
+  #endif  // __NVCC__
 
   // [doc-only]
   // alias = metrics, metric_types
   // default = ""
   // type = multi-enum
   // desc = metric(s) to be evaluated on the evaluation set(s)
   // descl2 = ``""`` (empty string or not specified) means that metric corresponding to specified ``objective`` will be used (this is possible only for pre-defined objective functions, otherwise no evaluation metric will be added)
@@ -963,17 +1037,19 @@
   // desc = used only with ``auc_mu`` metric
   // desc = list representing flattened matrix (in row-major order) giving loss weights for classification errors
   // desc = list should have ``n * n`` elements, where ``n`` is the number of classes
   // desc = the matrix co-ordinate ``[i, j]`` should correspond to the ``i * n + j``-th element of the list
   // desc = if not specified, will use equal weights for all classes
   std::vector<double> auc_mu_weights;
 
+  #ifndef __NVCC__
   #pragma endregion
 
   #pragma region Network Parameters
+  #endif  // __NVCC__
 
   // check = >0
   // alias = num_machine
   // desc = the number of machines for distributed learning application
   // desc = this parameter is needed to be set in both **socket** and **mpi** versions
   int num_machines = 1;
 
@@ -994,17 +1070,19 @@
   // desc = **Note**: can be used only in CLI version
   std::string machine_list_filename = "";
 
   // alias = workers, nodes
   // desc = list of machines in the following format: ``ip1:port1,ip2:port2``
   std::string machines = "";
 
+  #ifndef __NVCC__
   #pragma endregion
 
   #pragma region GPU Parameters
+  #endif  // __NVCC__
 
   // desc = OpenCL platform ID. Usually each GPU vendor exposes one OpenCL platform
   // desc = ``-1`` means the system-wide default platform
   // desc = **Note**: refer to `GPU Targets <./GPU-Targets.rst#query-opencl-devices-in-your-system>`__ for more details
   int gpu_platform_id = -1;
 
   // desc = OpenCL device ID in the specified platform. Each GPU in the selected platform has a unique device ID
@@ -1017,27 +1095,32 @@
   bool gpu_use_dp = false;
 
   // check = >0
   // desc = number of GPUs
   // desc = **Note**: can be used only in CUDA implementation
   int num_gpu = 1;
 
+  #ifndef __NVCC__
   #pragma endregion
 
   #pragma endregion
+  #endif  // __NVCC__
 
   size_t file_load_progress_interval_bytes = size_t(10) * 1024 * 1024 * 1024;
 
   bool is_parallel = false;
   bool is_data_based_parallel = false;
   LIGHTGBM_EXPORT void Set(const std::unordered_map<std::string, std::string>& params);
   static const std::unordered_map<std::string, std::string>& alias_table();
+  static const std::unordered_map<std::string, std::vector<std::string>>& parameter2aliases();
   static const std::unordered_set<std::string>& parameter_set();
   std::vector<std::vector<double>> auc_mu_weights_matrix;
   std::vector<std::vector<int>> interaction_constraints_vector;
+  static const std::unordered_map<std::string, std::string>& ParameterTypes();
+  static const std::string DumpAliases();
 
  private:
   void CheckParamConflict();
   void GetMembersFromString(const std::unordered_map<std::string, std::string>& params);
   std::string SaveMembersToString() const;
   void GetAucMuWeights();
   void GetInteractionConstraints();
@@ -1094,25 +1177,27 @@
                  name.c_str(), params.at(name).c_str());
     }
     return true;
   }
   return false;
 }
 
+inline bool Config::SortAlias(const std::string& x, const std::string& y) {
+  return x.size() < y.size() || (x.size() == y.size() && x < y);
+}
+
 struct ParameterAlias {
   static void KeyAliasTransform(std::unordered_map<std::string, std::string>* params) {
     std::unordered_map<std::string, std::string> tmp_map;
     for (const auto& pair : *params) {
       auto alias = Config::alias_table().find(pair.first);
       if (alias != Config::alias_table().end()) {  // found alias
         auto alias_set = tmp_map.find(alias->second);
         if (alias_set != tmp_map.end()) {  // alias already set
-                                           // set priority by length & alphabetically to ensure reproducible behavior
-          if (alias_set->second.size() < pair.first.size() ||
-            (alias_set->second.size() == pair.first.size() && alias_set->second < pair.first)) {
+          if (Config::SortAlias(alias_set->second, pair.first)) {
             Log::Warning("%s is set with %s=%s, %s=%s will be ignored. Current value: %s=%s",
                          alias->second.c_str(), alias_set->second.c_str(), params->at(alias_set->second).c_str(),
                          pair.first.c_str(), pair.second.c_str(), alias->second.c_str(), params->at(alias_set->second).c_str());
           } else {
             Log::Warning("%s is set with %s=%s, will be overridden by %s=%s. Current value: %s=%s",
                          alias->second.c_str(), alias_set->second.c_str(), params->at(alias_set->second).c_str(),
                          pair.first.c_str(), pair.second.c_str(), alias->second.c_str(), pair.second.c_str());
```

### Comparing `lightgbm-3.3.5/compile/include/LightGBM/cuda/vector_cudahost.h` & `lightgbm-4.0.0/include/LightGBM/cuda/vector_cudahost.h`

 * *Files 9% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /*!
- * Copyright (c) 2020 IBM Corporation. All rights reserved.
+ * Copyright (c) 2020 IBM Corporation, Microsoft Corporation. All rights reserved.
  * Licensed under the MIT License. See LICENSE file in the project root for license information.
  */
 #ifndef LIGHTGBM_CUDA_VECTOR_CUDAHOST_H_
 #define LIGHTGBM_CUDA_VECTOR_CUDAHOST_H_
 
 #include <LightGBM/utils/common.h>
 
@@ -38,15 +38,15 @@
 struct CHAllocator {
   typedef T value_type;
   CHAllocator() {}
   template <class U> CHAllocator(const CHAllocator<U>& other);
   T* allocate(std::size_t n) {
     T* ptr;
     if (n == 0) return NULL;
-    n = (n + kAlignedSize - 1) & -kAlignedSize;
+    n = SIZE_ALIGNED(n);
     #ifdef USE_CUDA
       if (LGBM_config_::current_device == lgbm_device_cuda) {
         cudaError_t ret = cudaHostAlloc(&ptr, n*sizeof(T), cudaHostAllocPortable);
         if (ret != cudaSuccess) {
           Log::Warning("Defaulting to malloc in CHAllocator!!!");
           ptr = reinterpret_cast<T*>(_mm_malloc(n*sizeof(T), 16));
         }
```

### Comparing `lightgbm-3.3.5/compile/include/LightGBM/dataset.h` & `lightgbm-4.0.0/include/LightGBM/tree.h`

 * *Files 24% similar despite different names*

```diff
@@ -1,729 +1,729 @@
 /*!
  * Copyright (c) 2016 Microsoft Corporation. All rights reserved.
  * Licensed under the MIT License. See LICENSE file in the project root for license information.
  */
-#ifndef LIGHTGBM_DATASET_H_
-#define LIGHTGBM_DATASET_H_
+#ifndef LIGHTGBM_TREE_H_
+#define LIGHTGBM_TREE_H_
 
-#include <LightGBM/config.h>
-#include <LightGBM/feature_group.h>
+#include <LightGBM/dataset.h>
 #include <LightGBM/meta.h>
-#include <LightGBM/train_share_states.h>
-#include <LightGBM/utils/openmp_wrapper.h>
-#include <LightGBM/utils/random.h>
-#include <LightGBM/utils/text_reader.h>
 
 #include <string>
-#include <functional>
+#include <map>
 #include <memory>
-#include <mutex>
-#include <unordered_set>
-#include <utility>
+#include <unordered_map>
 #include <vector>
 
 namespace LightGBM {
 
-/*! \brief forward declaration */
-class DatasetLoader;
+#define kCategoricalMask (1)
+#define kDefaultLeftMask (2)
+
 /*!
-* \brief This class is used to store some meta(non-feature) data for training data,
-*        e.g. labels, weights, initial scores, query level information.
-*
-*        Some details:
-*        1. Label, used for training.
-*        2. Weights, weighs of records, optional
-*        3. Query Boundaries, necessary for LambdaRank.
-*           The documents of i-th query is in [ query_boundaries[i], query_boundaries[i+1] )
-*        4. Query Weights, auto calculate by weights and query_boundaries(if both of them are existed)
-*           the weight for i-th query is sum(query_boundaries[i] , .., query_boundaries[i+1]) / (query_boundaries[i + 1] -  query_boundaries[i+1])
-*        5. Initial score. optional. if existing, the model will boost from this score, otherwise will start from 0.
+* \brief Tree model
 */
-class Metadata {
+class Tree {
  public:
   /*!
-  * \brief Null constructor
-  */
-  Metadata();
-  /*!
-  * \brief Initialization will load query level information, since it is need for sampling data
-  * \param data_filename Filename of data
-  */
-  void Init(const char* data_filename);
-  /*!
-  * \brief init as subset
-  * \param metadata Filename of data
-  * \param used_indices
-  * \param num_used_indices
-  */
-  void Init(const Metadata& metadata, const data_size_t* used_indices, data_size_t num_used_indices);
-  /*!
-  * \brief Initial with binary memory
-  * \param memory Pointer to memory
-  */
-  void LoadFromMemory(const void* memory);
-  /*! \brief Destructor */
-  ~Metadata();
-
-  /*!
-  * \brief Initial work, will allocate space for label, weight(if exists) and query(if exists)
-  * \param num_data Number of training data
-  * \param weight_idx Index of weight column, < 0 means doesn't exists
-  * \param query_idx Index of query id column, < 0 means doesn't exists
+  * \brief Constructor
+  * \param max_leaves The number of max leaves
+  * \param track_branch_features Whether to keep track of ancestors of leaf nodes
+  * \param is_linear Whether the tree has linear models at each leaf
   */
-  void Init(data_size_t num_data, int weight_idx, int query_idx);
-
-  /*!
-  * \brief Partition label by used indices
-  * \param used_indices Indices of local used
-  */
-  void PartitionLabel(const std::vector<data_size_t>& used_indices);
-
-  /*!
-  * \brief Partition meta data according to local used indices if need
-  * \param num_all_data Number of total training data, including other machines' data on distributed learning
-  * \param used_data_indices Indices of local used training data
-  */
-  void CheckOrPartition(data_size_t num_all_data,
-                        const std::vector<data_size_t>& used_data_indices);
-
-  void SetLabel(const label_t* label, data_size_t len);
-
-  void SetWeights(const label_t* weights, data_size_t len);
-
-  void SetQuery(const data_size_t* query, data_size_t len);
+  explicit Tree(int max_leaves, bool track_branch_features, bool is_linear);
 
   /*!
-  * \brief Set initial scores
-  * \param init_score Initial scores, this class will manage memory for init_score.
+  * \brief Constructor, from a string
+  * \param str Model string
+  * \param used_len used count of str
   */
-  void SetInitScore(const double* init_score, data_size_t len);
+  Tree(const char* str, size_t* used_len);
 
+  virtual ~Tree() noexcept = default;
 
   /*!
-  * \brief Save binary data to file
-  * \param file File want to write
+  * \brief Performing a split on tree leaves.
+  * \param leaf Index of leaf to be split
+  * \param feature Index of feature; the converted index after removing useless features
+  * \param real_feature Index of feature, the original index on data
+  * \param threshold_bin Threshold(bin) of split
+  * \param threshold_double Threshold on feature value
+  * \param left_value Model Left child output
+  * \param right_value Model Right child output
+  * \param left_cnt Count of left child
+  * \param right_cnt Count of right child
+  * \param left_weight Weight of left child
+  * \param right_weight Weight of right child
+  * \param gain Split gain
+  * \param missing_type missing type
+  * \param default_left default direction for missing value
+  * \return The index of new leaf.
   */
-  void SaveBinaryToFile(const VirtualFileWriter* writer) const;
+  int Split(int leaf, int feature, int real_feature, uint32_t threshold_bin,
+            double threshold_double, double left_value, double right_value,
+            int left_cnt, int right_cnt, double left_weight, double right_weight,
+            float gain, MissingType missing_type, bool default_left);
 
   /*!
-  * \brief Get sizes in byte of this object
+  * \brief Performing a split on tree leaves, with categorical feature
+  * \param leaf Index of leaf to be split
+  * \param feature Index of feature; the converted index after removing useless features
+  * \param real_feature Index of feature, the original index on data
+  * \param threshold_bin Threshold(bin) of split, use bitset to represent
+  * \param num_threshold_bin size of threshold_bin
+  * \param threshold Thresholds of real feature value, use bitset to represent
+  * \param num_threshold size of threshold
+  * \param left_value Model Left child output
+  * \param right_value Model Right child output
+  * \param left_cnt Count of left child
+  * \param right_cnt Count of right child
+  * \param left_weight Weight of left child
+  * \param right_weight Weight of right child
+  * \param gain Split gain
+  * \return The index of new leaf.
   */
-  size_t SizesInByte() const;
+  int SplitCategorical(int leaf, int feature, int real_feature, const uint32_t* threshold_bin, int num_threshold_bin,
+                       const uint32_t* threshold, int num_threshold, double left_value, double right_value,
+                       int left_cnt, int right_cnt, double left_weight, double right_weight, float gain, MissingType missing_type);
 
-  /*!
-  * \brief Get pointer of label
-  * \return Pointer of label
-  */
-  inline const label_t* label() const { return label_.data(); }
+  /*! \brief Get the output of one leaf */
+  inline double LeafOutput(int leaf) const { return leaf_value_[leaf]; }
 
-  /*!
-  * \brief Set label for one record
-  * \param idx Index of this record
-  * \param value Label value of this record
-  */
-  inline void SetLabelAt(data_size_t idx, label_t value) {
-    label_[idx] = value;
+  /*! \brief Set the output of one leaf */
+  inline void SetLeafOutput(int leaf, double output) {
+    leaf_value_[leaf] = MaybeRoundToZero(output);
   }
 
   /*!
-  * \brief Set Weight for one record
-  * \param idx Index of this record
-  * \param value Weight value of this record
+  * \brief Adding prediction value of this tree model to scores
+  * \param data The dataset
+  * \param num_data Number of total data
+  * \param score Will add prediction to score
   */
-  inline void SetWeightAt(data_size_t idx, label_t value) {
-    weights_[idx] = value;
-  }
+  virtual void AddPredictionToScore(const Dataset* data,
+                            data_size_t num_data,
+                            double* score) const;
 
   /*!
-  * \brief Set Query Id for one record
-  * \param idx Index of this record
-  * \param value Query Id value of this record
+  * \brief Adding prediction value of this tree model to scores
+  * \param data The dataset
+  * \param used_data_indices Indices of used data
+  * \param num_data Number of total data
+  * \param score Will add prediction to score
   */
-  inline void SetQueryAt(data_size_t idx, data_size_t value) {
-    queries_[idx] = static_cast<data_size_t>(value);
-  }
+  virtual void AddPredictionToScore(const Dataset* data,
+                            const data_size_t* used_data_indices,
+                            data_size_t num_data, double* score) const;
 
   /*!
-  * \brief Get weights, if not exists, will return nullptr
-  * \return Pointer of weights
+  * \brief Get upper bound leaf value of this tree model
   */
-  inline const label_t* weights() const {
-    if (!weights_.empty()) {
-      return weights_.data();
-    } else {
-      return nullptr;
-    }
-  }
+  double GetUpperBoundValue() const;
 
   /*!
-  * \brief Get data boundaries on queries, if not exists, will return nullptr
-  *        we assume data will order by query,
-  *        the interval of [query_boundaris[i], query_boundaris[i+1])
-  *        is the data indices for query i.
-  * \return Pointer of data boundaries on queries
+  * \brief Get lower bound leaf value of this tree model
   */
-  inline const data_size_t* query_boundaries() const {
-    if (!query_boundaries_.empty()) {
-      return query_boundaries_.data();
-    } else {
-      return nullptr;
-    }
-  }
+  double GetLowerBoundValue() const;
 
   /*!
-  * \brief Get Number of queries
-  * \return Number of queries
+  * \brief Prediction on one record
+  * \param feature_values Feature value of this record
+  * \return Prediction result
   */
-  inline data_size_t num_queries() const { return num_queries_; }
+  inline double Predict(const double* feature_values) const;
+  inline double PredictByMap(const std::unordered_map<int, double>& feature_values) const;
 
-  /*!
-  * \brief Get weights for queries, if not exists, will return nullptr
-  * \return Pointer of weights for queries
-  */
-  inline const label_t* query_weights() const {
-    if (!query_weights_.empty()) {
-      return query_weights_.data();
-    } else {
-      return nullptr;
-    }
-  }
+  inline int PredictLeafIndex(const double* feature_values) const;
+  inline int PredictLeafIndexByMap(const std::unordered_map<int, double>& feature_values) const;
 
-  /*!
-  * \brief Get initial scores, if not exists, will return nullptr
-  * \return Pointer of initial scores
-  */
-  inline const double* init_score() const {
-    if (!init_score_.empty()) {
-      return init_score_.data();
-    } else {
-      return nullptr;
-    }
-  }
+  inline void PredictContrib(const double* feature_values, int num_features, double* output);
+  inline void PredictContribByMap(const std::unordered_map<int, double>& feature_values,
+                                  int num_features, std::unordered_map<int, double>* output);
 
-  /*!
-  * \brief Get size of initial scores
-  */
-  inline int64_t num_init_score() const { return num_init_score_; }
+  /*! \brief Get Number of leaves*/
+  inline int num_leaves() const { return num_leaves_; }
 
-  /*! \brief Disable copy */
-  Metadata& operator=(const Metadata&) = delete;
-  /*! \brief Disable copy */
-  Metadata(const Metadata&) = delete;
-
- private:
-  /*! \brief Load initial scores from file */
-  void LoadInitialScore();
-  /*! \brief Load wights from file */
-  void LoadWeights();
-  /*! \brief Load query boundaries from file */
-  void LoadQueryBoundaries();
-  /*! \brief Load query wights */
-  void LoadQueryWeights();
-  /*! \brief Filename of current data */
-  std::string data_filename_;
-  /*! \brief Number of data */
-  data_size_t num_data_;
-  /*! \brief Number of weights, used to check correct weight file */
-  data_size_t num_weights_;
-  /*! \brief Label data */
-  std::vector<label_t> label_;
-  /*! \brief Weights data */
-  std::vector<label_t> weights_;
-  /*! \brief Query boundaries */
-  std::vector<data_size_t> query_boundaries_;
-  /*! \brief Query weights */
-  std::vector<label_t> query_weights_;
-  /*! \brief Number of querys */
-  data_size_t num_queries_;
-  /*! \brief Number of Initial score, used to check correct weight file */
-  int64_t num_init_score_;
-  /*! \brief Initial score */
-  std::vector<double> init_score_;
-  /*! \brief Queries data */
-  std::vector<data_size_t> queries_;
-  /*! \brief mutex for threading safe call */
-  std::mutex mutex_;
-  bool weight_load_from_file_;
-  bool query_load_from_file_;
-  bool init_score_load_from_file_;
-};
+  /*! \brief Get depth of specific leaf*/
+  inline int leaf_depth(int leaf_idx) const { return leaf_depth_[leaf_idx]; }
 
+  /*! \brief Get parent of specific leaf*/
+  inline int leaf_parent(int leaf_idx) const {return leaf_parent_[leaf_idx]; }
 
-/*! \brief Interface for Parser */
-class Parser {
- public:
-  typedef const char* (*AtofFunc)(const char* p, double* out);
+  /*! \brief Get feature of specific split (original feature index)*/
+  inline int split_feature(int split_idx) const { return split_feature_[split_idx]; }
 
-  /*! \brief virtual destructor */
-  virtual ~Parser() {}
+  /*! \brief Get feature of specific split*/
+  inline int split_feature_inner(int split_idx) const { return split_feature_inner_[split_idx]; }
 
-  /*!
-  * \brief Parse one line with label
-  * \param str One line record, string format, should end with '\0'
-  * \param out_features Output columns, store in (column_idx, values)
-  * \param out_label Label will store to this if exists
-  */
-  virtual void ParseOneLine(const char* str,
-                            std::vector<std::pair<int, double>>* out_features, double* out_label) const = 0;
+  /*! \brief Get features on leaf's branch*/
+  inline std::vector<int> branch_features(int leaf) const { return branch_features_[leaf]; }
 
-  virtual int NumFeatures() const = 0;
+  inline double split_gain(int split_idx) const { return split_gain_[split_idx]; }
 
-  /*!
-  * \brief Create an object of parser, will auto choose the format depend on file
-  * \param filename One Filename of data
-  * \param num_features Pass num_features of this data file if you know, <=0 means don't know
-  * \param label_idx index of label column
-  * \param precise_float_parser using precise floating point number parsing if true
-  * \return Object of parser
-  */
-  static Parser* CreateParser(const char* filename, bool header, int num_features, int label_idx, bool precise_float_parser);
-};
+  inline double internal_value(int node_idx) const {
+    return internal_value_[node_idx];
+  }
 
-/*! \brief The main class of data set,
-*          which are used to training or validation
-*/
-class Dataset {
- public:
-  friend DatasetLoader;
+  inline bool IsNumericalSplit(int node_idx) const {
+    return !GetDecisionType(decision_type_[node_idx], kCategoricalMask);
+  }
 
-  LIGHTGBM_EXPORT Dataset();
+  inline int left_child(int node_idx) const { return left_child_[node_idx]; }
 
-  LIGHTGBM_EXPORT Dataset(data_size_t num_data);
+  inline int right_child(int node_idx) const { return right_child_[node_idx]; }
 
-  void Construct(
-    std::vector<std::unique_ptr<BinMapper>>* bin_mappers,
-    int num_total_features,
-    const std::vector<std::vector<double>>& forced_bins,
-    int** sample_non_zero_indices,
-    double** sample_values,
-    const int* num_per_col,
-    int num_sample_col,
-    size_t total_sample_cnt,
-    const Config& io_config);
-
-  /*! \brief Destructor */
-  LIGHTGBM_EXPORT ~Dataset();
-
-  LIGHTGBM_EXPORT bool CheckAlign(const Dataset& other) const {
-    if (num_features_ != other.num_features_) {
-      return false;
-    }
-    if (num_total_features_ != other.num_total_features_) {
-      return false;
-    }
-    if (label_idx_ != other.label_idx_) {
-      return false;
-    }
-    for (int i = 0; i < num_features_; ++i) {
-      if (!FeatureBinMapper(i)->CheckAlign(*(other.FeatureBinMapper(i)))) {
-        return false;
-      }
-    }
-    return true;
+  inline uint32_t threshold_in_bin(int node_idx) const {
+    return threshold_in_bin_[node_idx];
   }
 
-  inline void FinishOneRow(int tid, data_size_t row_idx, const std::vector<bool>& is_feature_added) {
-    if (is_finish_load_) { return; }
-    for (auto fidx : feature_need_push_zeros_) {
-      if (is_feature_added[fidx]) { continue; }
-      const int group = feature2group_[fidx];
-      const int sub_feature = feature2subfeature_[fidx];
-      feature_groups_[group]->PushData(tid, sub_feature, row_idx, 0.0f);
-    }
-  }
+  /*! \brief Get the number of data points that fall at or below this node*/
+  inline int data_count(int node) const { return node >= 0 ? internal_count_[node] : leaf_count_[~node]; }
 
-  inline void PushOneRow(int tid, data_size_t row_idx, const std::vector<double>& feature_values) {
-    if (is_finish_load_) { return; }
-    for (size_t i = 0; i < feature_values.size() && i < static_cast<size_t>(num_total_features_); ++i) {
-      int feature_idx = used_feature_map_[i];
-      if (feature_idx >= 0) {
-        const int group = feature2group_[feature_idx];
-        const int sub_feature = feature2subfeature_[feature_idx];
-        feature_groups_[group]->PushData(tid, sub_feature, row_idx, feature_values[i]);
-        if (has_raw_) {
-          int feat_ind = numeric_feature_map_[feature_idx];
-          if (feat_ind >= 0) {
-            raw_data_[feat_ind][row_idx] = static_cast<float>(feature_values[i]);
-          }
+  /*!
+  * \brief Shrinkage for the tree's output
+  *        shrinkage rate (a.k.a learning rate) is used to tune the training process
+  * \param rate The factor of shrinkage
+  */
+  virtual inline void Shrinkage(double rate) {
+#pragma omp parallel for schedule(static, 1024) if (num_leaves_ >= 2048)
+    for (int i = 0; i < num_leaves_ - 1; ++i) {
+      leaf_value_[i] = MaybeRoundToZero(leaf_value_[i] * rate);
+      internal_value_[i] = MaybeRoundToZero(internal_value_[i] * rate);
+      if (is_linear_) {
+        leaf_const_[i] = MaybeRoundToZero(leaf_const_[i] * rate);
+        for (size_t j = 0; j < leaf_coeff_[i].size(); ++j) {
+          leaf_coeff_[i][j] = MaybeRoundToZero(leaf_coeff_[i][j] * rate);
         }
       }
     }
-  }
-
-  inline void PushOneRow(int tid, data_size_t row_idx, const std::vector<std::pair<int, double>>& feature_values) {
-    if (is_finish_load_) { return; }
-    std::vector<bool> is_feature_added(num_features_, false);
-    for (auto& inner_data : feature_values) {
-      if (inner_data.first >= num_total_features_) { continue; }
-      int feature_idx = used_feature_map_[inner_data.first];
-      if (feature_idx >= 0) {
-        is_feature_added[feature_idx] = true;
-        const int group = feature2group_[feature_idx];
-        const int sub_feature = feature2subfeature_[feature_idx];
-        feature_groups_[group]->PushData(tid, sub_feature, row_idx, inner_data.second);
-        if (has_raw_) {
-          int feat_ind = numeric_feature_map_[feature_idx];
-          if (feat_ind >= 0) {
-            raw_data_[feat_ind][row_idx] = static_cast<float>(inner_data.second);
-          }
-        }
+    leaf_value_[num_leaves_ - 1] =
+        MaybeRoundToZero(leaf_value_[num_leaves_ - 1] * rate);
+    if (is_linear_) {
+      leaf_const_[num_leaves_ - 1] = MaybeRoundToZero(leaf_const_[num_leaves_ - 1] * rate);
+      for (size_t j = 0; j < leaf_coeff_[num_leaves_ - 1].size(); ++j) {
+        leaf_coeff_[num_leaves_ - 1][j] = MaybeRoundToZero(leaf_coeff_[num_leaves_ - 1][j] * rate);
       }
     }
-    FinishOneRow(tid, row_idx, is_feature_added);
+    shrinkage_ *= rate;
   }
 
-  inline void PushOneData(int tid, data_size_t row_idx, int group, int feature_idx, int sub_feature, double value) {
-    feature_groups_[group]->PushData(tid, sub_feature, row_idx, value);
-    if (has_raw_) {
-      int feat_ind = numeric_feature_map_[feature_idx];
-      if (feat_ind >= 0) {
-        raw_data_[feat_ind][row_idx] = static_cast<float>(value);
+  inline double shrinkage() const { return shrinkage_; }
+
+  virtual inline void AddBias(double val) {
+#pragma omp parallel for schedule(static, 1024) if (num_leaves_ >= 2048)
+    for (int i = 0; i < num_leaves_ - 1; ++i) {
+      leaf_value_[i] = MaybeRoundToZero(leaf_value_[i] + val);
+      internal_value_[i] = MaybeRoundToZero(internal_value_[i] + val);
+    }
+    leaf_value_[num_leaves_ - 1] =
+        MaybeRoundToZero(leaf_value_[num_leaves_ - 1] + val);
+    if (is_linear_) {
+#pragma omp parallel for schedule(static, 1024) if (num_leaves_ >= 2048)
+      for (int i = 0; i < num_leaves_ - 1; ++i) {
+        leaf_const_[i] = MaybeRoundToZero(leaf_const_[i] + val);
       }
+      leaf_const_[num_leaves_ - 1] = MaybeRoundToZero(leaf_const_[num_leaves_ - 1] + val);
     }
+    // force to 1.0
+    shrinkage_ = 1.0f;
   }
 
-  inline int RealFeatureIndex(int fidx) const {
-    return real_feature_idx_[fidx];
+  virtual inline void AsConstantTree(double val) {
+    num_leaves_ = 1;
+    shrinkage_ = 1.0f;
+    leaf_value_[0] = val;
+    if (is_linear_) {
+      leaf_const_[0] = val;
+    }
   }
 
-  inline int InnerFeatureIndex(int col_idx) const {
-    return used_feature_map_[col_idx];
-  }
-  inline int Feature2Group(int feature_idx) const {
-    return feature2group_[feature_idx];
-  }
-  inline int Feture2SubFeature(int feature_idx) const {
-    return feature2subfeature_[feature_idx];
+  /*! \brief Serialize this object to string*/
+  std::string ToString() const;
+
+  /*! \brief Serialize this object to json*/
+  std::string ToJSON() const;
+
+  /*! \brief Serialize linear model of tree node to json*/
+  std::string LinearModelToJSON(int index) const;
+
+  /*! \brief Serialize this object to if-else statement*/
+  std::string ToIfElse(int index, bool predict_leaf_index) const;
+
+  inline static bool IsZero(double fval) {
+    return (fval >= -kZeroThreshold && fval <= kZeroThreshold);
   }
-  inline uint64_t GroupBinBoundary(int group_idx) const {
-    return group_bin_boundaries_[group_idx];
+
+  inline static double MaybeRoundToZero(double fval) {
+    return IsZero(fval) ? 0 : fval;
   }
-  inline uint64_t NumTotalBin() const {
-    return group_bin_boundaries_.back();
+
+  inline static bool GetDecisionType(int8_t decision_type, int8_t mask) {
+    return (decision_type & mask) > 0;
   }
 
-  inline std::vector<int> ValidFeatureIndices() const {
-    std::vector<int> ret;
-    for (int i = 0; i < num_total_features_; ++i) {
-      if (used_feature_map_[i] >= 0) {
-        ret.push_back(i);
-      }
+  inline static void SetDecisionType(int8_t* decision_type, bool input, int8_t mask) {
+    if (input) {
+      (*decision_type) |= mask;
+    } else {
+      (*decision_type) &= (127 - mask);
     }
-    return ret;
   }
-  void ReSize(data_size_t num_data);
 
-  void CopySubrow(const Dataset* fullset, const data_size_t* used_indices, data_size_t num_used_indices, bool need_meta_data);
-
-  MultiValBin* GetMultiBinFromSparseFeatures(const std::vector<uint32_t>& offsets) const;
+  inline static int8_t GetMissingType(int8_t decision_type) {
+    return (decision_type >> 2) & 3;
+  }
 
-  MultiValBin* GetMultiBinFromAllFeatures(const std::vector<uint32_t>& offsets) const;
+  inline static void SetMissingType(int8_t* decision_type, int8_t input) {
+    (*decision_type) &= 3;
+    (*decision_type) |= (input << 2);
+  }
 
-  TrainingShareStates* GetShareStates(
-      score_t* gradients, score_t* hessians,
-      const std::vector<int8_t>& is_feature_used, bool is_constant_hessian,
-      bool force_col_wise, bool force_row_wise) const;
+  void RecomputeMaxDepth();
 
-  LIGHTGBM_EXPORT void FinishLoad();
+  int NextLeafId() const { return num_leaves_; }
 
-  LIGHTGBM_EXPORT bool SetFloatField(const char* field_name, const float* field_data, data_size_t num_element);
+  /*! \brief Get the linear model constant term (bias) of one leaf */
+  inline double LeafConst(int leaf) const { return leaf_const_[leaf]; }
 
-  LIGHTGBM_EXPORT bool SetDoubleField(const char* field_name, const double* field_data, data_size_t num_element);
+  /*! \brief Get the linear model coefficients of one leaf */
+  inline std::vector<double> LeafCoeffs(int leaf) const { return leaf_coeff_[leaf]; }
 
-  LIGHTGBM_EXPORT bool SetIntField(const char* field_name, const int* field_data, data_size_t num_element);
+  /*! \brief Get the linear model features of one leaf */
+  inline std::vector<int> LeafFeaturesInner(int leaf) const {return leaf_features_inner_[leaf]; }
 
-  LIGHTGBM_EXPORT bool GetFloatField(const char* field_name, data_size_t* out_len, const float** out_ptr);
+  /*! \brief Get the linear model features of one leaf */
+  inline std::vector<int> LeafFeatures(int leaf) const {return leaf_features_[leaf]; }
 
-  LIGHTGBM_EXPORT bool GetDoubleField(const char* field_name, data_size_t* out_len, const double** out_ptr);
+  /*! \brief Set the linear model coefficients on one leaf */
+  inline void SetLeafCoeffs(int leaf, const std::vector<double>& output) {
+    leaf_coeff_[leaf].resize(output.size());
+    for (size_t i = 0; i < output.size(); ++i) {
+      leaf_coeff_[leaf][i] = MaybeRoundToZero(output[i]);
+    }
+  }
 
-  LIGHTGBM_EXPORT bool GetIntField(const char* field_name, data_size_t* out_len, const int** out_ptr);
+  /*! \brief Set the linear model constant term (bias) on one leaf */
+  inline void SetLeafConst(int leaf, double output) {
+    leaf_const_[leaf] = MaybeRoundToZero(output);
+  }
 
-  /*!
-  * \brief Save current dataset into binary file, will save to "filename.bin"
-  */
-  LIGHTGBM_EXPORT void SaveBinaryFile(const char* bin_filename);
+  /*! \brief Set the linear model features on one leaf */
+  inline void SetLeafFeaturesInner(int leaf, const std::vector<int>& features) {
+    leaf_features_inner_[leaf] = features;
+  }
 
-  LIGHTGBM_EXPORT void DumpTextFile(const char* text_filename);
+  /*! \brief Set the linear model features on one leaf */
+  inline void SetLeafFeatures(int leaf, const std::vector<int>& features) {
+    leaf_features_[leaf] = features;
+  }
 
-  LIGHTGBM_EXPORT void CopyFeatureMapperFrom(const Dataset* dataset);
+  inline bool is_linear() const { return is_linear_; }
 
-  LIGHTGBM_EXPORT void CreateValid(const Dataset* dataset);
+  #ifdef USE_CUDA
+  inline bool is_cuda_tree() const { return is_cuda_tree_; }
+  #endif  // USE_CUDA
 
-  void InitTrain(const std::vector<int8_t>& is_feature_used,
-                 TrainingShareStates* share_state) const;
+  inline void SetIsLinear(bool is_linear) {
+    is_linear_ = is_linear;
+  }
 
-  template <bool USE_INDICES, bool USE_HESSIAN>
-  void ConstructHistogramsInner(const std::vector<int8_t>& is_feature_used,
-                                const data_size_t* data_indices,
-                                data_size_t num_data, const score_t* gradients,
-                                const score_t* hessians,
-                                score_t* ordered_gradients,
-                                score_t* ordered_hessians,
-                                TrainingShareStates* share_state,
-                                hist_t* hist_data) const;
+ protected:
+  std::string NumericalDecisionIfElse(int node) const;
 
-  template <bool USE_INDICES, bool ORDERED>
-  void ConstructHistogramsMultiVal(const data_size_t* data_indices,
-                                   data_size_t num_data,
-                                   const score_t* gradients,
-                                   const score_t* hessians,
-                                   TrainingShareStates* share_state,
-                                   hist_t* hist_data) const;
+  std::string CategoricalDecisionIfElse(int node) const;
 
-  inline void ConstructHistograms(
-      const std::vector<int8_t>& is_feature_used,
-      const data_size_t* data_indices, data_size_t num_data,
-      const score_t* gradients, const score_t* hessians,
-      score_t* ordered_gradients, score_t* ordered_hessians,
-      TrainingShareStates* share_state, hist_t* hist_data) const {
-    if (num_data <= 0) {
-      return;
+  inline int NumericalDecision(double fval, int node) const {
+    uint8_t missing_type = GetMissingType(decision_type_[node]);
+    if (std::isnan(fval) && missing_type != MissingType::NaN) {
+      fval = 0.0f;
     }
-    bool use_indices = data_indices != nullptr && (num_data < num_data_);
-    if (share_state->is_constant_hessian) {
-      if (use_indices) {
-        ConstructHistogramsInner<true, false>(
-            is_feature_used, data_indices, num_data, gradients, hessians,
-            ordered_gradients, ordered_hessians, share_state, hist_data);
+    if ((missing_type == MissingType::Zero && IsZero(fval))
+        || (missing_type == MissingType::NaN && std::isnan(fval))) {
+      if (GetDecisionType(decision_type_[node], kDefaultLeftMask)) {
+        return left_child_[node];
       } else {
-        ConstructHistogramsInner<false, false>(
-            is_feature_used, data_indices, num_data, gradients, hessians,
-            ordered_gradients, ordered_hessians, share_state, hist_data);
+        return right_child_[node];
       }
+    }
+    if (fval <= threshold_[node]) {
+      return left_child_[node];
     } else {
-      if (use_indices) {
-        ConstructHistogramsInner<true, true>(
-            is_feature_used, data_indices, num_data, gradients, hessians,
-            ordered_gradients, ordered_hessians, share_state, hist_data);
-      } else {
-        ConstructHistogramsInner<false, true>(
-            is_feature_used, data_indices, num_data, gradients, hessians,
-            ordered_gradients, ordered_hessians, share_state, hist_data);
-      }
+      return right_child_[node];
     }
   }
 
-  void FixHistogram(int feature_idx, double sum_gradient, double sum_hessian, hist_t* data) const;
-
-  inline data_size_t Split(int feature, const uint32_t* threshold,
-                           int num_threshold, bool default_left,
-                           const data_size_t* data_indices,
-                           data_size_t cnt, data_size_t* lte_indices,
-                           data_size_t* gt_indices) const {
-    const int group = feature2group_[feature];
-    const int sub_feature = feature2subfeature_[feature];
-    return feature_groups_[group]->Split(
-        sub_feature, threshold, num_threshold, default_left, data_indices,
-        cnt, lte_indices, gt_indices);
-  }
-
-  inline int SubFeatureBinOffset(int i) const {
-    const int sub_feature = feature2subfeature_[i];
-    if (sub_feature == 0) {
-      return 1;
+  inline int NumericalDecisionInner(uint32_t fval, int node, uint32_t default_bin, uint32_t max_bin) const {
+    uint8_t missing_type = GetMissingType(decision_type_[node]);
+    if ((missing_type == MissingType::Zero && fval == default_bin)
+        || (missing_type == MissingType::NaN && fval == max_bin)) {
+      if (GetDecisionType(decision_type_[node], kDefaultLeftMask)) {
+        return left_child_[node];
+      } else {
+        return right_child_[node];
+      }
+    }
+    if (fval <= threshold_in_bin_[node]) {
+      return left_child_[node];
     } else {
-      return 0;
+      return right_child_[node];
     }
   }
 
-  inline int FeatureNumBin(int i) const {
-    const int group = feature2group_[i];
-    const int sub_feature = feature2subfeature_[i];
-    return feature_groups_[group]->bin_mappers_[sub_feature]->num_bin();
-  }
-
-  inline int FeatureGroupNumBin(int group) const {
-    return feature_groups_[group]->num_total_bin_;
-  }
-
-  inline const BinMapper* FeatureBinMapper(int i) const {
-    const int group = feature2group_[i];
-    const int sub_feature = feature2subfeature_[i];
-    return feature_groups_[group]->bin_mappers_[sub_feature].get();
-  }
-
-  inline const Bin* FeatureGroupBin(int group) const {
-    return feature_groups_[group]->bin_data_.get();
-  }
-
-  inline BinIterator* FeatureIterator(int i) const {
-    const int group = feature2group_[i];
-    const int sub_feature = feature2subfeature_[i];
-    return feature_groups_[group]->SubFeatureIterator(sub_feature);
-  }
-
-  inline BinIterator* FeatureGroupIterator(int group) const {
-    return feature_groups_[group]->FeatureGroupIterator();
-  }
-
-  inline bool IsMultiGroup(int i) const {
-    return feature_groups_[i]->is_multi_val_;
-  }
-
-  inline size_t FeatureGroupSizesInByte(int group) const {
-    return feature_groups_[group]->FeatureGroupSizesInByte();
+  inline int CategoricalDecision(double fval, int node) const {
+    int int_fval;
+    if (std::isnan(fval)) {
+      return right_child_[node];
+    } else {
+      int_fval = static_cast<int>(fval);
+      if (int_fval < 0) {
+        return right_child_[node];
+      }
+    }
+    int cat_idx = static_cast<int>(threshold_[node]);
+    if (Common::FindInBitset(cat_threshold_.data() + cat_boundaries_[cat_idx],
+                             cat_boundaries_[cat_idx + 1] - cat_boundaries_[cat_idx], int_fval)) {
+      return left_child_[node];
+    }
+    return right_child_[node];
   }
 
-  inline void* FeatureGroupData(int group) const {
-    return feature_groups_[group]->FeatureGroupData();
+  inline int CategoricalDecisionInner(uint32_t fval, int node) const {
+    int cat_idx = static_cast<int>(threshold_in_bin_[node]);
+    if (Common::FindInBitset(cat_threshold_inner_.data() + cat_boundaries_inner_[cat_idx],
+                             cat_boundaries_inner_[cat_idx + 1] - cat_boundaries_inner_[cat_idx], fval)) {
+      return left_child_[node];
+    }
+    return right_child_[node];
   }
 
-  inline double RealThreshold(int i, uint32_t threshold) const {
-    const int group = feature2group_[i];
-    const int sub_feature = feature2subfeature_[i];
-    return feature_groups_[group]->bin_mappers_[sub_feature]->BinToValue(threshold);
+  inline int Decision(double fval, int node) const {
+    if (GetDecisionType(decision_type_[node], kCategoricalMask)) {
+      return CategoricalDecision(fval, node);
+    } else {
+      return NumericalDecision(fval, node);
+    }
   }
 
-  // given a real threshold, find the closest threshold bin
-  inline uint32_t BinThreshold(int i, double threshold_double) const {
-    const int group = feature2group_[i];
-    const int sub_feature = feature2subfeature_[i];
-    return feature_groups_[group]->bin_mappers_[sub_feature]->ValueToBin(threshold_double);
+  inline int DecisionInner(uint32_t fval, int node, uint32_t default_bin, uint32_t max_bin) const {
+    if (GetDecisionType(decision_type_[node], kCategoricalMask)) {
+      return CategoricalDecisionInner(fval, node);
+    } else {
+      return NumericalDecisionInner(fval, node, default_bin, max_bin);
+    }
   }
 
+  inline void Split(int leaf, int feature, int real_feature, double left_value, double right_value, int left_cnt, int right_cnt,
+                    double left_weight, double right_weight, float gain);
   /*!
-  * \brief Get meta data pointer
-  * \return Pointer of meta data
-  */
-  inline const Metadata& metadata() const { return metadata_; }
-
-  /*! \brief Get Number of used features */
-  inline int num_features() const { return num_features_; }
-
-  /*! \brief Get number of numeric features */
-  inline int num_numeric_features() const { return num_numeric_features_; }
-
-  /*! \brief Get Number of feature groups */
-  inline int num_feature_groups() const { return num_groups_;}
-
-  /*! \brief Get Number of total features */
-  inline int num_total_features() const { return num_total_features_; }
-
-  /*! \brief Get the index of label column */
-  inline int label_idx() const { return label_idx_; }
-
-  /*! \brief Get names of current data set */
-  inline const std::vector<std::string>& feature_names() const { return feature_names_; }
+  * \brief Find leaf index of which record belongs by features
+  * \param feature_values Feature value of this record
+  * \return Leaf index
+  */
+  inline int GetLeaf(const double* feature_values) const;
+  inline int GetLeafByMap(const std::unordered_map<int, double>& feature_values) const;
+
+  /*! \brief Serialize one node to json*/
+  std::string NodeToJSON(int index) const;
+
+  /*! \brief Serialize one node to if-else statement*/
+  std::string NodeToIfElse(int index, bool predict_leaf_index) const;
+
+  std::string NodeToIfElseByMap(int index, bool predict_leaf_index) const;
+
+  double ExpectedValue() const;
+
+  /*! \brief This is used fill in leaf_depth_ after reloading a model*/
+  inline void RecomputeLeafDepths(int node = 0, int depth = 0);
+
+  /*!
+  * \brief Used by TreeSHAP for data we keep about our decision path
+  */
+  struct PathElement {
+    int feature_index;
+    double zero_fraction;
+    double one_fraction;
+
+    // note that pweight is included for convenience and is not tied with the other attributes,
+    // the pweight of the i'th path element is the permutation weight of paths with i-1 ones in them
+    double pweight;
+
+    PathElement() {}
+    PathElement(int i, double z, double o, double w) : feature_index(i), zero_fraction(z), one_fraction(o), pweight(w) {}
+  };
+
+  /*! \brief Polynomial time algorithm for SHAP values (arXiv:1706.06060)*/
+  void TreeSHAP(const double *feature_values, double *phi,
+                int node, int unique_depth,
+                PathElement *parent_unique_path, double parent_zero_fraction,
+                double parent_one_fraction, int parent_feature_index) const;
+
+  void TreeSHAPByMap(const std::unordered_map<int, double>& feature_values,
+                     std::unordered_map<int, double>* phi,
+                     int node, int unique_depth,
+                     PathElement *parent_unique_path, double parent_zero_fraction,
+                     double parent_one_fraction, int parent_feature_index) const;
+
+  /*! \brief Extend our decision path with a fraction of one and zero extensions for TreeSHAP*/
+  static void ExtendPath(PathElement *unique_path, int unique_depth,
+                         double zero_fraction, double one_fraction, int feature_index);
+
+  /*! \brief Undo a previous extension of the decision path for TreeSHAP*/
+  static void UnwindPath(PathElement *unique_path, int unique_depth, int path_index);
+
+  /*! determine what the total permutation weight would be if we unwound a previous extension in the decision path*/
+  static double UnwoundPathSum(const PathElement *unique_path, int unique_depth, int path_index);
+
+  /*! \brief Number of max leaves*/
+  int max_leaves_;
+  /*! \brief Number of current leaves*/
+  int num_leaves_;
+  // following values used for non-leaf node
+  /*! \brief A non-leaf node's left child */
+  std::vector<int> left_child_;
+  /*! \brief A non-leaf node's right child */
+  std::vector<int> right_child_;
+  /*! \brief A non-leaf node's split feature */
+  std::vector<int> split_feature_inner_;
+  /*! \brief A non-leaf node's split feature, the original index */
+  std::vector<int> split_feature_;
+  /*! \brief A non-leaf node's split threshold in bin */
+  std::vector<uint32_t> threshold_in_bin_;
+  /*! \brief A non-leaf node's split threshold in feature value */
+  std::vector<double> threshold_;
+  int num_cat_;
+  std::vector<int> cat_boundaries_inner_;
+  std::vector<uint32_t> cat_threshold_inner_;
+  std::vector<int> cat_boundaries_;
+  std::vector<uint32_t> cat_threshold_;
+  /*! \brief Store the information for categorical feature handle and missing value handle. */
+  std::vector<int8_t> decision_type_;
+  /*! \brief A non-leaf node's split gain */
+  std::vector<float> split_gain_;
+  // used for leaf node
+  /*! \brief The parent of leaf */
+  std::vector<int> leaf_parent_;
+  /*! \brief Output of leaves */
+  std::vector<double> leaf_value_;
+  /*! \brief weight of leaves */
+  std::vector<double> leaf_weight_;
+  /*! \brief DataCount of leaves */
+  std::vector<int> leaf_count_;
+  /*! \brief Output of non-leaf nodes */
+  std::vector<double> internal_value_;
+  /*! \brief weight of non-leaf nodes */
+  std::vector<double> internal_weight_;
+  /*! \brief DataCount of non-leaf nodes */
+  std::vector<int> internal_count_;
+  /*! \brief Depth for leaves */
+  std::vector<int> leaf_depth_;
+  /*! \brief whether to keep track of ancestor nodes for each leaf (only needed when feature interactions are restricted) */
+  bool track_branch_features_;
+  /*! \brief Features on leaf's branch, original index */
+  std::vector<std::vector<int>> branch_features_;
+  double shrinkage_;
+  int max_depth_;
+  /*! \brief Tree has linear model at each leaf */
+  bool is_linear_;
+  /*! \brief coefficients of linear models on leaves */
+  std::vector<std::vector<double>> leaf_coeff_;
+  /*! \brief constant term (bias) of linear models on leaves */
+  std::vector<double> leaf_const_;
+  /* \brief features used in leaf linear models; indexing is relative to num_total_features_ */
+  std::vector<std::vector<int>> leaf_features_;
+  /* \brief features used in leaf linear models; indexing is relative to used_features_ */
+  std::vector<std::vector<int>> leaf_features_inner_;
+  #ifdef USE_CUDA
+  /*! \brief Marks whether this tree is a CUDATree */
+  bool is_cuda_tree_;
+  #endif  // USE_CUDA
+};
 
-  inline void set_feature_names(const std::vector<std::string>& feature_names) {
-    if (feature_names.size() != static_cast<size_t>(num_total_features_)) {
-      Log::Fatal("Size of feature_names error, should equal with total number of features");
+inline void Tree::Split(int leaf, int feature, int real_feature,
+                        double left_value, double right_value, int left_cnt, int right_cnt,
+                        double left_weight, double right_weight, float gain) {
+  int new_node_idx = num_leaves_ - 1;
+  // update parent info
+  int parent = leaf_parent_[leaf];
+  if (parent >= 0) {
+    // if cur node is left child
+    if (left_child_[parent] == ~leaf) {
+      left_child_[parent] = new_node_idx;
+    } else {
+      right_child_[parent] = new_node_idx;
     }
-    feature_names_ = std::vector<std::string>(feature_names);
-    std::unordered_set<std::string> feature_name_set;
-    // replace ' ' in feature_names with '_'
-    bool spaceInFeatureName = false;
-    for (auto& feature_name : feature_names_) {
-      // check JSON
-      if (!Common::CheckAllowedJSON(feature_name)) {
-        Log::Fatal("Do not support special JSON characters in feature name.");
-      }
-      if (feature_name.find(' ') != std::string::npos) {
-        spaceInFeatureName = true;
-        std::replace(feature_name.begin(), feature_name.end(), ' ', '_');
+  }
+  // add new node
+  split_feature_inner_[new_node_idx] = feature;
+  split_feature_[new_node_idx] = real_feature;
+  split_gain_[new_node_idx] = gain;
+  // add two new leaves
+  left_child_[new_node_idx] = ~leaf;
+  right_child_[new_node_idx] = ~num_leaves_;
+  // update new leaves
+  leaf_parent_[leaf] = new_node_idx;
+  leaf_parent_[num_leaves_] = new_node_idx;
+  // save current leaf value to internal node before change
+  internal_weight_[new_node_idx] = leaf_weight_[leaf];
+  internal_value_[new_node_idx] = leaf_value_[leaf];
+  internal_count_[new_node_idx] = left_cnt + right_cnt;
+  leaf_value_[leaf] = std::isnan(left_value) ? 0.0f : left_value;
+  leaf_weight_[leaf] = left_weight;
+  leaf_count_[leaf] = left_cnt;
+  leaf_value_[num_leaves_] = std::isnan(right_value) ? 0.0f : right_value;
+  leaf_weight_[num_leaves_] = right_weight;
+  leaf_count_[num_leaves_] = right_cnt;
+  // update leaf depth
+  leaf_depth_[num_leaves_] = leaf_depth_[leaf] + 1;
+  leaf_depth_[leaf]++;
+  if (track_branch_features_) {
+    branch_features_[num_leaves_] = branch_features_[leaf];
+    branch_features_[num_leaves_].push_back(split_feature_[new_node_idx]);
+    branch_features_[leaf].push_back(split_feature_[new_node_idx]);
+  }
+}
+
+inline double Tree::Predict(const double* feature_values) const {
+  if (is_linear_) {
+      int leaf = (num_leaves_ > 1) ? GetLeaf(feature_values) : 0;
+      double output = leaf_const_[leaf];
+      bool nan_found = false;
+      for (size_t i = 0; i < leaf_features_[leaf].size(); ++i) {
+        int feat_raw = leaf_features_[leaf][i];
+        double feat_val = feature_values[feat_raw];
+        if (std::isnan(feat_val)) {
+          nan_found = true;
+          break;
+        } else {
+          output += leaf_coeff_[leaf][i] * feat_val;
+        }
       }
-      if (feature_name_set.count(feature_name) > 0) {
-        Log::Fatal("Feature (%s) appears more than one time.", feature_name.c_str());
+      if (nan_found) {
+        return LeafOutput(leaf);
+      } else {
+        return output;
       }
-      feature_name_set.insert(feature_name);
-    }
-    if (spaceInFeatureName) {
-      Log::Warning("Found whitespace in feature_names, replace with underlines");
+  } else {
+    if (num_leaves_ > 1) {
+      int leaf = GetLeaf(feature_values);
+      return LeafOutput(leaf);
+    } else {
+      return leaf_value_[0];
     }
   }
+}
 
-  inline std::vector<std::string> feature_infos() const {
-    std::vector<std::string> bufs;
-    for (int i = 0; i < num_total_features_; ++i) {
-      int fidx = used_feature_map_[i];
-      if (fidx < 0) {
-        bufs.push_back("none");
-      } else {
-        const auto bin_mapper = FeatureBinMapper(fidx);
-        bufs.push_back(bin_mapper->bin_info_string());
+inline double Tree::PredictByMap(const std::unordered_map<int, double>& feature_values) const {
+  if (is_linear_) {
+    int leaf = (num_leaves_ > 1) ? GetLeafByMap(feature_values) : 0;
+    double output = leaf_const_[leaf];
+    bool nan_found = false;
+    for (size_t i = 0; i < leaf_features_[leaf].size(); ++i) {
+      int feat = leaf_features_[leaf][i];
+      auto val_it = feature_values.find(feat);
+      if (val_it != feature_values.end()) {
+        double feat_val = val_it->second;
+        if (std::isnan(feat_val)) {
+          nan_found = true;
+          break;
+        } else {
+          output += leaf_coeff_[leaf][i] * feat_val;
+        }
       }
     }
-    return bufs;
+    if (nan_found) {
+      return LeafOutput(leaf);
+    } else {
+      return output;
+    }
+  } else {
+    if (num_leaves_ > 1) {
+      int leaf = GetLeafByMap(feature_values);
+      return LeafOutput(leaf);
+    } else {
+      return leaf_value_[0];
+    }
   }
+}
 
-  /*! \brief Get Number of data */
-  inline data_size_t num_data() const { return num_data_; }
-
-  /*! \brief Disable copy */
-  Dataset& operator=(const Dataset&) = delete;
-  /*! \brief Disable copy */
-  Dataset(const Dataset&) = delete;
-
-  void AddFeaturesFrom(Dataset* other);
-
-  /*! \brief Get has_raw_ */
-  inline bool has_raw() const { return has_raw_; }
-
-  /*! \brief Set has_raw_ */
-  inline void SetHasRaw(bool has_raw) { has_raw_ = has_raw; }
-
-  /*! \brief Resize raw_data_ */
-  inline void ResizeRaw(int num_rows) {
-    if (static_cast<int>(raw_data_.size()) > num_numeric_features_) {
-      raw_data_.resize(num_numeric_features_);
-    }
-    for (size_t i = 0; i < raw_data_.size(); ++i) {
-      raw_data_[i].resize(num_rows);
-    }
-    int curr_size = static_cast<int>(raw_data_.size());
-    for (int i = curr_size; i < num_numeric_features_; ++i) {
-      raw_data_.push_back(std::vector<float>(num_rows, 0));
-    }
-  }
-
-  /*! \brief Get pointer to raw_data_ feature */
-  inline const float* raw_index(int feat_ind) const {
-    return raw_data_[numeric_feature_map_[feat_ind]].data();
-  }
-
- private:
-  std::string data_filename_;
-  /*! \brief Store used features */
-  std::vector<std::unique_ptr<FeatureGroup>> feature_groups_;
-  /*! \brief Mapper from real feature index to used index*/
-  std::vector<int> used_feature_map_;
-  /*! \brief Number of used features*/
-  int num_features_;
-  /*! \brief Number of total features*/
-  int num_total_features_;
-  /*! \brief Number of total data*/
-  data_size_t num_data_;
-  /*! \brief Store some label level data*/
-  Metadata metadata_;
-  /*! \brief index of label column */
-  int label_idx_ = 0;
-  /*! \brief store feature names */
-  std::vector<std::string> feature_names_;
-  /*! \brief store feature names */
-  static const char* binary_file_token;
-  int num_groups_;
-  std::vector<int> real_feature_idx_;
-  std::vector<int> feature2group_;
-  std::vector<int> feature2subfeature_;
-  std::vector<uint64_t> group_bin_boundaries_;
-  std::vector<int> group_feature_start_;
-  std::vector<int> group_feature_cnt_;
-  bool is_finish_load_;
-  int max_bin_;
-  std::vector<int32_t> max_bin_by_feature_;
-  std::vector<std::vector<double>> forced_bin_bounds_;
-  int bin_construct_sample_cnt_;
-  int min_data_in_bin_;
-  bool use_missing_;
-  bool zero_as_missing_;
-  std::vector<int> feature_need_push_zeros_;
-  std::vector<std::vector<float>> raw_data_;
-  bool has_raw_;
-  /*! map feature (inner index) to its index in the list of numeric (non-categorical) features */
-  std::vector<int> numeric_feature_map_;
-  int num_numeric_features_;
-};
+inline int Tree::PredictLeafIndex(const double* feature_values) const {
+  if (num_leaves_ > 1) {
+    int leaf = GetLeaf(feature_values);
+    return leaf;
+  } else {
+    return 0;
+  }
+}
+
+inline int Tree::PredictLeafIndexByMap(const std::unordered_map<int, double>& feature_values) const {
+  if (num_leaves_ > 1) {
+    int leaf = GetLeafByMap(feature_values);
+    return leaf;
+  } else {
+    return 0;
+  }
+}
+
+inline void Tree::PredictContrib(const double* feature_values, int num_features, double* output) {
+  output[num_features] += ExpectedValue();
+  // Run the recursion with preallocated space for the unique path data
+  if (num_leaves_ > 1) {
+    CHECK_GE(max_depth_, 0);
+    const int max_path_len = max_depth_ + 1;
+    std::vector<PathElement> unique_path_data(max_path_len*(max_path_len + 1) / 2);
+    TreeSHAP(feature_values, output, 0, 0, unique_path_data.data(), 1, 1, -1);
+  }
+}
+
+inline void Tree::PredictContribByMap(const std::unordered_map<int, double>& feature_values,
+                                      int num_features, std::unordered_map<int, double>* output) {
+  (*output)[num_features] += ExpectedValue();
+  // Run the recursion with preallocated space for the unique path data
+  if (num_leaves_ > 1) {
+    CHECK_GE(max_depth_, 0);
+    const int max_path_len = max_depth_ + 1;
+    std::vector<PathElement> unique_path_data(max_path_len*(max_path_len + 1) / 2);
+    TreeSHAPByMap(feature_values, output, 0, 0, unique_path_data.data(), 1, 1, -1);
+  }
+}
+
+inline void Tree::RecomputeLeafDepths(int node, int depth) {
+  if (node == 0) leaf_depth_.resize(num_leaves());
+  if (node < 0) {
+    leaf_depth_[~node] = depth;
+  } else {
+    RecomputeLeafDepths(left_child_[node], depth + 1);
+    RecomputeLeafDepths(right_child_[node], depth + 1);
+  }
+}
+
+inline int Tree::GetLeaf(const double* feature_values) const {
+  int node = 0;
+  if (num_cat_ > 0) {
+    while (node >= 0) {
+      node = Decision(feature_values[split_feature_[node]], node);
+    }
+  } else {
+    while (node >= 0) {
+      node = NumericalDecision(feature_values[split_feature_[node]], node);
+    }
+  }
+  return ~node;
+}
+
+inline int Tree::GetLeafByMap(const std::unordered_map<int, double>& feature_values) const {
+  int node = 0;
+  if (num_cat_ > 0) {
+    while (node >= 0) {
+      node = Decision(feature_values.count(split_feature_[node]) > 0 ? feature_values.at(split_feature_[node]) : 0.0f, node);
+    }
+  } else {
+    while (node >= 0) {
+      node = NumericalDecision(feature_values.count(split_feature_[node]) > 0 ? feature_values.at(split_feature_[node]) : 0.0f, node);
+    }
+  }
+  return ~node;
+}
 
 }  // namespace LightGBM
 
-#endif   // LightGBM_DATA_H_
+#endif   // LightGBM_TREE_H_
```

### Comparing `lightgbm-3.3.5/compile/include/LightGBM/dataset_loader.h` & `lightgbm-4.0.0/include/LightGBM/dataset_loader.h`

 * *Files 21% similar despite different names*

```diff
@@ -3,14 +3,15 @@
  * Licensed under the MIT License. See LICENSE file in the project root for license information.
  */
 #ifndef LIGHTGBM_DATASET_LOADER_H_
 #define LIGHTGBM_DATASET_LOADER_H_
 
 #include <LightGBM/dataset.h>
 
+#include <memory>
 #include <string>
 #include <unordered_set>
 #include <vector>
 
 namespace LightGBM {
 
 class DatasetLoader {
@@ -23,27 +24,35 @@
 
   LIGHTGBM_EXPORT Dataset* LoadFromFile(const char* filename) {
     return LoadFromFile(filename, 0, 1);
   }
 
   LIGHTGBM_EXPORT Dataset* LoadFromFileAlignWithOtherDataset(const char* filename, const Dataset* train_data);
 
+  LIGHTGBM_EXPORT Dataset* LoadFromSerializedReference(const char* buffer, size_t buffer_size, data_size_t num_data, int32_t num_classes);
+
   LIGHTGBM_EXPORT Dataset* ConstructFromSampleData(double** sample_values,
-    int** sample_indices, int num_col, const int* num_per_col,
-    size_t total_sample_size, data_size_t num_data);
+                                                   int** sample_indices,
+                                                   int num_col,
+                                                   const int* num_per_col,
+                                                   size_t total_sample_size,
+                                                   data_size_t num_local_data,
+                                                   int64_t num_dist_data);
 
   /*! \brief Disable copy */
   DatasetLoader& operator=(const DatasetLoader&) = delete;
   /*! \brief Disable copy */
   DatasetLoader(const DatasetLoader&) = delete;
 
   static std::vector<std::vector<double>> GetForcedBins(std::string forced_bins_path, int num_total_features,
                                                         const std::unordered_set<int>& categorical_features);
 
  private:
+  void LoadHeaderFromMemory(Dataset* dataset, const char* buffer);
+
   Dataset* LoadFromBinFile(const char* data_filename, const char* bin_filename, int rank, int num_machines, int* num_global_data, std::vector<data_size_t>* used_data_indices);
 
   void SetHeader(const char* filename);
 
   void CheckDataset(const Dataset* dataset, bool is_load_from_binary);
 
   std::vector<std::string> LoadTextDataToMemory(const char* filename, const Metadata& metadata, int rank, int num_machines, int* num_global_data, std::vector<data_size_t>* used_data_indices);
@@ -59,14 +68,24 @@
 
   /*! \brief Extract local features from file */
   void ExtractFeaturesFromFile(const char* filename, const Parser* parser, const std::vector<data_size_t>& used_data_indices, Dataset* dataset);
 
   /*! \brief Check can load from binary file */
   std::string CheckCanLoadFromBin(const char* filename);
 
+  /*! \brief Check the number of bins for categorical features.
+   * The number of bins for categorical features may exceed the configured maximum value.
+   * Log warnings when such cases happen.
+   *
+   * \param bin_mappers the bin_mappers of all features
+   * \param max_bin max_bin from Config
+   * \param max_bin_by_feature max_bin_by_feature from Config
+   */
+  void CheckCategoricalFeatureNumBin(const std::vector<std::unique_ptr<BinMapper>>& bin_mappers, const int max_bin, const std::vector<int>& max_bin_by_feature) const;
+
   const Config& config_;
   /*! \brief Random generator*/
   Random random_;
   /*! \brief prediction function for initial model */
   const PredictFunction predict_fun_;
   /*! \brief number of classes */
   int num_class_;
```

### Comparing `lightgbm-3.3.5/compile/include/LightGBM/export.h` & `lightgbm-4.0.0/include/LightGBM/export.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/include/LightGBM/feature_group.h` & `lightgbm-4.0.0/include/LightGBM/feature_group.h`

 * *Files 7% similar despite different names*

```diff
@@ -106,35 +106,77 @@
       num_total_bin_ += num_bin;
       bin_offsets_.emplace_back(num_total_bin_);
     }
     CreateBinData(num_data, false, false, false);
   }
 
   /*!
-   * \brief Constructor from memory
+   * \brief Constructor from memory when data is present
    * \param memory Pointer of memory
    * \param num_all_data Number of global data
    * \param local_used_indices Local used indices, empty means using all data
+   * \param group_id Id of group
    */
-  FeatureGroup(const void* memory, data_size_t num_all_data,
+  FeatureGroup(const void* memory,
+               data_size_t num_all_data,
                const std::vector<data_size_t>& local_used_indices,
                int group_id) {
+    // Load the definition schema first
+    const char* memory_ptr = LoadDefinitionFromMemory(memory, group_id);
+
+    // Allocate memory for the data
+    data_size_t num_data = num_all_data;
+    if (!local_used_indices.empty()) {
+      num_data = static_cast<data_size_t>(local_used_indices.size());
+    }
+    AllocateBins(num_data);
+
+    // Now load the actual data
+    if (is_multi_val_) {
+      for (int i = 0; i < num_feature_; ++i) {
+        multi_bin_data_[i]->LoadFromMemory(memory_ptr, local_used_indices);
+        memory_ptr += multi_bin_data_[i]->SizesInByte();
+      }
+    } else {
+      bin_data_->LoadFromMemory(memory_ptr, local_used_indices);
+    }
+  }
+
+  /*!
+   * \brief Constructor from definition in memory (without data)
+   * \param memory Pointer of memory
+   * \param local_used_indices Local used indices, empty means using all data
+   */
+  FeatureGroup(const void* memory, data_size_t num_data, int group_id) {
+    LoadDefinitionFromMemory(memory, group_id);
+    AllocateBins(num_data);
+  }
+
+  /*! \brief Destructor */
+  ~FeatureGroup() {}
+
+  /*!
+   * \brief Load the overall definition of the feature group from binary serialized data
+   * \param memory Pointer of memory
+   * \param group_id Id of group
+   */
+  const char* LoadDefinitionFromMemory(const void* memory, int group_id) {
     const char* memory_ptr = reinterpret_cast<const char*>(memory);
     // get is_sparse
     is_multi_val_ = *(reinterpret_cast<const bool*>(memory_ptr));
     memory_ptr += VirtualFileWriter::AlignedSize(sizeof(is_multi_val_));
     is_dense_multi_val_ = *(reinterpret_cast<const bool*>(memory_ptr));
     memory_ptr += VirtualFileWriter::AlignedSize(sizeof(is_dense_multi_val_));
     is_sparse_ = *(reinterpret_cast<const bool*>(memory_ptr));
     memory_ptr += VirtualFileWriter::AlignedSize(sizeof(is_sparse_));
     num_feature_ = *(reinterpret_cast<const int*>(memory_ptr));
     memory_ptr += VirtualFileWriter::AlignedSize(sizeof(num_feature_));
-    // get bin mapper
-    bin_mappers_.clear();
 
+    // get bin mapper(s)
+    bin_mappers_.clear();
     for (int i = 0; i < num_feature_; ++i) {
       bin_mappers_.emplace_back(new BinMapper(memory_ptr));
       memory_ptr += bin_mappers_[i]->SizesInByte();
     }
 
     bin_offsets_.clear();
     int offset = 1;
@@ -154,53 +196,64 @@
       auto num_bin = bin_mappers_[i]->num_bin();
       if (bin_mappers_[i]->GetMostFreqBin() == 0) {
         num_bin -= offset;
       }
       num_total_bin_ += num_bin;
       bin_offsets_.emplace_back(num_total_bin_);
     }
-    data_size_t num_data = num_all_data;
-    if (!local_used_indices.empty()) {
-      num_data = static_cast<data_size_t>(local_used_indices.size());
-    }
+
+    return memory_ptr;
+  }
+
+  /*!
+   * \brief Allocate the bins
+   * \param num_all_data Number of global data
+   */
+  inline void AllocateBins(data_size_t num_data) {
     if (is_multi_val_) {
       for (int i = 0; i < num_feature_; ++i) {
         int addi = bin_mappers_[i]->GetMostFreqBin() == 0 ? 0 : 1;
         if (bin_mappers_[i]->sparse_rate() >= kSparseThreshold) {
-          multi_bin_data_.emplace_back(Bin::CreateSparseBin(
-              num_data, bin_mappers_[i]->num_bin() + addi));
+          multi_bin_data_.emplace_back(Bin::CreateSparseBin(num_data, bin_mappers_[i]->num_bin() + addi));
         } else {
-          multi_bin_data_.emplace_back(
-              Bin::CreateDenseBin(num_data, bin_mappers_[i]->num_bin() + addi));
+          multi_bin_data_.emplace_back(Bin::CreateDenseBin(num_data, bin_mappers_[i]->num_bin() + addi));
         }
-        multi_bin_data_.back()->LoadFromMemory(memory_ptr, local_used_indices);
-        memory_ptr += multi_bin_data_.back()->SizesInByte();
       }
     } else {
       if (is_sparse_) {
         bin_data_.reset(Bin::CreateSparseBin(num_data, num_total_bin_));
       } else {
         bin_data_.reset(Bin::CreateDenseBin(num_data, num_total_bin_));
       }
-      // get bin data
-      bin_data_->LoadFromMemory(memory_ptr, local_used_indices);
     }
   }
 
-  /*! \brief Destructor */
-  ~FeatureGroup() {}
+  /*!
+  * \brief Initialize for pushing in a streaming fashion.  By default, no action needed.
+  * \param num_thread The number of external threads that will be calling the push APIs
+  * \param omp_max_threads The maximum number of OpenMP threads to allocate for
+  */
+  void InitStreaming(int32_t num_thread, int32_t omp_max_threads) {
+    if (is_multi_val_) {
+      for (int i = 0; i < num_feature_; ++i) {
+        multi_bin_data_[i]->InitStreaming(num_thread, omp_max_threads);
+      }
+    } else {
+      bin_data_->InitStreaming(num_thread, omp_max_threads);
+    }
+  }
 
   /*!
    * \brief Push one record, will auto convert to bin and push to bin data
    * \param tid Thread id
-   * \param idx Index of record
+   * \param sub_feature_idx Index of the subfeature
+   * \param line_idx Index of record
    * \param value feature value of record
    */
-  inline void PushData(int tid, int sub_feature_idx, data_size_t line_idx,
-                       double value) {
+  inline void PushData(int tid, int sub_feature_idx, data_size_t line_idx, double value) {
     uint32_t bin = bin_mappers_[sub_feature_idx]->ValueToBin(value);
     if (bin == bin_mappers_[sub_feature_idx]->GetMostFreqBin()) {
       return;
     }
     if (bin_mappers_[sub_feature_idx]->GetMostFreqBin() == 0) {
       bin -= 1;
     }
@@ -395,50 +448,56 @@
    * \return FeatureGroup value of this bin
    */
   inline double BinToValue(int sub_feature_idx, uint32_t bin) const {
     return bin_mappers_[sub_feature_idx]->BinToValue(bin);
   }
 
   /*!
-   * \brief Save binary data to file
-   * \param file File want to write
+   * \brief Write to binary stream
+   * \param writer Writer
+   * \param include_data Whether to write data (true) or just header information (false)
    */
-  void SaveBinaryToFile(const VirtualFileWriter* writer) const {
+  void SerializeToBinary(BinaryWriter* writer, bool include_data = true) const {
     writer->AlignedWrite(&is_multi_val_, sizeof(is_multi_val_));
     writer->AlignedWrite(&is_dense_multi_val_, sizeof(is_dense_multi_val_));
     writer->AlignedWrite(&is_sparse_, sizeof(is_sparse_));
     writer->AlignedWrite(&num_feature_, sizeof(num_feature_));
     for (int i = 0; i < num_feature_; ++i) {
       bin_mappers_[i]->SaveBinaryToFile(writer);
     }
-    if (is_multi_val_) {
-      for (int i = 0; i < num_feature_; ++i) {
-        multi_bin_data_[i]->SaveBinaryToFile(writer);
+
+    if (include_data) {
+      if (is_multi_val_) {
+        for (int i = 0; i < num_feature_; ++i) {
+          multi_bin_data_[i]->SaveBinaryToFile(writer);
+        }
+      } else {
+        bin_data_->SaveBinaryToFile(writer);
       }
-    } else {
-      bin_data_->SaveBinaryToFile(writer);
     }
   }
 
   /*!
    * \brief Get sizes in byte of this object
    */
-  size_t SizesInByte() const {
+  size_t SizesInByte(bool include_data = true) const {
     size_t ret = VirtualFileWriter::AlignedSize(sizeof(is_multi_val_)) +
                  VirtualFileWriter::AlignedSize(sizeof(is_dense_multi_val_)) +
                  VirtualFileWriter::AlignedSize(sizeof(is_sparse_)) +
                  VirtualFileWriter::AlignedSize(sizeof(num_feature_));
     for (int i = 0; i < num_feature_; ++i) {
       ret += bin_mappers_[i]->SizesInByte();
     }
-    if (!is_multi_val_) {
-      ret += bin_data_->SizesInByte();
-    } else {
-      for (int i = 0; i < num_feature_; ++i) {
-        ret += multi_bin_data_[i]->SizesInByte();
+    if (include_data) {
+      if (!is_multi_val_) {
+        ret += bin_data_->SizesInByte();
+      } else {
+        for (int i = 0; i < num_feature_; ++i) {
+          ret += multi_bin_data_[i]->SizesInByte();
+        }
       }
     }
     return ret;
   }
 
   /*! \brief Disable copy */
   FeatureGroup& operator=(const FeatureGroup&) = delete;
@@ -474,14 +533,58 @@
           bin_offsets_[i] -= 1;
         }
         num_total_bin_ -= 1;
       }
     }
   }
 
+  const void* GetColWiseData(const int sub_feature_index,
+    uint8_t* bit_type,
+    bool* is_sparse,
+    std::vector<BinIterator*>* bin_iterator,
+    const int num_threads) const {
+    if (sub_feature_index >= 0) {
+      CHECK(is_multi_val_);
+      return multi_bin_data_[sub_feature_index]->GetColWiseData(bit_type, is_sparse, bin_iterator, num_threads);
+    } else {
+      CHECK(!is_multi_val_);
+      return bin_data_->GetColWiseData(bit_type, is_sparse, bin_iterator, num_threads);
+    }
+  }
+
+  const void* GetColWiseData(const int sub_feature_index,
+    uint8_t* bit_type,
+    bool* is_sparse,
+    BinIterator** bin_iterator) const {
+    if (sub_feature_index >= 0) {
+      CHECK(is_multi_val_);
+      return multi_bin_data_[sub_feature_index]->GetColWiseData(bit_type, is_sparse, bin_iterator);
+    } else {
+      CHECK(!is_multi_val_);
+      return bin_data_->GetColWiseData(bit_type, is_sparse, bin_iterator);
+    }
+  }
+
+  uint32_t feature_max_bin(const int sub_feature_index) {
+    if (!is_multi_val_) {
+      return bin_offsets_[sub_feature_index + 1] - 1;
+    } else {
+      int addi = bin_mappers_[sub_feature_index]->GetMostFreqBin() == 0 ? 0 : 1;
+      return bin_mappers_[sub_feature_index]->num_bin() - 1 + addi;
+    }
+  }
+
+  uint32_t feature_min_bin(const int sub_feature_index) {
+    if (!is_multi_val_) {
+      return bin_offsets_[sub_feature_index];
+    } else {
+      return 1;
+    }
+  }
+
  private:
   void CreateBinData(int num_data, bool is_multi_val, bool force_dense, bool force_sparse) {
     if (is_multi_val) {
       multi_bin_data_.clear();
       for (int i = 0; i < num_feature_; ++i) {
         int addi = bin_mappers_[i]->GetMostFreqBin() == 0 ? 0 : 1;
         if (bin_mappers_[i]->sparse_rate() >= kSparseThreshold) {
```

### Comparing `lightgbm-3.3.5/compile/include/LightGBM/meta.h` & `lightgbm-4.0.0/include/LightGBM/meta.h`

 * *Files 4% similar despite different names*

```diff
@@ -45,14 +45,16 @@
 typedef double label_t;
 #else
 typedef float label_t;
 #endif
 
 const score_t kMinScore = -std::numeric_limits<score_t>::infinity();
 
+const score_t kMaxScore = std::numeric_limits<score_t>::infinity();
+
 const score_t kEpsilon = 1e-15f;
 
 const double kZeroThreshold = 1e-35f;
 
 
 typedef int32_t comm_size_t;
```

### Comparing `lightgbm-3.3.5/compile/include/LightGBM/metric.h` & `lightgbm-4.0.0/include/LightGBM/metric.h`

 * *Files 2% similar despite different names*

```diff
@@ -51,14 +51,19 @@
 
   /*!
   * \brief Create object of metrics
   * \param type Specific type of metric
   * \param config Config for metric
   */
   LIGHTGBM_EXPORT static Metric* CreateMetric(const std::string& type, const Config& config);
+
+  /*!
+  * \brief Whether boosting is done on CUDA
+  */
+  virtual bool IsCUDAMetric() const { return false; }
 };
 
 /*!
 * \brief Static class, used to calculate DCG score
 */
 class DCGCalculator {
  public:
```

### Comparing `lightgbm-3.3.5/compile/include/LightGBM/network.h` & `lightgbm-4.0.0/include/LightGBM/network.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/include/LightGBM/objective_function.h` & `lightgbm-4.0.0/include/LightGBM/objective_function.h`

 * *Files 20% similar despite different names*

```diff
@@ -44,14 +44,17 @@
   virtual bool IsRenewTreeOutput() const { return false; }
 
   virtual double RenewTreeOutput(double ori_output, std::function<double(const label_t*, int)>,
                                  const data_size_t*,
                                  const data_size_t*,
                                  data_size_t) const { return ori_output; }
 
+  virtual void RenewTreeOutputCUDA(const double* /*score*/, const data_size_t* /*data_indices_in_leaf*/, const data_size_t* /*num_data_in_leaf*/,
+    const data_size_t* /*data_start_in_leaf*/, const int /*num_leaves*/, double* /*leaf_value*/) const {}
+
   virtual double BoostFromScore(int /*class_id*/) const { return 0.0; }
 
   virtual bool ClassNeedTrain(int /*class_id*/) const { return true; }
 
   virtual bool SkipEmptyClass() const { return false; }
 
   virtual int NumModelPerIteration() const { return 1; }
@@ -84,12 +87,29 @@
   LIGHTGBM_EXPORT static ObjectiveFunction* CreateObjectiveFunction(const std::string& type,
     const Config& config);
 
   /*!
   * \brief Load objective function from string object
   */
   LIGHTGBM_EXPORT static ObjectiveFunction* CreateObjectiveFunction(const std::string& str);
+
+  /*!
+  * \brief Whether boosting is done on CUDA
+  */
+  virtual bool IsCUDAObjective() const { return false; }
+
+  #ifdef USE_CUDA
+  /*!
+  * \brief Convert output for CUDA version
+  */
+  virtual const double* ConvertOutputCUDA(data_size_t /*num_data*/, const double* input, double* /*output*/) const {
+    return input;
+  }
+
+  virtual bool NeedConvertOutputCUDA () const { return false; }
+
+  #endif  // USE_CUDA
 };
 
 }  // namespace LightGBM
 
 #endif   // LightGBM_OBJECTIVE_FUNCTION_H_
```

### Comparing `lightgbm-3.3.5/compile/include/LightGBM/prediction_early_stop.h` & `lightgbm-4.0.0/include/LightGBM/prediction_early_stop.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/include/LightGBM/tree_learner.h` & `lightgbm-4.0.0/include/LightGBM/tree_learner.h`

 * *Files 11% similar despite different names*

```diff
@@ -10,15 +10,15 @@
 #include <LightGBM/utils/json11.h>
 
 #include <string>
 #include <vector>
 
 namespace LightGBM {
 
-using json11::Json;
+using json11_internal_lightgbm::Json;
 
 /*! \brief forward declaration */
 class Tree;
 class Dataset;
 class ObjectiveFunction;
 
 /*!
@@ -46,14 +46,20 @@
 
   /*!
   * \brief Reset tree configs
   * \param config config of tree
   */
   virtual void ResetConfig(const Config* config) = 0;
 
+  /*!
+  * \brief Reset boosting_on_gpu_
+  * \param boosting_on_gpu flag for boosting on GPU
+  */
+  virtual void ResetBoostingOnGPU(const bool /*boosting_on_gpu*/) {}
+
   virtual void SetForcedSplit(const Json* forced_split_json) = 0;
 
   /*!
   * \brief training tree model on dataset
   * \param gradients The first order gradients
   * \param hessians The second order gradients
   * \param is_first_tree If linear tree learning is enabled, first tree needs to be handled differently
@@ -82,15 +88,15 @@
   /*!
   * \brief Using last trained tree to predict score then adding to out_score;
   * \param out_score output score
   */
   virtual void AddPredictionToScore(const Tree* tree, double* out_score) const = 0;
 
   virtual void RenewTreeOutput(Tree* tree, const ObjectiveFunction* obj, std::function<double(const label_t*, int)> residual_getter,
-                               data_size_t total_num_data, const data_size_t* bag_indices, data_size_t bag_cnt) const = 0;
+                               data_size_t total_num_data, const data_size_t* bag_indices, data_size_t bag_cnt, const double* train_score) const = 0;
 
   TreeLearner() = default;
   /*! \brief Disable copy */
   TreeLearner& operator=(const TreeLearner&) = delete;
   /*! \brief Disable copy */
   TreeLearner(const TreeLearner&) = delete;
 
@@ -99,13 +105,14 @@
   * \param learner_type Type of tree learner
   * \param device_type Type of tree learner
   * \param booster_type Type of boosting
   * \param config config of tree
   */
   static TreeLearner* CreateTreeLearner(const std::string& learner_type,
                                         const std::string& device_type,
-                                        const Config* config);
+                                        const Config* config,
+                                        const bool boosting_on_cuda);
 };
 
 }  // namespace LightGBM
 
 #endif   // LightGBM_TREE_LEARNER_H_
```

### Comparing `lightgbm-3.3.5/compile/include/LightGBM/utils/array_args.h` & `lightgbm-4.0.0/include/LightGBM/utils/array_args.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/include/LightGBM/utils/chunked_array.hpp` & `lightgbm-4.0.0/include/LightGBM/utils/chunked_array.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/include/LightGBM/utils/file_io.h` & `lightgbm-4.0.0/include/LightGBM/utils/file_io.h`

 * *Files 25% similar despite different names*

```diff
@@ -1,71 +1,51 @@
 /*!
  * Copyright (c) 2018 Microsoft Corporation. All rights reserved.
  * Licensed under the MIT License. See LICENSE file in the project root for license information.
  */
 #ifndef LIGHTGBM_UTILS_FILE_IO_H_
 #define LIGHTGBM_UTILS_FILE_IO_H_
 
+#include <LightGBM/utils/binary_writer.h>
+
 #include <string>
 #include <cstdio>
 #include <cstdlib>
 #include <cstring>
 #include <iostream>
 #include <memory>
 #include <vector>
 
 namespace LightGBM {
 
 /*!
  * \brief An interface for writing files from buffers
  */
-struct VirtualFileWriter {
+struct VirtualFileWriter : BinaryWriter {
   virtual ~VirtualFileWriter() {}
+
   /*!
    * \brief Initialize the writer
    * \return True when the file is available for writes
    */
   virtual bool Init() = 0;
-  /*!
-   * \brief Append buffer to file
-   * \param data Buffer to write from
-   * \param bytes Number of bytes to write from buffer
-   * \return Number of bytes written
-   */
-  virtual size_t Write(const void* data, size_t bytes) const = 0;
 
-  size_t AlignedWrite(const void* data, size_t bytes, size_t alignment = 8) const {
-    auto ret = Write(data, bytes);
-    if (bytes % alignment != 0) {
-      size_t padding = AlignedSize(bytes, alignment) - bytes;
-      std::vector<char> tmp(padding, 0);
-      ret += Write(tmp.data(), padding);
-    }
-    return ret;
-  }
   /*!
    * \brief Create appropriate writer for filename
    * \param filename Filename of the data
    * \return File writer instance
    */
   static std::unique_ptr<VirtualFileWriter> Make(const std::string& filename);
+
   /*!
    * \brief Check filename existence
    * \param filename Filename of the data
    * \return True when the file exists
    */
   static bool Exists(const std::string& filename);
-
-  static size_t AlignedSize(size_t bytes, size_t alignment = 8) {
-    if (bytes % alignment == 0) {
-      return bytes;
-    } else {
-      return bytes / alignment * alignment + alignment;
-    }
-  }
 };
 
 /**
  * \brief An interface for reading files into buffers
  */
 struct VirtualFileReader {
   /*!
```

### Comparing `lightgbm-3.3.5/compile/include/LightGBM/utils/json11.h` & `lightgbm-4.0.0/include/LightGBM/utils/json11.h`

 * *Files 3% similar despite different names*

```diff
@@ -56,15 +56,15 @@
 #include <initializer_list>
 #include <map>
 #include <memory>
 #include <string>
 #include <utility>
 #include <vector>
 
-namespace json11 {
+namespace json11_internal_lightgbm {
 
 enum JsonParse { STANDARD, COMMENTS };
 
 class JsonValue;
 
 class Json final {
  public:
@@ -219,8 +219,8 @@
   virtual const Json::array &array_items() const;
   virtual const Json &operator[](size_t i) const;
   virtual const Json::object &object_items() const;
   virtual const Json &operator[](const std::string &key) const;
   virtual ~JsonValue() {}
 };
 
-}  // namespace json11
+}  // namespace json11_internal_lightgbm
```

### Comparing `lightgbm-3.3.5/compile/include/LightGBM/utils/log.h` & `lightgbm-4.0.0/include/LightGBM/utils/log.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/include/LightGBM/utils/openmp_wrapper.h` & `lightgbm-4.0.0/include/LightGBM/utils/openmp_wrapper.h`

 * *Files 10% similar despite different names*

```diff
@@ -21,14 +21,23 @@
   int ret = 1;
 #pragma omp parallel
 #pragma omp master
   { ret = omp_get_num_threads(); }
   return ret;
 }
 
+inline void OMP_SET_NUM_THREADS(int num_threads) {
+  static const int default_omp_num_threads = OMP_NUM_THREADS();
+  if (num_threads > 0) {
+    omp_set_num_threads(num_threads);
+  } else {
+    omp_set_num_threads(default_omp_num_threads);
+  }
+}
+
 class ThreadExceptionHelper {
  public:
   ThreadExceptionHelper() {
     ex_ptr_ = nullptr;
   }
 
   ~ThreadExceptionHelper() {
@@ -90,14 +99,15 @@
 #ifdef __cplusplus
   extern "C" {
 #endif
   /** Fall here if no OPENMP support, so just
       simulate a single thread running.
       All #pragma omp should be ignored by the compiler **/
   inline void omp_set_num_threads(int) __GOMP_NOTHROW {}  // NOLINT (no cast done here)
+  inline void OMP_SET_NUM_THREADS(int) __GOMP_NOTHROW {}
   inline int omp_get_num_threads() __GOMP_NOTHROW {return 1;}
   inline int omp_get_max_threads() __GOMP_NOTHROW {return 1;}
   inline int omp_get_thread_num() __GOMP_NOTHROW {return 0;}
   inline int OMP_NUM_THREADS() __GOMP_NOTHROW { return 1; }
 #ifdef __cplusplus
 }  // extern "C"
 #endif
```

### Comparing `lightgbm-3.3.5/compile/include/LightGBM/utils/pipeline_reader.h` & `lightgbm-4.0.0/include/LightGBM/utils/pipeline_reader.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/include/LightGBM/utils/random.h` & `lightgbm-4.0.0/include/LightGBM/utils/random.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/include/LightGBM/utils/text_reader.h` & `lightgbm-4.0.0/include/LightGBM/utils/text_reader.h`

 * *Files 2% similar despite different names*

```diff
@@ -80,14 +80,25 @@
     return first_line_;
   }
   /*!
   * \brief Get text data that read from file
   * \return Text data, store in std::vector by line
   */
   inline std::vector<std::string>& Lines() { return lines_; }
+  /*!
+  * \brief Get joined text data that read from file
+  * \return Text data, store in std::string, joined all lines by delimiter
+  */
+  inline std::string JoinedLines(std::string delimiter = "\n") {
+    std::stringstream ss;
+    for (auto line : lines_) {
+      ss << line << delimiter;
+    }
+    return ss.str();
+  }
 
   INDEX_T ReadAllAndProcess(const std::function<void(INDEX_T, const char*, size_t)>& process_fun) {
     last_line_ = "";
     INDEX_T total_cnt = 0;
     size_t bytes_read = 0;
     PipelineReader::Read(filename_, skip_bytes_,
         [&process_fun, &bytes_read, &total_cnt, this]
```

### Comparing `lightgbm-3.3.5/compile/include/LightGBM/utils/threading.h` & `lightgbm-4.0.0/include/LightGBM/utils/threading.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/include/LightGBM/utils/yamc/alternate_shared_mutex.hpp` & `lightgbm-4.0.0/include/LightGBM/utils/yamc/alternate_shared_mutex.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/include/LightGBM/utils/yamc/yamc_rwlock_sched.hpp` & `lightgbm-4.0.0/include/LightGBM/utils/yamc/yamc_rwlock_sched.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/include/LightGBM/utils/yamc/yamc_shared_lock.hpp` & `lightgbm-4.0.0/include/LightGBM/utils/yamc/yamc_shared_lock.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/src/application/application.cpp` & `lightgbm-4.0.0/src/application/application.cpp`

 * *Files 2% similar despite different names*

```diff
@@ -27,17 +27,15 @@
 #include "predictor.hpp"
 
 namespace LightGBM {
 
 Application::Application(int argc, char** argv) {
   LoadParameters(argc, argv);
   // set number of threads for openmp
-  if (config_.num_threads > 0) {
-    omp_set_num_threads(config_.num_threads);
-  }
+  OMP_SET_NUM_THREADS(config_.num_threads);
   if (config_.data.size() == 0 && config_.task != TaskType::kConvertModel) {
     Log::Fatal("No training/prediction data, application quit");
   }
 
   if (config_.device_type == std::string("cuda")) {
       LGBM_config_::current_device = lgbm_device_cuda;
   }
@@ -46,44 +44,47 @@
 Application::~Application() {
   if (config_.is_parallel) {
     Network::Dispose();
   }
 }
 
 void Application::LoadParameters(int argc, char** argv) {
+  std::unordered_map<std::string, std::vector<std::string>> all_params;
   std::unordered_map<std::string, std::string> params;
   for (int i = 1; i < argc; ++i) {
-    Config::KV2Map(&params, argv[i]);
+    Config::KV2Map(&all_params, argv[i]);
   }
-  // check for alias
-  ParameterAlias::KeyAliasTransform(&params);
   // read parameters from config file
-  if (params.count("config") > 0) {
-    TextReader<size_t> config_reader(params["config"].c_str(), false);
+  bool config_file_ok = true;
+  if (all_params.count("config") > 0) {
+    TextReader<size_t> config_reader(all_params["config"][0].c_str(), false);
     config_reader.ReadAllLines();
     if (!config_reader.Lines().empty()) {
       for (auto& line : config_reader.Lines()) {
         // remove str after "#"
         if (line.size() > 0 && std::string::npos != line.find_first_of("#")) {
           line.erase(line.find_first_of("#"));
         }
         line = Common::Trim(line);
         if (line.size() == 0) {
           continue;
         }
-        Config::KV2Map(&params, line.c_str());
+        Config::KV2Map(&all_params, line.c_str());
       }
     } else {
-      Log::Warning("Config file %s doesn't exist, will ignore",
-                   params["config"].c_str());
+      config_file_ok = false;
     }
   }
-  // check for alias again
+  Config::SetVerbosity(all_params);
+  // de-duplicate params
+  Config::KeepFirstValues(all_params, &params);
+  if (!config_file_ok) {
+    Log::Warning("Config file %s doesn't exist, will ignore", params["config"].c_str());
+  }
   ParameterAlias::KeyAliasTransform(&params);
-  // load configs
   config_.Set(params);
   Log::Info("Finished loading parameters");
 }
 
 void Application::LoadData() {
   auto start_time = std::chrono::high_resolution_clock::now();
   std::unique_ptr<Predictor> predictor;
@@ -196,15 +197,15 @@
   // initialize the boosting
   boosting_->Init(&config_, train_data_.get(), objective_fun_.get(),
                   Common::ConstPtrInVectorWrapper<Metric>(train_metric_));
   // add validation data into boosting
   for (size_t i = 0; i < valid_datas_.size(); ++i) {
     boosting_->AddValidDataset(valid_datas_[i].get(),
                                Common::ConstPtrInVectorWrapper<Metric>(valid_metrics_[i]));
-    Log::Debug("Number of data points in validation set #%zu: %zu", i + 1, valid_datas_[i]->num_data());
+    Log::Debug("Number of data points in validation set #%zu: %d", i + 1, valid_datas_[i]->num_data());
   }
   Log::Info("Finished initializing training");
 }
 
 void Application::Train() {
   Log::Info("Started training...");
   boosting_->Train(config_.snapshot_freq, config_.output_model);
```

### Comparing `lightgbm-3.3.5/compile/src/application/predictor.hpp` & `lightgbm-4.0.0/src/application/predictor.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -4,14 +4,15 @@
  */
 #ifndef LIGHTGBM_PREDICTOR_HPP_
 #define LIGHTGBM_PREDICTOR_HPP_
 
 #include <LightGBM/boosting.h>
 #include <LightGBM/dataset.h>
 #include <LightGBM/meta.h>
+#include <LightGBM/utils/common.h>
 #include <LightGBM/utils/openmp_wrapper.h>
 #include <LightGBM/utils/text_reader.h>
 
 #include <string>
 #include <cstdio>
 #include <cstring>
 #include <functional>
@@ -163,27 +164,28 @@
   void Predict(const char* data_filename, const char* result_filename, bool header, bool disable_shape_check, bool precise_float_parser) {
     auto writer = VirtualFileWriter::Make(result_filename);
     if (!writer->Init()) {
       Log::Fatal("Prediction results file %s cannot be created", result_filename);
     }
     auto label_idx = header ? -1 : boosting_->LabelIdx();
     auto parser = std::unique_ptr<Parser>(Parser::CreateParser(data_filename, header, boosting_->MaxFeatureIdx() + 1, label_idx,
-                                                               precise_float_parser));
+                                                               precise_float_parser, boosting_->ParserConfigStr()));
 
     if (parser == nullptr) {
       Log::Fatal("Could not recognize the data format of data file %s", data_filename);
     }
     if (!header && !disable_shape_check && parser->NumFeatures() != boosting_->MaxFeatureIdx() + 1) {
       Log::Fatal("The number of features in data (%d) is not the same as it was in training data (%d).\n" \
                  "You can set ``predict_disable_shape_check=true`` to discard this error, but please be aware what you are doing.", parser->NumFeatures(), boosting_->MaxFeatureIdx() + 1);
     }
     TextReader<data_size_t> predict_data_reader(data_filename, header);
     std::vector<int> feature_remapper(parser->NumFeatures(), -1);
     bool need_adjust = false;
-    if (header) {
+    // skip raw feature remapping if trained model has parser config str which may contain actual feature names.
+    if (header && boosting_->ParserConfigStr().empty()) {
       std::string first_line = predict_data_reader.first_line();
       std::vector<std::string> header_words = Common::Split(first_line.c_str(), "\t,");
       std::unordered_map<std::string, int> header_mapper;
       for (int i = 0; i < static_cast<int>(header_words.size()); ++i) {
         if (header_mapper.count(header_words[i]) > 0) {
           Log::Fatal("Feature (%s) appears more than one time.", header_words[i].c_str());
         }
```

### Comparing `lightgbm-3.3.5/compile/src/boosting/boosting.cpp` & `lightgbm-4.0.0/src/boosting/boosting.cpp`

 * *Files 4% similar despite different names*

```diff
@@ -2,15 +2,14 @@
  * Copyright (c) 2016 Microsoft Corporation. All rights reserved.
  * Licensed under the MIT License. See LICENSE file in the project root for license information.
  */
 #include <LightGBM/boosting.h>
 
 #include "dart.hpp"
 #include "gbdt.h"
-#include "goss.hpp"
 #include "rf.hpp"
 
 namespace LightGBM {
 
 std::string GetBoostingTypeFromModelFile(const char* filename) {
   TextReader<size_t> model_reader(filename, true);
   std::string type = model_reader.first_line();
@@ -35,29 +34,29 @@
 Boosting* Boosting::CreateBoosting(const std::string& type, const char* filename) {
   if (filename == nullptr || filename[0] == '\0') {
     if (type == std::string("gbdt")) {
       return new GBDT();
     } else if (type == std::string("dart")) {
       return new DART();
     } else if (type == std::string("goss")) {
-      return new GOSS();
+      return new GBDT();
     } else if (type == std::string("rf")) {
       return new RF();
     } else {
       return nullptr;
     }
   } else {
     std::unique_ptr<Boosting> ret;
     if (GetBoostingTypeFromModelFile(filename) == std::string("tree")) {
       if (type == std::string("gbdt")) {
         ret.reset(new GBDT());
       } else if (type == std::string("dart")) {
         ret.reset(new DART());
       } else if (type == std::string("goss")) {
-        ret.reset(new GOSS());
+        ret.reset(new GBDT());
       } else if (type == std::string("rf")) {
         return new RF();
       } else {
         Log::Fatal("Unknown boosting type %s", type.c_str());
       }
       LoadFileToBoosting(ret.get(), filename);
     } else {
```

### Comparing `lightgbm-3.3.5/compile/src/boosting/dart.hpp` & `lightgbm-4.0.0/src/boosting/dart.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/src/boosting/gbdt.cpp` & `lightgbm-4.0.0/src/boosting/gbdt.cpp`

 * *Files 13% similar despite different names*

```diff
@@ -6,17 +6,19 @@
 
 #include <LightGBM/metric.h>
 #include <LightGBM/network.h>
 #include <LightGBM/objective_function.h>
 #include <LightGBM/prediction_early_stop.h>
 #include <LightGBM/utils/common.h>
 #include <LightGBM/utils/openmp_wrapper.h>
+#include <LightGBM/sample_strategy.h>
 
 #include <chrono>
 #include <ctime>
+#include <queue>
 #include <sstream>
 
 namespace LightGBM {
 
 Common::Timer global_timer;
 
 int LGBM_config_::current_device = lgbm_device_cpu;
@@ -30,21 +32,22 @@
       early_stopping_round_(0),
       es_first_metric_only_(false),
       max_feature_idx_(0),
       num_tree_per_iteration_(1),
       num_class_(1),
       num_iteration_for_pred_(0),
       shrinkage_rate_(0.1f),
-      num_init_iteration_(0),
-      need_re_bagging_(false),
-      balanced_bagging_(false),
-      bagging_runner_(0, bagging_rand_block_) {
+      num_init_iteration_(0) {
   average_output_ = false;
   tree_learner_ = nullptr;
   linear_tree_ = false;
+  data_sample_strategy_.reset(nullptr);
+  gradients_pointer_ = nullptr;
+  hessians_pointer_ = nullptr;
+  boosting_on_gpu_ = false;
 }
 
 GBDT::~GBDT() {
 }
 
 void GBDT::Init(const Config* config, const Dataset* train_data, const ObjectiveFunction* objective_function,
                 const std::vector<const Metric*>& training_metrics) {
@@ -63,14 +66,20 @@
   config_ = std::unique_ptr<Config>(new Config(*config));
   early_stopping_round_ = config_->early_stopping_round;
   es_first_metric_only_ = config_->first_metric_only;
   shrinkage_rate_ = config_->learning_rate;
 
   if (config_->device_type == std::string("cuda")) {
     LGBM_config_::current_learner = use_cuda_learner;
+    #ifdef USE_CUDA
+    if (config_->device_type == std::string("cuda")) {
+      const int gpu_device_id = config_->gpu_device_id >= 0 ? config_->gpu_device_id : 0;
+      CUDASUCCESS_OR_FATAL(cudaSetDevice(gpu_device_id));
+    }
+    #endif  // USE_CUDA
   }
 
   // load forced_splits file
   if (!config->forcedsplits_filename.empty()) {
     std::ifstream forced_splits_file(config->forcedsplits_filename.c_str());
     std::stringstream buffer;
     buffer << forced_splits_file.rdbuf();
@@ -83,71 +92,110 @@
   if (objective_function_ != nullptr) {
     num_tree_per_iteration_ = objective_function_->NumModelPerIteration();
     if (objective_function_->IsRenewTreeOutput() && !config->monotone_constraints.empty()) {
       Log::Fatal("Cannot use ``monotone_constraints`` in %s objective, please disable it.", objective_function_->GetName());
     }
   }
 
+  data_sample_strategy_.reset(SampleStrategy::CreateSampleStrategy(config_.get(), train_data_, objective_function_, num_tree_per_iteration_));
   is_constant_hessian_ = GetIsConstHessian(objective_function);
 
+  boosting_on_gpu_ = objective_function_ != nullptr && objective_function_->IsCUDAObjective() &&
+                     !data_sample_strategy_->IsHessianChange();  // for sample strategy with Hessian change, fall back to boosting on CPU
+
   tree_learner_ = std::unique_ptr<TreeLearner>(TreeLearner::CreateTreeLearner(config_->tree_learner, config_->device_type,
-                                                                              config_.get()));
+                                                                              config_.get(), boosting_on_gpu_));
 
   // init tree learner
   tree_learner_->Init(train_data_, is_constant_hessian_);
   tree_learner_->SetForcedSplit(&forced_splits_json_);
 
   // push training metrics
   training_metrics_.clear();
   for (const auto& metric : training_metrics) {
     training_metrics_.push_back(metric);
   }
   training_metrics_.shrink_to_fit();
 
-  train_score_updater_.reset(new ScoreUpdater(train_data_, num_tree_per_iteration_));
+  #ifdef USE_CUDA
+  if (config_->device_type == std::string("cuda")) {
+    train_score_updater_.reset(new CUDAScoreUpdater(train_data_, num_tree_per_iteration_, boosting_on_gpu_));
+  } else {
+  #endif  // USE_CUDA
+    train_score_updater_.reset(new ScoreUpdater(train_data_, num_tree_per_iteration_));
+  #ifdef USE_CUDA
+  }
+  #endif  // USE_CUDA
 
   num_data_ = train_data_->num_data();
-  // create buffer for gradients and Hessians
-  if (objective_function_ != nullptr) {
-    size_t total_size = static_cast<size_t>(num_data_) * num_tree_per_iteration_;
-    gradients_.resize(total_size);
-    hessians_.resize(total_size);
-  }
+
   // get max feature index
   max_feature_idx_ = train_data_->num_total_features() - 1;
   // get label index
   label_idx_ = train_data_->label_idx();
   // get feature names
   feature_names_ = train_data_->feature_names();
   feature_infos_ = train_data_->feature_infos();
   monotone_constraints_ = config->monotone_constraints;
+  // get parser config file content
+  parser_config_str_ = train_data_->parser_config_str();
+
+  // check that forced splits does not use feature indices larger than dataset size
+  CheckForcedSplitFeatures();
 
   // if need bagging, create buffer
-  ResetBaggingConfig(config_.get(), true);
+  data_sample_strategy_->ResetSampleConfig(config_.get(), true);
+  ResetGradientBuffers();
 
   class_need_train_ = std::vector<bool>(num_tree_per_iteration_, true);
   if (objective_function_ != nullptr && objective_function_->SkipEmptyClass()) {
     CHECK_EQ(num_tree_per_iteration_, num_class_);
     for (int i = 0; i < num_class_; ++i) {
       class_need_train_[i] = objective_function_->ClassNeedTrain(i);
     }
   }
 
   if (config_->linear_tree) {
     linear_tree_ = true;
   }
 }
 
+void GBDT::CheckForcedSplitFeatures() {
+  std::queue<Json> forced_split_nodes;
+  forced_split_nodes.push(forced_splits_json_);
+  while (!forced_split_nodes.empty()) {
+    Json node = forced_split_nodes.front();
+    forced_split_nodes.pop();
+    const int feature_index = node["feature"].int_value();
+    if (feature_index > max_feature_idx_) {
+      Log::Fatal("Forced splits file includes feature index %d, but maximum feature index in dataset is %d",
+        feature_index, max_feature_idx_);
+    }
+    if (node.object_items().count("left") > 0) {
+      forced_split_nodes.push(node["left"]);
+    }
+    if (node.object_items().count("right") > 0) {
+      forced_split_nodes.push(node["right"]);
+    }
+  }
+}
+
 void GBDT::AddValidDataset(const Dataset* valid_data,
                            const std::vector<const Metric*>& valid_metrics) {
   if (!train_data_->CheckAlign(*valid_data)) {
     Log::Fatal("Cannot add validation data, since it has different bin mappers with training data");
   }
   // for a validation dataset, we need its score and metric
-  auto new_score_updater = std::unique_ptr<ScoreUpdater>(new ScoreUpdater(valid_data, num_tree_per_iteration_));
+  auto new_score_updater =
+    #ifdef USE_CUDA
+    config_->device_type == std::string("cuda") ?
+    std::unique_ptr<CUDAScoreUpdater>(new CUDAScoreUpdater(valid_data, num_tree_per_iteration_,
+      objective_function_ != nullptr && objective_function_->IsCUDAObjective())) :
+    #endif  // USE_CUDA
+    std::unique_ptr<ScoreUpdater>(new ScoreUpdater(valid_data, num_tree_per_iteration_));
   // update score
   for (int i = 0; i < iter_; ++i) {
     for (int cur_tree_id = 0; cur_tree_id < num_tree_per_iteration_; ++cur_tree_id) {
       auto curr_tree = (i + num_init_iteration_) * num_tree_per_iteration_ + cur_tree_id;
       new_score_updater->AddScore(models_[curr_tree].get(), cur_tree_id);
     }
   }
@@ -166,103 +214,20 @@
     best_msg_.emplace_back(num_metrics);
   }
 }
 
 void GBDT::Boosting() {
   Common::FunctionTimer fun_timer("GBDT::Boosting", global_timer);
   if (objective_function_ == nullptr) {
-    Log::Fatal("No object function provided");
+    Log::Fatal("No objective function provided");
   }
   // objective function will calculate gradients and hessians
   int64_t num_score = 0;
   objective_function_->
-    GetGradients(GetTrainingScore(&num_score), gradients_.data(), hessians_.data());
-}
-
-data_size_t GBDT::BaggingHelper(data_size_t start, data_size_t cnt, data_size_t* buffer) {
-  if (cnt <= 0) {
-    return 0;
-  }
-  data_size_t cur_left_cnt = 0;
-  data_size_t cur_right_pos = cnt;
-  // random bagging, minimal unit is one record
-  for (data_size_t i = 0; i < cnt; ++i) {
-    auto cur_idx = start + i;
-    if (bagging_rands_[cur_idx / bagging_rand_block_].NextFloat() < config_->bagging_fraction) {
-      buffer[cur_left_cnt++] = cur_idx;
-    } else {
-      buffer[--cur_right_pos] = cur_idx;
-    }
-  }
-  return cur_left_cnt;
-}
-
-data_size_t GBDT::BalancedBaggingHelper(data_size_t start, data_size_t cnt,
-                                        data_size_t* buffer) {
-  if (cnt <= 0) {
-    return 0;
-  }
-  auto label_ptr = train_data_->metadata().label();
-  data_size_t cur_left_cnt = 0;
-  data_size_t cur_right_pos = cnt;
-  // random bagging, minimal unit is one record
-  for (data_size_t i = 0; i < cnt; ++i) {
-    auto cur_idx = start + i;
-    bool is_pos = label_ptr[start + i] > 0;
-    bool is_in_bag = false;
-    if (is_pos) {
-      is_in_bag = bagging_rands_[cur_idx / bagging_rand_block_].NextFloat() <
-                  config_->pos_bagging_fraction;
-    } else {
-      is_in_bag = bagging_rands_[cur_idx / bagging_rand_block_].NextFloat() <
-                  config_->neg_bagging_fraction;
-    }
-    if (is_in_bag) {
-      buffer[cur_left_cnt++] = cur_idx;
-    } else {
-      buffer[--cur_right_pos] = cur_idx;
-    }
-  }
-  return cur_left_cnt;
-}
-
-void GBDT::Bagging(int iter) {
-  Common::FunctionTimer fun_timer("GBDT::Bagging", global_timer);
-  // if need bagging
-  if ((bag_data_cnt_ < num_data_ && iter % config_->bagging_freq == 0) ||
-      need_re_bagging_) {
-    need_re_bagging_ = false;
-    auto left_cnt = bagging_runner_.Run<true>(
-        num_data_,
-        [=](int, data_size_t cur_start, data_size_t cur_cnt, data_size_t* left,
-            data_size_t*) {
-          data_size_t cur_left_count = 0;
-          if (balanced_bagging_) {
-            cur_left_count =
-                BalancedBaggingHelper(cur_start, cur_cnt, left);
-          } else {
-            cur_left_count = BaggingHelper(cur_start, cur_cnt, left);
-          }
-          return cur_left_count;
-        },
-        bag_data_indices_.data());
-    bag_data_cnt_ = left_cnt;
-    Log::Debug("Re-bagging, using %d data to train", bag_data_cnt_);
-    // set bagging data to tree learner
-    if (!is_use_subset_) {
-      tree_learner_->SetBaggingData(nullptr, bag_data_indices_.data(), bag_data_cnt_);
-    } else {
-      // get subset
-      tmp_subset_->ReSize(bag_data_cnt_);
-      tmp_subset_->CopySubrow(train_data_, bag_data_indices_.data(),
-                              bag_data_cnt_, false);
-      tree_learner_->SetBaggingData(tmp_subset_.get(), bag_data_indices_.data(),
-                                    bag_data_cnt_);
-    }
-  }
+    GetGradients(GetTrainingScore(&num_score), gradients_pointer_, hessians_pointer_);
 }
 
 void GBDT::Train(int snapshot_freq, const std::string& model_output_path) {
   Common::FunctionTimer fun_timer("GBDT::Train", global_timer);
   bool is_finished = false;
   auto start_time = std::chrono::steady_clock::now();
   for (int iter = 0; iter < config_->num_iterations && !is_finished; ++iter) {
@@ -307,16 +272,16 @@
       int model_index = iter * num_tree_per_iteration_ + tree_id;
       #pragma omp parallel for schedule(static)
       for (int i = 0; i < num_data_; ++i) {
         leaf_pred[i] = tree_leaf_prediction[i][model_index];
         CHECK_LT(leaf_pred[i], models_[model_index]->num_leaves());
       }
       size_t offset = static_cast<size_t>(tree_id) * num_data_;
-      auto grad = gradients_.data() + offset;
-      auto hess = hessians_.data() + offset;
+      auto grad = gradients_pointer_ + offset;
+      auto hess = hessians_pointer_ + offset;
       auto new_tree = tree_learner_->FitByExistingTree(models_[model_index].get(), leaf_pred, grad, hess);
       train_score_updater_->AddScore(tree_learner_.get(), new_tree, tree_id);
       models_[model_index].reset(new_tree);
     }
   }
 }
 
@@ -371,70 +336,89 @@
   std::vector<double> init_scores(num_tree_per_iteration_, 0.0);
   // boosting first
   if (gradients == nullptr || hessians == nullptr) {
     for (int cur_tree_id = 0; cur_tree_id < num_tree_per_iteration_; ++cur_tree_id) {
       init_scores[cur_tree_id] = BoostFromAverage(cur_tree_id, true);
     }
     Boosting();
-    gradients = gradients_.data();
-    hessians = hessians_.data();
+    gradients = gradients_pointer_;
+    hessians = hessians_pointer_;
+  } else {
+    // use customized objective function
+    CHECK(objective_function_ == nullptr);
+    if (data_sample_strategy_->IsHessianChange()) {
+      // need to copy customized gradients when using GOSS
+      int64_t total_size = static_cast<int64_t>(num_data_) * num_tree_per_iteration_;
+      #pragma omp parallel for schedule(static)
+      for (int64_t i = 0; i < total_size; ++i) {
+        gradients_[i] = gradients[i];
+        hessians_[i] = hessians[i];
+      }
+      CHECK_EQ(gradients_pointer_, gradients_.data());
+      CHECK_EQ(hessians_pointer_, hessians_.data());
+      gradients = gradients_pointer_;
+      hessians = hessians_pointer_;
+    }
   }
+
   // bagging logic
-  Bagging(iter_);
+  data_sample_strategy_->Bagging(iter_, tree_learner_.get(), gradients_.data(), hessians_.data());
+  const bool is_use_subset = data_sample_strategy_->is_use_subset();
+  const data_size_t bag_data_cnt = data_sample_strategy_->bag_data_cnt();
+  const std::vector<data_size_t, Common::AlignmentAllocator<data_size_t, kAlignedSize>>& bag_data_indices = data_sample_strategy_->bag_data_indices();
+
+  if (objective_function_ == nullptr && is_use_subset && bag_data_cnt < num_data_ && !boosting_on_gpu_ && !data_sample_strategy_->IsHessianChange()) {
+    ResetGradientBuffers();
+  }
 
   bool should_continue = false;
   for (int cur_tree_id = 0; cur_tree_id < num_tree_per_iteration_; ++cur_tree_id) {
     const size_t offset = static_cast<size_t>(cur_tree_id) * num_data_;
     std::unique_ptr<Tree> new_tree(new Tree(2, false, false));
     if (class_need_train_[cur_tree_id] && train_data_->num_features() > 0) {
       auto grad = gradients + offset;
       auto hess = hessians + offset;
       // need to copy gradients for bagging subset.
-      if (is_use_subset_ && bag_data_cnt_ < num_data_) {
-        for (int i = 0; i < bag_data_cnt_; ++i) {
-          gradients_[offset + i] = grad[bag_data_indices_[i]];
-          hessians_[offset + i] = hess[bag_data_indices_[i]];
+      if (is_use_subset && bag_data_cnt < num_data_ && !boosting_on_gpu_) {
+        for (int i = 0; i < bag_data_cnt; ++i) {
+          gradients_pointer_[offset + i] = grad[bag_data_indices[i]];
+          hessians_pointer_[offset + i] = hess[bag_data_indices[i]];
         }
-        grad = gradients_.data() + offset;
-        hess = hessians_.data() + offset;
+        grad = gradients_pointer_ + offset;
+        hess = hessians_pointer_ + offset;
       }
       bool is_first_tree = models_.size() < static_cast<size_t>(num_tree_per_iteration_);
       new_tree.reset(tree_learner_->Train(grad, hess, is_first_tree));
     }
 
     if (new_tree->num_leaves() > 1) {
       should_continue = true;
       auto score_ptr = train_score_updater_->score() + offset;
       auto residual_getter = [score_ptr](const label_t* label, int i) {return static_cast<double>(label[i]) - score_ptr[i]; };
       tree_learner_->RenewTreeOutput(new_tree.get(), objective_function_, residual_getter,
-                                     num_data_, bag_data_indices_.data(), bag_data_cnt_);
+                                     num_data_, bag_data_indices.data(), bag_data_cnt, train_score_updater_->score());
       // shrinkage by learning rate
       new_tree->Shrinkage(shrinkage_rate_);
       // update score
       UpdateScore(new_tree.get(), cur_tree_id);
       if (std::fabs(init_scores[cur_tree_id]) > kEpsilon) {
         new_tree->AddBias(init_scores[cur_tree_id]);
       }
     } else {
       // only add default score one-time
       if (models_.size() < static_cast<size_t>(num_tree_per_iteration_)) {
-        double output = 0.0;
-        if (!class_need_train_[cur_tree_id]) {
-          if (objective_function_ != nullptr) {
-            output = objective_function_->BoostFromScore(cur_tree_id);
+        if (objective_function_ != nullptr && !config_->boost_from_average && !train_score_updater_->has_init_score()) {
+          init_scores[cur_tree_id] = ObtainAutomaticInitialScore(objective_function_, cur_tree_id);
+          // updates scores
+          train_score_updater_->AddScore(init_scores[cur_tree_id], cur_tree_id);
+          for (auto& score_updater : valid_score_updater_) {
+            score_updater->AddScore(init_scores[cur_tree_id], cur_tree_id);
           }
-        } else {
-          output = init_scores[cur_tree_id];
-        }
-        new_tree->AsConstantTree(output);
-        // updates scores
-        train_score_updater_->AddScore(output, cur_tree_id);
-        for (auto& score_updater : valid_score_updater_) {
-          score_updater->AddScore(output, cur_tree_id);
         }
+        new_tree->AsConstantTree(init_scores[cur_tree_id]);
       }
     }
     // add model
     models_.push_back(std::move(new_tree));
   }
 
   if (!should_continue) {
@@ -487,47 +471,81 @@
   }
   return is_met_early_stopping;
 }
 
 void GBDT::UpdateScore(const Tree* tree, const int cur_tree_id) {
   Common::FunctionTimer fun_timer("GBDT::UpdateScore", global_timer);
   // update training score
-  if (!is_use_subset_) {
+  if (!data_sample_strategy_->is_use_subset()) {
     train_score_updater_->AddScore(tree_learner_.get(), tree, cur_tree_id);
 
+    const data_size_t bag_data_cnt = data_sample_strategy_->bag_data_cnt();
     // we need to predict out-of-bag scores of data for boosting
-    if (num_data_ - bag_data_cnt_ > 0) {
-      train_score_updater_->AddScore(tree, bag_data_indices_.data() + bag_data_cnt_, num_data_ - bag_data_cnt_, cur_tree_id);
+    if (num_data_ - bag_data_cnt > 0) {
+      #ifdef USE_CUDA
+      if (config_->device_type == std::string("cuda")) {
+        train_score_updater_->AddScore(tree, data_sample_strategy_->cuda_bag_data_indices().RawData() + bag_data_cnt, num_data_ - bag_data_cnt, cur_tree_id);
+      } else {
+      #endif  // USE_CUDA
+        train_score_updater_->AddScore(tree, data_sample_strategy_->bag_data_indices().data() + bag_data_cnt, num_data_ - bag_data_cnt, cur_tree_id);
+      #ifdef USE_CUDA
+      }
+      #endif  // USE_CUDA
     }
 
   } else {
     train_score_updater_->AddScore(tree, cur_tree_id);
   }
 
 
   // update validation score
   for (auto& score_updater : valid_score_updater_) {
     score_updater->AddScore(tree, cur_tree_id);
   }
 }
 
-std::vector<double> GBDT::EvalOneMetric(const Metric* metric, const double* score) const {
-  return metric->Eval(score, objective_function_);
+#ifdef USE_CUDA
+std::vector<double> GBDT::EvalOneMetric(const Metric* metric, const double* score, const data_size_t num_data) const {
+#else
+std::vector<double> GBDT::EvalOneMetric(const Metric* metric, const double* score, const data_size_t /*num_data*/) const {
+#endif  // USE_CUDA
+  #ifdef USE_CUDA
+  const bool evaluation_on_cuda = metric->IsCUDAMetric();
+  if ((boosting_on_gpu_ && evaluation_on_cuda) || (!boosting_on_gpu_ && !evaluation_on_cuda)) {
+  #endif  // USE_CUDA
+    return metric->Eval(score, objective_function_);
+  #ifdef USE_CUDA
+  } else if (boosting_on_gpu_ && !evaluation_on_cuda) {
+    const size_t total_size = static_cast<size_t>(num_data) * static_cast<size_t>(num_tree_per_iteration_);
+    if (total_size > host_score_.size()) {
+      host_score_.resize(total_size, 0.0f);
+    }
+    CopyFromCUDADeviceToHost<double>(host_score_.data(), score, total_size, __FILE__, __LINE__);
+    return metric->Eval(host_score_.data(), objective_function_);
+  } else {
+    const size_t total_size = static_cast<size_t>(num_data) * static_cast<size_t>(num_tree_per_iteration_);
+    if (total_size > cuda_score_.Size()) {
+      cuda_score_.Resize(total_size);
+    }
+    CopyFromHostToCUDADevice<double>(cuda_score_.RawData(), score, total_size, __FILE__, __LINE__);
+    return metric->Eval(cuda_score_.RawData(), objective_function_);
+  }
+  #endif  // USE_CUDA
 }
 
 std::string GBDT::OutputMetric(int iter) {
   bool need_output = (iter % config_->metric_freq) == 0;
   std::string ret = "";
   std::stringstream msg_buf;
   std::vector<std::pair<size_t, size_t>> meet_early_stopping_pairs;
   // print training metric
   if (need_output) {
     for (auto& sub_metric : training_metrics_) {
       auto name = sub_metric->GetName();
-      auto scores = EvalOneMetric(sub_metric, train_score_updater_->score());
+      auto scores = EvalOneMetric(sub_metric, train_score_updater_->score(), train_score_updater_->num_data());
       for (size_t k = 0; k < name.size(); ++k) {
         std::stringstream tmp_buf;
         tmp_buf << "Iteration:" << iter
           << ", training " << name[k]
           << " : " << scores[k];
         Log::Info(tmp_buf.str().c_str());
         if (early_stopping_round_ > 0) {
@@ -536,15 +554,15 @@
       }
     }
   }
   // print validation metric
   if (need_output || early_stopping_round_ > 0) {
     for (size_t i = 0; i < valid_metrics_.size(); ++i) {
       for (size_t j = 0; j < valid_metrics_[i].size(); ++j) {
-        auto test_scores = EvalOneMetric(valid_metrics_[i][j], valid_score_updater_[i]->score());
+        auto test_scores = EvalOneMetric(valid_metrics_[i][j], valid_score_updater_[i]->score(), valid_score_updater_[i]->num_data());
         auto name = valid_metrics_[i][j]->GetName();
         for (size_t k = 0; k < name.size(); ++k) {
           std::stringstream tmp_buf;
           tmp_buf << "Iteration:" << iter
             << ", valid_" << i + 1 << " " << name[k]
             << " : " << test_scores[k];
           if (need_output) {
@@ -576,23 +594,23 @@
 
 /*! \brief Get eval result */
 std::vector<double> GBDT::GetEvalAt(int data_idx) const {
   CHECK(data_idx >= 0 && data_idx <= static_cast<int>(valid_score_updater_.size()));
   std::vector<double> ret;
   if (data_idx == 0) {
     for (auto& sub_metric : training_metrics_) {
-      auto scores = EvalOneMetric(sub_metric, train_score_updater_->score());
+      auto scores = EvalOneMetric(sub_metric, train_score_updater_->score(), train_score_updater_->num_data());
       for (auto score : scores) {
         ret.push_back(score);
       }
     }
   } else {
     auto used_idx = data_idx - 1;
     for (size_t j = 0; j < valid_metrics_[used_idx].size(); ++j) {
-      auto test_scores = EvalOneMetric(valid_metrics_[used_idx][j], valid_score_updater_[used_idx]->score());
+      auto test_scores = EvalOneMetric(valid_metrics_[used_idx][j], valid_score_updater_[used_idx]->score(), valid_score_updater_[used_idx]->num_data());
       for (auto score : test_scores) {
         ret.push_back(score);
       }
     }
   }
   return ret;
 }
@@ -638,14 +656,22 @@
     num_data = train_score_updater_->num_data();
   } else {
     auto used_idx = data_idx - 1;
     raw_scores = valid_score_updater_[used_idx]->score();
     num_data = valid_score_updater_[used_idx]->num_data();
     *out_len = static_cast<int64_t>(num_data) * num_class_;
   }
+  #ifdef USE_CUDA
+  std::vector<double> host_raw_scores;
+  if (boosting_on_gpu_) {
+    host_raw_scores.resize(static_cast<size_t>(*out_len), 0.0);
+    CopyFromCUDADeviceToHost<double>(host_raw_scores.data(), raw_scores, static_cast<size_t>(*out_len), __FILE__, __LINE__);
+    raw_scores = host_raw_scores.data();
+  }
+  #endif  // USE_CUDA
   if (objective_function_ != nullptr) {
     #pragma omp parallel for schedule(static)
     for (data_size_t i = 0; i < num_data; ++i) {
       std::vector<double> tree_pred(num_tree_per_iteration_);
       for (int j = 0; j < num_tree_per_iteration_; ++j) {
         tree_pred[j] = raw_scores[j * num_data + i];
       }
@@ -684,14 +710,15 @@
 void GBDT::ResetTrainingData(const Dataset* train_data, const ObjectiveFunction* objective_function,
                              const std::vector<const Metric*>& training_metrics) {
   if (train_data != train_data_ && !train_data_->CheckAlign(*train_data)) {
     Log::Fatal("Cannot reset training data, since new training data has different bin mappers");
   }
 
   objective_function_ = objective_function;
+  data_sample_strategy_->UpdateObjectiveFunction(objective_function);
   if (objective_function_ != nullptr) {
     CHECK_EQ(num_tree_per_iteration_, objective_function_->NumModelPerIteration());
     if (objective_function_->IsRenewTreeOutput() && !config_->monotone_constraints.empty()) {
       Log::Fatal("Cannot use ``monotone_constraints`` in %s objective, please disable it.", objective_function_->GetName());
     }
   }
   is_constant_hessian_ = GetIsConstHessian(objective_function);
@@ -699,44 +726,55 @@
   // push training metrics
   training_metrics_.clear();
   for (const auto& metric : training_metrics) {
     training_metrics_.push_back(metric);
   }
   training_metrics_.shrink_to_fit();
 
+  #ifdef USE_CUDA
+  boosting_on_gpu_ = objective_function_ != nullptr && objective_function_->IsCUDAObjective() &&
+                    !data_sample_strategy_->IsHessianChange();  // for sample strategy with Hessian change, fall back to boosting on CPU
+  tree_learner_->ResetBoostingOnGPU(boosting_on_gpu_);
+  #endif  // USE_CUDA
+
   if (train_data != train_data_) {
     train_data_ = train_data;
+    data_sample_strategy_->UpdateTrainingData(train_data);
     // not same training data, need reset score and others
     // create score tracker
-    train_score_updater_.reset(new ScoreUpdater(train_data_, num_tree_per_iteration_));
+    #ifdef USE_CUDA
+    if (config_->device_type == std::string("cuda")) {
+      train_score_updater_.reset(new CUDAScoreUpdater(train_data_, num_tree_per_iteration_, boosting_on_gpu_));
+    } else {
+    #endif  // USE_CUDA
+      train_score_updater_.reset(new ScoreUpdater(train_data_, num_tree_per_iteration_));
+    #ifdef USE_CUDA
+    }
+    #endif  // USE_CUDA
 
     // update score
     for (int i = 0; i < iter_; ++i) {
       for (int cur_tree_id = 0; cur_tree_id < num_tree_per_iteration_; ++cur_tree_id) {
         auto curr_tree = (i + num_init_iteration_) * num_tree_per_iteration_ + cur_tree_id;
         train_score_updater_->AddScore(models_[curr_tree].get(), cur_tree_id);
       }
     }
 
     num_data_ = train_data_->num_data();
 
-    // create buffer for gradients and hessians
-    if (objective_function_ != nullptr) {
-      size_t total_size = static_cast<size_t>(num_data_) * num_tree_per_iteration_;
-      gradients_.resize(total_size);
-      hessians_.resize(total_size);
-    }
+    ResetGradientBuffers();
 
     max_feature_idx_ = train_data_->num_total_features() - 1;
     label_idx_ = train_data_->label_idx();
     feature_names_ = train_data_->feature_names();
     feature_infos_ = train_data_->feature_infos();
+    parser_config_str_ = train_data_->parser_config_str();
 
     tree_learner_->ResetTrainingData(train_data, is_constant_hessian_);
-    ResetBaggingConfig(config_.get(), true);
+    data_sample_strategy_->ResetSampleConfig(config_.get(), true);
   } else {
     tree_learner_->ResetIsConstantHessian(is_constant_hessian_);
   }
 }
 
 void GBDT::ResetConfig(const Config* config) {
   auto new_config = std::unique_ptr<Config>(new Config(*config));
@@ -750,16 +788,25 @@
     Log::Fatal("Cannot use ``monotone_constraints`` in %s objective, please disable it.", objective_function_->GetName());
   }
   early_stopping_round_ = new_config->early_stopping_round;
   shrinkage_rate_ = new_config->learning_rate;
   if (tree_learner_ != nullptr) {
     tree_learner_->ResetConfig(new_config.get());
   }
+
+  boosting_on_gpu_ = objective_function_ != nullptr && objective_function_->IsCUDAObjective() &&
+                    !data_sample_strategy_->IsHessianChange();  // for sample strategy with Hessian change, fall back to boosting on CPU
+  tree_learner_->ResetBoostingOnGPU(boosting_on_gpu_);
+
   if (train_data_ != nullptr) {
-    ResetBaggingConfig(new_config.get(), false);
+    data_sample_strategy_->ResetSampleConfig(new_config.get(), false);
+    if (data_sample_strategy_->NeedResizeGradients()) {
+      // resize gradient vectors to copy the customized gradients for goss or bagging with subset
+      ResetGradientBuffers();
+    }
   }
   if (config_.get() != nullptr && config_->forcedsplits_filename != new_config->forcedsplits_filename) {
     // load forced_splits file
     if (!new_config->forcedsplits_filename.empty()) {
       std::ifstream forced_splits_file(
           new_config->forcedsplits_filename.c_str());
       std::stringstream buffer;
@@ -771,68 +818,42 @@
       forced_splits_json_ = Json();
       tree_learner_->SetForcedSplit(nullptr);
     }
   }
   config_.reset(new_config.release());
 }
 
-void GBDT::ResetBaggingConfig(const Config* config, bool is_change_dataset) {
-  // if need bagging, create buffer
-  data_size_t num_pos_data = 0;
+void GBDT::ResetGradientBuffers() {
+  const size_t total_size = static_cast<size_t>(num_data_) * num_tree_per_iteration_;
+  const bool is_use_subset = data_sample_strategy_->is_use_subset();
+  const data_size_t bag_data_cnt = data_sample_strategy_->bag_data_cnt();
   if (objective_function_ != nullptr) {
-    num_pos_data = objective_function_->NumPositiveData();
-  }
-  bool balance_bagging_cond = (config->pos_bagging_fraction < 1.0 || config->neg_bagging_fraction < 1.0) && (num_pos_data > 0);
-  if ((config->bagging_fraction < 1.0 || balance_bagging_cond) && config->bagging_freq > 0) {
-    need_re_bagging_ = false;
-    if (!is_change_dataset &&
-      config_.get() != nullptr && config_->bagging_fraction == config->bagging_fraction && config_->bagging_freq == config->bagging_freq
-      && config_->pos_bagging_fraction == config->pos_bagging_fraction && config_->neg_bagging_fraction == config->neg_bagging_fraction) {
-      return;
-    }
-    if (balance_bagging_cond) {
-      balanced_bagging_ = true;
-      bag_data_cnt_ = static_cast<data_size_t>(num_pos_data * config->pos_bagging_fraction)
-                      + static_cast<data_size_t>((num_data_ - num_pos_data) * config->neg_bagging_fraction);
+    #ifdef USE_CUDA
+    if (config_->device_type == std::string("cuda") && boosting_on_gpu_) {
+      if (cuda_gradients_.Size() < total_size) {
+        cuda_gradients_.Resize(total_size);
+        cuda_hessians_.Resize(total_size);
+      }
+      gradients_pointer_ = cuda_gradients_.RawData();
+      hessians_pointer_ = cuda_hessians_.RawData();
     } else {
-      bag_data_cnt_ = static_cast<data_size_t>(config->bagging_fraction * num_data_);
-    }
-    bag_data_indices_.resize(num_data_);
-    bagging_runner_.ReSize(num_data_);
-    bagging_rands_.clear();
-    for (int i = 0;
-         i < (num_data_ + bagging_rand_block_ - 1) / bagging_rand_block_; ++i) {
-      bagging_rands_.emplace_back(config_->bagging_seed + i);
-    }
-
-    double average_bag_rate =
-        (static_cast<double>(bag_data_cnt_) / num_data_) / config->bagging_freq;
-    is_use_subset_ = false;
-    const int group_threshold_usesubset = 100;
-    if (average_bag_rate <= 0.5
-        && (train_data_->num_feature_groups() < group_threshold_usesubset)) {
-      if (tmp_subset_ == nullptr || is_change_dataset) {
-        tmp_subset_.reset(new Dataset(bag_data_cnt_));
-        tmp_subset_->CopyFeatureMapperFrom(train_data_);
-      }
-      is_use_subset_ = true;
-      Log::Debug("Use subset for bagging");
-    }
-
-    need_re_bagging_ = true;
-
-    if (is_use_subset_ && bag_data_cnt_ < num_data_) {
-      if (objective_function_ == nullptr) {
-        size_t total_size = static_cast<size_t>(num_data_) * num_tree_per_iteration_;
+    #endif  // USE_CUDA
+      if (gradients_.size() < total_size) {
         gradients_.resize(total_size);
         hessians_.resize(total_size);
       }
+      gradients_pointer_ = gradients_.data();
+      hessians_pointer_ = hessians_.data();
+    #ifdef USE_CUDA
+    }
+    #endif  // USE_CUDA
+  } else if (data_sample_strategy_->IsHessianChange() || (is_use_subset && bag_data_cnt < num_data_ && !boosting_on_gpu_)) {
+    if (gradients_.size() < total_size) {
+      gradients_.resize(total_size);
+      hessians_.resize(total_size);
     }
-  } else {
-    bag_data_cnt_ = num_data_;
-    bag_data_indices_.clear();
-    bagging_runner_.ReSize(0);
-    is_use_subset_ = false;
+    gradients_pointer_ = gradients_.data();
+    hessians_pointer_ = hessians_.data();
   }
 }
 
 }  // namespace LightGBM
```

### Comparing `lightgbm-3.3.5/compile/src/boosting/gbdt.h` & `lightgbm-4.0.0/src/boosting/gbdt.h`

 * *Files 18% similar despite different names*

```diff
@@ -7,31 +7,33 @@
 
 #include <LightGBM/boosting.h>
 #include <LightGBM/objective_function.h>
 #include <LightGBM/prediction_early_stop.h>
 #include <LightGBM/cuda/vector_cudahost.h>
 #include <LightGBM/utils/json11.h>
 #include <LightGBM/utils/threading.h>
+#include <LightGBM/sample_strategy.h>
 
 #include <string>
 #include <algorithm>
 #include <cstdio>
 #include <fstream>
 #include <map>
 #include <memory>
 #include <mutex>
 #include <unordered_map>
 #include <utility>
 #include <vector>
 
+#include "cuda/cuda_score_updater.hpp"
 #include "score_updater.hpp"
 
 namespace LightGBM {
 
-using json11::Json;
+using json11_internal_lightgbm::Json;
 
 /*!
 * \brief GBDT algorithm implementation. including Training, prediction, bagging.
 */
 class GBDT : public GBDTBase {
  public:
   /*!
@@ -53,14 +55,19 @@
   * \param training_metrics Training metrics
   */
   void Init(const Config* gbdt_config, const Dataset* train_data,
             const ObjectiveFunction* objective_function,
             const std::vector<const Metric*>& training_metrics) override;
 
   /*!
+  * \brief Traverse the tree of forced splits and check that all indices are less than the number of features.
+  */
+  void CheckForcedSplitFeatures();
+
+  /*!
   * \brief Merge model from other boosting object. Will insert to the front of current boosting object
   * \param other
   */
   void MergeFrom(const Boosting* other) override {
     auto other_gbdt = reinterpret_cast<const GBDT*>(other);
     // tmp move to other vector
     auto original_models = std::move(models_);
@@ -153,14 +160,68 @@
 
   /*!
   * \brief Get current iteration
   */
   int GetCurrentIteration() const override { return static_cast<int>(models_.size()) / num_tree_per_iteration_; }
 
   /*!
+  * \brief Get parameters as a JSON string
+  */
+  std::string GetLoadedParam() const override {
+    if (loaded_parameter_.empty()) {
+      return std::string("{}");
+    }
+    const auto param_types = Config::ParameterTypes();
+    const auto lines = Common::Split(loaded_parameter_.c_str(), "\n");
+    bool first = true;
+    std::stringstream str_buf;
+    str_buf << "{";
+    for (const auto& line : lines) {
+      const auto pair = Common::Split(line.c_str(), ":");
+      if (pair[1] == " ]")
+        continue;
+      if (first) {
+        first = false;
+        str_buf << "\"";
+      } else {
+        str_buf << ",\"";
+      }
+      const auto param = pair[0].substr(1);
+      const auto value_str = pair[1].substr(1, pair[1].size() - 2);
+      const auto param_type = param_types.at(param);
+      str_buf << param << "\": ";
+      if (param_type == "string") {
+        str_buf << "\"" << value_str << "\"";
+      } else if (param_type == "int") {
+        int value;
+        Common::Atoi(value_str.c_str(), &value);
+        str_buf << value;
+      } else if (param_type == "double") {
+        double value;
+        Common::Atof(value_str.c_str(), &value);
+        str_buf << value;
+      } else if (param_type == "bool") {
+        bool value = value_str == "1";
+        str_buf << std::boolalpha << value;
+      } else if (param_type.substr(0, 6) == "vector") {
+        str_buf << "[";
+        if (param_type.substr(7, 6) == "string") {
+          const auto parts = Common::Split(value_str.c_str(), ",");
+          str_buf << "\"" << Common::Join(parts, "\",\"") << "\"";
+        } else {
+          str_buf << value_str;
+        }
+        str_buf << "]";
+      }
+    }
+    str_buf << "}";
+    return str_buf.str();
+  }
+
+  /*!
   * \brief Can use early stopping for prediction or not
   * \return True if cannot use early stopping for prediction
   */
   bool NeedAccuratePrediction() const override {
     if (objective_function_ == nullptr) {
       return true;
     } else {
@@ -189,15 +250,15 @@
   */
   int64_t GetNumPredictAt(int data_idx) const override {
     CHECK(data_idx >= 0 && data_idx <= static_cast<int>(valid_score_updater_.size()));
     data_size_t num_data = train_data_->num_data();
     if (data_idx > 0) {
       num_data = valid_score_updater_[data_idx - 1]->num_data();
     }
-    return num_data * num_class_;
+    return static_cast<int64_t>(num_data) * num_class_;
   }
 
   /*!
   * \brief Get prediction result at data_idx data
   * \param data_idx 0: training data, 1: 1st validation data
   * \param result used to store prediction result, should allocate memory before call this function
   * \param out_len length of returned score
@@ -390,17 +451,19 @@
   /*!
   * \brief Get Type name of this boosting object
   */
   const char* SubModelName() const override { return "tree"; }
 
   bool IsLinear() const override { return linear_tree_; }
 
+  inline std::string ParserConfigStr() const override {return parser_config_str_;}
+
  protected:
   virtual bool GetIsConstHessian(const ObjectiveFunction* objective_function) {
-    if (objective_function != nullptr) {
+    if (objective_function != nullptr && !data_sample_strategy_->IsHessianChange()) {
       return objective_function->IsConstantHessian();
     } else {
       return false;
     }
   }
   /*!
   * \brief Print eval result and check early stopping
@@ -409,52 +472,45 @@
 
   /*!
   * \brief reset config for bagging
   */
   void ResetBaggingConfig(const Config* config, bool is_change_dataset);
 
   /*!
-  * \brief Implement bagging logic
-  * \param iter Current interation
-  */
-  virtual void Bagging(int iter);
-
-  virtual data_size_t BaggingHelper(data_size_t start, data_size_t cnt,
-                                    data_size_t* buffer);
-
-  data_size_t BalancedBaggingHelper(data_size_t start, data_size_t cnt,
-                                    data_size_t* buffer);
-
-  /*!
-  * \brief calculate the object function
+  * \brief calculate the objective function
   */
   virtual void Boosting();
 
   /*!
   * \brief updating score after tree was trained
   * \param tree Trained tree of this iteration
   * \param cur_tree_id Current tree for multiclass training
   */
   virtual void UpdateScore(const Tree* tree, const int cur_tree_id);
 
   /*!
   * \brief eval results for one metric
 
   */
-  virtual std::vector<double> EvalOneMetric(const Metric* metric, const double* score) const;
+  virtual std::vector<double> EvalOneMetric(const Metric* metric, const double* score, const data_size_t num_data) const;
 
   /*!
   * \brief Print metric result of current iteration
   * \param iter Current iteration
   * \return best_msg if met early_stopping
   */
   std::string OutputMetric(int iter);
 
   double BoostFromAverage(int class_id, bool update_scorer);
 
+  /*!
+  * \brief Reset gradient buffers, must be called after sample strategy is reset
+  */
+  void ResetGradientBuffers();
+
   /*! \brief current iteration */
   int iter_;
   /*! \brief Pointer to training data */
   const Dataset* train_data_;
   /*! \brief Config of gbdt */
   std::unique_ptr<Config> config_;
   /*! \brief Tree learner, will use this class to learn trees */
@@ -479,31 +535,45 @@
   std::vector<std::vector<double>> best_score_;
   /*! \brief output message of best iteration */
   std::vector<std::vector<std::string>> best_msg_;
   /*! \brief Trained models(trees) */
   std::vector<std::unique_ptr<Tree>> models_;
   /*! \brief Max feature index of training data*/
   int max_feature_idx_;
+  /*! \brief Parser config file content */
+  std::string parser_config_str_ = "";
 
 #ifdef USE_CUDA
   /*! \brief First order derivative of training data */
   std::vector<score_t, CHAllocator<score_t>> gradients_;
   /*! \brief Second order derivative of training data */
   std::vector<score_t, CHAllocator<score_t>> hessians_;
 #else
   /*! \brief First order derivative of training data */
   std::vector<score_t, Common::AlignmentAllocator<score_t, kAlignedSize>> gradients_;
   /*! \brief Second order derivative of training data */
   std::vector<score_t, Common::AlignmentAllocator<score_t, kAlignedSize>> hessians_;
 #endif
+  /*! \brief Pointer to gradient vector, can be on CPU or GPU */
+  score_t* gradients_pointer_;
+  /*! \brief Pointer to hessian vector, can be on CPU or GPU */
+  score_t* hessians_pointer_;
+  /*! \brief Whether boosting is done on GPU, used for device_type=cuda */
+  bool boosting_on_gpu_;
+  #ifdef USE_CUDA
+  /*! \brief Gradient vector on GPU */
+  CUDAVector<score_t> cuda_gradients_;
+  /*! \brief Hessian vector on GPU */
+  CUDAVector<score_t> cuda_hessians_;
+  /*! \brief Buffer for scores when boosting is on GPU but evaluation is not, used only with device_type=cuda */
+  mutable std::vector<double> host_score_;
+  /*! \brief Buffer for scores when boosting is not on GPU but evaluation is, used only with device_type=cuda */
+  mutable CUDAVector<double> cuda_score_;
+  #endif  // USE_CUDA
 
-  /*! \brief Store the indices of in-bag data */
-  std::vector<data_size_t, Common::AlignmentAllocator<data_size_t, kAlignedSize>> bag_data_indices_;
-  /*! \brief Number of in-bag data */
-  data_size_t bag_data_cnt_;
   /*! \brief Number of training data */
   data_size_t num_data_;
   /*! \brief Number of trees per iterations */
   int num_tree_per_iteration_;
   /*! \brief Number of class */
   int num_class_;
   /*! \brief Index of label column */
@@ -515,26 +585,22 @@
   /*! \brief Shrinkage rate for one iteration */
   double shrinkage_rate_;
   /*! \brief Number of loaded initial models */
   int num_init_iteration_;
   /*! \brief Feature names */
   std::vector<std::string> feature_names_;
   std::vector<std::string> feature_infos_;
-  std::unique_ptr<Dataset> tmp_subset_;
-  bool is_use_subset_;
   std::vector<bool> class_need_train_;
   bool is_constant_hessian_;
   std::unique_ptr<ObjectiveFunction> loaded_objective_;
   bool average_output_;
   bool need_re_bagging_;
   bool balanced_bagging_;
   std::string loaded_parameter_;
   std::vector<int8_t> monotone_constraints_;
-  const int bagging_rand_block_ = 1024;
-  std::vector<Random> bagging_rands_;
-  ParallelPartitionRunner<data_size_t, false> bagging_runner_;
   Json forced_splits_json_;
   bool linear_tree_;
+  std::unique_ptr<SampleStrategy> data_sample_strategy_;
 };
 
 }  // namespace LightGBM
 #endif   // LightGBM_BOOSTING_GBDT_H_
```

### Comparing `lightgbm-3.3.5/compile/src/boosting/gbdt_model_text.cpp` & `lightgbm-4.0.0/src/boosting/gbdt_model_text.cpp`

 * *Files 2% similar despite different names*

```diff
@@ -12,15 +12,15 @@
 #include <sstream>
 #include <vector>
 
 #include "gbdt.h"
 
 namespace LightGBM {
 
-const char* kModelVersion = "v3";
+const char* kModelVersion = "v4";
 
 std::string GBDT::DumpModel(int start_iteration, int num_iteration, int feature_importance_type) const {
   std::stringstream str_buf;
   Common::C_stringstream(str_buf);
 
   str_buf << "{";
   str_buf << "\"name\":\"" << SubModelName() << "\"," << '\n';
@@ -395,14 +395,19 @@
     ss << config_->ToString() << "\n";
     ss << "end of parameters" << '\n';
   } else if (!loaded_parameter_.empty()) {
     ss << "\nparameters:" << '\n';
     ss << loaded_parameter_ << "\n";
     ss << "end of parameters" << '\n';
   }
+  if (!parser_config_str_.empty()) {
+    ss << "\nparser:" << '\n';
+    ss << parser_config_str_ << "\n";
+    ss << "end of parser" << '\n';
+  }
   return ss.str();
 }
 
 bool GBDT::SaveModelToFile(int start_iteration, int num_iteration, int feature_importance_type, const char* filename) const {
   /*! \brief File to write models */
   auto writer = VirtualFileWriter::Make(filename);
   if (!writer->Init()) {
@@ -564,15 +569,15 @@
       OMP_LOOP_EX_END();
     }
     OMP_THROW_EX();
   }
   num_iteration_for_pred_ = static_cast<int>(models_.size()) / num_tree_per_iteration_;
   num_init_iteration_ = num_iteration_for_pred_;
   iter_ = 0;
-  bool is_inparameter = false;
+  bool is_inparameter = false, is_inparser = false;
   std::stringstream ss;
   Common::C_stringstream(ss);
   while (p < end) {
     auto line_len = Common::GetLine(p);
     if (line_len > 0) {
       std::string cur_line(p, line_len);
       if (cur_line == std::string("parameters:")) {
@@ -590,14 +595,36 @@
     }
     p += line_len;
     p = Common::SkipNewLine(p);
   }
   if (!ss.str().empty()) {
     loaded_parameter_ = ss.str();
   }
+  ss.clear();
+  ss.str("");
+  while (p < end) {
+    auto line_len = Common::GetLine(p);
+    if (line_len > 0) {
+      std::string cur_line(p, line_len);
+      if (cur_line == std::string("parser:")) {
+        is_inparser = true;
+      } else if (cur_line == std::string("end of parser")) {
+        p += line_len;
+        p = Common::SkipNewLine(p);
+        break;
+      } else if (is_inparser) {
+        ss << cur_line << "\n";
+      }
+    }
+    p += line_len;
+    p = Common::SkipNewLine(p);
+  }
+  parser_config_str_ = ss.str();
+  ss.clear();
+  ss.str("");
   return true;
 }
 
 std::vector<double> GBDT::FeatureImportance(int num_iteration, int importance_type) const {
   int num_used_model = static_cast<int>(models_.size());
   if (num_iteration > 0) {
     num_iteration += 0;
```

### Comparing `lightgbm-3.3.5/compile/src/boosting/gbdt_prediction.cpp` & `lightgbm-4.0.0/src/boosting/gbdt_prediction.cpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/src/boosting/goss.hpp` & `lightgbm-4.0.0/src/boosting/goss.hpp`

 * *Files 13% similar despite different names*

```diff
@@ -1,83 +1,91 @@
 /*!
- * Copyright (c) 2017 Microsoft Corporation. All rights reserved.
+ * Copyright (c) 2021 Microsoft Corporation. All rights reserved.
  * Licensed under the MIT License. See LICENSE file in the project root for license information.
  */
-#ifndef LIGHTGBM_BOOSTING_GOSS_H_
-#define LIGHTGBM_BOOSTING_GOSS_H_
 
-#include <LightGBM/boosting.h>
+#ifndef LIGHTGBM_BOOSTING_GOSS_HPP_
+#define LIGHTGBM_BOOSTING_GOSS_HPP_
+
 #include <LightGBM/utils/array_args.h>
-#include <LightGBM/utils/log.h>
+#include <LightGBM/sample_strategy.h>
 
-#include <string>
 #include <algorithm>
-#include <chrono>
-#include <cstdio>
-#include <cstdint>
-#include <fstream>
+#include <string>
 #include <vector>
 
-#include "gbdt.h"
-#include "score_updater.hpp"
-
 namespace LightGBM {
 
-class GOSS: public GBDT {
+class GOSSStrategy : public SampleStrategy {
  public:
-  /*!
-  * \brief Constructor
-  */
-  GOSS() : GBDT() {
-  }
-
-  ~GOSS() {
-  }
-
-  void Init(const Config* config, const Dataset* train_data, const ObjectiveFunction* objective_function,
-            const std::vector<const Metric*>& training_metrics) override {
-    GBDT::Init(config, train_data, objective_function, training_metrics);
-    ResetGoss();
-    if (objective_function_ == nullptr) {
-      // use customized objective function
-      size_t total_size = static_cast<size_t>(num_data_) * num_tree_per_iteration_;
-      gradients_.resize(total_size, 0.0f);
-      hessians_.resize(total_size, 0.0f);
-    }
-  }
-
-  void ResetTrainingData(const Dataset* train_data, const ObjectiveFunction* objective_function,
-                         const std::vector<const Metric*>& training_metrics) override {
-    GBDT::ResetTrainingData(train_data, objective_function, training_metrics);
-    ResetGoss();
+  GOSSStrategy(const Config* config, const Dataset* train_data, int num_tree_per_iteration) {
+    config_ = config;
+    train_data_ = train_data;
+    num_tree_per_iteration_ = num_tree_per_iteration;
+    num_data_ = train_data->num_data();
   }
 
-  void ResetConfig(const Config* config) override {
-    GBDT::ResetConfig(config);
-    ResetGoss();
+  ~GOSSStrategy() {
   }
 
-  bool TrainOneIter(const score_t* gradients, const score_t* hessians) override {
-    if (gradients != nullptr) {
-      // use customized objective function
-      CHECK(hessians != nullptr && objective_function_ == nullptr);
-      int64_t total_size = static_cast<int64_t>(num_data_) * num_tree_per_iteration_;
-      #pragma omp parallel for schedule(static)
-      for (int64_t i = 0; i < total_size; ++i) {
-        gradients_[i] = gradients[i];
-        hessians_[i] = hessians[i];
+  void Bagging(int iter, TreeLearner* tree_learner, score_t* gradients, score_t* hessians) override {
+    bag_data_cnt_ = num_data_;
+    // not subsample for first iterations
+    if (iter < static_cast<int>(1.0f / config_->learning_rate)) { return; }
+    auto left_cnt = bagging_runner_.Run<true>(
+        num_data_,
+        [=](int, data_size_t cur_start, data_size_t cur_cnt, data_size_t* left,
+            data_size_t*) {
+          data_size_t cur_left_count = 0;
+          cur_left_count = Helper(cur_start, cur_cnt, left, gradients, hessians);
+          return cur_left_count;
+        },
+        bag_data_indices_.data());
+    bag_data_cnt_ = left_cnt;
+    // set bagging data to tree learner
+    if (!is_use_subset_) {
+      #ifdef USE_CUDA
+      if (config_->device_type == std::string("cuda")) {
+        CopyFromHostToCUDADevice<data_size_t>(cuda_bag_data_indices_.RawData(), bag_data_indices_.data(), static_cast<size_t>(num_data_), __FILE__, __LINE__);
+        tree_learner->SetBaggingData(nullptr, cuda_bag_data_indices_.RawData(), bag_data_cnt_);
+      } else {
+      #endif  // USE_CUDA
+        tree_learner->SetBaggingData(nullptr, bag_data_indices_.data(), bag_data_cnt_);
+      #ifdef USE_CUDA
       }
-      return GBDT::TrainOneIter(gradients_.data(), hessians_.data());
+      #endif  // USE_CUDA
     } else {
-      CHECK(hessians == nullptr);
-      return GBDT::TrainOneIter(nullptr, nullptr);
+      // get subset
+      tmp_subset_->ReSize(bag_data_cnt_);
+      tmp_subset_->CopySubrow(train_data_, bag_data_indices_.data(),
+                              bag_data_cnt_, false);
+      #ifdef USE_CUDA
+      if (config_->device_type == std::string("cuda")) {
+        CopyFromHostToCUDADevice<data_size_t>(cuda_bag_data_indices_.RawData(), bag_data_indices_.data(), static_cast<size_t>(num_data_), __FILE__, __LINE__);
+        tree_learner->SetBaggingData(tmp_subset_.get(), cuda_bag_data_indices_.RawData(),
+                                      bag_data_cnt_);
+      } else {
+      #endif  // USE_CUDA
+        tree_learner->SetBaggingData(tmp_subset_.get(), bag_data_indices_.data(),
+                                     bag_data_cnt_);
+      #ifdef USE_CUDA
+      }
+      #endif  // USE_CUDA
     }
   }
 
-  void ResetGoss() {
+  void ResetSampleConfig(const Config* config, bool /*is_change_dataset*/) override {
+    // Cannot use bagging in GOSS
+    config_ = config;
+    need_resize_gradients_ = false;
+    if (objective_function_ == nullptr) {
+      // resize gradient vectors to copy the customized gradients for goss
+      need_resize_gradients_ = true;
+    }
+
     CHECK_LE(config_->top_rate + config_->other_rate, 1.0f);
     CHECK(config_->top_rate > 0.0f && config_->other_rate > 0.0f);
     if (config_->bagging_freq > 0 && config_->bagging_fraction != 1.0f) {
       Log::Fatal("Cannot use bagging in GOSS");
     }
     Log::Info("Using GOSS");
     balanced_bagging_ = false;
@@ -96,23 +104,28 @@
       tmp_subset_->CopyFeatureMapperFrom(train_data_);
       is_use_subset_ = true;
     }
     // flag to not bagging first
     bag_data_cnt_ = num_data_;
   }
 
-  data_size_t BaggingHelper(data_size_t start, data_size_t cnt, data_size_t* buffer) override {
+  bool IsHessianChange() const override {
+    return true;
+  }
+
+ private:
+  data_size_t Helper(data_size_t start, data_size_t cnt, data_size_t* buffer, score_t* gradients, score_t* hessians) {
     if (cnt <= 0) {
       return 0;
     }
     std::vector<score_t> tmp_gradients(cnt, 0.0f);
     for (data_size_t i = 0; i < cnt; ++i) {
       for (int cur_tree_id = 0; cur_tree_id < num_tree_per_iteration_; ++cur_tree_id) {
         size_t idx = static_cast<size_t>(cur_tree_id) * num_data_ + start + i;
-        tmp_gradients[i] += std::fabs(gradients_[idx] * hessians_[idx]);
+        tmp_gradients[i] += std::fabs(gradients[idx] * hessians[idx]);
       }
     }
     data_size_t top_k = static_cast<data_size_t>(cnt * config_->top_rate);
     data_size_t other_k = static_cast<data_size_t>(cnt * config_->other_rate);
     top_k = std::max(1, top_k);
     ArrayArgs<score_t>::ArgMaxAtK(&tmp_gradients, 0, static_cast<int>(tmp_gradients.size()), top_k - 1);
     score_t threshold = tmp_gradients[top_k - 1];
@@ -122,67 +135,36 @@
     data_size_t cur_right_pos = cnt;
     data_size_t big_weight_cnt = 0;
     for (data_size_t i = 0; i < cnt; ++i) {
       auto cur_idx = start + i;
       score_t grad = 0.0f;
       for (int cur_tree_id = 0; cur_tree_id < num_tree_per_iteration_; ++cur_tree_id) {
         size_t idx = static_cast<size_t>(cur_tree_id) * num_data_ + cur_idx;
-        grad += std::fabs(gradients_[idx] * hessians_[idx]);
+        grad += std::fabs(gradients[idx] * hessians[idx]);
       }
       if (grad >= threshold) {
         buffer[cur_left_cnt++] = cur_idx;
         ++big_weight_cnt;
       } else {
         data_size_t sampled = cur_left_cnt - big_weight_cnt;
         data_size_t rest_need = other_k - sampled;
         data_size_t rest_all = (cnt - i) - (top_k - big_weight_cnt);
         double prob = (rest_need) / static_cast<double>(rest_all);
         if (bagging_rands_[cur_idx / bagging_rand_block_].NextFloat() < prob) {
           buffer[cur_left_cnt++] = cur_idx;
           for (int cur_tree_id = 0; cur_tree_id < num_tree_per_iteration_; ++cur_tree_id) {
             size_t idx = static_cast<size_t>(cur_tree_id) * num_data_ + cur_idx;
-            gradients_[idx] *= multiply;
-            hessians_[idx] *= multiply;
+            gradients[idx] *= multiply;
+            hessians[idx] *= multiply;
           }
         } else {
           buffer[--cur_right_pos] = cur_idx;
         }
       }
     }
     return cur_left_cnt;
   }
-
-  void Bagging(int iter) override {
-    bag_data_cnt_ = num_data_;
-    // not subsample for first iterations
-    if (iter < static_cast<int>(1.0f / config_->learning_rate)) { return; }
-    auto left_cnt = bagging_runner_.Run<true>(
-        num_data_,
-        [=](int, data_size_t cur_start, data_size_t cur_cnt, data_size_t* left,
-            data_size_t*) {
-          data_size_t cur_left_count = 0;
-          cur_left_count = BaggingHelper(cur_start, cur_cnt, left);
-          return cur_left_count;
-        },
-        bag_data_indices_.data());
-    bag_data_cnt_ = left_cnt;
-    // set bagging data to tree learner
-    if (!is_use_subset_) {
-      tree_learner_->SetBaggingData(nullptr, bag_data_indices_.data(), bag_data_cnt_);
-    } else {
-      // get subset
-      tmp_subset_->ReSize(bag_data_cnt_);
-      tmp_subset_->CopySubrow(train_data_, bag_data_indices_.data(),
-                              bag_data_cnt_, false);
-      tree_learner_->SetBaggingData(tmp_subset_.get(), bag_data_indices_.data(),
-                                    bag_data_cnt_);
-    }
-  }
-
- protected:
-  bool GetIsConstHessian(const ObjectiveFunction*) override {
-    return false;
-  }
 };
 
 }  // namespace LightGBM
-#endif   // LIGHTGBM_BOOSTING_GOSS_H_
+
+#endif  // LIGHTGBM_BOOSTING_GOSS_HPP_
```

### Comparing `lightgbm-3.3.5/compile/src/boosting/prediction_early_stop.cpp` & `lightgbm-4.0.0/src/boosting/prediction_early_stop.cpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/src/boosting/rf.hpp` & `lightgbm-4.0.0/src/boosting/rf.hpp`

 * *Files 8% similar despite different names*

```diff
@@ -28,39 +28,47 @@
     average_output_ = true;
   }
 
   ~RF() {}
 
   void Init(const Config* config, const Dataset* train_data, const ObjectiveFunction* objective_function,
     const std::vector<const Metric*>& training_metrics) override {
-    CHECK(config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f);
-    CHECK(config->feature_fraction <= 1.0f && config->feature_fraction > 0.0f);
+    if (config->data_sample_strategy == std::string("bagging")) {
+      CHECK((config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) ||
+            (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f));
+    } else {
+      CHECK_EQ(config->data_sample_strategy, std::string("goss"));
+    }
     GBDT::Init(config, train_data, objective_function, training_metrics);
 
     if (num_init_iteration_ > 0) {
       for (int cur_tree_id = 0; cur_tree_id < num_tree_per_iteration_; ++cur_tree_id) {
         MultiplyScore(cur_tree_id, 1.0f / num_init_iteration_);
       }
     } else {
       CHECK_EQ(train_data->metadata().init_score(), nullptr);
     }
     CHECK_EQ(num_tree_per_iteration_, num_class_);
     // not shrinkage rate for the RF
     shrinkage_rate_ = 1.0f;
     // only boosting one time
     Boosting();
-    if (is_use_subset_ && bag_data_cnt_ < num_data_) {
+    if (data_sample_strategy_->is_use_subset() && data_sample_strategy_->bag_data_cnt() < num_data_) {
       tmp_grad_.resize(num_data_);
       tmp_hess_.resize(num_data_);
     }
   }
 
   void ResetConfig(const Config* config) override {
-    CHECK(config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f);
-    CHECK(config->feature_fraction <= 1.0f && config->feature_fraction > 0.0f);
+    if (config->data_sample_strategy == std::string("bagging")) {
+      CHECK((config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) ||
+            (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f));
+    } else {
+      CHECK_EQ(config->data_sample_strategy, std::string("goss"));
+    }
     GBDT::ResetConfig(config);
     // not shrinkage rate for the RF
     shrinkage_rate_ = 1.0f;
   }
 
   void ResetTrainingData(const Dataset* train_data, const ObjectiveFunction* objective_function,
     const std::vector<const Metric*>& training_metrics) override {
@@ -69,15 +77,15 @@
       for (int cur_tree_id = 0; cur_tree_id < num_tree_per_iteration_; ++cur_tree_id) {
         train_score_updater_->MultiplyScore(1.0f / (iter_ + num_init_iteration_), cur_tree_id);
       }
     }
     CHECK_EQ(num_tree_per_iteration_, num_class_);
     // only boosting one time
     Boosting();
-    if (is_use_subset_ && bag_data_cnt_ < num_data_) {
+    if (data_sample_strategy_->is_use_subset() && data_sample_strategy_->bag_data_cnt() < num_data_) {
       tmp_grad_.resize(num_data_);
       tmp_hess_.resize(num_data_);
     }
   }
 
   void Boosting() override {
     if (objective_function_ == nullptr) {
@@ -98,45 +106,48 @@
     }
     objective_function_->
       GetGradients(tmp_scores.data(), gradients_.data(), hessians_.data());
   }
 
   bool TrainOneIter(const score_t* gradients, const score_t* hessians) override {
     // bagging logic
-    Bagging(iter_);
+    data_sample_strategy_ ->Bagging(iter_, tree_learner_.get(), gradients_.data(), hessians_.data());
+    const bool is_use_subset = data_sample_strategy_->is_use_subset();
+    const data_size_t bag_data_cnt = data_sample_strategy_->bag_data_cnt();
+    const std::vector<data_size_t, Common::AlignmentAllocator<data_size_t, kAlignedSize>>& bag_data_indices = data_sample_strategy_->bag_data_indices();
+
     CHECK_EQ(gradients, nullptr);
     CHECK_EQ(hessians, nullptr);
 
     gradients = gradients_.data();
     hessians = hessians_.data();
     for (int cur_tree_id = 0; cur_tree_id < num_tree_per_iteration_; ++cur_tree_id) {
       std::unique_ptr<Tree> new_tree(new Tree(2, false, false));
       size_t offset = static_cast<size_t>(cur_tree_id)* num_data_;
       if (class_need_train_[cur_tree_id]) {
         auto grad = gradients + offset;
         auto hess = hessians + offset;
 
-        // need to copy gradients for bagging subset.
-        if (is_use_subset_ && bag_data_cnt_ < num_data_) {
-          for (int i = 0; i < bag_data_cnt_; ++i) {
-            tmp_grad_[i] = grad[bag_data_indices_[i]];
-            tmp_hess_[i] = hess[bag_data_indices_[i]];
+        if (is_use_subset && bag_data_cnt < num_data_ && !boosting_on_gpu_) {
+          for (int i = 0; i < bag_data_cnt; ++i) {
+            tmp_grad_[i] = grad[bag_data_indices[i]];
+            tmp_hess_[i] = hess[bag_data_indices[i]];
           }
           grad = tmp_grad_.data();
           hess = tmp_hess_.data();
         }
 
         new_tree.reset(tree_learner_->Train(grad, hess, false));
       }
 
       if (new_tree->num_leaves() > 1) {
         double pred = init_scores_[cur_tree_id];
         auto residual_getter = [pred](const label_t* label, int i) {return static_cast<double>(label[i]) - pred; };
         tree_learner_->RenewTreeOutput(new_tree.get(), objective_function_, residual_getter,
-          num_data_, bag_data_indices_.data(), bag_data_cnt_);
+          num_data_, bag_data_indices.data(), bag_data_cnt, train_score_updater_->score());
         if (std::fabs(init_scores_[cur_tree_id]) > kEpsilon) {
           new_tree->AddBias(init_scores_[cur_tree_id]);
         }
         // update score
         MultiplyScore(cur_tree_id, (iter_ + num_init_iteration_));
         UpdateScore(new_tree.get(), cur_tree_id);
         MultiplyScore(cur_tree_id, 1.0 / (iter_ + num_init_iteration_ + 1));
```

### Comparing `lightgbm-3.3.5/compile/src/boosting/score_updater.hpp` & `lightgbm-4.0.0/src/boosting/score_updater.hpp`

 * *Files 4% similar despite different names*

```diff
@@ -42,83 +42,83 @@
 #pragma omp parallel for schedule(static, 512) if (total_size >= 1024)
       for (int64_t i = 0; i < total_size; ++i) {
         score_[i] = init_score[i];
       }
     }
   }
   /*! \brief Destructor */
-  ~ScoreUpdater() {
+  virtual ~ScoreUpdater() {
   }
 
   inline bool has_init_score() const { return has_init_score_; }
 
-  inline void AddScore(double val, int cur_tree_id) {
+  virtual inline void AddScore(double val, int cur_tree_id) {
     Common::FunctionTimer fun_timer("ScoreUpdater::AddScore", global_timer);
     const size_t offset = static_cast<size_t>(num_data_) * cur_tree_id;
 #pragma omp parallel for schedule(static, 512) if (num_data_ >= 1024)
     for (int i = 0; i < num_data_; ++i) {
       score_[offset + i] += val;
     }
   }
 
-  inline void MultiplyScore(double val, int cur_tree_id) {
+  virtual inline void MultiplyScore(double val, int cur_tree_id) {
     const size_t offset = static_cast<size_t>(num_data_) * cur_tree_id;
 #pragma omp parallel for schedule(static, 512) if (num_data_ >= 1024)
     for (int i = 0; i < num_data_; ++i) {
       score_[offset + i] *= val;
     }
   }
   /*!
   * \brief Using tree model to get prediction number, then adding to scores for all data
   *        Note: this function generally will be used on validation data too.
   * \param tree Trained tree model
   * \param cur_tree_id Current tree for multiclass training
   */
-  inline void AddScore(const Tree* tree, int cur_tree_id) {
+  virtual inline void AddScore(const Tree* tree, int cur_tree_id) {
     Common::FunctionTimer fun_timer("ScoreUpdater::AddScore", global_timer);
     const size_t offset = static_cast<size_t>(num_data_) * cur_tree_id;
     tree->AddPredictionToScore(data_, num_data_, score_.data() + offset);
   }
   /*!
   * \brief Adding prediction score, only used for training data.
   *        The training data is partitioned into tree leaves after training
   *        Based on which We can get prediction quickly.
   * \param tree_learner
   * \param cur_tree_id Current tree for multiclass training
   */
-  inline void AddScore(const TreeLearner* tree_learner, const Tree* tree, int cur_tree_id) {
+  virtual inline void AddScore(const TreeLearner* tree_learner, const Tree* tree, int cur_tree_id) {
     Common::FunctionTimer fun_timer("ScoreUpdater::AddScore", global_timer);
     const size_t offset = static_cast<size_t>(num_data_) * cur_tree_id;
     tree_learner->AddPredictionToScore(tree, score_.data() + offset);
   }
   /*!
   * \brief Using tree model to get prediction number, then adding to scores for parts of data
   *        Used for prediction of training out-of-bag data
   * \param tree Trained tree model
   * \param data_indices Indices of data that will be processed
   * \param data_cnt Number of data that will be processed
   * \param cur_tree_id Current tree for multiclass training
   */
-  inline void AddScore(const Tree* tree, const data_size_t* data_indices,
+  virtual inline void AddScore(const Tree* tree, const data_size_t* data_indices,
                        data_size_t data_cnt, int cur_tree_id) {
     Common::FunctionTimer fun_timer("ScoreUpdater::AddScore", global_timer);
     const size_t offset = static_cast<size_t>(num_data_) * cur_tree_id;
     tree->AddPredictionToScore(data_, data_indices, data_cnt, score_.data() + offset);
   }
   /*! \brief Pointer of score */
-  inline const double* score() const { return score_.data(); }
+  virtual inline const double* score() const { return score_.data(); }
 
   inline data_size_t num_data() const { return num_data_; }
 
   /*! \brief Disable copy */
   ScoreUpdater& operator=(const ScoreUpdater&) = delete;
   /*! \brief Disable copy */
   ScoreUpdater(const ScoreUpdater&) = delete;
 
- private:
+ protected:
   /*! \brief Number of total data */
   data_size_t num_data_;
   /*! \brief Pointer of data set */
   const Dataset* data_;
   /*! \brief Scores for data set */
   std::vector<double, Common::AlignmentAllocator<double, kAlignedSize>> score_;
   bool has_init_score_;
```

### Comparing `lightgbm-3.3.5/compile/src/c_api.cpp` & `lightgbm-4.0.0/src/c_api.cpp`

 * *Files 6% similar despite different names*

```diff
@@ -8,14 +8,15 @@
 #include <LightGBM/config.h>
 #include <LightGBM/dataset.h>
 #include <LightGBM/dataset_loader.h>
 #include <LightGBM/metric.h>
 #include <LightGBM/network.h>
 #include <LightGBM/objective_function.h>
 #include <LightGBM/prediction_early_stop.h>
+#include <LightGBM/utils/byte_buffer.h>
 #include <LightGBM/utils/common.h>
 #include <LightGBM/utils/log.h>
 #include <LightGBM/utils/openmp_wrapper.h>
 #include <LightGBM/utils/random.h>
 #include <LightGBM/utils/threading.h>
 
 #include <string>
@@ -109,17 +110,15 @@
     boosting_.reset(Boosting::CreateBoosting("gbdt", filename));
   }
 
   Booster(const Dataset* train_data,
           const char* parameters) {
     auto param = Config::Str2Map(parameters);
     config_.Set(param);
-    if (config_.num_threads > 0) {
-      omp_set_num_threads(config_.num_threads);
-    }
+    OMP_SET_NUM_THREADS(config_.num_threads);
     // create boosting
     if (config_.input_model.size() > 0) {
       Log::Warning("Continued train from model is not supported for c_api,\n"
                    "please use continued train with input score");
     }
 
     boosting_.reset(Boosting::CreateBoosting(config_.boosting, nullptr));
@@ -310,17 +309,15 @@
     if (param.count("metric") && new_config.metric != config_.metric) {
       Log::Fatal("Cannot change metric during training");
     }
     CheckDatasetResetConfig(config_, param);
 
     config_.Set(param);
 
-    if (config_.num_threads > 0) {
-      omp_set_num_threads(config_.num_threads);
-    }
+    OMP_SET_NUM_THREADS(config_.num_threads);
 
     if (param.count("objective")) {
       // create objective function
       objective_fun_.reset(ObjectiveFunction::CreateObjectiveFunction(config_.objective,
                                                                       config_));
       if (objective_fun_ == nullptr) {
         Log::Warning("Using self-defined objective function");
@@ -888,14 +885,26 @@
 
 // start of c_api functions
 
 const char* LGBM_GetLastError() {
   return LastErrorMsg();
 }
 
+int LGBM_DumpParamAliases(int64_t buffer_len,
+                          int64_t* out_len,
+                          char* out_str) {
+  API_BEGIN();
+  std::string aliases = Config::DumpAliases();
+  *out_len = static_cast<int64_t>(aliases.size()) + 1;
+  if (*out_len <= buffer_len) {
+    std::memcpy(out_str, aliases.c_str(), *out_len);
+  }
+  API_END();
+}
+
 int LGBM_RegisterLogCallback(void (*callback)(const char*)) {
   API_BEGIN();
   Log::ResetCallBack(callback);
   API_END();
 }
 
 static inline int SampleCount(int32_t total_nrow, const Config& config) {
@@ -939,74 +948,123 @@
 
   auto sample_indices = CreateSampleIndices(num_total_row, config);
   memcpy(out, sample_indices.data(), sizeof(int32_t) * sample_indices.size());
   *out_len = static_cast<int32_t>(sample_indices.size());
   API_END();
 }
 
+int LGBM_ByteBufferGetAt(ByteBufferHandle handle, int32_t index, uint8_t* out_val) {
+  API_BEGIN();
+  LightGBM::ByteBuffer* byteBuffer = reinterpret_cast<LightGBM::ByteBuffer*>(handle);
+  *out_val = byteBuffer->GetAt(index);
+  API_END();
+}
+
+int LGBM_ByteBufferFree(ByteBufferHandle handle) {
+  API_BEGIN();
+  delete reinterpret_cast<LightGBM::ByteBuffer*>(handle);
+  API_END();
+}
+
 int LGBM_DatasetCreateFromFile(const char* filename,
                                const char* parameters,
                                const DatasetHandle reference,
                                DatasetHandle* out) {
   API_BEGIN();
   auto param = Config::Str2Map(parameters);
   Config config;
   config.Set(param);
-  if (config.num_threads > 0) {
-    omp_set_num_threads(config.num_threads);
-  }
+  OMP_SET_NUM_THREADS(config.num_threads);
   DatasetLoader loader(config, nullptr, 1, filename);
   if (reference == nullptr) {
     if (Network::num_machines() == 1) {
       *out = loader.LoadFromFile(filename);
     } else {
       *out = loader.LoadFromFile(filename, Network::rank(), Network::num_machines());
     }
   } else {
     *out = loader.LoadFromFileAlignWithOtherDataset(filename,
                                                     reinterpret_cast<const Dataset*>(reference));
   }
   API_END();
 }
 
-
 int LGBM_DatasetCreateFromSampledColumn(double** sample_data,
                                         int** sample_indices,
                                         int32_t ncol,
                                         const int* num_per_col,
                                         int32_t num_sample_row,
-                                        int32_t num_total_row,
+                                        int32_t num_local_row,
+                                        int64_t num_dist_row,
                                         const char* parameters,
                                         DatasetHandle* out) {
   API_BEGIN();
   auto param = Config::Str2Map(parameters);
   Config config;
   config.Set(param);
-  if (config.num_threads > 0) {
-    omp_set_num_threads(config.num_threads);
-  }
+  OMP_SET_NUM_THREADS(config.num_threads);
   DatasetLoader loader(config, nullptr, 1, nullptr);
-  *out = loader.ConstructFromSampleData(sample_data, sample_indices, ncol, num_per_col,
+  *out = loader.ConstructFromSampleData(sample_data,
+                                        sample_indices,
+                                        ncol,
+                                        num_per_col,
                                         num_sample_row,
-                                        static_cast<data_size_t>(num_total_row));
+                                        static_cast<data_size_t>(num_local_row),
+                                        num_dist_row);
   API_END();
 }
 
-
 int LGBM_DatasetCreateByReference(const DatasetHandle reference,
                                   int64_t num_total_row,
                                   DatasetHandle* out) {
   API_BEGIN();
   std::unique_ptr<Dataset> ret;
-  ret.reset(new Dataset(static_cast<data_size_t>(num_total_row)));
-  ret->CreateValid(reinterpret_cast<const Dataset*>(reference));
+  data_size_t nrows = static_cast<data_size_t>(num_total_row);
+  ret.reset(new Dataset(nrows));
+  const Dataset* reference_dataset = reinterpret_cast<const Dataset*>(reference);
+  ret->CreateValid(reference_dataset);
+  ret->InitByReference(nrows, reference_dataset);
   *out = ret.release();
   API_END();
 }
 
+int LGBM_DatasetCreateFromSerializedReference(const void* ref_buffer,
+                                              int32_t ref_buffer_size,
+                                              int64_t num_row,
+                                              int32_t num_classes,
+                                              const char* parameters,
+                                              DatasetHandle* out) {
+  API_BEGIN();
+  auto param = Config::Str2Map(parameters);
+  Config config;
+  config.Set(param);
+  OMP_SET_NUM_THREADS(config.num_threads);
+  DatasetLoader loader(config, nullptr, 1, nullptr);
+  *out = loader.LoadFromSerializedReference(static_cast<const char*>(ref_buffer),
+    static_cast<size_t>(ref_buffer_size),
+    static_cast<data_size_t>(num_row),
+    num_classes);
+  API_END();
+}
+
+int LGBM_DatasetInitStreaming(DatasetHandle dataset,
+                              int32_t has_weights,
+                              int32_t has_init_scores,
+                              int32_t has_queries,
+                              int32_t nclasses,
+                              int32_t nthreads,
+                              int32_t omp_max_threads) {
+  API_BEGIN();
+  auto p_dataset = reinterpret_cast<Dataset*>(dataset);
+  auto num_data = p_dataset->num_data();
+  p_dataset->InitStreaming(num_data, has_weights, has_init_scores, has_queries, nclasses, nthreads, omp_max_threads);
+  p_dataset->set_wait_for_manual_finish(true);
+  API_END();
+}
+
 int LGBM_DatasetPushRows(DatasetHandle dataset,
                          const void* data,
                          int data_type,
                          int32_t nrow,
                          int32_t ncol,
                          int32_t start_row) {
   API_BEGIN();
@@ -1021,15 +1079,61 @@
     OMP_LOOP_EX_BEGIN();
     const int tid = omp_get_thread_num();
     auto one_row = get_row_fun(i);
     p_dataset->PushOneRow(tid, start_row + i, one_row);
     OMP_LOOP_EX_END();
   }
   OMP_THROW_EX();
-  if (start_row + nrow == p_dataset->num_data()) {
+  if (!p_dataset->wait_for_manual_finish() && (start_row + nrow == p_dataset->num_data())) {
+    p_dataset->FinishLoad();
+  }
+  API_END();
+}
+
+int LGBM_DatasetPushRowsWithMetadata(DatasetHandle dataset,
+                                     const void* data,
+                                     int data_type,
+                                     int32_t nrow,
+                                     int32_t ncol,
+                                     int32_t start_row,
+                                     const float* labels,
+                                     const float* weights,
+                                     const double* init_scores,
+                                     const int32_t* queries,
+                                     int32_t tid) {
+  API_BEGIN();
+#ifdef LABEL_T_USE_DOUBLE
+  Log::Fatal("Don't support LABEL_T_USE_DOUBLE");
+#endif
+  if (!data) {
+    Log::Fatal("data cannot be null.");
+  }
+  auto p_dataset = reinterpret_cast<Dataset*>(dataset);
+  auto get_row_fun = RowFunctionFromDenseMatric(data, nrow, ncol, data_type, 1);
+  if (p_dataset->has_raw()) {
+    p_dataset->ResizeRaw(p_dataset->num_numeric_features() + nrow);
+  }
+
+  const int max_omp_threads = p_dataset->omp_max_threads() > 0 ? p_dataset->omp_max_threads() : OMP_NUM_THREADS();
+
+  OMP_INIT_EX();
+#pragma omp parallel for schedule(static)
+  for (int i = 0; i < nrow; ++i) {
+    OMP_LOOP_EX_BEGIN();
+    // convert internal thread id to be unique based on external thread id
+    const int internal_tid = omp_get_thread_num() + (max_omp_threads * tid);
+    auto one_row = get_row_fun(i);
+    p_dataset->PushOneRow(internal_tid, start_row + i, one_row);
+    OMP_LOOP_EX_END();
+  }
+  OMP_THROW_EX();
+
+  p_dataset->InsertMetadataAt(start_row, nrow, labels, weights, init_scores, queries);
+
+  if (!p_dataset->wait_for_manual_finish() && (start_row + nrow == p_dataset->num_data())) {
     p_dataset->FinishLoad();
   }
   API_END();
 }
 
 int LGBM_DatasetPushRowsByCSR(DatasetHandle dataset,
                               const void* indptr,
@@ -1054,20 +1158,84 @@
     OMP_LOOP_EX_BEGIN();
     const int tid = omp_get_thread_num();
     auto one_row = get_row_fun(i);
     p_dataset->PushOneRow(tid, static_cast<data_size_t>(start_row + i), one_row);
     OMP_LOOP_EX_END();
   }
   OMP_THROW_EX();
-  if (start_row + nrow == static_cast<int64_t>(p_dataset->num_data())) {
+  if (!p_dataset->wait_for_manual_finish() && (start_row + nrow == static_cast<int64_t>(p_dataset->num_data()))) {
     p_dataset->FinishLoad();
   }
   API_END();
 }
 
+int LGBM_DatasetPushRowsByCSRWithMetadata(DatasetHandle dataset,
+                                          const void* indptr,
+                                          int indptr_type,
+                                          const int32_t* indices,
+                                          const void* data,
+                                          int data_type,
+                                          int64_t nindptr,
+                                          int64_t nelem,
+                                          int64_t start_row,
+                                          const float* labels,
+                                          const float* weights,
+                                          const double* init_scores,
+                                          const int32_t* queries,
+                                          int32_t tid) {
+  API_BEGIN();
+#ifdef LABEL_T_USE_DOUBLE
+  Log::Fatal("Don't support LABEL_T_USE_DOUBLE");
+#endif
+  if (!data) {
+    Log::Fatal("data cannot be null.");
+  }
+  auto p_dataset = reinterpret_cast<Dataset*>(dataset);
+  auto get_row_fun = RowFunctionFromCSR<int>(indptr, indptr_type, indices, data, data_type, nindptr, nelem);
+  int32_t nrow = static_cast<int32_t>(nindptr - 1);
+  if (p_dataset->has_raw()) {
+    p_dataset->ResizeRaw(p_dataset->num_numeric_features() + nrow);
+  }
+
+  const int max_omp_threads = p_dataset->omp_max_threads() > 0 ? p_dataset->omp_max_threads() : OMP_NUM_THREADS();
+
+  OMP_INIT_EX();
+#pragma omp parallel for schedule(static)
+  for (int i = 0; i < nrow; ++i) {
+    OMP_LOOP_EX_BEGIN();
+    // convert internal thread id to be unique based on external thread id
+    const int internal_tid = omp_get_thread_num() + (max_omp_threads * tid);
+    auto one_row = get_row_fun(i);
+    p_dataset->PushOneRow(internal_tid, static_cast<data_size_t>(start_row + i), one_row);
+    OMP_LOOP_EX_END();
+  }
+  OMP_THROW_EX();
+
+  p_dataset->InsertMetadataAt(static_cast<int32_t>(start_row), nrow, labels, weights, init_scores, queries);
+
+  if (!p_dataset->wait_for_manual_finish() && (start_row + nrow == static_cast<int64_t>(p_dataset->num_data()))) {
+    p_dataset->FinishLoad();
+  }
+  API_END();
+}
+
+int LGBM_DatasetSetWaitForManualFinish(DatasetHandle dataset, int wait) {
+  API_BEGIN();
+  auto p_dataset = reinterpret_cast<Dataset*>(dataset);
+  p_dataset->set_wait_for_manual_finish(wait);
+  API_END();
+}
+
+int LGBM_DatasetMarkFinished(DatasetHandle dataset) {
+  API_BEGIN();
+  auto p_dataset = reinterpret_cast<Dataset*>(dataset);
+  p_dataset->FinishLoad();
+  API_END();
+}
+
 int LGBM_DatasetCreateFromMat(const void* data,
                               int data_type,
                               int32_t nrow,
                               int32_t ncol,
                               int is_row_major,
                               const char* parameters,
                               const DatasetHandle reference,
@@ -1092,17 +1260,15 @@
                                const char* parameters,
                                const DatasetHandle reference,
                                DatasetHandle* out) {
   API_BEGIN();
   auto param = Config::Str2Map(parameters);
   Config config;
   config.Set(param);
-  if (config.num_threads > 0) {
-    omp_set_num_threads(config.num_threads);
-  }
+  OMP_SET_NUM_THREADS(config.num_threads);
   std::unique_ptr<Dataset> ret;
   int32_t total_nrow = 0;
   for (int j = 0; j < nmat; ++j) {
     total_nrow += nrow[j];
   }
 
   std::vector<std::function<std::vector<double>(int row_idx)>> get_row_fun;
@@ -1135,15 +1301,17 @@
       }
     }
     DatasetLoader loader(config, nullptr, 1, nullptr);
     ret.reset(loader.ConstructFromSampleData(Vector2Ptr<double>(&sample_values).data(),
                                              Vector2Ptr<int>(&sample_idx).data(),
                                              ncol,
                                              VectorSize<double>(sample_values).data(),
-                                             sample_cnt, total_nrow));
+                                             sample_cnt,
+                                             total_nrow,
+                                             total_nrow));
   } else {
     ret.reset(new Dataset(total_nrow));
     ret->CreateValid(
       reinterpret_cast<const Dataset*>(reference));
     if (ret->has_raw()) {
       ret->ResizeRaw(total_nrow);
     }
@@ -1184,17 +1352,15 @@
     Log::Fatal("The number of columns should be greater than zero.");
   } else if (num_col >= INT32_MAX) {
     Log::Fatal("The number of columns should be smaller than INT32_MAX.");
   }
   auto param = Config::Str2Map(parameters);
   Config config;
   config.Set(param);
-  if (config.num_threads > 0) {
-    omp_set_num_threads(config.num_threads);
-  }
+  OMP_SET_NUM_THREADS(config.num_threads);
   std::unique_ptr<Dataset> ret;
   auto get_row_fun = RowFunctionFromCSR<int>(indptr, indptr_type, indices, data, data_type, nindptr, nelem);
   int32_t nrow = static_cast<int32_t>(nindptr - 1);
   if (reference == nullptr) {
     // sample data first
     auto sample_indices = CreateSampleIndices(nrow, config);
     int sample_cnt = static_cast<int>(sample_indices.size());
@@ -1212,15 +1378,17 @@
       }
     }
     DatasetLoader loader(config, nullptr, 1, nullptr);
     ret.reset(loader.ConstructFromSampleData(Vector2Ptr<double>(&sample_values).data(),
                                              Vector2Ptr<int>(&sample_idx).data(),
                                              static_cast<int>(num_col),
                                              VectorSize<double>(sample_values).data(),
-                                             sample_cnt, nrow));
+                                             sample_cnt,
+                                             nrow,
+                                             nrow));
   } else {
     ret.reset(new Dataset(nrow));
     ret->CreateValid(
       reinterpret_cast<const Dataset*>(reference));
     if (ret->has_raw()) {
       ret->ResizeRaw(nrow);
     }
@@ -1252,17 +1420,15 @@
   } else if (num_col >= INT32_MAX) {
     Log::Fatal("The number of columns should be smaller than INT32_MAX.");
   }
   auto get_row_fun = *static_cast<std::function<void(int idx, std::vector<std::pair<int, double>>&)>*>(get_row_funptr);
   auto param = Config::Str2Map(parameters);
   Config config;
   config.Set(param);
-  if (config.num_threads > 0) {
-    omp_set_num_threads(config.num_threads);
-  }
+  OMP_SET_NUM_THREADS(config.num_threads);
   std::unique_ptr<Dataset> ret;
   int32_t nrow = num_rows;
   if (reference == nullptr) {
     // sample data first
     auto sample_indices = CreateSampleIndices(nrow, config);
     int sample_cnt = static_cast<int>(sample_indices.size());
     std::vector<std::vector<double>> sample_values(num_col);
@@ -1281,15 +1447,17 @@
       }
     }
     DatasetLoader loader(config, nullptr, 1, nullptr);
     ret.reset(loader.ConstructFromSampleData(Vector2Ptr<double>(&sample_values).data(),
                                              Vector2Ptr<int>(&sample_idx).data(),
                                              static_cast<int>(num_col),
                                              VectorSize<double>(sample_values).data(),
-                                             sample_cnt, nrow));
+                                             sample_cnt,
+                                             nrow,
+                                             nrow));
   } else {
     ret.reset(new Dataset(nrow));
     ret->CreateValid(
       reinterpret_cast<const Dataset*>(reference));
     if (ret->has_raw()) {
       ret->ResizeRaw(nrow);
     }
@@ -1324,17 +1492,15 @@
                               const char* parameters,
                               const DatasetHandle reference,
                               DatasetHandle* out) {
   API_BEGIN();
   auto param = Config::Str2Map(parameters);
   Config config;
   config.Set(param);
-  if (config.num_threads > 0) {
-    omp_set_num_threads(config.num_threads);
-  }
+  OMP_SET_NUM_THREADS(config.num_threads);
   std::unique_ptr<Dataset> ret;
   int32_t nrow = static_cast<int32_t>(num_row);
   if (reference == nullptr) {
     // sample data first
     auto sample_indices = CreateSampleIndices(nrow, config);
     int sample_cnt = static_cast<int>(sample_indices.size());
     std::vector<std::vector<double>> sample_values(ncol_ptr - 1);
@@ -1355,15 +1521,17 @@
     }
     OMP_THROW_EX();
     DatasetLoader loader(config, nullptr, 1, nullptr);
     ret.reset(loader.ConstructFromSampleData(Vector2Ptr<double>(&sample_values).data(),
                                              Vector2Ptr<int>(&sample_idx).data(),
                                              static_cast<int>(sample_values.size()),
                                              VectorSize<double>(sample_values).data(),
-                                             sample_cnt, nrow));
+                                             sample_cnt,
+                                             nrow,
+                                             nrow));
   } else {
     ret.reset(new Dataset(nrow));
     ret->CreateValid(
       reinterpret_cast<const Dataset*>(reference));
   }
   OMP_INIT_EX();
   #pragma omp parallel for schedule(static)
@@ -1405,17 +1573,15 @@
   int32_t num_used_row_indices,
   const char* parameters,
   DatasetHandle* out) {
   API_BEGIN();
   auto param = Config::Str2Map(parameters);
   Config config;
   config.Set(param);
-  if (config.num_threads > 0) {
-    omp_set_num_threads(config.num_threads);
-  }
+  OMP_SET_NUM_THREADS(config.num_threads);
   auto full_dataset = reinterpret_cast<const Dataset*>(handle);
   CHECK_GT(num_used_row_indices, 0);
   const int32_t lower = 0;
   const int32_t upper = full_dataset->num_data() - 1;
   CheckElementsIntervalClosed(used_row_indices, lower, upper, num_used_row_indices, "Used indices of subset");
   if (!std::is_sorted(used_row_indices, used_row_indices + num_used_row_indices)) {
     Log::Fatal("used_row_indices should be sorted in Subset");
@@ -1476,14 +1642,27 @@
                            const char* filename) {
   API_BEGIN();
   auto dataset = reinterpret_cast<Dataset*>(handle);
   dataset->SaveBinaryFile(filename);
   API_END();
 }
 
+int LGBM_DatasetSerializeReferenceToBinary(DatasetHandle handle,
+                                           ByteBufferHandle* out,
+                                           int32_t* out_len) {
+  API_BEGIN();
+  auto dataset = reinterpret_cast<Dataset*>(handle);
+  std::unique_ptr<LightGBM::ByteBuffer> ret;
+  ret.reset(new LightGBM::ByteBuffer());
+  dataset->SerializeReference(ret.get());
+  *out_len = static_cast<int32_t>(ret->GetSize());
+  *out = ret.release();
+  API_END();
+}
+
 int LGBM_DatasetDumpText(DatasetHandle handle,
                          const char* filename) {
   API_BEGIN();
   auto dataset = reinterpret_cast<Dataset*>(handle);
   dataset->DumpTextFile(filename);
   API_END();
 }
@@ -1552,14 +1731,33 @@
                               int* out) {
   API_BEGIN();
   auto dataset = reinterpret_cast<Dataset*>(handle);
   *out = dataset->num_total_features();
   API_END();
 }
 
+int LGBM_DatasetGetFeatureNumBin(DatasetHandle handle,
+                                 int feature,
+                                 int* out) {
+  API_BEGIN();
+  auto dataset = reinterpret_cast<Dataset*>(handle);
+  int num_features = dataset->num_total_features();
+  if (feature < 0 || feature >= num_features) {
+    Log::Fatal("Tried to retrieve number of bins for feature index %d, "
+               "but the valid feature indices are [0, %d].", feature, num_features - 1);
+  }
+  int inner_idx = dataset->InnerFeatureIndex(feature);
+  if (inner_idx >= 0) {
+    *out = dataset->FeatureNumBin(inner_idx);
+  } else {
+    *out = 0;
+  }
+  API_END();
+}
+
 int LGBM_DatasetAddFeaturesFrom(DatasetHandle target,
                                 DatasetHandle source) {
   API_BEGIN();
   auto target_d = reinterpret_cast<Dataset*>(target);
   auto source_d = reinterpret_cast<Dataset*>(source);
   target_d->AddFeaturesFrom(source_d);
   API_END();
@@ -1596,14 +1794,29 @@
   auto ret = std::unique_ptr<Booster>(new Booster(nullptr));
   ret->LoadModelFromString(model_str);
   *out_num_iterations = ret->GetBoosting()->GetCurrentIteration();
   *out = ret.release();
   API_END();
 }
 
+int LGBM_BoosterGetLoadedParam(
+  BoosterHandle handle,
+  int64_t buffer_len,
+  int64_t* out_len,
+  char* out_str) {
+  API_BEGIN();
+  Booster* ref_booster = reinterpret_cast<Booster*>(handle);
+  std::string params = ref_booster->GetBoosting()->GetLoadedParam();
+  *out_len = static_cast<int64_t>(params.size()) + 1;
+  if (*out_len <= buffer_len) {
+    std::memcpy(out_str, params.c_str(), *out_len);
+  }
+  API_END();
+}
+
 #ifdef _MSC_VER
   #pragma warning(disable : 4702)
 #endif
 int LGBM_BoosterFree(BoosterHandle handle) {
   API_BEGIN();
   delete reinterpret_cast<Booster*>(handle);
   API_END();
@@ -1653,18 +1866,22 @@
 int LGBM_BoosterGetNumClasses(BoosterHandle handle, int* out_len) {
   API_BEGIN();
   Booster* ref_booster = reinterpret_cast<Booster*>(handle);
   *out_len = ref_booster->GetBoosting()->NumberOfClasses();
   API_END();
 }
 
-int LGBM_BoosterGetLinear(BoosterHandle handle, bool* out) {
+int LGBM_BoosterGetLinear(BoosterHandle handle, int* out) {
   API_BEGIN();
   Booster* ref_booster = reinterpret_cast<Booster*>(handle);
-  *out = ref_booster->GetBoosting()->IsLinear();
+  if (ref_booster->GetBoosting()->IsLinear()) {
+    *out = 1;
+  } else {
+    *out = 0;
+  }
   API_END();
 }
 
 int LGBM_BoosterRefit(BoosterHandle handle, const int32_t* leaf_preds, int32_t nrow, int32_t ncol) {
   API_BEGIN();
   Booster* ref_booster = reinterpret_cast<Booster*>(handle);
   ref_booster->Refit(leaf_preds, nrow, ncol);
@@ -1812,17 +2029,15 @@
                                int num_iteration,
                                const char* parameter,
                                const char* result_filename) {
   API_BEGIN();
   auto param = Config::Str2Map(parameter);
   Config config;
   config.Set(param);
-  if (config.num_threads > 0) {
-    omp_set_num_threads(config.num_threads);
-  }
+  OMP_SET_NUM_THREADS(config.num_threads);
   Booster* ref_booster = reinterpret_cast<Booster*>(handle);
   ref_booster->Predict(start_iteration, num_iteration, predict_type, data_filename, data_has_header,
                        config, result_filename);
   API_END();
 }
 
 int LGBM_BoosterCalcNumPredict(BoosterHandle handle,
@@ -1890,17 +2105,15 @@
     Log::Fatal("The number of columns should be greater than zero.");
   } else if (num_col >= INT32_MAX) {
     Log::Fatal("The number of columns should be smaller than INT32_MAX.");
   }
   auto param = Config::Str2Map(parameter);
   Config config;
   config.Set(param);
-  if (config.num_threads > 0) {
-    omp_set_num_threads(config.num_threads);
-  }
+  OMP_SET_NUM_THREADS(config.num_threads);
   Booster* ref_booster = reinterpret_cast<Booster*>(handle);
   auto get_row_fun = RowFunctionFromCSR<int>(indptr, indptr_type, indices, data, data_type, nindptr, nelem);
   int nrow = static_cast<int>(nindptr - 1);
   ref_booster->Predict(start_iteration, num_iteration, predict_type, nrow, static_cast<int>(num_col), get_row_fun,
                        config, out_result, out_len);
   API_END();
 }
@@ -1924,17 +2137,15 @@
                                     int32_t** out_indices,
                                     void** out_data) {
   API_BEGIN();
   Booster* ref_booster = reinterpret_cast<Booster*>(handle);
   auto param = Config::Str2Map(parameter);
   Config config;
   config.Set(param);
-  if (config.num_threads > 0) {
-    omp_set_num_threads(config.num_threads);
-  }
+  OMP_SET_NUM_THREADS(config.num_threads);
   if (matrix_type == C_API_MATRIX_TYPE_CSR) {
     if (num_col_or_row <= 0) {
       Log::Fatal("The number of columns should be greater than zero.");
     } else if (num_col_or_row >= INT32_MAX) {
       Log::Fatal("The number of columns should be smaller than INT32_MAX.");
     }
     auto get_row_fun = RowFunctionFromCSR<int64_t>(indptr, indptr_type, indices, data, data_type, nindptr, nelem);
@@ -1970,25 +2181,25 @@
   }
   API_END();
 }
 
 int LGBM_BoosterFreePredictSparse(void* indptr, int32_t* indices, void* data, int indptr_type, int data_type) {
   API_BEGIN();
   if (indptr_type == C_API_DTYPE_INT32) {
-    delete reinterpret_cast<int32_t*>(indptr);
+    delete[] reinterpret_cast<int32_t*>(indptr);
   } else if (indptr_type == C_API_DTYPE_INT64) {
-    delete reinterpret_cast<int64_t*>(indptr);
+    delete[] reinterpret_cast<int64_t*>(indptr);
   } else {
     Log::Fatal("Unknown indptr type in LGBM_BoosterFreePredictSparse");
   }
-  delete indices;
+  delete[] indices;
   if (data_type == C_API_DTYPE_FLOAT32) {
-    delete reinterpret_cast<float*>(data);
+    delete[] reinterpret_cast<float*>(data);
   } else if (data_type == C_API_DTYPE_FLOAT64) {
-    delete reinterpret_cast<double*>(data);
+    delete[] reinterpret_cast<double*>(data);
   } else {
     Log::Fatal("Unknown data type in LGBM_BoosterFreePredictSparse");
   }
   API_END();
 }
 
 int LGBM_BoosterPredictForCSRSingleRow(BoosterHandle handle,
@@ -2011,17 +2222,15 @@
     Log::Fatal("The number of columns should be greater than zero.");
   } else if (num_col >= INT32_MAX) {
     Log::Fatal("The number of columns should be smaller than INT32_MAX.");
   }
   auto param = Config::Str2Map(parameter);
   Config config;
   config.Set(param);
-  if (config.num_threads > 0) {
-    omp_set_num_threads(config.num_threads);
-  }
+  OMP_SET_NUM_THREADS(config.num_threads);
   Booster* ref_booster = reinterpret_cast<Booster*>(handle);
   auto get_row_fun = RowFunctionFromCSR<int>(indptr, indptr_type, indices, data, data_type, nindptr, nelem);
   ref_booster->SetSingleRowPredictor(start_iteration, num_iteration, predict_type, config);
   ref_booster->PredictSingleRow(predict_type, static_cast<int32_t>(num_col), get_row_fun, config, out_result, out_len);
   API_END();
 }
 
@@ -2043,17 +2252,15 @@
   auto fastConfig_ptr = std::unique_ptr<FastConfig>(new FastConfig(
     reinterpret_cast<Booster*>(handle),
     parameter,
     predict_type,
     data_type,
     static_cast<int32_t>(num_col)));
 
-  if (fastConfig_ptr->config.num_threads > 0) {
-    omp_set_num_threads(fastConfig_ptr->config.num_threads);
-  }
+  OMP_SET_NUM_THREADS(fastConfig_ptr->config.num_threads);
 
   fastConfig_ptr->booster->SetSingleRowPredictor(start_iteration, num_iteration, predict_type, fastConfig_ptr->config);
 
   *out_fastConfig = fastConfig_ptr.release();
   API_END();
 }
 
@@ -2091,17 +2298,15 @@
                               int64_t* out_len,
                               double* out_result) {
   API_BEGIN();
   Booster* ref_booster = reinterpret_cast<Booster*>(handle);
   auto param = Config::Str2Map(parameter);
   Config config;
   config.Set(param);
-  if (config.num_threads > 0) {
-    omp_set_num_threads(config.num_threads);
-  }
+  OMP_SET_NUM_THREADS(config.num_threads);
   int num_threads = OMP_NUM_THREADS();
   int ncol = static_cast<int>(ncol_ptr - 1);
   std::vector<std::vector<CSC_RowIterator>> iterators(num_threads, std::vector<CSC_RowIterator>());
   for (int i = 0; i < num_threads; ++i) {
     for (int j = 0; j < ncol; ++j) {
       iterators[i].emplace_back(col_ptr, col_ptr_type, indices, data, data_type, ncol_ptr, nelem, j);
     }
@@ -2120,14 +2325,35 @@
         return one_row;
       };
   ref_booster->Predict(start_iteration, num_iteration, predict_type, static_cast<int>(num_row), ncol, get_row_fun, config,
                        out_result, out_len);
   API_END();
 }
 
+int LGBM_BoosterValidateFeatureNames(BoosterHandle handle,
+                                     const char** data_names,
+                                     int data_num_features) {
+  API_BEGIN();
+  int booster_num_features;
+  size_t out_buffer_len;
+  LGBM_BoosterGetFeatureNames(handle, 0, &booster_num_features, 0, &out_buffer_len, nullptr);
+  if (booster_num_features != data_num_features) {
+    Log::Fatal("Model was trained on %d features, but got %d input features to predict.", booster_num_features, data_num_features);
+  }
+  std::vector<std::vector<char>> tmp_names(booster_num_features, std::vector<char>(out_buffer_len));
+  std::vector<char*> booster_names = Vector2Ptr(&tmp_names);
+  LGBM_BoosterGetFeatureNames(handle, data_num_features, &booster_num_features, out_buffer_len, &out_buffer_len, booster_names.data());
+  for (int i = 0; i < booster_num_features; ++i) {
+    if (strcmp(data_names[i], booster_names[i]) != 0) {
+      Log::Fatal("Expected '%s' at position %d but found '%s'", booster_names[i], i, data_names[i]);
+    }
+  }
+  API_END();
+}
+
 int LGBM_BoosterPredictForMat(BoosterHandle handle,
                               const void* data,
                               int data_type,
                               int32_t nrow,
                               int32_t ncol,
                               int is_row_major,
                               int predict_type,
@@ -2136,17 +2362,15 @@
                               const char* parameter,
                               int64_t* out_len,
                               double* out_result) {
   API_BEGIN();
   auto param = Config::Str2Map(parameter);
   Config config;
   config.Set(param);
-  if (config.num_threads > 0) {
-    omp_set_num_threads(config.num_threads);
-  }
+  OMP_SET_NUM_THREADS(config.num_threads);
   Booster* ref_booster = reinterpret_cast<Booster*>(handle);
   auto get_row_fun = RowPairFunctionFromDenseMatric(data, nrow, ncol, data_type, is_row_major);
   ref_booster->Predict(start_iteration, num_iteration, predict_type, nrow, ncol, get_row_fun,
                        config, out_result, out_len);
   API_END();
 }
 
@@ -2161,17 +2385,15 @@
                                        const char* parameter,
                                        int64_t* out_len,
                                        double* out_result) {
   API_BEGIN();
   auto param = Config::Str2Map(parameter);
   Config config;
   config.Set(param);
-  if (config.num_threads > 0) {
-    omp_set_num_threads(config.num_threads);
-  }
+  OMP_SET_NUM_THREADS(config.num_threads);
   Booster* ref_booster = reinterpret_cast<Booster*>(handle);
   auto get_row_fun = RowPairFunctionFromDenseMatric(data, 1, ncol, data_type, is_row_major);
   ref_booster->SetSingleRowPredictor(start_iteration, num_iteration, predict_type, config);
   ref_booster->PredictSingleRow(predict_type, ncol, get_row_fun, config, out_result, out_len);
   API_END();
 }
 
@@ -2187,17 +2409,15 @@
   auto fastConfig_ptr = std::unique_ptr<FastConfig>(new FastConfig(
     reinterpret_cast<Booster*>(handle),
     parameter,
     predict_type,
     data_type,
     ncol));
 
-  if (fastConfig_ptr->config.num_threads > 0) {
-    omp_set_num_threads(fastConfig_ptr->config.num_threads);
-  }
+  OMP_SET_NUM_THREADS(fastConfig_ptr->config.num_threads);
 
   fastConfig_ptr->booster->SetSingleRowPredictor(start_iteration, num_iteration, predict_type, fastConfig_ptr->config);
 
   *out_fastConfig = fastConfig_ptr.release();
   API_END();
 }
 
@@ -2227,17 +2447,15 @@
                                const char* parameter,
                                int64_t* out_len,
                                double* out_result) {
   API_BEGIN();
   auto param = Config::Str2Map(parameter);
   Config config;
   config.Set(param);
-  if (config.num_threads > 0) {
-    omp_set_num_threads(config.num_threads);
-  }
+  OMP_SET_NUM_THREADS(config.num_threads);
   Booster* ref_booster = reinterpret_cast<Booster*>(handle);
   auto get_row_fun = RowPairFunctionFromDenseRows(data, ncol, data_type);
   ref_booster->Predict(start_iteration, num_iteration, predict_type, nrow, ncol, get_row_fun, config, out_result, out_len);
   API_END();
 }
 
 int LGBM_BoosterSaveModel(BoosterHandle handle,
```

### Comparing `lightgbm-3.3.5/compile/src/io/bin.cpp` & `lightgbm-4.0.0/src/io/bin.cpp`

 * *Files 25% similar despite different names*

```diff
@@ -156,28 +156,14 @@
 
   std::vector<double> FindBinWithPredefinedBin(const double* distinct_values, const int* counts,
                                                int num_distinct_values, int max_bin,
                                                size_t total_sample_cnt, int min_data_in_bin,
                                                const std::vector<double>& forced_upper_bounds) {
     std::vector<double> bin_upper_bound;
 
-    // get list of distinct values
-    int left_cnt_data = 0;
-    int cnt_zero = 0;
-    int right_cnt_data = 0;
-    for (int i = 0; i < num_distinct_values; ++i) {
-      if (distinct_values[i] <= -kZeroThreshold) {
-        left_cnt_data += counts[i];
-      } else if (distinct_values[i] > kZeroThreshold) {
-        right_cnt_data += counts[i];
-      } else {
-        cnt_zero += counts[i];
-      }
-    }
-
     // get number of positive and negative distinct values
     int left_cnt = -1;
     for (int i = 0; i < num_distinct_values; ++i) {
       if (distinct_values[i] > -kZeroThreshold) {
         left_cnt = i;
         break;
       }
@@ -323,40 +309,40 @@
   }
 
   void BinMapper::FindBin(double* values, int num_sample_values, size_t total_sample_cnt,
                           int max_bin, int min_data_in_bin, int min_split_data, bool pre_filter, BinType bin_type,
                           bool use_missing, bool zero_as_missing,
                           const std::vector<double>& forced_upper_bounds) {
     int na_cnt = 0;
-    int tmp_num_sample_values = 0;
+    int non_na_cnt = 0;
     for (int i = 0; i < num_sample_values; ++i) {
       if (!std::isnan(values[i])) {
-        values[tmp_num_sample_values++] = values[i];
+        values[non_na_cnt++] = values[i];
       }
     }
     if (!use_missing) {
       missing_type_ = MissingType::None;
     } else if (zero_as_missing) {
       missing_type_ = MissingType::Zero;
     } else {
-      if (tmp_num_sample_values == num_sample_values) {
+      if (non_na_cnt == num_sample_values) {
         missing_type_ = MissingType::None;
       } else {
         missing_type_ = MissingType::NaN;
-        na_cnt = num_sample_values - tmp_num_sample_values;
+        na_cnt = num_sample_values - non_na_cnt;
       }
     }
-    num_sample_values = tmp_num_sample_values;
+    num_sample_values = non_na_cnt;
 
     bin_type_ = bin_type;
     default_bin_ = 0;
     int zero_cnt = static_cast<int>(total_sample_cnt - num_sample_values - na_cnt);
     // find distinct_values first
     std::vector<double> distinct_values;
-    std::vector<int> counts;
+    std::vector<int> counts;  // count of data points for each distinct feature value.
 
     std::stable_sort(values, values + num_sample_values);
 
     // push zero in the front
     if (num_sample_values == 0 || (values[0] > 0.0f && zero_cnt > 0)) {
       distinct_values.push_back(0.0f);
       counts.push_back(zero_cnt);
@@ -385,15 +371,15 @@
     // push zero in the back
     if (num_sample_values > 0 && values[num_sample_values - 1] < 0.0f && zero_cnt > 0) {
       distinct_values.push_back(0.0f);
       counts.push_back(zero_cnt);
     }
     min_val_ = distinct_values.front();
     max_val_ = distinct_values.back();
-    std::vector<int> cnt_in_bin;
+    std::vector<int> cnt_in_bin;  // count of data points in each bin.
     int num_distinct_values = static_cast<int>(distinct_values.size());
     if (bin_type_ == BinType::NumericalBin) {
       if (missing_type_ == MissingType::Zero) {
         bin_upper_bound_ = FindBinWithZeroAsOneBin(distinct_values.data(), counts.data(), num_distinct_values, max_bin, total_sample_cnt,
                                                    min_data_in_bin, forced_upper_bounds);
         if (bin_upper_bound_.size() == 2) {
           missing_type_ = MissingType::None;
@@ -442,20 +428,20 @@
       int rest_cnt = static_cast<int>(total_sample_cnt - na_cnt);
       if (rest_cnt > 0) {
         const int SPARSE_RATIO = 100;
         if (distinct_values_int.back() / SPARSE_RATIO > static_cast<int>(distinct_values_int.size())) {
           Log::Warning("Met categorical feature which contains sparse values. "
                        "Consider renumbering to consecutive integers started from zero");
         }
-        // sort by counts
+        // sort by counts in descending order
         Common::SortForPair<int, int>(&counts_int, &distinct_values_int, 0, true);
         // will ignore the categorical of small counts
         int cut_cnt = static_cast<int>(
             Common::RoundInt((total_sample_cnt - na_cnt) * 0.99f));
-        size_t cur_cat = 0;
+        size_t cur_cat_idx = 0;  // index of current category.
         categorical_2_bin_.clear();
         bin_2_categorical_.clear();
         int used_cnt = 0;
         int distinct_cnt = static_cast<int>(distinct_values_int.size());
         if (na_cnt > 0) {
           ++distinct_cnt;
         }
@@ -463,28 +449,28 @@
         cnt_in_bin.clear();
 
         // Push the dummy bin for NaN
         bin_2_categorical_.push_back(-1);
         categorical_2_bin_[-1] = 0;
         cnt_in_bin.push_back(0);
         num_bin_ = 1;
-        while (cur_cat < distinct_values_int.size()
+        while (cur_cat_idx < distinct_values_int.size()
                && (used_cnt < cut_cnt || num_bin_ < max_bin)) {
-          if (counts_int[cur_cat] < min_data_in_bin && cur_cat > 1) {
+          if (counts_int[cur_cat_idx] < min_data_in_bin && cur_cat_idx > 1) {
             break;
           }
-          bin_2_categorical_.push_back(distinct_values_int[cur_cat]);
-          categorical_2_bin_[distinct_values_int[cur_cat]] = static_cast<unsigned int>(num_bin_);
-          used_cnt += counts_int[cur_cat];
-          cnt_in_bin.push_back(counts_int[cur_cat]);
+          bin_2_categorical_.push_back(distinct_values_int[cur_cat_idx]);
+          categorical_2_bin_[distinct_values_int[cur_cat_idx]] = static_cast<unsigned int>(num_bin_);
+          used_cnt += counts_int[cur_cat_idx];
+          cnt_in_bin.push_back(counts_int[cur_cat_idx]);
           ++num_bin_;
-          ++cur_cat;
+          ++cur_cat_idx;
         }
         // Use MissingType::None to represent this bin contains all categoricals
-        if (cur_cat == distinct_values_int.size() && na_cnt == 0) {
+        if (cur_cat_idx == distinct_values_int.size() && na_cnt == 0) {
           missing_type_ = MissingType::None;
         } else {
           missing_type_ = MissingType::NaN;
         }
         // fix count of NaN bin
         cnt_in_bin[0] = static_cast<int>(total_sample_cnt - used_cnt);
       }
@@ -504,15 +490,15 @@
     if (!is_trivial_) {
       default_bin_ = ValueToBin(0);
       most_freq_bin_ =
           static_cast<uint32_t>(ArrayArgs<int>::ArgMax(cnt_in_bin));
       const double max_sparse_rate =
           static_cast<double>(cnt_in_bin[most_freq_bin_]) / total_sample_cnt;
       // When most_freq_bin_ != default_bin_, there are some additional data loading costs.
-      // so use most_freq_bin_  = default_bin_ when there is not so sparse
+      // so use most_freq_bin_ = default_bin_ when there is not so sparse
       if (most_freq_bin_ != default_bin_ && max_sparse_rate < kSparseThreshold) {
         most_freq_bin_ = default_bin_;
       }
       sparse_rate_ =
           static_cast<double>(cnt_in_bin[most_freq_bin_]) / total_sample_cnt;
     } else {
       sparse_rate_ = 1.0f;
@@ -573,15 +559,15 @@
       categorical_2_bin_.clear();
       for (int i = 0; i < num_bin_; ++i) {
         categorical_2_bin_[bin_2_categorical_[i]] = static_cast<unsigned int>(i);
       }
     }
   }
 
-  void BinMapper::SaveBinaryToFile(const VirtualFileWriter* writer) const {
+  void BinMapper::SaveBinaryToFile(BinaryWriter* writer) const {
     writer->AlignedWrite(&num_bin_, sizeof(num_bin_));
     writer->AlignedWrite(&missing_type_, sizeof(missing_type_));
     writer->AlignedWrite(&is_trivial_, sizeof(is_trivial_));
     writer->Write(&sparse_rate_, sizeof(sparse_rate_));
     writer->AlignedWrite(&bin_type_, sizeof(bin_type_));
     writer->Write(&min_val_, sizeof(min_val_));
     writer->Write(&max_val_, sizeof(max_val_));
@@ -701,22 +687,386 @@
       } else if (num_bin <= 65536) {
         return new MultiValSparseBin<uint32_t, uint16_t>(
             num_data, num_bin, estimate_element_per_row);
       } else {
         return new MultiValSparseBin<uint32_t, uint32_t>(
             num_data, num_bin, estimate_element_per_row);
       }
-    } else  {
+    } else {
       if (num_bin <= 256) {
         return new MultiValSparseBin<size_t, uint8_t>(
             num_data, num_bin, estimate_element_per_row);
       } else if (num_bin <= 65536) {
         return new MultiValSparseBin<size_t, uint16_t>(
             num_data, num_bin, estimate_element_per_row);
       } else {
         return new MultiValSparseBin<size_t, uint32_t>(
             num_data, num_bin, estimate_element_per_row);
       }
     }
   }
 
+  template <>
+  const void* DenseBin<uint8_t, false>::GetColWiseData(
+    uint8_t* bit_type,
+    bool* is_sparse,
+    std::vector<BinIterator*>* bin_iterator,
+    const int /*num_threads*/) const {
+    *is_sparse = false;
+    *bit_type = 8;
+    bin_iterator->clear();
+    return reinterpret_cast<const void*>(data_.data());
+  }
+
+  template <>
+  const void* DenseBin<uint16_t, false>::GetColWiseData(
+    uint8_t* bit_type,
+    bool* is_sparse,
+    std::vector<BinIterator*>* bin_iterator,
+    const int /*num_threads*/) const {
+    *is_sparse = false;
+    *bit_type = 16;
+    bin_iterator->clear();
+    return reinterpret_cast<const void*>(data_.data());
+  }
+
+  template <>
+  const void* DenseBin<uint32_t, false>::GetColWiseData(
+    uint8_t* bit_type,
+    bool* is_sparse,
+    std::vector<BinIterator*>* bin_iterator,
+    const int /*num_threads*/) const {
+    *is_sparse = false;
+    *bit_type = 32;
+    bin_iterator->clear();
+    return reinterpret_cast<const void*>(data_.data());
+  }
+
+  template <>
+  const void* DenseBin<uint8_t, true>::GetColWiseData(
+    uint8_t* bit_type,
+    bool* is_sparse,
+    std::vector<BinIterator*>* bin_iterator,
+    const int /*num_threads*/) const {
+    *is_sparse = false;
+    *bit_type = 4;
+    bin_iterator->clear();
+    return reinterpret_cast<const void*>(data_.data());
+  }
+
+  template <>
+  const void* DenseBin<uint8_t, false>::GetColWiseData(
+    uint8_t* bit_type,
+    bool* is_sparse,
+    BinIterator** bin_iterator) const {
+    *is_sparse = false;
+    *bit_type = 8;
+    *bin_iterator = nullptr;
+    return reinterpret_cast<const void*>(data_.data());
+  }
+
+  template <>
+  const void* DenseBin<uint16_t, false>::GetColWiseData(
+    uint8_t* bit_type,
+    bool* is_sparse,
+    BinIterator** bin_iterator) const {
+    *is_sparse = false;
+    *bit_type = 16;
+    *bin_iterator = nullptr;
+    return reinterpret_cast<const void*>(data_.data());
+  }
+
+  template <>
+  const void* DenseBin<uint32_t, false>::GetColWiseData(
+    uint8_t* bit_type,
+    bool* is_sparse,
+    BinIterator** bin_iterator) const {
+    *is_sparse = false;
+    *bit_type = 32;
+    *bin_iterator = nullptr;
+    return reinterpret_cast<const void*>(data_.data());
+  }
+
+  template <>
+  const void* DenseBin<uint8_t, true>::GetColWiseData(
+    uint8_t* bit_type,
+    bool* is_sparse,
+    BinIterator** bin_iterator) const {
+    *is_sparse = false;
+    *bit_type = 4;
+    *bin_iterator = nullptr;
+    return reinterpret_cast<const void*>(data_.data());
+  }
+
+  template <>
+  const void* SparseBin<uint8_t>::GetColWiseData(
+    uint8_t* bit_type,
+    bool* is_sparse,
+    std::vector<BinIterator*>* bin_iterator,
+    const int num_threads) const {
+    *is_sparse = true;
+    *bit_type = 8;
+    for (int thread_index = 0; thread_index < num_threads; ++thread_index) {
+      bin_iterator->emplace_back(new SparseBinIterator<uint8_t>(this, 0));
+    }
+    return nullptr;
+  }
+
+  template <>
+  const void* SparseBin<uint16_t>::GetColWiseData(
+    uint8_t* bit_type,
+    bool* is_sparse,
+    std::vector<BinIterator*>* bin_iterator,
+    const int num_threads) const {
+    *is_sparse = true;
+    *bit_type = 16;
+    for (int thread_index = 0; thread_index < num_threads; ++thread_index) {
+      bin_iterator->emplace_back(new SparseBinIterator<uint16_t>(this, 0));
+    }
+    return nullptr;
+  }
+
+  template <>
+  const void* SparseBin<uint32_t>::GetColWiseData(
+    uint8_t* bit_type,
+    bool* is_sparse,
+    std::vector<BinIterator*>* bin_iterator,
+    const int num_threads) const {
+    *is_sparse = true;
+    *bit_type = 32;
+    for (int thread_index = 0; thread_index < num_threads; ++thread_index) {
+      bin_iterator->emplace_back(new SparseBinIterator<uint32_t>(this, 0));
+    }
+    return nullptr;
+  }
+
+  template <>
+  const void* SparseBin<uint8_t>::GetColWiseData(
+    uint8_t* bit_type,
+    bool* is_sparse,
+    BinIterator** bin_iterator) const {
+    *is_sparse = true;
+    *bit_type = 8;
+    *bin_iterator = new SparseBinIterator<uint8_t>(this, 0);
+    return nullptr;
+  }
+
+  template <>
+  const void* SparseBin<uint16_t>::GetColWiseData(
+    uint8_t* bit_type,
+    bool* is_sparse,
+    BinIterator** bin_iterator) const {
+    *is_sparse = true;
+    *bit_type = 16;
+    *bin_iterator = new SparseBinIterator<uint16_t>(this, 0);
+    return nullptr;
+  }
+
+  template <>
+  const void* SparseBin<uint32_t>::GetColWiseData(
+    uint8_t* bit_type,
+    bool* is_sparse,
+    BinIterator** bin_iterator) const {
+    *is_sparse = true;
+    *bit_type = 32;
+    *bin_iterator = new SparseBinIterator<uint32_t>(this, 0);
+    return nullptr;
+  }
+
+  #ifdef USE_CUDA
+  template <>
+  const void* MultiValDenseBin<uint8_t>::GetRowWiseData(uint8_t* bit_type,
+      size_t* total_size,
+      bool* is_sparse,
+      const void** out_data_ptr,
+      uint8_t* data_ptr_bit_type) const {
+    const uint8_t* to_return = data_.data();
+    *bit_type = 8;
+    *total_size = static_cast<size_t>(num_data_) * static_cast<size_t>(num_feature_);
+    CHECK_EQ(*total_size, data_.size());
+    *is_sparse = false;
+    *out_data_ptr = nullptr;
+    *data_ptr_bit_type = 0;
+    return to_return;
+  }
+
+  template <>
+  const void* MultiValDenseBin<uint16_t>::GetRowWiseData(uint8_t* bit_type,
+    size_t* total_size,
+    bool* is_sparse,
+    const void** out_data_ptr,
+    uint8_t* data_ptr_bit_type) const {
+    const uint16_t* data_ptr = data_.data();
+    const uint8_t* to_return = reinterpret_cast<const uint8_t*>(data_ptr);
+    *bit_type = 16;
+    *total_size = static_cast<size_t>(num_data_) * static_cast<size_t>(num_feature_);
+    CHECK_EQ(*total_size, data_.size());
+    *is_sparse = false;
+    *out_data_ptr = nullptr;
+    *data_ptr_bit_type = 0;
+    return to_return;
+  }
+
+  template <>
+  const void* MultiValDenseBin<uint32_t>::GetRowWiseData(uint8_t* bit_type,
+    size_t* total_size,
+    bool* is_sparse,
+    const void** out_data_ptr,
+    uint8_t* data_ptr_bit_type) const {
+    const uint32_t* data_ptr = data_.data();
+    const uint8_t* to_return = reinterpret_cast<const uint8_t*>(data_ptr);
+    *bit_type = 32;
+    *total_size = static_cast<size_t>(num_data_) * static_cast<size_t>(num_feature_);
+    CHECK_EQ(*total_size, data_.size());
+    *is_sparse = false;
+    *out_data_ptr = nullptr;
+    *data_ptr_bit_type = 0;
+    return to_return;
+  }
+
+  template <>
+  const void* MultiValSparseBin<uint16_t, uint8_t>::GetRowWiseData(
+    uint8_t* bit_type,
+    size_t* total_size,
+    bool* is_sparse,
+    const void** out_data_ptr,
+    uint8_t* data_ptr_bit_type) const {
+    const uint8_t* to_return = data_.data();
+    *bit_type = 8;
+    *total_size = data_.size();
+    *is_sparse = true;
+    *out_data_ptr = reinterpret_cast<const uint8_t*>(row_ptr_.data());
+    *data_ptr_bit_type = 16;
+    return to_return;
+  }
+
+  template <>
+  const void* MultiValSparseBin<uint16_t, uint16_t>::GetRowWiseData(
+    uint8_t* bit_type,
+    size_t* total_size,
+    bool* is_sparse,
+    const void** out_data_ptr,
+    uint8_t* data_ptr_bit_type) const {
+    const uint8_t* to_return = reinterpret_cast<const uint8_t*>(data_.data());
+    *bit_type = 16;
+    *total_size = data_.size();
+    *is_sparse = true;
+    *out_data_ptr = reinterpret_cast<const uint8_t*>(row_ptr_.data());
+    *data_ptr_bit_type = 16;
+    return to_return;
+  }
+
+  template <>
+  const void* MultiValSparseBin<uint16_t, uint32_t>::GetRowWiseData(
+    uint8_t* bit_type,
+    size_t* total_size,
+    bool* is_sparse,
+    const void** out_data_ptr,
+    uint8_t* data_ptr_bit_type) const {
+    const uint8_t* to_return = reinterpret_cast<const uint8_t*>(data_.data());
+    *bit_type = 32;
+    *total_size = data_.size();
+    *is_sparse = true;
+    *out_data_ptr = reinterpret_cast<const uint8_t*>(row_ptr_.data());
+    *data_ptr_bit_type = 16;
+    return to_return;
+  }
+
+  template <>
+  const void* MultiValSparseBin<uint32_t, uint8_t>::GetRowWiseData(
+    uint8_t* bit_type,
+    size_t* total_size,
+    bool* is_sparse,
+    const void** out_data_ptr,
+    uint8_t* data_ptr_bit_type) const {
+    const uint8_t* to_return = data_.data();
+    *bit_type = 8;
+    *total_size = data_.size();
+    *is_sparse = true;
+    *out_data_ptr = reinterpret_cast<const uint8_t*>(row_ptr_.data());
+    *data_ptr_bit_type = 32;
+    return to_return;
+  }
+
+  template <>
+  const void* MultiValSparseBin<uint32_t, uint16_t>::GetRowWiseData(
+    uint8_t* bit_type,
+    size_t* total_size,
+    bool* is_sparse,
+    const void** out_data_ptr,
+    uint8_t* data_ptr_bit_type) const {
+    const uint8_t* to_return = reinterpret_cast<const uint8_t*>(data_.data());
+    *bit_type = 16;
+    *total_size = data_.size();
+    *is_sparse = true;
+    *out_data_ptr = reinterpret_cast<const uint8_t*>(row_ptr_.data());
+    *data_ptr_bit_type = 32;
+    return to_return;
+  }
+
+  template <>
+  const void* MultiValSparseBin<uint32_t, uint32_t>::GetRowWiseData(
+    uint8_t* bit_type,
+    size_t* total_size,
+    bool* is_sparse,
+    const void** out_data_ptr,
+    uint8_t* data_ptr_bit_type) const {
+    const uint8_t* to_return = reinterpret_cast<const uint8_t*>(data_.data());
+    *bit_type = 32;
+    *total_size = data_.size();
+    *is_sparse = true;
+    *out_data_ptr = reinterpret_cast<const uint8_t*>(row_ptr_.data());
+    *data_ptr_bit_type = 32;
+    return to_return;
+  }
+
+  template <>
+  const void* MultiValSparseBin<uint64_t, uint8_t>::GetRowWiseData(
+    uint8_t* bit_type,
+    size_t* total_size,
+    bool* is_sparse,
+    const void** out_data_ptr,
+    uint8_t* data_ptr_bit_type) const {
+    const uint8_t* to_return = data_.data();
+    *bit_type = 8;
+    *total_size = data_.size();
+    *is_sparse = true;
+    *out_data_ptr = reinterpret_cast<const uint8_t*>(row_ptr_.data());
+    *data_ptr_bit_type = 64;
+    return to_return;
+  }
+
+  template <>
+  const void* MultiValSparseBin<uint64_t, uint16_t>::GetRowWiseData(
+    uint8_t* bit_type,
+    size_t* total_size,
+    bool* is_sparse,
+    const void** out_data_ptr,
+    uint8_t* data_ptr_bit_type) const {
+    const uint8_t* to_return = reinterpret_cast<const uint8_t*>(data_.data());
+    *bit_type = 16;
+    *total_size = data_.size();
+    *is_sparse = true;
+    *out_data_ptr = reinterpret_cast<const uint8_t*>(row_ptr_.data());
+    *data_ptr_bit_type = 64;
+    return to_return;
+  }
+
+  template <>
+  const void* MultiValSparseBin<uint64_t, uint32_t>::GetRowWiseData(
+    uint8_t* bit_type,
+    size_t* total_size,
+    bool* is_sparse,
+    const void** out_data_ptr,
+    uint8_t* data_ptr_bit_type) const {
+    const uint8_t* to_return = reinterpret_cast<const uint8_t*>(data_.data());
+    *bit_type = 32;
+    *total_size = data_.size();
+    *is_sparse = true;
+    *out_data_ptr = reinterpret_cast<const uint8_t*>(row_ptr_.data());
+    *data_ptr_bit_type = 64;
+    return to_return;
+  }
+
+  #endif  // USE_CUDA
+
 }  // namespace LightGBM
```

### Comparing `lightgbm-3.3.5/compile/src/io/config.cpp` & `lightgbm-4.0.0/src/io/config.cpp`

 * *Files 12% similar despite different names*

```diff
@@ -9,43 +9,78 @@
 #include <LightGBM/utils/log.h>
 #include <LightGBM/utils/random.h>
 
 #include <limits>
 
 namespace LightGBM {
 
-void Config::KV2Map(std::unordered_map<std::string, std::string>* params, const char* kv) {
+void Config::KV2Map(std::unordered_map<std::string, std::vector<std::string>>* params, const char* kv) {
   std::vector<std::string> tmp_strs = Common::Split(kv, '=');
   if (tmp_strs.size() == 2 || tmp_strs.size() == 1) {
     std::string key = Common::RemoveQuotationSymbol(Common::Trim(tmp_strs[0]));
     std::string value = "";
     if (tmp_strs.size() == 2) {
       value = Common::RemoveQuotationSymbol(Common::Trim(tmp_strs[1]));
     }
     if (key.size() > 0) {
-      auto value_search = params->find(key);
-      if (value_search == params->end()) {  // not set
-        params->emplace(key, value);
-      } else {
-        Log::Warning("%s is set=%s, %s=%s will be ignored. Current value: %s=%s",
-          key.c_str(), value_search->second.c_str(), key.c_str(), value.c_str(),
-          key.c_str(), value_search->second.c_str());
-      }
+      params->operator[](key).emplace_back(value);
     }
   } else {
     Log::Warning("Unknown parameter %s", kv);
   }
 }
 
+void GetFirstValueAsInt(const std::unordered_map<std::string, std::vector<std::string>>& params, std::string key, int* out) {
+  const auto pair = params.find(key);
+  if (pair != params.end()) {
+    auto candidate = pair->second[0].c_str();
+    if (!Common::AtoiAndCheck(candidate, out)) {
+      Log::Fatal("Parameter %s should be of type int, got \"%s\"", key.c_str(), candidate);
+    }
+  }
+}
+
+void Config::SetVerbosity(const std::unordered_map<std::string, std::vector<std::string>>& params) {
+  int verbosity = Config().verbosity;
+  GetFirstValueAsInt(params, "verbose", &verbosity);
+  GetFirstValueAsInt(params, "verbosity", &verbosity);
+  if (verbosity < 0) {
+    LightGBM::Log::ResetLogLevel(LightGBM::LogLevel::Fatal);
+  } else if (verbosity == 0) {
+    LightGBM::Log::ResetLogLevel(LightGBM::LogLevel::Warning);
+  } else if (verbosity == 1) {
+    LightGBM::Log::ResetLogLevel(LightGBM::LogLevel::Info);
+  } else {
+    LightGBM::Log::ResetLogLevel(LightGBM::LogLevel::Debug);
+  }
+}
+
+void Config::KeepFirstValues(const std::unordered_map<std::string, std::vector<std::string>>& params, std::unordered_map<std::string, std::string>* out) {
+  for (auto pair = params.begin(); pair != params.end(); ++pair) {
+    auto name = pair->first.c_str();
+    auto values = pair->second;
+    out->emplace(name, values[0]);
+    for (size_t i = 1; i < pair->second.size(); ++i) {
+      Log::Warning("%s is set=%s, %s=%s will be ignored. Current value: %s=%s",
+        name, values[0].c_str(),
+        name, values[i].c_str(),
+        name, values[0].c_str());
+    }
+  }
+}
+
 std::unordered_map<std::string, std::string> Config::Str2Map(const char* parameters) {
+  std::unordered_map<std::string, std::vector<std::string>> all_params;
   std::unordered_map<std::string, std::string> params;
   auto args = Common::Split(parameters, " \t\n\r");
   for (auto arg : args) {
-    KV2Map(&params, Common::Trim(arg).c_str());
+    KV2Map(&all_params, Common::Trim(arg).c_str());
   }
+  SetVerbosity(all_params);
+  KeepFirstValues(all_params, &params);
   ParameterAlias::KeyAliasTransform(&params);
   return params;
 }
 
 void GetBoostingType(const std::unordered_map<std::string, std::string>& params, std::string* boosting) {
   std::string value;
   if (Config::GetString(params, "boosting", &value)) {
@@ -60,14 +95,28 @@
       *boosting = "rf";
     } else {
       Log::Fatal("Unknown boosting type %s", value.c_str());
     }
   }
 }
 
+void GetDataSampleStrategy(const std::unordered_map<std::string, std::string>& params, std::string* strategy) {
+  std::string value;
+  if (Config::GetString(params, "data_sample_strategy", &value)) {
+    std::transform(value.begin(), value.end(), value.begin(), Common::tolower);
+    if (value == std::string("goss")) {
+      *strategy = "goss";
+    } else if (value == std::string("bagging")) {
+      *strategy = "bagging";
+    } else {
+      Log::Fatal("Unknown sample strategy %s", value.c_str());
+    }
+  }
+}
+
 void ParseMetrics(const std::string& value, std::vector<std::string>* out_metric) {
   std::unordered_set<std::string> metric_sets;
   out_metric->clear();
   std::vector<std::string> metrics = Common::Split(value.c_str(), ',');
   for (auto& met : metrics) {
     auto type = ParseMetricAlias(met);
     if (metric_sets.count(type) <= 0) {
@@ -158,26 +207,26 @@
     auc_mu_weights_matrix = std::vector<std::vector<double>> (num_class, std::vector<double>(num_class, 1));
     for (size_t i = 0; i < static_cast<size_t>(num_class); ++i) {
       auc_mu_weights_matrix[i][i] = 0;
     }
   } else {
     auc_mu_weights_matrix = std::vector<std::vector<double>> (num_class, std::vector<double>(num_class, 0));
     if (auc_mu_weights.size() != static_cast<size_t>(num_class * num_class)) {
-      Log::Fatal("auc_mu_weights must have %d elements, but found %d", num_class * num_class, auc_mu_weights.size());
+      Log::Fatal("auc_mu_weights must have %d elements, but found %zu", num_class * num_class, auc_mu_weights.size());
     }
     for (size_t i = 0; i < static_cast<size_t>(num_class); ++i) {
       for (size_t j = 0; j < static_cast<size_t>(num_class); ++j) {
         if (i == j) {
           auc_mu_weights_matrix[i][j] = 0;
           if (std::fabs(auc_mu_weights[i * num_class + j]) > kZeroThreshold) {
-            Log::Info("AUC-mu matrix must have zeros on diagonal. Overwriting value in position %d of auc_mu_weights with 0.", i * num_class + j);
+            Log::Info("AUC-mu matrix must have zeros on diagonal. Overwriting value in position %zu of auc_mu_weights with 0.", i * num_class + j);
           }
         } else {
           if (std::fabs(auc_mu_weights[i * num_class + j]) < kZeroThreshold) {
-            Log::Fatal("AUC-mu matrix must have non-zero values for non-diagonal entries. Found zero value in position %d of auc_mu_weights.", i * num_class + j);
+            Log::Fatal("AUC-mu matrix must have non-zero values for non-diagonal entries. Found zero value in position %zu of auc_mu_weights.", i * num_class + j);
           }
           auc_mu_weights_matrix[i][j] = auc_mu_weights[i * num_class + j];
         }
       }
     }
   }
 }
@@ -201,14 +250,15 @@
     feature_fraction_seed = static_cast<int>(rand.NextShort(0, int_max));
     objective_seed = static_cast<int>(rand.NextShort(0, int_max));
     extra_seed = static_cast<int>(rand.NextShort(0, int_max));
   }
 
   GetTaskType(params, &task);
   GetBoostingType(params, &boosting);
+  GetDataSampleStrategy(params, &data_sample_strategy);
   GetObjectiveType(params, &objective);
   GetMetricType(params, objective, &metric);
   GetDeviceType(params, &device_type);
   if (device_type == std::string("cuda")) {
     LGBM_config_::current_device = lgbm_device_cuda;
   }
   GetTreeLearnerType(params, &tree_learner);
@@ -234,24 +284,14 @@
   valid = new_valid;
 
   if ((task == TaskType::kSaveBinary) && !save_binary) {
     Log::Info("save_binary parameter set to true because task is save_binary");
     save_binary = true;
   }
 
-  if (verbosity == 1) {
-    LightGBM::Log::ResetLogLevel(LightGBM::LogLevel::Info);
-  } else if (verbosity == 0) {
-    LightGBM::Log::ResetLogLevel(LightGBM::LogLevel::Warning);
-  } else if (verbosity >= 2) {
-    LightGBM::Log::ResetLogLevel(LightGBM::LogLevel::Debug);
-  } else {
-    LightGBM::Log::ResetLogLevel(LightGBM::LogLevel::Fatal);
-  }
-
   // check for conflicts
   CheckParamConflict();
 }
 
 bool CheckMultiClassObjective(const std::string& objective) {
   return (objective == std::string("multiclass") || objective == std::string("multiclassova"));
 }
@@ -327,26 +367,36 @@
     }
 
     if (full_num_leaves < num_leaves) {
       // Fits in an int, and is more restrictive than the current num_leaves
       num_leaves = static_cast<int>(full_num_leaves);
     }
   }
-  // force col-wise for gpu & CUDA
-  if (device_type == std::string("gpu") || device_type == std::string("cuda")) {
+  if (device_type == std::string("gpu")) {
+    // force col-wise for gpu, and cuda version
     force_col_wise = true;
     force_row_wise = false;
     if (deterministic) {
       Log::Warning("Although \"deterministic\" is set, the results ran by GPU may be non-deterministic.");
     }
-  }
-  // force gpu_use_dp for CUDA
-  if (device_type == std::string("cuda") && !gpu_use_dp) {
-    Log::Warning("CUDA currently requires double precision calculations.");
-    gpu_use_dp = true;
+    if (use_quantized_grad) {
+      Log::Warning("Quantized training is not supported by GPU tree learner. Switch to full precision training.");
+      use_quantized_grad = false;
+    }
+  } else if (device_type == std::string("cuda")) {
+    // force row-wise for cuda version
+    force_col_wise = false;
+    force_row_wise = true;
+    if (deterministic) {
+      Log::Warning("Although \"deterministic\" is set, the results ran by GPU may be non-deterministic.");
+    }
+    if (use_quantized_grad) {
+      Log::Warning("Quantized training is not supported by CUDA tree learner. Switch to full precision training.");
+      use_quantized_grad = false;
+    }
   }
   // linear tree learner must be serial type and run on CPU device
   if (linear_tree) {
     if (device_type != std::string("cpu")) {
       device_type = "cpu";
       Log::Warning("Linear tree learner only works with CPU.");
     }
@@ -385,21 +435,52 @@
   }
   if (min_data_in_leaf <= 0 && min_sum_hessian_in_leaf <= kEpsilon) {
     Log::Warning(
         "Cannot set both min_data_in_leaf and min_sum_hessian_in_leaf to 0. "
         "Will set min_data_in_leaf to 1.");
     min_data_in_leaf = 1;
   }
+  if (boosting == std::string("goss")) {
+    boosting = std::string("gbdt");
+    data_sample_strategy = std::string("goss");
+    Log::Warning("Found boosting=goss. For backwards compatibility reasons, LightGBM interprets this as boosting=gbdt, data_sample_strategy=goss."
+                 "To suppress this warning, set data_sample_strategy=goss instead.");
+  }
 }
 
 std::string Config::ToString() const {
   std::stringstream str_buf;
   str_buf << "[boosting: " << boosting << "]\n";
   str_buf << "[objective: " << objective << "]\n";
   str_buf << "[metric: " << Common::Join(metric, ",") << "]\n";
   str_buf << "[tree_learner: " << tree_learner << "]\n";
   str_buf << "[device_type: " << device_type << "]\n";
   str_buf << SaveMembersToString();
   return str_buf.str();
 }
 
+const std::string Config::DumpAliases() {
+  auto map = Config::parameter2aliases();
+  for (auto& pair : map) {
+    std::sort(pair.second.begin(), pair.second.end(), SortAlias);
+  }
+  std::stringstream str_buf;
+  str_buf << "{\n";
+  bool first = true;
+  for (const auto& pair : map) {
+    if (first) {
+      str_buf << "   \"";
+      first = false;
+    } else {
+      str_buf << "   , \"";
+    }
+    str_buf << pair.first << "\": [";
+    if (pair.second.size() > 0) {
+      str_buf << "\"" << CommonC::Join(pair.second, "\", \"") << "\"";
+    }
+    str_buf << "]\n";
+  }
+  str_buf << "}\n";
+  return str_buf.str();
+}
+
 }  // namespace LightGBM
```

### Comparing `lightgbm-3.3.5/compile/src/io/config_auto.cpp` & `lightgbm-4.0.0/src/io/config_auto.cpp`

 * *Files 27% similar despite different names*

```diff
@@ -29,14 +29,15 @@
   {"valid_filenames", "valid"},
   {"num_iteration", "num_iterations"},
   {"n_iter", "num_iterations"},
   {"num_tree", "num_iterations"},
   {"num_trees", "num_iterations"},
   {"num_round", "num_iterations"},
   {"num_rounds", "num_iterations"},
+  {"nrounds", "num_iterations"},
   {"num_boost_round", "num_iterations"},
   {"n_estimators", "num_iterations"},
   {"max_iter", "num_iterations"},
   {"shrinkage_rate", "learning_rate"},
   {"eta", "learning_rate"},
   {"num_leaf", "num_leaves"},
   {"max_leaves", "num_leaves"},
@@ -181,14 +182,15 @@
 
 const std::unordered_set<std::string>& Config::parameter_set() {
   static std::unordered_set<std::string> params({
   "config",
   "task",
   "objective",
   "boosting",
+  "data_sample_strategy",
   "data",
   "valid",
   "num_iterations",
   "learning_rate",
   "num_leaves",
   "tree_learner",
   "num_threads",
@@ -245,14 +247,18 @@
   "path_smooth",
   "interaction_constraints",
   "verbosity",
   "input_model",
   "output_model",
   "saved_feature_importance_type",
   "snapshot_freq",
+  "use_quantized_grad",
+  "num_grad_quant_bins",
+  "quant_train_renew_leaf",
+  "stochastic_rounding",
   "linear_tree",
   "max_bin",
   "max_bin_by_feature",
   "min_data_in_bin",
   "bin_construct_sample_cnt",
   "data_random_seed",
   "is_enable_sparse",
@@ -267,14 +273,15 @@
   "weight_column",
   "group_column",
   "ignore_column",
   "categorical_feature",
   "forcedbins_filename",
   "save_binary",
   "precise_float_parser",
+  "parser_config_file",
   "start_iteration_predict",
   "num_iteration_predict",
   "predict_raw_score",
   "predict_leaf_index",
   "predict_contrib",
   "predict_disable_shape_check",
   "pred_early_stop",
@@ -486,14 +493,22 @@
 
   GetString(params, "output_model", &output_model);
 
   GetInt(params, "saved_feature_importance_type", &saved_feature_importance_type);
 
   GetInt(params, "snapshot_freq", &snapshot_freq);
 
+  GetBool(params, "use_quantized_grad", &use_quantized_grad);
+
+  GetInt(params, "num_grad_quant_bins", &num_grad_quant_bins);
+
+  GetBool(params, "quant_train_renew_leaf", &quant_train_renew_leaf);
+
+  GetBool(params, "stochastic_rounding", &stochastic_rounding);
+
   GetBool(params, "linear_tree", &linear_tree);
 
   GetInt(params, "max_bin", &max_bin);
   CHECK_GT(max_bin, 1);
 
   if (GetString(params, "max_bin_by_feature", &tmp_str)) {
     max_bin_by_feature = Common::StringToArray<int32_t>(tmp_str, ',');
@@ -535,14 +550,16 @@
 
   GetString(params, "forcedbins_filename", &forcedbins_filename);
 
   GetBool(params, "save_binary", &save_binary);
 
   GetBool(params, "precise_float_parser", &precise_float_parser);
 
+  GetString(params, "parser_config_file", &parser_config_file);
+
   GetInt(params, "start_iteration_predict", &start_iteration_predict);
 
   GetInt(params, "num_iteration_predict", &num_iteration_predict);
 
   GetBool(params, "predict_raw_score", &predict_raw_score);
 
   GetBool(params, "predict_leaf_index", &predict_leaf_index);
@@ -718,14 +735,15 @@
   str_buf << "[label_column: " << label_column << "]\n";
   str_buf << "[weight_column: " << weight_column << "]\n";
   str_buf << "[group_column: " << group_column << "]\n";
   str_buf << "[ignore_column: " << ignore_column << "]\n";
   str_buf << "[categorical_feature: " << categorical_feature << "]\n";
   str_buf << "[forcedbins_filename: " << forcedbins_filename << "]\n";
   str_buf << "[precise_float_parser: " << precise_float_parser << "]\n";
+  str_buf << "[parser_config_file: " << parser_config_file << "]\n";
   str_buf << "[objective_seed: " << objective_seed << "]\n";
   str_buf << "[num_class: " << num_class << "]\n";
   str_buf << "[is_unbalance: " << is_unbalance << "]\n";
   str_buf << "[scale_pos_weight: " << scale_pos_weight << "]\n";
   str_buf << "[sigmoid: " << sigmoid << "]\n";
   str_buf << "[boost_from_average: " << boost_from_average << "]\n";
   str_buf << "[reg_sqrt: " << reg_sqrt << "]\n";
@@ -747,8 +765,293 @@
   str_buf << "[gpu_platform_id: " << gpu_platform_id << "]\n";
   str_buf << "[gpu_device_id: " << gpu_device_id << "]\n";
   str_buf << "[gpu_use_dp: " << gpu_use_dp << "]\n";
   str_buf << "[num_gpu: " << num_gpu << "]\n";
   return str_buf.str();
 }
 
+const std::unordered_map<std::string, std::vector<std::string>>& Config::parameter2aliases() {
+  static std::unordered_map<std::string, std::vector<std::string>> map({
+    {"config", {"config_file"}},
+    {"task", {"task_type"}},
+    {"objective", {"objective_type", "app", "application", "loss"}},
+    {"boosting", {"boosting_type", "boost"}},
+    {"data_sample_strategy", {}},
+    {"data", {"train", "train_data", "train_data_file", "data_filename"}},
+    {"valid", {"test", "valid_data", "valid_data_file", "test_data", "test_data_file", "valid_filenames"}},
+    {"num_iterations", {"num_iteration", "n_iter", "num_tree", "num_trees", "num_round", "num_rounds", "nrounds", "num_boost_round", "n_estimators", "max_iter"}},
+    {"learning_rate", {"shrinkage_rate", "eta"}},
+    {"num_leaves", {"num_leaf", "max_leaves", "max_leaf", "max_leaf_nodes"}},
+    {"tree_learner", {"tree", "tree_type", "tree_learner_type"}},
+    {"num_threads", {"num_thread", "nthread", "nthreads", "n_jobs"}},
+    {"device_type", {"device"}},
+    {"seed", {"random_seed", "random_state"}},
+    {"deterministic", {}},
+    {"force_col_wise", {}},
+    {"force_row_wise", {}},
+    {"histogram_pool_size", {"hist_pool_size"}},
+    {"max_depth", {}},
+    {"min_data_in_leaf", {"min_data_per_leaf", "min_data", "min_child_samples", "min_samples_leaf"}},
+    {"min_sum_hessian_in_leaf", {"min_sum_hessian_per_leaf", "min_sum_hessian", "min_hessian", "min_child_weight"}},
+    {"bagging_fraction", {"sub_row", "subsample", "bagging"}},
+    {"pos_bagging_fraction", {"pos_sub_row", "pos_subsample", "pos_bagging"}},
+    {"neg_bagging_fraction", {"neg_sub_row", "neg_subsample", "neg_bagging"}},
+    {"bagging_freq", {"subsample_freq"}},
+    {"bagging_seed", {"bagging_fraction_seed"}},
+    {"feature_fraction", {"sub_feature", "colsample_bytree"}},
+    {"feature_fraction_bynode", {"sub_feature_bynode", "colsample_bynode"}},
+    {"feature_fraction_seed", {}},
+    {"extra_trees", {"extra_tree"}},
+    {"extra_seed", {}},
+    {"early_stopping_round", {"early_stopping_rounds", "early_stopping", "n_iter_no_change"}},
+    {"first_metric_only", {}},
+    {"max_delta_step", {"max_tree_output", "max_leaf_output"}},
+    {"lambda_l1", {"reg_alpha", "l1_regularization"}},
+    {"lambda_l2", {"reg_lambda", "lambda", "l2_regularization"}},
+    {"linear_lambda", {}},
+    {"min_gain_to_split", {"min_split_gain"}},
+    {"drop_rate", {"rate_drop"}},
+    {"max_drop", {}},
+    {"skip_drop", {}},
+    {"xgboost_dart_mode", {}},
+    {"uniform_drop", {}},
+    {"drop_seed", {}},
+    {"top_rate", {}},
+    {"other_rate", {}},
+    {"min_data_per_group", {}},
+    {"max_cat_threshold", {}},
+    {"cat_l2", {}},
+    {"cat_smooth", {}},
+    {"max_cat_to_onehot", {}},
+    {"top_k", {"topk"}},
+    {"monotone_constraints", {"mc", "monotone_constraint", "monotonic_cst"}},
+    {"monotone_constraints_method", {"monotone_constraining_method", "mc_method"}},
+    {"monotone_penalty", {"monotone_splits_penalty", "ms_penalty", "mc_penalty"}},
+    {"feature_contri", {"feature_contrib", "fc", "fp", "feature_penalty"}},
+    {"forcedsplits_filename", {"fs", "forced_splits_filename", "forced_splits_file", "forced_splits"}},
+    {"refit_decay_rate", {}},
+    {"cegb_tradeoff", {}},
+    {"cegb_penalty_split", {}},
+    {"cegb_penalty_feature_lazy", {}},
+    {"cegb_penalty_feature_coupled", {}},
+    {"path_smooth", {}},
+    {"interaction_constraints", {}},
+    {"verbosity", {"verbose"}},
+    {"input_model", {"model_input", "model_in"}},
+    {"output_model", {"model_output", "model_out"}},
+    {"saved_feature_importance_type", {}},
+    {"snapshot_freq", {"save_period"}},
+    {"use_quantized_grad", {}},
+    {"num_grad_quant_bins", {}},
+    {"quant_train_renew_leaf", {}},
+    {"stochastic_rounding", {}},
+    {"linear_tree", {"linear_trees"}},
+    {"max_bin", {"max_bins"}},
+    {"max_bin_by_feature", {}},
+    {"min_data_in_bin", {}},
+    {"bin_construct_sample_cnt", {"subsample_for_bin"}},
+    {"data_random_seed", {"data_seed"}},
+    {"is_enable_sparse", {"is_sparse", "enable_sparse", "sparse"}},
+    {"enable_bundle", {"is_enable_bundle", "bundle"}},
+    {"use_missing", {}},
+    {"zero_as_missing", {}},
+    {"feature_pre_filter", {}},
+    {"pre_partition", {"is_pre_partition"}},
+    {"two_round", {"two_round_loading", "use_two_round_loading"}},
+    {"header", {"has_header"}},
+    {"label_column", {"label"}},
+    {"weight_column", {"weight"}},
+    {"group_column", {"group", "group_id", "query_column", "query", "query_id"}},
+    {"ignore_column", {"ignore_feature", "blacklist"}},
+    {"categorical_feature", {"cat_feature", "categorical_column", "cat_column", "categorical_features"}},
+    {"forcedbins_filename", {}},
+    {"save_binary", {"is_save_binary", "is_save_binary_file"}},
+    {"precise_float_parser", {}},
+    {"parser_config_file", {}},
+    {"start_iteration_predict", {}},
+    {"num_iteration_predict", {}},
+    {"predict_raw_score", {"is_predict_raw_score", "predict_rawscore", "raw_score"}},
+    {"predict_leaf_index", {"is_predict_leaf_index", "leaf_index"}},
+    {"predict_contrib", {"is_predict_contrib", "contrib"}},
+    {"predict_disable_shape_check", {}},
+    {"pred_early_stop", {}},
+    {"pred_early_stop_freq", {}},
+    {"pred_early_stop_margin", {}},
+    {"output_result", {"predict_result", "prediction_result", "predict_name", "prediction_name", "pred_name", "name_pred"}},
+    {"convert_model_language", {}},
+    {"convert_model", {"convert_model_file"}},
+    {"objective_seed", {}},
+    {"num_class", {"num_classes"}},
+    {"is_unbalance", {"unbalance", "unbalanced_sets"}},
+    {"scale_pos_weight", {}},
+    {"sigmoid", {}},
+    {"boost_from_average", {}},
+    {"reg_sqrt", {}},
+    {"alpha", {}},
+    {"fair_c", {}},
+    {"poisson_max_delta_step", {}},
+    {"tweedie_variance_power", {}},
+    {"lambdarank_truncation_level", {}},
+    {"lambdarank_norm", {}},
+    {"label_gain", {}},
+    {"metric", {"metrics", "metric_types"}},
+    {"metric_freq", {"output_freq"}},
+    {"is_provide_training_metric", {"training_metric", "is_training_metric", "train_metric"}},
+    {"eval_at", {"ndcg_eval_at", "ndcg_at", "map_eval_at", "map_at"}},
+    {"multi_error_top_k", {}},
+    {"auc_mu_weights", {}},
+    {"num_machines", {"num_machine"}},
+    {"local_listen_port", {"local_port", "port"}},
+    {"time_out", {}},
+    {"machine_list_filename", {"machine_list_file", "machine_list", "mlist"}},
+    {"machines", {"workers", "nodes"}},
+    {"gpu_platform_id", {}},
+    {"gpu_device_id", {}},
+    {"gpu_use_dp", {}},
+    {"num_gpu", {}},
+  });
+  return map;
+}
+
+const std::unordered_map<std::string, std::string>& Config::ParameterTypes() {
+  static std::unordered_map<std::string, std::string> map({
+    {"config", "string"},
+    {"objective", "string"},
+    {"boosting", "string"},
+    {"data_sample_strategy", "string"},
+    {"data", "string"},
+    {"valid", "vector<string>"},
+    {"num_iterations", "int"},
+    {"learning_rate", "double"},
+    {"num_leaves", "int"},
+    {"tree_learner", "string"},
+    {"num_threads", "int"},
+    {"device_type", "string"},
+    {"seed", "int"},
+    {"deterministic", "bool"},
+    {"force_col_wise", "bool"},
+    {"force_row_wise", "bool"},
+    {"histogram_pool_size", "double"},
+    {"max_depth", "int"},
+    {"min_data_in_leaf", "int"},
+    {"min_sum_hessian_in_leaf", "double"},
+    {"bagging_fraction", "double"},
+    {"pos_bagging_fraction", "double"},
+    {"neg_bagging_fraction", "double"},
+    {"bagging_freq", "int"},
+    {"bagging_seed", "int"},
+    {"feature_fraction", "double"},
+    {"feature_fraction_bynode", "double"},
+    {"feature_fraction_seed", "int"},
+    {"extra_trees", "bool"},
+    {"extra_seed", "int"},
+    {"early_stopping_round", "int"},
+    {"first_metric_only", "bool"},
+    {"max_delta_step", "double"},
+    {"lambda_l1", "double"},
+    {"lambda_l2", "double"},
+    {"linear_lambda", "double"},
+    {"min_gain_to_split", "double"},
+    {"drop_rate", "double"},
+    {"max_drop", "int"},
+    {"skip_drop", "double"},
+    {"xgboost_dart_mode", "bool"},
+    {"uniform_drop", "bool"},
+    {"drop_seed", "int"},
+    {"top_rate", "double"},
+    {"other_rate", "double"},
+    {"min_data_per_group", "int"},
+    {"max_cat_threshold", "int"},
+    {"cat_l2", "double"},
+    {"cat_smooth", "double"},
+    {"max_cat_to_onehot", "int"},
+    {"top_k", "int"},
+    {"monotone_constraints", "vector<int>"},
+    {"monotone_constraints_method", "string"},
+    {"monotone_penalty", "double"},
+    {"feature_contri", "vector<double>"},
+    {"forcedsplits_filename", "string"},
+    {"refit_decay_rate", "double"},
+    {"cegb_tradeoff", "double"},
+    {"cegb_penalty_split", "double"},
+    {"cegb_penalty_feature_lazy", "vector<double>"},
+    {"cegb_penalty_feature_coupled", "vector<double>"},
+    {"path_smooth", "double"},
+    {"interaction_constraints", "vector<vector<int>>"},
+    {"verbosity", "int"},
+    {"input_model", "string"},
+    {"output_model", "string"},
+    {"saved_feature_importance_type", "int"},
+    {"snapshot_freq", "int"},
+    {"use_quantized_grad", "bool"},
+    {"num_grad_quant_bins", "int"},
+    {"quant_train_renew_leaf", "bool"},
+    {"stochastic_rounding", "bool"},
+    {"linear_tree", "bool"},
+    {"max_bin", "int"},
+    {"max_bin_by_feature", "vector<int>"},
+    {"min_data_in_bin", "int"},
+    {"bin_construct_sample_cnt", "int"},
+    {"data_random_seed", "int"},
+    {"is_enable_sparse", "bool"},
+    {"enable_bundle", "bool"},
+    {"use_missing", "bool"},
+    {"zero_as_missing", "bool"},
+    {"feature_pre_filter", "bool"},
+    {"pre_partition", "bool"},
+    {"two_round", "bool"},
+    {"header", "bool"},
+    {"label_column", "string"},
+    {"weight_column", "string"},
+    {"group_column", "string"},
+    {"ignore_column", "vector<int>"},
+    {"categorical_feature", "vector<int>"},
+    {"forcedbins_filename", "string"},
+    {"save_binary", "bool"},
+    {"precise_float_parser", "bool"},
+    {"parser_config_file", "string"},
+    {"start_iteration_predict", "int"},
+    {"num_iteration_predict", "int"},
+    {"predict_raw_score", "bool"},
+    {"predict_leaf_index", "bool"},
+    {"predict_contrib", "bool"},
+    {"predict_disable_shape_check", "bool"},
+    {"pred_early_stop", "bool"},
+    {"pred_early_stop_freq", "int"},
+    {"pred_early_stop_margin", "double"},
+    {"output_result", "string"},
+    {"convert_model_language", "string"},
+    {"convert_model", "string"},
+    {"objective_seed", "int"},
+    {"num_class", "int"},
+    {"is_unbalance", "bool"},
+    {"scale_pos_weight", "double"},
+    {"sigmoid", "double"},
+    {"boost_from_average", "bool"},
+    {"reg_sqrt", "bool"},
+    {"alpha", "double"},
+    {"fair_c", "double"},
+    {"poisson_max_delta_step", "double"},
+    {"tweedie_variance_power", "double"},
+    {"lambdarank_truncation_level", "int"},
+    {"lambdarank_norm", "bool"},
+    {"label_gain", "vector<double>"},
+    {"metric", "vector<string>"},
+    {"metric_freq", "int"},
+    {"is_provide_training_metric", "bool"},
+    {"eval_at", "vector<int>"},
+    {"multi_error_top_k", "int"},
+    {"auc_mu_weights", "vector<double>"},
+    {"num_machines", "int"},
+    {"local_listen_port", "int"},
+    {"time_out", "int"},
+    {"machine_list_filename", "string"},
+    {"machines", "string"},
+    {"gpu_platform_id", "int"},
+    {"gpu_device_id", "int"},
+    {"gpu_use_dp", "bool"},
+    {"num_gpu", "int"},
+  });
+  return map;
+}
+
 }  // namespace LightGBM
```

### Comparing `lightgbm-3.3.5/compile/src/io/dataset.cpp` & `lightgbm-4.0.0/src/io/dataset.cpp`

 * *Files 17% similar despite different names*

```diff
@@ -15,37 +15,44 @@
 #include <cstdio>
 #include <limits>
 #include <sstream>
 #include <unordered_map>
 
 namespace LightGBM {
 
+const int Dataset::kSerializedReferenceVersionLength = 2;
+const char* Dataset::serialized_reference_version = "v1";
+
 const char* Dataset::binary_file_token =
     "______LightGBM_Binary_File_Token______\n";
+const char* Dataset::binary_serialized_reference_token =
+    "______LightGBM_Binary_Serialized_Token______\n";
 
 Dataset::Dataset() {
   data_filename_ = "noname";
   num_data_ = 0;
   is_finish_load_ = false;
+  wait_for_manual_finish_ = false;
   has_raw_ = false;
 }
 
 Dataset::Dataset(data_size_t num_data) {
   CHECK_GT(num_data, 0);
   data_filename_ = "noname";
   num_data_ = num_data;
   metadata_.Init(num_data_, NO_SPECIFIC, NO_SPECIFIC);
   is_finish_load_ = false;
+  wait_for_manual_finish_ = false;
   group_bin_boundaries_.push_back(0);
   has_raw_ = false;
 }
 
 Dataset::~Dataset() {}
 
-std::vector<std::vector<int>> NoGroup(const std::vector<int>& used_features) {
+std::vector<std::vector<int>> OneFeaturePerGroup(const std::vector<int>& used_features) {
   std::vector<std::vector<int>> features_in_group;
   features_in_group.resize(used_features.size());
   for (size_t i = 0; i < used_features.size(); ++i) {
     features_in_group[i].emplace_back(used_features[i]);
   }
   return features_in_group;
 }
@@ -314,41 +321,45 @@
   *multi_val_group = group_is_multi_val;
   return features_in_group;
 }
 
 void Dataset::Construct(std::vector<std::unique_ptr<BinMapper>>* bin_mappers,
                         int num_total_features,
                         const std::vector<std::vector<double>>& forced_bins,
-                        int** sample_non_zero_indices, double** sample_values,
-                        const int* num_per_col, int num_sample_col,
-                        size_t total_sample_cnt, const Config& io_config) {
+                        int** sample_non_zero_indices,
+                        double** sample_values,
+                        const int* num_per_col,
+                        int num_sample_col,
+                        size_t total_sample_cnt,
+                        const Config& io_config) {
   num_total_features_ = num_total_features;
   CHECK_EQ(num_total_features_, static_cast<int>(bin_mappers->size()));
   // get num_features
   std::vector<int> used_features;
   auto& ref_bin_mappers = *bin_mappers;
   for (int i = 0; i < static_cast<int>(bin_mappers->size()); ++i) {
     if (ref_bin_mappers[i] != nullptr && !ref_bin_mappers[i]->is_trivial()) {
       used_features.emplace_back(i);
     }
   }
   if (used_features.empty()) {
     Log::Warning(
-        "There are no meaningful features, as all feature values are "
-        "constant.");
+        "There are no meaningful features which satisfy the provided configuration. "
+        "Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing "
+        "Dataset might resolve this warning.");
   }
-  auto features_in_group = NoGroup(used_features);
+  auto features_in_group = OneFeaturePerGroup(used_features);
 
   auto is_sparse = io_config.is_enable_sparse;
   if (io_config.device_type == std::string("cuda")) {
       LGBM_config_::current_device = lgbm_device_cuda;
-      if (is_sparse) {
+      if ((io_config.device_type == std::string("cuda")) && is_sparse) {
         Log::Warning("Using sparse features with CUDA is currently not supported.");
+        is_sparse = false;
       }
-      is_sparse = false;
   }
 
   std::vector<int8_t> group_is_multi_val(used_features.size(), 0);
   if (io_config.enable_bundle && !used_features.empty()) {
     bool lgbm_is_gpu_used = io_config.device_type == std::string("gpu") || io_config.device_type == std::string("cuda");
     features_in_group = FastFeatureBundling(
         *bin_mappers, sample_non_zero_indices, sample_values, num_per_col,
@@ -421,25 +432,37 @@
   num_numeric_features_ = 0;
   for (int i = 0; i < num_features_; ++i) {
     if (FeatureBinMapper(i)->bin_type() == BinType::NumericalBin) {
       numeric_feature_map_[i] = num_numeric_features_;
       ++num_numeric_features_;
     }
   }
+  device_type_ = io_config.device_type;
+  gpu_device_id_ = io_config.gpu_device_id;
 }
 
 void Dataset::FinishLoad() {
   if (is_finish_load_) {
     return;
   }
   if (num_groups_ > 0) {
     for (int i = 0; i < num_groups_; ++i) {
       feature_groups_[i]->FinishLoad();
     }
   }
+  metadata_.FinishLoad();
+
+  #ifdef USE_CUDA
+  if (device_type_ == std::string("cuda")) {
+    CreateCUDAColumnData();
+    metadata_.CreateCUDAMetadata(gpu_device_id_);
+  } else {
+    cuda_column_data_.reset(nullptr);
+  }
+  #endif  // USE_CUDA
   is_finish_load_ = true;
 }
 
 void PushDataToMultiValBin(
     data_size_t num_data, const std::vector<uint32_t> most_freq_bins,
     const std::vector<uint32_t> offsets,
     std::vector<std::vector<std::unique_ptr<BinIterator>>>* iters,
@@ -581,18 +604,20 @@
       num_data_, offsets.back(), static_cast<int>(most_freq_bins.size()),
       1.0 - sum_dense_ratio, offsets));
   PushDataToMultiValBin(num_data_, most_freq_bins, offsets, &iters, ret.get());
   ret->FinishLoad();
   return ret.release();
 }
 
+template <bool USE_QUANT_GRAD, int HIST_BITS>
 TrainingShareStates* Dataset::GetShareStates(
     score_t* gradients, score_t* hessians,
     const std::vector<int8_t>& is_feature_used, bool is_constant_hessian,
-    bool force_col_wise, bool force_row_wise) const {
+    bool force_col_wise, bool force_row_wise,
+    const int num_grad_quant_bins) const {
   Common::FunctionTimer fun_timer("Dataset::TestMultiThreadingMethod",
                                   global_timer);
   if (force_col_wise && force_row_wise) {
     Log::Fatal(
         "Cannot set both of `force_col_wise` and `force_row_wise` to `true` at "
         "the same time");
   }
@@ -604,25 +629,25 @@
   }
   if (force_col_wise) {
     TrainingShareStates* share_state = new TrainingShareStates();
     std::vector<uint32_t> offsets;
     share_state->CalcBinOffsets(
       feature_groups_, &offsets, true);
     share_state->SetMultiValBin(GetMultiBinFromSparseFeatures(offsets),
-      num_data_, feature_groups_, false, true);
+      num_data_, feature_groups_, false, true, num_grad_quant_bins);
     share_state->is_col_wise = true;
     share_state->is_constant_hessian = is_constant_hessian;
     return share_state;
   } else if (force_row_wise) {
     TrainingShareStates* share_state = new TrainingShareStates();
     std::vector<uint32_t> offsets;
     share_state->CalcBinOffsets(
       feature_groups_, &offsets, false);
     share_state->SetMultiValBin(GetMultiBinFromAllFeatures(offsets), num_data_,
-      feature_groups_, false, false);
+      feature_groups_, false, false, num_grad_quant_bins);
     share_state->is_col_wise = false;
     share_state->is_constant_hessian = is_constant_hessian;
     return share_state;
   } else {
     std::unique_ptr<MultiValBin> sparse_bin;
     std::unique_ptr<MultiValBin> all_bin;
     std::unique_ptr<TrainingShareStates> col_wise_state;
@@ -631,22 +656,22 @@
     row_wise_state.reset(new TrainingShareStates());
 
     std::chrono::duration<double, std::milli> col_wise_init_time, row_wise_init_time;
     auto start_time = std::chrono::steady_clock::now();
     std::vector<uint32_t> col_wise_offsets;
     col_wise_state->CalcBinOffsets(feature_groups_, &col_wise_offsets, true);
     col_wise_state->SetMultiValBin(GetMultiBinFromSparseFeatures(col_wise_offsets), num_data_,
-      feature_groups_, false, true);
+      feature_groups_, false, true, num_grad_quant_bins);
     col_wise_init_time = std::chrono::steady_clock::now() - start_time;
 
     start_time = std::chrono::steady_clock::now();
     std::vector<uint32_t> row_wise_offsets;
     row_wise_state->CalcBinOffsets(feature_groups_, &row_wise_offsets, false);
     row_wise_state->SetMultiValBin(GetMultiBinFromAllFeatures(row_wise_offsets), num_data_,
-      feature_groups_, false, false);
+      feature_groups_, false, false, num_grad_quant_bins);
     row_wise_init_time = std::chrono::steady_clock::now() - start_time;
 
     uint64_t max_total_bin = std::max<uint64_t>(row_wise_state->num_hist_total_bin(),
       col_wise_state->num_hist_total_bin());
     std::vector<hist_t, Common::AlignmentAllocator<hist_t, kAlignedSize>>
         hist_data(max_total_bin * 2);
 
@@ -658,20 +683,20 @@
     col_wise_state->is_constant_hessian = is_constant_hessian;
     InitTrain(is_feature_used, col_wise_state.get());
     row_wise_state->is_col_wise = false;
     row_wise_state->is_constant_hessian = is_constant_hessian;
     InitTrain(is_feature_used, row_wise_state.get());
     std::chrono::duration<double, std::milli> col_wise_time, row_wise_time;
     start_time = std::chrono::steady_clock::now();
-    ConstructHistograms(is_feature_used, nullptr, num_data_, gradients,
+    ConstructHistograms<USE_QUANT_GRAD, HIST_BITS>(is_feature_used, nullptr, num_data_, gradients,
                         hessians, gradients, hessians, col_wise_state.get(),
                         hist_data.data());
     col_wise_time = std::chrono::steady_clock::now() - start_time;
     start_time = std::chrono::steady_clock::now();
-    ConstructHistograms(is_feature_used, nullptr, num_data_, gradients,
+    ConstructHistograms<USE_QUANT_GRAD, HIST_BITS>(is_feature_used, nullptr, num_data_, gradients,
                         hessians, gradients, hessians, row_wise_state.get(),
                         hist_data.data());
     row_wise_time = std::chrono::steady_clock::now() - start_time;
 
     if (col_wise_time < row_wise_time) {
       auto overhead_cost = row_wise_init_time + row_wise_time + col_wise_time;
       Log::Warning(
@@ -694,14 +719,32 @@
         Log::Debug("Using Dense Multi-Val Bin");
       }
       return row_wise_state.release();
     }
   }
 }
 
+template TrainingShareStates* Dataset::GetShareStates<false, 0>(
+    score_t* gradients, score_t* hessians,
+    const std::vector<int8_t>& is_feature_used, bool is_constant_hessian,
+    bool force_col_wise, bool force_row_wise,
+    const int num_grad_quant_bins) const;
+
+template TrainingShareStates* Dataset::GetShareStates<true, 16>(
+    score_t* gradients, score_t* hessians,
+    const std::vector<int8_t>& is_feature_used, bool is_constant_hessian,
+    bool force_col_wise, bool force_row_wise,
+    const int num_grad_quant_bins) const;
+
+template TrainingShareStates* Dataset::GetShareStates<true, 32>(
+    score_t* gradients, score_t* hessians,
+    const std::vector<int8_t>& is_feature_used, bool is_constant_hessian,
+    bool force_col_wise, bool force_row_wise,
+    const int num_grad_quant_bins) const;
+
 void Dataset::CopyFeatureMapperFrom(const Dataset* dataset) {
   feature_groups_.clear();
   num_features_ = dataset->num_features_;
   num_groups_ = dataset->num_groups_;
   has_raw_ = dataset->has_raw();
   // copy feature bin mapper data
   for (int i = 0; i < num_groups_; ++i) {
@@ -717,14 +760,19 @@
   feature2group_ = dataset->feature2group_;
   feature2subfeature_ = dataset->feature2subfeature_;
   group_bin_boundaries_ = dataset->group_bin_boundaries_;
   group_feature_start_ = dataset->group_feature_start_;
   group_feature_cnt_ = dataset->group_feature_cnt_;
   forced_bin_bounds_ = dataset->forced_bin_bounds_;
   feature_need_push_zeros_ = dataset->feature_need_push_zeros_;
+  max_bin_ = dataset->max_bin_;
+  min_data_in_bin_ = dataset->min_data_in_bin_;
+  bin_construct_sample_cnt_ = dataset->bin_construct_sample_cnt_;
+  use_missing_ = dataset->use_missing_;
+  zero_as_missing_ = dataset->zero_as_missing_;
 }
 
 void Dataset::CreateValid(const Dataset* dataset) {
   feature_groups_.clear();
   num_features_ = dataset->num_features_;
   num_groups_ = num_features_;
   max_bin_ = dataset->max_bin_;
@@ -763,14 +811,16 @@
   feature_groups_.shrink_to_fit();
   used_feature_map_ = dataset->used_feature_map_;
   num_total_features_ = dataset->num_total_features_;
   feature_names_ = dataset->feature_names_;
   label_idx_ = dataset->label_idx_;
   real_feature_idx_ = dataset->real_feature_idx_;
   forced_bin_bounds_ = dataset->forced_bin_bounds_;
+  device_type_ = dataset->device_type_;
+  gpu_device_id_ = dataset->gpu_device_id_;
 }
 
 void Dataset::ReSize(data_size_t num_data) {
   if (num_data_ != num_data) {
     num_data_ = num_data;
     OMP_INIT_EX();
 #pragma omp parallel for schedule(static)
@@ -828,14 +878,27 @@
 #pragma omp parallel for schedule(static)
     for (int i = 0; i < num_used_indices; ++i) {
       for (int j = 0; j < num_numeric_features_; ++j) {
         raw_data_[j][i] = fullset->raw_data_[j][used_indices[i]];
       }
     }
   }
+  // update CUDA storage for column data and metadata
+  device_type_ = fullset->device_type_;
+  gpu_device_id_ = fullset->gpu_device_id_;
+
+  #ifdef USE_CUDA
+  if (device_type_ == std::string("cuda")) {
+    if (cuda_column_data_ == nullptr) {
+      cuda_column_data_.reset(new CUDAColumnData(fullset->num_data(), gpu_device_id_));
+      metadata_.CreateCUDAMetadata(gpu_device_id_);
+    }
+    cuda_column_data_->CopySubrow(fullset->cuda_column_data(), used_indices, num_used_indices);
+  }
+  #endif  // USE_CUDA
 }
 
 bool Dataset::SetFloatField(const char* field_name, const float* field_data,
                             data_size_t num_element) {
   std::string name(field_name);
   name = Common::Trim(name);
   if (name == std::string("label") || name == std::string("target")) {
@@ -952,102 +1015,31 @@
     auto writer = VirtualFileWriter::Make(bin_filename);
     if (!writer->Init()) {
       Log::Fatal("Cannot write binary data to %s ", bin_filename);
     }
     Log::Info("Saving data to binary file %s", bin_filename);
     size_t size_of_token = std::strlen(binary_file_token);
     writer->AlignedWrite(binary_file_token, size_of_token);
-    // get size of header
-    size_t size_of_header =
-        VirtualFileWriter::AlignedSize(sizeof(num_data_)) +
-        VirtualFileWriter::AlignedSize(sizeof(num_features_)) +
-        VirtualFileWriter::AlignedSize(sizeof(num_total_features_)) +
-        VirtualFileWriter::AlignedSize(sizeof(int) * num_total_features_) +
-        VirtualFileWriter::AlignedSize(sizeof(label_idx_)) +
-        VirtualFileWriter::AlignedSize(sizeof(num_groups_)) +
-        3 * VirtualFileWriter::AlignedSize(sizeof(int) * num_features_) +
-        sizeof(uint64_t) * (num_groups_ + 1) +
-        2 * VirtualFileWriter::AlignedSize(sizeof(int) * num_groups_) +
-        VirtualFileWriter::AlignedSize(sizeof(int32_t) * num_total_features_) +
-        VirtualFileWriter::AlignedSize(sizeof(int)) * 3 +
-        VirtualFileWriter::AlignedSize(sizeof(bool)) * 3;
-    // size of feature names
-    for (int i = 0; i < num_total_features_; ++i) {
-      size_of_header +=
-          VirtualFileWriter::AlignedSize(feature_names_[i].size()) +
-          VirtualFileWriter::AlignedSize(sizeof(int));
-    }
-    // size of forced bins
-    for (int i = 0; i < num_total_features_; ++i) {
-      size_of_header += forced_bin_bounds_[i].size() * sizeof(double) +
-                        VirtualFileWriter::AlignedSize(sizeof(int));
-    }
-    writer->Write(&size_of_header, sizeof(size_of_header));
-    // write header
-    writer->AlignedWrite(&num_data_, sizeof(num_data_));
-    writer->AlignedWrite(&num_features_, sizeof(num_features_));
-    writer->AlignedWrite(&num_total_features_, sizeof(num_total_features_));
-    writer->AlignedWrite(&label_idx_, sizeof(label_idx_));
-    writer->AlignedWrite(&max_bin_, sizeof(max_bin_));
-    writer->AlignedWrite(&bin_construct_sample_cnt_,
-                         sizeof(bin_construct_sample_cnt_));
-    writer->AlignedWrite(&min_data_in_bin_, sizeof(min_data_in_bin_));
-    writer->AlignedWrite(&use_missing_, sizeof(use_missing_));
-    writer->AlignedWrite(&zero_as_missing_, sizeof(zero_as_missing_));
-    writer->AlignedWrite(&has_raw_, sizeof(has_raw_));
-    writer->AlignedWrite(used_feature_map_.data(),
-                         sizeof(int) * num_total_features_);
-    writer->AlignedWrite(&num_groups_, sizeof(num_groups_));
-    writer->AlignedWrite(real_feature_idx_.data(), sizeof(int) * num_features_);
-    writer->AlignedWrite(feature2group_.data(), sizeof(int) * num_features_);
-    writer->AlignedWrite(feature2subfeature_.data(),
-                         sizeof(int) * num_features_);
-    writer->Write(group_bin_boundaries_.data(),
-                  sizeof(uint64_t) * (num_groups_ + 1));
-    writer->AlignedWrite(group_feature_start_.data(),
-                         sizeof(int) * num_groups_);
-    writer->AlignedWrite(group_feature_cnt_.data(), sizeof(int) * num_groups_);
-    if (max_bin_by_feature_.empty()) {
-      ArrayArgs<int32_t>::Assign(&max_bin_by_feature_, -1, num_total_features_);
-    }
-    writer->AlignedWrite(max_bin_by_feature_.data(),
-                  sizeof(int32_t) * num_total_features_);
-    if (ArrayArgs<int32_t>::CheckAll(max_bin_by_feature_, -1)) {
-      max_bin_by_feature_.clear();
-    }
-    // write feature names
-    for (int i = 0; i < num_total_features_; ++i) {
-      int str_len = static_cast<int>(feature_names_[i].size());
-      writer->AlignedWrite(&str_len, sizeof(int));
-      const char* c_str = feature_names_[i].c_str();
-      writer->AlignedWrite(c_str, sizeof(char) * str_len);
-    }
-    // write forced bins
-    for (int i = 0; i < num_total_features_; ++i) {
-      int num_bounds = static_cast<int>(forced_bin_bounds_[i].size());
-      writer->AlignedWrite(&num_bounds, sizeof(int));
 
-      for (size_t j = 0; j < forced_bin_bounds_[i].size(); ++j) {
-        writer->Write(&forced_bin_bounds_[i][j], sizeof(double));
-      }
-    }
+    // Write the basic header information for the dataset
+    SerializeHeader(writer.get());
 
     // get size of meta data
     size_t size_of_metadata = metadata_.SizesInByte();
     writer->Write(&size_of_metadata, sizeof(size_of_metadata));
     // write meta data
     metadata_.SaveBinaryToFile(writer.get());
 
     // write feature data
     for (int i = 0; i < num_groups_; ++i) {
       // get size of feature
       size_t size_of_feature = feature_groups_[i]->SizesInByte();
       writer->Write(&size_of_feature, sizeof(size_of_feature));
       // write feature
-      feature_groups_[i]->SaveBinaryToFile(writer.get());
+      feature_groups_[i]->SerializeToBinary(writer.get());
     }
 
     // write raw data; use row-major order so we can read row-by-row
     if (has_raw_) {
       for (int i = 0; i < num_data_; ++i) {
         for (int j = 0; j < num_features_; ++j) {
           int feat_ind = numeric_feature_map_[j];
@@ -1056,14 +1048,125 @@
           }
         }
       }
     }
   }
 }
 
+void Dataset::SerializeReference(ByteBuffer* buffer) {
+  Log::Info("Saving data reference to binary buffer");
+
+  // Calculate approximate size of output and reserve space
+  size_t size_of_token = std::strlen(binary_serialized_reference_token);
+  size_t initial_capacity = size_of_token + GetSerializedHeaderSize();
+  // write feature group definitions
+  for (int i = 0; i < num_groups_; ++i) {
+    initial_capacity += feature_groups_[i]->SizesInByte(/* include_data */ false);
+  }
+
+  // Give a little extra just in case, to avoid unnecessary resizes
+  buffer->Reserve(static_cast<size_t>(1.1 * static_cast<double>(initial_capacity)));
+
+  // Write token that marks the data as binary reference, and the version
+  buffer->AlignedWrite(binary_serialized_reference_token, size_of_token);
+  buffer->AlignedWrite(serialized_reference_version, kSerializedReferenceVersionLength);
+
+  // Write the basic definition of the overall dataset
+  SerializeHeader(buffer);
+
+  // write feature group definitions
+  for (int i = 0; i < num_groups_; ++i) {
+    // get size of feature
+    size_t size_of_feature = feature_groups_[i]->SizesInByte(false);
+    buffer->Write(&size_of_feature, sizeof(size_of_feature));
+    // write feature
+    feature_groups_[i]->SerializeToBinary(buffer, /* include_data */ false);
+  }
+}
+
+size_t Dataset::GetSerializedHeaderSize() {
+  size_t size_of_header =
+    VirtualFileWriter::AlignedSize(sizeof(num_data_)) +
+    VirtualFileWriter::AlignedSize(sizeof(num_features_)) +
+    VirtualFileWriter::AlignedSize(sizeof(num_total_features_)) +
+    VirtualFileWriter::AlignedSize(sizeof(int) * num_total_features_) +
+    VirtualFileWriter::AlignedSize(sizeof(label_idx_)) +
+    VirtualFileWriter::AlignedSize(sizeof(num_groups_)) +
+    3 * VirtualFileWriter::AlignedSize(sizeof(int) * num_features_) +
+    sizeof(uint64_t) * (num_groups_ + 1) +
+    2 * VirtualFileWriter::AlignedSize(sizeof(int) * num_groups_) +
+    VirtualFileWriter::AlignedSize(sizeof(int32_t) * num_total_features_) +
+    VirtualFileWriter::AlignedSize(sizeof(int)) * 3 +
+    VirtualFileWriter::AlignedSize(sizeof(bool)) * 3;
+  // size of feature names and forced bins
+  for (int i = 0; i < num_total_features_; ++i) {
+    size_of_header +=
+      VirtualFileWriter::AlignedSize(feature_names_[i].size()) +
+      VirtualFileWriter::AlignedSize(sizeof(int)) +
+      forced_bin_bounds_[i].size() * sizeof(double) +
+      VirtualFileWriter::AlignedSize(sizeof(int));
+  }
+
+  return size_of_header;
+}
+
+void Dataset::SerializeHeader(BinaryWriter* writer) {
+  size_t size_of_header = GetSerializedHeaderSize();
+  writer->Write(&size_of_header, sizeof(size_of_header));
+
+  // write header
+  writer->AlignedWrite(&num_data_, sizeof(num_data_));
+  writer->AlignedWrite(&num_features_, sizeof(num_features_));
+  writer->AlignedWrite(&num_total_features_, sizeof(num_total_features_));
+  writer->AlignedWrite(&label_idx_, sizeof(label_idx_));
+  writer->AlignedWrite(&max_bin_, sizeof(max_bin_));
+  writer->AlignedWrite(&bin_construct_sample_cnt_,
+    sizeof(bin_construct_sample_cnt_));
+  writer->AlignedWrite(&min_data_in_bin_, sizeof(min_data_in_bin_));
+  writer->AlignedWrite(&use_missing_, sizeof(use_missing_));
+  writer->AlignedWrite(&zero_as_missing_, sizeof(zero_as_missing_));
+  writer->AlignedWrite(&has_raw_, sizeof(has_raw_));
+  writer->AlignedWrite(used_feature_map_.data(),
+    sizeof(int) * num_total_features_);
+  writer->AlignedWrite(&num_groups_, sizeof(num_groups_));
+  writer->AlignedWrite(real_feature_idx_.data(), sizeof(int) * num_features_);
+  writer->AlignedWrite(feature2group_.data(), sizeof(int) * num_features_);
+  writer->AlignedWrite(feature2subfeature_.data(),
+    sizeof(int) * num_features_);
+  writer->Write(group_bin_boundaries_.data(),
+    sizeof(uint64_t) * (num_groups_ + 1));
+  writer->AlignedWrite(group_feature_start_.data(),
+    sizeof(int) * num_groups_);
+  writer->AlignedWrite(group_feature_cnt_.data(), sizeof(int) * num_groups_);
+  if (max_bin_by_feature_.empty()) {
+    ArrayArgs<int32_t>::Assign(&max_bin_by_feature_, -1, num_total_features_);
+  }
+  writer->AlignedWrite(max_bin_by_feature_.data(),
+    sizeof(int32_t) * num_total_features_);
+  if (ArrayArgs<int32_t>::CheckAll(max_bin_by_feature_, -1)) {
+    max_bin_by_feature_.clear();
+  }
+  // write feature names
+  for (int i = 0; i < num_total_features_; ++i) {
+    int str_len = static_cast<int>(feature_names_[i].size());
+    writer->AlignedWrite(&str_len, sizeof(int));
+    const char* c_str = feature_names_[i].c_str();
+    writer->AlignedWrite(c_str, sizeof(char) * str_len);
+  }
+  // write forced bins
+  for (int i = 0; i < num_total_features_; ++i) {
+    int num_bounds = static_cast<int>(forced_bin_bounds_[i].size());
+    writer->AlignedWrite(&num_bounds, sizeof(int));
+
+    for (size_t j = 0; j < forced_bin_bounds_[i].size(); ++j) {
+      writer->Write(&forced_bin_bounds_[i][j], sizeof(double));
+    }
+  }
+}
+
 void Dataset::DumpTextFile(const char* text_filename) {
   FILE* file = NULL;
 #if _MSC_VER
   fopen_s(&file, text_filename, "wt");
 #else
   file = fopen(text_filename, "wt");
 #endif
@@ -1116,35 +1219,35 @@
                         TrainingShareStates* share_state) const {
   Common::FunctionTimer fun_time("Dataset::InitTrain", global_timer);
   share_state->InitTrain(group_feature_start_,
         feature_groups_,
         is_feature_used);
 }
 
-template <bool USE_INDICES, bool ORDERED>
+template <bool USE_INDICES, bool ORDERED, bool USE_QUANT_GRAD, int HIST_BITS>
 void Dataset::ConstructHistogramsMultiVal(const data_size_t* data_indices,
                                           data_size_t num_data,
                                           const score_t* gradients,
                                           const score_t* hessians,
                                           TrainingShareStates* share_state,
                                           hist_t* hist_data) const {
   Common::FunctionTimer fun_time("Dataset::ConstructHistogramsMultiVal",
                                  global_timer);
-  share_state->ConstructHistograms<USE_INDICES, ORDERED>(
+  share_state->ConstructHistograms<USE_INDICES, ORDERED, USE_QUANT_GRAD, HIST_BITS>(
       data_indices, num_data, gradients, hessians, hist_data);
 }
 
-template <bool USE_INDICES, bool USE_HESSIAN>
+template <bool USE_INDICES, bool USE_HESSIAN, bool USE_QUANT_GRAD, int HIST_BITS>
 void Dataset::ConstructHistogramsInner(
     const std::vector<int8_t>& is_feature_used, const data_size_t* data_indices,
     data_size_t num_data, const score_t* gradients, const score_t* hessians,
     score_t* ordered_gradients, score_t* ordered_hessians,
     TrainingShareStates* share_state, hist_t* hist_data) const {
   if (!share_state->is_col_wise) {
-    return ConstructHistogramsMultiVal<USE_INDICES, false>(
+    return ConstructHistogramsMultiVal<USE_INDICES, false, USE_QUANT_GRAD, HIST_BITS>(
         data_indices, num_data, gradients, hessians, share_state, hist_data);
   }
   std::vector<int> used_dense_group;
   int multi_val_groud_id = -1;
   used_dense_group.reserve(num_groups_);
   for (int group = 0; group < num_groups_; ++group) {
     const int f_start = group_feature_start_[group];
@@ -1188,83 +1291,168 @@
       }
     }
     OMP_INIT_EX();
 #pragma omp parallel for schedule(static) num_threads(share_state->num_threads)
     for (int gi = 0; gi < num_used_dense_group; ++gi) {
       OMP_LOOP_EX_BEGIN();
       int group = used_dense_group[gi];
-      auto data_ptr = hist_data + group_bin_boundaries_[group] * 2;
       const int num_bin = feature_groups_[group]->num_total_bin_;
-      std::memset(reinterpret_cast<void*>(data_ptr), 0,
-                  num_bin * kHistEntrySize);
-      if (USE_HESSIAN) {
-        if (USE_INDICES) {
-          feature_groups_[group]->bin_data_->ConstructHistogram(
-              data_indices, 0, num_data, ptr_ordered_grad, ptr_ordered_hess,
-              data_ptr);
+      if (USE_QUANT_GRAD) {
+        if (HIST_BITS == 16) {
+          auto data_ptr = reinterpret_cast<hist_t*>(reinterpret_cast<int32_t*>(hist_data) + group_bin_boundaries_[group]);
+          std::memset(reinterpret_cast<void*>(data_ptr), 0,
+                      num_bin * kInt16HistEntrySize);
+          if (USE_HESSIAN) {
+            if (USE_INDICES) {
+              feature_groups_[group]->bin_data_->ConstructHistogramInt16(
+                  data_indices, 0, num_data, ptr_ordered_grad, ptr_ordered_hess,
+                  data_ptr);
+            } else {
+              feature_groups_[group]->bin_data_->ConstructHistogramInt16(
+                  0, num_data, ptr_ordered_grad, ptr_ordered_hess, data_ptr);
+            }
+          } else {
+            if (USE_INDICES) {
+              feature_groups_[group]->bin_data_->ConstructHistogramInt16(
+                  data_indices, 0, num_data, ptr_ordered_grad,
+                  data_ptr);
+            } else {
+              feature_groups_[group]->bin_data_->ConstructHistogramInt16(
+                  0, num_data, ptr_ordered_grad, data_ptr);
+            }
+          }
         } else {
-          feature_groups_[group]->bin_data_->ConstructHistogram(
-              0, num_data, ptr_ordered_grad, ptr_ordered_hess, data_ptr);
+          auto data_ptr = hist_data + group_bin_boundaries_[group];
+          std::memset(reinterpret_cast<void*>(data_ptr), 0,
+                      num_bin * kInt32HistEntrySize);
+          if (USE_HESSIAN) {
+            if (USE_INDICES) {
+              feature_groups_[group]->bin_data_->ConstructHistogramInt32(
+                  data_indices, 0, num_data, ptr_ordered_grad, ptr_ordered_hess,
+                  data_ptr);
+            } else {
+              feature_groups_[group]->bin_data_->ConstructHistogramInt32(
+                  0, num_data, ptr_ordered_grad, ptr_ordered_hess, data_ptr);
+            }
+          } else {
+            if (USE_INDICES) {
+              feature_groups_[group]->bin_data_->ConstructHistogramInt32(
+                  data_indices, 0, num_data, ptr_ordered_grad,
+                  data_ptr);
+            } else {
+              feature_groups_[group]->bin_data_->ConstructHistogramInt32(
+                  0, num_data, ptr_ordered_grad, data_ptr);
+            }
+          }
         }
       } else {
-        if (USE_INDICES) {
-          feature_groups_[group]->bin_data_->ConstructHistogram(
-              data_indices, 0, num_data, ptr_ordered_grad, data_ptr);
+        auto data_ptr = hist_data + group_bin_boundaries_[group] * 2;
+        std::memset(reinterpret_cast<void*>(data_ptr), 0,
+                    num_bin * kHistEntrySize);
+        if (USE_HESSIAN) {
+          if (USE_INDICES) {
+            feature_groups_[group]->bin_data_->ConstructHistogram(
+                data_indices, 0, num_data, ptr_ordered_grad, ptr_ordered_hess,
+                data_ptr);
+          } else {
+            feature_groups_[group]->bin_data_->ConstructHistogram(
+                0, num_data, ptr_ordered_grad, ptr_ordered_hess, data_ptr);
+          }
         } else {
-          feature_groups_[group]->bin_data_->ConstructHistogram(
-              0, num_data, ptr_ordered_grad, data_ptr);
-        }
-        auto cnt_dst = reinterpret_cast<hist_cnt_t*>(data_ptr + 1);
-        for (int i = 0; i < num_bin * 2; i += 2) {
-          data_ptr[i + 1] = static_cast<double>(cnt_dst[i]) * hessians[0];
+          if (USE_INDICES) {
+            feature_groups_[group]->bin_data_->ConstructHistogram(
+                data_indices, 0, num_data, ptr_ordered_grad, data_ptr);
+          } else {
+            feature_groups_[group]->bin_data_->ConstructHistogram(
+                0, num_data, ptr_ordered_grad, data_ptr);
+          }
+          auto cnt_dst = reinterpret_cast<hist_cnt_t*>(data_ptr + 1);
+          for (int i = 0; i < num_bin * 2; i += 2) {
+            data_ptr[i + 1] = static_cast<double>(cnt_dst[i]) * hessians[0];
+          }
         }
       }
       OMP_LOOP_EX_END();
     }
     OMP_THROW_EX();
   }
   global_timer.Stop("Dataset::dense_bin_histogram");
   if (multi_val_groud_id >= 0) {
-    if (num_used_dense_group > 0) {
-      ConstructHistogramsMultiVal<USE_INDICES, true>(
-          data_indices, num_data, ptr_ordered_grad, ptr_ordered_hess,
-          share_state,
-          hist_data + group_bin_boundaries_[multi_val_groud_id] * 2);
+    if (USE_QUANT_GRAD) {
+      if (HIST_BITS == 32) {
+        int32_t* hist_data_ptr = reinterpret_cast<int32_t*>(hist_data);
+        if (num_used_dense_group > 0) {
+          ConstructHistogramsMultiVal<USE_INDICES, true, USE_QUANT_GRAD, HIST_BITS>(
+              data_indices, num_data, ptr_ordered_grad, ptr_ordered_hess,
+              share_state,
+              reinterpret_cast<hist_t*>(hist_data_ptr + group_bin_boundaries_[multi_val_groud_id] * 2));
+        } else {
+          ConstructHistogramsMultiVal<USE_INDICES, false, USE_QUANT_GRAD, HIST_BITS>(
+              data_indices, num_data, gradients, hessians, share_state,
+              reinterpret_cast<hist_t*>(hist_data_ptr + group_bin_boundaries_[multi_val_groud_id] * 2));
+        }
+      } else if (HIST_BITS == 16) {
+        int16_t* hist_data_ptr = reinterpret_cast<int16_t*>(hist_data);
+        if (num_used_dense_group > 0) {
+          ConstructHistogramsMultiVal<USE_INDICES, true, USE_QUANT_GRAD, HIST_BITS>(
+              data_indices, num_data, ptr_ordered_grad, ptr_ordered_hess,
+              share_state,
+              reinterpret_cast<hist_t*>(hist_data_ptr + group_bin_boundaries_[multi_val_groud_id] * 2));
+        } else {
+          ConstructHistogramsMultiVal<USE_INDICES, false, USE_QUANT_GRAD, HIST_BITS>(
+              data_indices, num_data, gradients, hessians, share_state,
+              reinterpret_cast<hist_t*>(hist_data_ptr + group_bin_boundaries_[multi_val_groud_id] * 2));
+        }
+      }
     } else {
-      ConstructHistogramsMultiVal<USE_INDICES, false>(
-          data_indices, num_data, gradients, hessians, share_state,
-          hist_data + group_bin_boundaries_[multi_val_groud_id] * 2);
+      if (num_used_dense_group > 0) {
+        ConstructHistogramsMultiVal<USE_INDICES, true, USE_QUANT_GRAD, HIST_BITS>(
+            data_indices, num_data, ptr_ordered_grad, ptr_ordered_hess,
+            share_state,
+            hist_data + group_bin_boundaries_[multi_val_groud_id] * 2);
+      } else {
+        ConstructHistogramsMultiVal<USE_INDICES, false, USE_QUANT_GRAD, HIST_BITS>(
+            data_indices, num_data, gradients, hessians, share_state,
+            hist_data + group_bin_boundaries_[multi_val_groud_id] * 2);
+      }
     }
   }
 }
 
 // explicitly initialize template methods, for cross module call
-template void Dataset::ConstructHistogramsInner<true, true>(
-    const std::vector<int8_t>& is_feature_used, const data_size_t* data_indices,
-    data_size_t num_data, const score_t* gradients, const score_t* hessians,
-    score_t* ordered_gradients, score_t* ordered_hessians,
-    TrainingShareStates* share_state, hist_t* hist_data) const;
+#define CONSTRUCT_HISTOGRAMS_INNER_PARMA \
+  const std::vector<int8_t>& is_feature_used, const data_size_t* data_indices, \
+  data_size_t num_data, const score_t* gradients, const score_t* hessians, \
+  score_t* ordered_gradients, score_t* ordered_hessians, \
+  TrainingShareStates* share_state, hist_t* hist_data
 
-template void Dataset::ConstructHistogramsInner<true, false>(
-    const std::vector<int8_t>& is_feature_used, const data_size_t* data_indices,
-    data_size_t num_data, const score_t* gradients, const score_t* hessians,
-    score_t* ordered_gradients, score_t* ordered_hessians,
-    TrainingShareStates* share_state, hist_t* hist_data) const;
+// explicitly initialize template methods, for cross module call
+template void Dataset::ConstructHistogramsInner<true, true, false, 0>(CONSTRUCT_HISTOGRAMS_INNER_PARMA) const;
 
-template void Dataset::ConstructHistogramsInner<false, true>(
-    const std::vector<int8_t>& is_feature_used, const data_size_t* data_indices,
-    data_size_t num_data, const score_t* gradients, const score_t* hessians,
-    score_t* ordered_gradients, score_t* ordered_hessians,
-    TrainingShareStates* share_state, hist_t* hist_data) const;
+template void Dataset::ConstructHistogramsInner<true, false, false, 0>(CONSTRUCT_HISTOGRAMS_INNER_PARMA) const;
 
-template void Dataset::ConstructHistogramsInner<false, false>(
-    const std::vector<int8_t>& is_feature_used, const data_size_t* data_indices,
-    data_size_t num_data, const score_t* gradients, const score_t* hessians,
-    score_t* ordered_gradients, score_t* ordered_hessians,
-    TrainingShareStates* share_state, hist_t* hist_data) const;
+template void Dataset::ConstructHistogramsInner<false, true, false, 0>(CONSTRUCT_HISTOGRAMS_INNER_PARMA) const;
+
+template void Dataset::ConstructHistogramsInner<false, false, false, 0>(CONSTRUCT_HISTOGRAMS_INNER_PARMA) const;
+
+template void Dataset::ConstructHistogramsInner<true, true, true, 16>(CONSTRUCT_HISTOGRAMS_INNER_PARMA) const;
+
+template void Dataset::ConstructHistogramsInner<true, false, true, 16>(CONSTRUCT_HISTOGRAMS_INNER_PARMA) const;
+
+template void Dataset::ConstructHistogramsInner<false, true, true, 16>(CONSTRUCT_HISTOGRAMS_INNER_PARMA) const;
+
+template void Dataset::ConstructHistogramsInner<false, false, true, 16>(CONSTRUCT_HISTOGRAMS_INNER_PARMA) const;
+
+template void Dataset::ConstructHistogramsInner<true, true, true, 32>(CONSTRUCT_HISTOGRAMS_INNER_PARMA) const;
+
+template void Dataset::ConstructHistogramsInner<true, false, true, 32>(CONSTRUCT_HISTOGRAMS_INNER_PARMA) const;
+
+template void Dataset::ConstructHistogramsInner<false, true, true, 32>(CONSTRUCT_HISTOGRAMS_INNER_PARMA) const;
+
+template void Dataset::ConstructHistogramsInner<false, false, true, 32>(CONSTRUCT_HISTOGRAMS_INNER_PARMA) const;
 
 void Dataset::FixHistogram(int feature_idx, double sum_gradient,
                            double sum_hessian, hist_t* data) const {
   const int group = feature2group_[feature_idx];
   const int sub_feature = feature2subfeature_[feature_idx];
   const BinMapper* bin_mapper =
       feature_groups_[group]->bin_mappers_[sub_feature].get();
@@ -1278,14 +1466,57 @@
         GET_GRAD(data, most_freq_bin) -= GET_GRAD(data, i);
         GET_HESS(data, most_freq_bin) -= GET_HESS(data, i);
       }
     }
   }
 }
 
+template <typename PACKED_HIST_BIN_T, typename PACKED_HIST_ACC_T, int HIST_BITS_BIN, int HIST_BITS_ACC>
+void Dataset::FixHistogramInt(int feature_idx, int64_t int_sum_gradient_and_hessian, hist_t* data) const {
+  const int group = feature2group_[feature_idx];
+  const int sub_feature = feature2subfeature_[feature_idx];
+  const BinMapper* bin_mapper =
+      feature_groups_[group]->bin_mappers_[sub_feature].get();
+  const int most_freq_bin = bin_mapper->GetMostFreqBin();
+  PACKED_HIST_BIN_T* data_ptr = reinterpret_cast<PACKED_HIST_BIN_T*>(data);
+  PACKED_HIST_ACC_T int_sum_gradient_and_hessian_local = HIST_BITS_ACC == 16 ?
+    ((static_cast<int32_t>(int_sum_gradient_and_hessian >> 32) << 16) |
+    static_cast<int32_t>(int_sum_gradient_and_hessian & 0x0000ffff)) :
+    int_sum_gradient_and_hessian;
+  if (most_freq_bin > 0) {
+    const int num_bin = bin_mapper->num_bin();
+    if (HIST_BITS_BIN == HIST_BITS_ACC) {
+      for (int i = 0; i < num_bin; ++i) {
+        if (i != most_freq_bin) {
+          int_sum_gradient_and_hessian_local -= data_ptr[i];
+        }
+      }
+      data_ptr[most_freq_bin] = int_sum_gradient_and_hessian_local;
+    } else {
+      CHECK_EQ(HIST_BITS_ACC, 32);
+      CHECK_EQ(HIST_BITS_BIN, 16);
+      for (int i = 0; i < num_bin; ++i) {
+        if (i != most_freq_bin) {
+          const PACKED_HIST_BIN_T packed_hist = data_ptr[i];
+          const PACKED_HIST_ACC_T packed_hist_acc = (static_cast<int64_t>(static_cast<int16_t>(packed_hist >> 16)) << 32) |
+            static_cast<int64_t>(packed_hist & 0x0000ffff);
+          int_sum_gradient_and_hessian_local -= packed_hist_acc;
+        }
+      }
+      PACKED_HIST_BIN_T int_sum_gradient_and_hessian_local_bin =
+        (static_cast<int32_t>(int_sum_gradient_and_hessian_local >> 32) << 16) | static_cast<int32_t>(int_sum_gradient_and_hessian_local & 0x0000ffff);
+      data_ptr[most_freq_bin] = int_sum_gradient_and_hessian_local_bin;
+    }
+  }
+}
+
+template void Dataset::FixHistogramInt<int64_t, int64_t, 32, 32>(int feature_idx, int64_t int_sum_gradient_and_hessian, hist_t* data) const;
+
+template void Dataset::FixHistogramInt<int32_t, int32_t, 16, 16>(int feature_idx, int64_t int_sum_gradient_and_hessian, hist_t* data) const;
+
 template <typename T>
 void PushVector(std::vector<T>* dest, const std::vector<T>& src) {
   dest->reserve(dest->size() + src.size());
   for (auto i : src) {
     dest->push_back(i);
   }
 }
@@ -1452,23 +1683,186 @@
     feature_names_.push_back(new_name);
   }
   PushVector(&forced_bin_bounds_, other->forced_bin_bounds_);
   PushClearIfEmpty(&max_bin_by_feature_, num_total_features_,
                    other->max_bin_by_feature_, other->num_total_features_, -1);
   num_total_features_ += other->num_total_features_;
   for (size_t i = 0; i < (other->numeric_feature_map_).size(); ++i) {
-    int feat_ind = numeric_feature_map_[i];
+    int feat_ind = other->numeric_feature_map_[i];
     if (feat_ind > -1) {
       numeric_feature_map_.push_back(feat_ind + num_numeric_features_);
     } else {
       numeric_feature_map_.push_back(-1);
     }
   }
   num_numeric_features_ += other->num_numeric_features_;
   if (has_raw_) {
     for (int i = 0; i < other->num_numeric_features_; ++i) {
       raw_data_.push_back(other->raw_data_[i]);
     }
   }
+  #ifdef USE_CUDA
+  if (device_type_ == std::string("cuda")) {
+    CreateCUDAColumnData();
+  } else {
+    cuda_column_data_ = nullptr;
+  }
+  #endif  // USE_CUDA
+}
+
+const void* Dataset::GetColWiseData(
+  const int feature_group_index,
+  const int sub_feature_index,
+  uint8_t* bit_type,
+  bool* is_sparse,
+  std::vector<BinIterator*>* bin_iterator,
+  const int num_threads) const {
+  return feature_groups_[feature_group_index]->GetColWiseData(sub_feature_index, bit_type, is_sparse, bin_iterator, num_threads);
+}
+
+const void* Dataset::GetColWiseData(
+  const int feature_group_index,
+  const int sub_feature_index,
+  uint8_t* bit_type,
+  bool* is_sparse,
+  BinIterator** bin_iterator) const {
+  return feature_groups_[feature_group_index]->GetColWiseData(sub_feature_index, bit_type, is_sparse, bin_iterator);
+}
+
+#ifdef USE_CUDA
+void Dataset::CreateCUDAColumnData() {
+  cuda_column_data_.reset(new CUDAColumnData(num_data_, gpu_device_id_));
+  int num_columns = 0;
+  std::vector<const void*> column_data;
+  std::vector<BinIterator*> column_bin_iterator;
+  std::vector<uint8_t> column_bit_type;
+  int feature_index = 0;
+  std::vector<int> feature_to_column(num_features_, -1);
+  std::vector<uint32_t> feature_max_bins(num_features_, 0);
+  std::vector<uint32_t> feature_min_bins(num_features_, 0);
+  std::vector<uint32_t> feature_offsets(num_features_, 0);
+  std::vector<uint32_t> feature_most_freq_bins(num_features_, 0);
+  std::vector<uint32_t> feature_default_bin(num_features_, 0);
+  std::vector<uint8_t> feature_missing_is_zero(num_features_, 0);
+  std::vector<uint8_t> feature_missing_is_na(num_features_, 0);
+  std::vector<uint8_t> feature_mfb_is_zero(num_features_, 0);
+  std::vector<uint8_t> feature_mfb_is_na(num_features_, 0);
+  for (int feature_group_index = 0; feature_group_index < num_groups_; ++feature_group_index) {
+    if (feature_groups_[feature_group_index]->is_multi_val_) {
+      for (int sub_feature_index = 0; sub_feature_index < feature_groups_[feature_group_index]->num_feature_; ++sub_feature_index) {
+        uint8_t bit_type = 0;
+        bool is_sparse = false;
+        BinIterator* bin_iterator = nullptr;
+        const void* one_column_data = GetColWiseData(feature_group_index,
+                                                     sub_feature_index,
+                                                     &bit_type,
+                                                     &is_sparse,
+                                                     &bin_iterator);
+        column_data.emplace_back(one_column_data);
+        column_bin_iterator.emplace_back(bin_iterator);
+        column_bit_type.emplace_back(bit_type);
+        feature_to_column[feature_index] = num_columns;
+        ++num_columns;
+        const BinMapper* feature_bin_mapper = FeatureBinMapper(feature_index);
+        feature_max_bins[feature_index] = feature_max_bin(feature_index);
+        feature_min_bins[feature_index] = feature_min_bin(feature_index);
+        const uint32_t most_freq_bin = feature_bin_mapper->GetMostFreqBin();
+        feature_offsets[feature_index] = static_cast<uint32_t>(most_freq_bin == 0);
+        feature_most_freq_bins[feature_index] = most_freq_bin;
+        feature_default_bin[feature_index] = feature_bin_mapper->GetDefaultBin();
+        if (feature_bin_mapper->missing_type() == MissingType::Zero) {
+          feature_missing_is_zero[feature_index] = 1;
+          feature_missing_is_na[feature_index] = 0;
+          if (feature_default_bin[feature_index] == feature_most_freq_bins[feature_index]) {
+            feature_mfb_is_zero[feature_index] = 1;
+          } else {
+            feature_mfb_is_zero[feature_index] = 0;
+          }
+          feature_mfb_is_na[feature_index] = 0;
+        } else if (feature_bin_mapper->missing_type() == MissingType::NaN) {
+          feature_missing_is_zero[feature_index] = 0;
+          feature_missing_is_na[feature_index] = 1;
+          feature_mfb_is_zero[feature_index] = 0;
+          if (feature_most_freq_bins[feature_index] + feature_min_bins[feature_index] == feature_max_bins[feature_index] &&
+              feature_most_freq_bins[feature_index] > 0) {
+            feature_mfb_is_na[feature_index] = 1;
+          } else {
+            feature_mfb_is_na[feature_index] = 0;
+          }
+        } else {
+          feature_missing_is_zero[feature_index] = 0;
+          feature_missing_is_na[feature_index] = 0;
+          feature_mfb_is_zero[feature_index] = 0;
+          feature_mfb_is_na[feature_index] = 0;
+        }
+        ++feature_index;
+      }
+    } else {
+      uint8_t bit_type = 0;
+      bool is_sparse = false;
+      BinIterator* bin_iterator = nullptr;
+      const void* one_column_data = GetColWiseData(feature_group_index,
+                                                   -1,
+                                                   &bit_type,
+                                                   &is_sparse,
+                                                   &bin_iterator);
+      column_data.emplace_back(one_column_data);
+      column_bin_iterator.emplace_back(bin_iterator);
+      column_bit_type.emplace_back(bit_type);
+      for (int sub_feature_index = 0; sub_feature_index < feature_groups_[feature_group_index]->num_feature_; ++sub_feature_index) {
+        feature_to_column[feature_index] = num_columns;
+        const BinMapper* feature_bin_mapper = FeatureBinMapper(feature_index);
+        feature_max_bins[feature_index] = feature_max_bin(feature_index);
+        feature_min_bins[feature_index] = feature_min_bin(feature_index);
+        const uint32_t most_freq_bin = feature_bin_mapper->GetMostFreqBin();
+        feature_offsets[feature_index] = static_cast<uint32_t>(most_freq_bin == 0);
+        feature_most_freq_bins[feature_index] = most_freq_bin;
+        feature_default_bin[feature_index] = feature_bin_mapper->GetDefaultBin();
+        if (feature_bin_mapper->missing_type() == MissingType::Zero) {
+          feature_missing_is_zero[feature_index] = 1;
+          feature_missing_is_na[feature_index] = 0;
+          if (feature_default_bin[feature_index] == feature_most_freq_bins[feature_index]) {
+            feature_mfb_is_zero[feature_index] = 1;
+          } else {
+            feature_mfb_is_zero[feature_index] = 0;
+          }
+          feature_mfb_is_na[feature_index] = 0;
+        } else if (feature_bin_mapper->missing_type() == MissingType::NaN) {
+          feature_missing_is_zero[feature_index] = 0;
+          feature_missing_is_na[feature_index] = 1;
+          feature_mfb_is_zero[feature_index] = 0;
+          if (feature_most_freq_bins[feature_index] + feature_min_bins[feature_index] == feature_max_bins[feature_index] &&
+              feature_most_freq_bins[feature_index] > 0) {
+            feature_mfb_is_na[feature_index] = 1;
+          } else {
+            feature_mfb_is_na[feature_index] = 0;
+          }
+        } else {
+          feature_missing_is_zero[feature_index] = 0;
+          feature_missing_is_na[feature_index] = 0;
+          feature_mfb_is_zero[feature_index] = 0;
+          feature_mfb_is_na[feature_index] = 0;
+        }
+        ++feature_index;
+      }
+      ++num_columns;
+    }
+  }
+  cuda_column_data_->Init(num_columns,
+                          column_data,
+                          column_bin_iterator,
+                          column_bit_type,
+                          feature_max_bins,
+                          feature_min_bins,
+                          feature_offsets,
+                          feature_most_freq_bins,
+                          feature_default_bin,
+                          feature_missing_is_zero,
+                          feature_missing_is_na,
+                          feature_mfb_is_zero,
+                          feature_mfb_is_na,
+                          feature_to_column);
 }
 
+#endif  // USE_CUDA
+
 }  // namespace LightGBM
```

### Comparing `lightgbm-3.3.5/compile/src/io/dataset_loader.cpp` & `lightgbm-4.0.0/src/io/dataset_loader.cpp`

 * *Files 4% similar despite different names*

```diff
@@ -11,15 +11,15 @@
 #include <LightGBM/utils/openmp_wrapper.h>
 
 #include <chrono>
 #include <fstream>
 
 namespace LightGBM {
 
-using json11::Json;
+using json11_internal_lightgbm::Json;
 
 DatasetLoader::DatasetLoader(const Config& io_config, const PredictFunction& predict_fun, int num_class, const char* filename)
   :config_(io_config), random_(config_.data_random_seed), predict_fun_(predict_fun), num_class_(num_class) {
   label_idx_ = 0;
   weight_idx_ = NO_SPECIFIC;
   group_idx_ = NO_SPECIFIC;
   SetHeader(filename);
@@ -38,14 +38,26 @@
   if (filename != nullptr && CheckCanLoadFromBin(filename) == "") {
     TextReader<data_size_t> text_reader(filename, config_.header);
 
     // get column names
     if (config_.header) {
       std::string first_line = text_reader.first_line();
       feature_names_ = Common::Split(first_line.c_str(), "\t,");
+    } else if (!config_.parser_config_file.empty()) {
+      // support to get header from parser config, so could utilize following label name to id mapping logic.
+      TextReader<data_size_t> parser_config_reader(config_.parser_config_file.c_str(), false);
+      parser_config_reader.ReadAllLines();
+      std::string parser_config_str = parser_config_reader.JoinedLines();
+      if (!parser_config_str.empty()) {
+        std::string header_in_parser_config = Common::GetFromParserConfig(parser_config_str, "header");
+        if (!header_in_parser_config.empty()) {
+          Log::Info("Get raw column names from parser config.");
+          feature_names_ = Common::Split(header_in_parser_config.c_str(), "\t,");
+        }
+      }
     }
 
     // load label idx first
     if (config_.label_column.size() > 0) {
       if (Common::StartsWith(config_.label_column, name_prefix)) {
         std::string name = config_.label_column.substr(name_prefix.size());
         label_idx_ = -1;
@@ -67,14 +79,23 @@
                      "if you want to use a column name,\n"
                      "please add the prefix \"name:\" to the column name");
         }
         Log::Info("Using column number %d as label", label_idx_);
       }
     }
 
+    if (!config_.parser_config_file.empty()) {
+      // if parser config file exists, feature names may be changed after customized parser applied.
+      // clear here so could use default filled feature names during dataset construction.
+      // may improve by saving real feature names defined in parser in the future.
+      if (!feature_names_.empty()) {
+        feature_names_.clear();
+      }
+    }
+
     if (!feature_names_.empty()) {
       // erase label column name
       feature_names_.erase(feature_names_.begin() + label_idx_);
       for (size_t i = 0; i < feature_names_.size(); ++i) {
         name2idx[feature_names_[i]] = static_cast<int>(i);
       }
     }
@@ -192,32 +213,34 @@
     dataset->SetHasRaw(true);
   }
   data_size_t num_global_data = 0;
   std::vector<data_size_t> used_data_indices;
   auto bin_filename = CheckCanLoadFromBin(filename);
   bool is_load_from_binary = false;
   if (bin_filename.size() == 0) {
+    dataset->parser_config_str_ = Parser::GenerateParserConfigStr(filename, config_.parser_config_file.c_str(), config_.header, label_idx_);
     auto parser = std::unique_ptr<Parser>(Parser::CreateParser(filename, config_.header, 0, label_idx_,
-                                                               config_.precise_float_parser));
+                                                               config_.precise_float_parser, dataset->parser_config_str_));
     if (parser == nullptr) {
       Log::Fatal("Could not recognize data format of %s", filename);
     }
     dataset->data_filename_ = filename;
     dataset->label_idx_ = label_idx_;
     dataset->metadata_.Init(filename);
     if (!config_.two_round) {
       // read data to memory
       auto text_data = LoadTextDataToMemory(filename, dataset->metadata_, rank, num_machines, &num_global_data, &used_data_indices);
       dataset->num_data_ = static_cast<data_size_t>(text_data.size());
       // sample data
       auto sample_data = SampleTextDataFromMemory(text_data);
       CheckSampleSize(sample_data.size(),
                       static_cast<size_t>(dataset->num_data_));
-      // construct feature bin mappers
+      // construct feature bin mappers & clear sample data
       ConstructBinMappersFromTextData(rank, num_machines, sample_data, parser.get(), dataset.get());
+      std::vector<std::string>().swap(sample_data);
       if (dataset->has_raw()) {
         dataset->ResizeRaw(dataset->num_data_);
       }
       // initialize label
       dataset->metadata_.Init(dataset->num_data_, weight_idx_, group_idx_);
       // extract features
       ExtractFeaturesFromMemory(&text_data, parser.get(), dataset.get());
@@ -228,52 +251,66 @@
       if (used_data_indices.size() > 0) {
         dataset->num_data_ = static_cast<data_size_t>(used_data_indices.size());
       } else {
         dataset->num_data_ = num_global_data;
       }
       CheckSampleSize(sample_data.size(),
                       static_cast<size_t>(dataset->num_data_));
-      // construct feature bin mappers
+      // construct feature bin mappers & clear sample data
       ConstructBinMappersFromTextData(rank, num_machines, sample_data, parser.get(), dataset.get());
+      std::vector<std::string>().swap(sample_data);
       if (dataset->has_raw()) {
         dataset->ResizeRaw(dataset->num_data_);
       }
       // initialize label
       dataset->metadata_.Init(dataset->num_data_, weight_idx_, group_idx_);
       Log::Info("Making second pass...");
       // extract features
       ExtractFeaturesFromFile(filename, parser.get(), used_data_indices, dataset.get());
     }
   } else {
     // load data from binary file
     is_load_from_binary = true;
     Log::Info("Load from binary file %s", bin_filename.c_str());
     dataset.reset(LoadFromBinFile(filename, bin_filename.c_str(), rank, num_machines, &num_global_data, &used_data_indices));
+
+    // checks whether there's a initial score file when loaded from binary data files
+    // the intial score file should with suffix ".bin.init"
+    dataset->metadata_.LoadInitialScore(bin_filename);
+
+    dataset->device_type_ = config_.device_type;
+    dataset->gpu_device_id_ = config_.gpu_device_id;
+    #ifdef USE_CUDA
+    if (config_.device_type == std::string("cuda")) {
+      dataset->CreateCUDAColumnData();
+      dataset->metadata_.CreateCUDAMetadata(dataset->gpu_device_id_);
+    } else {
+      dataset->cuda_column_data_ = nullptr;
+    }
+    #endif  // USE_CUDA
   }
   // check meta data
   dataset->metadata_.CheckOrPartition(num_global_data, used_data_indices);
   // need to check training data
   CheckDataset(dataset.get(), is_load_from_binary);
 
   return dataset.release();
 }
 
-
-
 Dataset* DatasetLoader::LoadFromFileAlignWithOtherDataset(const char* filename, const Dataset* train_data) {
   data_size_t num_global_data = 0;
   std::vector<data_size_t> used_data_indices;
   auto dataset = std::unique_ptr<Dataset>(new Dataset());
   if (store_raw_) {
     dataset->SetHasRaw(true);
   }
   auto bin_filename = CheckCanLoadFromBin(filename);
   if (bin_filename.size() == 0) {
     auto parser = std::unique_ptr<Parser>(Parser::CreateParser(filename, config_.header, 0, label_idx_,
-                                                               config_.precise_float_parser));
+                                                               config_.precise_float_parser, train_data->parser_config_str_));
     if (parser == nullptr) {
       Log::Fatal("Could not recognize data format of %s", filename);
     }
     dataset->data_filename_ = filename;
     dataset->label_idx_ = label_idx_;
     dataset->metadata_.Init(filename);
     if (!config_.two_round) {
@@ -302,21 +339,85 @@
       }
       // extract features
       ExtractFeaturesFromFile(filename, parser.get(), used_data_indices, dataset.get());
     }
   } else {
     // load data from binary file
     dataset.reset(LoadFromBinFile(filename, bin_filename.c_str(), 0, 1, &num_global_data, &used_data_indices));
+    // checks whether there's a initial score file when loaded from binary data files
+    // the intial score file should with suffix ".bin.init"
+    dataset->metadata_.LoadInitialScore(bin_filename);
   }
   // not need to check validation data
   // check meta data
   dataset->metadata_.CheckOrPartition(num_global_data, used_data_indices);
   return dataset.release();
 }
 
+Dataset* DatasetLoader::LoadFromSerializedReference(const char* binary_data, size_t buffer_size, data_size_t num_data, int32_t num_classes) {
+  auto dataset = std::unique_ptr<Dataset>(new Dataset(num_data));
+
+  auto mem_ptr = binary_data;
+
+  // check token
+  const size_t size_of_token = std::strlen(Dataset::binary_serialized_reference_token);
+  size_t size_of_token_in_input = VirtualFileWriter::AlignedSize(sizeof(char) * size_of_token);
+  if (buffer_size < size_of_token_in_input) {
+    Log::Fatal("Binary definition file error: token has the wrong size");
+  }
+  if (std::string(mem_ptr, size_of_token) != std::string(Dataset::binary_serialized_reference_token)) {
+    Log::Fatal("Input file is not LightGBM binary reference file");
+  }
+  mem_ptr += size_of_token_in_input;
+
+  size_t size_of_version = VirtualFileWriter::AlignedSize(Dataset::kSerializedReferenceVersionLength);
+  std::string version(mem_ptr, Dataset::kSerializedReferenceVersionLength);
+  if (version != std::string(Dataset::serialized_reference_version)) {
+    Log::Fatal("Unexpected version of serialized binary data: %s", version.c_str());
+  }
+  mem_ptr += size_of_version;
+
+  size_t size_of_header = *(reinterpret_cast<const size_t*>(mem_ptr));
+  mem_ptr += sizeof(size_t);
+
+  LoadHeaderFromMemory(dataset.get(), mem_ptr);
+  dataset->num_data_ = num_data;  // update to the given num_data
+  mem_ptr += size_of_header;
+
+  // read feature group definitions
+  for (int i = 0; i < dataset->num_groups_; ++i) {
+    // read feature size
+    const size_t size_of_feature = *(reinterpret_cast<const size_t*>(mem_ptr));
+    mem_ptr += sizeof(size_t);
+    dataset->feature_groups_.emplace_back(std::unique_ptr<FeatureGroup>(new FeatureGroup(mem_ptr, num_data, i)));
+    mem_ptr += size_of_feature;
+  }
+  dataset->feature_groups_.shrink_to_fit();
+
+  dataset->numeric_feature_map_ = std::vector<int>(dataset->num_features_, false);
+  dataset->num_numeric_features_ = 0;
+  for (int i = 0; i < dataset->num_features_; ++i) {
+    if (dataset->FeatureBinMapper(i)->bin_type() == BinType::CategoricalBin) {
+      dataset->numeric_feature_map_[i] = -1;
+    } else {
+      dataset->numeric_feature_map_[i] = dataset->num_numeric_features_;
+      ++dataset->num_numeric_features_;
+    }
+  }
+
+  int has_weights = config_.weight_column.size() > 0;
+  int has_init_scores = num_classes > 0;
+  int has_queries = config_.group_column.size() > 0;
+  dataset->metadata_.Init(num_data, has_weights, has_init_scores, has_queries, num_classes);
+
+  Log::Info("Loaded reference dataset: %d features, %d num_data", dataset->num_features_, num_data);
+
+  return dataset.release();
+}
+
 Dataset* DatasetLoader::LoadFromBinFile(const char* data_filename, const char* bin_filename,
                                         int rank, int num_machines, int* num_global_data,
                                         std::vector<data_size_t>* used_data_indices) {
   auto dataset = std::unique_ptr<Dataset>(new Dataset());
   auto reader = VirtualFileReader::Make(bin_filename);
   dataset->data_filename_ = data_filename;
   if (!reader->Init()) {
@@ -344,156 +445,28 @@
 
   if (read_cnt != sizeof(size_t)) {
     Log::Fatal("Binary file error: header has the wrong size");
   }
 
   size_t size_of_head = *(reinterpret_cast<size_t*>(buffer.data()));
 
-  // re-allocmate space if not enough
+  // re-allocate space if not enough
   if (size_of_head > buffer_size) {
     buffer_size = size_of_head;
     buffer.resize(buffer_size);
   }
   // read header
   read_cnt = reader->Read(buffer.data(), size_of_head);
 
   if (read_cnt != size_of_head) {
     Log::Fatal("Binary file error: header is incorrect");
   }
   // get header
   const char* mem_ptr = buffer.data();
-  dataset->num_data_ = *(reinterpret_cast<const data_size_t*>(mem_ptr));
-  mem_ptr += VirtualFileWriter::AlignedSize(sizeof(dataset->num_data_));
-  dataset->num_features_ = *(reinterpret_cast<const int*>(mem_ptr));
-  mem_ptr += VirtualFileWriter::AlignedSize(sizeof(dataset->num_features_));
-  dataset->num_total_features_ = *(reinterpret_cast<const int*>(mem_ptr));
-  mem_ptr +=
-      VirtualFileWriter::AlignedSize(sizeof(dataset->num_total_features_));
-  dataset->label_idx_ = *(reinterpret_cast<const int*>(mem_ptr));
-  mem_ptr += VirtualFileWriter::AlignedSize(sizeof(dataset->label_idx_));
-  dataset->max_bin_ = *(reinterpret_cast<const int*>(mem_ptr));
-  mem_ptr += VirtualFileWriter::AlignedSize(sizeof(dataset->max_bin_));
-  dataset->bin_construct_sample_cnt_ = *(reinterpret_cast<const int*>(mem_ptr));
-  mem_ptr += VirtualFileWriter::AlignedSize(
-      sizeof(dataset->bin_construct_sample_cnt_));
-  dataset->min_data_in_bin_ = *(reinterpret_cast<const int*>(mem_ptr));
-  mem_ptr += VirtualFileWriter::AlignedSize(sizeof(dataset->min_data_in_bin_));
-  dataset->use_missing_ = *(reinterpret_cast<const bool*>(mem_ptr));
-  mem_ptr += VirtualFileWriter::AlignedSize(sizeof(dataset->use_missing_));
-  dataset->zero_as_missing_ = *(reinterpret_cast<const bool*>(mem_ptr));
-  mem_ptr += VirtualFileWriter::AlignedSize(sizeof(dataset->zero_as_missing_));
-  dataset->has_raw_ = *(reinterpret_cast<const bool*>(mem_ptr));
-  mem_ptr += VirtualFileWriter::AlignedSize(sizeof(dataset->has_raw_));
-  const int* tmp_feature_map = reinterpret_cast<const int*>(mem_ptr);
-  dataset->used_feature_map_.clear();
-  for (int i = 0; i < dataset->num_total_features_; ++i) {
-    dataset->used_feature_map_.push_back(tmp_feature_map[i]);
-  }
-  mem_ptr += VirtualFileWriter::AlignedSize(sizeof(int) *
-                                            dataset->num_total_features_);
-  // num_groups
-  dataset->num_groups_ = *(reinterpret_cast<const int*>(mem_ptr));
-  mem_ptr += VirtualFileWriter::AlignedSize(sizeof(dataset->num_groups_));
-  // real_feature_idx_
-  const int* tmp_ptr_real_feature_idx_ = reinterpret_cast<const int*>(mem_ptr);
-  dataset->real_feature_idx_.clear();
-  for (int i = 0; i < dataset->num_features_; ++i) {
-    dataset->real_feature_idx_.push_back(tmp_ptr_real_feature_idx_[i]);
-  }
-  mem_ptr +=
-      VirtualFileWriter::AlignedSize(sizeof(int) * dataset->num_features_);
-  // feature2group
-  const int* tmp_ptr_feature2group = reinterpret_cast<const int*>(mem_ptr);
-  dataset->feature2group_.clear();
-  for (int i = 0; i < dataset->num_features_; ++i) {
-    dataset->feature2group_.push_back(tmp_ptr_feature2group[i]);
-  }
-  mem_ptr +=
-      VirtualFileWriter::AlignedSize(sizeof(int) * dataset->num_features_);
-  // feature2subfeature
-  const int* tmp_ptr_feature2subfeature = reinterpret_cast<const int*>(mem_ptr);
-  dataset->feature2subfeature_.clear();
-  for (int i = 0; i < dataset->num_features_; ++i) {
-    dataset->feature2subfeature_.push_back(tmp_ptr_feature2subfeature[i]);
-  }
-  mem_ptr +=
-      VirtualFileWriter::AlignedSize(sizeof(int) * dataset->num_features_);
-  // group_bin_boundaries
-  const uint64_t* tmp_ptr_group_bin_boundaries = reinterpret_cast<const uint64_t*>(mem_ptr);
-  dataset->group_bin_boundaries_.clear();
-  for (int i = 0; i < dataset->num_groups_ + 1; ++i) {
-    dataset->group_bin_boundaries_.push_back(tmp_ptr_group_bin_boundaries[i]);
-  }
-  mem_ptr += sizeof(uint64_t) * (dataset->num_groups_ + 1);
-
-  // group_feature_start_
-  const int* tmp_ptr_group_feature_start = reinterpret_cast<const int*>(mem_ptr);
-  dataset->group_feature_start_.clear();
-  for (int i = 0; i < dataset->num_groups_; ++i) {
-    dataset->group_feature_start_.push_back(tmp_ptr_group_feature_start[i]);
-  }
-  mem_ptr +=
-      VirtualFileWriter::AlignedSize(sizeof(int) * (dataset->num_groups_));
-
-  // group_feature_cnt_
-  const int* tmp_ptr_group_feature_cnt = reinterpret_cast<const int*>(mem_ptr);
-  dataset->group_feature_cnt_.clear();
-  for (int i = 0; i < dataset->num_groups_; ++i) {
-    dataset->group_feature_cnt_.push_back(tmp_ptr_group_feature_cnt[i]);
-  }
-  mem_ptr +=
-      VirtualFileWriter::AlignedSize(sizeof(int) * (dataset->num_groups_));
-
-  if (!config_.max_bin_by_feature.empty()) {
-    CHECK_EQ(static_cast<size_t>(dataset->num_total_features_), config_.max_bin_by_feature.size());
-    CHECK_GT(*(std::min_element(config_.max_bin_by_feature.begin(), config_.max_bin_by_feature.end())), 1);
-    dataset->max_bin_by_feature_.resize(dataset->num_total_features_);
-    dataset->max_bin_by_feature_.assign(config_.max_bin_by_feature.begin(), config_.max_bin_by_feature.end());
-  } else {
-    const int32_t* tmp_ptr_max_bin_by_feature = reinterpret_cast<const int32_t*>(mem_ptr);
-    dataset->max_bin_by_feature_.clear();
-    for (int i = 0; i < dataset->num_total_features_; ++i) {
-      dataset->max_bin_by_feature_.push_back(tmp_ptr_max_bin_by_feature[i]);
-    }
-  }
-  mem_ptr += VirtualFileWriter::AlignedSize(sizeof(int32_t) *
-                                            (dataset->num_total_features_));
-  if (ArrayArgs<int32_t>::CheckAll(dataset->max_bin_by_feature_, -1)) {
-    dataset->max_bin_by_feature_.clear();
-  }
-
-  // get feature names
-  dataset->feature_names_.clear();
-  // write feature names
-  for (int i = 0; i < dataset->num_total_features_; ++i) {
-    int str_len = *(reinterpret_cast<const int*>(mem_ptr));
-    mem_ptr += VirtualFileWriter::AlignedSize(sizeof(int));
-    std::stringstream str_buf;
-    auto tmp_arr = reinterpret_cast<const char*>(mem_ptr);
-    for (int j = 0; j < str_len; ++j) {
-      char tmp_char = tmp_arr[j];
-      str_buf << tmp_char;
-    }
-    mem_ptr += VirtualFileWriter::AlignedSize(sizeof(char) * str_len);
-    dataset->feature_names_.emplace_back(str_buf.str());
-  }
-  // get forced_bin_bounds_
-  dataset->forced_bin_bounds_ = std::vector<std::vector<double>>(dataset->num_total_features_, std::vector<double>());
-  for (int i = 0; i < dataset->num_total_features_; ++i) {
-    int num_bounds = *(reinterpret_cast<const int*>(mem_ptr));
-    mem_ptr += VirtualFileWriter::AlignedSize(sizeof(int));
-    dataset->forced_bin_bounds_[i] = std::vector<double>();
-    const double* tmp_ptr_forced_bounds =
-        reinterpret_cast<const double*>(mem_ptr);
-    for (int j = 0; j < num_bounds; ++j) {
-      double bound = tmp_ptr_forced_bounds[j];
-      dataset->forced_bin_bounds_[i].push_back(bound);
-    }
-    mem_ptr += num_bounds * sizeof(double);
-  }
+  LoadHeaderFromMemory(dataset.get(), mem_ptr);
 
   // read size of meta data
   read_cnt = reader->Read(buffer.data(), sizeof(size_t));
 
   if (read_cnt != sizeof(size_t)) {
     Log::Fatal("Binary file error: meta data has the wrong size");
   }
@@ -565,15 +538,15 @@
       buffer_size = size_of_feature;
       buffer.resize(buffer_size);
     }
 
     read_cnt = reader->Read(buffer.data(), size_of_feature);
 
     if (read_cnt != size_of_feature) {
-      Log::Fatal("Binary file error: feature %d is incorrect, read count: %d", i, read_cnt);
+      Log::Fatal("Binary file error: feature %d is incorrect, read count: %zu", i, read_cnt);
     }
     dataset->feature_groups_.emplace_back(std::unique_ptr<FeatureGroup>(
       new FeatureGroup(buffer.data(),
                        *num_global_data,
                        *used_data_indices, i)));
   }
   dataset->feature_groups_.shrink_to_fit();
@@ -595,15 +568,15 @@
       if (row_size > buffer_size) {
         buffer_size = row_size;
         buffer.resize(buffer_size);
       }
     for (int i = 0; i < dataset->num_data(); ++i) {
       read_cnt = reader->Read(buffer.data(), row_size);
       if (read_cnt != row_size) {
-        Log::Fatal("Binary file error: row %d of raw data is incorrect, read count: %d", i, read_cnt);
+        Log::Fatal("Binary file error: row %d of raw data is incorrect, read count: %zu", i, read_cnt);
       }
       mem_ptr = buffer.data();
       const float* tmp_ptr_raw_row = reinterpret_cast<const float*>(mem_ptr);
       for (int j = 0; j < dataset->num_features(); ++j) {
         int feat_ind = dataset->numeric_feature_map_[j];
         if (feat_ind >= 0) {
           dataset->raw_data_[feat_ind][i] = tmp_ptr_raw_row[feat_ind];
@@ -613,19 +586,22 @@
     }
   }
 
   dataset->is_finish_load_ = true;
   return dataset.release();
 }
 
-
 Dataset* DatasetLoader::ConstructFromSampleData(double** sample_values,
-                                                int** sample_indices, int num_col, const int* num_per_col,
-                                                size_t total_sample_size, data_size_t num_data) {
-  CheckSampleSize(total_sample_size, static_cast<size_t>(num_data));
+                                                int** sample_indices,
+                                                int num_col,
+                                                const int* num_per_col,
+                                                size_t total_sample_size,
+                                                data_size_t num_local_data,
+                                                int64_t num_dist_data) {
+  CheckSampleSize(total_sample_size, static_cast<size_t>(num_dist_data));
   int num_total_features = num_col;
   if (Network::num_machines() > 1) {
     num_total_features = Network::GlobalSyncUpByMax(num_total_features);
   }
   std::vector<std::unique_ptr<BinMapper>> bin_mappers(num_total_features);
   // fill feature_names_ if not header
   if (feature_names_.empty()) {
@@ -641,15 +617,15 @@
   }
 
   // get forced split
   std::string forced_bins_path = config_.forcedbins_filename;
   std::vector<std::vector<double>> forced_bin_bounds = DatasetLoader::GetForcedBins(forced_bins_path, num_col, categorical_features_);
 
   const data_size_t filter_cnt = static_cast<data_size_t>(
-    static_cast<double>(config_.min_data_in_leaf * total_sample_size) / num_data);
+    static_cast<double>(config_.min_data_in_leaf * total_sample_size) / num_dist_data);
   if (Network::num_machines() == 1) {
     // if only one machine, find bin locally
     OMP_INIT_EX();
     #pragma omp parallel for schedule(guided)
     for (int i = 0; i < num_col; ++i) {
       OMP_LOOP_EX_BEGIN();
       if (ignore_features_.count(i) > 0) {
@@ -761,26 +737,152 @@
         continue;
       }
       bin_mappers[i].reset(new BinMapper());
       bin_mappers[i]->CopyFrom(cp_ptr);
       cp_ptr += bin_mappers[i]->SizesInByte();
     }
   }
-  auto dataset = std::unique_ptr<Dataset>(new Dataset(num_data));
+  CheckCategoricalFeatureNumBin(bin_mappers, config_.max_bin, config_.max_bin_by_feature);
+  auto dataset = std::unique_ptr<Dataset>(new Dataset(num_local_data));
   dataset->Construct(&bin_mappers, num_total_features, forced_bin_bounds, sample_indices, sample_values, num_per_col, num_col, total_sample_size, config_);
   if (dataset->has_raw()) {
-    dataset->ResizeRaw(num_data);
+    dataset->ResizeRaw(num_local_data);
   }
   dataset->set_feature_names(feature_names_);
   return dataset.release();
 }
 
 
 // ---- private functions ----
 
+void DatasetLoader::LoadHeaderFromMemory(Dataset* dataset, const char* buffer) {
+  // get header
+  const char* mem_ptr = buffer;
+  dataset->num_data_ = *(reinterpret_cast<const data_size_t*>(mem_ptr));
+  mem_ptr += VirtualFileWriter::AlignedSize(sizeof(dataset->num_data_));
+  dataset->num_features_ = *(reinterpret_cast<const int*>(mem_ptr));
+  mem_ptr += VirtualFileWriter::AlignedSize(sizeof(dataset->num_features_));
+  dataset->num_total_features_ = *(reinterpret_cast<const int*>(mem_ptr));
+  mem_ptr += VirtualFileWriter::AlignedSize(sizeof(dataset->num_total_features_));
+  dataset->label_idx_ = *(reinterpret_cast<const int*>(mem_ptr));
+  mem_ptr += VirtualFileWriter::AlignedSize(sizeof(dataset->label_idx_));
+  dataset->max_bin_ = *(reinterpret_cast<const int*>(mem_ptr));
+  mem_ptr += VirtualFileWriter::AlignedSize(sizeof(dataset->max_bin_));
+  dataset->bin_construct_sample_cnt_ = *(reinterpret_cast<const int*>(mem_ptr));
+  mem_ptr += VirtualFileWriter::AlignedSize(sizeof(dataset->bin_construct_sample_cnt_));
+  dataset->min_data_in_bin_ = *(reinterpret_cast<const int*>(mem_ptr));
+  mem_ptr += VirtualFileWriter::AlignedSize(sizeof(dataset->min_data_in_bin_));
+  dataset->use_missing_ = *(reinterpret_cast<const bool*>(mem_ptr));
+  mem_ptr += VirtualFileWriter::AlignedSize(sizeof(dataset->use_missing_));
+  dataset->zero_as_missing_ = *(reinterpret_cast<const bool*>(mem_ptr));
+  mem_ptr += VirtualFileWriter::AlignedSize(sizeof(dataset->zero_as_missing_));
+  dataset->has_raw_ = *(reinterpret_cast<const bool*>(mem_ptr));
+
+  mem_ptr += VirtualFileWriter::AlignedSize(sizeof(dataset->has_raw_));
+  const int* tmp_feature_map = reinterpret_cast<const int*>(mem_ptr);
+  dataset->used_feature_map_.clear();
+  for (int i = 0; i < dataset->num_total_features_; ++i) {
+    dataset->used_feature_map_.push_back(tmp_feature_map[i]);
+  }
+  mem_ptr += VirtualFileWriter::AlignedSize(sizeof(int) * dataset->num_total_features_);
+  // num_groups
+  dataset->num_groups_ = *(reinterpret_cast<const int*>(mem_ptr));
+  mem_ptr += VirtualFileWriter::AlignedSize(sizeof(dataset->num_groups_));
+  // real_feature_idx_
+  const int* tmp_ptr_real_feature_idx_ = reinterpret_cast<const int*>(mem_ptr);
+  dataset->real_feature_idx_.clear();
+  for (int i = 0; i < dataset->num_features_; ++i) {
+    dataset->real_feature_idx_.push_back(tmp_ptr_real_feature_idx_[i]);
+  }
+  mem_ptr += VirtualFileWriter::AlignedSize(sizeof(int) * dataset->num_features_);
+  // feature2group
+  const int* tmp_ptr_feature2group = reinterpret_cast<const int*>(mem_ptr);
+  dataset->feature2group_.clear();
+  for (int i = 0; i < dataset->num_features_; ++i) {
+    dataset->feature2group_.push_back(tmp_ptr_feature2group[i]);
+  }
+  mem_ptr += VirtualFileWriter::AlignedSize(sizeof(int) * dataset->num_features_);
+  // feature2subfeature
+  const int* tmp_ptr_feature2subfeature = reinterpret_cast<const int*>(mem_ptr);
+  dataset->feature2subfeature_.clear();
+  for (int i = 0; i < dataset->num_features_; ++i) {
+    dataset->feature2subfeature_.push_back(tmp_ptr_feature2subfeature[i]);
+  }
+  mem_ptr += VirtualFileWriter::AlignedSize(sizeof(int) * dataset->num_features_);
+  // group_bin_boundaries
+  const uint64_t* tmp_ptr_group_bin_boundaries = reinterpret_cast<const uint64_t*>(mem_ptr);
+  dataset->group_bin_boundaries_.clear();
+  for (int i = 0; i < dataset->num_groups_ + 1; ++i) {
+    dataset->group_bin_boundaries_.push_back(tmp_ptr_group_bin_boundaries[i]);
+  }
+  mem_ptr += sizeof(uint64_t) * (dataset->num_groups_ + 1);
+
+  // group_feature_start_
+  const int* tmp_ptr_group_feature_start = reinterpret_cast<const int*>(mem_ptr);
+  dataset->group_feature_start_.clear();
+  for (int i = 0; i < dataset->num_groups_; ++i) {
+    dataset->group_feature_start_.push_back(tmp_ptr_group_feature_start[i]);
+  }
+  mem_ptr += VirtualFileWriter::AlignedSize(sizeof(int) * (dataset->num_groups_));
+
+  // group_feature_cnt_
+  const int* tmp_ptr_group_feature_cnt = reinterpret_cast<const int*>(mem_ptr);
+  dataset->group_feature_cnt_.clear();
+  for (int i = 0; i < dataset->num_groups_; ++i) {
+    dataset->group_feature_cnt_.push_back(tmp_ptr_group_feature_cnt[i]);
+  }
+  mem_ptr += VirtualFileWriter::AlignedSize(sizeof(int) * (dataset->num_groups_));
+
+  if (!config_.max_bin_by_feature.empty()) {
+    CHECK_EQ(static_cast<size_t>(dataset->num_total_features_), config_.max_bin_by_feature.size());
+    CHECK_GT(*(std::min_element(config_.max_bin_by_feature.begin(), config_.max_bin_by_feature.end())), 1);
+    dataset->max_bin_by_feature_.resize(dataset->num_total_features_);
+    dataset->max_bin_by_feature_.assign(config_.max_bin_by_feature.begin(), config_.max_bin_by_feature.end());
+  } else {
+    const int32_t* tmp_ptr_max_bin_by_feature = reinterpret_cast<const int32_t*>(mem_ptr);
+    dataset->max_bin_by_feature_.clear();
+    for (int i = 0; i < dataset->num_total_features_; ++i) {
+      dataset->max_bin_by_feature_.push_back(tmp_ptr_max_bin_by_feature[i]);
+    }
+  }
+  mem_ptr += VirtualFileWriter::AlignedSize(sizeof(int32_t) * (dataset->num_total_features_));
+  if (ArrayArgs<int32_t>::CheckAll(dataset->max_bin_by_feature_, -1)) {
+    dataset->max_bin_by_feature_.clear();
+  }
+
+  // get feature names
+  dataset->feature_names_.clear();
+  for (int i = 0; i < dataset->num_total_features_; ++i) {
+    int str_len = *(reinterpret_cast<const int*>(mem_ptr));
+    mem_ptr += VirtualFileWriter::AlignedSize(sizeof(int));
+    std::stringstream str_buf;
+    auto tmp_arr = reinterpret_cast<const char*>(mem_ptr);
+    for (int j = 0; j < str_len; ++j) {
+      char tmp_char = tmp_arr[j];
+      str_buf << tmp_char;
+    }
+    mem_ptr += VirtualFileWriter::AlignedSize(sizeof(char) * str_len);
+    dataset->feature_names_.emplace_back(str_buf.str());
+  }
+  // get forced_bin_bounds_
+  dataset->forced_bin_bounds_ = std::vector<std::vector<double>>(dataset->num_total_features_, std::vector<double>());
+  for (int i = 0; i < dataset->num_total_features_; ++i) {
+    int num_bounds = *(reinterpret_cast<const int*>(mem_ptr));
+    mem_ptr += VirtualFileWriter::AlignedSize(sizeof(int));
+    dataset->forced_bin_bounds_[i] = std::vector<double>();
+    const double* tmp_ptr_forced_bounds =
+      reinterpret_cast<const double*>(mem_ptr);
+    for (int j = 0; j < num_bounds; ++j) {
+      double bound = tmp_ptr_forced_bounds[j];
+      dataset->forced_bin_bounds_[i].push_back(bound);
+    }
+    mem_ptr += num_bounds * sizeof(double);
+  }
+}
+
 void DatasetLoader::CheckDataset(const Dataset* dataset, bool is_load_from_binary) {
   if (dataset->num_data_ <= 0) {
     Log::Fatal("Data file %s is empty", dataset->data_filename_.c_str());
   }
   if (dataset->feature_names_.size() != static_cast<size_t>(dataset->num_total_features_)) {
     Log::Fatal("Size of feature name error, should be %d, got %d", dataset->num_total_features_,
                static_cast<int>(dataset->feature_names_.size()));
@@ -805,54 +907,56 @@
   }
   if (!is_feature_order_by_group) {
     Log::Fatal("Features in dataset should be ordered by group");
   }
 
   if (is_load_from_binary) {
     if (dataset->max_bin_ != config_.max_bin) {
-      Log::Fatal("Dataset max_bin %d != config %d", dataset->max_bin_, config_.max_bin);
+      Log::Fatal("Dataset was constructed with parameter max_bin=%d. It cannot be changed to %d when loading from binary file.",
+                 dataset->max_bin_, config_.max_bin);
     }
     if (dataset->min_data_in_bin_ != config_.min_data_in_bin) {
-      Log::Fatal("Dataset min_data_in_bin %d != config %d", dataset->min_data_in_bin_, config_.min_data_in_bin);
+      Log::Fatal("Dataset was constructed with parameter min_data_in_bin=%d. It cannot be changed to %d when loading from binary file.",
+                 dataset->min_data_in_bin_, config_.min_data_in_bin);
     }
     if (dataset->use_missing_ != config_.use_missing) {
-      Log::Fatal("Dataset use_missing %d != config %d", dataset->use_missing_, config_.use_missing);
+      Log::Fatal("Dataset was constructed with parameter use_missing=%d. It cannot be changed to %d when loading from binary file.",
+                 dataset->use_missing_, config_.use_missing);
     }
     if (dataset->zero_as_missing_ != config_.zero_as_missing) {
-      Log::Fatal("Dataset zero_as_missing %d != config %d", dataset->zero_as_missing_, config_.zero_as_missing);
+      Log::Fatal("Dataset was constructed with parameter zero_as_missing=%d. It cannot be changed to %d when loading from binary file.",
+                 dataset->zero_as_missing_, config_.zero_as_missing);
     }
     if (dataset->bin_construct_sample_cnt_ != config_.bin_construct_sample_cnt) {
-      Log::Fatal("Dataset bin_construct_sample_cnt %d != config %d", dataset->bin_construct_sample_cnt_, config_.bin_construct_sample_cnt);
+      Log::Fatal("Dataset was constructed with parameter bin_construct_sample_cnt=%d. It cannot be changed to %d when loading from binary file.",
+                 dataset->bin_construct_sample_cnt_, config_.bin_construct_sample_cnt);
     }
     if ((dataset->max_bin_by_feature_.size() != config_.max_bin_by_feature.size()) ||
         !std::equal(dataset->max_bin_by_feature_.begin(), dataset->max_bin_by_feature_.end(),
             config_.max_bin_by_feature.begin())) {
-      Log::Fatal("Dataset max_bin_by_feature does not match with config");
-    }
-
-    int label_idx = -1;
-    if (Common::AtoiAndCheck(config_.label_column.c_str(), &label_idx)) {
-      if (dataset->label_idx_ != label_idx) {
-        Log::Fatal("Dataset label_idx %d != config %d", dataset->label_idx_, label_idx);
-      }
-    } else {
-      Log::Info("Recommend use integer for label index when loading data from binary for sanity check.");
+      Log::Fatal("Parameter max_bin_by_feature cannot be changed when loading from binary file.");
     }
 
     if (config_.label_column != "") {
-      Log::Warning("Config label_column works only in case of loading data directly from text file. It will be ignored when loading from binary file.");
+      Log::Warning("Parameter label_column works only in case of loading data directly from text file. It will be ignored when loading from binary file.");
     }
     if (config_.weight_column != "") {
-      Log::Warning("Config weight_column works only in case of loading data directly from text file. It will be ignored when loading from binary file.");
+      Log::Warning("Parameter weight_column works only in case of loading data directly from text file. It will be ignored when loading from binary file.");
     }
     if (config_.group_column != "") {
-      Log::Warning("Config group_column works only in case of loading data directly from text file. It will be ignored when loading from binary file.");
+      Log::Warning("Parameter group_column works only in case of loading data directly from text file. It will be ignored when loading from binary file.");
     }
     if (config_.ignore_column != "") {
-      Log::Warning("Config ignore_column works only in case of loading data directly from text file. It will be ignored when loading from binary file.");
+      Log::Warning("Parameter ignore_column works only in case of loading data directly from text file. It will be ignored when loading from binary file.");
+    }
+    if (config_.two_round) {
+      Log::Warning("Parameter two_round works only in case of loading data directly from text file. It will be ignored when loading from binary file.");
+    }
+    if (config_.header) {
+      Log::Warning("Parameter header works only in case of loading data directly from text file. It will be ignored when loading from binary file.");
     }
   }
 }
 
 std::vector<std::string> DatasetLoader::LoadTextDataToMemory(const char* filename, const Metadata& metadata,
                                                              int rank, int num_machines, int* num_global_data,
                                                              std::vector<data_size_t>* used_data_indices) {
@@ -1004,15 +1108,19 @@
   // get forced split
   std::string forced_bins_path = config_.forcedbins_filename;
   std::vector<std::vector<double>> forced_bin_bounds = DatasetLoader::GetForcedBins(forced_bins_path,
                                                                                     dataset->num_total_features_,
                                                                                     categorical_features_);
 
   // check the range of label_idx, weight_idx and group_idx
-  CHECK(label_idx_ >= 0 && label_idx_ <= dataset->num_total_features_);
+  // skip label check if user input parser config file,
+  // because label id is got from raw features while dataset features are consistent with customized parser.
+  if (dataset->parser_config_str_.empty()) {
+    CHECK(label_idx_ >= 0 && label_idx_ <= dataset->num_total_features_);
+  }
   CHECK(weight_idx_ < 0 || weight_idx_ < dataset->num_total_features_);
   CHECK(group_idx_ < 0 || group_idx_ < dataset->num_total_features_);
 
   // fill feature_names_ if not header
   if (feature_names_.empty()) {
     for (int i = 0; i < dataset->num_total_features_; ++i) {
       std::stringstream str_buf;
@@ -1134,14 +1242,15 @@
         continue;
       }
       bin_mappers[i].reset(new BinMapper());
       bin_mappers[i]->CopyFrom(cp_ptr);
       cp_ptr += bin_mappers[i]->SizesInByte();
     }
   }
+  CheckCategoricalFeatureNumBin(bin_mappers, config_.max_bin, config_.max_bin_by_feature);
   dataset->Construct(&bin_mappers, dataset->num_total_features_, forced_bin_bounds, Common::Vector2Ptr<int>(&sample_indices).data(),
                      Common::Vector2Ptr<double>(&sample_values).data(),
                      Common::VectorSize<int>(sample_indices).data(), static_cast<int>(sample_indices.size()), sample_data.size(), config_);
   if (dataset->has_raw()) {
     dataset->ResizeRaw(static_cast<int>(sample_data.size()));
   }
 
@@ -1205,15 +1314,15 @@
       dataset->FinishOneRow(tid, i, is_feature_added);
       OMP_LOOP_EX_END();
     }
     OMP_THROW_EX();
   } else {
     OMP_INIT_EX();
     // if need to prediction with initial model
-    std::vector<double> init_score(dataset->num_data_ * num_class_);
+    std::vector<double> init_score(static_cast<size_t>(dataset->num_data_) * num_class_);
     #pragma omp parallel for schedule(static) private(oneline_features) firstprivate(tmp_label, feature_row)
     for (data_size_t i = 0; i < dataset->num_data_; ++i) {
       OMP_LOOP_EX_BEGIN();
       const int tid = omp_get_thread_num();
       oneline_features.clear();
       // parser
       parser->ParseOneLine(ref_text_data[i].c_str(), &oneline_features, &tmp_label);
@@ -1272,15 +1381,15 @@
 }
 
 /*! \brief Extract local features from file */
 void DatasetLoader::ExtractFeaturesFromFile(const char* filename, const Parser* parser,
                                             const std::vector<data_size_t>& used_data_indices, Dataset* dataset) {
   std::vector<double> init_score;
   if (predict_fun_) {
-    init_score = std::vector<double>(dataset->num_data_ * num_class_);
+    init_score = std::vector<double>(static_cast<size_t>(dataset->num_data_) * num_class_);
   }
   std::function<void(data_size_t, const std::vector<std::string>&)> process_fun =
     [this, &init_score, &parser, &dataset]
   (data_size_t start_idx, const std::vector<std::string>& lines) {
     std::vector<std::pair<int, double>> oneline_features;
     double tmp_label = 0.0f;
     std::vector<float> feature_row(dataset->num_features_);
@@ -1377,16 +1486,14 @@
       && std::string(buffer.data()) == std::string(Dataset::binary_file_token)) {
     return bin_filename;
   } else {
     return std::string();
   }
 }
 
-
-
 std::vector<std::vector<double>> DatasetLoader::GetForcedBins(std::string forced_bins_path, int num_total_features,
                                                               const std::unordered_set<int>& categorical_features) {
   std::vector<std::vector<double>> forced_bins(num_total_features, std::vector<double>());
   if (forced_bins_path != "") {
     std::ifstream forced_bins_stream(forced_bins_path.c_str());
     if (forced_bins_stream.fail()) {
       Log::Warning("Could not open %s. Will ignore.", forced_bins_path.c_str());
@@ -1415,8 +1522,48 @@
         forced_bins[i].erase(new_end, forced_bins[i].end());
       }
     }
   }
   return forced_bins;
 }
 
+void DatasetLoader::CheckCategoricalFeatureNumBin(
+  const std::vector<std::unique_ptr<BinMapper>>& bin_mappers,
+  const int max_bin, const std::vector<int>& max_bin_by_feature) const {
+  bool need_warning = false;
+  if (bin_mappers.size() < 1024) {
+    for (size_t i = 0; i < bin_mappers.size(); ++i) {
+      const int max_bin_for_this_feature = max_bin_by_feature.empty() ? max_bin : max_bin_by_feature[i];
+      if (bin_mappers[i] != nullptr && bin_mappers[i]->bin_type() == BinType::CategoricalBin && bin_mappers[i]->num_bin() > max_bin_for_this_feature) {
+        need_warning = true;
+        break;
+      }
+    }
+  } else {
+    const int num_threads = OMP_NUM_THREADS();
+    std::vector<bool> thread_need_warning(num_threads, false);
+    Threading::For<size_t>(0, bin_mappers.size(), 1,
+      [&bin_mappers, &thread_need_warning, &max_bin_by_feature, max_bin] (int thread_index, size_t start, size_t end) {
+        for (size_t i = start; i < end; ++i) {
+          thread_need_warning[thread_index] = false;
+          const int max_bin_for_this_feature = max_bin_by_feature.empty() ? max_bin : max_bin_by_feature[i];
+          if (bin_mappers[i] != nullptr && bin_mappers[i]->bin_type() == BinType::CategoricalBin && bin_mappers[i]->num_bin() > max_bin_for_this_feature) {
+            thread_need_warning[thread_index] = true;
+            break;
+          }
+        }
+      });
+    for (int thread_index = 0; thread_index < num_threads; ++thread_index) {
+      if (thread_need_warning[thread_index]) {
+        need_warning = true;
+        break;
+      }
+    }
+  }
+
+  if (need_warning) {
+    Log::Warning("Categorical features with more bins than the configured maximum bin number found.");
+    Log::Warning("For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.");
+  }
+}
+
 }  // namespace LightGBM
```

### Comparing `lightgbm-3.3.5/compile/src/io/dense_bin.hpp` & `lightgbm-4.0.0/src/io/dense_bin.hpp`

 * *Files 17% similar despite different names*

```diff
@@ -167,14 +167,154 @@
                           const score_t* ordered_gradients,
                           hist_t* out) const override {
     ConstructHistogramInner<false, false, false>(
         nullptr, start, end, ordered_gradients, nullptr, out);
   }
 
 
+  template <bool USE_INDICES, bool USE_PREFETCH, bool USE_HESSIAN, typename PACKED_HIST_T, int HIST_BITS>
+  void ConstructHistogramIntInner(const data_size_t* data_indices,
+                               data_size_t start, data_size_t end,
+                               const score_t* ordered_gradients,
+                               hist_t* out) const {
+    data_size_t i = start;
+    PACKED_HIST_T* out_ptr = reinterpret_cast<PACKED_HIST_T*>(out);
+    const int16_t* gradients_ptr = reinterpret_cast<const int16_t*>(ordered_gradients);
+    const VAL_T* data_ptr_base = data_.data();
+    if (USE_PREFETCH) {
+      const data_size_t pf_offset = 64 / sizeof(VAL_T);
+      const data_size_t pf_end = end - pf_offset;
+      for (; i < pf_end; ++i) {
+        const auto idx = USE_INDICES ? data_indices[i] : i;
+        const auto pf_idx =
+            USE_INDICES ? data_indices[i + pf_offset] : i + pf_offset;
+        if (IS_4BIT) {
+          PREFETCH_T0(data_ptr_base + (pf_idx >> 1));
+        } else {
+          PREFETCH_T0(data_ptr_base + pf_idx);
+        }
+        const auto ti = static_cast<uint32_t>(data(idx));
+        const int16_t gradient_16 = gradients_ptr[i];
+        if (USE_HESSIAN) {
+          const PACKED_HIST_T gradient_packed = HIST_BITS == 8 ? gradient_16 :
+            (static_cast<PACKED_HIST_T>(static_cast<int8_t>(gradient_16 >> 8)) << HIST_BITS) | (gradient_16 & 0xff);
+          out_ptr[ti] += gradient_packed;
+        } else {
+          const PACKED_HIST_T gradient_packed = HIST_BITS == 8 ? gradient_16 :
+            (static_cast<PACKED_HIST_T>(static_cast<int8_t>(gradient_16 >> 8)) << HIST_BITS) | (1);
+          out_ptr[ti] += gradient_packed;
+        }
+      }
+    }
+    for (; i < end; ++i) {
+      const auto idx = USE_INDICES ? data_indices[i] : i;
+      const auto ti = static_cast<uint32_t>(data(idx));
+      const int16_t gradient_16 = gradients_ptr[i];
+      if (USE_HESSIAN) {
+        const PACKED_HIST_T gradient_packed = HIST_BITS == 8 ? gradient_16 :
+            (static_cast<PACKED_HIST_T>(static_cast<int8_t>(gradient_16 >> 8)) << HIST_BITS) | (gradient_16 & 0xff);
+        out_ptr[ti] += gradient_packed;
+      } else {
+        const PACKED_HIST_T gradient_packed = HIST_BITS == 8 ? gradient_16 :
+            (static_cast<PACKED_HIST_T>(static_cast<int8_t>(gradient_16 >> 8)) << HIST_BITS) | (1);
+        out_ptr[ti] += gradient_packed;
+      }
+    }
+  }
+
+  void ConstructHistogramInt8(const data_size_t* data_indices, data_size_t start,
+                          data_size_t end, const score_t* ordered_gradients,
+                          const score_t* /*ordered_hessians*/,
+                          hist_t* out) const override {
+    ConstructHistogramIntInner<true, true, true, int16_t, 8>(
+        data_indices, start, end, ordered_gradients, out);
+  }
+
+  void ConstructHistogramInt8(data_size_t start, data_size_t end,
+                          const score_t* ordered_gradients,
+                          const score_t* /*ordered_hessians*/,
+                          hist_t* out) const override {
+    ConstructHistogramIntInner<false, false, true, int16_t, 8>(
+        nullptr, start, end, ordered_gradients, out);
+  }
+
+  void ConstructHistogramInt8(const data_size_t* data_indices, data_size_t start,
+                          data_size_t end, const score_t* ordered_gradients,
+                          hist_t* out) const override {
+    ConstructHistogramIntInner<true, true, false, int16_t, 8>(
+      data_indices, start, end, ordered_gradients, out);
+  }
+
+  void ConstructHistogramInt8(data_size_t start, data_size_t end,
+                          const score_t* ordered_gradients,
+                          hist_t* out) const override {
+    ConstructHistogramIntInner<false, false, false, int16_t, 8>(
+        nullptr, start, end, ordered_gradients, out);
+  }
+
+  void ConstructHistogramInt16(const data_size_t* data_indices, data_size_t start,
+                          data_size_t end, const score_t* ordered_gradients,
+                          const score_t* /*ordered_hessians*/,
+                          hist_t* out) const override {
+    ConstructHistogramIntInner<true, true, true, int32_t, 16>(
+        data_indices, start, end, ordered_gradients, out);
+  }
+
+  void ConstructHistogramInt16(data_size_t start, data_size_t end,
+                          const score_t* ordered_gradients,
+                          const score_t* /*ordered_hessians*/,
+                          hist_t* out) const override {
+    ConstructHistogramIntInner<false, false, true, int32_t, 16>(
+        nullptr, start, end, ordered_gradients, out);
+  }
+
+  void ConstructHistogramInt16(const data_size_t* data_indices, data_size_t start,
+                          data_size_t end, const score_t* ordered_gradients,
+                          hist_t* out) const override {
+    ConstructHistogramIntInner<true, true, false, int32_t, 16>(
+      data_indices, start, end, ordered_gradients, out);
+  }
+
+  void ConstructHistogramInt16(data_size_t start, data_size_t end,
+                          const score_t* ordered_gradients,
+                          hist_t* out) const override {
+    ConstructHistogramIntInner<false, false, false, int32_t, 16>(
+        nullptr, start, end, ordered_gradients, out);
+  }
+
+  void ConstructHistogramInt32(const data_size_t* data_indices, data_size_t start,
+                          data_size_t end, const score_t* ordered_gradients,
+                          const score_t* /*ordered_hessians*/,
+                          hist_t* out) const override {
+    ConstructHistogramIntInner<true, true, true, int64_t, 32>(
+        data_indices, start, end, ordered_gradients, out);
+  }
+
+  void ConstructHistogramInt32(data_size_t start, data_size_t end,
+                          const score_t* ordered_gradients,
+                          const score_t* /*ordered_hessians*/,
+                          hist_t* out) const override {
+    ConstructHistogramIntInner<false, false, true, int64_t, 32>(
+        nullptr, start, end, ordered_gradients, out);
+  }
+
+  void ConstructHistogramInt32(const data_size_t* data_indices, data_size_t start,
+                          data_size_t end, const score_t* ordered_gradients,
+                          hist_t* out) const override {
+    ConstructHistogramIntInner<true, true, false, int64_t, 32>(
+      data_indices, start, end, ordered_gradients, out);
+  }
+
+  void ConstructHistogramInt32(data_size_t start, data_size_t end,
+                          const score_t* ordered_gradients,
+                          hist_t* out) const override {
+    ConstructHistogramIntInner<false, false, false, int64_t, 32>(
+        nullptr, start, end, ordered_gradients, out);
+  }
+
   template <bool MISS_IS_ZERO, bool MISS_IS_NA, bool MFB_IS_ZERO,
             bool MFB_IS_NA, bool USE_MIN_BIN>
   data_size_t SplitInner(uint32_t min_bin, uint32_t max_bin,
                          uint32_t default_bin, uint32_t most_freq_bin,
                          bool default_left, uint32_t threshold,
                          const data_size_t* data_indices, data_size_t cnt,
                          data_size_t* lte_indices,
@@ -447,24 +587,28 @@
     } else {
       for (int i = 0; i < num_used_indices; ++i) {
         data_[i] = other_bin->data_[used_indices[i]];
       }
     }
   }
 
-  void SaveBinaryToFile(const VirtualFileWriter* writer) const override {
+  void SaveBinaryToFile(BinaryWriter* writer) const override {
     writer->AlignedWrite(data_.data(), sizeof(VAL_T) * data_.size());
   }
 
   size_t SizesInByte() const override {
     return VirtualFileWriter::AlignedSize(sizeof(VAL_T) * data_.size());
   }
 
   DenseBin<VAL_T, IS_4BIT>* Clone() override;
 
+  const void* GetColWiseData(uint8_t* bit_type, bool* is_sparse, std::vector<BinIterator*>* bin_iterator, const int num_threads) const override;
+
+  const void* GetColWiseData(uint8_t* bit_type, bool* is_sparse, BinIterator** bin_iterator) const override;
+
  private:
   data_size_t num_data_;
 #ifdef USE_CUDA
   std::vector<VAL_T, CHAllocator<VAL_T>> data_;
 #else
   std::vector<VAL_T, Common::AlignmentAllocator<VAL_T, kAlignedSize>> data_;
 #endif
```

### Comparing `lightgbm-3.3.5/compile/src/io/file_io.cpp` & `lightgbm-4.0.0/src/io/file_io.cpp`

 * *Files 1% similar despite different names*

```diff
@@ -42,15 +42,15 @@
     return file.Init();
   }
 
   size_t Read(void* buffer, size_t bytes) const {
     return fread(buffer, 1, bytes, file_);
   }
 
-  size_t Write(const void* buffer, size_t bytes) const {
+  size_t Write(const void* buffer, size_t bytes) {
     return fwrite(buffer, bytes, 1, file_) == 1 ? bytes : 0;
   }
 
  private:
   FILE* file_ = NULL;
   const std::string filename_;
   const std::string mode_;
```

### Comparing `lightgbm-3.3.5/compile/src/io/json11.cpp` & `lightgbm-4.0.0/src/io/json11.cpp`

 * *Files 0% similar despite different names*

```diff
@@ -23,15 +23,15 @@
 #include <LightGBM/utils/log.h>
 
 #include <cmath>
 #include <cstdio>
 #include <cstdlib>
 #include <limits>
 
-namespace json11 {
+namespace json11_internal_lightgbm {
 
 static const int max_depth = 200;
 
 using std::initializer_list;
 using std::make_shared;
 using std::map;
 using std::string;
@@ -156,15 +156,15 @@
     return m_value == static_cast<const Value<tag, T> *>(other)->m_value;
   }
   bool less(const JsonValue *other) const override {
     return m_value < (static_cast<const Value<tag, T> *>(other)->m_value);
   }
 
   const T m_value;
-  void dump(string *out) const override { json11::dump(m_value, out); }
+  void dump(string *out) const override { json11_internal_lightgbm::dump(m_value, out); }
 };
 
 class JsonDouble final : public Value<Json::NUMBER, double> {
   double number_value() const override { return m_value; }
   int int_value() const override { return static_cast<int>(m_value); }
   bool equals(const JsonValue *other) const override {
     return m_value == other->number_value();
@@ -773,8 +773,8 @@
       return false;
     }
   }
 
   return true;
 }
 
-}  // namespace json11
+}  // namespace json11_internal_lightgbm
```

### Comparing `lightgbm-3.3.5/compile/src/io/metadata.cpp` & `lightgbm-4.0.0/src/io/metadata.cpp`

 * *Files 12% similar despite different names*

```diff
@@ -14,23 +14,26 @@
   num_weights_ = 0;
   num_init_score_ = 0;
   num_data_ = 0;
   num_queries_ = 0;
   weight_load_from_file_ = false;
   query_load_from_file_ = false;
   init_score_load_from_file_ = false;
+  #ifdef USE_CUDA
+  cuda_metadata_ = nullptr;
+  #endif  // USE_CUDA
 }
 
 void Metadata::Init(const char* data_filename) {
   data_filename_ = data_filename;
   // for lambdarank, it needs query data for partition data in distributed learning
   LoadQueryBoundaries();
   LoadWeights();
-  LoadQueryWeights();
-  LoadInitialScore();
+  CalculateQueryWeights();
+  LoadInitialScore(data_filename_);
 }
 
 Metadata::~Metadata() {
 }
 
 void Metadata::Init(data_size_t num_data, int weight_idx, int query_idx) {
   num_data_ = num_data;
@@ -51,14 +54,49 @@
     }
     if (!query_weights_.empty()) { query_weights_.clear(); }
     queries_ = std::vector<data_size_t>(num_data_, 0);
     query_load_from_file_ = false;
   }
 }
 
+void Metadata::InitByReference(data_size_t num_data, const Metadata* reference) {
+  int has_weights = reference->num_weights_ > 0;
+  int has_init_scores = reference->num_init_score_ > 0;
+  int has_queries = reference->num_queries_ > 0;
+  int nclasses = reference->num_init_score_classes();
+  Init(num_data, has_weights, has_init_scores, has_queries, nclasses);
+}
+
+void Metadata::Init(data_size_t num_data, int32_t has_weights, int32_t has_init_scores, int32_t has_queries, int32_t nclasses) {
+  num_data_ = num_data;
+  label_ = std::vector<label_t>(num_data_);
+  if (has_weights) {
+    if (!weights_.empty()) {
+      Log::Fatal("Calling Init() on Metadata weights that have already been initialized");
+    }
+    weights_.resize(num_data_, 0.0f);
+    num_weights_ = num_data_;
+    weight_load_from_file_ = false;
+  }
+  if (has_init_scores) {
+    if (!init_score_.empty()) {
+      Log::Fatal("Calling Init() on Metadata initial scores that have already been initialized");
+    }
+    num_init_score_ = static_cast<int64_t>(num_data) * nclasses;
+    init_score_.resize(num_init_score_, 0);
+  }
+  if (has_queries) {
+    if (!query_weights_.empty()) {
+      Log::Fatal("Calling Init() on Metadata queries that have already been initialized");
+    }
+    queries_.resize(num_data_, 0);
+    query_load_from_file_ = false;
+  }
+}
+
 void Metadata::Init(const Metadata& fullset, const data_size_t* used_indices, data_size_t num_used_indices) {
   num_data_ = num_used_indices;
 
   label_ = std::vector<label_t>(num_used_indices);
 #pragma omp parallel for schedule(static, 512) if (num_used_indices >= 1024)
   for (data_size_t i = 0; i < num_used_indices; ++i) {
     label_[i] = fullset.label_[used_indices[i]];
@@ -134,41 +172,45 @@
 #pragma omp parallel for schedule(static, 512) if (num_data_ >= 1024)
   for (data_size_t i = 0; i < num_data_; ++i) {
     label_[i] = old_label[used_indices[i]];
   }
   old_label.clear();
 }
 
-void Metadata::CheckOrPartition(data_size_t num_all_data, const std::vector<data_size_t>& used_data_indices) {
-  if (used_data_indices.empty()) {
-    if (!queries_.empty()) {
-      // need convert query_id to boundaries
-      std::vector<data_size_t> tmp_buffer;
-      data_size_t last_qid = -1;
-      data_size_t cur_cnt = 0;
-      for (data_size_t i = 0; i < num_data_; ++i) {
-        if (last_qid != queries_[i]) {
-          if (cur_cnt > 0) {
-            tmp_buffer.push_back(cur_cnt);
-          }
-          cur_cnt = 0;
-          last_qid = queries_[i];
+void Metadata::CalculateQueryBoundaries() {
+  if (!queries_.empty()) {
+    // need convert query_id to boundaries
+    std::vector<data_size_t> tmp_buffer;
+    data_size_t last_qid = -1;
+    data_size_t cur_cnt = 0;
+    for (data_size_t i = 0; i < num_data_; ++i) {
+      if (last_qid != queries_[i]) {
+        if (cur_cnt > 0) {
+          tmp_buffer.push_back(cur_cnt);
         }
-        ++cur_cnt;
-      }
-      tmp_buffer.push_back(cur_cnt);
-      query_boundaries_ = std::vector<data_size_t>(tmp_buffer.size() + 1);
-      num_queries_ = static_cast<data_size_t>(tmp_buffer.size());
-      query_boundaries_[0] = 0;
-      for (size_t i = 0; i < tmp_buffer.size(); ++i) {
-        query_boundaries_[i + 1] = query_boundaries_[i] + tmp_buffer[i];
+        cur_cnt = 0;
+        last_qid = queries_[i];
       }
-      LoadQueryWeights();
-      queries_.clear();
+      ++cur_cnt;
     }
+    tmp_buffer.push_back(cur_cnt);
+    query_boundaries_ = std::vector<data_size_t>(tmp_buffer.size() + 1);
+    num_queries_ = static_cast<data_size_t>(tmp_buffer.size());
+    query_boundaries_[0] = 0;
+    for (size_t i = 0; i < tmp_buffer.size(); ++i) {
+      query_boundaries_[i + 1] = query_boundaries_[i] + tmp_buffer[i];
+    }
+    CalculateQueryWeights();
+    queries_.clear();
+  }
+}
+
+void Metadata::CheckOrPartition(data_size_t num_all_data, const std::vector<data_size_t>& used_data_indices) {
+  if (used_data_indices.empty()) {
+     CalculateQueryBoundaries();
     // check weights
     if (!weights_.empty() && num_weights_ != num_data_) {
       weights_.clear();
       num_weights_ = 0;
       Log::Fatal("Weights size doesn't match data size");
     }
 
@@ -270,16 +312,16 @@
           for (size_t i = 0; i < used_data_indices.size(); ++i) {
             init_score_[offset_dest + i] = old_scores[offset_src + used_data_indices[i]];
           }
         }
         old_scores.clear();
       }
     }
-    // re-load query weight
-    LoadQueryWeights();
+    // re-calculate query weight
+    CalculateQueryWeights();
   }
   if (num_queries_ > 0) {
     Log::Debug("Number of queries in %s: %i. Average number of rows per query: %f.",
       data_filename_.c_str(), static_cast<int>(num_queries_), static_cast<double>(num_data_) / num_queries_);
   }
 }
 
@@ -298,14 +340,41 @@
   num_init_score_ = len;
 
   #pragma omp parallel for schedule(static, 512) if (num_init_score_ >= 1024)
   for (int64_t i = 0; i < num_init_score_; ++i) {
     init_score_[i] = Common::AvoidInf(init_score[i]);
   }
   init_score_load_from_file_ = false;
+  #ifdef USE_CUDA
+  if (cuda_metadata_ != nullptr) {
+    cuda_metadata_->SetInitScore(init_score_.data(), len);
+  }
+  #endif  // USE_CUDA
+}
+
+void Metadata::InsertInitScores(const double* init_scores, data_size_t start_index, data_size_t len, data_size_t source_size) {
+  if (num_init_score_ <= 0) {
+    Log::Fatal("Inserting initial score data into dataset with no initial scores");
+  }
+  if (start_index + len > num_data_) {
+    // Note that len here is row count, not num_init_score, so we compare against num_data
+    Log::Fatal("Inserted initial score data is too large for dataset");
+  }
+  if (init_score_.empty()) { init_score_.resize(num_init_score_); }
+
+  int nclasses = num_init_score_classes();
+
+  for (int32_t col = 0; col < nclasses; ++col) {
+    int32_t dest_offset = num_data_ * col + start_index;
+    // We need to use source_size here, because len might not equal size (due to a partially loaded dataset)
+    int32_t source_offset = source_size * col;
+    memcpy(init_score_.data() + dest_offset, init_scores + source_offset, sizeof(double) * len);
+  }
+  init_score_load_from_file_ = false;
+  // CUDA is handled after all insertions are complete
 }
 
 void Metadata::SetLabel(const label_t* label, data_size_t len) {
   std::lock_guard<std::mutex> lock(mutex_);
   if (label == nullptr) {
     Log::Fatal("label cannot be nullptr");
   }
@@ -314,14 +383,33 @@
   }
   if (label_.empty()) { label_.resize(num_data_); }
 
   #pragma omp parallel for schedule(static, 512) if (num_data_ >= 1024)
   for (data_size_t i = 0; i < num_data_; ++i) {
     label_[i] = Common::AvoidInf(label[i]);
   }
+  #ifdef USE_CUDA
+  if (cuda_metadata_ != nullptr) {
+    cuda_metadata_->SetLabel(label_.data(), len);
+  }
+  #endif  // USE_CUDA
+}
+
+void Metadata::InsertLabels(const label_t* labels, data_size_t start_index, data_size_t len) {
+  if (labels == nullptr) {
+    Log::Fatal("label cannot be nullptr");
+  }
+  if (start_index + len > num_data_) {
+    Log::Fatal("Inserted label data is too large for dataset");
+  }
+  if (label_.empty()) { label_.resize(num_data_); }
+
+  memcpy(label_.data() + start_index, labels, sizeof(label_t) * len);
+
+  // CUDA is handled after all insertions are complete
 }
 
 void Metadata::SetWeights(const label_t* weights, data_size_t len) {
   std::lock_guard<std::mutex> lock(mutex_);
   // save to nullptr
   if (weights == nullptr || len == 0) {
     weights_.clear();
@@ -334,16 +422,39 @@
   if (weights_.empty()) { weights_.resize(num_data_); }
   num_weights_ = num_data_;
 
   #pragma omp parallel for schedule(static, 512) if (num_weights_ >= 1024)
   for (data_size_t i = 0; i < num_weights_; ++i) {
     weights_[i] = Common::AvoidInf(weights[i]);
   }
-  LoadQueryWeights();
+  CalculateQueryWeights();
+  weight_load_from_file_ = false;
+  #ifdef USE_CUDA
+  if (cuda_metadata_ != nullptr) {
+    cuda_metadata_->SetWeights(weights_.data(), len);
+  }
+  #endif  // USE_CUDA
+}
+
+void Metadata::InsertWeights(const label_t* weights, data_size_t start_index, data_size_t len) {
+  if (!weights) {
+    Log::Fatal("Passed null weights");
+  }
+  if (num_weights_ <= 0) {
+    Log::Fatal("Inserting weight data into dataset with no weights");
+  }
+  if (start_index + len > num_weights_) {
+    Log::Fatal("Inserted weight data is too large for dataset");
+  }
+  if (weights_.empty()) { weights_.resize(num_weights_); }
+
+  memcpy(weights_.data() + start_index, weights, sizeof(label_t) * len);
+
   weight_load_from_file_ = false;
+  // CUDA is handled after all insertions are complete
 }
 
 void Metadata::SetQuery(const data_size_t* query, data_size_t len) {
   std::lock_guard<std::mutex> lock(mutex_);
   // save to nullptr
   if (query == nullptr || len == 0) {
     query_boundaries_.clear();
@@ -360,16 +471,43 @@
   }
   num_queries_ = len;
   query_boundaries_.resize(num_queries_ + 1);
   query_boundaries_[0] = 0;
   for (data_size_t i = 0; i < num_queries_; ++i) {
     query_boundaries_[i + 1] = query_boundaries_[i] + query[i];
   }
-  LoadQueryWeights();
+  CalculateQueryWeights();
+  query_load_from_file_ = false;
+  #ifdef USE_CUDA
+  if (cuda_metadata_ != nullptr) {
+    if (query_weights_.size() > 0) {
+      CHECK_EQ(query_weights_.size(), static_cast<size_t>(num_queries_));
+      cuda_metadata_->SetQuery(query_boundaries_.data(), query_weights_.data(), num_queries_);
+    } else {
+      cuda_metadata_->SetQuery(query_boundaries_.data(), nullptr, num_queries_);
+    }
+  }
+  #endif  // USE_CUDA
+}
+
+void Metadata::InsertQueries(const data_size_t* queries, data_size_t start_index, data_size_t len) {
+  if (!queries) {
+    Log::Fatal("Passed null queries");
+  }
+  if (queries_.size() <= 0) {
+    Log::Fatal("Inserting query data into dataset with no queries");
+  }
+  if (static_cast<size_t>(start_index + len) > queries_.size()) {
+    Log::Fatal("Inserted query data is too large for dataset");
+  }
+
+  memcpy(queries_.data() + start_index, queries, sizeof(data_size_t) * len);
+
   query_load_from_file_ = false;
+  // CUDA is handled after all insertions are complete
 }
 
 void Metadata::LoadWeights() {
   num_weights_ = 0;
   std::string weight_filename(data_filename_);
   // default weight file name
   weight_filename.append(".weight");
@@ -386,18 +524,18 @@
     double tmp_weight = 0.0f;
     Common::Atof(reader.Lines()[i].c_str(), &tmp_weight);
     weights_[i] = Common::AvoidInf(static_cast<label_t>(tmp_weight));
   }
   weight_load_from_file_ = true;
 }
 
-void Metadata::LoadInitialScore() {
+void Metadata::LoadInitialScore(const std::string& data_filename) {
   num_init_score_ = 0;
-  std::string init_score_filename(data_filename_);
-  init_score_filename = std::string(data_filename_);
+  std::string init_score_filename(data_filename);
+  init_score_filename = std::string(data_filename);
   // default init_score file name
   init_score_filename.append(".init");
   TextReader<size_t> reader(init_score_filename.c_str(), false);
   reader.ReadAllLines();
   if (reader.Lines().empty()) {
     return;
   }
@@ -440,42 +578,74 @@
   // default query file name
   query_filename.append(".query");
   TextReader<size_t> reader(query_filename.c_str(), false);
   reader.ReadAllLines();
   if (reader.Lines().empty()) {
     return;
   }
-  Log::Info("Loading query boundaries...");
+  Log::Info("Calculating query boundaries...");
   query_boundaries_ = std::vector<data_size_t>(reader.Lines().size() + 1);
   num_queries_ = static_cast<data_size_t>(reader.Lines().size());
   query_boundaries_[0] = 0;
   for (size_t i = 0; i < reader.Lines().size(); ++i) {
     int tmp_cnt;
     Common::Atoi(reader.Lines()[i].c_str(), &tmp_cnt);
     query_boundaries_[i + 1] = query_boundaries_[i] + static_cast<data_size_t>(tmp_cnt);
   }
   query_load_from_file_ = true;
 }
 
-void Metadata::LoadQueryWeights() {
+void Metadata::CalculateQueryWeights() {
   if (weights_.size() == 0 || query_boundaries_.size() == 0) {
     return;
   }
   query_weights_.clear();
-  Log::Info("Loading query weights...");
+  Log::Info("Calculating query weights...");
   query_weights_ = std::vector<label_t>(num_queries_);
   for (data_size_t i = 0; i < num_queries_; ++i) {
     query_weights_[i] = 0.0f;
     for (data_size_t j = query_boundaries_[i]; j < query_boundaries_[i + 1]; ++j) {
       query_weights_[i] += weights_[j];
     }
     query_weights_[i] /= (query_boundaries_[i + 1] - query_boundaries_[i]);
   }
 }
 
+void Metadata::InsertAt(data_size_t start_index,
+  data_size_t count,
+  const float* labels,
+  const float* weights,
+  const double* init_scores,
+  const int32_t* queries) {
+  if (num_data_ < count + start_index) {
+    Log::Fatal("Length of metadata is too long to append #data");
+  }
+  InsertLabels(labels, start_index, count);
+  if (weights) {
+    InsertWeights(weights, start_index, count);
+  }
+  if (init_scores) {
+    InsertInitScores(init_scores, start_index, count, count);
+  }
+  if (queries) {
+    InsertQueries(queries, start_index, count);
+  }
+}
+
+void Metadata::FinishLoad() {
+  CalculateQueryBoundaries();
+}
+
+#ifdef USE_CUDA
+void Metadata::CreateCUDAMetadata(const int gpu_device_id) {
+  cuda_metadata_.reset(new CUDAMetadata(gpu_device_id));
+  cuda_metadata_->Init(label_, weights_, query_boundaries_, query_weights_, init_score_);
+}
+#endif  // USE_CUDA
+
 void Metadata::LoadFromMemory(const void* memory) {
   const char* mem_ptr = reinterpret_cast<const char*>(memory);
 
   num_data_ = *(reinterpret_cast<const data_size_t*>(mem_ptr));
   mem_ptr += VirtualFileWriter::AlignedSize(sizeof(num_data_));
   num_weights_ = *(reinterpret_cast<const data_size_t*>(mem_ptr));
   mem_ptr += VirtualFileWriter::AlignedSize(sizeof(num_weights_));
@@ -498,18 +668,18 @@
     if (!query_boundaries_.empty()) { query_boundaries_.clear(); }
     query_boundaries_ = std::vector<data_size_t>(num_queries_ + 1);
     std::memcpy(query_boundaries_.data(), mem_ptr, sizeof(data_size_t) * (num_queries_ + 1));
     mem_ptr += VirtualFileWriter::AlignedSize(sizeof(data_size_t) *
                                               (num_queries_ + 1));
     query_load_from_file_ = true;
   }
-  LoadQueryWeights();
+  CalculateQueryWeights();
 }
 
-void Metadata::SaveBinaryToFile(const VirtualFileWriter* writer) const {
+void Metadata::SaveBinaryToFile(BinaryWriter* writer) const {
   writer->AlignedWrite(&num_data_, sizeof(num_data_));
   writer->AlignedWrite(&num_weights_, sizeof(num_weights_));
   writer->AlignedWrite(&num_queries_, sizeof(num_queries_));
   writer->AlignedWrite(label_.data(), sizeof(label_t) * num_data_);
   if (!weights_.empty()) {
     writer->AlignedWrite(weights_.data(), sizeof(label_t) * num_weights_);
   }
```

### Comparing `lightgbm-3.3.5/compile/src/io/multi_val_sparse_bin.hpp` & `lightgbm-4.0.0/include/LightGBM/train_share_states.h`

 * *Files 24% similar despite different names*

```diff
@@ -1,320 +1,365 @@
 /*!
- * Copyright (c) 2020 Microsoft Corporation. All rights reserved.
+ * Copyright (c) 2016 Microsoft Corporation. All rights reserved.
  * Licensed under the MIT License. See LICENSE file in the project root for license information.
  */
-#ifndef LIGHTGBM_IO_MULTI_VAL_SPARSE_BIN_HPP_
-#define LIGHTGBM_IO_MULTI_VAL_SPARSE_BIN_HPP_
+#ifndef LIGHTGBM_TRAIN_SHARE_STATES_H_
+#define LIGHTGBM_TRAIN_SHARE_STATES_H_
 
 #include <LightGBM/bin.h>
-#include <LightGBM/utils/openmp_wrapper.h>
+#include <LightGBM/feature_group.h>
+#include <LightGBM/meta.h>
+#include <LightGBM/utils/threading.h>
 
 #include <algorithm>
-#include <cstdint>
-#include <cstring>
+#include <memory>
 #include <vector>
 
 namespace LightGBM {
 
-template <typename INDEX_T, typename VAL_T>
-class MultiValSparseBin : public MultiValBin {
+class MultiValBinWrapper {
  public:
-  explicit MultiValSparseBin(data_size_t num_data, int num_bin,
-                             double estimate_element_per_row)
-      : num_data_(num_data),
-        num_bin_(num_bin),
-        estimate_element_per_row_(estimate_element_per_row) {
-    row_ptr_.resize(num_data_ + 1, 0);
-    INDEX_T estimate_num_data = static_cast<INDEX_T>(estimate_element_per_row_ * 1.1 * num_data_);
-    int num_threads = OMP_NUM_THREADS();
-    if (num_threads > 1) {
-      t_data_.resize(num_threads - 1);
-      for (size_t i = 0; i < t_data_.size(); ++i) {
-        t_data_[i].resize(estimate_num_data / num_threads);
+  MultiValBinWrapper(MultiValBin* bin, data_size_t num_data,
+    const std::vector<int>& feature_groups_contained, const int num_grad_quant_bins);
+
+  bool IsSparse() {
+    if (multi_val_bin_ != nullptr) {
+      return multi_val_bin_->IsSparse();
+    }
+    return false;
+  }
+
+  void InitTrain(const std::vector<int>& group_feature_start,
+    const std::vector<std::unique_ptr<FeatureGroup>>& feature_groups,
+    const std::vector<int8_t>& is_feature_used,
+    const data_size_t* bagging_use_indices,
+    data_size_t bagging_indices_cnt);
+
+  template <bool USE_QUANT_GRAD, int HIST_BITS, int INNER_HIST_BITS>
+  void HistMove(const std::vector<hist_t, Common::AlignmentAllocator<hist_t, kAlignedSize>>& hist_buf);
+
+  template <bool USE_QUANT_GRAD, int HIST_BITS, int INNER_HIST_BITS>
+  void HistMerge(std::vector<hist_t, Common::AlignmentAllocator<hist_t, kAlignedSize>>* hist_buf);
+
+  void ResizeHistBuf(std::vector<hist_t, Common::AlignmentAllocator<hist_t, kAlignedSize>>* hist_buf,
+    MultiValBin* sub_multi_val_bin,
+    hist_t* origin_hist_data);
+
+  template <bool USE_INDICES, bool ORDERED, bool USE_QUANT_GRAD, int HIST_BITS>
+  void ConstructHistograms(const data_size_t* data_indices,
+      data_size_t num_data,
+      const score_t* gradients,
+      const score_t* hessians,
+      std::vector<hist_t, Common::AlignmentAllocator<hist_t, kAlignedSize>>* hist_buf,
+      hist_t* origin_hist_data) {
+    const auto cur_multi_val_bin = (is_use_subcol_ || is_use_subrow_)
+          ? multi_val_bin_subset_.get()
+          : multi_val_bin_.get();
+    if (cur_multi_val_bin != nullptr) {
+      global_timer.Start("Dataset::sparse_bin_histogram");
+      n_data_block_ = 1;
+      data_block_size_ = num_data;
+      Threading::BlockInfo<data_size_t>(num_threads_, num_data, min_block_size_,
+                                        &n_data_block_, &data_block_size_);
+      ResizeHistBuf(hist_buf, cur_multi_val_bin, origin_hist_data);
+      const int inner_hist_bits = (data_block_size_ * num_grad_quant_bins_ < 256 && HIST_BITS == 16) ? 8 : HIST_BITS;
+      OMP_INIT_EX();
+      #pragma omp parallel for schedule(static) num_threads(num_threads_)
+      for (int block_id = 0; block_id < n_data_block_; ++block_id) {
+        OMP_LOOP_EX_BEGIN();
+        data_size_t start = block_id * data_block_size_;
+        data_size_t end = std::min<data_size_t>(start + data_block_size_, num_data);
+        if (inner_hist_bits == 8) {
+          ConstructHistogramsForBlock<USE_INDICES, ORDERED, USE_QUANT_GRAD, 8>(
+            cur_multi_val_bin, start, end, data_indices, gradients, hessians,
+            block_id, hist_buf);
+        } else {
+          ConstructHistogramsForBlock<USE_INDICES, ORDERED, USE_QUANT_GRAD, HIST_BITS>(
+            cur_multi_val_bin, start, end, data_indices, gradients, hessians,
+            block_id, hist_buf);
+        }
+        OMP_LOOP_EX_END();
       }
+      OMP_THROW_EX();
+      global_timer.Stop("Dataset::sparse_bin_histogram");
+
+      global_timer.Start("Dataset::sparse_bin_histogram_merge");
+      if (inner_hist_bits == 8) {
+        HistMerge<USE_QUANT_GRAD, HIST_BITS, 8>(hist_buf);
+      } else {
+        HistMerge<USE_QUANT_GRAD, HIST_BITS, HIST_BITS>(hist_buf);
+      }
+      global_timer.Stop("Dataset::sparse_bin_histogram_merge");
+      global_timer.Start("Dataset::sparse_bin_histogram_move");
+      if (inner_hist_bits == 8) {
+        HistMove<USE_QUANT_GRAD, HIST_BITS, 8>(*hist_buf);
+      } else {
+        HistMove<USE_QUANT_GRAD, HIST_BITS, HIST_BITS>(*hist_buf);
+      }
+      global_timer.Stop("Dataset::sparse_bin_histogram_move");
     }
-    t_size_.resize(num_threads, 0);
-    data_.resize(estimate_num_data / num_threads);
   }
 
-  ~MultiValSparseBin() {}
+  template <bool USE_INDICES, bool ORDERED, bool USE_QUANT_GRAD, int HIST_BITS>
+  void ConstructHistogramsForBlock(const MultiValBin* sub_multi_val_bin,
+    data_size_t start, data_size_t end, const data_size_t* data_indices,
+    const score_t* gradients, const score_t* hessians, int block_id,
+    std::vector<hist_t, Common::AlignmentAllocator<hist_t, kAlignedSize>>* hist_buf) {
+    if (USE_QUANT_GRAD) {
+      if (HIST_BITS == 8) {
+        int8_t* hist_buf_ptr = reinterpret_cast<int8_t*>(hist_buf->data());
+        int8_t* data_ptr = hist_buf_ptr +
+          static_cast<size_t>(num_bin_aligned_) * block_id * 2;
+        std::memset(reinterpret_cast<void*>(data_ptr), 0, num_bin_ * kInt8HistBufferEntrySize);
+        if (USE_INDICES) {
+          if (ORDERED) {
+            sub_multi_val_bin->ConstructHistogramOrderedInt8(data_indices, start, end,
+                                                              gradients, hessians,
+                                                              reinterpret_cast<hist_t*>(data_ptr));
+          } else {
+            sub_multi_val_bin->ConstructHistogramInt8(data_indices, start, end, gradients,
+                                                       hessians,
+                                                       reinterpret_cast<hist_t*>(data_ptr));
+          }
+        } else {
+          sub_multi_val_bin->ConstructHistogramInt8(start, end, gradients, hessians,
+                                                     reinterpret_cast<hist_t*>(data_ptr));
+        }
+      } else if (HIST_BITS == 16) {
+        int16_t* data_ptr = reinterpret_cast<int16_t*>(origin_hist_data_);
+        int16_t* hist_buf_ptr = reinterpret_cast<int16_t*>(hist_buf->data());
+        if (block_id == 0) {
+          if (is_use_subcol_) {
+            data_ptr = hist_buf_ptr + hist_buf->size() - 2 * static_cast<size_t>(num_bin_aligned_);
+          }
+        } else {
+          data_ptr = hist_buf_ptr +
+            static_cast<size_t>(num_bin_aligned_) * (block_id - 1) * 2;
+        }
+        std::memset(reinterpret_cast<void*>(data_ptr), 0, num_bin_ * kInt16HistBufferEntrySize);
+        if (USE_INDICES) {
+          if (ORDERED) {
+            sub_multi_val_bin->ConstructHistogramOrderedInt16(data_indices, start, end,
+                                                              gradients, hessians,
+                                                              reinterpret_cast<hist_t*>(data_ptr));
+          } else {
+            sub_multi_val_bin->ConstructHistogramInt16(data_indices, start, end, gradients,
+                                                       hessians,
+                                                       reinterpret_cast<hist_t*>(data_ptr));
+          }
+        } else {
+          sub_multi_val_bin->ConstructHistogramInt16(start, end, gradients, hessians,
+                                                     reinterpret_cast<hist_t*>(data_ptr));
+        }
+      } else {
+        int32_t* data_ptr = reinterpret_cast<int32_t*>(origin_hist_data_);
+        int32_t* hist_buf_ptr = reinterpret_cast<int32_t*>(hist_buf->data());
+        if (block_id == 0) {
+          if (is_use_subcol_) {
+            data_ptr = hist_buf_ptr + hist_buf->size() - 2 * static_cast<size_t>(num_bin_aligned_);
+          }
+        } else {
+          data_ptr = hist_buf_ptr +
+            static_cast<size_t>(num_bin_aligned_) * (block_id - 1) * 2;
+        }
+        std::memset(reinterpret_cast<void*>(data_ptr), 0, num_bin_ * kInt32HistBufferEntrySize);
+        if (USE_INDICES) {
+          if (ORDERED) {
+            sub_multi_val_bin->ConstructHistogramOrderedInt32(data_indices, start, end,
+                                                              gradients, hessians,
+                                                              reinterpret_cast<hist_t*>(data_ptr));
+          } else {
+            sub_multi_val_bin->ConstructHistogramInt32(data_indices, start, end, gradients,
+                                                       hessians,
+                                                       reinterpret_cast<hist_t*>(data_ptr));
+          }
+        } else {
+          sub_multi_val_bin->ConstructHistogramInt32(start, end, gradients, hessians,
+                                                     reinterpret_cast<hist_t*>(data_ptr));
+        }
+      }
+    } else {
+      hist_t* data_ptr = origin_hist_data_;
+      if (block_id == 0) {
+        if (is_use_subcol_) {
+          data_ptr = hist_buf->data() + hist_buf->size() - 2 * static_cast<size_t>(num_bin_aligned_);
+        }
+      } else {
+        data_ptr = hist_buf->data() +
+          static_cast<size_t>(num_bin_aligned_) * (block_id - 1) * 2;
+      }
+      std::memset(reinterpret_cast<void*>(data_ptr), 0, num_bin_ * kHistBufferEntrySize);
+      if (USE_INDICES) {
+        if (ORDERED) {
+          sub_multi_val_bin->ConstructHistogramOrdered(data_indices, start, end,
+                                                  gradients, hessians, data_ptr);
+        } else {
+          sub_multi_val_bin->ConstructHistogram(data_indices, start, end, gradients,
+                                            hessians, data_ptr);
+        }
+      } else {
+        sub_multi_val_bin->ConstructHistogram(start, end, gradients, hessians,
+                                          data_ptr);
+      }
+    }
+  }
 
-  data_size_t num_data() const override { return num_data_; }
+  void CopyMultiValBinSubset(const std::vector<int>& group_feature_start,
+    const std::vector<std::unique_ptr<FeatureGroup>>& feature_groups,
+    const std::vector<int8_t>& is_feature_used,
+    const data_size_t* bagging_use_indices,
+    data_size_t bagging_indices_cnt);
 
-  int num_bin() const override { return num_bin_; }
+  void SetUseSubrow(bool is_use_subrow) {
+    is_use_subrow_ = is_use_subrow;
+  }
 
-  double num_element_per_row() const override {
-    return estimate_element_per_row_;
+  void SetSubrowCopied(bool is_subrow_copied) {
+    is_subrow_copied_ = is_subrow_copied;
   }
 
-  const std::vector<uint32_t>& offsets() const override { return offsets_; }
 
-  void PushOneRow(int tid, data_size_t idx,
-                  const std::vector<uint32_t>& values) override {
-    const int pre_alloc_size = 50;
-    row_ptr_[idx + 1] = static_cast<INDEX_T>(values.size());
-    if (tid == 0) {
-      if (t_size_[tid] + row_ptr_[idx + 1] >
-          static_cast<INDEX_T>(data_.size())) {
-        data_.resize(t_size_[tid] + row_ptr_[idx + 1] * pre_alloc_size);
-      }
-      for (auto val : values) {
-        data_[t_size_[tid]++] = static_cast<VAL_T>(val);
-      }
+  #ifdef USE_CUDA
+  const void* GetRowWiseData(
+    uint8_t* bit_type,
+    size_t* total_size,
+    bool* is_sparse,
+    const void** out_data_ptr,
+    uint8_t* data_ptr_bit_type) const {
+    if (multi_val_bin_ == nullptr) {
+      *bit_type = 0;
+      *total_size = 0;
+      *is_sparse = false;
+      return nullptr;
     } else {
-      if (t_size_[tid] + row_ptr_[idx + 1] >
-          static_cast<INDEX_T>(t_data_[tid - 1].size())) {
-        t_data_[tid - 1].resize(t_size_[tid] +
-                                row_ptr_[idx + 1] * pre_alloc_size);
-      }
-      for (auto val : values) {
-        t_data_[tid - 1][t_size_[tid]++] = static_cast<VAL_T>(val);
-      }
+      return multi_val_bin_->GetRowWiseData(bit_type, total_size, is_sparse, out_data_ptr, data_ptr_bit_type);
     }
   }
+  #endif  // USE_CUDA
 
-  void MergeData(const INDEX_T* sizes) {
-    Common::FunctionTimer fun_time("MultiValSparseBin::MergeData", global_timer);
-    for (data_size_t i = 0; i < num_data_; ++i) {
-      row_ptr_[i + 1] += row_ptr_[i];
-    }
-    if (t_data_.size() > 0) {
-      std::vector<INDEX_T> offsets(1 + t_data_.size());
-      offsets[0] = sizes[0];
-      for (size_t tid = 0; tid < t_data_.size() - 1; ++tid) {
-        offsets[tid + 1] = offsets[tid] + sizes[tid + 1];
-      }
-      data_.resize(row_ptr_[num_data_]);
-#pragma omp parallel for schedule(static, 1)
-      for (int tid = 0; tid < static_cast<int>(t_data_.size()); ++tid) {
-        std::copy_n(t_data_[tid].data(), sizes[tid + 1],
-                    data_.data() + offsets[tid]);
-      }
-    } else {
-      data_.resize(row_ptr_[num_data_]);
-    }
-  }
+ private:
+  bool is_use_subcol_ = false;
+  bool is_use_subrow_ = false;
+  bool is_subrow_copied_ = false;
+  std::unique_ptr<MultiValBin> multi_val_bin_;
+  std::unique_ptr<MultiValBin> multi_val_bin_subset_;
+  std::vector<uint32_t> hist_move_src_;
+  std::vector<uint32_t> hist_move_dest_;
+  std::vector<uint32_t> hist_move_size_;
+  const std::vector<int> feature_groups_contained_;
 
-  void FinishLoad() override {
-    MergeData(t_size_.data());
-    t_size_.clear();
-    row_ptr_.shrink_to_fit();
-    data_.shrink_to_fit();
-    t_data_.clear();
-    t_data_.shrink_to_fit();
-    // update estimate_element_per_row_ by all data
-    estimate_element_per_row_ =
-        static_cast<double>(row_ptr_[num_data_]) / num_data_;
-  }
-
-  bool IsSparse() override { return true; }
-
-  template <bool USE_INDICES, bool USE_PREFETCH, bool ORDERED>
-  void ConstructHistogramInner(const data_size_t* data_indices,
-                               data_size_t start, data_size_t end,
-                               const score_t* gradients,
-                               const score_t* hessians, hist_t* out) const {
-    data_size_t i = start;
-    hist_t* grad = out;
-    hist_t* hess = out + 1;
-    const VAL_T* data_ptr = data_.data();
-    if (USE_PREFETCH) {
-      const data_size_t pf_offset = 32 / sizeof(VAL_T);
-      const data_size_t pf_end = end - pf_offset;
-
-      for (; i < pf_end; ++i) {
-        const auto idx = USE_INDICES ? data_indices[i] : i;
-        const auto pf_idx =
-            USE_INDICES ? data_indices[i + pf_offset] : i + pf_offset;
-        if (!ORDERED) {
-          PREFETCH_T0(gradients + pf_idx);
-          PREFETCH_T0(hessians + pf_idx);
-        }
-        PREFETCH_T0(row_ptr_.data() + pf_idx);
-        PREFETCH_T0(data_ptr + row_ptr_[pf_idx]);
-        const auto j_start = RowPtr(idx);
-        const auto j_end = RowPtr(idx + 1);
-        const score_t gradient = ORDERED ? gradients[i] : gradients[idx];
-        const score_t hessian = ORDERED ? hessians[i] : hessians[idx];
-        for (auto j = j_start; j < j_end; ++j) {
-          const auto ti = static_cast<uint32_t>(data_ptr[j]) << 1;
-          grad[ti] += gradient;
-          hess[ti] += hessian;
-        }
-      }
-    }
-    for (; i < end; ++i) {
-      const auto idx = USE_INDICES ? data_indices[i] : i;
-      const auto j_start = RowPtr(idx);
-      const auto j_end = RowPtr(idx + 1);
-      const score_t gradient = ORDERED ? gradients[i] : gradients[idx];
-      const score_t hessian = ORDERED ? hessians[i] : hessians[idx];
-      for (auto j = j_start; j < j_end; ++j) {
-        const auto ti = static_cast<uint32_t>(data_ptr[j]) << 1;
-        grad[ti] += gradient;
-        hess[ti] += hessian;
-      }
-    }
+  int num_threads_;
+  int num_bin_;
+  int num_bin_aligned_;
+  int n_data_block_;
+  int data_block_size_;
+  int min_block_size_;
+  int num_data_;
+  int num_grad_quant_bins_;
+
+  hist_t* origin_hist_data_;
+
+  const size_t kHistBufferEntrySize = 2 * sizeof(hist_t);
+  const size_t kInt32HistBufferEntrySize = 2 * sizeof(int32_t);
+  const size_t kInt16HistBufferEntrySize = 2 * sizeof(int16_t);
+  const size_t kInt8HistBufferEntrySize = 2 * sizeof(int8_t);
+};
+
+struct TrainingShareStates {
+  int num_threads = 0;
+  bool is_col_wise = true;
+  bool is_constant_hessian = true;
+  const data_size_t* bagging_use_indices;
+  data_size_t bagging_indices_cnt;
+
+  TrainingShareStates() {
+    multi_val_bin_wrapper_.reset(nullptr);
   }
 
-  void ConstructHistogram(const data_size_t* data_indices, data_size_t start,
-                          data_size_t end, const score_t* gradients,
-                          const score_t* hessians, hist_t* out) const override {
-    ConstructHistogramInner<true, true, false>(data_indices, start, end,
-                                               gradients, hessians, out);
-  }
-
-  void ConstructHistogram(data_size_t start, data_size_t end,
-                          const score_t* gradients, const score_t* hessians,
-                          hist_t* out) const override {
-    ConstructHistogramInner<false, false, false>(
-        nullptr, start, end, gradients, hessians, out);
-  }
-
-  void ConstructHistogramOrdered(const data_size_t* data_indices,
-                                 data_size_t start, data_size_t end,
-                                 const score_t* gradients,
-                                 const score_t* hessians,
-                                 hist_t* out) const override {
-    ConstructHistogramInner<true, true, true>(data_indices, start, end,
-                                              gradients, hessians, out);
-  }
-
-  MultiValBin* CreateLike(data_size_t num_data, int num_bin, int,
-                          double estimate_element_per_row,
-                          const std::vector<uint32_t>& /*offsets*/) const override {
-    return new MultiValSparseBin<INDEX_T, VAL_T>(num_data, num_bin,
-                                                 estimate_element_per_row);
-  }
-
-  void ReSize(data_size_t num_data, int num_bin, int,
-              double estimate_element_per_row, const std::vector<uint32_t>& /*offsets*/) override {
-    num_data_ = num_data;
-    num_bin_ = num_bin;
-    estimate_element_per_row_ = estimate_element_per_row;
-    INDEX_T estimate_num_data =
-        static_cast<INDEX_T>(estimate_element_per_row_ * 1.1 * num_data_);
-    size_t npart = 1 + t_data_.size();
-    INDEX_T avg_num_data = static_cast<INDEX_T>(estimate_num_data / npart);
-    if (static_cast<INDEX_T>(data_.size()) < avg_num_data) {
-      data_.resize(avg_num_data, 0);
-    }
-    for (size_t i = 0; i < t_data_.size(); ++i) {
-      if (static_cast<INDEX_T>(t_data_[i].size()) < avg_num_data) {
-        t_data_[i].resize(avg_num_data, 0);
-      }
-    }
-    if (num_data_ + 1 > static_cast<data_size_t>(row_ptr_.size())) {
-      row_ptr_.resize(num_data_ + 1);
-    }
+  int num_hist_total_bin() { return num_hist_total_bin_; }
+
+  const std::vector<uint32_t>& feature_hist_offsets() const { return feature_hist_offsets_; }
+
+  #ifdef USE_CUDA
+  const std::vector<uint32_t>& column_hist_offsets() const { return column_hist_offsets_; }
+  #endif  // USE_CUDA
+
+  bool IsSparseRowwise() {
+    return (multi_val_bin_wrapper_ != nullptr && multi_val_bin_wrapper_->IsSparse());
   }
 
-  template <bool SUBROW, bool SUBCOL>
-  void CopyInner(const MultiValBin* full_bin, const data_size_t* used_indices,
-                 data_size_t num_used_indices,
-                 const std::vector<uint32_t>& lower,
-                 const std::vector<uint32_t>& upper,
-                 const std::vector<uint32_t>& delta) {
-    const auto other =
-        reinterpret_cast<const MultiValSparseBin<INDEX_T, VAL_T>*>(full_bin);
-    if (SUBROW) {
-      CHECK_EQ(num_data_, num_used_indices);
-    }
-    int n_block = 1;
-    data_size_t block_size = num_data_;
-    Threading::BlockInfo<data_size_t>(static_cast<int>(t_data_.size() + 1),
-                                      num_data_, 1024, &n_block, &block_size);
-    std::vector<INDEX_T> sizes(t_data_.size() + 1, 0);
-    const int pre_alloc_size = 50;
-#pragma omp parallel for schedule(static, 1)
-    for (int tid = 0; tid < n_block; ++tid) {
-      data_size_t start = tid * block_size;
-      data_size_t end = std::min(num_data_, start + block_size);
-      auto& buf = (tid == 0) ? data_ : t_data_[tid - 1];
-      INDEX_T size = 0;
-      for (data_size_t i = start; i < end; ++i) {
-        const auto j_start =
-            SUBROW ? other->RowPtr(used_indices[i]) : other->RowPtr(i);
-        const auto j_end =
-            SUBROW ? other->RowPtr(used_indices[i] + 1) : other->RowPtr(i + 1);
-        if (size + (j_end - j_start) > static_cast<INDEX_T>(buf.size())) {
-          buf.resize(size + (j_end - j_start) * pre_alloc_size);
-        }
-        int k = 0;
-        const auto pre_size = size;
-        for (auto j = j_start; j < j_end; ++j) {
-          const auto val = other->data_[j];
-          if (SUBCOL) {
-            while (val >= upper[k]) {
-              ++k;
-            }
-            if (val >= lower[k]) {
-              buf[size++] = static_cast<VAL_T>(val - delta[k]);
-            }
-          } else {
-            buf[size++] = val;
-          }
-        }
-        row_ptr_[i + 1] = size - pre_size;
-      }
-      sizes[tid] = size;
+  void SetMultiValBin(MultiValBin* bin, data_size_t num_data,
+    const std::vector<std::unique_ptr<FeatureGroup>>& feature_groups,
+    bool dense_only, bool sparse_only, const int num_grad_quant_bins);
+
+  void CalcBinOffsets(const std::vector<std::unique_ptr<FeatureGroup>>& feature_groups,
+    std::vector<uint32_t>* offsets, bool is_col_wise);
+
+  void InitTrain(const std::vector<int>& group_feature_start,
+        const std::vector<std::unique_ptr<FeatureGroup>>& feature_groups,
+        const std::vector<int8_t>& is_feature_used) {
+    if (multi_val_bin_wrapper_ != nullptr) {
+      multi_val_bin_wrapper_->InitTrain(group_feature_start,
+        feature_groups,
+        is_feature_used,
+        bagging_use_indices,
+        bagging_indices_cnt);
     }
-    MergeData(sizes.data());
   }
 
-  void CopySubrow(const MultiValBin* full_bin, const data_size_t* used_indices,
-                  data_size_t num_used_indices) override {
-    CopyInner<true, false>(full_bin, used_indices, num_used_indices,
-                           std::vector<uint32_t>(), std::vector<uint32_t>(),
-                           std::vector<uint32_t>());
+  template <bool USE_INDICES, bool ORDERED, bool USE_QUANT_GRAD, int HIST_BITS>
+  void ConstructHistograms(const data_size_t* data_indices,
+                          data_size_t num_data,
+                          const score_t* gradients,
+                          const score_t* hessians,
+                          hist_t* hist_data) {
+    if (multi_val_bin_wrapper_ != nullptr) {
+      multi_val_bin_wrapper_->ConstructHistograms<USE_INDICES, ORDERED, USE_QUANT_GRAD, HIST_BITS>(
+        data_indices, num_data, gradients, hessians, &hist_buf_, hist_data);
+    }
   }
 
-  void CopySubcol(const MultiValBin* full_bin, const std::vector<int>&,
-                  const std::vector<uint32_t>& lower,
-                  const std::vector<uint32_t>& upper,
-                  const std::vector<uint32_t>& delta) override {
-    CopyInner<false, true>(full_bin, nullptr, num_data_, lower, upper, delta);
+  void SetUseSubrow(bool is_use_subrow) {
+    if (multi_val_bin_wrapper_ != nullptr) {
+      multi_val_bin_wrapper_->SetUseSubrow(is_use_subrow);
+    }
   }
 
-  void CopySubrowAndSubcol(const MultiValBin* full_bin,
-                           const data_size_t* used_indices,
-                           data_size_t num_used_indices,
-                           const std::vector<int>&,
-                           const std::vector<uint32_t>& lower,
-                           const std::vector<uint32_t>& upper,
-                           const std::vector<uint32_t>& delta) override {
-    CopyInner<true, true>(full_bin, used_indices, num_used_indices, lower,
-                          upper, delta);
+  void SetSubrowCopied(bool is_subrow_copied) {
+    if (multi_val_bin_wrapper_ != nullptr) {
+      multi_val_bin_wrapper_->SetSubrowCopied(is_subrow_copied);
+    }
   }
 
-  inline INDEX_T RowPtr(data_size_t idx) const { return row_ptr_[idx]; }
 
-  MultiValSparseBin<INDEX_T, VAL_T>* Clone() override;
+  #ifdef USE_CUDA
+  const void* GetRowWiseData(uint8_t* bit_type,
+    size_t* total_size,
+    bool* is_sparse,
+    const void** out_data_ptr,
+    uint8_t* data_ptr_bit_type) {
+    if (multi_val_bin_wrapper_ != nullptr) {
+      return multi_val_bin_wrapper_->GetRowWiseData(bit_type, total_size, is_sparse, out_data_ptr, data_ptr_bit_type);
+    } else {
+      *bit_type = 0;
+      *total_size = 0;
+      *is_sparse = false;
+      return nullptr;
+    }
+  }
+  #endif  // USE_CUDA
 
  private:
-  data_size_t num_data_;
-  int num_bin_;
-  double estimate_element_per_row_;
-  std::vector<VAL_T, Common::AlignmentAllocator<VAL_T, 32>> data_;
-  std::vector<INDEX_T, Common::AlignmentAllocator<INDEX_T, 32>>
-      row_ptr_;
-  std::vector<std::vector<VAL_T, Common::AlignmentAllocator<VAL_T, 32>>>
-      t_data_;
-  std::vector<INDEX_T> t_size_;
-  std::vector<uint32_t> offsets_;
-
-  MultiValSparseBin<INDEX_T, VAL_T>(
-      const MultiValSparseBin<INDEX_T, VAL_T>& other)
-      : num_data_(other.num_data_),
-        num_bin_(other.num_bin_),
-        estimate_element_per_row_(other.estimate_element_per_row_),
-        data_(other.data_),
-        row_ptr_(other.row_ptr_) {}
+  std::vector<uint32_t> feature_hist_offsets_;
+  #ifdef USE_CUDA
+  std::vector<uint32_t> column_hist_offsets_;
+  #endif  // USE_CUDA
+  int num_hist_total_bin_ = 0;
+  std::unique_ptr<MultiValBinWrapper> multi_val_bin_wrapper_;
+  std::vector<hist_t, Common::AlignmentAllocator<hist_t, kAlignedSize>> hist_buf_;
+  int num_total_bin_ = 0;
+  double num_elements_per_row_ = 0.0f;
 };
 
-template <typename INDEX_T, typename VAL_T>
-MultiValSparseBin<INDEX_T, VAL_T>* MultiValSparseBin<INDEX_T, VAL_T>::Clone() {
-  return new MultiValSparseBin<INDEX_T, VAL_T>(*this);
-}
-
 }  // namespace LightGBM
-#endif  // LIGHTGBM_IO_MULTI_VAL_SPARSE_BIN_HPP_
+
+#endif   // LightGBM_TRAIN_SHARE_STATES_H_
```

### Comparing `lightgbm-3.3.5/compile/src/io/parser.cpp` & `lightgbm-4.0.0/src/io/parser.cpp`

 * *Files 20% similar despite different names*

```diff
@@ -1,15 +1,17 @@
 /*!
  * Copyright (c) 2016 Microsoft Corporation. All rights reserved.
  * Licensed under the MIT License. See LICENSE file in the project root for license information.
  */
 #include "parser.hpp"
 
+#include <functional>
 #include <string>
 #include <algorithm>
+#include <map>
 #include <memory>
 
 namespace LightGBM {
 
 void GetStatistic(const char* str, int* comma_cnt, int* tab_cnt, int* colon_cnt) {
   *comma_cnt = 0;
   *tab_cnt = 0;
@@ -226,14 +228,38 @@
     *num_col = comma_cnt + 1;
   } else if (type == DataType::TSV) {
     *num_col = tab_cnt + 1;
   }
   return type;
 }
 
+// parser factory implementation.
+ParserFactory& ParserFactory::getInstance() {
+  static ParserFactory factory;
+  return factory;
+}
+
+void ParserFactory::Register(std::string class_name, std::function<Parser*(std::string)> m_objc) {
+  if (m_objc) {
+    object_map_.insert(
+        std::map<std::string, std::function<Parser*(std::string)>>::value_type(class_name, m_objc));
+  }
+}
+
+Parser* ParserFactory::getObject(std::string class_name, std::string config_str) {
+  std::map<std::string, std::function<Parser*(std::string)>>::const_iterator iter =
+      object_map_.find(class_name);
+  if (iter != object_map_.end()) {
+    return iter->second(config_str);
+  } else {
+    Log::Fatal("Cannot find parser class '%s', please register first or check config format.", class_name.c_str());
+    return nullptr;
+  }
+}
+
 Parser* Parser::CreateParser(const char* filename, bool header, int num_features, int label_idx, bool precise_float_parser) {
   const int n_read_line = 32;
   auto lines = ReadKLineFromFile(filename, header, n_read_line);
   int num_col = 0;
   DataType type = GetDataType(filename, header, lines, &num_col);
   if (type == DataType::INVALID) {
     Log::Fatal("Unknown format of training data. Only CSV, TSV, and LibSVM (zero-based) formatted text files are supported.");
@@ -254,8 +280,38 @@
 
   if (output_label_index < 0 && label_idx >= 0) {
     Log::Info("Data file %s doesn't contain a label column.", filename);
   }
   return ret.release();
 }
 
+Parser* Parser::CreateParser(const char* filename, bool header, int num_features, int label_idx, bool precise_float_parser, std::string parser_config_str) {
+  // customized parser add-on.
+  if (!parser_config_str.empty()) {
+    std::unique_ptr<Parser> ret;
+    std::string class_name = Common::GetFromParserConfig(parser_config_str, "className");
+    Log::Info("Custom parser class name: %s", class_name.c_str());
+    Parser* p = ParserFactory::getInstance().getObject(class_name, parser_config_str);
+    ret.reset(p);
+    return ret.release();
+  }
+  return CreateParser(filename, header, num_features, label_idx, precise_float_parser);
+}
+
+std::string Parser::GenerateParserConfigStr(const char* filename, const char* parser_config_filename, bool header, int label_idx) {
+  TextReader<data_size_t> parser_config_reader(parser_config_filename, false);
+  parser_config_reader.ReadAllLines();
+  std::string parser_config_str = parser_config_reader.JoinedLines();
+  if (!parser_config_str.empty()) {
+    // save header to parser config in case needed.
+    if (header && Common::GetFromParserConfig(parser_config_str, "header").empty()) {
+      TextReader<data_size_t> text_reader(filename, header);
+      parser_config_str = Common::SaveToParserConfig(parser_config_str, "header", text_reader.first_line());
+    }
+    // save label id to parser config in case needed.
+    if (Common::GetFromParserConfig(parser_config_str, "labelId").empty()) {
+      parser_config_str = Common::SaveToParserConfig(parser_config_str, "labelId", std::to_string(label_idx));
+    }
+  }
+  return parser_config_str;
+}
 }  // namespace LightGBM
```

### Comparing `lightgbm-3.3.5/compile/src/io/parser.hpp` & `lightgbm-4.0.0/src/io/parser.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/src/io/sparse_bin.hpp` & `lightgbm-4.0.0/src/io/sparse_bin.hpp`

 * *Files 26% similar despite different names*

```diff
@@ -77,14 +77,20 @@
   explicit SparseBin(data_size_t num_data) : num_data_(num_data) {
     int num_threads = OMP_NUM_THREADS();
     push_buffers_.resize(num_threads);
   }
 
   ~SparseBin() {}
 
+  void InitStreaming(uint32_t num_thread, int32_t omp_max_threads) override {
+    // Each external thread needs its own set of OpenMP push buffers,
+    // so allocate num_thread times the maximum number of OMP threads per external thread
+    push_buffers_.resize(omp_max_threads * num_thread);
+  };
+
   void ReSize(data_size_t num_data) override { num_data_ = num_data; }
 
   void Push(int tid, data_size_t idx, uint32_t value) override {
     auto cur_bin = static_cast<VAL_T>(value);
     if (cur_bin != 0) {
       push_buffers_[tid].emplace_back(idx, cur_bin);
     }
@@ -193,14 +199,192 @@
       grad[ti] += ordered_gradients[cur_pos];
       ++cnt[ti];
       cur_pos += deltas_[++i_delta];
     }
   }
 #undef ACC_GH
 
+  template <bool USE_HESSIAN, typename PACKED_HIST_T, typename GRAD_HIST_T, typename HESS_HIST_T, int HIST_BITS>
+  void ConstructIntHistogramInner(data_size_t start, data_size_t end,
+                          const score_t* ordered_gradients_and_hessians,
+                          hist_t* out) const {
+    data_size_t i_delta, cur_pos;
+    InitIndex(start, &i_delta, &cur_pos);
+    if (USE_HESSIAN) {
+      PACKED_HIST_T* out_ptr = reinterpret_cast<PACKED_HIST_T*>(out);
+      const int16_t* gradients_and_hessians_ptr = reinterpret_cast<const int16_t*>(ordered_gradients_and_hessians);
+      while (cur_pos < start && i_delta < num_vals_) {
+        cur_pos += deltas_[++i_delta];
+      }
+      while (cur_pos < end && i_delta < num_vals_) {
+        const VAL_T bin = vals_[i_delta];
+        const int16_t gradient_16 = gradients_and_hessians_ptr[cur_pos];
+        const PACKED_HIST_T gradient_64 = (static_cast<PACKED_HIST_T>(static_cast<int8_t>(gradient_16 >> 8)) << HIST_BITS) | (gradient_16 & 0xff);
+        out_ptr[bin] += gradient_64;
+        cur_pos += deltas_[++i_delta];
+      }
+    } else {
+      GRAD_HIST_T* grad = reinterpret_cast<GRAD_HIST_T*>(out);
+      HESS_HIST_T* cnt = reinterpret_cast<HESS_HIST_T*>(out) + 1;
+      const int8_t* gradients_and_hessians_ptr = reinterpret_cast<const int8_t*>(ordered_gradients_and_hessians);
+      while (cur_pos < start && i_delta < num_vals_) {
+        cur_pos += deltas_[++i_delta];
+      }
+      while (cur_pos < end && i_delta < num_vals_) {
+        const uint32_t ti = static_cast<uint32_t>(vals_[i_delta]) << 1;
+        grad[ti] += gradients_and_hessians_ptr[cur_pos];
+        ++cnt[ti];
+        cur_pos += deltas_[++i_delta];
+      }
+    }
+  }
+
+  template <bool USE_HESSIAN, typename PACKED_HIST_T, typename GRAD_HIST_T, typename HESS_HIST_T, int HIST_BITS>
+  void ConstructIntHistogramInner(const data_size_t* data_indices, data_size_t start,
+                          data_size_t end, const score_t* ordered_gradients_and_hessians,
+                          hist_t* out) const {
+    data_size_t i_delta, cur_pos;
+    InitIndex(data_indices[start], &i_delta, &cur_pos);
+    data_size_t i = start;
+    if (USE_HESSIAN) {
+      PACKED_HIST_T* out_ptr = reinterpret_cast<PACKED_HIST_T*>(out);
+      const int16_t* gradients_and_hessians_ptr = reinterpret_cast<const int16_t*>(ordered_gradients_and_hessians);
+      for (;;) {
+        if (cur_pos < data_indices[i]) {
+          cur_pos += deltas_[++i_delta];
+          if (i_delta >= num_vals_) {
+            break;
+          }
+        } else if (cur_pos > data_indices[i]) {
+          if (++i >= end) {
+            break;
+          }
+        } else {
+          const VAL_T bin = vals_[i_delta];
+          const int16_t gradient_16 = gradients_and_hessians_ptr[i];
+          const PACKED_HIST_T gradient_packed = (HIST_BITS == 8) ? gradient_16 :
+            (static_cast<PACKED_HIST_T>(static_cast<int8_t>(gradient_16 >> 8)) << HIST_BITS) | (gradient_16 & 0xff);
+          out_ptr[bin] += gradient_packed;
+          if (++i >= end) {
+            break;
+          }
+          cur_pos += deltas_[++i_delta];
+          if (i_delta >= num_vals_) {
+            break;
+          }
+        }
+      }
+    } else {
+      GRAD_HIST_T* grad = reinterpret_cast<GRAD_HIST_T*>(out);
+      HESS_HIST_T* cnt = reinterpret_cast<HESS_HIST_T*>(out) + 1;
+      const int8_t* gradients_and_hessians_ptr = reinterpret_cast<const int8_t*>(ordered_gradients_and_hessians);
+      for (;;) {
+        if (cur_pos < data_indices[i]) {
+          cur_pos += deltas_[++i_delta];
+          if (i_delta >= num_vals_) {
+            break;
+          }
+        } else if (cur_pos > data_indices[i]) {
+          if (++i >= end) {
+            break;
+          }
+        } else {
+          const uint32_t ti = static_cast<uint32_t>(vals_[i_delta]) << 1;
+          grad[ti] += gradients_and_hessians_ptr[i << 1];
+          ++cnt[ti];
+          if (++i >= end) {
+            break;
+          }
+          cur_pos += deltas_[++i_delta];
+          if (i_delta >= num_vals_) {
+            break;
+          }
+        }
+      }
+    }
+  }
+
+  void ConstructHistogramInt32(const data_size_t* data_indices, data_size_t start,
+                          data_size_t end, const score_t* ordered_gradients,
+                          const score_t* /*ordered_hessians*/,
+                          hist_t* out) const override {
+    ConstructIntHistogramInner<true, int64_t, int32_t, uint32_t, 32>(data_indices, start, end, ordered_gradients, out);
+  }
+
+  void ConstructHistogramInt32(data_size_t start, data_size_t end,
+                          const score_t* ordered_gradients,
+                          const score_t* /*ordered_hessians*/,
+                          hist_t* out) const override {
+    ConstructIntHistogramInner<true, int64_t, int32_t, uint32_t, 32>(start, end, ordered_gradients, out);
+  }
+
+  void ConstructHistogramInt32(const data_size_t* data_indices, data_size_t start,
+                          data_size_t end, const score_t* ordered_gradients,
+                          hist_t* out) const override {
+    ConstructIntHistogramInner<false, int64_t, int32_t, uint32_t, 32>(data_indices, start, end, ordered_gradients, out);
+  }
+
+  void ConstructHistogramInt32(data_size_t start, data_size_t end,
+                          const score_t* ordered_gradients,
+                          hist_t* out) const override {
+    ConstructIntHistogramInner<false, int64_t, int32_t, uint32_t, 32>(start, end, ordered_gradients, out);
+  }
+
+  void ConstructHistogramInt16(const data_size_t* data_indices, data_size_t start,
+                          data_size_t end, const score_t* ordered_gradients,
+                          const score_t* /*ordered_hessians*/,
+                          hist_t* out) const override {
+    ConstructIntHistogramInner<true, int32_t, int16_t, uint16_t, 16>(data_indices, start, end, ordered_gradients, out);
+  }
+
+  void ConstructHistogramInt16(data_size_t start, data_size_t end,
+                          const score_t* ordered_gradients,
+                          const score_t* /*ordered_hessians*/,
+                          hist_t* out) const override {
+    ConstructIntHistogramInner<true, int32_t, int16_t, uint16_t, 16>(start, end, ordered_gradients, out);
+  }
+
+  void ConstructHistogramInt16(const data_size_t* data_indices, data_size_t start,
+                          data_size_t end, const score_t* ordered_gradients,
+                          hist_t* out) const override {
+    ConstructIntHistogramInner<false, int32_t, int16_t, uint16_t, 16>(data_indices, start, end, ordered_gradients, out);
+  }
+
+  void ConstructHistogramInt16(data_size_t start, data_size_t end,
+                          const score_t* ordered_gradients,
+                          hist_t* out) const override {
+    ConstructIntHistogramInner<false, int32_t, int16_t, uint16_t, 16>(start, end, ordered_gradients, out);
+  }
+
+  void ConstructHistogramInt8(const data_size_t* data_indices, data_size_t start,
+                          data_size_t end, const score_t* ordered_gradients,
+                          const score_t* /*ordered_hessians*/,
+                          hist_t* out) const override {
+    ConstructIntHistogramInner<true, int16_t, uint8_t, uint8_t, 8>(data_indices, start, end, ordered_gradients, out);
+  }
+
+  void ConstructHistogramInt8(data_size_t start, data_size_t end,
+                          const score_t* ordered_gradients,
+                          const score_t* /*ordered_hessians*/,
+                          hist_t* out) const override {
+    ConstructIntHistogramInner<true, int16_t, uint8_t, uint8_t, 8>(start, end, ordered_gradients, out);
+  }
+
+  void ConstructHistogramInt8(const data_size_t* data_indices, data_size_t start,
+                          data_size_t end, const score_t* ordered_gradients,
+                          hist_t* out) const override {
+    ConstructIntHistogramInner<false, int16_t, uint8_t, uint8_t, 8>(data_indices, start, end, ordered_gradients, out);
+  }
+
+  void ConstructHistogramInt8(data_size_t start, data_size_t end,
+                          const score_t* ordered_gradients,
+                          hist_t* out) const override {
+    ConstructIntHistogramInner<false, int16_t, uint8_t, uint8_t, 8>(start, end, ordered_gradients, out);
+  }
+
   inline void NextNonzeroFast(data_size_t* i_delta,
                               data_size_t* cur_pos) const {
     *cur_pos += deltas_[++(*i_delta)];
     if (*i_delta >= num_vals_) {
       *cur_pos = num_data_;
     }
   }
@@ -498,15 +682,15 @@
     while (next_threshold < num_data_) {
       fast_index_.emplace_back(num_vals_ - 1, cur_pos);
       next_threshold += pow2_mod_size;
     }
     fast_index_.shrink_to_fit();
   }
 
-  void SaveBinaryToFile(const VirtualFileWriter* writer) const override {
+  void SaveBinaryToFile(BinaryWriter* writer) const override {
     writer->AlignedWrite(&num_vals_, sizeof(num_vals_));
     writer->AlignedWrite(deltas_.data(), sizeof(uint8_t) * (num_vals_ + 1));
     writer->AlignedWrite(vals_.data(), sizeof(VAL_T) * num_vals_);
   }
 
   size_t SizesInByte() const override {
     return VirtualFileWriter::AlignedSize(sizeof(num_vals_)) +
@@ -616,14 +800,18 @@
       *cur_pos = fast_pair.second;
     } else {
       *i_delta = -1;
       *cur_pos = 0;
     }
   }
 
+  const void* GetColWiseData(uint8_t* bit_type, bool* is_sparse, std::vector<BinIterator*>* bin_iterator, const int num_threads) const override;
+
+  const void* GetColWiseData(uint8_t* bit_type, bool* is_sparse, BinIterator** bin_iterator) const override;
+
  private:
   data_size_t num_data_;
   std::vector<uint8_t, Common::AlignmentAllocator<uint8_t, kAlignedSize>>
       deltas_;
   std::vector<VAL_T, Common::AlignmentAllocator<VAL_T, kAlignedSize>> vals_;
   data_size_t num_vals_;
   std::vector<std::vector<std::pair<data_size_t, VAL_T>>> push_buffers_;
@@ -661,8 +849,9 @@
 template <typename VAL_T>
 BinIterator* SparseBin<VAL_T>::GetIterator(uint32_t min_bin, uint32_t max_bin,
                                            uint32_t most_freq_bin) const {
   return new SparseBinIterator<VAL_T>(this, min_bin, max_bin, most_freq_bin);
 }
 
 }  // namespace LightGBM
+
 #endif  // LightGBM_IO_SPARSE_BIN_HPP_
```

### Comparing `lightgbm-3.3.5/compile/src/io/train_share_states.cpp` & `lightgbm-4.0.0/src/io/train_share_states.cpp`

 * *Files 25% similar despite different names*

```diff
@@ -5,24 +5,25 @@
  */
 
 #include <LightGBM/train_share_states.h>
 
 namespace LightGBM {
 
 MultiValBinWrapper::MultiValBinWrapper(MultiValBin* bin, data_size_t num_data,
-  const std::vector<int>& feature_groups_contained):
+  const std::vector<int>& feature_groups_contained, const int num_grad_quant_bins):
     feature_groups_contained_(feature_groups_contained) {
   num_threads_ = OMP_NUM_THREADS();
   num_data_ = num_data;
   multi_val_bin_.reset(bin);
   if (bin == nullptr) {
     return;
   }
   num_bin_ = bin->num_bin();
   num_bin_aligned_ = (num_bin_ + kAlignedSize - 1) / kAlignedSize * kAlignedSize;
+  num_grad_quant_bins_ = num_grad_quant_bins;
 }
 
 void MultiValBinWrapper::InitTrain(const std::vector<int>& group_feature_start,
   const std::vector<std::unique_ptr<FeatureGroup>>& feature_groups,
   const std::vector<int8_t>& is_feature_used,
   const data_size_t* bagging_use_indices,
   data_size_t bagging_indices_cnt) {
@@ -41,51 +42,169 @@
     auto num_element_per_row = cur_multi_val_bin->num_element_per_row();
     min_block_size_ = std::min<int>(static_cast<int>(0.3f * num_bin_ /
       (num_element_per_row + kZeroThreshold)) + 1, 1024);
     min_block_size_ = std::max<int>(min_block_size_, 32);
   }
 }
 
+template <bool USE_QUANT_GRAD, int HIST_BITS, int INNER_HIST_BITS>
 void MultiValBinWrapper::HistMove(const std::vector<hist_t,
   Common::AlignmentAllocator<hist_t, kAlignedSize>>& hist_buf) {
-  if (!is_use_subcol_) {
+  if (!is_use_subcol_ && INNER_HIST_BITS != 8) {
     return;
   }
-  const hist_t* src = hist_buf.data() + hist_buf.size() -
-    2 * static_cast<size_t>(num_bin_aligned_);
-  #pragma omp parallel for schedule(static)
-  for (int i = 0; i < static_cast<int>(hist_move_src_.size()); ++i) {
-    std::copy_n(src + hist_move_src_[i], hist_move_size_[i],
-                origin_hist_data_ + hist_move_dest_[i]);
+  if (USE_QUANT_GRAD) {
+    if (HIST_BITS == 32) {
+      const int64_t* src = reinterpret_cast<const int64_t*>(hist_buf.data()) + hist_buf.size() / 2 -
+        static_cast<size_t>(num_bin_aligned_);
+      #pragma omp parallel for schedule(static)
+      for (int i = 0; i < static_cast<int>(hist_move_src_.size()); ++i) {
+        std::copy_n(src + hist_move_src_[i] / 2, hist_move_size_[i] / 2,
+                    reinterpret_cast<int64_t*>(origin_hist_data_) + hist_move_dest_[i] / 2);
+      }
+    } else if (HIST_BITS == 16) {
+      const int32_t* src = reinterpret_cast<const int32_t*>(hist_buf.data()) + hist_buf.size() / 2 -
+        static_cast<size_t>(num_bin_aligned_);
+      if (is_use_subcol_) {
+        #pragma omp parallel for schedule(static)
+        for (int i = 0; i < static_cast<int>(hist_move_src_.size()); ++i) {
+          std::copy_n(src + hist_move_src_[i] / 2, hist_move_size_[i] / 2,
+                      reinterpret_cast<int32_t*>(origin_hist_data_) + hist_move_dest_[i] / 2);
+        }
+      } else {
+        int32_t* orig_ptr = reinterpret_cast<int32_t*>(origin_hist_data_);
+        #pragma omp parallel for schedule(static)
+        for (int i = 0; i < num_bin_; ++i) {
+          orig_ptr[i] = src[i];
+        }
+      }
+    }
+  } else {
+    const hist_t* src = hist_buf.data() + hist_buf.size() -
+      2 * static_cast<size_t>(num_bin_aligned_);
+    #pragma omp parallel for schedule(static)
+    for (int i = 0; i < static_cast<int>(hist_move_src_.size()); ++i) {
+      std::copy_n(src + hist_move_src_[i], hist_move_size_[i],
+                  origin_hist_data_ + hist_move_dest_[i]);
+    }
   }
 }
 
+template void MultiValBinWrapper::HistMove<false, 0, 0>(const std::vector<hist_t,
+  Common::AlignmentAllocator<hist_t, kAlignedSize>>& hist_buf);
+
+template void MultiValBinWrapper::HistMove<false, 0, 8>(const std::vector<hist_t,
+  Common::AlignmentAllocator<hist_t, kAlignedSize>>& hist_buf);
+
+template void MultiValBinWrapper::HistMove<true, 16, 8>(const std::vector<hist_t,
+  Common::AlignmentAllocator<hist_t, kAlignedSize>>& hist_buf);
+
+template void MultiValBinWrapper::HistMove<true, 16, 16>(const std::vector<hist_t,
+  Common::AlignmentAllocator<hist_t, kAlignedSize>>& hist_buf);
+
+template void MultiValBinWrapper::HistMove<true, 32, 8>(const std::vector<hist_t,
+  Common::AlignmentAllocator<hist_t, kAlignedSize>>& hist_buf);
+
+template void MultiValBinWrapper::HistMove<true, 32, 32>(const std::vector<hist_t,
+  Common::AlignmentAllocator<hist_t, kAlignedSize>>& hist_buf);
+
+template <bool USE_QUANT_GRAD, int HIST_BITS, int INNER_HIST_BITS>
 void MultiValBinWrapper::HistMerge(std::vector<hist_t,
   Common::AlignmentAllocator<hist_t, kAlignedSize>>* hist_buf) {
   int n_bin_block = 1;
   int bin_block_size = num_bin_;
   Threading::BlockInfo<data_size_t>(num_threads_, num_bin_, 512, &n_bin_block,
                                   &bin_block_size);
-  hist_t* dst = origin_hist_data_;
-  if (is_use_subcol_) {
-    dst = hist_buf->data() + hist_buf->size() - 2 * static_cast<size_t>(num_bin_aligned_);
-  }
-  #pragma omp parallel for schedule(static, 1) num_threads(num_threads_)
-  for (int t = 0; t < n_bin_block; ++t) {
-    const int start = t * bin_block_size;
-    const int end = std::min(start + bin_block_size, num_bin_);
-    for (int tid = 1; tid < n_data_block_; ++tid) {
-      auto src_ptr = hist_buf->data() + static_cast<size_t>(num_bin_aligned_) * 2 * (tid - 1);
-      for (int i = start * 2; i < end * 2; ++i) {
-        dst[i] += src_ptr[i];
+  if (USE_QUANT_GRAD) {
+    if (HIST_BITS == 32) {
+      int64_t* dst = reinterpret_cast<int64_t*>(origin_hist_data_);
+      if (is_use_subcol_) {
+        dst = reinterpret_cast<int64_t*>(hist_buf->data()) + hist_buf->size() / 2 - static_cast<size_t>(num_bin_aligned_);
+      }
+      #pragma omp parallel for schedule(static, 1) num_threads(num_threads_)
+      for (int t = 0; t < n_bin_block; ++t) {
+        const int start = t * bin_block_size;
+        const int end = std::min(start + bin_block_size, num_bin_);
+        for (int tid = 1; tid < n_data_block_; ++tid) {
+          auto src_ptr = reinterpret_cast<const int64_t*>(hist_buf->data()) + static_cast<size_t>(num_bin_aligned_) * (tid - 1);
+          for (int i = start; i < end; ++i) {
+            dst[i] += src_ptr[i];
+          }
+        }
+      }
+    } else if (HIST_BITS == 16 && INNER_HIST_BITS == 16) {
+      int32_t* dst = reinterpret_cast<int32_t*>(origin_hist_data_);
+      if (is_use_subcol_) {
+        dst = reinterpret_cast<int32_t*>(hist_buf->data()) + hist_buf->size() / 2 - static_cast<size_t>(num_bin_aligned_);
+      }
+      #pragma omp parallel for schedule(static, 1) num_threads(num_threads_)
+      for (int t = 0; t < n_bin_block; ++t) {
+        const int start = t * bin_block_size;
+        const int end = std::min(start + bin_block_size, num_bin_);
+        for (int tid = 1; tid < n_data_block_; ++tid) {
+          auto src_ptr = reinterpret_cast<const int32_t*>(hist_buf->data()) + static_cast<size_t>(num_bin_aligned_) * (tid - 1);
+          for (int i = start; i < end; ++i) {
+            dst[i] += src_ptr[i];
+          }
+        }
+      }
+    } else if (HIST_BITS == 16 && INNER_HIST_BITS == 8) {
+      int32_t* dst = reinterpret_cast<int32_t*>(hist_buf->data()) + hist_buf->size() / 2 - static_cast<size_t>(num_bin_aligned_);
+      std::memset(reinterpret_cast<void*>(dst), 0, num_bin_ * kInt16HistBufferEntrySize);
+      #pragma omp parallel for schedule(static, 1) num_threads(num_threads_)
+      for (int t = 0; t < n_bin_block; ++t) {
+        const int start = t * bin_block_size;
+        const int end = std::min(start + bin_block_size, num_bin_);
+        for (int tid = 0; tid < n_data_block_; ++tid) {
+          auto src_ptr = reinterpret_cast<const int16_t*>(hist_buf->data()) + static_cast<size_t>(num_bin_aligned_) * tid;
+          for (int i = start; i < end; ++i) {
+            const int16_t packed_hist = src_ptr[i];
+            const int32_t packed_hist_int32 = (static_cast<int32_t>(static_cast<int8_t>(packed_hist >> 8)) << 16) | static_cast<int32_t>(packed_hist & 0x00ff);
+            dst[i] += packed_hist_int32;
+          }
+        }
+      }
+    }
+  } else {
+    hist_t* dst = origin_hist_data_;
+    if (is_use_subcol_) {
+      dst = hist_buf->data() + hist_buf->size() - 2 * static_cast<size_t>(num_bin_aligned_);
+    }
+    #pragma omp parallel for schedule(static, 1) num_threads(num_threads_)
+    for (int t = 0; t < n_bin_block; ++t) {
+      const int start = t * bin_block_size;
+      const int end = std::min(start + bin_block_size, num_bin_);
+      for (int tid = 1; tid < n_data_block_; ++tid) {
+        auto src_ptr = hist_buf->data() + static_cast<size_t>(num_bin_aligned_) * 2 * (tid - 1);
+        for (int i = start * 2; i < end * 2; ++i) {
+          dst[i] += src_ptr[i];
+        }
       }
     }
   }
 }
 
+template void MultiValBinWrapper::HistMerge<false, 0, 0>(std::vector<hist_t,
+  Common::AlignmentAllocator<hist_t, kAlignedSize>>* hist_buf);
+
+template void MultiValBinWrapper::HistMerge<false, 0, 8>(std::vector<hist_t,
+  Common::AlignmentAllocator<hist_t, kAlignedSize>>* hist_buf);
+
+template void MultiValBinWrapper::HistMerge<true, 16, 8>(std::vector<hist_t,
+  Common::AlignmentAllocator<hist_t, kAlignedSize>>* hist_buf);
+
+template void MultiValBinWrapper::HistMerge<true, 16, 16>(std::vector<hist_t,
+  Common::AlignmentAllocator<hist_t, kAlignedSize>>* hist_buf);
+
+template void MultiValBinWrapper::HistMerge<true, 32, 8>(std::vector<hist_t,
+  Common::AlignmentAllocator<hist_t, kAlignedSize>>* hist_buf);
+
+template void MultiValBinWrapper::HistMerge<true, 32, 32>(std::vector<hist_t,
+  Common::AlignmentAllocator<hist_t, kAlignedSize>>* hist_buf);
+
 void MultiValBinWrapper::ResizeHistBuf(std::vector<hist_t,
   Common::AlignmentAllocator<hist_t, kAlignedSize>>* hist_buf,
   MultiValBin* sub_multi_val_bin,
   hist_t* origin_hist_data) {
   num_bin_ = sub_multi_val_bin->num_bin();
   num_bin_aligned_ = (num_bin_ + kAlignedSize - 1) / kAlignedSize * kAlignedSize;
   origin_hist_data_ = origin_hist_data;
@@ -378,19 +497,22 @@
         }
       }
       offsets->push_back(cur_num_bin);
       feature_hist_offsets_.push_back(hist_cur_num_bin);
     }
     num_hist_total_bin_ = static_cast<int>(feature_hist_offsets_.back());
   }
+  #ifdef USE_CUDA
+  column_hist_offsets_ = *offsets;
+  #endif  // USE_CUDA
 }
 
 void TrainingShareStates::SetMultiValBin(MultiValBin* bin, data_size_t num_data,
   const std::vector<std::unique_ptr<FeatureGroup>>& feature_groups,
-  bool dense_only, bool sparse_only) {
+  bool dense_only, bool sparse_only, const int num_grad_quant_bins) {
   num_threads = OMP_NUM_THREADS();
   if (bin == nullptr) {
     return;
   }
   std::vector<int> feature_groups_contained;
   for (int group = 0; group < static_cast<int>(feature_groups.size()); ++group) {
     const auto& feature_group = feature_groups[group];
@@ -401,11 +523,11 @@
     } else if (!sparse_only) {
       feature_groups_contained.push_back(group);
     }
   }
   num_total_bin_ += bin->num_bin();
   num_elements_per_row_ += bin->num_element_per_row();
   multi_val_bin_wrapper_.reset(new MultiValBinWrapper(
-    bin, num_data, feature_groups_contained));
+    bin, num_data, feature_groups_contained, num_grad_quant_bins));
 }
 
 }  // namespace LightGBM
```

### Comparing `lightgbm-3.3.5/compile/src/io/tree.cpp` & `lightgbm-4.0.0/src/io/tree.cpp`

 * *Files 4% similar despite different names*

```diff
@@ -49,14 +49,17 @@
   is_linear_ = is_linear;
   if (is_linear_) {
     leaf_coeff_.resize(max_leaves_);
     leaf_const_ = std::vector<double>(max_leaves_, 0);
     leaf_features_.resize(max_leaves_);
     leaf_features_inner_.resize(max_leaves_);
   }
+  #ifdef USE_CUDA
+  is_cuda_tree_ = false;
+  #endif  // USE_CUDA
 }
 
 int Tree::Split(int leaf, int feature, int real_feature, uint32_t threshold_bin,
                 double threshold_double, double left_value, double right_value,
                 int left_cnt, int right_cnt, double left_weight, double right_weight, float gain,
                 MissingType missing_type, bool default_left) {
   Split(leaf, feature, real_feature, left_value, right_value, left_cnt, right_cnt, left_weight, right_weight, gain);
@@ -333,19 +336,15 @@
   return lower_bound;
 }
 
 std::string Tree::ToString() const {
   std::stringstream str_buf;
   Common::C_stringstream(str_buf);
 
-  #if ((defined(sun) || defined(__sun)) && (defined(__SVR4) || defined(__svr4__)))
-  using CommonLegacy::ArrayToString;  // Slower & unsafe regarding locale.
-  #else
   using CommonC::ArrayToString;
-  #endif
 
   str_buf << "num_leaves=" << num_leaves_ << '\n';
   str_buf << "num_cat=" << num_cat_ << '\n';
   str_buf << "split_feature="
     << ArrayToString(split_feature_, num_leaves_ - 1) << '\n';
   str_buf << "split_gain="
     << ArrayToString(split_gain_, num_leaves_ - 1) << '\n';
@@ -517,45 +516,43 @@
   }
   return str_buf.str();
 }
 
 std::string Tree::NumericalDecisionIfElse(int node) const {
   std::stringstream str_buf;
   Common::C_stringstream(str_buf);
+  str_buf << std::setprecision(std::numeric_limits<double>::digits10 + 2);
   uint8_t missing_type = GetMissingType(decision_type_[node]);
   bool default_left = GetDecisionType(decision_type_[node], kDefaultLeftMask);
-  if (missing_type == MissingType::None
-      || (missing_type == MissingType::Zero && default_left && kZeroThreshold < threshold_[node])) {
-    str_buf << "if (fval <= " << threshold_[node] << ") {";
-  } else if (missing_type == MissingType::Zero) {
+  if (missing_type != MissingType::NaN) {
+    str_buf << "if (std::isnan(fval)) fval = 0.0;";
+  }
+  if (missing_type == MissingType::Zero) {
     if (default_left) {
-      str_buf << "if (fval <= " << threshold_[node] << " || Tree::IsZero(fval)" << " || std::isnan(fval)) {";
+      str_buf << "if (Tree::IsZero(fval)) {";
     } else {
-      str_buf << "if (fval <= " << threshold_[node] << " && !Tree::IsZero(fval)" << " && !std::isnan(fval)) {";
+      str_buf << "if (!Tree::IsZero(fval)) {";
     }
-  } else {
+  } else if (missing_type == MissingType::NaN) {
     if (default_left) {
-      str_buf << "if (fval <= " << threshold_[node] << " || std::isnan(fval)) {";
+      str_buf << "if (std::isnan(fval)) {";
     } else {
-      str_buf << "if (fval <= " << threshold_[node] << " && !std::isnan(fval)) {";
+      str_buf << "if (!std::isnan(fval)) {";
     }
+  } else {
+    str_buf << "if (fval <= " << threshold_[node] << ") {";
   }
   return str_buf.str();
 }
 
 std::string Tree::CategoricalDecisionIfElse(int node) const {
-  uint8_t missing_type = GetMissingType(decision_type_[node]);
   std::stringstream str_buf;
   Common::C_stringstream(str_buf);
-  if (missing_type == MissingType::NaN) {
-    str_buf << "if (std::isnan(fval)) { int_fval = -1; } else { int_fval = static_cast<int>(fval); }";
-  } else {
-    str_buf << "if (std::isnan(fval)) { int_fval = 0; } else { int_fval = static_cast<int>(fval); }";
-  }
   int cat_idx = static_cast<int>(threshold_[node]);
+  str_buf << "if (std::isnan(fval)) { int_fval = -1; } else { int_fval = static_cast<int>(fval); }";
   str_buf << "if (int_fval >= 0 && int_fval < 32 * (";
   str_buf << cat_boundaries_[cat_idx + 1] - cat_boundaries_[cat_idx];
   str_buf << ") && (((cat_threshold[" << cat_boundaries_[cat_idx];
   str_buf << " + int_fval / 32] >> (int_fval & 31)) & 1))) {";
   return str_buf.str();
 }
 
@@ -730,14 +727,18 @@
     int is_linear_int;
     Common::Atoi(key_vals["is_linear"].c_str(), &is_linear_int);
     is_linear_ = static_cast<bool>(is_linear_int);
   } else {
     is_linear_ = false;
   }
 
+  #ifdef USE_CUDA
+  is_cuda_tree_ = false;
+  #endif  // USE_CUDA
+
   if ((num_leaves_ <= 1) && !is_linear_) {
     return;
   }
 
   if (key_vals.count("left_child")) {
     left_child_ = CommonC::StringToArrayFast<int>(key_vals["left_child"], num_leaves_ - 1);
   } else {
```

### Comparing `lightgbm-3.3.5/compile/src/main.cpp` & `lightgbm-4.0.0/src/main.cpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/src/metric/binary_metric.hpp` & `lightgbm-4.0.0/src/metric/binary_metric.hpp`

 * *Files 0% similar despite different names*

```diff
@@ -92,15 +92,15 @@
         }
       }
     }
     double loss = sum_loss / sum_weights_;
     return std::vector<double>(1, loss);
   }
 
- private:
+ protected:
   /*! \brief Number of data */
   data_size_t num_data_;
   /*! \brief Pointer of label */
   const label_t* label_;
   /*! \brief Pointer of weighs */
   const label_t* weights_;
   /*! \brief Sum weights */
```

### Comparing `lightgbm-3.3.5/compile/src/metric/dcg_calculator.cpp` & `lightgbm-4.0.0/src/metric/dcg_calculator.cpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/src/metric/map_metric.hpp` & `lightgbm-4.0.0/src/metric/map_metric.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/src/metric/multiclass_metric.hpp` & `lightgbm-4.0.0/src/metric/multiclass_metric.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/src/metric/rank_metric.hpp` & `lightgbm-4.0.0/src/metric/rank_metric.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/src/metric/regression_metric.hpp` & `lightgbm-4.0.0/src/metric/regression_metric.hpp`

 * *Files 1% similar despite different names*

```diff
@@ -97,15 +97,15 @@
   inline static double AverageLoss(double sum_loss, double sum_weights) {
     return sum_loss / sum_weights;
   }
 
   inline static void CheckLabel(label_t) {
   }
 
- private:
+ protected:
   /*! \brief Number of data */
   data_size_t num_data_;
   /*! \brief Pointer of label */
   const label_t* label_;
   /*! \brief Pointer of weighs */
   const label_t* weights_;
   /*! \brief Sum weights */
```

### Comparing `lightgbm-3.3.5/compile/src/metric/xentropy_metric.hpp` & `lightgbm-4.0.0/src/metric/xentropy_metric.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/src/network/linker_topo.cpp` & `lightgbm-4.0.0/src/network/linker_topo.cpp`

 * *Files 2% similar despite different names*

```diff
@@ -151,24 +151,24 @@
     const int cur_group_idx = node_to_group[rank];
     for (int i = 0; i < k; ++i) {
       const int dir = ((cur_group_idx / distance[i]) % 2 == 0) ? 1 : -1;
       const int next_node_idx = group_to_node[(cur_group_idx + dir * distance[i])];
       rec_map.ranks[i] = next_node_idx;
       // get receive block information
       const int recv_block_start = cur_group_idx / distance[i];
-      rec_map.recv_block_start[i] = group_block_start[recv_block_start * distance[i]];
+      rec_map.recv_block_start[i] = group_block_start[static_cast<size_t>(recv_block_start) * distance[i]];
       int recv_block_len = 0;
       // accumulate block len
       for (int j = 0; j < distance[i]; ++j) {
         recv_block_len += group_block_len[recv_block_start * distance[i] + j];
       }
       rec_map.recv_block_len[i] = recv_block_len;
       // get send block information
       const int send_block_start = (cur_group_idx + dir * distance[i]) / distance[i];
-      rec_map.send_block_start[i] = group_block_start[send_block_start * distance[i]];
+      rec_map.send_block_start[i] = group_block_start[static_cast<size_t>(send_block_start) * distance[i]];
       int send_block_len = 0;
       // accumulate block len
       for (int j = 0; j < distance[i]; ++j) {
         send_block_len += group_block_len[send_block_start * distance[i] + j];
       }
       rec_map.send_block_len[i] = send_block_len;
     }
```

### Comparing `lightgbm-3.3.5/compile/src/network/linkers.h` & `lightgbm-4.0.0/src/network/linkers.h`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/src/network/linkers_mpi.cpp` & `lightgbm-4.0.0/src/network/linkers_mpi.cpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/src/network/linkers_socket.cpp` & `lightgbm-4.0.0/src/network/linkers_socket.cpp`

 * *Files 0% similar despite different names*

```diff
@@ -114,15 +114,15 @@
     client_ports_.push_back(atoi(str_after_split[1].c_str()));
   }
   if (client_ips_.empty()) {
     Log::Fatal("Cannot find any ip and port.\n"
                "Please check machine_list_filename or machines parameter");
   }
   if (client_ips_.size() != static_cast<size_t>(num_machines_)) {
-    Log::Warning("World size is larger than the machine_list size, change world size to %d", client_ips_.size());
+    Log::Warning("World size is larger than the machine_list size, change world size to %zu", client_ips_.size());
     num_machines_ = static_cast<int>(client_ips_.size());
   }
 }
 
 void Linkers::TryBind(int port) {
   Log::Info("Trying to bind port %d...", port);
   if (listener_->Bind(port)) {
```

### Comparing `lightgbm-3.3.5/compile/src/network/network.cpp` & `lightgbm-4.0.0/src/network/network.cpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/src/network/socket_wrapper.hpp` & `lightgbm-4.0.0/src/network/socket_wrapper.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -31,20 +31,15 @@
 #include <netinet/in.h>
 #include <netinet/tcp.h>
 #include <sys/ioctl.h>
 #include <sys/socket.h>
 #include <sys/types.h>
 #include <unistd.h>
 
-// ifaddrs.h is not available on Solaris 10
-#if (defined(sun) || defined(__sun)) && (defined(__SVR4) || defined(__svr4__))
-  #include "ifaddrs_patch.h"
-#else
-  #include <ifaddrs.h>
-#endif
+#include <ifaddrs.h>
 
 #endif  // defined(_WIN32)
 
 #ifdef _MSC_VER
 #pragma comment(lib, "Ws2_32.lib")
 #pragma comment(lib, "IPHLPAPI.lib")
 #endif
@@ -249,15 +244,15 @@
     if (bind(sockfd_, reinterpret_cast<const sockaddr*>(&local_addr), sizeof(sockaddr_in)) == 0) {
       return true;
     }
     return false;
   }
 
   inline bool Connect(const char *url, int port) {
-    sockaddr_in  server_addr = GetAddress(url, port);
+    sockaddr_in server_addr = GetAddress(url, port);
     if (connect(sockfd_, reinterpret_cast<const sockaddr*>(&server_addr), sizeof(sockaddr_in)) == 0) {
       return true;
     }
     return false;
   }
 
   inline void Listen(int backlog = 128) {
```

### Comparing `lightgbm-3.3.5/compile/src/objective/binary_objective.hpp` & `lightgbm-4.0.0/src/objective/binary_objective.hpp`

 * *Files 1% similar despite different names*

```diff
@@ -30,15 +30,15 @@
     is_unbalance_ = config.is_unbalance;
     scale_pos_weight_ = static_cast<double>(config.scale_pos_weight);
     if (is_unbalance_ && std::fabs(scale_pos_weight_ - 1.0f) > 1e-6) {
       Log::Fatal("Cannot set is_unbalance and scale_pos_weight at the same time");
     }
     is_pos_ = is_pos;
     if (is_pos_ == nullptr) {
-      is_pos_ = [](label_t label) {return label > 0; };
+      is_pos_ = [](label_t label) { return label > 0; };
     }
   }
 
   explicit BinaryLogloss(const std::vector<std::string>& strs)
       : deterministic_(false) {
     sigmoid_ = -1;
     for (auto str : strs) {
@@ -125,15 +125,15 @@
         // get label and label weights
         const int is_pos = is_pos_(label_[i]);
         const int label = label_val_[is_pos];
         const double label_weight = label_weights_[is_pos];
         // calculate gradients and hessians
         const double response = -label * sigmoid_ / (1.0f + std::exp(label * sigmoid_ * score[i]));
         const double abs_response = fabs(response);
-        gradients[i] = static_cast<score_t>(response * label_weight  * weights_[i]);
+        gradients[i] = static_cast<score_t>(response * label_weight * weights_[i]);
         hessians[i] = static_cast<score_t>(abs_response * (sigmoid_ - abs_response) * label_weight * weights_[i]);
       }
     }
   }
 
   // implement custom average to boost from (if enabled among options)
   double BoostFromScore(int) const override {
@@ -156,15 +156,15 @@
       suml = Network::GlobalSyncUpBySum(suml);
       sumw = Network::GlobalSyncUpBySum(sumw);
     }
     double pavg = suml / sumw;
     pavg = std::min(pavg, 1.0 - kEpsilon);
     pavg = std::max<double>(pavg, kEpsilon);
     double initscore = std::log(pavg / (1.0f - pavg)) / sigmoid_;
-    Log::Info("[%s:%s]: pavg=%f -> initscore=%f",  GetName(), __func__, pavg, initscore);
+    Log::Info("[%s:%s]: pavg=%f -> initscore=%f", GetName(), __func__, pavg, initscore);
     return initscore;
   }
 
   bool ClassNeedTrain(int /*class_id*/) const override {
     return need_train_;
   }
 
@@ -185,15 +185,15 @@
 
   bool SkipEmptyClass() const override { return true; }
 
   bool NeedAccuratePrediction() const override { return false; }
 
   data_size_t NumPositiveData() const override { return num_pos_data_; }
 
- private:
+ protected:
   /*! \brief Number of data */
   data_size_t num_data_;
   /*! \brief Number of positive samples */
   data_size_t num_pos_data_;
   /*! \brief Pointer of label */
   const label_t* label_;
   /*! \brief True if using unbalance training */
```

### Comparing `lightgbm-3.3.5/compile/src/objective/multiclass_objective.hpp` & `lightgbm-4.0.0/src/objective/multiclass_objective.hpp`

 * *Files 5% similar despite different names*

```diff
@@ -117,15 +117,15 @@
         Common::Softmax(&rec);
         for (int k = 0; k < num_class_; ++k) {
           auto p = rec[k];
           size_t idx = static_cast<size_t>(num_data_) * k + i;
           if (label_int_[i] == k) {
             gradients[idx] = static_cast<score_t>((p - 1.0f) * weights_[i]);
           } else {
-            gradients[idx] = static_cast<score_t>((p) * weights_[i]);
+            gradients[idx] = static_cast<score_t>(p * weights_[i]);
           }
           hessians[idx] = static_cast<score_t>((factor_ * p * (1.0f - p))* weights_[i]);
         }
       }
     }
   }
 
@@ -161,15 +161,15 @@
         || std::fabs(class_init_probs_[class_id]) >= 1.0 - kEpsilon) {
       return false;
     } else {
       return true;
     }
   }
 
- private:
+ protected:
   double factor_;
   /*! \brief Number of data */
   data_size_t num_data_;
   /*! \brief Number of classes */
   int num_class_;
   /*! \brief Pointer of label */
   const label_t* label_;
@@ -262,15 +262,15 @@
     return binary_loss_[class_id]->BoostFromScore(0);
   }
 
   bool ClassNeedTrain(int class_id) const override {
     return binary_loss_[class_id]->ClassNeedTrain(0);
   }
 
- private:
+ protected:
   /*! \brief Number of data */
   data_size_t num_data_;
   /*! \brief Number of classes */
   int num_class_;
   std::vector<std::unique_ptr<BinaryLogloss>> binary_loss_;
   double sigmoid_;
 };
```

### Comparing `lightgbm-3.3.5/compile/src/objective/objective_function.cpp` & `lightgbm-4.0.0/src/objective/objective_function.cpp`

 * *Files 26% similar despite different names*

```diff
@@ -6,52 +6,107 @@
 
 #include "binary_objective.hpp"
 #include "multiclass_objective.hpp"
 #include "rank_objective.hpp"
 #include "regression_objective.hpp"
 #include "xentropy_objective.hpp"
 
+#include "cuda/cuda_binary_objective.hpp"
+#include "cuda/cuda_multiclass_objective.hpp"
+#include "cuda/cuda_rank_objective.hpp"
+#include "cuda/cuda_regression_objective.hpp"
+
 namespace LightGBM {
 
 ObjectiveFunction* ObjectiveFunction::CreateObjectiveFunction(const std::string& type, const Config& config) {
-  if (type == std::string("regression")) {
-    return new RegressionL2loss(config);
-  } else if (type == std::string("regression_l1")) {
-    return new RegressionL1loss(config);
-  } else if (type == std::string("quantile")) {
-    return new RegressionQuantileloss(config);
-  } else if (type == std::string("huber")) {
-    return new RegressionHuberLoss(config);
-  } else if (type == std::string("fair")) {
-    return new RegressionFairLoss(config);
-  } else if (type == std::string("poisson")) {
-    return new RegressionPoissonLoss(config);
-  } else if (type == std::string("binary")) {
-    return new BinaryLogloss(config);
-  } else if (type == std::string("lambdarank")) {
-    return new LambdarankNDCG(config);
-  } else if (type == std::string("rank_xendcg")) {
-    return new RankXENDCG(config);
-  } else if (type == std::string("multiclass")) {
-    return new MulticlassSoftmax(config);
-  } else if (type == std::string("multiclassova")) {
-    return new MulticlassOVA(config);
-  } else if (type == std::string("cross_entropy")) {
-    return new CrossEntropy(config);
-  } else if (type == std::string("cross_entropy_lambda")) {
-    return new CrossEntropyLambda(config);
-  } else if (type == std::string("mape")) {
-    return new RegressionMAPELOSS(config);
-  } else if (type == std::string("gamma")) {
-    return new RegressionGammaLoss(config);
-  } else if (type == std::string("tweedie")) {
-    return new RegressionTweedieLoss(config);
-  } else if (type == std::string("custom")) {
-    return nullptr;
+  #ifdef USE_CUDA
+  if (config.device_type == std::string("cuda") &&
+      config.data_sample_strategy != std::string("goss") &&
+      config.boosting != std::string("rf")) {
+    if (type == std::string("regression")) {
+      return new CUDARegressionL2loss(config);
+    } else if (type == std::string("regression_l1")) {
+      return new CUDARegressionL1loss(config);
+    } else if (type == std::string("quantile")) {
+      return new CUDARegressionQuantileloss(config);
+    } else if (type == std::string("huber")) {
+      return new CUDARegressionHuberLoss(config);
+    } else if (type == std::string("fair")) {
+      return new CUDARegressionFairLoss(config);
+    } else if (type == std::string("poisson")) {
+      return new CUDARegressionPoissonLoss(config);
+    } else if (type == std::string("binary")) {
+      return new CUDABinaryLogloss(config);
+    } else if (type == std::string("lambdarank")) {
+      return new CUDALambdarankNDCG(config);
+    } else if (type == std::string("rank_xendcg")) {
+      return new CUDARankXENDCG(config);
+    } else if (type == std::string("multiclass")) {
+      return new CUDAMulticlassSoftmax(config);
+    } else if (type == std::string("multiclassova")) {
+      return new CUDAMulticlassOVA(config);
+    } else if (type == std::string("cross_entropy")) {
+      Log::Warning("Objective cross_entropy is not implemented in cuda version. Fall back to boosting on CPU.");
+      return new CrossEntropy(config);
+    } else if (type == std::string("cross_entropy_lambda")) {
+      Log::Warning("Objective cross_entropy_lambda is not implemented in cuda version. Fall back to boosting on CPU.");
+      return new CrossEntropyLambda(config);
+    } else if (type == std::string("mape")) {
+      Log::Warning("Objective mape is not implemented in cuda version. Fall back to boosting on CPU.");
+      return new RegressionMAPELOSS(config);
+    } else if (type == std::string("gamma")) {
+      Log::Warning("Objective gamma is not implemented in cuda version. Fall back to boosting on CPU.");
+      return new RegressionGammaLoss(config);
+    } else if (type == std::string("tweedie")) {
+      Log::Warning("Objective tweedie is not implemented in cuda version. Fall back to boosting on CPU.");
+      return new RegressionTweedieLoss(config);
+    } else if (type == std::string("custom")) {
+      Log::Warning("Using customized objective with cuda. This requires copying gradients from CPU to GPU, which can be slow.");
+      return nullptr;
+    }
+  } else {
+  #endif  // USE_CUDA
+    if (type == std::string("regression")) {
+      return new RegressionL2loss(config);
+    } else if (type == std::string("regression_l1")) {
+      return new RegressionL1loss(config);
+    } else if (type == std::string("quantile")) {
+      return new RegressionQuantileloss(config);
+    } else if (type == std::string("huber")) {
+      return new RegressionHuberLoss(config);
+    } else if (type == std::string("fair")) {
+      return new RegressionFairLoss(config);
+    } else if (type == std::string("poisson")) {
+      return new RegressionPoissonLoss(config);
+    } else if (type == std::string("binary")) {
+      return new BinaryLogloss(config);
+    } else if (type == std::string("lambdarank")) {
+      return new LambdarankNDCG(config);
+    } else if (type == std::string("rank_xendcg")) {
+      return new RankXENDCG(config);
+    } else if (type == std::string("multiclass")) {
+      return new MulticlassSoftmax(config);
+    } else if (type == std::string("multiclassova")) {
+      return new MulticlassOVA(config);
+    } else if (type == std::string("cross_entropy")) {
+      return new CrossEntropy(config);
+    } else if (type == std::string("cross_entropy_lambda")) {
+      return new CrossEntropyLambda(config);
+    } else if (type == std::string("mape")) {
+      return new RegressionMAPELOSS(config);
+    } else if (type == std::string("gamma")) {
+      return new RegressionGammaLoss(config);
+    } else if (type == std::string("tweedie")) {
+      return new RegressionTweedieLoss(config);
+    } else if (type == std::string("custom")) {
+      return nullptr;
+    }
+  #ifdef USE_CUDA
   }
+  #endif  // USE_CUDA
   Log::Fatal("Unknown objective type name: %s", type.c_str());
   return nullptr;
 }
 
 ObjectiveFunction* ObjectiveFunction::CreateObjectiveFunction(const std::string& str) {
   auto strs = Common::Split(str.c_str(), ' ');
   auto type = strs[0];
```

### Comparing `lightgbm-3.3.5/compile/src/objective/rank_objective.hpp` & `lightgbm-4.0.0/src/objective/rank_objective.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -251,15 +251,15 @@
       const double score = i / sigmoid_table_idx_factor_ + min_sigmoid_input_;
       sigmoid_table_[i] = 1.0f / (1.0f + std::exp(score * sigmoid_));
     }
   }
 
   const char* GetName() const override { return "lambdarank"; }
 
- private:
+ protected:
   /*! \brief Sigmoid param */
   double sigmoid_;
   /*! \brief Normalize the lambdas or not */
   bool norm_;
   /*! \brief Truncation position for max DCG */
   int truncation_level_;
   /*! \brief Cache inverse max DCG, speed up calculation */
@@ -354,13 +354,13 @@
 
   double Phi(const label_t l, double g) const {
     return Common::Pow(2, static_cast<int>(l)) - g;
   }
 
   const char* GetName() const override { return "rank_xendcg"; }
 
- private:
+ protected:
   mutable std::vector<Random> rands_;
 };
 
 }  // namespace LightGBM
 #endif  // LightGBM_OBJECTIVE_RANK_OBJECTIVE_HPP_
```

### Comparing `lightgbm-3.3.5/compile/src/objective/regression_objective.hpp` & `lightgbm-4.0.0/src/objective/regression_objective.hpp`

 * *Files 3% similar despite different names*

```diff
@@ -20,15 +20,15 @@
     if (cnt_data <= 1) {                                                  \
       return data_reader(0);                                              \
     }                                                                     \
     std::vector<T> ref_data(cnt_data);                                    \
     for (data_size_t i = 0; i < cnt_data; ++i) {                          \
       ref_data[i] = data_reader(i);                                       \
     }                                                                     \
-    const double float_pos = (1.0f - alpha) * cnt_data;                   \
+    const double float_pos = static_cast<double>(1.0 - alpha) * cnt_data; \
     const data_size_t pos = static_cast<data_size_t>(float_pos);          \
     if (pos < 1) {                                                        \
       return ref_data[ArrayArgs<T>::ArgMax(ref_data)];                    \
     } else if (pos >= cnt_data) {                                         \
       return ref_data[ArrayArgs<T>::ArgMin(ref_data)];                    \
     } else {                                                              \
       const double bias = float_pos - pos;                                \
@@ -131,15 +131,15 @@
       for (data_size_t i = 0; i < num_data_; ++i) {
         gradients[i] = static_cast<score_t>(score[i] - label_[i]);
         hessians[i] = 1.0f;
       }
     } else {
       #pragma omp parallel for schedule(static)
       for (data_size_t i = 0; i < num_data_; ++i) {
-        gradients[i] = static_cast<score_t>((score[i] - label_[i]) * weights_[i]);
+        gradients[i] = static_cast<score_t>(static_cast<score_t>((score[i] - label_[i])) * weights_[i]);
         hessians[i] = static_cast<score_t>(weights_[i]);
       }
     }
   }
 
   const char* GetName() const override {
     return "regression";
@@ -172,15 +172,15 @@
 
   double BoostFromScore(int) const override {
     double suml = 0.0f;
     double sumw = 0.0f;
     if (weights_ != nullptr) {
       #pragma omp parallel for schedule(static) reduction(+:suml, sumw) if (!deterministic_)
       for (data_size_t i = 0; i < num_data_; ++i) {
-        suml += label_[i] * weights_[i];
+        suml += static_cast<double>(label_[i]) * weights_[i];
         sumw += weights_[i];
       }
     } else {
       sumw = static_cast<double>(num_data_);
       #pragma omp parallel for schedule(static) reduction(+:suml) if (!deterministic_)
       for (data_size_t i = 0; i < num_data_; ++i) {
         suml += label_[i];
@@ -326,26 +326,26 @@
     } else {
       #pragma omp parallel for schedule(static)
       for (data_size_t i = 0; i < num_data_; ++i) {
         const double diff = score[i] - label_[i];
         if (std::abs(diff) <= alpha_) {
           gradients[i] = static_cast<score_t>(diff * weights_[i]);
         } else {
-          gradients[i] = static_cast<score_t>(Common::Sign(diff) * weights_[i] * alpha_);
+          gradients[i] = static_cast<score_t>(Common::Sign(diff) * static_cast<score_t>(weights_[i]) * alpha_);
         }
         hessians[i] = static_cast<score_t>(weights_[i]);
       }
     }
   }
 
   const char* GetName() const override {
     return "huber";
   }
 
- private:
+ protected:
   /*! \brief delta for Huber loss */
   double alpha_;
 };
 
 
 // http://research.microsoft.com/en-us/um/people/zhang/INRIA/Publis/Tutorial-Estim/node24.html
 class RegressionFairLoss: public RegressionL2loss {
@@ -382,15 +382,15 @@
     return "fair";
   }
 
   bool IsConstantHessian() const override {
     return false;
   }
 
- private:
+ protected:
   /*! \brief c for Fair loss */
   double c_;
 };
 
 
 /*!
 * \brief Objective function for Poisson regression
@@ -435,25 +435,28 @@
    *
    * And the output is exp(f); so the associated metric get s=exp(f)
    * so that its loss = s - label * log(s); a little awkward maybe.
    *
    */
   void GetGradients(const double* score, score_t* gradients,
                     score_t* hessians) const override {
+    double exp_max_delta_step_ = std::exp(max_delta_step_);
     if (weights_ == nullptr) {
       #pragma omp parallel for schedule(static)
       for (data_size_t i = 0; i < num_data_; ++i) {
-        gradients[i] = static_cast<score_t>(std::exp(score[i]) - label_[i]);
-        hessians[i] = static_cast<score_t>(std::exp(score[i] + max_delta_step_));
+        double exp_score = std::exp(score[i]);
+        gradients[i] = static_cast<score_t>(exp_score - label_[i]);
+        hessians[i] = static_cast<score_t>(exp_score * exp_max_delta_step_);
       }
     } else {
       #pragma omp parallel for schedule(static)
       for (data_size_t i = 0; i < num_data_; ++i) {
-        gradients[i] = static_cast<score_t>((std::exp(score[i]) - label_[i]) * weights_[i]);
-        hessians[i] = static_cast<score_t>(std::exp(score[i] + max_delta_step_) * weights_[i]);
+        double exp_score = std::exp(score[i]);
+        gradients[i] = static_cast<score_t>((exp_score - label_[i]) * weights_[i]);
+        hessians[i] = static_cast<score_t>(exp_score * exp_max_delta_step_ * weights_[i]);
       }
     }
   }
 
   void ConvertOutput(const double* input, double* output) const override {
     output[0] = std::exp(input[0]);
   }
@@ -466,15 +469,15 @@
     return Common::SafeLog(RegressionL2loss::BoostFromScore(0));
   }
 
   bool IsConstantHessian() const override {
     return false;
   }
 
- private:
+ protected:
   /*! \brief used to safeguard optimization */
   double max_delta_step_;
 };
 
 class RegressionQuantileloss : public RegressionL2loss {
  public:
   explicit RegressionQuantileloss(const Config& config): RegressionL2loss(config) {
@@ -561,15 +564,15 @@
         WeightedPercentileFun(double, data_reader, weight_reader, num_data_in_leaf, alpha_);
         #undef data_reader
         #undef weight_reader
       }
     }
   }
 
- private:
+ protected:
   score_t alpha_;
 };
 
 
 /*!
 * \brief MAPE Regression Loss
 */
@@ -685,22 +688,24 @@
   ~RegressionGammaLoss() {}
 
   void GetGradients(const double* score, score_t* gradients,
                     score_t* hessians) const override {
     if (weights_ == nullptr) {
       #pragma omp parallel for schedule(static)
       for (data_size_t i = 0; i < num_data_; ++i) {
-        gradients[i] = static_cast<score_t>(1.0 - label_[i] * std::exp(-score[i]));
-        hessians[i] = static_cast<score_t>(label_[i] * std::exp(-score[i]));
+        double exp_score = std::exp(-score[i]);
+        gradients[i] = static_cast<score_t>(1.0 - label_[i] * exp_score);
+        hessians[i] = static_cast<score_t>(label_[i] * exp_score);
       }
     } else {
       #pragma omp parallel for schedule(static)
       for (data_size_t i = 0; i < num_data_; ++i) {
-        gradients[i] = static_cast<score_t>((1.0 - label_[i] * std::exp(-score[i])) * weights_[i]);
-        hessians[i] = static_cast<score_t>(label_[i] * std::exp(-score[i]) * weights_[i]);
+        double exp_score = std::exp(-score[i]);
+        gradients[i] = static_cast<score_t>((1.0 - label_[i] * exp_score) * weights_[i]);
+        hessians[i] = static_cast<score_t>(label_[i] * exp_score * weights_[i]);
       }
     }
   }
 
   const char* GetName() const override {
     return "gamma";
   }
@@ -721,24 +726,28 @@
   ~RegressionTweedieLoss() {}
 
   void GetGradients(const double* score, score_t* gradients,
                     score_t* hessians) const override {
     if (weights_ == nullptr) {
       #pragma omp parallel for schedule(static)
       for (data_size_t i = 0; i < num_data_; ++i) {
-        gradients[i] = static_cast<score_t>(-label_[i] * std::exp((1 - rho_) * score[i]) + std::exp((2 - rho_) * score[i]));
-        hessians[i] = static_cast<score_t>(-label_[i] * (1 - rho_) * std::exp((1 - rho_) * score[i]) +
-          (2 - rho_) * std::exp((2 - rho_) * score[i]));
+        double exp_1_score = std::exp((1 - rho_) * score[i]);
+        double exp_2_score = std::exp((2 - rho_) * score[i]);
+        gradients[i] = static_cast<score_t>(-label_[i] * exp_1_score + exp_2_score);
+        hessians[i] = static_cast<score_t>(-label_[i] * (1 - rho_) * exp_1_score +
+          (2 - rho_) * exp_2_score);
       }
     } else {
       #pragma omp parallel for schedule(static)
       for (data_size_t i = 0; i < num_data_; ++i) {
-        gradients[i] = static_cast<score_t>((-label_[i] * std::exp((1 - rho_) * score[i]) + std::exp((2 - rho_) * score[i])) * weights_[i]);
-        hessians[i] = static_cast<score_t>((-label_[i] * (1 - rho_) * std::exp((1 - rho_) * score[i]) +
-          (2 - rho_) * std::exp((2 - rho_) * score[i])) * weights_[i]);
+        double exp_1_score = std::exp((1 - rho_) * score[i]);
+        double exp_2_score = std::exp((2 - rho_) * score[i]);
+        gradients[i] = static_cast<score_t>((-label_[i] * exp_1_score + exp_2_score) * weights_[i]);
+        hessians[i] = static_cast<score_t>((-label_[i] * (1 - rho_) * exp_1_score +
+          (2 - rho_) * exp_2_score) * weights_[i]);
       }
     }
   }
 
   const char* GetName() const override {
     return "tweedie";
   }
```

### Comparing `lightgbm-3.3.5/compile/src/objective/xentropy_objective.hpp` & `lightgbm-4.0.0/src/objective/xentropy_objective.hpp`

 * *Files 2% similar despite different names*

```diff
@@ -113,15 +113,15 @@
   double BoostFromScore(int) const override {
     double suml = 0.0f;
     double sumw = 0.0f;
     if (weights_ != nullptr) {
       #pragma omp parallel for schedule(static) reduction(+:suml, sumw) if (!deterministic_)
 
       for (data_size_t i = 0; i < num_data_; ++i) {
-        suml += label_[i] * weights_[i];
+        suml += static_cast<double>(label_[i]) * weights_[i];
         sumw += weights_[i];
       }
     } else {
       sumw = static_cast<double>(num_data_);
       #pragma omp parallel for schedule(static) reduction(+:suml) if (!deterministic_)
 
       for (data_size_t i = 0; i < num_data_; ++i) {
@@ -243,15 +243,15 @@
   double BoostFromScore(int) const override {
     double suml = 0.0f;
     double sumw = 0.0f;
     if (weights_ != nullptr) {
       #pragma omp parallel for schedule(static) reduction(+:suml, sumw) if (!deterministic_)
 
       for (data_size_t i = 0; i < num_data_; ++i) {
-        suml += label_[i] * weights_[i];
+        suml += static_cast<double>(label_[i]) * weights_[i];
         sumw += weights_[i];
       }
     } else {
       sumw = static_cast<double>(num_data_);
       #pragma omp parallel for schedule(static) reduction(+:suml) if (!deterministic_)
 
       for (data_size_t i = 0; i < num_data_; ++i) {
```

### Comparing `lightgbm-3.3.5/compile/src/treelearner/col_sampler.hpp` & `lightgbm-4.0.0/src/treelearner/col_sampler.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/src/treelearner/cost_effective_gradient_boosting.hpp` & `lightgbm-4.0.0/src/treelearner/cost_effective_gradient_boosting.hpp`

 * *Files 4% similar despite different names*

```diff
@@ -6,14 +6,15 @@
 #ifndef LIGHTGBM_TREELEARNER_COST_EFFECTIVE_GRADIENT_BOOSTING_HPP_
 #define LIGHTGBM_TREELEARNER_COST_EFFECTIVE_GRADIENT_BOOSTING_HPP_
 
 #include <LightGBM/config.h>
 #include <LightGBM/dataset.h>
 #include <LightGBM/utils/common.h>
 #include <LightGBM/utils/log.h>
+#include <LightGBM/utils/threading.h>
 
 #include <vector>
 
 #include "data_partition.hpp"
 #include "serial_tree_learner.h"
 #include "split_info.hpp"
 
@@ -28,14 +29,15 @@
         config->cegb_penalty_feature_coupled.empty() &&
         config->cegb_penalty_feature_lazy.empty()) {
       return false;
     } else {
       return true;
     }
   }
+
   void Init() {
     auto train_data = tree_learner_->train_data_;
     if (!init_) {
       splits_per_leaf_.resize(
           static_cast<size_t>(tree_learner_->config_->num_leaves) *
           train_data->num_features());
       is_feature_used_in_split_.clear();
@@ -59,15 +61,26 @@
       if (!init_) {
         feature_used_in_data_ = Common::EmptyBitset(train_data->num_features() *
                                                     tree_learner_->num_data_);
       }
     }
     init_ = true;
   }
-  double DetlaGain(int feature_index, int real_fidx, int leaf_index,
+
+  void BeforeTrain() {
+    // clear the splits in splits_per_leaf_
+    Threading::For<size_t>(0, splits_per_leaf_.size(), 1024,
+      [this] (int /*thread_index*/, size_t start, size_t end) {
+      for (size_t i = start; i < end; ++i) {
+        splits_per_leaf_[i].Reset();
+      }
+    });
+  }
+
+  double DeltaGain(int feature_index, int real_fidx, int leaf_index,
                    int num_data_in_leaf, SplitInfo split_info) {
     auto config = tree_learner_->config_;
     double delta =
         config->cegb_tradeoff * config->cegb_penalty_split * num_data_in_leaf;
     if (!config->cegb_penalty_feature_coupled.empty() &&
         !is_feature_used_in_split_[feature_index]) {
       delta += config->cegb_tradeoff *
@@ -78,14 +91,15 @@
                CalculateOndemandCosts(feature_index, real_fidx, leaf_index);
     }
     splits_per_leaf_[static_cast<size_t>(leaf_index) *
                          tree_learner_->train_data_->num_features() +
                      feature_index] = split_info;
     return delta;
   }
+
   void UpdateLeafBestSplits(Tree* tree, int best_leaf,
                             const SplitInfo* best_split_info,
                             std::vector<SplitInfo>* best_split_per_leaf) {
     auto config = tree_learner_->config_;
     auto train_data = tree_learner_->train_data_;
     const int inner_feature_index =
         train_data->InnerFeatureIndex(best_split_info->feature);
```

### Comparing `lightgbm-3.3.5/compile/src/treelearner/data_partition.hpp` & `lightgbm-4.0.0/src/treelearner/data_partition.hpp`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/src/treelearner/feature_histogram.hpp` & `lightgbm-4.0.0/src/treelearner/feature_histogram.hpp`

 * *Files 23% similar despite different names*

```diff
@@ -52,37 +52,117 @@
   FeatureHistogram(const FeatureHistogram&) = delete;
 
   /*!
    * \brief Init the feature histogram
    * \param feature the feature data for this histogram
    * \param min_num_data_one_leaf minimal number of data in one leaf
    */
+  void Init(hist_t* data, int16_t* data_int16, const FeatureMetainfo* meta) {
+    meta_ = meta;
+    data_ = data;
+    data_int16_ = data_int16;
+    ResetFunc();
+  }
+
+  /*!
+   * \brief Init the feature histogram
+   * \param feature the feature data for this histogram
+   * \param min_num_data_one_leaf minimal number of data in one leaf
+   */
   void Init(hist_t* data, const FeatureMetainfo* meta) {
     meta_ = meta;
     data_ = data;
+    data_int16_ = nullptr;
     ResetFunc();
   }
 
   void ResetFunc() {
     if (meta_->bin_type == BinType::NumericalBin) {
       FuncForNumrical();
     } else {
       FuncForCategorical();
     }
   }
 
   hist_t* RawData() { return data_; }
 
+  int32_t* RawDataInt32() { return reinterpret_cast<int32_t*>(data_); }
+
+  int16_t* RawDataInt16() { return data_int16_; }
+
   /*!
    * \brief Subtract current histograms with other
    * \param other The histogram that want to subtract
    */
-  void Subtract(const FeatureHistogram& other) {
-    for (int i = 0; i < (meta_->num_bin - meta_->offset) * 2; ++i) {
-      data_[i] -= other.data_[i];
+  template <bool USE_DIST_GRAD = false,
+    typename THIS_HIST_T = hist_t, typename OTHER_HIST_T = hist_t, typename RESULT_HIST_T = hist_t,
+    int THIS_HIST_BITS = 0, int OTHER_HIST_BITS = 0, int RESULT_HIST_BITS = 0>
+  void Subtract(const FeatureHistogram& other, const int32_t* buffer = nullptr) {
+    if (USE_DIST_GRAD) {
+      const THIS_HIST_T* this_int_data = THIS_HIST_BITS == 16 ?
+        reinterpret_cast<const THIS_HIST_T*>(data_int16_) :
+        (RESULT_HIST_BITS == 16 ?
+          reinterpret_cast<const THIS_HIST_T*>(buffer) :
+          reinterpret_cast<const THIS_HIST_T*>(data_));
+      const OTHER_HIST_T* other_int_data = OTHER_HIST_BITS == 16 ?
+        reinterpret_cast<OTHER_HIST_T*>(other.data_int16_) :
+        reinterpret_cast<OTHER_HIST_T*>(other.data_);
+      RESULT_HIST_T* result_int_data = RESULT_HIST_BITS == 16 ?
+        reinterpret_cast<RESULT_HIST_T*>(data_int16_) :
+        reinterpret_cast<RESULT_HIST_T*>(data_);
+      if (THIS_HIST_BITS == 32 && OTHER_HIST_BITS == 16 && RESULT_HIST_BITS == 32) {
+        for (int i = 0; i < meta_->num_bin - meta_->offset; ++i) {
+          const int32_t other_grad_hess = static_cast<int32_t>(other_int_data[i]);
+          const int64_t this_grad_hess = this_int_data[i];
+          const int64_t other_grad_hess_int64 =
+            (static_cast<int64_t>(static_cast<int16_t>(other_grad_hess >> 16)) << 32) |
+            (static_cast<int64_t>(other_grad_hess & 0x0000ffff));
+          const int64_t result_grad_hess = this_grad_hess - other_grad_hess_int64;
+          result_int_data[i] = result_grad_hess;
+        }
+      } else if (THIS_HIST_BITS == 32 && OTHER_HIST_BITS == 16 && RESULT_HIST_BITS == 16) {
+        for (int i = 0; i < meta_->num_bin - meta_->offset; ++i) {
+          const int32_t other_grad_hess = static_cast<int32_t>(other_int_data[i]);
+          const int64_t this_grad_hess = this_int_data[i];
+          const int64_t other_grad_hess_int64 =
+            (static_cast<int64_t>(static_cast<int16_t>(other_grad_hess >> 16)) << 32) |
+            (static_cast<int64_t>(other_grad_hess & 0x0000ffff));
+          const int64_t result_grad_hess = this_grad_hess - other_grad_hess_int64;
+          const int32_t result_grad_hess_int32 =
+            (static_cast<int32_t>(result_grad_hess >> 32) << 16) |
+            static_cast<int32_t>(result_grad_hess & 0x00000000ffffffff);
+          result_int_data[i] = result_grad_hess_int32;
+        }
+      } else {
+        for (int i = 0; i < meta_->num_bin - meta_->offset; ++i) {
+          result_int_data[i] = this_int_data[i] - other_int_data[i];
+        }
+      }
+    } else {
+      for (int i = 0; i < (meta_->num_bin - meta_->offset) * 2; ++i) {
+        data_[i] -= other.data_[i];
+      }
+    }
+  }
+
+  void CopyToBuffer(int32_t* buffer) {
+    const int64_t* data_ptr = reinterpret_cast<const int64_t*>(data_);
+    int64_t* buffer_ptr = reinterpret_cast<int64_t*>(buffer);
+    for (int i = 0; i < meta_->num_bin - meta_->offset; ++i) {
+      buffer_ptr[i] = data_ptr[i];
+    }
+  }
+
+  void CopyFromInt16ToInt32(char* buffer) {
+    const int32_t* int16_data = reinterpret_cast<const int32_t*>(RawDataInt16());
+    int64_t* int32_data = reinterpret_cast<int64_t*>(buffer);
+    for (int i = 0; i < meta_->num_bin - meta_->offset; ++i) {
+      const int32_t int16_val = int16_data[i];
+      int32_data[i] = (static_cast<int64_t>(static_cast<int16_t>(int16_val >> 16)) << 32) |
+        static_cast<int64_t>(int16_val & 0x0000ffff);
     }
   }
 
   void FindBestThreshold(double sum_gradient, double sum_hessian,
                          data_size_t num_data,
                          const FeatureConstraint* constraints,
                          double parent_output,
@@ -90,16 +170,31 @@
     output->default_left = true;
     output->gain = kMinScore;
     find_best_threshold_fun_(sum_gradient, sum_hessian + 2 * kEpsilon, num_data,
                              constraints, parent_output, output);
     output->gain *= meta_->penalty;
   }
 
+  void FindBestThresholdInt(int64_t sum_gradient_and_hessian,
+                            double grad_scale, double hess_scale,
+                            const uint8_t num_bits_bin,
+                            const uint8_t num_bits_acc,
+                            data_size_t num_data,
+                            const FeatureConstraint* constraints,
+                            double parent_output,
+                            SplitInfo* output) {
+    output->default_left = true;
+    output->gain = kMinScore;
+    int_find_best_threshold_fun_(sum_gradient_and_hessian, grad_scale, hess_scale, num_bits_bin, num_bits_acc, num_data,
+                             constraints, parent_output, output);
+    output->gain *= meta_->penalty;
+  }
+
   template <bool USE_RAND, bool USE_L1, bool USE_MAX_OUTPUT, bool USE_SMOOTHING>
-  double BeforeNumercal(double sum_gradient, double sum_hessian, double parent_output, data_size_t num_data,
+  double BeforeNumerical(double sum_gradient, double sum_hessian, double parent_output, data_size_t num_data,
                         SplitInfo* output, int* rand_threshold) {
     is_splittable_ = false;
     output->monotone_type = meta_->monotone_type;
 
     double gain_shift = GetLeafGain<USE_L1, USE_MAX_OUTPUT, USE_SMOOTHING>(
         sum_gradient, sum_hessian, meta_->config->lambda_l1, meta_->config->lambda_l2,
         meta_->config->max_delta_step, meta_->config->path_smooth, num_data, parent_output);
@@ -108,14 +203,35 @@
       if (meta_->num_bin - 2 > 0) {
         *rand_threshold = meta_->rand.NextInt(0, meta_->num_bin - 2);
       }
     }
     return gain_shift + meta_->config->min_gain_to_split;
   }
 
+  template <bool USE_RAND, bool USE_L1, bool USE_MAX_OUTPUT, bool USE_SMOOTHING>
+  double BeforeNumericalInt(int64_t sum_gradient_and_hessian, double grad_scale, double hess_scale, double parent_output, data_size_t num_data,
+                        SplitInfo* output, int* rand_threshold) {
+    is_splittable_ = false;
+    output->monotone_type = meta_->monotone_type;
+    const int32_t int_sum_gradient = static_cast<int32_t>(sum_gradient_and_hessian >> 32);
+    const uint32_t int_sum_hessian = static_cast<uint32_t>(sum_gradient_and_hessian & 0x00000000ffffffff);
+    const double sum_gradient = static_cast<double>(int_sum_gradient) * grad_scale;
+    const double sum_hessian = static_cast<double>(int_sum_hessian) * hess_scale;
+    double gain_shift = GetLeafGain<USE_L1, USE_MAX_OUTPUT, USE_SMOOTHING>(
+        sum_gradient, sum_hessian, meta_->config->lambda_l1, meta_->config->lambda_l2,
+        meta_->config->max_delta_step, meta_->config->path_smooth, num_data, parent_output);
+    *rand_threshold = 0;
+    if (USE_RAND) {
+      if (meta_->num_bin - 2 > 0) {
+        *rand_threshold = meta_->rand.NextInt(0, meta_->num_bin - 2);
+      }
+    }
+    return gain_shift + meta_->config->min_gain_to_split;
+  }
+
   void FuncForNumrical() {
     if (meta_->config->extra_trees) {
       if (meta_->config->monotone_constraints.empty()) {
         FuncForNumricalL1<true, false>();
       } else {
         FuncForNumricalL1<true, true>();
       }
@@ -151,73 +267,187 @@
     } else {
       FuncForNumricalL3<USE_RAND, USE_MC, USE_L1, USE_MAX_OUTPUT, false>();
     }
   }
 
   template <bool USE_RAND, bool USE_MC, bool USE_L1, bool USE_MAX_OUTPUT, bool USE_SMOOTHING>
   void FuncForNumricalL3() {
+  if (meta_->config->use_quantized_grad) {
+#define TEMPLATE_PREFIX_INT USE_RAND, USE_MC, USE_L1, USE_MAX_OUTPUT, USE_SMOOTHING
+#define LAMBDA_ARGUMENTS_INT                                         \
+  int64_t sum_gradient_and_hessian, double grad_scale, double hess_scale, const uint8_t hist_bits_bin, const uint8_t hist_bits_acc, data_size_t num_data, \
+      const FeatureConstraint* constraints, double parent_output, SplitInfo *output
+#define BEFORE_ARGUMENTS_INT sum_gradient_and_hessian, grad_scale, hess_scale, parent_output, num_data, output, &rand_threshold
+#define FUNC_ARGUMENTS_INT                                                      \
+  sum_gradient_and_hessian, grad_scale, hess_scale, num_data, constraints, min_gain_shift, \
+      output, rand_threshold, parent_output
+
+      if (meta_->num_bin > 2 && meta_->missing_type != MissingType::None) {
+        if (meta_->missing_type == MissingType::Zero) {
+          int_find_best_threshold_fun_ = [=](LAMBDA_ARGUMENTS_INT) {
+            int rand_threshold = 0;
+            double min_gain_shift =
+                BeforeNumericalInt<USE_RAND, USE_L1, USE_MAX_OUTPUT, USE_SMOOTHING>(
+                    BEFORE_ARGUMENTS_INT);
+            if (hist_bits_acc <= 16) {
+              CHECK_LE(hist_bits_bin, 16);
+              FindBestThresholdSequentiallyInt<TEMPLATE_PREFIX_INT, true, true, false, int32_t, int32_t, int16_t, int16_t, 16, 16>(
+                  FUNC_ARGUMENTS_INT);
+              FindBestThresholdSequentiallyInt<TEMPLATE_PREFIX_INT, false, true, false, int32_t, int32_t, int16_t, int16_t, 16, 16>(
+                  FUNC_ARGUMENTS_INT);
+            } else {
+              if (hist_bits_bin == 32) {
+                FindBestThresholdSequentiallyInt<TEMPLATE_PREFIX_INT, true, true, false, int64_t, int64_t, int32_t, int32_t, 32, 32>(
+                    FUNC_ARGUMENTS_INT);
+                FindBestThresholdSequentiallyInt<TEMPLATE_PREFIX_INT, false, true, false, int64_t, int64_t, int32_t, int32_t, 32, 32>(
+                    FUNC_ARGUMENTS_INT);
+              } else {
+                FindBestThresholdSequentiallyInt<TEMPLATE_PREFIX_INT, true, true, false, int32_t, int64_t, int16_t, int32_t, 16, 32>(
+                    FUNC_ARGUMENTS_INT);
+                FindBestThresholdSequentiallyInt<TEMPLATE_PREFIX_INT, false, true, false, int32_t, int64_t, int16_t, int32_t, 16, 32>(
+                    FUNC_ARGUMENTS_INT);
+              }
+            }
+          };
+        } else {
+          int_find_best_threshold_fun_ = [=](LAMBDA_ARGUMENTS_INT) {
+            int rand_threshold = 0;
+            double min_gain_shift =
+                BeforeNumericalInt<USE_RAND, USE_L1, USE_MAX_OUTPUT, USE_SMOOTHING>(
+                    BEFORE_ARGUMENTS_INT);
+            if (hist_bits_acc <= 16) {
+              CHECK_LE(hist_bits_bin, 16);
+              FindBestThresholdSequentiallyInt<TEMPLATE_PREFIX_INT, true, false, true, int32_t, int32_t, int16_t, int16_t, 16, 16>(
+                  FUNC_ARGUMENTS_INT);
+              FindBestThresholdSequentiallyInt<TEMPLATE_PREFIX_INT, false, false, true, int32_t, int32_t, int16_t, int16_t, 16, 16>(
+                  FUNC_ARGUMENTS_INT);
+            } else {
+              if (hist_bits_bin == 32) {
+                FindBestThresholdSequentiallyInt<TEMPLATE_PREFIX_INT, true, false, true, int64_t, int64_t, int32_t, int32_t, 32, 32>(
+                    FUNC_ARGUMENTS_INT);
+                FindBestThresholdSequentiallyInt<TEMPLATE_PREFIX_INT, false, false, true, int64_t, int64_t, int32_t, int32_t, 32, 32>(
+                    FUNC_ARGUMENTS_INT);
+              } else {
+                FindBestThresholdSequentiallyInt<TEMPLATE_PREFIX_INT, true, false, true, int32_t, int64_t, int16_t, int32_t, 16, 32>(
+                    FUNC_ARGUMENTS_INT);
+                FindBestThresholdSequentiallyInt<TEMPLATE_PREFIX_INT, false, false, true, int32_t, int64_t, int16_t, int32_t, 16, 32>(
+                    FUNC_ARGUMENTS_INT);
+              }
+            }
+          };
+        }
+      } else {
+        if (meta_->missing_type != MissingType::NaN) {
+          int_find_best_threshold_fun_ = [=](LAMBDA_ARGUMENTS_INT) {
+            int rand_threshold = 0;
+            double min_gain_shift =
+                BeforeNumericalInt<USE_RAND, USE_L1, USE_MAX_OUTPUT, USE_SMOOTHING>(
+                    BEFORE_ARGUMENTS_INT);
+            if (hist_bits_acc <= 16) {
+              CHECK_LE(hist_bits_bin, 16);
+              FindBestThresholdSequentiallyInt<TEMPLATE_PREFIX_INT, true, false, false, int32_t, int32_t, int16_t, int16_t, 16, 16>(
+                  FUNC_ARGUMENTS_INT);
+            } else {
+              if (hist_bits_bin == 32) {
+                FindBestThresholdSequentiallyInt<TEMPLATE_PREFIX_INT, true, false, false, int64_t, int64_t, int32_t, int32_t, 32, 32>(
+                    FUNC_ARGUMENTS_INT);
+              } else {
+                FindBestThresholdSequentiallyInt<TEMPLATE_PREFIX_INT, true, false, false, int32_t, int64_t, int16_t, int32_t, 16, 32>(
+                    FUNC_ARGUMENTS_INT);
+              }
+            }
+          };
+        } else {
+          int_find_best_threshold_fun_ = [=](LAMBDA_ARGUMENTS_INT) {
+            int rand_threshold = 0;
+            double min_gain_shift =
+                BeforeNumericalInt<USE_RAND, USE_L1, USE_MAX_OUTPUT, USE_SMOOTHING>(
+                    BEFORE_ARGUMENTS_INT);
+            if (hist_bits_acc <= 16) {
+              CHECK_LE(hist_bits_bin, 16);
+              FindBestThresholdSequentiallyInt<TEMPLATE_PREFIX_INT, true, false, false, int32_t, int32_t, int16_t, int16_t, 16, 16>(
+                  FUNC_ARGUMENTS_INT);
+            } else {
+              if (hist_bits_bin == 32) {
+                FindBestThresholdSequentiallyInt<TEMPLATE_PREFIX_INT, true, false, false, int64_t, int64_t, int32_t, int32_t, 32, 32>(
+                    FUNC_ARGUMENTS_INT);
+              } else {
+                FindBestThresholdSequentiallyInt<TEMPLATE_PREFIX_INT, true, false, false, int32_t, int64_t, int16_t, int32_t, 16, 32>(
+                    FUNC_ARGUMENTS_INT);
+              }
+            }
+            output->default_left = false;
+          };
+        }
+      }
+#undef TEMPLATE_PREFIX_INT
+#undef LAMBDA_ARGUMENTS_INT
+#undef BEFORE_ARGUMENTS_INT
+#undef FUNC_ARGURMENTS_INT
+  } else {
 #define TEMPLATE_PREFIX USE_RAND, USE_MC, USE_L1, USE_MAX_OUTPUT, USE_SMOOTHING
 #define LAMBDA_ARGUMENTS                                         \
   double sum_gradient, double sum_hessian, data_size_t num_data, \
       const FeatureConstraint* constraints, double parent_output, SplitInfo *output
 #define BEFORE_ARGUMENTS sum_gradient, sum_hessian, parent_output, num_data, output, &rand_threshold
 #define FUNC_ARGUMENTS                                                      \
   sum_gradient, sum_hessian, num_data, constraints, min_gain_shift, \
       output, rand_threshold, parent_output
 
-    if (meta_->num_bin > 2 && meta_->missing_type != MissingType::None) {
-      if (meta_->missing_type == MissingType::Zero) {
-        find_best_threshold_fun_ = [=](LAMBDA_ARGUMENTS) {
-          int rand_threshold = 0;
-          double min_gain_shift =
-              BeforeNumercal<USE_RAND, USE_L1, USE_MAX_OUTPUT, USE_SMOOTHING>(
-                  BEFORE_ARGUMENTS);
-          FindBestThresholdSequentially<TEMPLATE_PREFIX, true, true, false>(
-              FUNC_ARGUMENTS);
-          FindBestThresholdSequentially<TEMPLATE_PREFIX, false, true, false>(
-              FUNC_ARGUMENTS);
-        };
-      } else {
-        find_best_threshold_fun_ = [=](LAMBDA_ARGUMENTS) {
-          int rand_threshold = 0;
-          double min_gain_shift =
-              BeforeNumercal<USE_RAND, USE_L1, USE_MAX_OUTPUT, USE_SMOOTHING>(
-                  BEFORE_ARGUMENTS);
-          FindBestThresholdSequentially<TEMPLATE_PREFIX, true, false, true>(
-              FUNC_ARGUMENTS);
-          FindBestThresholdSequentially<TEMPLATE_PREFIX, false, false, true>(
-              FUNC_ARGUMENTS);
-        };
-      }
-    } else {
-      if (meta_->missing_type != MissingType::NaN) {
-        find_best_threshold_fun_ = [=](LAMBDA_ARGUMENTS) {
-          int rand_threshold = 0;
-          double min_gain_shift =
-              BeforeNumercal<USE_RAND, USE_L1, USE_MAX_OUTPUT, USE_SMOOTHING>(
-                  BEFORE_ARGUMENTS);
-          FindBestThresholdSequentially<TEMPLATE_PREFIX, true, false, false>(
-              FUNC_ARGUMENTS);
-        };
+      if (meta_->num_bin > 2 && meta_->missing_type != MissingType::None) {
+        if (meta_->missing_type == MissingType::Zero) {
+          find_best_threshold_fun_ = [=](LAMBDA_ARGUMENTS) {
+            int rand_threshold = 0;
+            double min_gain_shift =
+                BeforeNumerical<USE_RAND, USE_L1, USE_MAX_OUTPUT, USE_SMOOTHING>(
+                    BEFORE_ARGUMENTS);
+            FindBestThresholdSequentially<TEMPLATE_PREFIX, true, true, false>(
+                FUNC_ARGUMENTS);
+            FindBestThresholdSequentially<TEMPLATE_PREFIX, false, true, false>(
+                FUNC_ARGUMENTS);
+          };
+        } else {
+          find_best_threshold_fun_ = [=](LAMBDA_ARGUMENTS) {
+            int rand_threshold = 0;
+            double min_gain_shift =
+                BeforeNumerical<USE_RAND, USE_L1, USE_MAX_OUTPUT, USE_SMOOTHING>(
+                    BEFORE_ARGUMENTS);
+            FindBestThresholdSequentially<TEMPLATE_PREFIX, true, false, true>(
+                FUNC_ARGUMENTS);
+            FindBestThresholdSequentially<TEMPLATE_PREFIX, false, false, true>(
+                FUNC_ARGUMENTS);
+          };
+        }
       } else {
-        find_best_threshold_fun_ = [=](LAMBDA_ARGUMENTS) {
-          int rand_threshold = 0;
-          double min_gain_shift =
-              BeforeNumercal<USE_RAND, USE_L1, USE_MAX_OUTPUT, USE_SMOOTHING>(
-                  BEFORE_ARGUMENTS);
-          FindBestThresholdSequentially<TEMPLATE_PREFIX, true, false, false>(
-              FUNC_ARGUMENTS);
-          output->default_left = false;
-        };
+        if (meta_->missing_type != MissingType::NaN) {
+          find_best_threshold_fun_ = [=](LAMBDA_ARGUMENTS) {
+            int rand_threshold = 0;
+            double min_gain_shift =
+                BeforeNumerical<USE_RAND, USE_L1, USE_MAX_OUTPUT, USE_SMOOTHING>(
+                    BEFORE_ARGUMENTS);
+            FindBestThresholdSequentially<TEMPLATE_PREFIX, true, false, false>(
+                FUNC_ARGUMENTS);
+          };
+        } else {
+          find_best_threshold_fun_ = [=](LAMBDA_ARGUMENTS) {
+            int rand_threshold = 0;
+            double min_gain_shift =
+                BeforeNumerical<USE_RAND, USE_L1, USE_MAX_OUTPUT, USE_SMOOTHING>(
+                    BEFORE_ARGUMENTS);
+            FindBestThresholdSequentially<TEMPLATE_PREFIX, true, false, false>(
+                FUNC_ARGUMENTS);
+            output->default_left = false;
+          };
+        }
       }
-    }
 #undef TEMPLATE_PREFIX
 #undef LAMBDA_ARGUMENTS
 #undef BEFORE_ARGUMENTS
 #undef FUNC_ARGURMENTS
+    }
   }
 
   void FuncForCategorical() {
     if (meta_->config->extra_trees) {
       if (meta_->config->monotone_constraints.empty()) {
         FuncForCategoricalL1<true, false>();
       } else {
@@ -712,22 +942,40 @@
   /*!
    * \brief Binary size of this histogram
    */
   int SizeOfHistgram() const {
     return (meta_->num_bin - meta_->offset) * kHistEntrySize;
   }
 
+  int SizeOfInt32Histgram() const {
+    return (meta_->num_bin - meta_->offset) * kInt32HistEntrySize;
+  }
+
+  int SizeOfInt16Histgram() const {
+    return (meta_->num_bin - meta_->offset) * kInt16HistEntrySize;
+  }
+
   /*!
    * \brief Restore histogram from memory
    */
   void FromMemory(char* memory_data) {
     std::memcpy(data_, memory_data,
                 (meta_->num_bin - meta_->offset) * kHistEntrySize);
   }
 
+  void FromMemoryInt32(char* memory_data) {
+    std::memcpy(data_, memory_data,
+                (meta_->num_bin - meta_->offset) * kInt32HistEntrySize);
+  }
+
+  void FromMemoryInt16(char* memory_data) {
+    std::memcpy(data_int16_, memory_data,
+                (meta_->num_bin - meta_->offset) * kInt16HistEntrySize);
+  }
+
   /*!
    * \brief True if this histogram can be splitted
    */
   bool is_splittable() { return is_splittable_; }
 
   /*!
    * \brief Set splittable to this histogram
@@ -1078,22 +1326,320 @@
       output->right_sum_hessian =
           sum_hessian - best_sum_left_hessian - kEpsilon;
       output->gain = best_gain - min_gain_shift;
       output->default_left = REVERSE;
     }
   }
 
+  template <bool USE_RAND, bool USE_MC, bool USE_L1, bool USE_MAX_OUTPUT, bool USE_SMOOTHING,
+          bool REVERSE, bool SKIP_DEFAULT_BIN, bool NA_AS_MISSING, typename PACKED_HIST_BIN_T, typename PACKED_HIST_ACC_T,
+          typename HIST_BIN_T, typename HIST_ACC_T, int HIST_BITS_BIN, int HIST_BITS_ACC>
+  void FindBestThresholdSequentiallyInt(int64_t int_sum_gradient_and_hessian,
+                                        const double grad_scale, const double hess_scale,
+                                        data_size_t num_data,
+                                        const FeatureConstraint* constraints,
+                                        double min_gain_shift, SplitInfo* output,
+                                        int rand_threshold, double parent_output) {
+    const int8_t offset = meta_->offset;
+    PACKED_HIST_ACC_T best_sum_left_gradient_and_hessian = 0;
+    PACKED_HIST_ACC_T local_int_sum_gradient_and_hessian =
+      HIST_BITS_ACC == 16 ?
+      ((static_cast<int32_t>(int_sum_gradient_and_hessian >> 32) << 16) | static_cast<int32_t>(int_sum_gradient_and_hessian & 0x0000ffff)) :
+      int_sum_gradient_and_hessian;
+    double best_gain = kMinScore;
+    uint32_t best_threshold = static_cast<uint32_t>(meta_->num_bin);
+    const double cnt_factor = static_cast<double>(num_data) /
+      static_cast<double>(static_cast<uint32_t>(int_sum_gradient_and_hessian & 0x00000000ffffffff));
+
+    BasicConstraint best_right_constraints;
+    BasicConstraint best_left_constraints;
+    bool constraint_update_necessary =
+        USE_MC && constraints->ConstraintDifferentDependingOnThreshold();
+
+    if (USE_MC) {
+      constraints->InitCumulativeConstraints(REVERSE);
+    }
+
+    const PACKED_HIST_BIN_T* data_ptr = nullptr;
+    if (HIST_BITS_BIN == 16) {
+      data_ptr = reinterpret_cast<const PACKED_HIST_BIN_T*>(data_int16_);
+    } else {
+      data_ptr = reinterpret_cast<const PACKED_HIST_BIN_T*>(data_);
+    }
+    if (REVERSE) {
+      PACKED_HIST_ACC_T sum_right_gradient_and_hessian = 0;
+
+      int t = meta_->num_bin - 1 - offset - NA_AS_MISSING;
+      const int t_end = 1 - offset;
+
+      // from right to left, and we don't need data in bin0
+      for (; t >= t_end; --t) {
+        // need to skip default bin
+        if (SKIP_DEFAULT_BIN) {
+          if ((t + offset) == static_cast<int>(meta_->default_bin)) {
+            continue;
+          }
+        }
+        const PACKED_HIST_BIN_T grad_and_hess = data_ptr[t];
+        if (HIST_BITS_ACC != HIST_BITS_BIN) {
+          const PACKED_HIST_ACC_T grad_and_hess_acc = HIST_BITS_BIN == 16 ?
+            ((static_cast<PACKED_HIST_ACC_T>(static_cast<HIST_BIN_T>(grad_and_hess >> HIST_BITS_BIN)) << HIST_BITS_ACC) |
+            (static_cast<PACKED_HIST_ACC_T>(grad_and_hess & 0x0000ffff))) :
+            ((static_cast<PACKED_HIST_ACC_T>(static_cast<HIST_BIN_T>(grad_and_hess >> HIST_BITS_BIN)) << HIST_BITS_ACC) |
+            (static_cast<PACKED_HIST_ACC_T>(grad_and_hess & 0x00000000ffffffff)));
+          sum_right_gradient_and_hessian += grad_and_hess_acc;
+        } else {
+          sum_right_gradient_and_hessian += grad_and_hess;
+        }
+        const uint32_t int_sum_right_hessian = HIST_BITS_ACC == 16 ?
+          static_cast<uint32_t>(sum_right_gradient_and_hessian & 0x0000ffff) :
+          static_cast<uint32_t>(sum_right_gradient_and_hessian & 0x00000000ffffffff);
+        data_size_t right_count = Common::RoundInt(int_sum_right_hessian * cnt_factor);
+        double sum_right_hessian = int_sum_right_hessian * hess_scale;
+        // if data not enough, or sum hessian too small
+        if (right_count < meta_->config->min_data_in_leaf ||
+            sum_right_hessian < meta_->config->min_sum_hessian_in_leaf) {
+          continue;
+        }
+        data_size_t left_count = num_data - right_count;
+        // if data not enough
+        if (left_count < meta_->config->min_data_in_leaf) {
+          break;
+        }
+
+        const PACKED_HIST_ACC_T sum_left_gradient_and_hessian = local_int_sum_gradient_and_hessian - sum_right_gradient_and_hessian;
+        const uint32_t int_sum_left_hessian = HIST_BITS_ACC == 16 ?
+          static_cast<uint32_t>(sum_left_gradient_and_hessian & 0x0000ffff) :
+          static_cast<uint32_t>(sum_left_gradient_and_hessian & 0x00000000ffffffff);
+        double sum_left_hessian = int_sum_left_hessian * hess_scale;
+        // if sum hessian too small
+        if (sum_left_hessian < meta_->config->min_sum_hessian_in_leaf) {
+          break;
+        }
+
+        double sum_right_gradient = HIST_BITS_ACC == 16 ?
+          static_cast<double>(static_cast<int16_t>(sum_right_gradient_and_hessian >> 16)) * grad_scale :
+          static_cast<double>(static_cast<int32_t>(sum_right_gradient_and_hessian >> 32)) * grad_scale;
+        double sum_left_gradient = HIST_BITS_ACC == 16 ?
+          static_cast<double>(static_cast<int16_t>(sum_left_gradient_and_hessian >> 16)) * grad_scale :
+          static_cast<double>(static_cast<int32_t>(sum_left_gradient_and_hessian >> 32)) * grad_scale;
+        if (USE_RAND) {
+          if (t - 1 + offset != rand_threshold) {
+            continue;
+          }
+        }
+
+        if (USE_MC && constraint_update_necessary) {
+          constraints->Update(t + offset);
+        }
+
+        // current split gain
+        double current_gain = GetSplitGains<USE_MC, USE_L1, USE_MAX_OUTPUT, USE_SMOOTHING>(
+            sum_left_gradient, sum_left_hessian + kEpsilon, sum_right_gradient,
+            sum_right_hessian + kEpsilon, meta_->config->lambda_l1,
+            meta_->config->lambda_l2, meta_->config->max_delta_step,
+            constraints, meta_->monotone_type, meta_->config->path_smooth,
+            left_count, right_count, parent_output);
+        // gain with split is worse than without split
+        if (current_gain <= min_gain_shift) {
+          continue;
+        }
+
+        // mark as able to be split
+        is_splittable_ = true;
+        // better split point
+        if (current_gain > best_gain) {
+          if (USE_MC) {
+            best_right_constraints = constraints->RightToBasicConstraint();
+            best_left_constraints = constraints->LeftToBasicConstraint();
+            if (best_right_constraints.min > best_right_constraints.max ||
+                best_left_constraints.min > best_left_constraints.max) {
+              continue;
+            }
+          }
+          best_sum_left_gradient_and_hessian = sum_left_gradient_and_hessian;
+          // left is <= threshold, right is > threshold.  so this is t-1
+          best_threshold = static_cast<uint32_t>(t - 1 + offset);
+          best_gain = current_gain;
+        }
+      }
+    } else {
+      PACKED_HIST_ACC_T sum_left_gradient_and_hessian = 0;
+
+      int t = 0;
+      const int t_end = meta_->num_bin - 2 - offset;
+
+      if (NA_AS_MISSING) {
+        if (offset == 1) {
+          sum_left_gradient_and_hessian = local_int_sum_gradient_and_hessian;
+          for (int i = 0; i < meta_->num_bin - offset; ++i) {
+            const PACKED_HIST_BIN_T grad_and_hess = data_ptr[i];
+            if (HIST_BITS_ACC != HIST_BITS_BIN) {
+              const PACKED_HIST_ACC_T grad_and_hess_acc = HIST_BITS_BIN == 16 ?
+                ((static_cast<PACKED_HIST_ACC_T>(static_cast<HIST_BIN_T>(grad_and_hess >> HIST_BITS_BIN)) << HIST_BITS_ACC) |
+                (static_cast<PACKED_HIST_ACC_T>(grad_and_hess & 0x0000ffff))) :
+                ((static_cast<PACKED_HIST_ACC_T>(static_cast<HIST_BIN_T>(grad_and_hess >> HIST_BITS_BIN)) << HIST_BITS_ACC) |
+                (static_cast<PACKED_HIST_ACC_T>(grad_and_hess & 0x00000000ffffffff)));
+              sum_left_gradient_and_hessian -= grad_and_hess_acc;
+            } else {
+              sum_left_gradient_and_hessian -= grad_and_hess;
+            }
+          }
+          t = -1;
+        }
+      }
+
+      for (; t <= t_end; ++t) {
+        if (SKIP_DEFAULT_BIN) {
+          if ((t + offset) == static_cast<int>(meta_->default_bin)) {
+            continue;
+          }
+        }
+        if (t >= 0) {
+          const PACKED_HIST_BIN_T grad_and_hess = data_ptr[t];
+          if (HIST_BITS_ACC != HIST_BITS_BIN) {
+            const PACKED_HIST_ACC_T grad_and_hess_acc = HIST_BITS_BIN == 16 ?
+              ((static_cast<PACKED_HIST_ACC_T>(static_cast<HIST_BIN_T>(grad_and_hess >> HIST_BITS_BIN)) << HIST_BITS_ACC) |
+              (static_cast<PACKED_HIST_ACC_T>(grad_and_hess & 0x0000ffff))) :
+              ((static_cast<PACKED_HIST_ACC_T>(static_cast<HIST_BIN_T>(grad_and_hess >> HIST_BITS_BIN)) << HIST_BITS_ACC) |
+              (static_cast<PACKED_HIST_ACC_T>(grad_and_hess & 0x00000000ffffffff)));
+            sum_left_gradient_and_hessian += grad_and_hess_acc;
+          } else {
+            sum_left_gradient_and_hessian += grad_and_hess;
+          }
+        }
+        // if data not enough, or sum hessian too small
+        const uint32_t int_sum_left_hessian = HIST_BITS_ACC == 16 ?
+          static_cast<uint32_t>(sum_left_gradient_and_hessian & 0x0000ffff) :
+          static_cast<uint32_t>(sum_left_gradient_and_hessian & 0x00000000ffffffff);
+        const data_size_t left_count = Common::RoundInt(static_cast<double>(int_sum_left_hessian) * cnt_factor);
+        const double sum_left_hessian = static_cast<double>(int_sum_left_hessian) * hess_scale;
+        if (left_count < meta_->config->min_data_in_leaf ||
+            sum_left_hessian < meta_->config->min_sum_hessian_in_leaf) {
+          continue;
+        }
+        data_size_t right_count = num_data - left_count;
+        // if data not enough
+        if (right_count < meta_->config->min_data_in_leaf) {
+          break;
+        }
+
+        const PACKED_HIST_ACC_T sum_right_gradient_and_hessian = local_int_sum_gradient_and_hessian - sum_left_gradient_and_hessian;
+        const uint32_t int_sum_right_hessian = HIST_BITS_ACC == 16 ?
+          static_cast<uint32_t>(sum_right_gradient_and_hessian & 0x0000ffff) :
+          static_cast<uint32_t>(sum_right_gradient_and_hessian & 0x00000000ffffffff);
+        const double sum_right_hessian = static_cast<double>(int_sum_right_hessian) * hess_scale;
+        // if sum Hessian too small
+        if (sum_right_hessian < meta_->config->min_sum_hessian_in_leaf) {
+          break;
+        }
+
+        double sum_right_gradient = HIST_BITS_ACC == 16 ?
+          static_cast<double>(static_cast<int16_t>(sum_right_gradient_and_hessian >> 16)) * grad_scale :
+          static_cast<double>(static_cast<int32_t>(sum_right_gradient_and_hessian >> 32)) * grad_scale;
+        double sum_left_gradient = HIST_BITS_ACC == 16 ?
+          static_cast<double>(static_cast<int16_t>(sum_left_gradient_and_hessian >> 16)) * grad_scale :
+          static_cast<double>(static_cast<int32_t>(sum_left_gradient_and_hessian >> 32)) * grad_scale;
+        if (USE_RAND) {
+          if (t + offset != rand_threshold) {
+            continue;
+          }
+        }
+        // current split gain
+        double current_gain = GetSplitGains<USE_MC, USE_L1, USE_MAX_OUTPUT, USE_SMOOTHING>(
+            sum_left_gradient, sum_left_hessian + kEpsilon, sum_right_gradient,
+            sum_right_hessian + kEpsilon, meta_->config->lambda_l1,
+            meta_->config->lambda_l2, meta_->config->max_delta_step,
+            constraints, meta_->monotone_type, meta_->config->path_smooth, left_count,
+            right_count, parent_output);
+        // gain with split is worse than without split
+        if (current_gain <= min_gain_shift) {
+          continue;
+        }
+
+        // mark as able to be split
+        is_splittable_ = true;
+        // better split point
+        if (current_gain > best_gain) {
+          if (USE_MC) {
+            best_right_constraints = constraints->RightToBasicConstraint();
+            best_left_constraints = constraints->LeftToBasicConstraint();
+            if (best_right_constraints.min > best_right_constraints.max ||
+                best_left_constraints.min > best_left_constraints.max) {
+              continue;
+            }
+          }
+          best_sum_left_gradient_and_hessian = sum_left_gradient_and_hessian;
+          best_threshold = static_cast<uint32_t>(t + offset);
+          best_gain = current_gain;
+        }
+      }
+    }
+
+    if (is_splittable_ && best_gain > output->gain + min_gain_shift) {
+      const int32_t int_best_sum_left_gradient = HIST_BITS_ACC == 16 ?
+        static_cast<int32_t>(static_cast<int16_t>(best_sum_left_gradient_and_hessian >> 16)) :
+        static_cast<int32_t>(best_sum_left_gradient_and_hessian >> 32);
+      const uint32_t int_best_sum_left_hessian = HIST_BITS_ACC == 16 ?
+        static_cast<uint32_t>(best_sum_left_gradient_and_hessian & 0x0000ffff) :
+        static_cast<uint32_t>(best_sum_left_gradient_and_hessian & 0x00000000ffffffff);
+      const double best_sum_left_gradient = static_cast<double>(int_best_sum_left_gradient) * grad_scale;
+      const double best_sum_left_hessian = static_cast<double>(int_best_sum_left_hessian) * hess_scale;
+      const int64_t best_sum_left_gradient_and_hessian_int64 = HIST_BITS_ACC == 16 ?
+          ((static_cast<int64_t>(static_cast<int16_t>(best_sum_left_gradient_and_hessian >> 16)) << 32) |
+          static_cast<int64_t>(best_sum_left_gradient_and_hessian & 0x0000ffff)) :
+          best_sum_left_gradient_and_hessian;
+      const int64_t best_sum_right_gradient_and_hessian = int_sum_gradient_and_hessian - best_sum_left_gradient_and_hessian_int64;
+      const int32_t int_best_sum_right_gradient = static_cast<int32_t>(best_sum_right_gradient_and_hessian >> 32);
+      const uint32_t int_best_sum_right_hessian = static_cast<uint32_t>(best_sum_right_gradient_and_hessian & 0x00000000ffffffff);
+      const double best_sum_right_gradient = static_cast<double>(int_best_sum_right_gradient) * grad_scale;
+      const double best_sum_right_hessian = static_cast<double>(int_best_sum_right_hessian) * hess_scale;
+      const data_size_t best_left_count = Common::RoundInt(static_cast<double>(int_best_sum_left_hessian) * cnt_factor);
+      const data_size_t best_right_count = Common::RoundInt(static_cast<double>(int_best_sum_right_hessian) * cnt_factor);
+      // update split information
+      output->threshold = best_threshold;
+      output->left_output =
+          CalculateSplittedLeafOutput<USE_MC, USE_L1, USE_MAX_OUTPUT, USE_SMOOTHING>(
+              best_sum_left_gradient, best_sum_left_hessian,
+              meta_->config->lambda_l1, meta_->config->lambda_l2,
+              meta_->config->max_delta_step, best_left_constraints, meta_->config->path_smooth,
+              best_left_count, parent_output);
+      output->left_count = best_left_count;
+      output->left_sum_gradient = best_sum_left_gradient;
+      output->left_sum_hessian = best_sum_left_hessian;
+      output->left_sum_gradient_and_hessian = best_sum_left_gradient_and_hessian_int64;
+      output->right_output =
+          CalculateSplittedLeafOutput<USE_MC, USE_L1, USE_MAX_OUTPUT, USE_SMOOTHING>(
+              best_sum_right_gradient,
+              best_sum_right_hessian, meta_->config->lambda_l1,
+              meta_->config->lambda_l2, meta_->config->max_delta_step,
+              best_right_constraints, meta_->config->path_smooth, best_right_count,
+              parent_output);
+      output->right_count = best_right_count;
+      output->right_sum_gradient = best_sum_right_gradient;
+      output->right_sum_hessian = best_sum_right_hessian;
+      output->right_sum_gradient_and_hessian = best_sum_right_gradient_and_hessian;
+      output->gain = best_gain - min_gain_shift;
+      output->default_left = REVERSE;
+    }
+  }
+
   const FeatureMetainfo* meta_;
   /*! \brief sum of gradient of each bin */
   hist_t* data_;
+  int16_t* data_int16_;
   bool is_splittable_ = true;
 
   std::function<void(double, double, data_size_t, const FeatureConstraint*,
                      double, SplitInfo*)>
       find_best_threshold_fun_;
+
+  std::function<void(int64_t, double, double, const uint8_t, const uint8_t, data_size_t, const FeatureConstraint*,
+                     double, SplitInfo*)>
+      int_find_best_threshold_fun_;
 };
 
 class HistogramPool {
  public:
   /*!
    * \brief Constructor
    */
@@ -1196,26 +1742,43 @@
     int old_cache_size = static_cast<int>(pool_.size());
     Reset(cache_size, total_size);
 
     if (cache_size > old_cache_size) {
       pool_.resize(cache_size);
       data_.resize(cache_size);
     }
-    OMP_INIT_EX();
-#pragma omp parallel for schedule(static)
-    for (int i = old_cache_size; i < cache_size; ++i) {
-      OMP_LOOP_EX_BEGIN();
-      pool_[i].reset(new FeatureHistogram[train_data->num_features()]);
-      data_[i].resize(num_total_bin * 2);
-      for (int j = 0; j < train_data->num_features(); ++j) {
-        pool_[i][j].Init(data_[i].data() + offsets[j] * 2, &feature_metas_[j]);
+
+    if (config->use_quantized_grad) {
+      OMP_INIT_EX();
+      #pragma omp parallel for schedule(static)
+      for (int i = old_cache_size; i < cache_size; ++i) {
+        OMP_LOOP_EX_BEGIN();
+        pool_[i].reset(new FeatureHistogram[train_data->num_features()]);
+        data_[i].resize(num_total_bin);
+        for (int j = 0; j < train_data->num_features(); ++j) {
+          int16_t* data_ptr = reinterpret_cast<int16_t*>(data_[i].data());
+          pool_[i][j].Init(data_[i].data() + offsets[j], data_ptr + 2 * offsets[j], &feature_metas_[j]);
+        }
+        OMP_LOOP_EX_END();
+      }
+      OMP_THROW_EX();
+    } else {
+      OMP_INIT_EX();
+      #pragma omp parallel for schedule(static)
+      for (int i = old_cache_size; i < cache_size; ++i) {
+        OMP_LOOP_EX_BEGIN();
+        pool_[i].reset(new FeatureHistogram[train_data->num_features()]);
+        data_[i].resize(num_total_bin * 2);
+        for (int j = 0; j < train_data->num_features(); ++j) {
+          pool_[i][j].Init(data_[i].data() + offsets[j] * 2, &feature_metas_[j]);
+        }
+        OMP_LOOP_EX_END();
       }
-      OMP_LOOP_EX_END();
+      OMP_THROW_EX();
     }
-    OMP_THROW_EX();
   }
 
   void ResetConfig(const Dataset* train_data, const Config* config) {
     CHECK_GT(train_data->num_features(), 0);
     const Config* old_config = feature_metas_[0].config;
     SetFeatureInfo<false, true>(train_data, config, &feature_metas_);
     // if need to reset the function pointers
```

### Comparing `lightgbm-3.3.5/compile/src/treelearner/feature_parallel_tree_learner.cpp` & `lightgbm-4.0.0/src/treelearner/feature_parallel_tree_learner.cpp`

 * *Files 2% similar despite different names*

```diff
@@ -73,11 +73,10 @@
   this->best_split_per_leaf_[this->smaller_leaf_splits_->leaf_index()] = smaller_best_split;
   if (this->larger_leaf_splits_->leaf_index() >= 0) {
     this->best_split_per_leaf_[this->larger_leaf_splits_->leaf_index()] = larger_best_split;
   }
 }
 
 // instantiate template classes, otherwise linker cannot find the code
-template class FeatureParallelTreeLearner<CUDATreeLearner>;
 template class FeatureParallelTreeLearner<GPUTreeLearner>;
 template class FeatureParallelTreeLearner<SerialTreeLearner>;
 }  // namespace LightGBM
```

### Comparing `lightgbm-3.3.5/compile/src/treelearner/gpu_tree_learner.cpp` & `lightgbm-4.0.0/src/treelearner/gpu_tree_learner.cpp`

 * *Files 1% similar despite different names*

```diff
@@ -241,15 +241,15 @@
   // do nothing if no features can be processed on GPU
   if (!num_dense_feature_groups_) {
     Log::Warning("GPU acceleration is disabled because no non-trivial dense features can be found");
     return;
   }
   // allocate memory for all features (FIXME: 4 GB barrier on some devices, need to split to multiple buffers)
   device_features_.reset();
-  device_features_ = std::unique_ptr<boost::compute::vector<Feature4>>(new boost::compute::vector<Feature4>(num_dense_feature4_ * num_data_, ctx_));
+  device_features_ = std::unique_ptr<boost::compute::vector<Feature4>>(new boost::compute::vector<Feature4>((uint64_t)num_dense_feature4_ * num_data_, ctx_));
   // unpin old buffer if necessary before destructing them
   if (ptr_pinned_gradients_) {
     queue_.enqueue_unmap_buffer(pinned_gradients_, ptr_pinned_gradients_);
   }
   if (ptr_pinned_hessians_) {
     queue_.enqueue_unmap_buffer(pinned_hessians_, ptr_pinned_hessians_);
   }
@@ -262,26 +262,26 @@
   pinned_gradients_ = boost::compute::buffer();  // deallocate
   pinned_gradients_ = boost::compute::buffer(ctx_, allocated_num_data_ * sizeof(score_t),
                                              boost::compute::memory_object::read_write | boost::compute::memory_object::use_host_ptr,
                                              ordered_gradients_.data());
   ptr_pinned_gradients_ = queue_.enqueue_map_buffer(pinned_gradients_, boost::compute::command_queue::map_write_invalidate_region,
                                                     0, allocated_num_data_ * sizeof(score_t));
   pinned_hessians_ = boost::compute::buffer();  // deallocate
-  pinned_hessians_  = boost::compute::buffer(ctx_, allocated_num_data_ * sizeof(score_t),
+  pinned_hessians_ = boost::compute::buffer(ctx_, allocated_num_data_ * sizeof(score_t),
                                              boost::compute::memory_object::read_write | boost::compute::memory_object::use_host_ptr,
                                              ordered_hessians_.data());
   ptr_pinned_hessians_ = queue_.enqueue_map_buffer(pinned_hessians_, boost::compute::command_queue::map_write_invalidate_region,
                                                    0, allocated_num_data_ * sizeof(score_t));
   // allocate space for gradients and Hessians on device
   // we will copy gradients and Hessians in after ordered_gradients_ and ordered_hessians_ are constructed
   device_gradients_ = boost::compute::buffer();  // deallocate
   device_gradients_ = boost::compute::buffer(ctx_, allocated_num_data_ * sizeof(score_t),
                       boost::compute::memory_object::read_only, nullptr);
   device_hessians_ = boost::compute::buffer();  // deallocate
-  device_hessians_  = boost::compute::buffer(ctx_, allocated_num_data_ * sizeof(score_t),
+  device_hessians_ = boost::compute::buffer(ctx_, allocated_num_data_ * sizeof(score_t),
                       boost::compute::memory_object::read_only, nullptr);
   // allocate feature mask, for disabling some feature-groups' histogram calculation
   feature_masks_.resize(num_dense_feature4_ * dword_features_);
   device_feature_masks_ = boost::compute::buffer();  // deallocate
   device_feature_masks_ = boost::compute::buffer(ctx_, num_dense_feature4_ * dword_features_,
                           boost::compute::memory_object::read_only, nullptr);
   pinned_feature_masks_ = boost::compute::buffer(ctx_, num_dense_feature4_ * dword_features_,
@@ -423,15 +423,15 @@
         }
       }
     } else {
       Log::Fatal("Bug in GPU tree builder: dword_features_ can only be 4 or 8");
     }
     #pragma omp critical
     queue_.enqueue_write_buffer(device_features_->get_buffer(),
-                        i * num_data_ * sizeof(Feature4), num_data_ * sizeof(Feature4), host4);
+                        (uint64_t)i * num_data_ * sizeof(Feature4), num_data_ * sizeof(Feature4), host4);
     #if GPU_DEBUG >= 1
     printf("first example of feature-group tuple is: %d %d %d %d\n", host4[0].s[0], host4[0].s[1], host4[0].s[2], host4[0].s[3]);
     printf("Feature-groups copied to device with multipliers ");
     for (int l = 0; l < dword_features_; ++l) {
       printf("%d ", dev_bin_mult[l]);
     }
     printf("\n");
@@ -499,15 +499,15 @@
           // fill this empty feature with some "random" value
           host4[j].s[i] = (uint8_t)j;
         }
       }
     }
     // copying the last 1 to (dword_features - 1) feature-groups in the last tuple
     queue_.enqueue_write_buffer(device_features_->get_buffer(),
-                        (num_dense_feature4_ - 1) * num_data_ * sizeof(Feature4), num_data_ * sizeof(Feature4), host4);
+                        (num_dense_feature4_ - 1) * (uint64_t)num_data_ * sizeof(Feature4), num_data_ * sizeof(Feature4), host4);
     #if GPU_DEBUG >= 1
     printf("Last features copied to device\n");
     #endif
     for (int i = 0; i < k; ++i) {
       dense_feature_group_map_.push_back(dense_dword_ind[i]);
     }
   }
@@ -715,18 +715,38 @@
     kernel_source_ = kernel256_src_ + 9;
     kernel_name_ = "histogram256";
     device_bin_size_ = 256;
     dword_features_ = 4;
   } else {
     Log::Fatal("bin size %d cannot run on GPU", max_num_bin_);
   }
-  if (max_num_bin_ == 65) {
+
+  // ignore the feature groups that contain categorical features when producing warnings about max_bin.
+  // these groups may contain larger number of bins due to categorical features, but not due to the setting of max_bin.
+  int max_num_bin_no_categorical = 0;
+  int cur_feature_group = 0;
+  bool categorical_feature_found = false;
+  for (int inner_feature_index = 0; inner_feature_index < num_features_; ++inner_feature_index) {
+    const int feature_group = train_data_->Feature2Group(inner_feature_index);
+    const BinMapper* feature_bin_mapper = train_data_->FeatureBinMapper(inner_feature_index);
+    if (feature_bin_mapper->bin_type() == BinType::CategoricalBin) {
+      categorical_feature_found = true;
+    }
+    if (feature_group != cur_feature_group || inner_feature_index == num_features_ - 1) {
+      if (!categorical_feature_found) {
+        max_num_bin_no_categorical = std::max(max_num_bin_no_categorical, train_data_->FeatureGroupNumBin(cur_feature_group));
+      }
+      categorical_feature_found = false;
+      cur_feature_group = feature_group;
+    }
+  }
+  if (max_num_bin_no_categorical == 65) {
     Log::Warning("Setting max_bin to 63 is suggested for best performance");
   }
-  if (max_num_bin_ == 17) {
+  if (max_num_bin_no_categorical == 17) {
     Log::Warning("Setting max_bin to 15 is suggested for best performance");
   }
   ctx_ = boost::compute::context(dev_);
   queue_ = boost::compute::command_queue(ctx_, dev_);
   Log::Info("Using GPU Device: %s, Vendor: %s", dev_.name().c_str(), dev_.vendor().c_str());
   BuildGPUKernels();
   AllocateGPUMemory();
@@ -967,15 +987,15 @@
   hist_t* ptr_smaller_leaf_hist_data = smaller_leaf_histogram_array_[0].RawData() - kHistOffset;
   // ConstructGPUHistogramsAsync will return true if there are available feature groups dispatched to GPU
   bool is_gpu_used = ConstructGPUHistogramsAsync(is_feature_used,
     nullptr, smaller_leaf_splits_->num_data_in_leaf(),
     nullptr, nullptr,
     nullptr, nullptr);
   // then construct sparse features on CPU
-  train_data_->ConstructHistograms(is_sparse_feature_used,
+  train_data_->ConstructHistograms<false, 0>(is_sparse_feature_used,
     smaller_leaf_splits_->data_indices(), smaller_leaf_splits_->num_data_in_leaf(),
     gradients_, hessians_,
     ordered_gradients_.data(), ordered_hessians_.data(),
     share_state_.get(),
     ptr_smaller_leaf_hist_data);
   // wait for GPU to finish, only if GPU is actually used
   if (is_gpu_used) {
@@ -1032,15 +1052,15 @@
     // construct larger leaf
     hist_t* ptr_larger_leaf_hist_data = larger_leaf_histogram_array_[0].RawData() - kHistOffset;
     is_gpu_used = ConstructGPUHistogramsAsync(is_feature_used,
       larger_leaf_splits_->data_indices(), larger_leaf_splits_->num_data_in_leaf(),
       gradients_, hessians_,
       ordered_gradients_.data(), ordered_hessians_.data());
     // then construct sparse features on CPU
-    train_data_->ConstructHistograms(is_sparse_feature_used,
+    train_data_->ConstructHistograms<false, 0>(is_sparse_feature_used,
       larger_leaf_splits_->data_indices(), larger_leaf_splits_->num_data_in_leaf(),
       gradients_, hessians_,
       ordered_gradients_.data(), ordered_hessians_.data(),
       share_state_.get(),
       ptr_larger_leaf_hist_data);
     // wait for GPU to finish, only if GPU is actually used
     if (is_gpu_used) {
```

### Comparing `lightgbm-3.3.5/compile/src/treelearner/gpu_tree_learner.h` & `lightgbm-4.0.0/src/treelearner/gpu_tree_learner.h`

 * *Files 0% similar despite different names*

```diff
@@ -32,15 +32,15 @@
 #define BOOST_COMPUTE_USE_OFFLINE_CACHE
 #include <boost/compute/core.hpp>
 #include <boost/compute/container/vector.hpp>
 #include <boost/align/aligned_allocator.hpp>
 
 namespace LightGBM {
 
-using json11::Json;
+using json11_internal_lightgbm::Json;
 
 /*!
 * \brief GPU-based parallel learning algorithm.
 */
 class GPUTreeLearner: public SerialTreeLearner {
  public:
   explicit GPUTreeLearner(const Config* tree_config);
```

### Comparing `lightgbm-3.3.5/compile/src/treelearner/kernels/histogram_16_64_256.cu` & `lightgbm-4.0.0/src/treelearner/kernels/histogram_16_64_256.cu`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/src/treelearner/kernels/histogram_16_64_256.hu` & `lightgbm-4.0.0/src/treelearner/kernels/histogram_16_64_256.hu`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/src/treelearner/linear_tree_learner.cpp` & `lightgbm-4.0.0/src/treelearner/linear_tree_learner.cpp`

 * *Files 2% similar despite different names*

```diff
@@ -43,16 +43,16 @@
   int max_num_feat = std::min(max_leaves, train_data_->num_numeric_features());
   XTHX_.clear();
   XTg_.clear();
   for (int i = 0; i < max_leaves; ++i) {
     // store only upper triangular half of matrix as an array, in row-major order
     // this requires (max_num_feat + 1) * (max_num_feat + 2) / 2 entries (including the constant terms of the regression)
     // we add another 8 to ensure cache lines are not shared among processors
-    XTHX_.push_back(std::vector<float>((max_num_feat + 1) * (max_num_feat + 2) / 2 + 8, 0));
-    XTg_.push_back(std::vector<float>(max_num_feat + 9, 0.0));
+    XTHX_.push_back(std::vector<double>((max_num_feat + 1) * (max_num_feat + 2) / 2 + 8, 0));
+    XTg_.push_back(std::vector<double>(max_num_feat + 9, 0.0));
   }
   XTHX_by_thread_.clear();
   XTg_by_thread_.clear();
   int max_threads = omp_get_max_threads();
   for (int i = 0; i < max_threads; ++i) {
     XTHX_by_thread_.push_back(XTHX_);
     XTg_by_thread_.push_back(XTg_);
@@ -277,15 +277,15 @@
         }
       }
       curr_row[num_feat] = 1.0;
       float h = static_cast<float>(hessians[i]);
       float g = static_cast<float>(gradients[i]);
       int j = 0;
       for (int feat1 = 0; feat1 < num_feat + 1; ++feat1) {
-        float f1_val = curr_row[feat1];
+        double f1_val = static_cast<double>(curr_row[feat1]);
         XTg_by_thread_[tid][leaf_num][feat1] += f1_val * g;
         f1_val *= h;
         for (int feat2 = feat1; feat2 < num_feat + 1; ++feat2) {
           XTHX_by_thread_[tid][leaf_num][j] += f1_val * curr_row[feat2];
           ++j;
         }
       }
```

### Comparing `lightgbm-3.3.5/compile/src/treelearner/linear_tree_learner.h` & `lightgbm-4.0.0/src/treelearner/linear_tree_learner.h`

 * *Files 6% similar despite different names*

```diff
@@ -114,15 +114,15 @@
   /*! \brief whether numerical features contain any nan values */
   std::vector<int8_t> contains_nan_;
   /*! whether any numerical feature contains a nan value */
   bool any_nan_;
   /*! \brief map dataset to leaves */
   mutable std::vector<int> leaf_map_;
   /*! \brief temporary storage for calculating linear model coefficients */
-  mutable std::vector<std::vector<float>> XTHX_;
-  mutable std::vector<std::vector<float>> XTg_;
-  mutable std::vector<std::vector<std::vector<float>>> XTHX_by_thread_;
-  mutable std::vector<std::vector<std::vector<float>>> XTg_by_thread_;
+  mutable std::vector<std::vector<double>> XTHX_;
+  mutable std::vector<std::vector<double>> XTg_;
+  mutable std::vector<std::vector<std::vector<double>>> XTHX_by_thread_;
+  mutable std::vector<std::vector<std::vector<double>>> XTg_by_thread_;
 };
 
 }  // namespace LightGBM
 #endif   // LightGBM_TREELEARNER_LINEAR_TREE_LEARNER_H_
```

### Comparing `lightgbm-3.3.5/compile/src/treelearner/monotone_constraints.hpp` & `lightgbm-4.0.0/src/treelearner/monotone_constraints.hpp`

 * *Files 0% similar despite different names*

```diff
@@ -871,15 +871,15 @@
                          bool use_max_operator, uint32_t last_threshold) {
     bool start_done = false;
     bool end_done = false;
     // previous constraint have to be tracked
     // for example when adding a constraints cstr2 on thresholds [1:2),
     // on an existing constraints cstr1 on thresholds [0, +inf),
     // the thresholds and constraints must become
-    // [0, 1, 2] and  [cstr1, cstr2, cstr1]
+    // [0, 1, 2] and [cstr1, cstr2, cstr1]
     // so since we loop through thresholds only once,
     // the previous constraint that still applies needs to be recorded
     double previous_constraint = use_max_operator
       ? -std::numeric_limits<double>::max()
       : std::numeric_limits<double>::max();
     double current_constraint;
     for (size_t i = 0; i < feature_constraint->thresholds.size(); ++i) {
```

### Comparing `lightgbm-3.3.5/compile/src/treelearner/ocl/histogram16.cl` & `lightgbm-4.0.0/src/treelearner/ocl/histogram16.cl`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/src/treelearner/ocl/histogram256.cl` & `lightgbm-4.0.0/src/treelearner/ocl/histogram256.cl`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/src/treelearner/ocl/histogram64.cl` & `lightgbm-4.0.0/src/treelearner/ocl/histogram64.cl`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/src/treelearner/parallel_tree_learner.h` & `lightgbm-4.0.0/src/treelearner/parallel_tree_learner.h`

 * *Files 5% similar despite different names*

```diff
@@ -8,15 +8,14 @@
 #include <LightGBM/network.h>
 #include <LightGBM/utils/array_args.h>
 
 #include <cstring>
 #include <memory>
 #include <vector>
 
-#include "cuda_tree_learner.h"
 #include "gpu_tree_learner.h"
 #include "serial_tree_learner.h"
 
 namespace LightGBM {
 
 /*!
 * \brief Feature parallel learning algorithm.
@@ -68,36 +67,55 @@
     if (leaf_idx >= 0) {
       return global_data_count_in_leaf_[leaf_idx];
     } else {
       return 0;
     }
   }
 
+  void PrepareBufferPos(
+    const std::vector<std::vector<int>>& feature_distribution,
+    std::vector<comm_size_t>* block_start,
+    std::vector<comm_size_t>* block_len,
+    std::vector<comm_size_t>* buffer_write_start_pos,
+    std::vector<comm_size_t>* buffer_read_start_pos,
+    comm_size_t* reduce_scatter_size,
+    size_t hist_entry_size);
+
  private:
   /*! \brief Rank of local machine */
   int rank_;
   /*! \brief Number of machines of this parallel task */
   int num_machines_;
   /*! \brief Buffer for network send */
-  std::vector<char> input_buffer_;
+  std::vector<char, Common::AlignmentAllocator<char, 32>> input_buffer_;
   /*! \brief Buffer for network receive */
-  std::vector<char> output_buffer_;
+  std::vector<char, Common::AlignmentAllocator<char, 32>> output_buffer_;
   /*! \brief different machines will aggregate histograms for different features,
        use this to mark local aggregate features*/
   std::vector<bool> is_feature_aggregated_;
   /*! \brief Block start index for reduce scatter */
   std::vector<comm_size_t> block_start_;
   /*! \brief Block size for reduce scatter */
   std::vector<comm_size_t> block_len_;
+  /*! \brief Block start index for reduce scatter with int16 histograms */
+  std::vector<comm_size_t> block_start_int16_;
+  /*! \brief Block size for reduce scatter with int16 histograms */
+  std::vector<comm_size_t> block_len_int16_;
   /*! \brief Write positions for feature histograms */
   std::vector<comm_size_t> buffer_write_start_pos_;
   /*! \brief Read positions for local feature histograms */
   std::vector<comm_size_t> buffer_read_start_pos_;
+  /*! \brief Write positions for feature histograms with int16 histograms*/
+  std::vector<comm_size_t> buffer_write_start_pos_int16_;
+  /*! \brief Read positions for local feature histograms with int16 histograms */
+  std::vector<comm_size_t> buffer_read_start_pos_int16_;
   /*! \brief Size for reduce scatter */
   comm_size_t reduce_scatter_size_;
+  /*! \brief Size for reduce scatter with int16 histogram*/
+  comm_size_t reduce_scatter_size_int16_;
   /*! \brief Store global number of data in leaves  */
   std::vector<data_size_t> global_data_count_in_leaf_;
 };
 
 /*!
 * \brief Voting based data parallel learning algorithm.
 * Like data parallel, but not aggregate histograms for all features.
```

### Comparing `lightgbm-3.3.5/compile/src/treelearner/serial_tree_learner.cpp` & `lightgbm-4.0.0/src/treelearner/serial_tree_learner.cpp`

 * *Files 16% similar despite different names*

```diff
@@ -7,23 +7,25 @@
 #include <LightGBM/network.h>
 #include <LightGBM/objective_function.h>
 #include <LightGBM/utils/array_args.h>
 #include <LightGBM/utils/common.h>
 
 #include <algorithm>
 #include <queue>
+#include <set>
 #include <unordered_map>
 #include <utility>
 
 #include "cost_effective_gradient_boosting.hpp"
 
 namespace LightGBM {
 
 SerialTreeLearner::SerialTreeLearner(const Config* config)
     : config_(config), col_sampler_(config) {
+  gradient_discretizer_ = nullptr;
 }
 
 SerialTreeLearner::~SerialTreeLearner() {
 }
 
 void SerialTreeLearner::Init(const Dataset* train_data, bool is_constant_hessian) {
   train_data_ = train_data;
@@ -55,14 +57,19 @@
   // initialize data partition
   data_partition_.reset(new DataPartition(num_data_, config_->num_leaves));
   col_sampler_.SetTrainingData(train_data_);
   // initialize ordered gradients and hessians
   ordered_gradients_.resize(num_data_);
   ordered_hessians_.resize(num_data_);
 
+  if (config_->use_quantized_grad) {
+    gradient_discretizer_.reset(new GradientDiscretizer(config_->num_grad_quant_bins, config_->num_iterations, config_->seed, is_constant_hessian, config_->stochastic_rounding));
+    gradient_discretizer_->Init(num_data_, config_->num_leaves, num_features_, train_data_);
+  }
+
   GetShareStates(train_data_, is_constant_hessian, true);
   histogram_pool_.DynamicChangeSize(train_data_,
   share_state_->num_hist_total_bin(),
   share_state_->feature_hist_offsets(),
   config_, max_cache_size, config_->num_leaves);
   Log::Info("Number of data points in the train set: %d, number of used features: %d", num_data_, num_features_);
   if (CostEfficientGradientBoosting::IsEnable(config_)) {
@@ -71,25 +78,39 @@
   }
 }
 
 void SerialTreeLearner::GetShareStates(const Dataset* dataset,
                                        bool is_constant_hessian,
                                        bool is_first_time) {
   if (is_first_time) {
-    share_state_.reset(dataset->GetShareStates(
-        ordered_gradients_.data(), ordered_hessians_.data(),
+    if (config_->use_quantized_grad) {
+      share_state_.reset(dataset->GetShareStates<true, 32>(
+        reinterpret_cast<score_t*>(gradient_discretizer_->ordered_int_gradients_and_hessians()), nullptr,
         col_sampler_.is_feature_used_bytree(), is_constant_hessian,
-        config_->force_col_wise, config_->force_row_wise));
+        config_->force_col_wise, config_->force_row_wise, config_->num_grad_quant_bins));
+    } else {
+      share_state_.reset(dataset->GetShareStates<false, 0>(
+          ordered_gradients_.data(), ordered_hessians_.data(),
+          col_sampler_.is_feature_used_bytree(), is_constant_hessian,
+          config_->force_col_wise, config_->force_row_wise, config_->num_grad_quant_bins));
+    }
   } else {
     CHECK_NOTNULL(share_state_);
     // cannot change is_hist_col_wise during training
-    share_state_.reset(dataset->GetShareStates(
-        ordered_gradients_.data(), ordered_hessians_.data(), col_sampler_.is_feature_used_bytree(),
-        is_constant_hessian, share_state_->is_col_wise,
-        !share_state_->is_col_wise));
+    if (config_->use_quantized_grad) {
+      share_state_.reset(dataset->GetShareStates<true, 32>(
+          reinterpret_cast<score_t*>(gradient_discretizer_->ordered_int_gradients_and_hessians()), nullptr,
+          col_sampler_.is_feature_used_bytree(), is_constant_hessian,
+          share_state_->is_col_wise, !share_state_->is_col_wise, config_->num_grad_quant_bins));
+    } else {
+      share_state_.reset(dataset->GetShareStates<false, 0>(
+          ordered_gradients_.data(), ordered_hessians_.data(), col_sampler_.is_feature_used_bytree(),
+          is_constant_hessian, share_state_->is_col_wise,
+          !share_state_->is_col_wise, config_->num_grad_quant_bins));
+    }
   }
   CHECK_NOTNULL(share_state_);
 }
 
 void SerialTreeLearner::ResetTrainingDataInner(const Dataset* train_data,
                                                bool is_constant_hessian,
                                                bool reset_multi_val_bin) {
@@ -164,14 +185,18 @@
     Log::Warning(
         "Detected that num_threads changed during training (from %d to %d), "
         "it may cause unexpected errors.",
         share_state_->num_threads, num_threads);
   }
   share_state_->num_threads = num_threads;
 
+  if (config_->use_quantized_grad) {
+    gradient_discretizer_->DiscretizeGradients(num_data_, gradients_, hessians_);
+  }
+
   // some initial works before training
   BeforeTrain();
 
   bool track_branch_features = !(config_->interaction_constraints_vector.empty());
   auto tree = std::unique_ptr<Tree>(new Tree(config_->num_leaves, track_branch_features, false));
   auto tree_ptr = tree.get();
   constraints_->ShareTreePointer(tree_ptr);
@@ -200,14 +225,19 @@
       break;
     }
     // split tree with best leaf
     Split(tree_ptr, best_leaf, &left_leaf, &right_leaf);
     cur_depth = std::max(cur_depth, tree->leaf_depth(left_leaf));
   }
 
+  if (config_->use_quantized_grad && config_->quant_train_renew_leaf) {
+    gradient_discretizer_->RenewIntGradTreeOutput(tree.get(), config_, data_partition_.get(), gradients_, hessians_,
+      [this] (int leaf_index) { return GetGlobalDataCountInLeaf(leaf_index); });
+  }
+
   Log::Debug("Trained a tree with leaves = %d and depth = %d", tree->num_leaves(), cur_depth);
   return tree.release();
 }
 
 Tree* SerialTreeLearner::FitByExistingTree(const Tree* old_tree, const score_t* gradients, const score_t *hessians) const {
   auto tree = std::unique_ptr<Tree>(new Tree(*old_tree));
   CHECK_GE(data_partition_->num_leaves(), tree->num_leaves());
@@ -265,22 +295,44 @@
   for (int i = 0; i < config_->num_leaves; ++i) {
     best_split_per_leaf_[i].Reset();
   }
 
   // Sumup for root
   if (data_partition_->leaf_count(0) == num_data_) {
     // use all data
-    smaller_leaf_splits_->Init(gradients_, hessians_);
-
+    if (!config_->use_quantized_grad) {
+      smaller_leaf_splits_->Init(gradients_, hessians_);
+    } else {
+      smaller_leaf_splits_->Init(
+        gradient_discretizer_->discretized_gradients_and_hessians(),
+        gradient_discretizer_->grad_scale(),
+        gradient_discretizer_->hess_scale());
+    }
   } else {
     // use bagging, only use part of data
-    smaller_leaf_splits_->Init(0, data_partition_.get(), gradients_, hessians_);
+    if (!config_->use_quantized_grad) {
+      smaller_leaf_splits_->Init(0, data_partition_.get(), gradients_, hessians_);
+    } else {
+      smaller_leaf_splits_->Init(
+        0, data_partition_.get(),
+        gradient_discretizer_->discretized_gradients_and_hessians(),
+        gradient_discretizer_->grad_scale(),
+        gradient_discretizer_->hess_scale());
+    }
   }
 
   larger_leaf_splits_->Init();
+
+  if (cegb_ != nullptr) {
+    cegb_->BeforeTrain();
+  }
+
+  if (config_->use_quantized_grad && config_->tree_learner != std::string("data")) {
+    gradient_discretizer_->SetNumBitsInHistogramBin<false>(0, -1, data_partition_->leaf_count(0), 0);
+  }
 }
 
 bool SerialTreeLearner::BeforeFindBestSplit(const Tree* tree, int left_leaf, int right_leaf) {
   Common::FunctionTimer fun_timer("SerialTreeLearner::BeforeFindBestSplit", global_timer);
   // check depth of current leaf
   if (config_->max_depth > 0) {
     // only need to check left leaf, since right leaf is in same level of left leaf
@@ -318,60 +370,101 @@
     if (histogram_pool_.Get(left_leaf, &larger_leaf_histogram_array_)) { parent_leaf_histogram_array_ = larger_leaf_histogram_array_; }
     histogram_pool_.Get(right_leaf, &smaller_leaf_histogram_array_);
   }
   return true;
 }
 
 void SerialTreeLearner::FindBestSplits(const Tree* tree) {
+  FindBestSplits(tree, nullptr);
+}
+
+void SerialTreeLearner::FindBestSplits(const Tree* tree, const std::set<int>* force_features) {
   std::vector<int8_t> is_feature_used(num_features_, 0);
   #pragma omp parallel for schedule(static, 256) if (num_features_ >= 512)
   for (int feature_index = 0; feature_index < num_features_; ++feature_index) {
-    if (!col_sampler_.is_feature_used_bytree()[feature_index]) continue;
+    if (!col_sampler_.is_feature_used_bytree()[feature_index] && (force_features == nullptr || force_features->find(feature_index) == force_features->end())) continue;
     if (parent_leaf_histogram_array_ != nullptr
         && !parent_leaf_histogram_array_[feature_index].is_splittable()) {
       smaller_leaf_histogram_array_[feature_index].set_is_splittable(false);
       continue;
     }
     is_feature_used[feature_index] = 1;
   }
   bool use_subtract = parent_leaf_histogram_array_ != nullptr;
 
-#ifdef USE_CUDA
-  if (LGBM_config_::current_learner == use_cpu_learner) {
-    SerialTreeLearner::ConstructHistograms(is_feature_used, use_subtract);
-  } else {
-    ConstructHistograms(is_feature_used, use_subtract);
-  }
-#else
   ConstructHistograms(is_feature_used, use_subtract);
-#endif
   FindBestSplitsFromHistograms(is_feature_used, use_subtract, tree);
 }
 
 void SerialTreeLearner::ConstructHistograms(
     const std::vector<int8_t>& is_feature_used, bool use_subtract) {
   Common::FunctionTimer fun_timer("SerialTreeLearner::ConstructHistograms",
                                   global_timer);
   // construct smaller leaf
-  hist_t* ptr_smaller_leaf_hist_data =
-      smaller_leaf_histogram_array_[0].RawData() - kHistOffset;
-  train_data_->ConstructHistograms(
-      is_feature_used, smaller_leaf_splits_->data_indices(),
-      smaller_leaf_splits_->num_data_in_leaf(), gradients_, hessians_,
-      ordered_gradients_.data(), ordered_hessians_.data(), share_state_.get(),
-      ptr_smaller_leaf_hist_data);
-  if (larger_leaf_histogram_array_ != nullptr && !use_subtract) {
-    // construct larger leaf
-    hist_t* ptr_larger_leaf_hist_data =
-        larger_leaf_histogram_array_[0].RawData() - kHistOffset;
-    train_data_->ConstructHistograms(
-        is_feature_used, larger_leaf_splits_->data_indices(),
-        larger_leaf_splits_->num_data_in_leaf(), gradients_, hessians_,
+  if (config_->use_quantized_grad) {
+    const uint8_t smaller_leaf_num_bits = gradient_discretizer_->GetHistBitsInLeaf<false>(smaller_leaf_splits_->leaf_index());
+    hist_t* ptr_smaller_leaf_hist_data =
+        smaller_leaf_num_bits <= 16 ?
+        reinterpret_cast<hist_t*>(smaller_leaf_histogram_array_[0].RawDataInt16() - kHistOffset) :
+        reinterpret_cast<hist_t*>(smaller_leaf_histogram_array_[0].RawDataInt32() - kHistOffset);
+    #define SMALLER_LEAF_ARGS \
+      is_feature_used, smaller_leaf_splits_->data_indices(), \
+      smaller_leaf_splits_->num_data_in_leaf(), \
+      reinterpret_cast<const score_t*>(gradient_discretizer_->discretized_gradients_and_hessians()), \
+      nullptr, \
+      reinterpret_cast<score_t*>(gradient_discretizer_->ordered_int_gradients_and_hessians()), \
+      nullptr, \
+      share_state_.get(), \
+      reinterpret_cast<hist_t*>(ptr_smaller_leaf_hist_data)
+    if (smaller_leaf_num_bits <= 16) {
+      train_data_->ConstructHistograms<true, 16>(SMALLER_LEAF_ARGS);
+    } else {
+      train_data_->ConstructHistograms<true, 32>(SMALLER_LEAF_ARGS);
+    }
+    #undef SMALLER_LEAF_ARGS
+    if (larger_leaf_histogram_array_ && !use_subtract) {
+      const uint8_t larger_leaf_num_bits = gradient_discretizer_->GetHistBitsInLeaf<false>(larger_leaf_splits_->leaf_index());
+      hist_t* ptr_larger_leaf_hist_data =
+        larger_leaf_num_bits <= 16 ?
+        reinterpret_cast<hist_t*>(larger_leaf_histogram_array_[0].RawDataInt16() - kHistOffset) :
+        reinterpret_cast<hist_t*>(larger_leaf_histogram_array_[0].RawDataInt32() - kHistOffset);
+      #define LARGER_LEAF_ARGS \
+        is_feature_used, larger_leaf_splits_->data_indices(), \
+        larger_leaf_splits_->num_data_in_leaf(), \
+        reinterpret_cast<const score_t*>(gradient_discretizer_->discretized_gradients_and_hessians()), \
+        nullptr, \
+        reinterpret_cast<score_t*>(gradient_discretizer_->ordered_int_gradients_and_hessians()), \
+        nullptr, \
+        share_state_.get(), \
+        reinterpret_cast<hist_t*>(ptr_larger_leaf_hist_data)
+      if (larger_leaf_num_bits <= 16) {
+        train_data_->ConstructHistograms<true, 16>(LARGER_LEAF_ARGS);
+      } else {
+        train_data_->ConstructHistograms<true, 32>(LARGER_LEAF_ARGS);
+      }
+      #undef LARGER_LEAF_ARGS
+    }
+  } else {
+    hist_t* ptr_smaller_leaf_hist_data =
+        smaller_leaf_histogram_array_[0].RawData() - kHistOffset;
+    train_data_->ConstructHistograms<false, 0>(
+        is_feature_used, smaller_leaf_splits_->data_indices(),
+        smaller_leaf_splits_->num_data_in_leaf(), gradients_, hessians_,
         ordered_gradients_.data(), ordered_hessians_.data(), share_state_.get(),
-        ptr_larger_leaf_hist_data);
+        ptr_smaller_leaf_hist_data);
+    if (larger_leaf_histogram_array_ != nullptr && !use_subtract) {
+      // construct larger leaf
+      hist_t* ptr_larger_leaf_hist_data =
+          larger_leaf_histogram_array_[0].RawData() - kHistOffset;
+      train_data_->ConstructHistograms<false, 0>(
+          is_feature_used, larger_leaf_splits_->data_indices(),
+          larger_leaf_splits_->num_data_in_leaf(), gradients_, hessians_,
+          ordered_gradients_.data(), ordered_hessians_.data(), share_state_.get(),
+          ptr_larger_leaf_hist_data);
+    }
   }
 }
 
 void SerialTreeLearner::FindBestSplitsFromHistograms(
     const std::vector<int8_t>& is_feature_used, bool use_subtract, const Tree* tree) {
   Common::FunctionTimer fun_timer(
       "SerialTreeLearner::FindBestSplitsFromHistograms", global_timer);
@@ -383,27 +476,61 @@
   double larger_leaf_parent_output = 0;
   if (larger_leaf_splits_ != nullptr && larger_leaf_splits_->leaf_index() >= 0) {
     larger_leaf_parent_output = GetParentOutput(tree, larger_leaf_splits_.get());
   }
   if (larger_leaf_splits_->leaf_index() >= 0) {
     larger_node_used_features = col_sampler_.GetByNode(tree, larger_leaf_splits_->leaf_index());
   }
+
+  if (use_subtract && config_->use_quantized_grad) {
+    const int parent_index = std::min(smaller_leaf_splits_->leaf_index(), larger_leaf_splits_->leaf_index());
+    const uint8_t parent_hist_bits = gradient_discretizer_->GetHistBitsInNode<false>(parent_index);
+    const uint8_t larger_hist_bits = gradient_discretizer_->GetHistBitsInLeaf<false>(larger_leaf_splits_->leaf_index());
+    if (parent_hist_bits > 16 && larger_hist_bits <= 16) {
+      OMP_INIT_EX();
+      #pragma omp parallel for schedule(static) num_threads(share_state_->num_threads)
+      for (int feature_index = 0; feature_index < num_features_; ++feature_index) {
+        OMP_LOOP_EX_BEGIN();
+        if (!is_feature_used[feature_index]) {
+          continue;
+        }
+        larger_leaf_histogram_array_[feature_index].CopyToBuffer(gradient_discretizer_->GetChangeHistBitsBuffer(feature_index));
+        OMP_LOOP_EX_END();
+      }
+      OMP_THROW_EX();
+    }
+  }
+
   OMP_INIT_EX();
 // find splits
 #pragma omp parallel for schedule(static) num_threads(share_state_->num_threads)
   for (int feature_index = 0; feature_index < num_features_; ++feature_index) {
     OMP_LOOP_EX_BEGIN();
     if (!is_feature_used[feature_index]) {
       continue;
     }
     const int tid = omp_get_thread_num();
-    train_data_->FixHistogram(
-        feature_index, smaller_leaf_splits_->sum_gradients(),
-        smaller_leaf_splits_->sum_hessians(),
-        smaller_leaf_histogram_array_[feature_index].RawData());
+    if (config_->use_quantized_grad) {
+      const uint8_t hist_bits_bin = gradient_discretizer_->GetHistBitsInLeaf<false>(smaller_leaf_splits_->leaf_index());
+      const int64_t int_sum_gradient_and_hessian = smaller_leaf_splits_->int_sum_gradients_and_hessians();
+      if (hist_bits_bin <= 16) {
+        train_data_->FixHistogramInt<int32_t, int32_t, 16, 16>(
+            feature_index, int_sum_gradient_and_hessian,
+            reinterpret_cast<hist_t*>(smaller_leaf_histogram_array_[feature_index].RawDataInt16()));
+      } else {
+        train_data_->FixHistogramInt<int64_t, int64_t, 32, 32>(
+            feature_index, int_sum_gradient_and_hessian,
+            reinterpret_cast<hist_t*>(smaller_leaf_histogram_array_[feature_index].RawDataInt32()));
+      }
+    } else {
+      train_data_->FixHistogram(
+          feature_index, smaller_leaf_splits_->sum_gradients(),
+          smaller_leaf_splits_->sum_hessians(),
+          smaller_leaf_histogram_array_[feature_index].RawData());
+    }
     int real_fidx = train_data_->RealFeatureIndex(feature_index);
 
     ComputeBestSplitForFeature(smaller_leaf_histogram_array_, feature_index,
                                real_fidx,
                                smaller_node_used_features[feature_index],
                                smaller_leaf_splits_->num_data_in_leaf(),
                                smaller_leaf_splits_.get(), &smaller_best[tid],
@@ -412,21 +539,58 @@
     // only has root leaf
     if (larger_leaf_splits_ == nullptr ||
         larger_leaf_splits_->leaf_index() < 0) {
       continue;
     }
 
     if (use_subtract) {
-      larger_leaf_histogram_array_[feature_index].Subtract(
-          smaller_leaf_histogram_array_[feature_index]);
+      if (config_->use_quantized_grad) {
+        const int parent_index = std::min(smaller_leaf_splits_->leaf_index(), larger_leaf_splits_->leaf_index());
+        const uint8_t parent_hist_bits = gradient_discretizer_->GetHistBitsInNode<false>(parent_index);
+        const uint8_t smaller_hist_bits = gradient_discretizer_->GetHistBitsInLeaf<false>(smaller_leaf_splits_->leaf_index());
+        const uint8_t larger_hist_bits = gradient_discretizer_->GetHistBitsInLeaf<false>(larger_leaf_splits_->leaf_index());
+        if (parent_hist_bits <= 16) {
+          CHECK_LE(smaller_hist_bits, 16);
+          CHECK_LE(larger_hist_bits, 16);
+          larger_leaf_histogram_array_[feature_index].Subtract<true, int32_t, int32_t, int32_t, 16, 16, 16>(
+              smaller_leaf_histogram_array_[feature_index]);
+        } else if (larger_hist_bits <= 16) {
+          CHECK_LE(smaller_hist_bits, 16);
+          larger_leaf_histogram_array_[feature_index].Subtract<true, int64_t, int32_t, int32_t, 32, 16, 16>(
+              smaller_leaf_histogram_array_[feature_index], gradient_discretizer_->GetChangeHistBitsBuffer(feature_index));
+        } else if (smaller_hist_bits <= 16) {
+          larger_leaf_histogram_array_[feature_index].Subtract<true, int64_t, int32_t, int64_t, 32, 16, 32>(
+              smaller_leaf_histogram_array_[feature_index]);
+        } else {
+          larger_leaf_histogram_array_[feature_index].Subtract<true, int64_t, int64_t, int64_t, 32, 32, 32>(
+              smaller_leaf_histogram_array_[feature_index]);
+        }
+      } else {
+        larger_leaf_histogram_array_[feature_index].Subtract<false>(
+            smaller_leaf_histogram_array_[feature_index]);
+      }
     } else {
-      train_data_->FixHistogram(
-          feature_index, larger_leaf_splits_->sum_gradients(),
-          larger_leaf_splits_->sum_hessians(),
-          larger_leaf_histogram_array_[feature_index].RawData());
+      if (config_->use_quantized_grad) {
+        const int64_t int_sum_gradient_and_hessian = larger_leaf_splits_->int_sum_gradients_and_hessians();
+        const uint8_t hist_bits_bin = gradient_discretizer_->GetHistBitsInLeaf<false>(larger_leaf_splits_->leaf_index());
+        if (hist_bits_bin <= 16) {
+          train_data_->FixHistogramInt<int32_t, int32_t, 16, 16>(
+              feature_index, int_sum_gradient_and_hessian,
+              reinterpret_cast<hist_t*>(larger_leaf_histogram_array_[feature_index].RawDataInt16()));
+        } else {
+          train_data_->FixHistogramInt<int64_t, int64_t, 32, 32>(
+              feature_index, int_sum_gradient_and_hessian,
+              reinterpret_cast<hist_t*>(larger_leaf_histogram_array_[feature_index].RawDataInt32()));
+        }
+      } else {
+        train_data_->FixHistogram(
+            feature_index, larger_leaf_splits_->sum_gradients(),
+            larger_leaf_splits_->sum_hessians(),
+            larger_leaf_histogram_array_[feature_index].RawData());
+      }
     }
 
     ComputeBestSplitForFeature(larger_leaf_histogram_array_, feature_index,
                                real_fidx,
                                larger_node_used_features[feature_index],
                                larger_leaf_splits_->num_data_in_leaf(),
                                larger_leaf_splits_.get(), &larger_best[tid],
@@ -458,20 +622,22 @@
   *left_leaf = 0;
   std::queue<std::pair<Json, int>> q;
   Json left = *forced_split_json_;
   Json right;
   bool left_smaller = true;
   std::unordered_map<int, SplitInfo> forceSplitMap;
   q.push(std::make_pair(left, *left_leaf));
+
+  // Histogram construction require parent features.
+  std::set<int> force_split_features = FindAllForceFeatures(*forced_split_json_);
   while (!q.empty()) {
-    // before processing next node from queue, store info for current left/right leaf
-    // store "best split" for left and right, even if they might be overwritten by forced split
     if (BeforeFindBestSplit(tree, *left_leaf, *right_leaf)) {
-      FindBestSplits(tree);
+      FindBestSplits(tree, &force_split_features);
     }
+
     // then, compute own splits
     SplitInfo left_split;
     SplitInfo right_split;
 
     if (!left.is_null()) {
       const int left_feature = left["feature"].int_value();
       const double left_threshold_double = left["threshold"].number_value();
@@ -557,14 +723,40 @@
     Split(tree, best_leaf, left_leaf, right_leaf);
     *(cur_depth) = std::max(*(cur_depth), tree->leaf_depth(*left_leaf));
     ++result_count;
   }
   return result_count;
 }
 
+std::set<int> SerialTreeLearner::FindAllForceFeatures(Json force_split_leaf_setting) {
+  std::set<int> force_features;
+  std::queue<Json> force_split_leafs;
+
+  force_split_leafs.push(force_split_leaf_setting);
+
+  while (!force_split_leafs.empty()) {
+    Json split_leaf = force_split_leafs.front();
+    force_split_leafs.pop();
+
+    const int feature_index = split_leaf["feature"].int_value();
+    const int feature_inner_index = train_data_->InnerFeatureIndex(feature_index);
+    force_features.insert(feature_inner_index);
+
+    if (split_leaf.object_items().count("left") > 0) {
+      force_split_leafs.push(split_leaf["left"]);
+    }
+
+    if (split_leaf.object_items().count("right") > 0) {
+      force_split_leafs.push(split_leaf["right"]);
+    }
+  }
+
+  return force_features;
+}
+
 void SerialTreeLearner::SplitInner(Tree* tree, int best_leaf, int* left_leaf,
                                    int* right_leaf, bool update_cnt) {
   Common::FunctionTimer fun_timer("SerialTreeLearner::SplitInner", global_timer);
   SplitInfo& best_split_info = best_split_per_leaf_[best_leaf];
   const int inner_feature_index =
       train_data_->InnerFeatureIndex(best_split_info.feature);
   if (cegb_ != nullptr) {
@@ -666,27 +858,32 @@
                                best_split_info.right_sum_hessian,
                                best_split_info.right_output);
     larger_leaf_splits_->Init(*left_leaf, data_partition_.get(),
                               best_split_info.left_sum_gradient,
                               best_split_info.left_sum_hessian,
                               best_split_info.left_output);
   }
+  if (config_->use_quantized_grad && config_->tree_learner != std::string("data")) {
+    gradient_discretizer_->SetNumBitsInHistogramBin<false>(*left_leaf, *right_leaf,
+                                                    data_partition_->leaf_count(*left_leaf),
+                                                    data_partition_->leaf_count(*right_leaf));
+  }
   auto leaves_need_update = constraints_->Update(
       is_numerical_split, *left_leaf, *right_leaf,
       best_split_info.monotone_type, best_split_info.right_output,
       best_split_info.left_output, inner_feature_index, best_split_info,
       best_split_per_leaf_);
   // update leave outputs if needed
   for (auto leaf : leaves_need_update) {
     RecomputeBestSplitForLeaf(tree, leaf, &best_split_per_leaf_[leaf]);
   }
 }
 
 void SerialTreeLearner::RenewTreeOutput(Tree* tree, const ObjectiveFunction* obj, std::function<double(const label_t*, int)> residual_getter,
-                                        data_size_t total_num_data, const data_size_t* bag_indices, data_size_t bag_cnt) const {
+                                        data_size_t total_num_data, const data_size_t* bag_indices, data_size_t bag_cnt, const double* /*train_score*/) const {
   if (obj != nullptr && obj->IsRenewTreeOutput()) {
     CHECK_LE(tree->num_leaves(), data_partition_->num_leaves());
     const data_size_t* bag_mapper = nullptr;
     if (total_num_data != num_data_) {
       CHECK_EQ(bag_cnt, num_data_);
       bag_mapper = bag_indices;
     }
@@ -729,21 +926,33 @@
                                   ->bin_type() == BinType::NumericalBin;
   if (is_feature_numerical & !config_->monotone_constraints.empty()) {
     constraints_->RecomputeConstraintsIfNeeded(
         constraints_.get(), feature_index, ~(leaf_splits->leaf_index()),
         train_data_->FeatureNumBin(feature_index));
   }
   SplitInfo new_split;
-  histogram_array_[feature_index].FindBestThreshold(
-      leaf_splits->sum_gradients(), leaf_splits->sum_hessians(), num_data,
-      constraints_->GetFeatureConstraint(leaf_splits->leaf_index(), feature_index), parent_output, &new_split);
+  if (config_->use_quantized_grad) {
+    const uint8_t hist_bits_bin = gradient_discretizer_->GetHistBitsInLeaf<false>(leaf_splits->leaf_index());
+    histogram_array_[feature_index].FindBestThresholdInt(
+        leaf_splits->int_sum_gradients_and_hessians(),
+        gradient_discretizer_->grad_scale(),
+        gradient_discretizer_->hess_scale(),
+        hist_bits_bin,
+        hist_bits_bin,
+        num_data,
+        constraints_->GetFeatureConstraint(leaf_splits->leaf_index(), feature_index), parent_output, &new_split);
+  } else {
+    histogram_array_[feature_index].FindBestThreshold(
+        leaf_splits->sum_gradients(), leaf_splits->sum_hessians(), num_data,
+        constraints_->GetFeatureConstraint(leaf_splits->leaf_index(), feature_index), parent_output, &new_split);
+  }
   new_split.feature = real_fidx;
   if (cegb_ != nullptr) {
     new_split.gain -=
-        cegb_->DetlaGain(feature_index, real_fidx, leaf_splits->leaf_index(),
+        cegb_->DeltaGain(feature_index, real_fidx, leaf_splits->leaf_index(),
                          num_data, new_split);
   }
   if (new_split.monotone_type != 0) {
     double penalty = constraints_->ComputeMonotoneSplitGainPenalty(
         leaf_splits->leaf_index(), config_->monotone_penalty);
     new_split.gain *= penalty;
   }
```

### Comparing `lightgbm-3.3.5/compile/src/treelearner/serial_tree_learner.h` & `lightgbm-4.0.0/src/treelearner/serial_tree_learner.h`

 * *Files 2% similar despite different names*

```diff
@@ -15,31 +15,33 @@
 
 #include <string>
 #include <cmath>
 #include <cstdio>
 #include <memory>
 #include <random>
 #include <vector>
+#include <set>
 
 #include "col_sampler.hpp"
 #include "data_partition.hpp"
 #include "feature_histogram.hpp"
+#include "gradient_discretizer.hpp"
 #include "leaf_splits.hpp"
 #include "monotone_constraints.hpp"
 #include "split_info.hpp"
 
 #ifdef USE_GPU
 // Use 4KBytes aligned allocator for ordered gradients and ordered Hessians when GPU is enabled.
 // This is necessary to pin the two arrays in memory and make transferring faster.
 #include <boost/align/aligned_allocator.hpp>
 #endif
 
 namespace LightGBM {
 
-using json11::Json;
+using json11_internal_lightgbm::Json;
 
 /*! \brief forward declaration */
 class CostEfficientGradientBoosting;
 
 /*!
 * \brief Used for learning a tree by single machine
 */
@@ -109,15 +111,15 @@
       for (data_size_t j = 0; j < cnt_leaf_data; ++j) {
         out_score[tmp_idx[j]] += output;
       }
     }
   }
 
   void RenewTreeOutput(Tree* tree, const ObjectiveFunction* obj, std::function<double(const label_t*, int)> residual_getter,
-                       data_size_t total_num_data, const data_size_t* bag_indices, data_size_t bag_cnt) const override;
+                       data_size_t total_num_data, const data_size_t* bag_indices, data_size_t bag_cnt, const double* train_score) const override;
 
   /*! \brief Get output of parent node, used for path smoothing */
   double GetParentOutput(const Tree* tree, const LeafSplits* leaf_splits) const;
 
  protected:
   void ComputeBestSplitForFeature(FeatureHistogram* histogram_array_,
                                   int feature_index, int real_fidx,
@@ -138,14 +140,16 @@
   /*!
   * \brief Some initial works before FindBestSplit
   */
   virtual bool BeforeFindBestSplit(const Tree* tree, int left_leaf, int right_leaf);
 
   virtual void FindBestSplits(const Tree* tree);
 
+  virtual void FindBestSplits(const Tree* tree, const std::set<int>* force_features);
+
   virtual void ConstructHistograms(const std::vector<int8_t>& is_feature_used, bool use_subtract);
 
   virtual void FindBestSplitsFromHistograms(const std::vector<int8_t>& is_feature_used, bool use_subtract, const Tree*);
 
   /*!
   * \brief Partition tree and data according best split.
   * \param tree Current tree, will be splitted on this function.
@@ -161,14 +165,18 @@
   void SplitInner(Tree* tree, int best_leaf, int* left_leaf, int* right_leaf,
                   bool update_cnt);
 
   /* Force splits with forced_split_json dict and then return num splits forced.*/
   int32_t ForceSplits(Tree* tree, int* left_leaf, int* right_leaf,
                       int* cur_depth);
 
+  std::set<int> FindAllForceFeatures(Json force_split_leaf_setting);
+
+  void CheckSplit(const SplitInfo& best_split_info, const int left_leaf_index, const int right_leaf_index);
+
   /*!
   * \brief Get the number of data in a leaf
   * \param leaf_idx The index of leaf
   * \return The number of data in the leaf_idx leaf
   */
   inline virtual data_size_t GetGlobalDataCountInLeaf(int leaf_idx) const;
 
@@ -197,20 +205,20 @@
   /*! \brief stores minimum and maximum constraints for each leaf */
   std::unique_ptr<LeafConstraintsBase> constraints_;
 
   /*! \brief stores best thresholds for all feature for smaller leaf */
   std::unique_ptr<LeafSplits> smaller_leaf_splits_;
   /*! \brief stores best thresholds for all feature for larger leaf */
   std::unique_ptr<LeafSplits> larger_leaf_splits_;
-#ifdef USE_GPU
+#if defined(USE_GPU)
   /*! \brief gradients of current iteration, ordered for cache optimized, aligned to 4K page */
   std::vector<score_t, boost::alignment::aligned_allocator<score_t, 4096>> ordered_gradients_;
   /*! \brief hessians of current iteration, ordered for cache optimized, aligned to 4K page */
   std::vector<score_t, boost::alignment::aligned_allocator<score_t, 4096>> ordered_hessians_;
-#elif USE_CUDA
+#elif defined(USE_CUDA)
   /*! \brief gradients of current iteration, ordered for cache optimized */
   std::vector<score_t, CHAllocator<score_t>> ordered_gradients_;
   /*! \brief hessians of current iteration, ordered for cache optimized */
   std::vector<score_t, CHAllocator<score_t>> ordered_hessians_;
 #else
   /*! \brief gradients of current iteration, ordered for cache optimized */
   std::vector<score_t, Common::AlignmentAllocator<score_t, kAlignedSize>> ordered_gradients_;
@@ -221,14 +229,15 @@
   HistogramPool histogram_pool_;
   /*! \brief config of tree learner*/
   const Config* config_;
   ColSampler col_sampler_;
   const Json* forced_split_json_;
   std::unique_ptr<TrainingShareStates> share_state_;
   std::unique_ptr<CostEfficientGradientBoosting> cegb_;
+  std::unique_ptr<GradientDiscretizer> gradient_discretizer_;
 };
 
 inline data_size_t SerialTreeLearner::GetGlobalDataCountInLeaf(int leaf_idx) const {
   if (leaf_idx >= 0) {
     return data_partition_->leaf_count(leaf_idx);
   } else {
     return 0;
```

### Comparing `lightgbm-3.3.5/compile/src/treelearner/split_info.hpp` & `lightgbm-4.0.0/src/treelearner/split_info.hpp`

 * *Files 18% similar despite different names*

```diff
@@ -36,18 +36,22 @@
   double right_output = 0.0;
   /*! \brief Split gain */
   double gain = kMinScore;
   /*! \brief Left sum gradient after split */
   double left_sum_gradient = 0;
   /*! \brief Left sum hessian after split */
   double left_sum_hessian = 0;
+  /*! \brief Left sum discretized gradient and hessian after split */
+  int64_t left_sum_gradient_and_hessian = 0;
   /*! \brief Right sum gradient after split */
   double right_sum_gradient = 0;
   /*! \brief Right sum hessian after split */
   double right_sum_hessian = 0;
+  /*! \brief Right sum discretized gradient and hessian after split */
+  int64_t right_sum_gradient_and_hessian = 0;
   std::vector<uint32_t> cat_threshold;
   /*! \brief True if default split is left */
   bool default_left = true;
   int8_t monotone_type = 0;
   inline static int Size(int max_cat_threshold) {
     return 2 * sizeof(int) + sizeof(uint32_t) + sizeof(bool) + sizeof(double) * 7 + sizeof(data_size_t) * 2 + max_cat_threshold * sizeof(uint32_t) + sizeof(int8_t);
   }
@@ -67,18 +71,22 @@
     buffer += sizeof(left_output);
     std::memcpy(buffer, &right_output, sizeof(right_output));
     buffer += sizeof(right_output);
     std::memcpy(buffer, &left_sum_gradient, sizeof(left_sum_gradient));
     buffer += sizeof(left_sum_gradient);
     std::memcpy(buffer, &left_sum_hessian, sizeof(left_sum_hessian));
     buffer += sizeof(left_sum_hessian);
+    std::memcpy(buffer, &left_sum_gradient_and_hessian, sizeof(left_sum_gradient_and_hessian));
+    buffer += sizeof(left_sum_gradient_and_hessian);
     std::memcpy(buffer, &right_sum_gradient, sizeof(right_sum_gradient));
     buffer += sizeof(right_sum_gradient);
     std::memcpy(buffer, &right_sum_hessian, sizeof(right_sum_hessian));
     buffer += sizeof(right_sum_hessian);
+    std::memcpy(buffer, &right_sum_gradient_and_hessian, sizeof(right_sum_gradient_and_hessian));
+    buffer += sizeof(right_sum_gradient_and_hessian);
     std::memcpy(buffer, &default_left, sizeof(default_left));
     buffer += sizeof(default_left);
     std::memcpy(buffer, &monotone_type, sizeof(monotone_type));
     buffer += sizeof(monotone_type);
     std::memcpy(buffer, &num_cat_threshold, sizeof(num_cat_threshold));
     buffer += sizeof(num_cat_threshold);
     std::memcpy(buffer, cat_threshold.data(), sizeof(uint32_t) * num_cat_threshold);
@@ -99,18 +107,22 @@
     buffer += sizeof(left_output);
     std::memcpy(&right_output, buffer, sizeof(right_output));
     buffer += sizeof(right_output);
     std::memcpy(&left_sum_gradient, buffer, sizeof(left_sum_gradient));
     buffer += sizeof(left_sum_gradient);
     std::memcpy(&left_sum_hessian, buffer, sizeof(left_sum_hessian));
     buffer += sizeof(left_sum_hessian);
+    std::memcpy(&left_sum_gradient_and_hessian, buffer, sizeof(left_sum_gradient_and_hessian));
+    buffer += sizeof(left_sum_gradient_and_hessian);
     std::memcpy(&right_sum_gradient, buffer, sizeof(right_sum_gradient));
     buffer += sizeof(right_sum_gradient);
     std::memcpy(&right_sum_hessian, buffer, sizeof(right_sum_hessian));
     buffer += sizeof(right_sum_hessian);
+    std::memcpy(&right_sum_gradient_and_hessian, buffer, sizeof(right_sum_gradient_and_hessian));
+    buffer += sizeof(right_sum_gradient_and_hessian);
     std::memcpy(&default_left, buffer, sizeof(default_left));
     buffer += sizeof(default_left);
     std::memcpy(&monotone_type, buffer, sizeof(monotone_type));
     buffer += sizeof(monotone_type);
     std::memcpy(&num_cat_threshold, buffer, sizeof(num_cat_threshold));
     buffer += sizeof(num_cat_threshold);
     cat_threshold.resize(num_cat_threshold);
```

### Comparing `lightgbm-3.3.5/compile/src/treelearner/tree_learner.cpp` & `lightgbm-4.0.0/src/treelearner/tree_learner.cpp`

 * *Files 6% similar despite different names*

```diff
@@ -1,23 +1,23 @@
 /*!
  * Copyright (c) 2016 Microsoft Corporation. All rights reserved.
  * Licensed under the MIT License. See LICENSE file in the project root for license information.
  */
 #include <LightGBM/tree_learner.h>
 
-#include "cuda_tree_learner.h"
 #include "gpu_tree_learner.h"
 #include "linear_tree_learner.h"
 #include "parallel_tree_learner.h"
 #include "serial_tree_learner.h"
+#include "cuda/cuda_single_gpu_tree_learner.hpp"
 
 namespace LightGBM {
 
 TreeLearner* TreeLearner::CreateTreeLearner(const std::string& learner_type, const std::string& device_type,
-                                            const Config* config) {
+                                            const Config* config, const bool boosting_on_cuda) {
   if (device_type == std::string("cpu")) {
     if (learner_type == std::string("serial")) {
       if (config->linear_tree) {
         return new LinearTreeLearner(config);
       } else {
         return new SerialTreeLearner(config);
       }
@@ -36,20 +36,20 @@
     } else if (learner_type == std::string("data")) {
       return new DataParallelTreeLearner<GPUTreeLearner>(config);
     } else if (learner_type == std::string("voting")) {
       return new VotingParallelTreeLearner<GPUTreeLearner>(config);
     }
   } else if (device_type == std::string("cuda")) {
     if (learner_type == std::string("serial")) {
-      return new CUDATreeLearner(config);
-    } else if (learner_type == std::string("feature")) {
-      return new FeatureParallelTreeLearner<CUDATreeLearner>(config);
-    } else if (learner_type == std::string("data")) {
-      return new DataParallelTreeLearner<CUDATreeLearner>(config);
-    } else if (learner_type == std::string("voting")) {
-      return new VotingParallelTreeLearner<CUDATreeLearner>(config);
+      if (config->num_gpu == 1) {
+        return new CUDASingleGPUTreeLearner(config, boosting_on_cuda);
+      } else {
+        Log::Fatal("Currently cuda version only supports training on a single GPU.");
+      }
+    } else {
+      Log::Fatal("Currently cuda version only supports training on a single machine.");
     }
   }
   return nullptr;
 }
 
 }  // namespace LightGBM
```

### Comparing `lightgbm-3.3.5/compile/src/treelearner/voting_parallel_tree_learner.cpp` & `lightgbm-4.0.0/src/treelearner/voting_parallel_tree_learner.cpp`

 * *Files 0% similar despite different names*

```diff
@@ -497,11 +497,10 @@
       best_split_info.left_sum_gradient,
       best_split_info.left_sum_hessian,
       best_split_info.left_output);
   }
 }
 
 // instantiate template classes, otherwise linker cannot find the code
-template class VotingParallelTreeLearner<CUDATreeLearner>;
 template class VotingParallelTreeLearner<GPUTreeLearner>;
 template class VotingParallelTreeLearner<SerialTreeLearner>;
 }  // namespace LightGBM
```

### Comparing `lightgbm-3.3.5/compile/windows/LightGBM.sln` & `lightgbm-4.0.0/windows/LightGBM.sln`

 * *Files identical despite different names*

### Comparing `lightgbm-3.3.5/compile/windows/LightGBM.vcxproj` & `lightgbm-4.0.0/windows/LightGBM.vcxproj`

 * *Files 2% similar despite different names*

#### Comparing `lightgbm-3.3.5/compile/windows/LightGBM.vcxproj` & `lightgbm-4.0.0/windows/LightGBM.vcxproj`

```diff
@@ -30,15 +30,15 @@
     <ProjectGuid>{F31C0B5D-715E-4953-AA1B-8D2AEEE4344C}</ProjectGuid>
     <RootNamespace>LightGBM</RootNamespace>
     <SccProjectName>SAK</SccProjectName>
     <SccAuxPath>SAK</SccAuxPath>
     <SccLocalPath>SAK</SccLocalPath>
     <SccProvider>SAK</SccProvider>
     <ProjectName>LightGBM</ProjectName>
-    <WindowsTargetPlatformVersion>8.1</WindowsTargetPlatformVersion>
+    <WindowsTargetPlatformVersion>10.0</WindowsTargetPlatformVersion>
   </PropertyGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.Default.props"/>
   <PropertyGroup Label="Configuration" Condition="'$(Configuration)|$(Platform)'=='Debug_mpi|x64'">
     <PlatformToolset>v140</PlatformToolset>
   </PropertyGroup>
   <PropertyGroup Label="Configuration" Condition="'$(Configuration)|$(Platform)'=='Release|x64'">
     <PlatformToolset>v140</PlatformToolset>
@@ -96,15 +96,15 @@
   </PropertyGroup>
   <PropertyGroup Condition="'$(Configuration)|$(Platform)'=='DLL|x64'">
     <IncludePath>..\include;$(VC_IncludePath);$(WindowsSDK_IncludePath);</IncludePath>
     <TargetName>lib_lightgbm</TargetName>
   </PropertyGroup>
   <ItemDefinitionGroup>
     <ClCompile>
-      <PreprocessorDefinitions>EIGEN_MPL2_ONLY</PreprocessorDefinitions>
+      <PreprocessorDefinitions>EIGEN_MPL2_ONLY;EIGEN_DONT_PARALLELIZE;WIN_HAS_INET_PTON;</PreprocessorDefinitions>
     </ClCompile>
   </ItemDefinitionGroup>
   <ItemDefinitionGroup Condition="'$(Configuration)|$(Platform)'=='Debug_mpi|x64'">
     <ClCompile>
       <PreprocessorDefinitions>USE_MPI;%(PreprocessorDefinitions)</PreprocessorDefinitions>
       <WarningLevel>Level4</WarningLevel>
       <OpenMPSupport>true</OpenMPSupport>
@@ -243,18 +243,21 @@
     <ClInclude Include="..\include\LightGBM\dataset_loader.h"/>
     <ClInclude Include="..\include\LightGBM\feature_group.h"/>
     <ClInclude Include="..\include\LightGBM\meta.h"/>
     <ClInclude Include="..\include\LightGBM\metric.h"/>
     <ClInclude Include="..\include\LightGBM\network.h"/>
     <ClInclude Include="..\include\LightGBM\objective_function.h"/>
     <ClInclude Include="..\include\LightGBM\prediction_early_stop.h"/>
+    <ClInclude Include="..\include\LightGBM\sample_strategy.h"/>
     <ClInclude Include="..\include\LightGBM\tree.h"/>
     <ClInclude Include="..\include\LightGBM\tree_learner.h"/>
     <ClInclude Include="..\include\LightGBM\utils\yamc\alternate_shared_mutex.hpp"/>
     <ClInclude Include="..\include\LightGBM\utils\array_args.h"/>
+    <ClInclude Include="..\include\LightGBM\utils\binary_writer.h"/>
+    <ClInclude Include="..\include\LightGBM\utils\byte_buffer.h"/>
     <ClInclude Include="..\include\LightGBM\utils\common.h"/>
     <ClInclude Include="..\include\LightGBM\utils\file_io.h"/>
     <ClInclude Include="..\include\LightGBM\utils\json11.h"/>
     <ClInclude Include="..\include\LightGBM\utils\locale_context.h"/>
     <ClInclude Include="..\include\LightGBM\utils\log.h"/>
     <ClInclude Include="..\include\LightGBM\utils\openmp_wrapper.h"/>
     <ClInclude Include="..\include\LightGBM\utils\pipeline_reader.h"/>
@@ -293,22 +296,24 @@
     <ClInclude Include="..\src\treelearner\feature_histogram.hpp"/>
     <ClInclude Include="..\src\treelearner\leaf_splits.hpp"/>
     <ClInclude Include="..\src\treelearner\linear_tree_learner.h"/>
     <ClInclude Include="..\src\treelearner\monotone_constraints.hpp"/>
     <ClInclude Include="..\src\treelearner\parallel_tree_learner.h"/>
     <ClInclude Include="..\src\treelearner\serial_tree_learner.h"/>
     <ClInclude Include="..\src\treelearner\split_info.hpp"/>
+    <ClInclude Include="..\src\treelearner\gradient_discretizer.hpp"/>
   </ItemGroup>
   <ItemGroup>
     <ClCompile Include="..\src\application\application.cpp"/>
     <ClCompile Include="..\src\boosting\boosting.cpp"/>
     <ClCompile Include="..\src\boosting\gbdt.cpp"/>
     <ClCompile Include="..\src\boosting\gbdt_model_text.cpp"/>
     <ClCompile Include="..\src\boosting\gbdt_prediction.cpp"/>
     <ClCompile Include="..\src\boosting\prediction_early_stop.cpp"/>
+    <ClCompile Include="..\src\boosting\sample_strategy.cpp"/>
     <ClCompile Include="..\src\c_api.cpp"/>
     <ClCompile Include="..\src\io\bin.cpp"/>
     <ClCompile Include="..\src\io\config.cpp"/>
     <ClCompile Include="..\src\io\config_auto.cpp"/>
     <ClCompile Include="..\src\io\dataset.cpp"/>
     <ClCompile Include="..\src\io\dataset_loader.cpp"/>
     <ClCompile Include="..\src\io\file_io.cpp"/>
@@ -327,11 +332,12 @@
     <ClCompile Include="..\src\main.cpp"/>
     <ClCompile Include="..\src\treelearner\data_parallel_tree_learner.cpp"/>
     <ClCompile Include="..\src\treelearner\feature_parallel_tree_learner.cpp"/>
     <ClCompile Include="..\src\treelearner\linear_tree_learner.cpp"/>
     <ClCompile Include="..\src\treelearner\serial_tree_learner.cpp"/>
     <ClCompile Include="..\src\treelearner\tree_learner.cpp"/>
     <ClCompile Include="..\src\treelearner\voting_parallel_tree_learner.cpp"/>
+    <ClCompile Include="..\src\treelearner\gradient_discretizer.cpp"/>
   </ItemGroup>
   <Import Project="$(VCTargetsPath)\Microsoft.Cpp.targets"/>
   <ImportGroup Label="ExtensionTargets"/>
 </Project>
```

### Comparing `lightgbm-3.3.5/lightgbm/__init__.py` & `lightgbm-4.0.0/lightgbm/__init__.py`

 * *Files 6% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 """LightGBM, Light Gradient Boosting Machine.
 
 Contributors: https://github.com/microsoft/LightGBM/graphs/contributors.
 """
 from pathlib import Path
 
 from .basic import Booster, Dataset, Sequence, register_logger
-from .callback import early_stopping, log_evaluation, print_evaluation, record_evaluation, reset_parameter
+from .callback import early_stopping, log_evaluation, record_evaluation, reset_parameter
 from .engine import CVBooster, cv, train
 
 try:
     from .sklearn import LGBMClassifier, LGBMModel, LGBMRanker, LGBMRegressor
 except ImportError:
     pass
 try:
@@ -28,9 +28,9 @@
     __version__ = _version_path.read_text(encoding='utf-8').strip()
 
 __all__ = ['Dataset', 'Booster', 'CVBooster', 'Sequence',
            'register_logger',
            'train', 'cv',
            'LGBMModel', 'LGBMRegressor', 'LGBMClassifier', 'LGBMRanker',
            'DaskLGBMRegressor', 'DaskLGBMClassifier', 'DaskLGBMRanker',
-           'log_evaluation', 'print_evaluation', 'record_evaluation', 'reset_parameter', 'early_stopping',
+           'log_evaluation', 'record_evaluation', 'reset_parameter', 'early_stopping',
            'plot_importance', 'plot_split_value_histogram', 'plot_metric', 'plot_tree', 'create_tree_digraph']
```

### Comparing `lightgbm-3.3.5/lightgbm/basic.py` & `lightgbm-4.0.0/lightgbm/basic.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,65 +1,172 @@
 # coding: utf-8
 """Wrapper for C API of LightGBM."""
 import abc
 import ctypes
+import inspect
 import json
 import warnings
 from collections import OrderedDict
 from copy import deepcopy
+from enum import Enum
 from functools import wraps
-from logging import Logger
-from os import SEEK_END
+from os import SEEK_END, environ
 from os.path import getsize
 from pathlib import Path
 from tempfile import NamedTemporaryFile
-from typing import Any, Callable, Dict, Iterable, List, Optional, Set, Tuple, Union
+from typing import TYPE_CHECKING, Any, Callable, Dict, Iterable, List, Optional, Set, Tuple, Union
 
 import numpy as np
 import scipy.sparse
 
-from .compat import PANDAS_INSTALLED, concat, dt_DataTable, is_dtype_sparse, pd_DataFrame, pd_Series
+from .compat import PANDAS_INSTALLED, concat, dt_DataTable, pd_CategoricalDtype, pd_DataFrame, pd_Series
 from .libpath import find_lib_path
 
+if TYPE_CHECKING:
+    from typing import Literal
+
+__all__ = [
+    'Booster',
+    'Dataset',
+    'LGBMDeprecationWarning',
+    'LightGBMError',
+    'register_logger',
+    'Sequence',
+]
+
+_DatasetHandle = ctypes.c_void_p
+_ctypes_int_ptr = Union[
+    "ctypes._Pointer[ctypes.c_int32]",
+    "ctypes._Pointer[ctypes.c_int64]"
+]
+_ctypes_int_array = Union[
+    "ctypes.Array[ctypes._Pointer[ctypes.c_int32]]",
+    "ctypes.Array[ctypes._Pointer[ctypes.c_int64]]"
+]
+_ctypes_float_ptr = Union[
+    "ctypes._Pointer[ctypes.c_float]",
+    "ctypes._Pointer[ctypes.c_double]"
+]
+_ctypes_float_array = Union[
+    "ctypes.Array[ctypes._Pointer[ctypes.c_float]]",
+    "ctypes.Array[ctypes._Pointer[ctypes.c_double]]"
+]
+_LGBM_EvalFunctionResultType = Tuple[str, float, bool]
+_LGBM_BoosterBestScoreType = Dict[str, Dict[str, float]]
+_LGBM_BoosterEvalMethodResultType = Tuple[str, str, float, bool]
+_LGBM_CategoricalFeatureConfiguration = Union[List[str], List[int], "Literal['auto']"]
+_LGBM_FeatureNameConfiguration = Union[List[str], "Literal['auto']"]
+_LGBM_GroupType = Union[
+    List[float],
+    List[int],
+    np.ndarray,
+    pd_Series
+]
+_LGBM_InitScoreType = Union[
+    List[float],
+    List[List[float]],
+    np.ndarray,
+    pd_Series,
+    pd_DataFrame,
+]
+_LGBM_TrainDataType = Union[
+    str,
+    Path,
+    np.ndarray,
+    pd_DataFrame,
+    dt_DataTable,
+    scipy.sparse.spmatrix,
+    "Sequence",
+    List["Sequence"],
+    List[np.ndarray]
+]
+_LGBM_LabelType = Union[
+    List[float],
+    List[int],
+    np.ndarray,
+    pd_Series,
+    pd_DataFrame
+]
+_LGBM_PredictDataType = Union[
+    str,
+    Path,
+    np.ndarray,
+    pd_DataFrame,
+    dt_DataTable,
+    scipy.sparse.spmatrix
+]
+_LGBM_WeightType = Union[
+    List[float],
+    List[int],
+    np.ndarray,
+    pd_Series
+]
 ZERO_THRESHOLD = 1e-35
 
 
-def _get_sample_count(total_nrow: int, params: str):
+def _is_zero(x: float) -> bool:
+    return -ZERO_THRESHOLD <= x <= ZERO_THRESHOLD
+
+
+def _get_sample_count(total_nrow: int, params: str) -> int:
     sample_cnt = ctypes.c_int(0)
     _safe_call(_LIB.LGBM_GetSampleCount(
         ctypes.c_int32(total_nrow),
-        c_str(params),
+        _c_str(params),
         ctypes.byref(sample_cnt),
     ))
     return sample_cnt.value
 
 
+class _MissingType(Enum):
+    NONE = 'None'
+    NAN = 'NaN'
+    ZERO = 'Zero'
+
+
 class _DummyLogger:
     def info(self, msg: str) -> None:
         print(msg)
 
     def warning(self, msg: str) -> None:
         warnings.warn(msg, stacklevel=3)
 
 
-_LOGGER: Union[_DummyLogger, Logger] = _DummyLogger()
+_LOGGER: Any = _DummyLogger()
+_INFO_METHOD_NAME = "info"
+_WARNING_METHOD_NAME = "warning"
+
 
+def _has_method(logger: Any, method_name: str) -> bool:
+    return callable(getattr(logger, method_name, None))
 
-def register_logger(logger: Logger) -> None:
+
+def register_logger(
+    logger: Any, info_method_name: str = "info", warning_method_name: str = "warning"
+) -> None:
     """Register custom logger.
 
     Parameters
     ----------
-    logger : logging.Logger
+    logger : Any
         Custom logger.
+    info_method_name : str, optional (default="info")
+        Method used to log info messages.
+    warning_method_name : str, optional (default="warning")
+        Method used to log warning messages.
     """
-    if not isinstance(logger, Logger):
-        raise TypeError("Logger should inherit logging.Logger class")
-    global _LOGGER
+    if not _has_method(logger, info_method_name) or not _has_method(logger, warning_method_name):
+        raise TypeError(
+            f"Logger must provide '{info_method_name}' and '{warning_method_name}' method"
+        )
+
+    global _LOGGER, _INFO_METHOD_NAME, _WARNING_METHOD_NAME
     _LOGGER = logger
+    _INFO_METHOD_NAME = info_method_name
+    _WARNING_METHOD_NAME = warning_method_name
 
 
 def _normalize_native_string(func: Callable[[str], None]) -> Callable[[str], None]:
     """Join log messages from native library which come by chunks."""
     msg_normalized: List[str] = []
 
     @wraps(func)
@@ -72,227 +179,241 @@
         else:
             msg_normalized.append(msg)
 
     return wrapper
 
 
 def _log_info(msg: str) -> None:
-    _LOGGER.info(msg)
+    getattr(_LOGGER, _INFO_METHOD_NAME)(msg)
 
 
 def _log_warning(msg: str) -> None:
-    _LOGGER.warning(msg)
+    getattr(_LOGGER, _WARNING_METHOD_NAME)(msg)
 
 
 @_normalize_native_string
 def _log_native(msg: str) -> None:
-    _LOGGER.info(msg)
+    getattr(_LOGGER, _INFO_METHOD_NAME)(msg)
 
 
 def _log_callback(msg: bytes) -> None:
     """Redirect logs from native library into Python."""
     _log_native(str(msg.decode('utf-8')))
 
 
-def _load_lib():
+def _load_lib() -> ctypes.CDLL:
     """Load LightGBM library."""
     lib_path = find_lib_path()
-    if len(lib_path) == 0:
-        return None
     lib = ctypes.cdll.LoadLibrary(lib_path[0])
     lib.LGBM_GetLastError.restype = ctypes.c_char_p
     callback = ctypes.CFUNCTYPE(None, ctypes.c_char_p)
-    lib.callback = callback(_log_callback)
+    lib.callback = callback(_log_callback)  # type: ignore[attr-defined]
     if lib.LGBM_RegisterLogCallback(lib.callback) != 0:
         raise LightGBMError(lib.LGBM_GetLastError().decode('utf-8'))
     return lib
 
 
-_LIB = _load_lib()
+# we don't need lib_lightgbm while building docs
+_LIB: ctypes.CDLL
+if environ.get('LIGHTGBM_BUILD_DOC', False):
+    from unittest.mock import Mock  # isort: skip
+    _LIB = Mock(ctypes.CDLL)  # type: ignore
+else:
+    _LIB = _load_lib()
 
 
-NUMERIC_TYPES = (int, float, bool)
+_NUMERIC_TYPES = (int, float, bool)
+_ArrayLike = Union[List, np.ndarray, pd_Series]
 
 
 def _safe_call(ret: int) -> None:
     """Check the return value from C API call.
 
     Parameters
     ----------
     ret : int
         The return value from C API calls.
     """
     if ret != 0:
         raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))
 
 
-def is_numeric(obj):
+def _is_numeric(obj: Any) -> bool:
     """Check whether object is a number or not, include numpy number, etc."""
     try:
         float(obj)
         return True
     except (TypeError, ValueError):
         # TypeError: obj is not a string or a number
         # ValueError: invalid literal
         return False
 
 
-def is_numpy_1d_array(data):
+def _is_numpy_1d_array(data: Any) -> bool:
     """Check whether data is a numpy 1-D array."""
     return isinstance(data, np.ndarray) and len(data.shape) == 1
 
 
-def is_numpy_column_array(data):
+def _is_numpy_column_array(data: Any) -> bool:
     """Check whether data is a column numpy array."""
     if not isinstance(data, np.ndarray):
         return False
     shape = data.shape
     return len(shape) == 2 and shape[1] == 1
 
 
-def cast_numpy_array_to_dtype(array, dtype):
+def _cast_numpy_array_to_dtype(array: np.ndarray, dtype: "np.typing.DTypeLike") -> np.ndarray:
     """Cast numpy array to given dtype."""
     if array.dtype == dtype:
         return array
     return array.astype(dtype=dtype, copy=False)
 
 
-def is_1d_list(data):
+def _is_1d_list(data: Any) -> bool:
     """Check whether data is a 1-D list."""
-    return isinstance(data, list) and (not data or is_numeric(data[0]))
+    return isinstance(data, list) and (not data or _is_numeric(data[0]))
 
 
 def _is_1d_collection(data: Any) -> bool:
     """Check whether data is a 1-D collection."""
     return (
-        is_numpy_1d_array(data)
-        or is_numpy_column_array(data)
-        or is_1d_list(data)
+        _is_numpy_1d_array(data)
+        or _is_numpy_column_array(data)
+        or _is_1d_list(data)
         or isinstance(data, pd_Series)
     )
 
 
-def list_to_1d_numpy(data, dtype=np.float32, name='list'):
+def _list_to_1d_numpy(
+    data: Any,
+    dtype: "np.typing.DTypeLike",
+    name: str
+) -> np.ndarray:
     """Convert data to numpy 1-D array."""
-    if is_numpy_1d_array(data):
-        return cast_numpy_array_to_dtype(data, dtype)
-    elif is_numpy_column_array(data):
+    if _is_numpy_1d_array(data):
+        return _cast_numpy_array_to_dtype(data, dtype)
+    elif _is_numpy_column_array(data):
         _log_warning('Converting column-vector to 1d array')
         array = data.ravel()
-        return cast_numpy_array_to_dtype(array, dtype)
-    elif is_1d_list(data):
+        return _cast_numpy_array_to_dtype(array, dtype)
+    elif _is_1d_list(data):
         return np.array(data, dtype=dtype, copy=False)
     elif isinstance(data, pd_Series):
-        if _get_bad_pandas_dtypes([data.dtypes]):
-            raise ValueError('Series.dtypes must be int, float or bool')
+        _check_for_bad_pandas_dtypes(data.to_frame().dtypes)
         return np.array(data, dtype=dtype, copy=False)  # SparseArray should be supported as well
     else:
         raise TypeError(f"Wrong type({type(data).__name__}) for {name}.\n"
                         "It should be list, numpy 1-D array or pandas Series")
 
 
 def _is_numpy_2d_array(data: Any) -> bool:
     """Check whether data is a numpy 2-D array."""
     return isinstance(data, np.ndarray) and len(data.shape) == 2 and data.shape[1] > 1
 
 
 def _is_2d_list(data: Any) -> bool:
     """Check whether data is a 2-D list."""
-    return isinstance(data, list) and len(data) > 0 and is_1d_list(data[0])
+    return isinstance(data, list) and len(data) > 0 and _is_1d_list(data[0])
 
 
 def _is_2d_collection(data: Any) -> bool:
     """Check whether data is a 2-D collection."""
     return (
         _is_numpy_2d_array(data)
         or _is_2d_list(data)
         or isinstance(data, pd_DataFrame)
     )
 
 
-def _data_to_2d_numpy(data: Any, dtype: type = np.float32, name: str = 'list') -> np.ndarray:
+def _data_to_2d_numpy(
+    data: Any,
+    dtype: "np.typing.DTypeLike",
+    name: str
+) -> np.ndarray:
     """Convert data to numpy 2-D array."""
     if _is_numpy_2d_array(data):
-        return cast_numpy_array_to_dtype(data, dtype)
+        return _cast_numpy_array_to_dtype(data, dtype)
     if _is_2d_list(data):
         return np.array(data, dtype=dtype)
     if isinstance(data, pd_DataFrame):
-        if _get_bad_pandas_dtypes(data.dtypes):
-            raise ValueError('DataFrame.dtypes must be int, float or bool')
-        return cast_numpy_array_to_dtype(data.values, dtype)
+        _check_for_bad_pandas_dtypes(data.dtypes)
+        return _cast_numpy_array_to_dtype(data.values, dtype)
     raise TypeError(f"Wrong type({type(data).__name__}) for {name}.\n"
                     "It should be list of lists, numpy 2-D array or pandas DataFrame")
 
 
-def cfloat32_array_to_numpy(cptr, length):
+def _cfloat32_array_to_numpy(cptr: "ctypes._Pointer", length: int) -> np.ndarray:
     """Convert a ctypes float pointer array to a numpy array."""
     if isinstance(cptr, ctypes.POINTER(ctypes.c_float)):
         return np.ctypeslib.as_array(cptr, shape=(length,)).copy()
     else:
         raise RuntimeError('Expected float pointer')
 
 
-def cfloat64_array_to_numpy(cptr, length):
+def _cfloat64_array_to_numpy(cptr: "ctypes._Pointer", length: int) -> np.ndarray:
     """Convert a ctypes double pointer array to a numpy array."""
     if isinstance(cptr, ctypes.POINTER(ctypes.c_double)):
         return np.ctypeslib.as_array(cptr, shape=(length,)).copy()
     else:
         raise RuntimeError('Expected double pointer')
 
 
-def cint32_array_to_numpy(cptr, length):
+def _cint32_array_to_numpy(cptr: "ctypes._Pointer", length: int) -> np.ndarray:
     """Convert a ctypes int pointer array to a numpy array."""
     if isinstance(cptr, ctypes.POINTER(ctypes.c_int32)):
         return np.ctypeslib.as_array(cptr, shape=(length,)).copy()
     else:
         raise RuntimeError('Expected int32 pointer')
 
 
-def cint64_array_to_numpy(cptr, length):
+def _cint64_array_to_numpy(cptr: "ctypes._Pointer", length: int) -> np.ndarray:
     """Convert a ctypes int pointer array to a numpy array."""
     if isinstance(cptr, ctypes.POINTER(ctypes.c_int64)):
         return np.ctypeslib.as_array(cptr, shape=(length,)).copy()
     else:
         raise RuntimeError('Expected int64 pointer')
 
 
-def c_str(string):
+def _c_str(string: str) -> ctypes.c_char_p:
     """Convert a Python string to C string."""
     return ctypes.c_char_p(string.encode('utf-8'))
 
 
-def c_array(ctype, values):
+def _c_array(ctype: type, values: List[Any]) -> ctypes.Array:
     """Convert a Python array to C array."""
-    return (ctype * len(values))(*values)
+    return (ctype * len(values))(*values)  # type: ignore[operator]
 
 
-def json_default_with_numpy(obj):
+def _json_default_with_numpy(obj: Any) -> Any:
     """Convert numpy classes to JSON serializable objects."""
     if isinstance(obj, (np.integer, np.floating, np.bool_)):
         return obj.item()
     elif isinstance(obj, np.ndarray):
         return obj.tolist()
     else:
         return obj
 
 
-def param_dict_to_str(data):
+def _to_string(x: Union[int, float, str, List]) -> str:
+    if isinstance(x, list):
+        val_list = ",".join(str(val) for val in x)
+        return f"[{val_list}]"
+    else:
+        return str(x)
+
+
+def _param_dict_to_str(data: Optional[Dict[str, Any]]) -> str:
     """Convert Python dictionary to string, which is passed to C API."""
     if data is None or not data:
         return ""
     pairs = []
     for key, val in data.items():
-        if isinstance(val, (list, tuple, set)) or is_numpy_1d_array(val):
-            def to_string(x):
-                if isinstance(x, list):
-                    return f"[{','.join(map(str, x))}]"
-                else:
-                    return str(x)
-            pairs.append(f"{key}={','.join(map(to_string, val))}")
-        elif isinstance(val, (str, Path, NUMERIC_TYPES)) or is_numeric(val):
+        if isinstance(val, (list, tuple, set)) or _is_numpy_1d_array(val):
+            pairs.append(f"{key}={','.join(map(_to_string, val))}")
+        elif isinstance(val, (str, Path, _NUMERIC_TYPES)) or _is_numeric(val):
             pairs.append(f"{key}={val}")
         elif val is not None:
             raise TypeError(f'Unknown type of parameter:{key}, got:{type(val).__name__}')
     return ' '.join(pairs)
 
 
 class _TempFile:
@@ -319,111 +440,67 @@
 class LGBMDeprecationWarning(UserWarning):
     """Custom deprecation warning."""
 
     pass
 
 
 class _ConfigAliases:
-    aliases = {"bin_construct_sample_cnt": {"bin_construct_sample_cnt",
-                                            "subsample_for_bin"},
-               "boosting": {"boosting",
-                            "boosting_type",
-                            "boost"},
-               "categorical_feature": {"categorical_feature",
-                                       "cat_feature",
-                                       "categorical_column",
-                                       "cat_column",
-                                       "categorical_features"},
-               "data_random_seed": {"data_random_seed",
-                                    "data_seed"},
-               "early_stopping_round": {"early_stopping_round",
-                                        "early_stopping_rounds",
-                                        "early_stopping",
-                                        "n_iter_no_change"},
-               "enable_bundle": {"enable_bundle",
-                                 "is_enable_bundle",
-                                 "bundle"},
-               "eval_at": {"eval_at",
-                           "ndcg_eval_at",
-                           "ndcg_at",
-                           "map_eval_at",
-                           "map_at"},
-               "group_column": {"group_column",
-                                "group",
-                                "group_id",
-                                "query_column",
-                                "query",
-                                "query_id"},
-               "header": {"header",
-                          "has_header"},
-               "ignore_column": {"ignore_column",
-                                 "ignore_feature",
-                                 "blacklist"},
-               "is_enable_sparse": {"is_enable_sparse",
-                                    "is_sparse",
-                                    "enable_sparse",
-                                    "sparse"},
-               "label_column": {"label_column",
-                                "label"},
-               "linear_tree": {"linear_tree",
-                               "linear_trees"},
-               "local_listen_port": {"local_listen_port",
-                                     "local_port",
-                                     "port"},
-               "machines": {"machines",
-                            "workers",
-                            "nodes"},
-               "max_bin": {"max_bin",
-                           "max_bins"},
-               "metric": {"metric",
-                          "metrics",
-                          "metric_types"},
-               "num_class": {"num_class",
-                             "num_classes"},
-               "num_iterations": {"num_iterations",
-                                  "num_iteration",
-                                  "n_iter",
-                                  "num_tree",
-                                  "num_trees",
-                                  "num_round",
-                                  "num_rounds",
-                                  "num_boost_round",
-                                  "n_estimators",
-                                  "max_iter"},
-               "num_machines": {"num_machines",
-                                "num_machine"},
-               "num_threads": {"num_threads",
-                               "num_thread",
-                               "nthread",
-                               "nthreads",
-                               "n_jobs"},
-               "objective": {"objective",
-                             "objective_type",
-                             "app",
-                             "application",
-                             "loss"},
-               "pre_partition": {"pre_partition",
-                                 "is_pre_partition"},
-               "tree_learner": {"tree_learner",
-                                "tree",
-                                "tree_type",
-                                "tree_learner_type"},
-               "two_round": {"two_round",
-                             "two_round_loading",
-                             "use_two_round_loading"},
-               "verbosity": {"verbosity",
-                             "verbose"},
-               "weight_column": {"weight_column",
-                                 "weight"}}
+    # lazy evaluation to allow import without dynamic library, e.g., for docs generation
+    aliases = None
+
+    @staticmethod
+    def _get_all_param_aliases() -> Dict[str, List[str]]:
+        buffer_len = 1 << 20
+        tmp_out_len = ctypes.c_int64(0)
+        string_buffer = ctypes.create_string_buffer(buffer_len)
+        ptr_string_buffer = ctypes.c_char_p(*[ctypes.addressof(string_buffer)])
+        _safe_call(_LIB.LGBM_DumpParamAliases(
+            ctypes.c_int64(buffer_len),
+            ctypes.byref(tmp_out_len),
+            ptr_string_buffer))
+        actual_len = tmp_out_len.value
+        # if buffer length is not long enough, re-allocate a buffer
+        if actual_len > buffer_len:
+            string_buffer = ctypes.create_string_buffer(actual_len)
+            ptr_string_buffer = ctypes.c_char_p(*[ctypes.addressof(string_buffer)])
+            _safe_call(_LIB.LGBM_DumpParamAliases(
+                ctypes.c_int64(actual_len),
+                ctypes.byref(tmp_out_len),
+                ptr_string_buffer))
+        aliases = json.loads(
+            string_buffer.value.decode('utf-8'),
+            object_hook=lambda obj: {k: [k] + v for k, v in obj.items()}
+        )
+        return aliases
 
     @classmethod
-    def get(cls, *args):
+    def get(cls, *args) -> Set[str]:
+        if cls.aliases is None:
+            cls.aliases = cls._get_all_param_aliases()
         ret = set()
         for i in args:
-            ret |= cls.aliases.get(i, {i})
+            ret.update(cls.get_sorted(i))
+        return ret
+
+    @classmethod
+    def get_sorted(cls, name: str) -> List[str]:
+        if cls.aliases is None:
+            cls.aliases = cls._get_all_param_aliases()
+        return cls.aliases.get(name, [name])
+
+    @classmethod
+    def get_by_alias(cls, *args) -> Set[str]:
+        if cls.aliases is None:
+            cls.aliases = cls._get_all_param_aliases()
+        ret = set(args)
+        for arg in args:
+            for aliases in cls.aliases.values():
+                if arg in aliases:
+                    ret.update(aliases)
+                    break
         return ret
 
 
 def _choose_param_value(main_param_name: str, params: Dict[str, Any], default_value: Any) -> Dict[str, Any]:
     """Get a single parameter value, accounting for aliases.
 
     Parameters
@@ -440,195 +517,226 @@
     params : dict
         A ``params`` dict with exactly one value for ``main_param_name``, and all aliases ``main_param_name`` removed.
         If both ``main_param_name`` and one or more aliases for it are found, the value of ``main_param_name`` will be preferred.
     """
     # avoid side effects on passed-in parameters
     params = deepcopy(params)
 
-    # find a value, and remove other aliases with .pop()
-    # prefer the value of 'main_param_name' if it exists, otherwise search the aliases
-    found_value = None
+    aliases = _ConfigAliases.get_sorted(main_param_name)
+    aliases = [a for a in aliases if a != main_param_name]
+
+    # if main_param_name was provided, keep that value and remove all aliases
     if main_param_name in params.keys():
-        found_value = params[main_param_name]
+        for param in aliases:
+            params.pop(param, None)
+        return params
+
+    # if main param name was not found, search for an alias
+    for param in aliases:
+        if param in params.keys():
+            params[main_param_name] = params[param]
+            break
 
-    for param in _ConfigAliases.get(main_param_name):
-        val = params.pop(param, None)
-        if found_value is None and val is not None:
-            found_value = val
+    if main_param_name in params.keys():
+        for param in aliases:
+            params.pop(param, None)
+        return params
 
-    if found_value is not None:
-        params[main_param_name] = found_value
-    else:
-        params[main_param_name] = default_value
+    # neither of main_param_name, aliases were found
+    params[main_param_name] = default_value
 
     return params
 
 
-MAX_INT32 = (1 << 31) - 1
+_MAX_INT32 = (1 << 31) - 1
 
 """Macro definition of data type in C API of LightGBM"""
-C_API_DTYPE_FLOAT32 = 0
-C_API_DTYPE_FLOAT64 = 1
-C_API_DTYPE_INT32 = 2
-C_API_DTYPE_INT64 = 3
+_C_API_DTYPE_FLOAT32 = 0
+_C_API_DTYPE_FLOAT64 = 1
+_C_API_DTYPE_INT32 = 2
+_C_API_DTYPE_INT64 = 3
 
 """Matrix is row major in Python"""
-C_API_IS_ROW_MAJOR = 1
+_C_API_IS_ROW_MAJOR = 1
 
 """Macro definition of prediction type in C API of LightGBM"""
-C_API_PREDICT_NORMAL = 0
-C_API_PREDICT_RAW_SCORE = 1
-C_API_PREDICT_LEAF_INDEX = 2
-C_API_PREDICT_CONTRIB = 3
+_C_API_PREDICT_NORMAL = 0
+_C_API_PREDICT_RAW_SCORE = 1
+_C_API_PREDICT_LEAF_INDEX = 2
+_C_API_PREDICT_CONTRIB = 3
 
 """Macro definition of sparse matrix type"""
-C_API_MATRIX_TYPE_CSR = 0
-C_API_MATRIX_TYPE_CSC = 1
+_C_API_MATRIX_TYPE_CSR = 0
+_C_API_MATRIX_TYPE_CSC = 1
 
 """Macro definition of feature importance type"""
-C_API_FEATURE_IMPORTANCE_SPLIT = 0
-C_API_FEATURE_IMPORTANCE_GAIN = 1
+_C_API_FEATURE_IMPORTANCE_SPLIT = 0
+_C_API_FEATURE_IMPORTANCE_GAIN = 1
 
 """Data type of data field"""
-FIELD_TYPE_MAPPER = {"label": C_API_DTYPE_FLOAT32,
-                     "weight": C_API_DTYPE_FLOAT32,
-                     "init_score": C_API_DTYPE_FLOAT64,
-                     "group": C_API_DTYPE_INT32}
+_FIELD_TYPE_MAPPER = {
+    "label": _C_API_DTYPE_FLOAT32,
+    "weight": _C_API_DTYPE_FLOAT32,
+    "init_score": _C_API_DTYPE_FLOAT64,
+    "group": _C_API_DTYPE_INT32
+}
 
 """String name to int feature importance type mapper"""
-FEATURE_IMPORTANCE_TYPE_MAPPER = {"split": C_API_FEATURE_IMPORTANCE_SPLIT,
-                                  "gain": C_API_FEATURE_IMPORTANCE_GAIN}
+_FEATURE_IMPORTANCE_TYPE_MAPPER = {
+    "split": _C_API_FEATURE_IMPORTANCE_SPLIT,
+    "gain": _C_API_FEATURE_IMPORTANCE_GAIN
+}
 
 
-def convert_from_sliced_object(data):
+def _convert_from_sliced_object(data: np.ndarray) -> np.ndarray:
     """Fix the memory of multi-dimensional sliced object."""
     if isinstance(data, np.ndarray) and isinstance(data.base, np.ndarray):
         if not data.flags.c_contiguous:
             _log_warning("Usage of np.ndarray subset (sliced data) is not recommended "
                          "due to it will double the peak memory cost in LightGBM.")
             return np.copy(data)
     return data
 
 
-def c_float_array(data):
+def _c_float_array(
+    data: np.ndarray
+) -> Tuple[_ctypes_float_ptr, int, np.ndarray]:
     """Get pointer of float numpy array / list."""
-    if is_1d_list(data):
+    if _is_1d_list(data):
         data = np.array(data, copy=False)
-    if is_numpy_1d_array(data):
-        data = convert_from_sliced_object(data)
+    if _is_numpy_1d_array(data):
+        data = _convert_from_sliced_object(data)
         assert data.flags.c_contiguous
+        ptr_data: _ctypes_float_ptr
         if data.dtype == np.float32:
             ptr_data = data.ctypes.data_as(ctypes.POINTER(ctypes.c_float))
-            type_data = C_API_DTYPE_FLOAT32
+            type_data = _C_API_DTYPE_FLOAT32
         elif data.dtype == np.float64:
             ptr_data = data.ctypes.data_as(ctypes.POINTER(ctypes.c_double))
-            type_data = C_API_DTYPE_FLOAT64
+            type_data = _C_API_DTYPE_FLOAT64
         else:
             raise TypeError(f"Expected np.float32 or np.float64, met type({data.dtype})")
     else:
         raise TypeError(f"Unknown type({type(data).__name__})")
     return (ptr_data, type_data, data)  # return `data` to avoid the temporary copy is freed
 
 
-def c_int_array(data):
+def _c_int_array(
+    data: np.ndarray
+) -> Tuple[_ctypes_int_ptr, int, np.ndarray]:
     """Get pointer of int numpy array / list."""
-    if is_1d_list(data):
+    if _is_1d_list(data):
         data = np.array(data, copy=False)
-    if is_numpy_1d_array(data):
-        data = convert_from_sliced_object(data)
+    if _is_numpy_1d_array(data):
+        data = _convert_from_sliced_object(data)
         assert data.flags.c_contiguous
+        ptr_data: _ctypes_int_ptr
         if data.dtype == np.int32:
             ptr_data = data.ctypes.data_as(ctypes.POINTER(ctypes.c_int32))
-            type_data = C_API_DTYPE_INT32
+            type_data = _C_API_DTYPE_INT32
         elif data.dtype == np.int64:
             ptr_data = data.ctypes.data_as(ctypes.POINTER(ctypes.c_int64))
-            type_data = C_API_DTYPE_INT64
+            type_data = _C_API_DTYPE_INT64
         else:
             raise TypeError(f"Expected np.int32 or np.int64, met type({data.dtype})")
     else:
         raise TypeError(f"Unknown type({type(data).__name__})")
     return (ptr_data, type_data, data)  # return `data` to avoid the temporary copy is freed
 
 
-def _get_bad_pandas_dtypes(dtypes):
-    pandas_dtype_mapper = {'int8': 'int', 'int16': 'int', 'int32': 'int',
-                           'int64': 'int', 'uint8': 'int', 'uint16': 'int',
-                           'uint32': 'int', 'uint64': 'int', 'bool': 'int',
-                           'float16': 'float', 'float32': 'float', 'float64': 'float'}
-    bad_indices = [i for i, dtype in enumerate(dtypes) if (dtype.name not in pandas_dtype_mapper
-                                                           and (not is_dtype_sparse(dtype)
-                                                                or dtype.subtype.name not in pandas_dtype_mapper))]
-    return bad_indices
+def _is_allowed_numpy_dtype(dtype: type) -> bool:
+    float128 = getattr(np, 'float128', type(None))
+    return (
+        issubclass(dtype, (np.integer, np.floating, np.bool_))
+        and not issubclass(dtype, (np.timedelta64, float128))
+    )
 
 
-def _data_from_pandas(data, feature_name, categorical_feature, pandas_categorical):
+def _check_for_bad_pandas_dtypes(pandas_dtypes_series: pd_Series) -> None:
+    bad_pandas_dtypes = [
+        f'{column_name}: {pandas_dtype}'
+        for column_name, pandas_dtype in pandas_dtypes_series.items()
+        if not _is_allowed_numpy_dtype(pandas_dtype.type)
+    ]
+    if bad_pandas_dtypes:
+        raise ValueError('pandas dtypes must be int, float or bool.\n'
+                         f'Fields with bad pandas dtypes: {", ".join(bad_pandas_dtypes)}')
+
+
+def _data_from_pandas(
+    data,
+    feature_name: Optional[_LGBM_FeatureNameConfiguration],
+    categorical_feature: Optional[_LGBM_CategoricalFeatureConfiguration],
+    pandas_categorical: Optional[List[List]]
+):
     if isinstance(data, pd_DataFrame):
         if len(data.shape) != 2 or data.shape[0] < 1:
             raise ValueError('Input data must be 2 dimensional and non empty.')
         if feature_name == 'auto' or feature_name is None:
-            data = data.rename(columns=str)
-        cat_cols = list(data.select_dtypes(include=['category']).columns)
+            data = data.rename(columns=str, copy=False)
+        cat_cols = [col for col, dtype in zip(data.columns, data.dtypes) if isinstance(dtype, pd_CategoricalDtype)]
         cat_cols_not_ordered = [col for col in cat_cols if not data[col].cat.ordered]
         if pandas_categorical is None:  # train dataset
             pandas_categorical = [list(data[col].cat.categories) for col in cat_cols]
         else:
             if len(cat_cols) != len(pandas_categorical):
                 raise ValueError('train and valid dataset categorical_feature do not match.')
             for col, category in zip(cat_cols, pandas_categorical):
                 if list(data[col].cat.categories) != list(category):
                     data[col] = data[col].cat.set_categories(category)
         if len(cat_cols):  # cat_cols is list
-            data = data.copy()  # not alter origin DataFrame
+            data = data.copy(deep=False)  # not alter origin DataFrame
             data[cat_cols] = data[cat_cols].apply(lambda x: x.cat.codes).replace({-1: np.nan})
         if categorical_feature is not None:
             if feature_name is None:
                 feature_name = list(data.columns)
             if categorical_feature == 'auto':  # use cat cols from DataFrame
                 categorical_feature = cat_cols_not_ordered
             else:  # use cat cols specified by user
-                categorical_feature = list(categorical_feature)
+                categorical_feature = list(categorical_feature)  # type: ignore[assignment]
         if feature_name == 'auto':
             feature_name = list(data.columns)
-        bad_indices = _get_bad_pandas_dtypes(data.dtypes)
-        if bad_indices:
-            bad_index_cols_str = ', '.join(data.columns[bad_indices])
-            raise ValueError("DataFrame.dtypes for data must be int, float or bool.\n"
-                             "Did not expect the data types in the following fields: "
-                             f"{bad_index_cols_str}")
-        data = data.values
-        if data.dtype != np.float32 and data.dtype != np.float64:
-            data = data.astype(np.float32)
+        _check_for_bad_pandas_dtypes(data.dtypes)
+        df_dtypes = [dtype.type for dtype in data.dtypes]
+        df_dtypes.append(np.float32)  # so that the target dtype considers floats
+        target_dtype = np.find_common_type(df_dtypes, [])
+        try:
+            # most common case (no nullable dtypes)
+            data = data.to_numpy(dtype=target_dtype, copy=False)
+        except TypeError:
+            # 1.0 <= pd version < 1.1 and nullable dtypes, least common case
+            # raises error because array is casted to type(pd.NA) and there's no na_value argument
+            data = data.astype(target_dtype, copy=False).values
+        except ValueError:
+            # data has nullable dtypes, but we can specify na_value argument and copy will be made
+            data = data.to_numpy(dtype=target_dtype, na_value=np.nan)
     else:
         if feature_name == 'auto':
             feature_name = None
         if categorical_feature == 'auto':
             categorical_feature = None
     return data, feature_name, categorical_feature, pandas_categorical
 
 
-def _label_from_pandas(label):
-    if isinstance(label, pd_DataFrame):
-        if len(label.columns) > 1:
-            raise ValueError('DataFrame for label cannot have multiple columns')
-        if _get_bad_pandas_dtypes(label.dtypes):
-            raise ValueError('DataFrame.dtypes for label must be int, float or bool')
-        label = np.ravel(label.values.astype(np.float32, copy=False))
-    return label
-
-
-def _dump_pandas_categorical(pandas_categorical, file_name=None):
-    categorical_json = json.dumps(pandas_categorical, default=json_default_with_numpy)
+def _dump_pandas_categorical(
+    pandas_categorical: Optional[List[List]],
+    file_name: Optional[Union[str, Path]] = None
+) -> str:
+    categorical_json = json.dumps(pandas_categorical, default=_json_default_with_numpy)
     pandas_str = f'\npandas_categorical:{categorical_json}\n'
     if file_name is not None:
         with open(file_name, 'a') as f:
             f.write(pandas_str)
     return pandas_str
 
 
-def _load_pandas_categorical(file_name=None, model_str=None):
+def _load_pandas_categorical(
+    file_name: Optional[Union[str, Path]] = None,
+    model_str: Optional[str] = None
+) -> Optional[List[List]]:
     pandas_key = 'pandas_categorical:'
     offset = -len(pandas_key)
     if file_name is not None:
         max_offset = -getsize(file_name)
         with open(file_name, 'rb') as f:
             while True:
                 if offset < max_offset:
@@ -701,15 +809,15 @@
         Parameters
         ----------
         idx : int, slice[int], list[int]
             Item index.
 
         Returns
         -------
-        result : numpy 1-D array, numpy 2-D array
+        result : numpy 1-D array or numpy 2-D array
             1-D array if idx is int, 2-D array if idx is slice or list.
         """
         raise NotImplementedError("Sub-classes of lightgbm.Sequence must implement __getitem__()")
 
     @abc.abstractmethod
     def __len__(self) -> int:
         """Return row count of this sequence."""
@@ -723,73 +831,87 @@
     Used only for prediction, usually used for continued training.
 
     .. note::
 
         Can be converted from Booster, but cannot be converted to Booster.
     """
 
-    def __init__(self, model_file=None, booster_handle=None, pred_parameter=None):
+    def __init__(
+        self,
+        model_file: Optional[Union[str, Path]] = None,
+        booster_handle: Optional[ctypes.c_void_p] = None,
+        pred_parameter: Optional[Dict[str, Any]] = None
+    ):
         """Initialize the _InnerPredictor.
 
         Parameters
         ----------
         model_file : str, pathlib.Path or None, optional (default=None)
             Path to the model file.
         booster_handle : object or None, optional (default=None)
             Handle of Booster.
         pred_parameter: dict or None, optional (default=None)
             Other parameters for the prediction.
         """
-        self.handle = ctypes.c_void_p()
+        self._handle = ctypes.c_void_p()
         self.__is_manage_handle = True
         if model_file is not None:
             """Prediction task"""
             out_num_iterations = ctypes.c_int(0)
             _safe_call(_LIB.LGBM_BoosterCreateFromModelfile(
-                c_str(str(model_file)),
+                _c_str(str(model_file)),
                 ctypes.byref(out_num_iterations),
-                ctypes.byref(self.handle)))
+                ctypes.byref(self._handle)))
             out_num_class = ctypes.c_int(0)
             _safe_call(_LIB.LGBM_BoosterGetNumClasses(
-                self.handle,
+                self._handle,
                 ctypes.byref(out_num_class)))
             self.num_class = out_num_class.value
             self.num_total_iteration = out_num_iterations.value
             self.pandas_categorical = _load_pandas_categorical(file_name=model_file)
         elif booster_handle is not None:
             self.__is_manage_handle = False
-            self.handle = booster_handle
+            self._handle = booster_handle
             out_num_class = ctypes.c_int(0)
             _safe_call(_LIB.LGBM_BoosterGetNumClasses(
-                self.handle,
+                self._handle,
                 ctypes.byref(out_num_class)))
             self.num_class = out_num_class.value
             self.num_total_iteration = self.current_iteration()
             self.pandas_categorical = None
         else:
             raise TypeError('Need model_file or booster_handle to create a predictor')
 
         pred_parameter = {} if pred_parameter is None else pred_parameter
-        self.pred_parameter = param_dict_to_str(pred_parameter)
+        self.pred_parameter = _param_dict_to_str(pred_parameter)
 
-    def __del__(self):
+    def __del__(self) -> None:
         try:
             if self.__is_manage_handle:
-                _safe_call(_LIB.LGBM_BoosterFree(self.handle))
+                _safe_call(_LIB.LGBM_BoosterFree(self._handle))
         except AttributeError:
             pass
 
-    def __getstate__(self):
+    def __getstate__(self) -> Dict[str, Any]:
         this = self.__dict__.copy()
         this.pop('handle', None)
+        this.pop('_handle', None)
         return this
 
-    def predict(self, data, start_iteration=0, num_iteration=-1,
-                raw_score=False, pred_leaf=False, pred_contrib=False, data_has_header=False,
-                is_reshape=True):
+    def predict(
+        self,
+        data: _LGBM_PredictDataType,
+        start_iteration: int = 0,
+        num_iteration: int = -1,
+        raw_score: bool = False,
+        pred_leaf: bool = False,
+        pred_contrib: bool = False,
+        data_has_header: bool = False,
+        validate_features: bool = False
+    ) -> Union[np.ndarray, scipy.sparse.spmatrix, List[scipy.sparse.spmatrix]]:
         """Predict logic.
 
         Parameters
         ----------
         data : str, pathlib.Path, numpy array, pandas DataFrame, H2O DataTable's Frame or scipy.sparse
             Data source for prediction.
             If str or pathlib.Path, it represents the path to a text file (CSV, TSV, or LibSVM).
@@ -802,163 +924,251 @@
         pred_leaf : bool, optional (default=False)
             Whether to predict leaf index.
         pred_contrib : bool, optional (default=False)
             Whether to predict feature contributions.
         data_has_header : bool, optional (default=False)
             Whether data has header.
             Used only for txt data.
-        is_reshape : bool, optional (default=True)
-            Whether to reshape to (nrow, ncol).
+        validate_features : bool, optional (default=False)
+            If True, ensure that the features used to predict match the ones used to train.
+            Used only if data is pandas DataFrame.
+
+            .. versionadded:: 4.0.0
 
         Returns
         -------
         result : numpy array, scipy.sparse or list of scipy.sparse
             Prediction result.
             Can be sparse or a list of sparse objects (each element represents predictions for one class) for feature contributions (when ``pred_contrib=True``).
         """
         if isinstance(data, Dataset):
             raise TypeError("Cannot use Dataset instance for prediction, please use raw data instead")
+        elif isinstance(data, pd_DataFrame) and validate_features:
+            data_names = [str(x) for x in data.columns]
+            ptr_names = (ctypes.c_char_p * len(data_names))()
+            ptr_names[:] = [x.encode('utf-8') for x in data_names]
+            _safe_call(
+                _LIB.LGBM_BoosterValidateFeatureNames(
+                    self._handle,
+                    ptr_names,
+                    ctypes.c_int(len(data_names)),
+                )
+            )
         data = _data_from_pandas(data, None, None, self.pandas_categorical)[0]
-        predict_type = C_API_PREDICT_NORMAL
+        predict_type = _C_API_PREDICT_NORMAL
         if raw_score:
-            predict_type = C_API_PREDICT_RAW_SCORE
+            predict_type = _C_API_PREDICT_RAW_SCORE
         if pred_leaf:
-            predict_type = C_API_PREDICT_LEAF_INDEX
+            predict_type = _C_API_PREDICT_LEAF_INDEX
         if pred_contrib:
-            predict_type = C_API_PREDICT_CONTRIB
-        int_data_has_header = 1 if data_has_header else 0
+            predict_type = _C_API_PREDICT_CONTRIB
 
         if isinstance(data, (str, Path)):
             with _TempFile() as f:
                 _safe_call(_LIB.LGBM_BoosterPredictForFile(
-                    self.handle,
-                    c_str(str(data)),
-                    ctypes.c_int(int_data_has_header),
+                    self._handle,
+                    _c_str(str(data)),
+                    ctypes.c_int(data_has_header),
                     ctypes.c_int(predict_type),
                     ctypes.c_int(start_iteration),
                     ctypes.c_int(num_iteration),
-                    c_str(self.pred_parameter),
-                    c_str(f.name)))
+                    _c_str(self.pred_parameter),
+                    _c_str(f.name)))
                 preds = np.loadtxt(f.name, dtype=np.float64)
                 nrow = preds.shape[0]
         elif isinstance(data, scipy.sparse.csr_matrix):
-            preds, nrow = self.__pred_for_csr(data, start_iteration, num_iteration, predict_type)
+            preds, nrow = self.__pred_for_csr(
+                csr=data,
+                start_iteration=start_iteration,
+                num_iteration=num_iteration,
+                predict_type=predict_type
+            )
         elif isinstance(data, scipy.sparse.csc_matrix):
-            preds, nrow = self.__pred_for_csc(data, start_iteration, num_iteration, predict_type)
+            preds, nrow = self.__pred_for_csc(
+                csc=data,
+                start_iteration=start_iteration,
+                num_iteration=num_iteration,
+                predict_type=predict_type
+            )
         elif isinstance(data, np.ndarray):
-            preds, nrow = self.__pred_for_np2d(data, start_iteration, num_iteration, predict_type)
+            preds, nrow = self.__pred_for_np2d(
+                mat=data,
+                start_iteration=start_iteration,
+                num_iteration=num_iteration,
+                predict_type=predict_type
+            )
         elif isinstance(data, list):
             try:
                 data = np.array(data)
-            except BaseException:
-                raise ValueError('Cannot convert data list to numpy array.')
-            preds, nrow = self.__pred_for_np2d(data, start_iteration, num_iteration, predict_type)
+            except BaseException as err:
+                raise ValueError('Cannot convert data list to numpy array.') from err
+            preds, nrow = self.__pred_for_np2d(
+                mat=data,
+                start_iteration=start_iteration,
+                num_iteration=num_iteration,
+                predict_type=predict_type
+            )
         elif isinstance(data, dt_DataTable):
-            preds, nrow = self.__pred_for_np2d(data.to_numpy(), start_iteration, num_iteration, predict_type)
+            preds, nrow = self.__pred_for_np2d(
+                mat=data.to_numpy(),
+                start_iteration=start_iteration,
+                num_iteration=num_iteration,
+                predict_type=predict_type
+            )
         else:
             try:
                 _log_warning('Converting data to scipy sparse matrix.')
                 csr = scipy.sparse.csr_matrix(data)
-            except BaseException:
-                raise TypeError(f'Cannot predict data for type {type(data).__name__}')
-            preds, nrow = self.__pred_for_csr(csr, start_iteration, num_iteration, predict_type)
+            except BaseException as err:
+                raise TypeError(f'Cannot predict data for type {type(data).__name__}') from err
+            preds, nrow = self.__pred_for_csr(
+                csr=csr,
+                start_iteration=start_iteration,
+                num_iteration=num_iteration,
+                predict_type=predict_type
+            )
         if pred_leaf:
             preds = preds.astype(np.int32)
-        is_sparse = scipy.sparse.issparse(preds) or isinstance(preds, list)
-        if is_reshape and not is_sparse and preds.size != nrow:
+        is_sparse = isinstance(preds, scipy.sparse.spmatrix) or isinstance(preds, list)
+        if not is_sparse and preds.size != nrow:
             if preds.size % nrow == 0:
                 preds = preds.reshape(nrow, -1)
             else:
                 raise ValueError(f'Length of predict result ({preds.size}) cannot be divide nrow ({nrow})')
         return preds
 
-    def __get_num_preds(self, start_iteration, num_iteration, nrow, predict_type):
+    def __get_num_preds(
+        self,
+        start_iteration: int,
+        num_iteration: int,
+        nrow: int,
+        predict_type: int
+    ) -> int:
         """Get size of prediction result."""
-        if nrow > MAX_INT32:
+        if nrow > _MAX_INT32:
             raise LightGBMError('LightGBM cannot perform prediction for data '
-                                f'with number of rows greater than MAX_INT32 ({MAX_INT32}).\n'
+                                f'with number of rows greater than MAX_INT32 ({_MAX_INT32}).\n'
                                 'You can split your data into chunks '
                                 'and then concatenate predictions for them')
         n_preds = ctypes.c_int64(0)
         _safe_call(_LIB.LGBM_BoosterCalcNumPredict(
-            self.handle,
+            self._handle,
             ctypes.c_int(nrow),
             ctypes.c_int(predict_type),
             ctypes.c_int(start_iteration),
             ctypes.c_int(num_iteration),
             ctypes.byref(n_preds)))
         return n_preds.value
 
-    def __pred_for_np2d(self, mat, start_iteration, num_iteration, predict_type):
+    def __inner_predict_np2d(
+        self,
+        mat: np.ndarray,
+        start_iteration: int,
+        num_iteration: int,
+        predict_type: int,
+        preds: Optional[np.ndarray]
+    ) -> Tuple[np.ndarray, int]:
+        if mat.dtype == np.float32 or mat.dtype == np.float64:
+            data = np.array(mat.reshape(mat.size), dtype=mat.dtype, copy=False)
+        else:  # change non-float data to float data, need to copy
+            data = np.array(mat.reshape(mat.size), dtype=np.float32)
+        ptr_data, type_ptr_data, _ = _c_float_array(data)
+        n_preds = self.__get_num_preds(
+            start_iteration=start_iteration,
+            num_iteration=num_iteration,
+            nrow=mat.shape[0],
+            predict_type=predict_type
+        )
+        if preds is None:
+            preds = np.empty(n_preds, dtype=np.float64)
+        elif len(preds.shape) != 1 or len(preds) != n_preds:
+            raise ValueError("Wrong length of pre-allocated predict array")
+        out_num_preds = ctypes.c_int64(0)
+        _safe_call(_LIB.LGBM_BoosterPredictForMat(
+            self._handle,
+            ptr_data,
+            ctypes.c_int(type_ptr_data),
+            ctypes.c_int32(mat.shape[0]),
+            ctypes.c_int32(mat.shape[1]),
+            ctypes.c_int(_C_API_IS_ROW_MAJOR),
+            ctypes.c_int(predict_type),
+            ctypes.c_int(start_iteration),
+            ctypes.c_int(num_iteration),
+            _c_str(self.pred_parameter),
+            ctypes.byref(out_num_preds),
+            preds.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))
+        if n_preds != out_num_preds.value:
+            raise ValueError("Wrong length for predict results")
+        return preds, mat.shape[0]
+
+    def __pred_for_np2d(
+        self,
+        mat: np.ndarray,
+        start_iteration: int,
+        num_iteration: int,
+        predict_type: int
+    ) -> Tuple[np.ndarray, int]:
         """Predict for a 2-D numpy matrix."""
         if len(mat.shape) != 2:
             raise ValueError('Input numpy.ndarray or list must be 2 dimensional')
 
-        def inner_predict(mat, start_iteration, num_iteration, predict_type, preds=None):
-            if mat.dtype == np.float32 or mat.dtype == np.float64:
-                data = np.array(mat.reshape(mat.size), dtype=mat.dtype, copy=False)
-            else:  # change non-float data to float data, need to copy
-                data = np.array(mat.reshape(mat.size), dtype=np.float32)
-            ptr_data, type_ptr_data, _ = c_float_array(data)
-            n_preds = self.__get_num_preds(start_iteration, num_iteration, mat.shape[0], predict_type)
-            if preds is None:
-                preds = np.empty(n_preds, dtype=np.float64)
-            elif len(preds.shape) != 1 or len(preds) != n_preds:
-                raise ValueError("Wrong length of pre-allocated predict array")
-            out_num_preds = ctypes.c_int64(0)
-            _safe_call(_LIB.LGBM_BoosterPredictForMat(
-                self.handle,
-                ptr_data,
-                ctypes.c_int(type_ptr_data),
-                ctypes.c_int32(mat.shape[0]),
-                ctypes.c_int32(mat.shape[1]),
-                ctypes.c_int(C_API_IS_ROW_MAJOR),
-                ctypes.c_int(predict_type),
-                ctypes.c_int(start_iteration),
-                ctypes.c_int(num_iteration),
-                c_str(self.pred_parameter),
-                ctypes.byref(out_num_preds),
-                preds.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))
-            if n_preds != out_num_preds.value:
-                raise ValueError("Wrong length for predict results")
-            return preds, mat.shape[0]
-
         nrow = mat.shape[0]
-        if nrow > MAX_INT32:
-            sections = np.arange(start=MAX_INT32, stop=nrow, step=MAX_INT32)
+        if nrow > _MAX_INT32:
+            sections = np.arange(start=_MAX_INT32, stop=nrow, step=_MAX_INT32)
             # __get_num_preds() cannot work with nrow > MAX_INT32, so calculate overall number of predictions piecemeal
             n_preds = [self.__get_num_preds(start_iteration, num_iteration, i, predict_type) for i in np.diff([0] + list(sections) + [nrow])]
             n_preds_sections = np.array([0] + n_preds, dtype=np.intp).cumsum()
             preds = np.empty(sum(n_preds), dtype=np.float64)
             for chunk, (start_idx_pred, end_idx_pred) in zip(np.array_split(mat, sections),
                                                              zip(n_preds_sections, n_preds_sections[1:])):
                 # avoid memory consumption by arrays concatenation operations
-                inner_predict(chunk, start_iteration, num_iteration, predict_type, preds[start_idx_pred:end_idx_pred])
+                self.__inner_predict_np2d(
+                    mat=chunk,
+                    start_iteration=start_iteration,
+                    num_iteration=num_iteration,
+                    predict_type=predict_type,
+                    preds=preds[start_idx_pred:end_idx_pred]
+                )
             return preds, nrow
         else:
-            return inner_predict(mat, start_iteration, num_iteration, predict_type)
+            return self.__inner_predict_np2d(
+                mat=mat,
+                start_iteration=start_iteration,
+                num_iteration=num_iteration,
+                predict_type=predict_type,
+                preds=None
+            )
 
-    def __create_sparse_native(self, cs, out_shape, out_ptr_indptr, out_ptr_indices, out_ptr_data,
-                               indptr_type, data_type, is_csr=True):
+    def __create_sparse_native(
+        self,
+        cs: Union[scipy.sparse.csc_matrix, scipy.sparse.csr_matrix],
+        out_shape: np.ndarray,
+        out_ptr_indptr: "ctypes._Pointer",
+        out_ptr_indices: "ctypes._Pointer",
+        out_ptr_data: "ctypes._Pointer",
+        indptr_type: int,
+        data_type: int,
+        is_csr: bool
+    ) -> Union[List[scipy.sparse.csc_matrix], List[scipy.sparse.csr_matrix]]:
         # create numpy array from output arrays
         data_indices_len = out_shape[0]
         indptr_len = out_shape[1]
-        if indptr_type == C_API_DTYPE_INT32:
-            out_indptr = cint32_array_to_numpy(out_ptr_indptr, indptr_len)
-        elif indptr_type == C_API_DTYPE_INT64:
-            out_indptr = cint64_array_to_numpy(out_ptr_indptr, indptr_len)
+        if indptr_type == _C_API_DTYPE_INT32:
+            out_indptr = _cint32_array_to_numpy(out_ptr_indptr, indptr_len)
+        elif indptr_type == _C_API_DTYPE_INT64:
+            out_indptr = _cint64_array_to_numpy(out_ptr_indptr, indptr_len)
         else:
             raise TypeError("Expected int32 or int64 type for indptr")
-        if data_type == C_API_DTYPE_FLOAT32:
-            out_data = cfloat32_array_to_numpy(out_ptr_data, data_indices_len)
-        elif data_type == C_API_DTYPE_FLOAT64:
-            out_data = cfloat64_array_to_numpy(out_ptr_data, data_indices_len)
+        if data_type == _C_API_DTYPE_FLOAT32:
+            out_data = _cfloat32_array_to_numpy(out_ptr_data, data_indices_len)
+        elif data_type == _C_API_DTYPE_FLOAT64:
+            out_data = _cfloat64_array_to_numpy(out_ptr_data, data_indices_len)
         else:
             raise TypeError("Expected float32 or float64 type for data")
-        out_indices = cint32_array_to_numpy(out_ptr_indices, data_indices_len)
+        out_indices = _cint32_array_to_numpy(out_ptr_indices, data_indices_len)
         # break up indptr based on number of rows (note more than one matrix in multiclass case)
         per_class_indptr_shape = cs.indptr.shape[0]
         # for CSC there is extra column added
         if not is_csr:
             per_class_indptr_shape += 1
         out_indptr_arrays = np.split(out_indptr, out_indptr.shape[0] / per_class_indptr_shape)
         # reformat output into a csr or csc matrix or list of csr or csc matrices
@@ -979,268 +1189,361 @@
         # free the temporary native indptr, indices, and data
         _safe_call(_LIB.LGBM_BoosterFreePredictSparse(out_ptr_indptr, out_ptr_indices, out_ptr_data,
                                                       ctypes.c_int(indptr_type), ctypes.c_int(data_type)))
         if len(cs_output_matrices) == 1:
             return cs_output_matrices[0]
         return cs_output_matrices
 
-    def __pred_for_csr(self, csr, start_iteration, num_iteration, predict_type):
-        """Predict for a CSR data."""
-        def inner_predict(csr, start_iteration, num_iteration, predict_type, preds=None):
-            nrow = len(csr.indptr) - 1
-            n_preds = self.__get_num_preds(start_iteration, num_iteration, nrow, predict_type)
-            if preds is None:
-                preds = np.empty(n_preds, dtype=np.float64)
-            elif len(preds.shape) != 1 or len(preds) != n_preds:
-                raise ValueError("Wrong length of pre-allocated predict array")
-            out_num_preds = ctypes.c_int64(0)
-
-            ptr_indptr, type_ptr_indptr, __ = c_int_array(csr.indptr)
-            ptr_data, type_ptr_data, _ = c_float_array(csr.data)
-
-            assert csr.shape[1] <= MAX_INT32
-            csr_indices = csr.indices.astype(np.int32, copy=False)
-
-            _safe_call(_LIB.LGBM_BoosterPredictForCSR(
-                self.handle,
-                ptr_indptr,
-                ctypes.c_int(type_ptr_indptr),
-                csr_indices.ctypes.data_as(ctypes.POINTER(ctypes.c_int32)),
-                ptr_data,
-                ctypes.c_int(type_ptr_data),
-                ctypes.c_int64(len(csr.indptr)),
-                ctypes.c_int64(len(csr.data)),
-                ctypes.c_int64(csr.shape[1]),
-                ctypes.c_int(predict_type),
-                ctypes.c_int(start_iteration),
-                ctypes.c_int(num_iteration),
-                c_str(self.pred_parameter),
-                ctypes.byref(out_num_preds),
-                preds.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))
-            if n_preds != out_num_preds.value:
-                raise ValueError("Wrong length for predict results")
-            return preds, nrow
+    def __inner_predict_csr(
+        self,
+        csr: scipy.sparse.csr_matrix,
+        start_iteration: int,
+        num_iteration: int,
+        predict_type: int,
+        preds: Optional[np.ndarray]
+    ) -> Tuple[np.ndarray, int]:
+        nrow = len(csr.indptr) - 1
+        n_preds = self.__get_num_preds(
+            start_iteration=start_iteration,
+            num_iteration=num_iteration,
+            nrow=nrow,
+            predict_type=predict_type
+        )
+        if preds is None:
+            preds = np.empty(n_preds, dtype=np.float64)
+        elif len(preds.shape) != 1 or len(preds) != n_preds:
+            raise ValueError("Wrong length of pre-allocated predict array")
+        out_num_preds = ctypes.c_int64(0)
 
-        def inner_predict_sparse(csr, start_iteration, num_iteration, predict_type):
-            ptr_indptr, type_ptr_indptr, __ = c_int_array(csr.indptr)
-            ptr_data, type_ptr_data, _ = c_float_array(csr.data)
-            csr_indices = csr.indices.astype(np.int32, copy=False)
-            matrix_type = C_API_MATRIX_TYPE_CSR
-            if type_ptr_indptr == C_API_DTYPE_INT32:
-                out_ptr_indptr = ctypes.POINTER(ctypes.c_int32)()
-            else:
-                out_ptr_indptr = ctypes.POINTER(ctypes.c_int64)()
-            out_ptr_indices = ctypes.POINTER(ctypes.c_int32)()
-            if type_ptr_data == C_API_DTYPE_FLOAT32:
-                out_ptr_data = ctypes.POINTER(ctypes.c_float)()
-            else:
-                out_ptr_data = ctypes.POINTER(ctypes.c_double)()
-            out_shape = np.empty(2, dtype=np.int64)
-            _safe_call(_LIB.LGBM_BoosterPredictSparseOutput(
-                self.handle,
-                ptr_indptr,
-                ctypes.c_int(type_ptr_indptr),
-                csr_indices.ctypes.data_as(ctypes.POINTER(ctypes.c_int32)),
-                ptr_data,
-                ctypes.c_int(type_ptr_data),
-                ctypes.c_int64(len(csr.indptr)),
-                ctypes.c_int64(len(csr.data)),
-                ctypes.c_int64(csr.shape[1]),
-                ctypes.c_int(predict_type),
-                ctypes.c_int(start_iteration),
-                ctypes.c_int(num_iteration),
-                c_str(self.pred_parameter),
-                ctypes.c_int(matrix_type),
-                out_shape.ctypes.data_as(ctypes.POINTER(ctypes.c_int64)),
-                ctypes.byref(out_ptr_indptr),
-                ctypes.byref(out_ptr_indices),
-                ctypes.byref(out_ptr_data)))
-            matrices = self.__create_sparse_native(csr, out_shape, out_ptr_indptr, out_ptr_indices, out_ptr_data,
-                                                   type_ptr_indptr, type_ptr_data, is_csr=True)
-            nrow = len(csr.indptr) - 1
-            return matrices, nrow
+        ptr_indptr, type_ptr_indptr, _ = _c_int_array(csr.indptr)
+        ptr_data, type_ptr_data, _ = _c_float_array(csr.data)
+
+        assert csr.shape[1] <= _MAX_INT32
+        csr_indices = csr.indices.astype(np.int32, copy=False)
+
+        _safe_call(_LIB.LGBM_BoosterPredictForCSR(
+            self._handle,
+            ptr_indptr,
+            ctypes.c_int(type_ptr_indptr),
+            csr_indices.ctypes.data_as(ctypes.POINTER(ctypes.c_int32)),
+            ptr_data,
+            ctypes.c_int(type_ptr_data),
+            ctypes.c_int64(len(csr.indptr)),
+            ctypes.c_int64(len(csr.data)),
+            ctypes.c_int64(csr.shape[1]),
+            ctypes.c_int(predict_type),
+            ctypes.c_int(start_iteration),
+            ctypes.c_int(num_iteration),
+            _c_str(self.pred_parameter),
+            ctypes.byref(out_num_preds),
+            preds.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))
+        if n_preds != out_num_preds.value:
+            raise ValueError("Wrong length for predict results")
+        return preds, nrow
 
-        if predict_type == C_API_PREDICT_CONTRIB:
-            return inner_predict_sparse(csr, start_iteration, num_iteration, predict_type)
+    def __inner_predict_csr_sparse(
+        self,
+        csr: scipy.sparse.csr_matrix,
+        start_iteration: int,
+        num_iteration: int,
+        predict_type: int
+    ) -> Tuple[Union[List[scipy.sparse.csc_matrix], List[scipy.sparse.csr_matrix]], int]:
+        ptr_indptr, type_ptr_indptr, __ = _c_int_array(csr.indptr)
+        ptr_data, type_ptr_data, _ = _c_float_array(csr.data)
+        csr_indices = csr.indices.astype(np.int32, copy=False)
+        matrix_type = _C_API_MATRIX_TYPE_CSR
+        out_ptr_indptr: _ctypes_int_ptr
+        if type_ptr_indptr == _C_API_DTYPE_INT32:
+            out_ptr_indptr = ctypes.POINTER(ctypes.c_int32)()
+        else:
+            out_ptr_indptr = ctypes.POINTER(ctypes.c_int64)()
+        out_ptr_indices = ctypes.POINTER(ctypes.c_int32)()
+        out_ptr_data: _ctypes_float_ptr
+        if type_ptr_data == _C_API_DTYPE_FLOAT32:
+            out_ptr_data = ctypes.POINTER(ctypes.c_float)()
+        else:
+            out_ptr_data = ctypes.POINTER(ctypes.c_double)()
+        out_shape = np.empty(2, dtype=np.int64)
+        _safe_call(_LIB.LGBM_BoosterPredictSparseOutput(
+            self._handle,
+            ptr_indptr,
+            ctypes.c_int(type_ptr_indptr),
+            csr_indices.ctypes.data_as(ctypes.POINTER(ctypes.c_int32)),
+            ptr_data,
+            ctypes.c_int(type_ptr_data),
+            ctypes.c_int64(len(csr.indptr)),
+            ctypes.c_int64(len(csr.data)),
+            ctypes.c_int64(csr.shape[1]),
+            ctypes.c_int(predict_type),
+            ctypes.c_int(start_iteration),
+            ctypes.c_int(num_iteration),
+            _c_str(self.pred_parameter),
+            ctypes.c_int(matrix_type),
+            out_shape.ctypes.data_as(ctypes.POINTER(ctypes.c_int64)),
+            ctypes.byref(out_ptr_indptr),
+            ctypes.byref(out_ptr_indices),
+            ctypes.byref(out_ptr_data)))
+        matrices = self.__create_sparse_native(
+            cs=csr,
+            out_shape=out_shape,
+            out_ptr_indptr=out_ptr_indptr,
+            out_ptr_indices=out_ptr_indices,
+            out_ptr_data=out_ptr_data,
+            indptr_type=type_ptr_indptr,
+            data_type=type_ptr_data,
+            is_csr=True
+        )
+        nrow = len(csr.indptr) - 1
+        return matrices, nrow
+
+    def __pred_for_csr(
+        self,
+        csr: scipy.sparse.csr_matrix,
+        start_iteration: int,
+        num_iteration: int,
+        predict_type: int
+    ) -> Tuple[np.ndarray, int]:
+        """Predict for a CSR data."""
+        if predict_type == _C_API_PREDICT_CONTRIB:
+            return self.__inner_predict_csr_sparse(
+                csr=csr,
+                start_iteration=start_iteration,
+                num_iteration=num_iteration,
+                predict_type=predict_type
+            )
         nrow = len(csr.indptr) - 1
-        if nrow > MAX_INT32:
-            sections = [0] + list(np.arange(start=MAX_INT32, stop=nrow, step=MAX_INT32)) + [nrow]
+        if nrow > _MAX_INT32:
+            sections = [0] + list(np.arange(start=_MAX_INT32, stop=nrow, step=_MAX_INT32)) + [nrow]
             # __get_num_preds() cannot work with nrow > MAX_INT32, so calculate overall number of predictions piecemeal
             n_preds = [self.__get_num_preds(start_iteration, num_iteration, i, predict_type) for i in np.diff(sections)]
             n_preds_sections = np.array([0] + n_preds, dtype=np.intp).cumsum()
             preds = np.empty(sum(n_preds), dtype=np.float64)
             for (start_idx, end_idx), (start_idx_pred, end_idx_pred) in zip(zip(sections, sections[1:]),
                                                                             zip(n_preds_sections, n_preds_sections[1:])):
                 # avoid memory consumption by arrays concatenation operations
-                inner_predict(csr[start_idx:end_idx], start_iteration, num_iteration, predict_type, preds[start_idx_pred:end_idx_pred])
+                self.__inner_predict_csr(
+                    csr=csr[start_idx:end_idx],
+                    start_iteration=start_iteration,
+                    num_iteration=num_iteration,
+                    predict_type=predict_type,
+                    preds=preds[start_idx_pred:end_idx_pred]
+                )
             return preds, nrow
         else:
-            return inner_predict(csr, start_iteration, num_iteration, predict_type)
+            return self.__inner_predict_csr(
+                csr=csr,
+                start_iteration=start_iteration,
+                num_iteration=num_iteration,
+                predict_type=predict_type,
+                preds=None
+            )
 
-    def __pred_for_csc(self, csc, start_iteration, num_iteration, predict_type):
-        """Predict for a CSC data."""
-        def inner_predict_sparse(csc, start_iteration, num_iteration, predict_type):
-            ptr_indptr, type_ptr_indptr, __ = c_int_array(csc.indptr)
-            ptr_data, type_ptr_data, _ = c_float_array(csc.data)
-            csc_indices = csc.indices.astype(np.int32, copy=False)
-            matrix_type = C_API_MATRIX_TYPE_CSC
-            if type_ptr_indptr == C_API_DTYPE_INT32:
-                out_ptr_indptr = ctypes.POINTER(ctypes.c_int32)()
-            else:
-                out_ptr_indptr = ctypes.POINTER(ctypes.c_int64)()
-            out_ptr_indices = ctypes.POINTER(ctypes.c_int32)()
-            if type_ptr_data == C_API_DTYPE_FLOAT32:
-                out_ptr_data = ctypes.POINTER(ctypes.c_float)()
-            else:
-                out_ptr_data = ctypes.POINTER(ctypes.c_double)()
-            out_shape = np.empty(2, dtype=np.int64)
-            _safe_call(_LIB.LGBM_BoosterPredictSparseOutput(
-                self.handle,
-                ptr_indptr,
-                ctypes.c_int(type_ptr_indptr),
-                csc_indices.ctypes.data_as(ctypes.POINTER(ctypes.c_int32)),
-                ptr_data,
-                ctypes.c_int(type_ptr_data),
-                ctypes.c_int64(len(csc.indptr)),
-                ctypes.c_int64(len(csc.data)),
-                ctypes.c_int64(csc.shape[0]),
-                ctypes.c_int(predict_type),
-                ctypes.c_int(start_iteration),
-                ctypes.c_int(num_iteration),
-                c_str(self.pred_parameter),
-                ctypes.c_int(matrix_type),
-                out_shape.ctypes.data_as(ctypes.POINTER(ctypes.c_int64)),
-                ctypes.byref(out_ptr_indptr),
-                ctypes.byref(out_ptr_indices),
-                ctypes.byref(out_ptr_data)))
-            matrices = self.__create_sparse_native(csc, out_shape, out_ptr_indptr, out_ptr_indices, out_ptr_data,
-                                                   type_ptr_indptr, type_ptr_data, is_csr=False)
-            nrow = csc.shape[0]
-            return matrices, nrow
+    def __inner_predict_sparse_csc(
+        self,
+        csc: scipy.sparse.csc_matrix,
+        start_iteration: int,
+        num_iteration: int,
+        predict_type: int
+    ):
+        ptr_indptr, type_ptr_indptr, __ = _c_int_array(csc.indptr)
+        ptr_data, type_ptr_data, _ = _c_float_array(csc.data)
+        csc_indices = csc.indices.astype(np.int32, copy=False)
+        matrix_type = _C_API_MATRIX_TYPE_CSC
+        out_ptr_indptr: _ctypes_int_ptr
+        if type_ptr_indptr == _C_API_DTYPE_INT32:
+            out_ptr_indptr = ctypes.POINTER(ctypes.c_int32)()
+        else:
+            out_ptr_indptr = ctypes.POINTER(ctypes.c_int64)()
+        out_ptr_indices = ctypes.POINTER(ctypes.c_int32)()
+        out_ptr_data: _ctypes_float_ptr
+        if type_ptr_data == _C_API_DTYPE_FLOAT32:
+            out_ptr_data = ctypes.POINTER(ctypes.c_float)()
+        else:
+            out_ptr_data = ctypes.POINTER(ctypes.c_double)()
+        out_shape = np.empty(2, dtype=np.int64)
+        _safe_call(_LIB.LGBM_BoosterPredictSparseOutput(
+            self._handle,
+            ptr_indptr,
+            ctypes.c_int(type_ptr_indptr),
+            csc_indices.ctypes.data_as(ctypes.POINTER(ctypes.c_int32)),
+            ptr_data,
+            ctypes.c_int(type_ptr_data),
+            ctypes.c_int64(len(csc.indptr)),
+            ctypes.c_int64(len(csc.data)),
+            ctypes.c_int64(csc.shape[0]),
+            ctypes.c_int(predict_type),
+            ctypes.c_int(start_iteration),
+            ctypes.c_int(num_iteration),
+            _c_str(self.pred_parameter),
+            ctypes.c_int(matrix_type),
+            out_shape.ctypes.data_as(ctypes.POINTER(ctypes.c_int64)),
+            ctypes.byref(out_ptr_indptr),
+            ctypes.byref(out_ptr_indices),
+            ctypes.byref(out_ptr_data)))
+        matrices = self.__create_sparse_native(
+            cs=csc,
+            out_shape=out_shape,
+            out_ptr_indptr=out_ptr_indptr,
+            out_ptr_indices=out_ptr_indices,
+            out_ptr_data=out_ptr_data,
+            indptr_type=type_ptr_indptr,
+            data_type=type_ptr_data,
+            is_csr=False
+        )
+        nrow = csc.shape[0]
+        return matrices, nrow
 
+    def __pred_for_csc(
+        self,
+        csc: scipy.sparse.csc_matrix,
+        start_iteration: int,
+        num_iteration: int,
+        predict_type: int
+    ) -> Tuple[np.ndarray, int]:
+        """Predict for a CSC data."""
         nrow = csc.shape[0]
-        if nrow > MAX_INT32:
-            return self.__pred_for_csr(csc.tocsr(), start_iteration, num_iteration, predict_type)
-        if predict_type == C_API_PREDICT_CONTRIB:
-            return inner_predict_sparse(csc, start_iteration, num_iteration, predict_type)
-        n_preds = self.__get_num_preds(start_iteration, num_iteration, nrow, predict_type)
+        if nrow > _MAX_INT32:
+            return self.__pred_for_csr(
+                csr=csc.tocsr(),
+                start_iteration=start_iteration,
+                num_iteration=num_iteration,
+                predict_type=predict_type
+            )
+        if predict_type == _C_API_PREDICT_CONTRIB:
+            return self.__inner_predict_sparse_csc(
+                csc=csc,
+                start_iteration=start_iteration,
+                num_iteration=num_iteration,
+                predict_type=predict_type
+            )
+        n_preds = self.__get_num_preds(
+            start_iteration=start_iteration,
+            num_iteration=num_iteration,
+            nrow=nrow,
+            predict_type=predict_type
+        )
         preds = np.empty(n_preds, dtype=np.float64)
         out_num_preds = ctypes.c_int64(0)
 
-        ptr_indptr, type_ptr_indptr, __ = c_int_array(csc.indptr)
-        ptr_data, type_ptr_data, _ = c_float_array(csc.data)
+        ptr_indptr, type_ptr_indptr, __ = _c_int_array(csc.indptr)
+        ptr_data, type_ptr_data, _ = _c_float_array(csc.data)
 
-        assert csc.shape[0] <= MAX_INT32
+        assert csc.shape[0] <= _MAX_INT32
         csc_indices = csc.indices.astype(np.int32, copy=False)
 
         _safe_call(_LIB.LGBM_BoosterPredictForCSC(
-            self.handle,
+            self._handle,
             ptr_indptr,
             ctypes.c_int(type_ptr_indptr),
             csc_indices.ctypes.data_as(ctypes.POINTER(ctypes.c_int32)),
             ptr_data,
             ctypes.c_int(type_ptr_data),
             ctypes.c_int64(len(csc.indptr)),
             ctypes.c_int64(len(csc.data)),
             ctypes.c_int64(csc.shape[0]),
             ctypes.c_int(predict_type),
             ctypes.c_int(start_iteration),
             ctypes.c_int(num_iteration),
-            c_str(self.pred_parameter),
+            _c_str(self.pred_parameter),
             ctypes.byref(out_num_preds),
             preds.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))
         if n_preds != out_num_preds.value:
             raise ValueError("Wrong length for predict results")
         return preds, nrow
 
-    def current_iteration(self):
+    def current_iteration(self) -> int:
         """Get the index of the current iteration.
 
         Returns
         -------
         cur_iter : int
             The index of the current iteration.
         """
         out_cur_iter = ctypes.c_int(0)
         _safe_call(_LIB.LGBM_BoosterGetCurrentIteration(
-            self.handle,
+            self._handle,
             ctypes.byref(out_cur_iter)))
         return out_cur_iter.value
 
 
 class Dataset:
     """Dataset in LightGBM."""
 
-    def __init__(self, data, label=None, reference=None,
-                 weight=None, group=None, init_score=None, silent='warn',
-                 feature_name='auto', categorical_feature='auto', params=None,
-                 free_raw_data=True):
+    def __init__(
+        self,
+        data: _LGBM_TrainDataType,
+        label: Optional[_LGBM_LabelType] = None,
+        reference: Optional["Dataset"] = None,
+        weight: Optional[_LGBM_WeightType] = None,
+        group: Optional[_LGBM_GroupType] = None,
+        init_score: Optional[_LGBM_InitScoreType] = None,
+        feature_name: _LGBM_FeatureNameConfiguration = 'auto',
+        categorical_feature: _LGBM_CategoricalFeatureConfiguration = 'auto',
+        params: Optional[Dict[str, Any]] = None,
+        free_raw_data: bool = True
+    ):
         """Initialize Dataset.
 
         Parameters
         ----------
         data : str, pathlib.Path, numpy array, pandas DataFrame, H2O DataTable's Frame, scipy.sparse, Sequence, list of Sequence or list of numpy array
             Data source of Dataset.
             If str or pathlib.Path, it represents the path to a text file (CSV, TSV, or LibSVM) or a LightGBM Dataset binary file.
         label : list, numpy 1-D array, pandas Series / one-column DataFrame or None, optional (default=None)
             Label of the data.
         reference : Dataset or None, optional (default=None)
             If this is Dataset for validation, training data should be used as reference.
         weight : list, numpy 1-D array, pandas Series or None, optional (default=None)
-            Weight for each instance.
+            Weight for each instance. Weights should be non-negative.
         group : list, numpy 1-D array, pandas Series or None, optional (default=None)
             Group/query data.
             Only used in the learning-to-rank task.
             sum(group) = n_samples.
             For example, if you have a 100-document dataset with ``group = [10, 20, 40, 10, 10, 10]``, that means that you have 6 groups,
             where the first 10 records are in the first group, records 11-30 are in the second group, records 31-70 are in the third group, etc.
         init_score : list, list of lists (for multi-class task), numpy array, pandas Series, pandas DataFrame (for multi-class task), or None, optional (default=None)
             Init score for Dataset.
-        silent : bool, optional (default=False)
-            Whether to print messages during construction.
         feature_name : list of str, or 'auto', optional (default="auto")
             Feature names.
             If 'auto' and data is pandas DataFrame, data columns names are used.
         categorical_feature : list of str or int, or 'auto', optional (default="auto")
             Categorical features.
             If list of int, interpreted as indices.
             If list of str, interpreted as feature names (need to specify ``feature_name`` as well).
             If 'auto' and data is pandas DataFrame, pandas unordered categorical columns are used.
-            All values in categorical features should be less than int32 max value (2147483647).
+            All values in categorical features will be cast to int32 and thus should be less than int32 max value (2147483647).
             Large values could be memory consuming. Consider using consecutive integers starting from zero.
             All negative values in categorical features will be treated as missing values.
             The output cannot be monotonically constrained with respect to a categorical feature.
+            Floating point numbers in categorical features will be rounded towards 0.
         params : dict or None, optional (default=None)
             Other parameters for Dataset.
         free_raw_data : bool, optional (default=True)
             If True, raw data is freed after constructing inner Dataset.
         """
-        self.handle = None
+        self._handle: Optional[_DatasetHandle] = None
         self.data = data
         self.label = label
         self.reference = reference
         self.weight = weight
         self.group = group
         self.init_score = init_score
-        self.silent = silent
-        self.feature_name = feature_name
-        self.categorical_feature = categorical_feature
+        self.feature_name: _LGBM_FeatureNameConfiguration = feature_name
+        self.categorical_feature: _LGBM_CategoricalFeatureConfiguration = categorical_feature
         self.params = deepcopy(params)
         self.free_raw_data = free_raw_data
-        self.used_indices = None
-        self.need_slice = True
-        self._predictor = None
+        self.used_indices: Optional[List[int]] = None
+        self._need_slice = True
+        self._predictor: Optional[_InnerPredictor] = None
         self.pandas_categorical = None
-        self.params_back_up = None
-        self.feature_penalty = None
-        self.monotone_constraints = None
+        self._params_back_up = None
         self.version = 0
         self._start_row = 0  # Used when pushing rows one by one.
 
-    def __del__(self):
+    def __del__(self) -> None:
         try:
             self._free_handle()
         except AttributeError:
             pass
 
     def _create_sample_indices(self, total_nrow: int) -> np.ndarray:
         """Get an array of randomly chosen indices from this ``Dataset``.
@@ -1255,49 +1558,53 @@
             If Dataset has multiple input data, this should be the sum of rows of every file.
 
         Returns
         -------
         indices : numpy array
             Indices for sampled data.
         """
-        param_str = param_dict_to_str(self.get_params())
+        param_str = _param_dict_to_str(self.get_params())
         sample_cnt = _get_sample_count(total_nrow, param_str)
         indices = np.empty(sample_cnt, dtype=np.int32)
-        ptr_data, _, _ = c_int_array(indices)
+        ptr_data, _, _ = _c_int_array(indices)
         actual_sample_cnt = ctypes.c_int32(0)
 
         _safe_call(_LIB.LGBM_SampleIndices(
             ctypes.c_int32(total_nrow),
-            c_str(param_str),
+            _c_str(param_str),
             ptr_data,
             ctypes.byref(actual_sample_cnt),
         ))
         assert sample_cnt == actual_sample_cnt.value
         return indices
 
-    def _init_from_ref_dataset(self, total_nrow: int, ref_dataset: 'Dataset') -> 'Dataset':
+    def _init_from_ref_dataset(
+        self,
+        total_nrow: int,
+        ref_dataset: _DatasetHandle
+    ) -> 'Dataset':
         """Create dataset from a reference dataset.
 
         Parameters
         ----------
         total_nrow : int
             Number of rows expected to add to dataset.
-        ref_dataset : Dataset
-            Reference dataset to extract meta from.
+        ref_dataset : object
+            Handle of reference dataset to extract metadata from.
 
         Returns
         -------
         self : Dataset
             Constructed Dataset object.
         """
-        self.handle = ctypes.c_void_p()
+        self._handle = ctypes.c_void_p()
         _safe_call(_LIB.LGBM_DatasetCreateByReference(
             ref_dataset,
             ctypes.c_int64(total_nrow),
-            ctypes.byref(self.handle),
+            ctypes.byref(self._handle),
         ))
         return self
 
     def _init_from_sample(
         self,
         sample_data: List[np.ndarray],
         sample_indices: List[np.ndarray],
@@ -1329,36 +1636,37 @@
             if sample_data[i].dtype != np.double:
                 raise ValueError(f"sample_data[{i}] type {sample_data[i].dtype} is not double")
             if sample_indices[i].dtype != np.int32:
                 raise ValueError(f"sample_indices[{i}] type {sample_indices[i].dtype} is not int32")
 
         # c type: double**
         # each double* element points to start of each column of sample data.
-        sample_col_ptr = (ctypes.POINTER(ctypes.c_double) * ncol)()
+        sample_col_ptr: _ctypes_float_array = (ctypes.POINTER(ctypes.c_double) * ncol)()
         # c type int**
         # each int* points to start of indices for each column
-        indices_col_ptr = (ctypes.POINTER(ctypes.c_int32) * ncol)()
+        indices_col_ptr: _ctypes_int_array = (ctypes.POINTER(ctypes.c_int32) * ncol)()
         for i in range(ncol):
-            sample_col_ptr[i] = c_float_array(sample_data[i])[0]
-            indices_col_ptr[i] = c_int_array(sample_indices[i])[0]
+            sample_col_ptr[i] = _c_float_array(sample_data[i])[0]
+            indices_col_ptr[i] = _c_int_array(sample_indices[i])[0]
 
         num_per_col = np.array([len(d) for d in sample_indices], dtype=np.int32)
-        num_per_col_ptr, _, _ = c_int_array(num_per_col)
+        num_per_col_ptr, _, _ = _c_int_array(num_per_col)
 
-        self.handle = ctypes.c_void_p()
-        params_str = param_dict_to_str(self.get_params())
+        self._handle = ctypes.c_void_p()
+        params_str = _param_dict_to_str(self.get_params())
         _safe_call(_LIB.LGBM_DatasetCreateFromSampledColumn(
             ctypes.cast(sample_col_ptr, ctypes.POINTER(ctypes.POINTER(ctypes.c_double))),
             ctypes.cast(indices_col_ptr, ctypes.POINTER(ctypes.POINTER(ctypes.c_int32))),
             ctypes.c_int32(ncol),
             num_per_col_ptr,
             ctypes.c_int32(sample_cnt),
             ctypes.c_int32(total_nrow),
-            c_str(params_str),
-            ctypes.byref(self.handle),
+            ctypes.c_int64(total_nrow),
+            _c_str(params_str),
+            ctypes.byref(self._handle),
         ))
         return self
 
     def _push_rows(self, data: np.ndarray) -> 'Dataset':
         """Add rows to Dataset.
 
         Parameters
@@ -1369,33 +1677,33 @@
         Returns
         -------
         self : Dataset
             Dataset object.
         """
         nrow, ncol = data.shape
         data = data.reshape(data.size)
-        data_ptr, data_type, _ = c_float_array(data)
+        data_ptr, data_type, _ = _c_float_array(data)
 
         _safe_call(_LIB.LGBM_DatasetPushRows(
-            self.handle,
+            self._handle,
             data_ptr,
             data_type,
             ctypes.c_int32(nrow),
             ctypes.c_int32(ncol),
             ctypes.c_int32(self._start_row),
         ))
         self._start_row += nrow
         return self
 
-    def get_params(self):
+    def get_params(self) -> Dict[str, Any]:
         """Get the used parameters in the Dataset.
 
         Returns
         -------
-        params : dict or None
+        params : dict
             The used parameters in this Dataset object.
         """
         if self.params is not None:
             # no min_data, nthreads and verbose in this function
             dataset_params = _ConfigAliases.get("bin_construct_sample_cnt",
                                                 "categorical_feature",
                                                 "data_random_seed",
@@ -1414,37 +1722,46 @@
                                                 "pre_partition",
                                                 "precise_float_parser",
                                                 "two_round",
                                                 "use_missing",
                                                 "weight_column",
                                                 "zero_as_missing")
             return {k: v for k, v in self.params.items() if k in dataset_params}
+        else:
+            return {}
 
-    def _free_handle(self):
-        if self.handle is not None:
-            _safe_call(_LIB.LGBM_DatasetFree(self.handle))
-            self.handle = None
-        self.need_slice = True
+    def _free_handle(self) -> "Dataset":
+        if self._handle is not None:
+            _safe_call(_LIB.LGBM_DatasetFree(self._handle))
+            self._handle = None
+        self._need_slice = True
         if self.used_indices is not None:
             self.data = None
         return self
 
-    def _set_init_score_by_predictor(self, predictor, data, used_indices=None):
+    def _set_init_score_by_predictor(
+        self,
+        predictor: Optional[_InnerPredictor],
+        data: _LGBM_TrainDataType,
+        used_indices: Optional[Union[List[int], np.ndarray]]
+    ) -> "Dataset":
         data_has_header = False
-        if isinstance(data, (str, Path)):
+        if isinstance(data, (str, Path)) and self.params is not None:
             # check data has header or not
             data_has_header = any(self.params.get(alias, False) for alias in _ConfigAliases.get("header"))
         num_data = self.num_data()
         if predictor is not None:
-            init_score = predictor.predict(data,
-                                           raw_score=True,
-                                           data_has_header=data_has_header,
-                                           is_reshape=False)
+            init_score: Union[np.ndarray, scipy.sparse.spmatrix] = predictor.predict(
+                data=data,
+                raw_score=True,
+                data_has_header=data_has_header
+            )
+            init_score = init_score.ravel()
             if used_indices is not None:
-                assert not self.need_slice
+                assert not self._need_slice
                 if isinstance(data, (str, Path)):
                     sub_init_score = np.empty(num_data * predictor.num_class, dtype=np.float64)
                     assert num_data == len(used_indices)
                     for i in range(len(used_indices)):
                         for j in range(predictor.num_class):
                             sub_init_score[i * predictor.num_class + j] = init_score[used_indices[i] * predictor.num_class + j]
                     init_score = sub_init_score
@@ -1452,52 +1769,51 @@
                 # need to regroup init_score
                 new_init_score = np.empty(init_score.size, dtype=np.float64)
                 for i in range(num_data):
                     for j in range(predictor.num_class):
                         new_init_score[j * num_data + i] = init_score[i * predictor.num_class + j]
                 init_score = new_init_score
         elif self.init_score is not None:
-            init_score = np.zeros(self.init_score.shape, dtype=np.float64)
+            init_score = np.full_like(self.init_score, fill_value=0.0, dtype=np.float64)
         else:
             return self
         self.set_init_score(init_score)
+        return self
 
-    def _lazy_init(self, data, label=None, reference=None,
-                   weight=None, group=None, init_score=None, predictor=None,
-                   silent=False, feature_name='auto',
-                   categorical_feature='auto', params=None):
+    def _lazy_init(
+        self,
+        data: Optional[_LGBM_TrainDataType],
+        label: Optional[_LGBM_LabelType],
+        reference: Optional["Dataset"],
+        weight: Optional[_LGBM_WeightType],
+        group: Optional[_LGBM_GroupType],
+        init_score: Optional[_LGBM_InitScoreType],
+        predictor: Optional[_InnerPredictor],
+        feature_name: _LGBM_FeatureNameConfiguration,
+        categorical_feature: _LGBM_CategoricalFeatureConfiguration,
+        params: Optional[Dict[str, Any]]
+    ) -> "Dataset":
         if data is None:
-            self.handle = None
+            self._handle = None
             return self
         if reference is not None:
             self.pandas_categorical = reference.pandas_categorical
             categorical_feature = reference.categorical_feature
-        data, feature_name, categorical_feature, self.pandas_categorical = _data_from_pandas(data,
-                                                                                             feature_name,
-                                                                                             categorical_feature,
-                                                                                             self.pandas_categorical)
-        label = _label_from_pandas(label)
+        data, feature_name, categorical_feature, self.pandas_categorical = _data_from_pandas(data=data,
+                                                                                             feature_name=feature_name,
+                                                                                             categorical_feature=categorical_feature,
+                                                                                             pandas_categorical=self.pandas_categorical)
 
         # process for args
         params = {} if params is None else params
-        args_names = (getattr(self.__class__, '_lazy_init')
-                      .__code__
-                      .co_varnames[:getattr(self.__class__, '_lazy_init').__code__.co_argcount])
+        args_names = inspect.signature(self.__class__._lazy_init).parameters.keys()
         for key in params.keys():
             if key in args_names:
                 _log_warning(f'{key} keyword has been found in `params` and will be ignored.\n'
                              f'Please use {key} argument of the Dataset constructor to pass this parameter.')
-        # user can set verbose with params, it has higher priority
-        if silent != "warn":
-            _log_warning("'silent' argument is deprecated and will be removed in a future release of LightGBM. "
-                         "Pass 'verbose' parameter via 'params' instead.")
-        else:
-            silent = False
-        if not any(verbose_alias in params for verbose_alias in _ConfigAliases.get("verbosity")) and silent:
-            params["verbose"] = -1
         # get categorical features
         if categorical_feature is not None:
             categorical_indices = set()
             feature_dict = {}
             if feature_name is not None:
                 feature_dict = {name: i for i, name in enumerate(feature_name)}
             for name in categorical_feature:
@@ -1506,34 +1822,36 @@
                 elif isinstance(name, int):
                     categorical_indices.add(name)
                 else:
                     raise TypeError(f"Wrong type({type(name).__name__}) or unknown name({name}) in categorical_feature")
             if categorical_indices:
                 for cat_alias in _ConfigAliases.get("categorical_feature"):
                     if cat_alias in params:
-                        _log_warning(f'{cat_alias} in param dict is overridden.')
+                        # If the params[cat_alias] is equal to categorical_indices, do not report the warning.
+                        if not (isinstance(params[cat_alias], list) and set(params[cat_alias]) == categorical_indices):
+                            _log_warning(f'{cat_alias} in param dict is overridden.')
                         params.pop(cat_alias, None)
                 params['categorical_column'] = sorted(categorical_indices)
 
-        params_str = param_dict_to_str(params)
+        params_str = _param_dict_to_str(params)
         self.params = params
         # process for reference dataset
         ref_dataset = None
         if isinstance(reference, Dataset):
-            ref_dataset = reference.construct().handle
+            ref_dataset = reference.construct()._handle
         elif reference is not None:
             raise TypeError('Reference dataset should be None or dataset instance')
         # start construct data
         if isinstance(data, (str, Path)):
-            self.handle = ctypes.c_void_p()
+            self._handle = ctypes.c_void_p()
             _safe_call(_LIB.LGBM_DatasetCreateFromFile(
-                c_str(str(data)),
-                c_str(params_str),
+                _c_str(str(data)),
+                _c_str(params_str),
                 ref_dataset,
-                ctypes.byref(self.handle)))
+                ctypes.byref(self._handle)))
         elif isinstance(data, scipy.sparse.csr_matrix):
             self.__init_from_csr(data, params_str, ref_dataset)
         elif isinstance(data, scipy.sparse.csc_matrix):
             self.__init_from_csc(data, params_str, ref_dataset)
         elif isinstance(data, np.ndarray):
             self.__init_from_np2d(data, params_str, ref_dataset)
         elif isinstance(data, list) and len(data) > 0:
@@ -1547,28 +1865,32 @@
             self.__init_from_seqs([data], ref_dataset)
         elif isinstance(data, dt_DataTable):
             self.__init_from_np2d(data.to_numpy(), params_str, ref_dataset)
         else:
             try:
                 csr = scipy.sparse.csr_matrix(data)
                 self.__init_from_csr(csr, params_str, ref_dataset)
-            except BaseException:
-                raise TypeError(f'Cannot initialize Dataset from {type(data).__name__}')
+            except BaseException as err:
+                raise TypeError(f'Cannot initialize Dataset from {type(data).__name__}') from err
         if label is not None:
             self.set_label(label)
         if self.get_label() is None:
             raise ValueError("Label should not be None")
         if weight is not None:
             self.set_weight(weight)
         if group is not None:
             self.set_group(group)
         if isinstance(predictor, _InnerPredictor):
             if self._predictor is None and init_score is not None:
                 _log_warning("The init_score will be overridden by the prediction of init_model.")
-            self._set_init_score_by_predictor(predictor, data)
+            self._set_init_score_by_predictor(
+                predictor=predictor,
+                data=data,
+                used_indices=None
+            )
         elif init_score is not None:
             self.set_init_score(init_score)
         elif predictor is not None:
             raise TypeError(f'Wrong predictor type {type(predictor).__name__}')
         # set feature names
         return self.set_feature_name(feature_name)
 
@@ -1595,15 +1917,15 @@
         Returns
         -------
             sampled_rows, sampled_row_indices
         """
         indices = self._create_sample_indices(total_nrow)
 
         # Select sampled rows, transpose to column order.
-        sampled = np.array([row for row in self._yield_row_from_seqlist(seqs, indices)])
+        sampled = np.array(list(self._yield_row_from_seqlist(seqs, indices)))
         sampled = sampled.T
 
         filtered = []
         filtered_idx = []
         sampled_row_range = np.arange(len(indices), dtype=np.int32)
         for col in sampled:
             col_predicate = (np.abs(col) > ZERO_THRESHOLD) | np.isnan(col)
@@ -1611,77 +1933,92 @@
             filtered_row_idx = sampled_row_range[col_predicate]
 
             filtered.append(filtered_col)
             filtered_idx.append(filtered_row_idx)
 
         return filtered, filtered_idx
 
-    def __init_from_seqs(self, seqs: List[Sequence], ref_dataset: Optional['Dataset'] = None):
+    def __init_from_seqs(
+        self,
+        seqs: List[Sequence],
+        ref_dataset: Optional[_DatasetHandle]
+    ) -> "Dataset":
         """
         Initialize data from list of Sequence objects.
 
         Sequence: Generic Data Access Object
             Supports random access and access by batch if properly defined by user
 
         Data scheme uniformity are trusted, not checked
         """
         total_nrow = sum(len(seq) for seq in seqs)
 
         # create validation dataset from ref_dataset
         if ref_dataset is not None:
             self._init_from_ref_dataset(total_nrow, ref_dataset)
         else:
-            param_str = param_dict_to_str(self.get_params())
+            param_str = _param_dict_to_str(self.get_params())
             sample_cnt = _get_sample_count(total_nrow, param_str)
 
             sample_data, col_indices = self.__sample(seqs, total_nrow)
             self._init_from_sample(sample_data, col_indices, sample_cnt, total_nrow)
 
         for seq in seqs:
             nrow = len(seq)
             batch_size = getattr(seq, 'batch_size', None) or Sequence.batch_size
             for start in range(0, nrow, batch_size):
                 end = min(start + batch_size, nrow)
                 self._push_rows(seq[start:end])
         return self
 
-    def __init_from_np2d(self, mat, params_str, ref_dataset):
+    def __init_from_np2d(
+        self,
+        mat: np.ndarray,
+        params_str: str,
+        ref_dataset: Optional[_DatasetHandle]
+    ) -> "Dataset":
         """Initialize data from a 2-D numpy matrix."""
         if len(mat.shape) != 2:
             raise ValueError('Input numpy.ndarray must be 2 dimensional')
 
-        self.handle = ctypes.c_void_p()
+        self._handle = ctypes.c_void_p()
         if mat.dtype == np.float32 or mat.dtype == np.float64:
             data = np.array(mat.reshape(mat.size), dtype=mat.dtype, copy=False)
         else:  # change non-float data to float data, need to copy
             data = np.array(mat.reshape(mat.size), dtype=np.float32)
 
-        ptr_data, type_ptr_data, _ = c_float_array(data)
+        ptr_data, type_ptr_data, _ = _c_float_array(data)
         _safe_call(_LIB.LGBM_DatasetCreateFromMat(
             ptr_data,
             ctypes.c_int(type_ptr_data),
             ctypes.c_int32(mat.shape[0]),
             ctypes.c_int32(mat.shape[1]),
-            ctypes.c_int(C_API_IS_ROW_MAJOR),
-            c_str(params_str),
+            ctypes.c_int(_C_API_IS_ROW_MAJOR),
+            _c_str(params_str),
             ref_dataset,
-            ctypes.byref(self.handle)))
+            ctypes.byref(self._handle)))
         return self
 
-    def __init_from_list_np2d(self, mats, params_str, ref_dataset):
+    def __init_from_list_np2d(
+        self,
+        mats: List[np.ndarray],
+        params_str: str,
+        ref_dataset: Optional[_DatasetHandle]
+    ) -> "Dataset":
         """Initialize data from a list of 2-D numpy matrices."""
         ncol = mats[0].shape[1]
         nrow = np.empty((len(mats),), np.int32)
+        ptr_data: _ctypes_float_array
         if mats[0].dtype == np.float64:
             ptr_data = (ctypes.POINTER(ctypes.c_double) * len(mats))()
         else:
             ptr_data = (ctypes.POINTER(ctypes.c_float) * len(mats))()
 
         holders = []
-        type_ptr_data = None
+        type_ptr_data = -1
 
         for i, mat in enumerate(mats):
             if len(mat.shape) != 2:
                 raise ValueError('Input numpy.ndarray must be 2 dimensional')
 
             if mat.shape[1] != ncol:
                 raise ValueError('Input arrays must have same number of columns')
@@ -1689,181 +2026,248 @@
             nrow[i] = mat.shape[0]
 
             if mat.dtype == np.float32 or mat.dtype == np.float64:
                 mats[i] = np.array(mat.reshape(mat.size), dtype=mat.dtype, copy=False)
             else:  # change non-float data to float data, need to copy
                 mats[i] = np.array(mat.reshape(mat.size), dtype=np.float32)
 
-            chunk_ptr_data, chunk_type_ptr_data, holder = c_float_array(mats[i])
-            if type_ptr_data is not None and chunk_type_ptr_data != type_ptr_data:
+            chunk_ptr_data, chunk_type_ptr_data, holder = _c_float_array(mats[i])
+            if type_ptr_data != -1 and chunk_type_ptr_data != type_ptr_data:
                 raise ValueError('Input chunks must have same type')
             ptr_data[i] = chunk_ptr_data
             type_ptr_data = chunk_type_ptr_data
             holders.append(holder)
 
-        self.handle = ctypes.c_void_p()
+        self._handle = ctypes.c_void_p()
         _safe_call(_LIB.LGBM_DatasetCreateFromMats(
             ctypes.c_int32(len(mats)),
             ctypes.cast(ptr_data, ctypes.POINTER(ctypes.POINTER(ctypes.c_double))),
             ctypes.c_int(type_ptr_data),
             nrow.ctypes.data_as(ctypes.POINTER(ctypes.c_int32)),
             ctypes.c_int32(ncol),
-            ctypes.c_int(C_API_IS_ROW_MAJOR),
-            c_str(params_str),
+            ctypes.c_int(_C_API_IS_ROW_MAJOR),
+            _c_str(params_str),
             ref_dataset,
-            ctypes.byref(self.handle)))
+            ctypes.byref(self._handle)))
         return self
 
-    def __init_from_csr(self, csr, params_str, ref_dataset):
+    def __init_from_csr(
+        self,
+        csr: scipy.sparse.csr_matrix,
+        params_str: str,
+        ref_dataset: Optional[_DatasetHandle]
+    ) -> "Dataset":
         """Initialize data from a CSR matrix."""
         if len(csr.indices) != len(csr.data):
             raise ValueError(f'Length mismatch: {len(csr.indices)} vs {len(csr.data)}')
-        self.handle = ctypes.c_void_p()
+        self._handle = ctypes.c_void_p()
 
-        ptr_indptr, type_ptr_indptr, __ = c_int_array(csr.indptr)
-        ptr_data, type_ptr_data, _ = c_float_array(csr.data)
+        ptr_indptr, type_ptr_indptr, __ = _c_int_array(csr.indptr)
+        ptr_data, type_ptr_data, _ = _c_float_array(csr.data)
 
-        assert csr.shape[1] <= MAX_INT32
+        assert csr.shape[1] <= _MAX_INT32
         csr_indices = csr.indices.astype(np.int32, copy=False)
 
         _safe_call(_LIB.LGBM_DatasetCreateFromCSR(
             ptr_indptr,
             ctypes.c_int(type_ptr_indptr),
             csr_indices.ctypes.data_as(ctypes.POINTER(ctypes.c_int32)),
             ptr_data,
             ctypes.c_int(type_ptr_data),
             ctypes.c_int64(len(csr.indptr)),
             ctypes.c_int64(len(csr.data)),
             ctypes.c_int64(csr.shape[1]),
-            c_str(params_str),
+            _c_str(params_str),
             ref_dataset,
-            ctypes.byref(self.handle)))
+            ctypes.byref(self._handle)))
         return self
 
-    def __init_from_csc(self, csc, params_str, ref_dataset):
+    def __init_from_csc(
+        self,
+        csc: scipy.sparse.csc_matrix,
+        params_str: str,
+        ref_dataset: Optional[_DatasetHandle]
+    ) -> "Dataset":
         """Initialize data from a CSC matrix."""
         if len(csc.indices) != len(csc.data):
             raise ValueError(f'Length mismatch: {len(csc.indices)} vs {len(csc.data)}')
-        self.handle = ctypes.c_void_p()
+        self._handle = ctypes.c_void_p()
 
-        ptr_indptr, type_ptr_indptr, __ = c_int_array(csc.indptr)
-        ptr_data, type_ptr_data, _ = c_float_array(csc.data)
+        ptr_indptr, type_ptr_indptr, __ = _c_int_array(csc.indptr)
+        ptr_data, type_ptr_data, _ = _c_float_array(csc.data)
 
-        assert csc.shape[0] <= MAX_INT32
+        assert csc.shape[0] <= _MAX_INT32
         csc_indices = csc.indices.astype(np.int32, copy=False)
 
         _safe_call(_LIB.LGBM_DatasetCreateFromCSC(
             ptr_indptr,
             ctypes.c_int(type_ptr_indptr),
             csc_indices.ctypes.data_as(ctypes.POINTER(ctypes.c_int32)),
             ptr_data,
             ctypes.c_int(type_ptr_data),
             ctypes.c_int64(len(csc.indptr)),
             ctypes.c_int64(len(csc.data)),
             ctypes.c_int64(csc.shape[0]),
-            c_str(params_str),
+            _c_str(params_str),
             ref_dataset,
-            ctypes.byref(self.handle)))
+            ctypes.byref(self._handle)))
         return self
 
-    def construct(self):
+    @staticmethod
+    def _compare_params_for_warning(
+        params: Optional[Dict[str, Any]],
+        other_params: Optional[Dict[str, Any]],
+        ignore_keys: Set[str]
+    ) -> bool:
+        """Compare two dictionaries with params ignoring some keys.
+
+        It is only for the warning purpose.
+
+        Parameters
+        ----------
+        params : dict or None
+            One dictionary with parameters to compare.
+        other_params : dict or None
+            Another dictionary with parameters to compare.
+        ignore_keys : set
+            Keys that should be ignored during comparing two dictionaries.
+
+        Returns
+        -------
+        compare_result : bool
+          Returns whether two dictionaries with params are equal.
+        """
+        if params is None:
+            params = {}
+        if other_params is None:
+            other_params = {}
+        for k in other_params:
+            if k not in ignore_keys:
+                if k not in params or params[k] != other_params[k]:
+                    return False
+        for k in params:
+            if k not in ignore_keys:
+                if k not in other_params or params[k] != other_params[k]:
+                    return False
+        return True
+
+    def construct(self) -> "Dataset":
         """Lazy init.
 
         Returns
         -------
         self : Dataset
             Constructed Dataset object.
         """
-        if self.handle is None:
+        if self._handle is None:
             if self.reference is not None:
                 reference_params = self.reference.get_params()
-                if self.get_params() != reference_params:
-                    _log_warning('Overriding the parameters from Reference Dataset.')
+                params = self.get_params()
+                if params != reference_params:
+                    if not self._compare_params_for_warning(
+                        params=params,
+                        other_params=reference_params,
+                        ignore_keys=_ConfigAliases.get("categorical_feature")
+                    ):
+                        _log_warning('Overriding the parameters from Reference Dataset.')
                     self._update_params(reference_params)
                 if self.used_indices is None:
                     # create valid
-                    self._lazy_init(self.data, label=self.label, reference=self.reference,
+                    self._lazy_init(data=self.data, label=self.label, reference=self.reference,
                                     weight=self.weight, group=self.group,
                                     init_score=self.init_score, predictor=self._predictor,
-                                    silent=self.silent, feature_name=self.feature_name, params=self.params)
+                                    feature_name=self.feature_name, categorical_feature='auto', params=self.params)
                 else:
                     # construct subset
-                    used_indices = list_to_1d_numpy(self.used_indices, np.int32, name='used_indices')
+                    used_indices = _list_to_1d_numpy(self.used_indices, dtype=np.int32, name='used_indices')
                     assert used_indices.flags.c_contiguous
                     if self.reference.group is not None:
                         group_info = np.array(self.reference.group).astype(np.int32, copy=False)
                         _, self.group = np.unique(np.repeat(range(len(group_info)), repeats=group_info)[self.used_indices],
                                                   return_counts=True)
-                    self.handle = ctypes.c_void_p()
-                    params_str = param_dict_to_str(self.params)
+                    self._handle = ctypes.c_void_p()
+                    params_str = _param_dict_to_str(self.params)
                     _safe_call(_LIB.LGBM_DatasetGetSubset(
-                        self.reference.construct().handle,
+                        self.reference.construct()._handle,
                         used_indices.ctypes.data_as(ctypes.POINTER(ctypes.c_int32)),
                         ctypes.c_int32(used_indices.shape[0]),
-                        c_str(params_str),
-                        ctypes.byref(self.handle)))
+                        _c_str(params_str),
+                        ctypes.byref(self._handle)))
                     if not self.free_raw_data:
                         self.get_data()
                     if self.group is not None:
                         self.set_group(self.group)
                     if self.get_label() is None:
                         raise ValueError("Label should not be None.")
                     if isinstance(self._predictor, _InnerPredictor) and self._predictor is not self.reference._predictor:
                         self.get_data()
-                        self._set_init_score_by_predictor(self._predictor, self.data, used_indices)
+                        self._set_init_score_by_predictor(
+                            predictor=self._predictor,
+                            data=self.data,
+                            used_indices=used_indices
+                        )
             else:
                 # create train
-                self._lazy_init(self.data, label=self.label,
+                self._lazy_init(data=self.data, label=self.label, reference=None,
                                 weight=self.weight, group=self.group,
                                 init_score=self.init_score, predictor=self._predictor,
-                                silent=self.silent, feature_name=self.feature_name,
-                                categorical_feature=self.categorical_feature, params=self.params)
+                                feature_name=self.feature_name, categorical_feature=self.categorical_feature, params=self.params)
             if self.free_raw_data:
                 self.data = None
+            self.feature_name = self.get_feature_name()
         return self
 
-    def create_valid(self, data, label=None, weight=None, group=None,
-                     init_score=None, silent='warn', params=None):
+    def create_valid(
+        self,
+        data: _LGBM_TrainDataType,
+        label: Optional[_LGBM_LabelType] = None,
+        weight: Optional[_LGBM_WeightType] = None,
+        group: Optional[_LGBM_GroupType] = None,
+        init_score: Optional[_LGBM_InitScoreType] = None,
+        params: Optional[Dict[str, Any]] = None
+    ) -> "Dataset":
         """Create validation data align with current Dataset.
 
         Parameters
         ----------
         data : str, pathlib.Path, numpy array, pandas DataFrame, H2O DataTable's Frame, scipy.sparse, Sequence, list of Sequence or list of numpy array
             Data source of Dataset.
             If str or pathlib.Path, it represents the path to a text file (CSV, TSV, or LibSVM) or a LightGBM Dataset binary file.
         label : list, numpy 1-D array, pandas Series / one-column DataFrame or None, optional (default=None)
             Label of the data.
         weight : list, numpy 1-D array, pandas Series or None, optional (default=None)
-            Weight for each instance.
+            Weight for each instance. Weights should be non-negative.
         group : list, numpy 1-D array, pandas Series or None, optional (default=None)
             Group/query data.
             Only used in the learning-to-rank task.
             sum(group) = n_samples.
             For example, if you have a 100-document dataset with ``group = [10, 20, 40, 10, 10, 10]``, that means that you have 6 groups,
             where the first 10 records are in the first group, records 11-30 are in the second group, records 31-70 are in the third group, etc.
         init_score : list, list of lists (for multi-class task), numpy array, pandas Series, pandas DataFrame (for multi-class task), or None, optional (default=None)
             Init score for Dataset.
-        silent : bool, optional (default=False)
-            Whether to print messages during construction.
         params : dict or None, optional (default=None)
             Other parameters for validation Dataset.
 
         Returns
         -------
         valid : Dataset
             Validation Dataset with reference to self.
         """
         ret = Dataset(data, label=label, reference=self,
                       weight=weight, group=group, init_score=init_score,
-                      silent=silent, params=params, free_raw_data=self.free_raw_data)
+                      params=params, free_raw_data=self.free_raw_data)
         ret._predictor = self._predictor
         ret.pandas_categorical = self.pandas_categorical
         return ret
 
-    def subset(self, used_indices, params=None):
+    def subset(
+        self,
+        used_indices: List[int],
+        params: Optional[Dict[str, Any]] = None
+    ) -> "Dataset":
         """Get subset of current Dataset.
 
         Parameters
         ----------
         used_indices : list of int
             Indices used to create the subset.
         params : dict or None, optional (default=None)
@@ -1880,15 +2284,15 @@
                       categorical_feature=self.categorical_feature, params=params,
                       free_raw_data=self.free_raw_data)
         ret._predictor = self._predictor
         ret.pandas_categorical = self.pandas_categorical
         ret.used_indices = sorted(used_indices)
         return ret
 
-    def save_binary(self, filename):
+    def save_binary(self, filename: Union[str, Path]) -> "Dataset":
         """Save Dataset to a binary file.
 
         .. note::
 
             Please note that `init_score` is not saved in binary file.
             If you need it, please set it again after loading Dataset.
 
@@ -1899,206 +2303,229 @@
 
         Returns
         -------
         self : Dataset
             Returns self.
         """
         _safe_call(_LIB.LGBM_DatasetSaveBinary(
-            self.construct().handle,
-            c_str(str(filename))))
+            self.construct()._handle,
+            _c_str(str(filename))))
         return self
 
-    def _update_params(self, params):
+    def _update_params(self, params: Optional[Dict[str, Any]]) -> "Dataset":
         if not params:
             return self
         params = deepcopy(params)
 
         def update():
             if not self.params:
                 self.params = params
             else:
-                self.params_back_up = deepcopy(self.params)
+                self._params_back_up = deepcopy(self.params)
                 self.params.update(params)
 
-        if self.handle is None:
+        if self._handle is None:
             update()
         elif params is not None:
             ret = _LIB.LGBM_DatasetUpdateParamChecking(
-                c_str(param_dict_to_str(self.params)),
-                c_str(param_dict_to_str(params)))
+                _c_str(_param_dict_to_str(self.params)),
+                _c_str(_param_dict_to_str(params)))
             if ret != 0:
                 # could be updated if data is not freed
                 if self.data is not None:
                     update()
                     self._free_handle()
                 else:
                     raise LightGBMError(_LIB.LGBM_GetLastError().decode('utf-8'))
         return self
 
-    def _reverse_update_params(self):
-        if self.handle is None:
-            self.params = deepcopy(self.params_back_up)
-            self.params_back_up = None
+    def _reverse_update_params(self) -> "Dataset":
+        if self._handle is None:
+            self.params = deepcopy(self._params_back_up)
+            self._params_back_up = None
         return self
 
-    def set_field(self, field_name, data):
+    def set_field(
+        self,
+        field_name: str,
+        data: Optional[Union[List[List[float]], List[List[int]], List[float], List[int], np.ndarray, pd_Series, pd_DataFrame]]
+    ) -> "Dataset":
         """Set property into the Dataset.
 
         Parameters
         ----------
         field_name : str
             The field name of the information.
         data : list, list of lists (for multi-class task), numpy array, pandas Series, pandas DataFrame (for multi-class task), or None
             The data to be set.
 
         Returns
         -------
         self : Dataset
             Dataset with set property.
         """
-        if self.handle is None:
+        if self._handle is None:
             raise Exception(f"Cannot set {field_name} before construct dataset")
         if data is None:
             # set to None
             _safe_call(_LIB.LGBM_DatasetSetField(
-                self.handle,
-                c_str(field_name),
+                self._handle,
+                _c_str(field_name),
                 None,
                 ctypes.c_int(0),
-                ctypes.c_int(FIELD_TYPE_MAPPER[field_name])))
+                ctypes.c_int(_FIELD_TYPE_MAPPER[field_name])))
             return self
+        dtype: "np.typing.DTypeLike"
         if field_name == 'init_score':
             dtype = np.float64
             if _is_1d_collection(data):
-                data = list_to_1d_numpy(data, dtype, name=field_name)
+                data = _list_to_1d_numpy(data, dtype=dtype, name=field_name)
             elif _is_2d_collection(data):
-                data = _data_to_2d_numpy(data, dtype, name=field_name)
+                data = _data_to_2d_numpy(data, dtype=dtype, name=field_name)
                 data = data.ravel(order='F')
             else:
                 raise TypeError(
                     'init_score must be list, numpy 1-D array or pandas Series.\n'
                     'In multiclass classification init_score can also be a list of lists, numpy 2-D array or pandas DataFrame.'
                 )
         else:
             dtype = np.int32 if field_name == 'group' else np.float32
-            data = list_to_1d_numpy(data, dtype, name=field_name)
+            data = _list_to_1d_numpy(data, dtype=dtype, name=field_name)
 
+        ptr_data: Union[_ctypes_float_ptr, _ctypes_int_ptr]
         if data.dtype == np.float32 or data.dtype == np.float64:
-            ptr_data, type_data, _ = c_float_array(data)
+            ptr_data, type_data, _ = _c_float_array(data)
         elif data.dtype == np.int32:
-            ptr_data, type_data, _ = c_int_array(data)
+            ptr_data, type_data, _ = _c_int_array(data)
         else:
             raise TypeError(f"Expected np.float32/64 or np.int32, met type({data.dtype})")
-        if type_data != FIELD_TYPE_MAPPER[field_name]:
+        if type_data != _FIELD_TYPE_MAPPER[field_name]:
             raise TypeError("Input type error for set_field")
         _safe_call(_LIB.LGBM_DatasetSetField(
-            self.handle,
-            c_str(field_name),
+            self._handle,
+            _c_str(field_name),
             ptr_data,
             ctypes.c_int(len(data)),
             ctypes.c_int(type_data)))
         self.version += 1
         return self
 
-    def get_field(self, field_name):
+    def get_field(self, field_name: str) -> Optional[np.ndarray]:
         """Get property from the Dataset.
 
         Parameters
         ----------
         field_name : str
             The field name of the information.
 
         Returns
         -------
         info : numpy array or None
             A numpy array with information from the Dataset.
         """
-        if self.handle is None:
+        if self._handle is None:
             raise Exception(f"Cannot get {field_name} before construct Dataset")
         tmp_out_len = ctypes.c_int(0)
         out_type = ctypes.c_int(0)
         ret = ctypes.POINTER(ctypes.c_void_p)()
         _safe_call(_LIB.LGBM_DatasetGetField(
-            self.handle,
-            c_str(field_name),
+            self._handle,
+            _c_str(field_name),
             ctypes.byref(tmp_out_len),
             ctypes.byref(ret),
             ctypes.byref(out_type)))
-        if out_type.value != FIELD_TYPE_MAPPER[field_name]:
+        if out_type.value != _FIELD_TYPE_MAPPER[field_name]:
             raise TypeError("Return type error for get_field")
         if tmp_out_len.value == 0:
             return None
-        if out_type.value == C_API_DTYPE_INT32:
-            arr = cint32_array_to_numpy(ctypes.cast(ret, ctypes.POINTER(ctypes.c_int32)), tmp_out_len.value)
-        elif out_type.value == C_API_DTYPE_FLOAT32:
-            arr = cfloat32_array_to_numpy(ctypes.cast(ret, ctypes.POINTER(ctypes.c_float)), tmp_out_len.value)
-        elif out_type.value == C_API_DTYPE_FLOAT64:
-            arr = cfloat64_array_to_numpy(ctypes.cast(ret, ctypes.POINTER(ctypes.c_double)), tmp_out_len.value)
+        if out_type.value == _C_API_DTYPE_INT32:
+            arr = _cint32_array_to_numpy(ctypes.cast(ret, ctypes.POINTER(ctypes.c_int32)), tmp_out_len.value)
+        elif out_type.value == _C_API_DTYPE_FLOAT32:
+            arr = _cfloat32_array_to_numpy(ctypes.cast(ret, ctypes.POINTER(ctypes.c_float)), tmp_out_len.value)
+        elif out_type.value == _C_API_DTYPE_FLOAT64:
+            arr = _cfloat64_array_to_numpy(ctypes.cast(ret, ctypes.POINTER(ctypes.c_double)), tmp_out_len.value)
         else:
             raise TypeError("Unknown type")
         if field_name == 'init_score':
             num_data = self.num_data()
             num_classes = arr.size // num_data
             if num_classes > 1:
                 arr = arr.reshape((num_data, num_classes), order='F')
         return arr
 
-    def set_categorical_feature(self, categorical_feature):
+    def set_categorical_feature(
+        self,
+        categorical_feature: _LGBM_CategoricalFeatureConfiguration
+    ) -> "Dataset":
         """Set categorical features.
 
         Parameters
         ----------
-        categorical_feature : list of int or str
+        categorical_feature : list of str or int, or 'auto'
             Names or indices of categorical features.
 
         Returns
         -------
         self : Dataset
             Dataset with set categorical features.
         """
         if self.categorical_feature == categorical_feature:
             return self
         if self.data is not None:
             if self.categorical_feature is None:
                 self.categorical_feature = categorical_feature
                 return self._free_handle()
             elif categorical_feature == 'auto':
-                _log_warning('Using categorical_feature in Dataset.')
                 return self
             else:
-                _log_warning('categorical_feature in Dataset is overridden.\n'
-                             f'New categorical_feature is {sorted(list(categorical_feature))}')
+                if self.categorical_feature != 'auto':
+                    _log_warning('categorical_feature in Dataset is overridden.\n'
+                                 f'New categorical_feature is {list(categorical_feature)}')
                 self.categorical_feature = categorical_feature
                 return self._free_handle()
         else:
             raise LightGBMError("Cannot set categorical feature after freed raw data, "
                                 "set free_raw_data=False when construct Dataset to avoid this.")
 
-    def _set_predictor(self, predictor):
+    def _set_predictor(
+        self,
+        predictor: Optional[_InnerPredictor]
+    ) -> "Dataset":
         """Set predictor for continued training.
 
         It is not recommended for user to call this function.
         Please use init_model argument in engine.train() or engine.cv() instead.
         """
-        if predictor is self._predictor and (predictor is None or predictor.current_iteration() == self._predictor.current_iteration()):
+        if predictor is None and self._predictor is None:
             return self
-        if self.handle is None:
+        elif isinstance(predictor, _InnerPredictor) and isinstance(self._predictor, _InnerPredictor):
+            if (predictor == self._predictor) and (predictor.current_iteration() == self._predictor.current_iteration()):
+                return self
+        if self._handle is None:
             self._predictor = predictor
         elif self.data is not None:
             self._predictor = predictor
-            self._set_init_score_by_predictor(self._predictor, self.data)
+            self._set_init_score_by_predictor(
+                predictor=self._predictor,
+                data=self.data,
+                used_indices=None
+            )
         elif self.used_indices is not None and self.reference is not None and self.reference.data is not None:
             self._predictor = predictor
-            self._set_init_score_by_predictor(self._predictor, self.reference.data, self.used_indices)
+            self._set_init_score_by_predictor(
+                predictor=self._predictor,
+                data=self.reference.data,
+                used_indices=self.used_indices
+            )
         else:
             raise LightGBMError("Cannot set predictor after freed raw data, "
                                 "set free_raw_data=False when construct Dataset to avoid this.")
         return self
 
-    def set_reference(self, reference):
+    def set_reference(self, reference: "Dataset") -> "Dataset":
         """Set reference Dataset.
 
         Parameters
         ----------
         reference : Dataset
             Reference that is used as a template to construct the current Dataset.
 
@@ -2116,101 +2543,126 @@
         if self.data is not None:
             self.reference = reference
             return self._free_handle()
         else:
             raise LightGBMError("Cannot set reference after freed raw data, "
                                 "set free_raw_data=False when construct Dataset to avoid this.")
 
-    def set_feature_name(self, feature_name):
+    def set_feature_name(self, feature_name: _LGBM_FeatureNameConfiguration) -> "Dataset":
         """Set feature name.
 
         Parameters
         ----------
         feature_name : list of str
             Feature names.
 
         Returns
         -------
         self : Dataset
             Dataset with set feature name.
         """
         if feature_name != 'auto':
             self.feature_name = feature_name
-        if self.handle is not None and feature_name is not None and feature_name != 'auto':
+        if self._handle is not None and feature_name is not None and feature_name != 'auto':
             if len(feature_name) != self.num_feature():
                 raise ValueError(f"Length of feature_name({len(feature_name)}) and num_feature({self.num_feature()}) don't match")
-            c_feature_name = [c_str(name) for name in feature_name]
+            c_feature_name = [_c_str(name) for name in feature_name]
             _safe_call(_LIB.LGBM_DatasetSetFeatureNames(
-                self.handle,
-                c_array(ctypes.c_char_p, c_feature_name),
+                self._handle,
+                _c_array(ctypes.c_char_p, c_feature_name),
                 ctypes.c_int(len(feature_name))))
         return self
 
-    def set_label(self, label):
+    def set_label(self, label: Optional[_LGBM_LabelType]) -> "Dataset":
         """Set label of Dataset.
 
         Parameters
         ----------
         label : list, numpy 1-D array, pandas Series / one-column DataFrame or None
             The label information to be set into Dataset.
 
         Returns
         -------
         self : Dataset
             Dataset with set label.
         """
         self.label = label
-        if self.handle is not None:
-            label = list_to_1d_numpy(_label_from_pandas(label), name='label')
-            self.set_field('label', label)
+        if self._handle is not None:
+            if isinstance(label, pd_DataFrame):
+                if len(label.columns) > 1:
+                    raise ValueError('DataFrame for label cannot have multiple columns')
+                _check_for_bad_pandas_dtypes(label.dtypes)
+                try:
+                    # most common case (no nullable dtypes)
+                    label = label.to_numpy(dtype=np.float32, copy=False)
+                except TypeError:
+                    # 1.0 <= pd version < 1.1 and nullable dtypes, least common case
+                    # raises error because array is casted to type(pd.NA) and there's no na_value argument
+                    label = label.astype(np.float32, copy=False).values
+                except ValueError:
+                    # data has nullable dtypes, but we can specify na_value argument and copy will be made
+                    label = label.to_numpy(dtype=np.float32, na_value=np.nan)
+                label_array = np.ravel(label)
+            else:
+                label_array = _list_to_1d_numpy(label, dtype=np.float32, name='label')
+            self.set_field('label', label_array)
             self.label = self.get_field('label')  # original values can be modified at cpp side
         return self
 
-    def set_weight(self, weight):
+    def set_weight(
+        self,
+        weight: Optional[_LGBM_WeightType]
+    ) -> "Dataset":
         """Set weight of each instance.
 
         Parameters
         ----------
         weight : list, numpy 1-D array, pandas Series or None
-            Weight to be set for each data point.
+            Weight to be set for each data point. Weights should be non-negative.
 
         Returns
         -------
         self : Dataset
             Dataset with set weight.
         """
         if weight is not None and np.all(weight == 1):
             weight = None
         self.weight = weight
-        if self.handle is not None and weight is not None:
-            weight = list_to_1d_numpy(weight, name='weight')
+        if self._handle is not None and weight is not None:
+            weight = _list_to_1d_numpy(weight, dtype=np.float32, name='weight')
             self.set_field('weight', weight)
             self.weight = self.get_field('weight')  # original values can be modified at cpp side
         return self
 
-    def set_init_score(self, init_score):
+    def set_init_score(
+        self,
+        init_score: Optional[_LGBM_InitScoreType]
+    ) -> "Dataset":
         """Set init score of Booster to start from.
 
         Parameters
         ----------
         init_score : list, list of lists (for multi-class task), numpy array, pandas Series, pandas DataFrame (for multi-class task), or None
             Init score for Booster.
 
         Returns
         -------
         self : Dataset
             Dataset with set init score.
         """
         self.init_score = init_score
-        if self.handle is not None and init_score is not None:
+        if self._handle is not None and init_score is not None:
             self.set_field('init_score', init_score)
             self.init_score = self.get_field('init_score')  # original values can be modified at cpp side
         return self
 
-    def set_group(self, group):
+    def set_group(
+        self,
+        group: Optional[_LGBM_GroupType]
+    ) -> "Dataset":
         """Set group size of Dataset (used for ranking).
 
         Parameters
         ----------
         group : list, numpy 1-D array, pandas Series or None
             Group/query data.
             Only used in the learning-to-rank task.
@@ -2220,127 +2672,127 @@
 
         Returns
         -------
         self : Dataset
             Dataset with set group.
         """
         self.group = group
-        if self.handle is not None and group is not None:
-            group = list_to_1d_numpy(group, np.int32, name='group')
+        if self._handle is not None and group is not None:
+            group = _list_to_1d_numpy(group, dtype=np.int32, name='group')
             self.set_field('group', group)
         return self
 
-    def get_feature_name(self):
+    def get_feature_name(self) -> List[str]:
         """Get the names of columns (features) in the Dataset.
 
         Returns
         -------
-        feature_names : list
+        feature_names : list of str
             The names of columns (features) in the Dataset.
         """
-        if self.handle is None:
+        if self._handle is None:
             raise LightGBMError("Cannot get feature_name before construct dataset")
         num_feature = self.num_feature()
         tmp_out_len = ctypes.c_int(0)
         reserved_string_buffer_size = 255
         required_string_buffer_size = ctypes.c_size_t(0)
         string_buffers = [ctypes.create_string_buffer(reserved_string_buffer_size) for _ in range(num_feature)]
         ptr_string_buffers = (ctypes.c_char_p * num_feature)(*map(ctypes.addressof, string_buffers))
         _safe_call(_LIB.LGBM_DatasetGetFeatureNames(
-            self.handle,
+            self._handle,
             ctypes.c_int(num_feature),
             ctypes.byref(tmp_out_len),
             ctypes.c_size_t(reserved_string_buffer_size),
             ctypes.byref(required_string_buffer_size),
             ptr_string_buffers))
         if num_feature != tmp_out_len.value:
             raise ValueError("Length of feature names doesn't equal with num_feature")
         actual_string_buffer_size = required_string_buffer_size.value
         # if buffer length is not long enough, reallocate buffers
         if reserved_string_buffer_size < actual_string_buffer_size:
             string_buffers = [ctypes.create_string_buffer(actual_string_buffer_size) for _ in range(num_feature)]
             ptr_string_buffers = (ctypes.c_char_p * num_feature)(*map(ctypes.addressof, string_buffers))
             _safe_call(_LIB.LGBM_DatasetGetFeatureNames(
-                self.handle,
+                self._handle,
                 ctypes.c_int(num_feature),
                 ctypes.byref(tmp_out_len),
                 ctypes.c_size_t(actual_string_buffer_size),
                 ctypes.byref(required_string_buffer_size),
                 ptr_string_buffers))
         return [string_buffers[i].value.decode('utf-8') for i in range(num_feature)]
 
-    def get_label(self):
+    def get_label(self) -> Optional[np.ndarray]:
         """Get the label of the Dataset.
 
         Returns
         -------
         label : numpy array or None
             The label information from the Dataset.
         """
         if self.label is None:
             self.label = self.get_field('label')
         return self.label
 
-    def get_weight(self):
+    def get_weight(self) -> Optional[np.ndarray]:
         """Get the weight of the Dataset.
 
         Returns
         -------
         weight : numpy array or None
-            Weight for each data point from the Dataset.
+            Weight for each data point from the Dataset. Weights should be non-negative.
         """
         if self.weight is None:
             self.weight = self.get_field('weight')
         return self.weight
 
-    def get_init_score(self):
+    def get_init_score(self) -> Optional[np.ndarray]:
         """Get the initial score of the Dataset.
 
         Returns
         -------
         init_score : numpy array or None
             Init score of Booster.
         """
         if self.init_score is None:
             self.init_score = self.get_field('init_score')
         return self.init_score
 
-    def get_data(self):
+    def get_data(self) -> Optional[_LGBM_TrainDataType]:
         """Get the raw data of the Dataset.
 
         Returns
         -------
         data : str, pathlib.Path, numpy array, pandas DataFrame, H2O DataTable's Frame, scipy.sparse, Sequence, list of Sequence or list of numpy array or None
             Raw data used in the Dataset construction.
         """
-        if self.handle is None:
+        if self._handle is None:
             raise Exception("Cannot get data before construct Dataset")
-        if self.need_slice and self.used_indices is not None and self.reference is not None:
+        if self._need_slice and self.used_indices is not None and self.reference is not None:
             self.data = self.reference.data
             if self.data is not None:
-                if isinstance(self.data, np.ndarray) or scipy.sparse.issparse(self.data):
+                if isinstance(self.data, np.ndarray) or isinstance(self.data, scipy.sparse.spmatrix):
                     self.data = self.data[self.used_indices, :]
                 elif isinstance(self.data, pd_DataFrame):
                     self.data = self.data.iloc[self.used_indices].copy()
                 elif isinstance(self.data, dt_DataTable):
                     self.data = self.data[self.used_indices, :]
                 elif isinstance(self.data, Sequence):
                     self.data = self.data[self.used_indices]
                 elif isinstance(self.data, list) and len(self.data) > 0 and all(isinstance(x, Sequence) for x in self.data):
-                    self.data = np.array([row for row in self._yield_row_from_seqlist(self.data, self.used_indices)])
+                    self.data = np.array(list(self._yield_row_from_seqlist(self.data, self.used_indices)))
                 else:
                     _log_warning(f"Cannot subset {type(self.data).__name__} type of raw data.\n"
                                  "Returning original raw data")
-            self.need_slice = False
+            self._need_slice = False
         if self.data is None:
             raise LightGBMError("Cannot call `get_data` after freed raw data, "
                                 "set free_raw_data=False when construct Dataset to avoid this.")
         return self.data
 
-    def get_group(self):
+    def get_group(self) -> Optional[np.ndarray]:
         """Get the group of the Dataset.
 
         Returns
         -------
         group : numpy array or None
             Group/query data.
             Only used in the learning-to-rank task.
@@ -2351,47 +2803,75 @@
         if self.group is None:
             self.group = self.get_field('group')
             if self.group is not None:
                 # group data from LightGBM is boundaries data, need to convert to group size
                 self.group = np.diff(self.group)
         return self.group
 
-    def num_data(self):
+    def num_data(self) -> int:
         """Get the number of rows in the Dataset.
 
         Returns
         -------
         number_of_rows : int
             The number of rows in the Dataset.
         """
-        if self.handle is not None:
+        if self._handle is not None:
             ret = ctypes.c_int(0)
-            _safe_call(_LIB.LGBM_DatasetGetNumData(self.handle,
+            _safe_call(_LIB.LGBM_DatasetGetNumData(self._handle,
                                                    ctypes.byref(ret)))
             return ret.value
         else:
             raise LightGBMError("Cannot get num_data before construct dataset")
 
-    def num_feature(self):
+    def num_feature(self) -> int:
         """Get the number of columns (features) in the Dataset.
 
         Returns
         -------
         number_of_columns : int
             The number of columns (features) in the Dataset.
         """
-        if self.handle is not None:
+        if self._handle is not None:
             ret = ctypes.c_int(0)
-            _safe_call(_LIB.LGBM_DatasetGetNumFeature(self.handle,
+            _safe_call(_LIB.LGBM_DatasetGetNumFeature(self._handle,
                                                       ctypes.byref(ret)))
             return ret.value
         else:
             raise LightGBMError("Cannot get num_feature before construct dataset")
 
-    def get_ref_chain(self, ref_limit=100):
+    def feature_num_bin(self, feature: Union[int, str]) -> int:
+        """Get the number of bins for a feature.
+
+        .. versionadded:: 4.0.0
+
+        Parameters
+        ----------
+        feature : int or str
+            Index or name of the feature.
+
+        Returns
+        -------
+        number_of_bins : int
+            The number of constructed bins for the feature in the Dataset.
+        """
+        if self._handle is not None:
+            if isinstance(feature, str):
+                feature_index = self.feature_name.index(feature)
+            else:
+                feature_index = feature
+            ret = ctypes.c_int(0)
+            _safe_call(_LIB.LGBM_DatasetGetFeatureNumBin(self._handle,
+                                                         ctypes.c_int(feature_index),
+                                                         ctypes.byref(ret)))
+            return ret.value
+        else:
+            raise LightGBMError("Cannot get feature_num_bin before construct dataset")
+
+    def get_ref_chain(self, ref_limit: int = 100) -> Set["Dataset"]:
         """Get a chain of Dataset objects.
 
         Starts with r, then goes to r.reference (if exists),
         then to r.reference.reference, etc.
         until we hit ``ref_limit`` or a reference loop.
 
         Parameters
@@ -2401,63 +2881,63 @@
 
         Returns
         -------
         ref_chain : set of Dataset
             Chain of references of the Datasets.
         """
         head = self
-        ref_chain = set()
+        ref_chain: Set[Dataset] = set()
         while len(ref_chain) < ref_limit:
             if isinstance(head, Dataset):
                 ref_chain.add(head)
                 if (head.reference is not None) and (head.reference not in ref_chain):
                     head = head.reference
                 else:
                     break
             else:
                 break
         return ref_chain
 
-    def add_features_from(self, other):
+    def add_features_from(self, other: "Dataset") -> "Dataset":
         """Add features from other Dataset to the current Dataset.
 
         Both Datasets must be constructed before calling this method.
 
         Parameters
         ----------
         other : Dataset
             The Dataset to take features from.
 
         Returns
         -------
         self : Dataset
             Dataset with the new features added.
         """
-        if self.handle is None or other.handle is None:
+        if self._handle is None or other._handle is None:
             raise ValueError('Both source and target Datasets must be constructed before adding features')
-        _safe_call(_LIB.LGBM_DatasetAddFeaturesFrom(self.handle, other.handle))
+        _safe_call(_LIB.LGBM_DatasetAddFeaturesFrom(self._handle, other._handle))
         was_none = self.data is None
         old_self_data_type = type(self.data).__name__
         if other.data is None:
             self.data = None
         elif self.data is not None:
             if isinstance(self.data, np.ndarray):
                 if isinstance(other.data, np.ndarray):
                     self.data = np.hstack((self.data, other.data))
-                elif scipy.sparse.issparse(other.data):
+                elif isinstance(other.data, scipy.sparse.spmatrix):
                     self.data = np.hstack((self.data, other.data.toarray()))
                 elif isinstance(other.data, pd_DataFrame):
                     self.data = np.hstack((self.data, other.data.values))
                 elif isinstance(other.data, dt_DataTable):
                     self.data = np.hstack((self.data, other.data.to_numpy()))
                 else:
                     self.data = None
-            elif scipy.sparse.issparse(self.data):
+            elif isinstance(self.data, scipy.sparse.spmatrix):
                 sparse_format = self.data.getformat()
-                if isinstance(other.data, np.ndarray) or scipy.sparse.issparse(other.data):
+                if isinstance(other.data, np.ndarray) or isinstance(other.data, scipy.sparse.spmatrix):
                     self.data = scipy.sparse.hstack((self.data, other.data), format=sparse_format)
                 elif isinstance(other.data, pd_DataFrame):
                     self.data = scipy.sparse.hstack((self.data, other.data.values), format=sparse_format)
                 elif isinstance(other.data, dt_DataTable):
                     self.data = scipy.sparse.hstack((self.data, other.data.to_numpy()), format=sparse_format)
                 else:
                     self.data = None
@@ -2465,29 +2945,29 @@
                 if not PANDAS_INSTALLED:
                     raise LightGBMError("Cannot add features to DataFrame type of raw data "
                                         "without pandas installed. "
                                         "Install pandas and restart your session.")
                 if isinstance(other.data, np.ndarray):
                     self.data = concat((self.data, pd_DataFrame(other.data)),
                                        axis=1, ignore_index=True)
-                elif scipy.sparse.issparse(other.data):
+                elif isinstance(other.data, scipy.sparse.spmatrix):
                     self.data = concat((self.data, pd_DataFrame(other.data.toarray())),
                                        axis=1, ignore_index=True)
                 elif isinstance(other.data, pd_DataFrame):
                     self.data = concat((self.data, other.data),
                                        axis=1, ignore_index=True)
                 elif isinstance(other.data, dt_DataTable):
                     self.data = concat((self.data, pd_DataFrame(other.data.to_numpy())),
                                        axis=1, ignore_index=True)
                 else:
                     self.data = None
             elif isinstance(self.data, dt_DataTable):
                 if isinstance(other.data, np.ndarray):
                     self.data = dt_DataTable(np.hstack((self.data.to_numpy(), other.data)))
-                elif scipy.sparse.issparse(other.data):
+                elif isinstance(other.data, scipy.sparse.spmatrix):
                     self.data = dt_DataTable(np.hstack((self.data.to_numpy(), other.data.toarray())))
                 elif isinstance(other.data, pd_DataFrame):
                     self.data = dt_DataTable(np.hstack((self.data.to_numpy(), other.data.values)))
                 elif isinstance(other.data, dt_DataTable):
                     self.data = dt_DataTable(np.hstack((self.data.to_numpy(), other.data.to_numpy())))
                 else:
                     self.data = None
@@ -2502,15 +2982,15 @@
         self.feature_name = self.get_feature_name()
         _log_warning("Reseting categorical features.\n"
                      "You can set new categorical features via ``set_categorical_feature`` method")
         self.categorical_feature = "auto"
         self.pandas_categorical = None
         return self
 
-    def _dump_text(self, filename):
+    def _dump_text(self, filename: Union[str, Path]) -> "Dataset":
         """Save Dataset to a text file.
 
         This format cannot be loaded back in by LightGBM, but is useful for debugging purposes.
 
         Parameters
         ----------
         filename : str or pathlib.Path
@@ -2518,55 +2998,66 @@
 
         Returns
         -------
         self : Dataset
             Returns self.
         """
         _safe_call(_LIB.LGBM_DatasetDumpText(
-            self.construct().handle,
-            c_str(str(filename))))
+            self.construct()._handle,
+            _c_str(str(filename))))
         return self
 
 
+_LGBM_CustomObjectiveFunction = Callable[
+    [np.ndarray, Dataset],
+    Tuple[np.ndarray, np.ndarray]
+]
+_LGBM_CustomEvalFunction = Union[
+    Callable[
+        [np.ndarray, Dataset],
+        _LGBM_EvalFunctionResultType
+    ],
+    Callable[
+        [np.ndarray, Dataset],
+        List[_LGBM_EvalFunctionResultType]
+    ]
+]
+
+
 class Booster:
     """Booster in LightGBM."""
 
-    def __init__(self, params=None, train_set=None, model_file=None, model_str=None, silent='warn'):
+    def __init__(
+        self,
+        params: Optional[Dict[str, Any]] = None,
+        train_set: Optional[Dataset] = None,
+        model_file: Optional[Union[str, Path]] = None,
+        model_str: Optional[str] = None
+    ):
         """Initialize the Booster.
 
         Parameters
         ----------
         params : dict or None, optional (default=None)
             Parameters for Booster.
         train_set : Dataset or None, optional (default=None)
             Training dataset.
         model_file : str, pathlib.Path or None, optional (default=None)
             Path to the model file.
         model_str : str or None, optional (default=None)
             Model will be loaded from this string.
-        silent : bool, optional (default=False)
-            Whether to print messages during construction.
         """
-        self.handle = None
-        self.network = False
+        self._handle = None
+        self._network = False
         self.__need_reload_eval_info = True
         self._train_data_name = "training"
-        self.__attr = {}
         self.__set_objective_to_none = False
         self.best_iteration = -1
-        self.best_score = {}
+        self.best_score: _LGBM_BoosterBestScoreType = {}
         params = {} if params is None else deepcopy(params)
-        # user can set verbose with params, it has higher priority
-        if silent != 'warn':
-            _log_warning("'silent' argument is deprecated and will be removed in a future release of LightGBM. "
-                         "Pass 'verbose' parameter via 'params' instead.")
-        else:
-            silent = False
-        if not any(verbose_alias in params for verbose_alias in _ConfigAliases.get("verbosity")) and silent:
-            params["verbose"] = -1
         if train_set is not None:
             # Training task
             if not isinstance(train_set, Dataset):
                 raise TypeError(f'Training data should be Dataset instance, met {type(train_set).__name__}')
             params = _choose_param_value(
                 main_param_name="machines",
                 params=params,
@@ -2601,117 +3092,142 @@
                     listen_time_out=params.get("time_out", 120),
                     num_machines=params["num_machines"]
                 )
             # construct booster object
             train_set.construct()
             # copy the parameters from train_set
             params.update(train_set.get_params())
-            params_str = param_dict_to_str(params)
-            self.handle = ctypes.c_void_p()
+            params_str = _param_dict_to_str(params)
+            self._handle = ctypes.c_void_p()
             _safe_call(_LIB.LGBM_BoosterCreate(
-                train_set.handle,
-                c_str(params_str),
-                ctypes.byref(self.handle)))
+                train_set._handle,
+                _c_str(params_str),
+                ctypes.byref(self._handle)))
             # save reference to data
             self.train_set = train_set
-            self.valid_sets = []
-            self.name_valid_sets = []
+            self.valid_sets: List[Dataset] = []
+            self.name_valid_sets: List[str] = []
             self.__num_dataset = 1
             self.__init_predictor = train_set._predictor
             if self.__init_predictor is not None:
                 _safe_call(_LIB.LGBM_BoosterMerge(
-                    self.handle,
-                    self.__init_predictor.handle))
+                    self._handle,
+                    self.__init_predictor._handle))
             out_num_class = ctypes.c_int(0)
             _safe_call(_LIB.LGBM_BoosterGetNumClasses(
-                self.handle,
+                self._handle,
                 ctypes.byref(out_num_class)))
             self.__num_class = out_num_class.value
             # buffer for inner predict
-            self.__inner_predict_buffer = [None]
+            self.__inner_predict_buffer: List[Optional[np.ndarray]] = [None]
             self.__is_predicted_cur_iter = [False]
             self.__get_eval_info()
             self.pandas_categorical = train_set.pandas_categorical
             self.train_set_version = train_set.version
         elif model_file is not None:
             # Prediction task
             out_num_iterations = ctypes.c_int(0)
-            self.handle = ctypes.c_void_p()
+            self._handle = ctypes.c_void_p()
             _safe_call(_LIB.LGBM_BoosterCreateFromModelfile(
-                c_str(str(model_file)),
+                _c_str(str(model_file)),
                 ctypes.byref(out_num_iterations),
-                ctypes.byref(self.handle)))
+                ctypes.byref(self._handle)))
             out_num_class = ctypes.c_int(0)
             _safe_call(_LIB.LGBM_BoosterGetNumClasses(
-                self.handle,
+                self._handle,
                 ctypes.byref(out_num_class)))
             self.__num_class = out_num_class.value
             self.pandas_categorical = _load_pandas_categorical(file_name=model_file)
+            if params:
+                _log_warning('Ignoring params argument, using parameters from model file.')
+            params = self._get_loaded_param()
         elif model_str is not None:
-            self.model_from_string(model_str, verbose="_silent_false")
+            self.model_from_string(model_str)
         else:
             raise TypeError('Need at least one training dataset or model file or model string '
                             'to create Booster instance')
         self.params = params
 
-    def __del__(self):
+    def __del__(self) -> None:
         try:
-            if self.network:
+            if self._network:
                 self.free_network()
         except AttributeError:
             pass
         try:
-            if self.handle is not None:
-                _safe_call(_LIB.LGBM_BoosterFree(self.handle))
+            if self._handle is not None:
+                _safe_call(_LIB.LGBM_BoosterFree(self._handle))
         except AttributeError:
             pass
 
-    def __copy__(self):
+    def __copy__(self) -> "Booster":
         return self.__deepcopy__(None)
 
-    def __deepcopy__(self, _):
+    def __deepcopy__(self, _) -> "Booster":
         model_str = self.model_to_string(num_iteration=-1)
         booster = Booster(model_str=model_str)
         return booster
 
-    def __getstate__(self):
+    def __getstate__(self) -> Dict[str, Any]:
         this = self.__dict__.copy()
-        handle = this['handle']
+        handle = this['_handle']
         this.pop('train_set', None)
         this.pop('valid_sets', None)
         if handle is not None:
-            this["handle"] = self.model_to_string(num_iteration=-1)
+            this["_handle"] = self.model_to_string(num_iteration=-1)
         return this
 
-    def __setstate__(self, state):
-        model_str = state.get('handle', None)
+    def __setstate__(self, state: Dict[str, Any]) -> None:
+        model_str = state.get('_handle', state.get('handle', None))
         if model_str is not None:
             handle = ctypes.c_void_p()
             out_num_iterations = ctypes.c_int(0)
             _safe_call(_LIB.LGBM_BoosterLoadModelFromString(
-                c_str(model_str),
+                _c_str(model_str),
                 ctypes.byref(out_num_iterations),
                 ctypes.byref(handle)))
-            state['handle'] = handle
+            state['_handle'] = handle
         self.__dict__.update(state)
 
-    def free_dataset(self):
+    def _get_loaded_param(self) -> Dict[str, Any]:
+        buffer_len = 1 << 20
+        tmp_out_len = ctypes.c_int64(0)
+        string_buffer = ctypes.create_string_buffer(buffer_len)
+        ptr_string_buffer = ctypes.c_char_p(*[ctypes.addressof(string_buffer)])
+        _safe_call(_LIB.LGBM_BoosterGetLoadedParam(
+            self._handle,
+            ctypes.c_int64(buffer_len),
+            ctypes.byref(tmp_out_len),
+            ptr_string_buffer))
+        actual_len = tmp_out_len.value
+        # if buffer length is not long enough, re-allocate a buffer
+        if actual_len > buffer_len:
+            string_buffer = ctypes.create_string_buffer(actual_len)
+            ptr_string_buffer = ctypes.c_char_p(*[ctypes.addressof(string_buffer)])
+            _safe_call(_LIB.LGBM_BoosterGetLoadedParam(
+                self._handle,
+                ctypes.c_int64(actual_len),
+                ctypes.byref(tmp_out_len),
+                ptr_string_buffer))
+        return json.loads(string_buffer.value.decode('utf-8'))
+
+    def free_dataset(self) -> "Booster":
         """Free Booster's Datasets.
 
         Returns
         -------
         self : Booster
             Booster without Datasets.
         """
         self.__dict__.pop('train_set', None)
         self.__dict__.pop('valid_sets', None)
         self.__num_dataset = 0
         return self
 
-    def _free_buffer(self):
+    def _free_buffer(self) -> "Booster":
         self.__inner_predict_buffer = []
         self.__is_predicted_cur_iter = []
         return self
 
     def set_network(
         self,
         machines: Union[List[str], Set[str], str],
@@ -2735,34 +3251,34 @@
         Returns
         -------
         self : Booster
             Booster with set network.
         """
         if isinstance(machines, (list, set)):
             machines = ','.join(machines)
-        _safe_call(_LIB.LGBM_NetworkInit(c_str(machines),
+        _safe_call(_LIB.LGBM_NetworkInit(_c_str(machines),
                                          ctypes.c_int(local_listen_port),
                                          ctypes.c_int(listen_time_out),
                                          ctypes.c_int(num_machines)))
-        self.network = True
+        self._network = True
         return self
 
-    def free_network(self):
+    def free_network(self) -> "Booster":
         """Free Booster's network.
 
         Returns
         -------
         self : Booster
             Booster with freed network.
         """
         _safe_call(_LIB.LGBM_NetworkFree())
-        self.network = False
+        self._network = False
         return self
 
-    def trees_to_dataframe(self):
+    def trees_to_dataframe(self) -> pd_DataFrame:
         """Parse the fitted model and return in an easy-to-read pandas DataFrame.
 
         The returned DataFrame has the following columns.
 
             - ``tree_index`` : int64, which tree a node belongs to. 0-based, so a value of ``6``, for example, means "this node is in the 7th tree".
             - ``node_depth`` : int64, how far a node is from the root of the tree. The root node has a value of ``1``, its direct children are ``2``, etc.
             - ``node_index`` : str, unique identifier for a node.
@@ -2774,58 +3290,69 @@
             - ``threshold`` : float64, value of the feature used to decide which side of the split a record will go down. ``NaN`` for leaf nodes.
             - ``decision_type`` : str, logical operator describing how to compare a value to ``threshold``.
               For example, ``split_feature = "Column_10", threshold = 15, decision_type = "<="`` means that
               records where ``Column_10 <= 15`` follow the left side of the split, otherwise follows the right side of the split. ``None`` for leaf nodes.
             - ``missing_direction`` : str, split direction that missing values should go to. ``None`` for leaf nodes.
             - ``missing_type`` : str, describes what types of values are treated as missing.
             - ``value`` : float64, predicted value for this leaf node, multiplied by the learning rate.
-            - ``weight`` : float64 or int64, sum of hessian (second-order derivative of objective), summed over observations that fall in this node.
+            - ``weight`` : float64 or int64, sum of Hessian (second-order derivative of objective), summed over observations that fall in this node.
             - ``count`` : int64, number of records in the training data that fall into this node.
 
         Returns
         -------
         result : pandas DataFrame
             Returns a pandas DataFrame of the parsed model.
         """
         if not PANDAS_INSTALLED:
             raise LightGBMError('This method cannot be run without pandas installed. '
                                 'You must install pandas and restart your session to use this method.')
 
         if self.num_trees() == 0:
             raise LightGBMError('There are no trees in this Booster and thus nothing to parse')
 
-        def _is_split_node(tree):
+        def _is_split_node(tree: Dict[str, Any]) -> bool:
             return 'split_index' in tree.keys()
 
-        def create_node_record(tree, node_depth=1, tree_index=None,
-                               feature_names=None, parent_node=None):
-
-            def _get_node_index(tree, tree_index):
+        def create_node_record(
+            tree: Dict[str, Any],
+            node_depth: int = 1,
+            tree_index: Optional[int] = None,
+            feature_names: Optional[List[str]] = None,
+            parent_node: Optional[str] = None
+        ) -> Dict[str, Any]:
+
+            def _get_node_index(
+                tree: Dict[str, Any],
+                tree_index: Optional[int]
+            ) -> str:
                 tree_num = f'{tree_index}-' if tree_index is not None else ''
                 is_split = _is_split_node(tree)
                 node_type = 'S' if is_split else 'L'
                 # if a single node tree it won't have `leaf_index` so return 0
                 node_num = tree.get('split_index' if is_split else 'leaf_index', 0)
                 return f"{tree_num}{node_type}{node_num}"
 
-            def _get_split_feature(tree, feature_names):
+            def _get_split_feature(
+                tree: Dict[str, Any],
+                feature_names: Optional[List[str]]
+            ) -> Optional[str]:
                 if _is_split_node(tree):
                     if feature_names is not None:
                         feature_name = feature_names[tree['split_feature']]
                     else:
                         feature_name = tree['split_feature']
                 else:
                     feature_name = None
                 return feature_name
 
-            def _is_single_node_tree(tree):
+            def _is_single_node_tree(tree: Dict[str, Any]) -> bool:
                 return set(tree.keys()) == {'leaf_value'}
 
             # Create the node record, and populate universal data members
-            node = OrderedDict()
+            node: Dict[str, Union[int, str, None]] = OrderedDict()
             node['tree_index'] = tree_index
             node['node_depth'] = node_depth
             node['node_index'] = _get_node_index(tree, tree_index)
             node['left_child'] = None
             node['right_child'] = None
             node['parent_index'] = parent_node
             node['split_feature'] = _get_split_feature(tree, feature_names)
@@ -2854,51 +3381,57 @@
                 node['value'] = tree['leaf_value']
                 if not _is_single_node_tree(tree):
                     node['weight'] = tree['leaf_weight']
                     node['count'] = tree['leaf_count']
 
             return node
 
-        def tree_dict_to_node_list(tree, node_depth=1, tree_index=None,
-                                   feature_names=None, parent_node=None):
+        def tree_dict_to_node_list(
+            tree: Dict[str, Any],
+            node_depth: int = 1,
+            tree_index: Optional[int] = None,
+            feature_names: Optional[List[str]] = None,
+            parent_node: Optional[str] = None
+        ) -> List[Dict[str, Any]]:
 
-            node = create_node_record(tree,
+            node = create_node_record(tree=tree,
                                       node_depth=node_depth,
                                       tree_index=tree_index,
                                       feature_names=feature_names,
                                       parent_node=parent_node)
 
             res = [node]
 
             if _is_split_node(tree):
                 # traverse the next level of the tree
                 children = ['left_child', 'right_child']
                 for child in children:
                     subtree_list = tree_dict_to_node_list(
-                        tree[child],
+                        tree=tree[child],
                         node_depth=node_depth + 1,
                         tree_index=tree_index,
                         feature_names=feature_names,
-                        parent_node=node['node_index'])
+                        parent_node=node['node_index']
+                    )
                     # In tree format, "subtree_list" is a list of node records (dicts),
                     # and we add node to the list.
                     res.extend(subtree_list)
             return res
 
         model_dict = self.dump_model()
         feature_names = model_dict['feature_names']
         model_list = []
         for tree in model_dict['tree_info']:
-            model_list.extend(tree_dict_to_node_list(tree['tree_structure'],
+            model_list.extend(tree_dict_to_node_list(tree=tree['tree_structure'],
                                                      tree_index=tree['tree_index'],
                                                      feature_names=feature_names))
 
         return pd_DataFrame(model_list, columns=model_list[0].keys())
 
-    def set_train_data_name(self, name):
+    def set_train_data_name(self, name: str) -> "Booster":
         """Set the name to the training Dataset.
 
         Parameters
         ----------
         name : str
             Name for the training Dataset.
 
@@ -2906,15 +3439,15 @@
         -------
         self : Booster
             Booster with set training Dataset name.
         """
         self._train_data_name = name
         return self
 
-    def add_valid(self, data, name):
+    def add_valid(self, data: Dataset, name: str) -> "Booster":
         """Add validation data.
 
         Parameters
         ----------
         data : Dataset
             Validation data.
         name : str
@@ -2927,73 +3460,76 @@
         """
         if not isinstance(data, Dataset):
             raise TypeError(f'Validation data should be Dataset instance, met {type(data).__name__}')
         if data._predictor is not self.__init_predictor:
             raise LightGBMError("Add validation data failed, "
                                 "you should use same predictor for these data")
         _safe_call(_LIB.LGBM_BoosterAddValidData(
-            self.handle,
-            data.construct().handle))
+            self._handle,
+            data.construct()._handle))
         self.valid_sets.append(data)
         self.name_valid_sets.append(name)
         self.__num_dataset += 1
         self.__inner_predict_buffer.append(None)
         self.__is_predicted_cur_iter.append(False)
         return self
 
-    def reset_parameter(self, params):
+    def reset_parameter(self, params: Dict[str, Any]) -> "Booster":
         """Reset parameters of Booster.
 
         Parameters
         ----------
         params : dict
             New parameters for Booster.
 
         Returns
         -------
         self : Booster
             Booster with new parameters.
         """
-        params_str = param_dict_to_str(params)
+        params_str = _param_dict_to_str(params)
         if params_str:
             _safe_call(_LIB.LGBM_BoosterResetParameter(
-                self.handle,
-                c_str(params_str)))
+                self._handle,
+                _c_str(params_str)))
         self.params.update(params)
         return self
 
-    def update(self, train_set=None, fobj=None):
+    def update(
+        self,
+        train_set: Optional[Dataset] = None,
+        fobj: Optional[_LGBM_CustomObjectiveFunction] = None
+    ) -> bool:
         """Update Booster for one iteration.
 
         Parameters
         ----------
         train_set : Dataset or None, optional (default=None)
             Training data.
             If None, last training data is used.
         fobj : callable or None, optional (default=None)
             Customized objective function.
             Should accept two parameters: preds, train_data,
             and return (grad, hess).
 
-                preds : list or numpy 1-D array
+                preds : numpy 1-D array or numpy 2-D array (for multi-class task)
                     The predicted values.
                     Predicted values are returned before any transformation,
                     e.g. they are raw margin instead of probability of positive class for binary task.
                 train_data : Dataset
                     The training dataset.
-                grad : list or numpy 1-D array
+                grad : numpy 1-D array or numpy 2-D array (for multi-class task)
                     The value of the first order derivative (gradient) of the loss
                     with respect to the elements of preds for each sample point.
-                hess : list or numpy 1-D array
+                hess : numpy 1-D array or numpy 2-D array (for multi-class task)
                     The value of the second order derivative (Hessian) of the loss
                     with respect to the elements of preds for each sample point.
 
-            For multi-class task, the preds is group by class_id first, then group by row_id.
-            If you want to get i-th row preds in j-th class, the access way is score[j * num_data + i]
-            and you should group grad and hess in this way as well.
+            For multi-class task, preds are numpy 2-D array of shape = [n_samples, n_classes],
+            and grad and hess should be returned in the same format.
 
         Returns
         -------
         is_finished : bool
             Whether the update was successfully finished.
         """
         # need reset training data
@@ -3006,190 +3542,206 @@
             if not isinstance(train_set, Dataset):
                 raise TypeError(f'Training data should be Dataset instance, met {type(train_set).__name__}')
             if train_set._predictor is not self.__init_predictor:
                 raise LightGBMError("Replace training data failed, "
                                     "you should use same predictor for these data")
             self.train_set = train_set
             _safe_call(_LIB.LGBM_BoosterResetTrainingData(
-                self.handle,
-                self.train_set.construct().handle))
+                self._handle,
+                self.train_set.construct()._handle))
             self.__inner_predict_buffer[0] = None
             self.train_set_version = self.train_set.version
         is_finished = ctypes.c_int(0)
         if fobj is None:
             if self.__set_objective_to_none:
                 raise LightGBMError('Cannot update due to null objective function.')
             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(
-                self.handle,
+                self._handle,
                 ctypes.byref(is_finished)))
             self.__is_predicted_cur_iter = [False for _ in range(self.__num_dataset)]
             return is_finished.value == 1
         else:
             if not self.__set_objective_to_none:
                 self.reset_parameter({"objective": "none"}).__set_objective_to_none = True
             grad, hess = fobj(self.__inner_predict(0), self.train_set)
             return self.__boost(grad, hess)
 
-    def __boost(self, grad, hess):
+    def __boost(
+        self,
+        grad: np.ndarray,
+        hess: np.ndarray
+    ) -> bool:
         """Boost Booster for one iteration with customized gradient statistics.
 
         .. note::
 
             Score is returned before any transformation,
             e.g. it is raw margin instead of probability of positive class for binary task.
-            For multi-class task, the score is group by class_id first, then group by row_id.
-            If you want to get i-th row score in j-th class, the access way is score[j * num_data + i]
-            and you should group grad and hess in this way as well.
+            For multi-class task, score are numpy 2-D array of shape = [n_samples, n_classes],
+            and grad and hess should be returned in the same format.
 
         Parameters
         ----------
-        grad : list or numpy 1-D array
+        grad : numpy 1-D array or numpy 2-D array (for multi-class task)
             The value of the first order derivative (gradient) of the loss
             with respect to the elements of score for each sample point.
-        hess : list or numpy 1-D array
+        hess : numpy 1-D array or numpy 2-D array (for multi-class task)
             The value of the second order derivative (Hessian) of the loss
             with respect to the elements of score for each sample point.
 
         Returns
         -------
         is_finished : bool
             Whether the boost was successfully finished.
         """
-        grad = list_to_1d_numpy(grad, name='gradient')
-        hess = list_to_1d_numpy(hess, name='hessian')
+        if self.__num_class > 1:
+            grad = grad.ravel(order='F')
+            hess = hess.ravel(order='F')
+        grad = _list_to_1d_numpy(grad, dtype=np.float32, name='gradient')
+        hess = _list_to_1d_numpy(hess, dtype=np.float32, name='hessian')
         assert grad.flags.c_contiguous
         assert hess.flags.c_contiguous
         if len(grad) != len(hess):
-            raise ValueError(f"Lengths of gradient({len(grad)}) and hessian({len(hess)}) don't match")
+            raise ValueError(f"Lengths of gradient ({len(grad)}) and Hessian ({len(hess)}) don't match")
+        num_train_data = self.train_set.num_data()
+        if len(grad) != num_train_data * self.__num_class:
+            raise ValueError(
+                f"Lengths of gradient ({len(grad)}) and Hessian ({len(hess)}) "
+                f"don't match training data length ({num_train_data}) * "
+                f"number of models per one iteration ({self.__num_class})"
+            )
         is_finished = ctypes.c_int(0)
         _safe_call(_LIB.LGBM_BoosterUpdateOneIterCustom(
-            self.handle,
+            self._handle,
             grad.ctypes.data_as(ctypes.POINTER(ctypes.c_float)),
             hess.ctypes.data_as(ctypes.POINTER(ctypes.c_float)),
             ctypes.byref(is_finished)))
         self.__is_predicted_cur_iter = [False for _ in range(self.__num_dataset)]
         return is_finished.value == 1
 
-    def rollback_one_iter(self):
+    def rollback_one_iter(self) -> "Booster":
         """Rollback one iteration.
 
         Returns
         -------
         self : Booster
             Booster with rolled back one iteration.
         """
         _safe_call(_LIB.LGBM_BoosterRollbackOneIter(
-            self.handle))
+            self._handle))
         self.__is_predicted_cur_iter = [False for _ in range(self.__num_dataset)]
         return self
 
-    def current_iteration(self):
+    def current_iteration(self) -> int:
         """Get the index of the current iteration.
 
         Returns
         -------
         cur_iter : int
             The index of the current iteration.
         """
         out_cur_iter = ctypes.c_int(0)
         _safe_call(_LIB.LGBM_BoosterGetCurrentIteration(
-            self.handle,
+            self._handle,
             ctypes.byref(out_cur_iter)))
         return out_cur_iter.value
 
-    def num_model_per_iteration(self):
+    def num_model_per_iteration(self) -> int:
         """Get number of models per iteration.
 
         Returns
         -------
         model_per_iter : int
             The number of models per iteration.
         """
         model_per_iter = ctypes.c_int(0)
         _safe_call(_LIB.LGBM_BoosterNumModelPerIteration(
-            self.handle,
+            self._handle,
             ctypes.byref(model_per_iter)))
         return model_per_iter.value
 
-    def num_trees(self):
+    def num_trees(self) -> int:
         """Get number of weak sub-models.
 
         Returns
         -------
         num_trees : int
             The number of weak sub-models.
         """
         num_trees = ctypes.c_int(0)
         _safe_call(_LIB.LGBM_BoosterNumberOfTotalModel(
-            self.handle,
+            self._handle,
             ctypes.byref(num_trees)))
         return num_trees.value
 
-    def upper_bound(self):
+    def upper_bound(self) -> float:
         """Get upper bound value of a model.
 
         Returns
         -------
-        upper_bound : double
+        upper_bound : float
             Upper bound value of the model.
         """
         ret = ctypes.c_double(0)
         _safe_call(_LIB.LGBM_BoosterGetUpperBoundValue(
-            self.handle,
+            self._handle,
             ctypes.byref(ret)))
         return ret.value
 
-    def lower_bound(self):
+    def lower_bound(self) -> float:
         """Get lower bound value of a model.
 
         Returns
         -------
-        lower_bound : double
+        lower_bound : float
             Lower bound value of the model.
         """
         ret = ctypes.c_double(0)
         _safe_call(_LIB.LGBM_BoosterGetLowerBoundValue(
-            self.handle,
+            self._handle,
             ctypes.byref(ret)))
         return ret.value
 
-    def eval(self, data, name, feval=None):
+    def eval(
+        self,
+        data: Dataset,
+        name: str,
+        feval: Optional[Union[_LGBM_CustomEvalFunction, List[_LGBM_CustomEvalFunction]]] = None
+    ) -> List[_LGBM_BoosterEvalMethodResultType]:
         """Evaluate for data.
 
         Parameters
         ----------
         data : Dataset
             Data for the evaluating.
         name : str
             Name of the data.
-        feval : callable or None, optional (default=None)
+        feval : callable, list of callable, or None, optional (default=None)
             Customized evaluation function.
-            Should accept two parameters: preds, eval_data,
+            Each evaluation function should accept two parameters: preds, eval_data,
             and return (eval_name, eval_result, is_higher_better) or list of such tuples.
 
-                preds : list or numpy 1-D array
+                preds : numpy 1-D array or numpy 2-D array (for multi-class task)
                     The predicted values.
-                    If ``fobj`` is specified, predicted values are returned before any transformation,
+                    For multi-class task, preds are numpy 2-D array of shape = [n_samples, n_classes].
+                    If custom objective function is used, predicted values are returned before any transformation,
                     e.g. they are raw margin instead of probability of positive class for binary task in this case.
                 eval_data : Dataset
-                    The evaluation dataset.
+                    A ``Dataset`` to evaluate.
                 eval_name : str
                     The name of evaluation function (without whitespace).
                 eval_result : float
                     The eval result.
                 is_higher_better : bool
                     Is eval result higher better, e.g. AUC is ``is_higher_better``.
 
-            For multi-class task, the preds is group by class_id first, then group by row_id.
-            If you want to get i-th row preds in j-th class, the access way is preds[j * num_data + i].
-
         Returns
         -------
         result : list
-            List with evaluation results.
+            List with (dataset_name, eval_name, eval_result, is_higher_better) tuples.
         """
         if not isinstance(data, Dataset):
             raise TypeError("Can only eval for Dataset instance")
         data_idx = -1
         if data is self.train_set:
             data_idx = 0
         else:
@@ -3200,82 +3752,90 @@
         # need to push new valid data
         if data_idx == -1:
             self.add_valid(data, name)
             data_idx = self.__num_dataset - 1
 
         return self.__inner_eval(name, data_idx, feval)
 
-    def eval_train(self, feval=None):
+    def eval_train(
+        self,
+        feval: Optional[Union[_LGBM_CustomEvalFunction, List[_LGBM_CustomEvalFunction]]] = None
+    ) -> List[_LGBM_BoosterEvalMethodResultType]:
         """Evaluate for training data.
 
         Parameters
         ----------
-        feval : callable or None, optional (default=None)
+        feval : callable, list of callable, or None, optional (default=None)
             Customized evaluation function.
-            Should accept two parameters: preds, train_data,
+            Each evaluation function should accept two parameters: preds, eval_data,
             and return (eval_name, eval_result, is_higher_better) or list of such tuples.
 
-                preds : list or numpy 1-D array
+                preds : numpy 1-D array or numpy 2-D array (for multi-class task)
                     The predicted values.
-                    If ``fobj`` is specified, predicted values are returned before any transformation,
+                    For multi-class task, preds are numpy 2-D array of shape = [n_samples, n_classes].
+                    If custom objective function is used, predicted values are returned before any transformation,
                     e.g. they are raw margin instead of probability of positive class for binary task in this case.
-                train_data : Dataset
+                eval_data : Dataset
                     The training dataset.
                 eval_name : str
                     The name of evaluation function (without whitespace).
                 eval_result : float
                     The eval result.
                 is_higher_better : bool
                     Is eval result higher better, e.g. AUC is ``is_higher_better``.
 
-            For multi-class task, the preds is group by class_id first, then group by row_id.
-            If you want to get i-th row preds in j-th class, the access way is preds[j * num_data + i].
-
         Returns
         -------
         result : list
-            List with evaluation results.
+            List with (train_dataset_name, eval_name, eval_result, is_higher_better) tuples.
         """
         return self.__inner_eval(self._train_data_name, 0, feval)
 
-    def eval_valid(self, feval=None):
+    def eval_valid(
+        self,
+        feval: Optional[Union[_LGBM_CustomEvalFunction, List[_LGBM_CustomEvalFunction]]] = None
+    ) -> List[_LGBM_BoosterEvalMethodResultType]:
         """Evaluate for validation data.
 
         Parameters
         ----------
-        feval : callable or None, optional (default=None)
+        feval : callable, list of callable, or None, optional (default=None)
             Customized evaluation function.
-            Should accept two parameters: preds, valid_data,
+            Each evaluation function should accept two parameters: preds, eval_data,
             and return (eval_name, eval_result, is_higher_better) or list of such tuples.
 
-                preds : list or numpy 1-D array
+                preds : numpy 1-D array or numpy 2-D array (for multi-class task)
                     The predicted values.
-                    If ``fobj`` is specified, predicted values are returned before any transformation,
+                    For multi-class task, preds are numpy 2-D array of shape = [n_samples, n_classes].
+                    If custom objective function is used, predicted values are returned before any transformation,
                     e.g. they are raw margin instead of probability of positive class for binary task in this case.
-                valid_data : Dataset
+                eval_data : Dataset
                     The validation dataset.
                 eval_name : str
                     The name of evaluation function (without whitespace).
                 eval_result : float
                     The eval result.
                 is_higher_better : bool
                     Is eval result higher better, e.g. AUC is ``is_higher_better``.
 
-            For multi-class task, the preds is group by class_id first, then group by row_id.
-            If you want to get i-th row preds in j-th class, the access way is preds[j * num_data + i].
-
         Returns
         -------
         result : list
-            List with evaluation results.
+            List with (validation_dataset_name, eval_name, eval_result, is_higher_better) tuples.
         """
         return [item for i in range(1, self.__num_dataset)
                 for item in self.__inner_eval(self.name_valid_sets[i - 1], i, feval)]
 
-    def save_model(self, filename, num_iteration=None, start_iteration=0, importance_type='split'):
+    def save_model(
+        self,
+        filename: Union[str, Path],
+        num_iteration: Optional[int] = None,
+        start_iteration: int = 0,
+        importance_type: str = 'split'
+    ) -> "Booster":
         """Save Booster to file.
 
         Parameters
         ----------
         filename : str or pathlib.Path
             Filename to save Booster.
         num_iteration : int or None, optional (default=None)
@@ -3292,25 +3852,29 @@
         Returns
         -------
         self : Booster
             Returns self.
         """
         if num_iteration is None:
             num_iteration = self.best_iteration
-        importance_type_int = FEATURE_IMPORTANCE_TYPE_MAPPER[importance_type]
+        importance_type_int = _FEATURE_IMPORTANCE_TYPE_MAPPER[importance_type]
         _safe_call(_LIB.LGBM_BoosterSaveModel(
-            self.handle,
+            self._handle,
             ctypes.c_int(start_iteration),
             ctypes.c_int(num_iteration),
             ctypes.c_int(importance_type_int),
-            c_str(str(filename))))
+            _c_str(str(filename))))
         _dump_pandas_categorical(self.pandas_categorical, filename)
         return self
 
-    def shuffle_models(self, start_iteration=0, end_iteration=-1):
+    def shuffle_models(
+        self,
+        start_iteration: int = 0,
+        end_iteration: int = -1
+    ) -> "Booster":
         """Shuffle models.
 
         Parameters
         ----------
         start_iteration : int, optional (default=0)
             The first iteration that will be shuffled.
         end_iteration : int, optional (default=-1)
@@ -3319,58 +3883,55 @@
 
         Returns
         -------
         self : Booster
             Booster with shuffled models.
         """
         _safe_call(_LIB.LGBM_BoosterShuffleModels(
-            self.handle,
+            self._handle,
             ctypes.c_int(start_iteration),
             ctypes.c_int(end_iteration)))
         return self
 
-    def model_from_string(self, model_str, verbose='warn'):
+    def model_from_string(self, model_str: str) -> "Booster":
         """Load Booster from a string.
 
         Parameters
         ----------
         model_str : str
             Model will be loaded from this string.
-        verbose : bool, optional (default=True)
-            Whether to print messages while loading model.
 
         Returns
         -------
         self : Booster
             Loaded Booster object.
         """
-        if self.handle is not None:
-            _safe_call(_LIB.LGBM_BoosterFree(self.handle))
+        if self._handle is not None:
+            _safe_call(_LIB.LGBM_BoosterFree(self._handle))
         self._free_buffer()
-        self.handle = ctypes.c_void_p()
+        self._handle = ctypes.c_void_p()
         out_num_iterations = ctypes.c_int(0)
         _safe_call(_LIB.LGBM_BoosterLoadModelFromString(
-            c_str(model_str),
+            _c_str(model_str),
             ctypes.byref(out_num_iterations),
-            ctypes.byref(self.handle)))
+            ctypes.byref(self._handle)))
         out_num_class = ctypes.c_int(0)
         _safe_call(_LIB.LGBM_BoosterGetNumClasses(
-            self.handle,
+            self._handle,
             ctypes.byref(out_num_class)))
-        if verbose in {'warn', '_silent_false'}:
-            verbose = verbose == 'warn'
-        else:
-            _log_warning("'verbose' argument is deprecated and will be removed in a future release of LightGBM.")
-        if verbose:
-            _log_info(f'Finished loading model, total used {int(out_num_iterations.value)} iterations')
         self.__num_class = out_num_class.value
         self.pandas_categorical = _load_pandas_categorical(model_str=model_str)
         return self
 
-    def model_to_string(self, num_iteration=None, start_iteration=0, importance_type='split'):
+    def model_to_string(
+        self,
+        num_iteration: Optional[int] = None,
+        start_iteration: int = 0,
+        importance_type: str = 'split'
+    ) -> str:
         """Save Booster to string.
 
         Parameters
         ----------
         num_iteration : int or None, optional (default=None)
             Index of the iteration that should be saved.
             If None, if the best iteration exists, it is saved; otherwise, all iterations are saved.
@@ -3385,45 +3946,51 @@
         Returns
         -------
         str_repr : str
             String representation of Booster.
         """
         if num_iteration is None:
             num_iteration = self.best_iteration
-        importance_type_int = FEATURE_IMPORTANCE_TYPE_MAPPER[importance_type]
+        importance_type_int = _FEATURE_IMPORTANCE_TYPE_MAPPER[importance_type]
         buffer_len = 1 << 20
         tmp_out_len = ctypes.c_int64(0)
         string_buffer = ctypes.create_string_buffer(buffer_len)
         ptr_string_buffer = ctypes.c_char_p(*[ctypes.addressof(string_buffer)])
         _safe_call(_LIB.LGBM_BoosterSaveModelToString(
-            self.handle,
+            self._handle,
             ctypes.c_int(start_iteration),
             ctypes.c_int(num_iteration),
             ctypes.c_int(importance_type_int),
             ctypes.c_int64(buffer_len),
             ctypes.byref(tmp_out_len),
             ptr_string_buffer))
         actual_len = tmp_out_len.value
         # if buffer length is not long enough, re-allocate a buffer
         if actual_len > buffer_len:
             string_buffer = ctypes.create_string_buffer(actual_len)
             ptr_string_buffer = ctypes.c_char_p(*[ctypes.addressof(string_buffer)])
             _safe_call(_LIB.LGBM_BoosterSaveModelToString(
-                self.handle,
+                self._handle,
                 ctypes.c_int(start_iteration),
                 ctypes.c_int(num_iteration),
                 ctypes.c_int(importance_type_int),
                 ctypes.c_int64(actual_len),
                 ctypes.byref(tmp_out_len),
                 ptr_string_buffer))
         ret = string_buffer.value.decode('utf-8')
         ret += _dump_pandas_categorical(self.pandas_categorical)
         return ret
 
-    def dump_model(self, num_iteration=None, start_iteration=0, importance_type='split', object_hook=None):
+    def dump_model(
+        self,
+        num_iteration: Optional[int] = None,
+        start_iteration: int = 0,
+        importance_type: str = 'split',
+        object_hook: Optional[Callable[[Dict[str, Any]], Dict[str, Any]]] = None
+    ) -> Dict[str, Any]:
         """Dump Booster to JSON format.
 
         Parameters
         ----------
         num_iteration : int or None, optional (default=None)
             Index of the iteration that should be dumped.
             If None, if the best iteration exists, it is dumped; otherwise, all iterations are dumped.
@@ -3447,48 +4014,57 @@
         Returns
         -------
         json_repr : dict
             JSON format of Booster.
         """
         if num_iteration is None:
             num_iteration = self.best_iteration
-        importance_type_int = FEATURE_IMPORTANCE_TYPE_MAPPER[importance_type]
+        importance_type_int = _FEATURE_IMPORTANCE_TYPE_MAPPER[importance_type]
         buffer_len = 1 << 20
         tmp_out_len = ctypes.c_int64(0)
         string_buffer = ctypes.create_string_buffer(buffer_len)
         ptr_string_buffer = ctypes.c_char_p(*[ctypes.addressof(string_buffer)])
         _safe_call(_LIB.LGBM_BoosterDumpModel(
-            self.handle,
+            self._handle,
             ctypes.c_int(start_iteration),
             ctypes.c_int(num_iteration),
             ctypes.c_int(importance_type_int),
             ctypes.c_int64(buffer_len),
             ctypes.byref(tmp_out_len),
             ptr_string_buffer))
         actual_len = tmp_out_len.value
         # if buffer length is not long enough, reallocate a buffer
         if actual_len > buffer_len:
             string_buffer = ctypes.create_string_buffer(actual_len)
             ptr_string_buffer = ctypes.c_char_p(*[ctypes.addressof(string_buffer)])
             _safe_call(_LIB.LGBM_BoosterDumpModel(
-                self.handle,
+                self._handle,
                 ctypes.c_int(start_iteration),
                 ctypes.c_int(num_iteration),
                 ctypes.c_int(importance_type_int),
                 ctypes.c_int64(actual_len),
                 ctypes.byref(tmp_out_len),
                 ptr_string_buffer))
         ret = json.loads(string_buffer.value.decode('utf-8'), object_hook=object_hook)
         ret['pandas_categorical'] = json.loads(json.dumps(self.pandas_categorical,
-                                                          default=json_default_with_numpy))
+                                                          default=_json_default_with_numpy))
         return ret
 
-    def predict(self, data, start_iteration=0, num_iteration=None,
-                raw_score=False, pred_leaf=False, pred_contrib=False,
-                data_has_header=False, is_reshape=True, **kwargs):
+    def predict(
+        self,
+        data: _LGBM_PredictDataType,
+        start_iteration: int = 0,
+        num_iteration: Optional[int] = None,
+        raw_score: bool = False,
+        pred_leaf: bool = False,
+        pred_contrib: bool = False,
+        data_has_header: bool = False,
+        validate_features: bool = False,
+        **kwargs: Any
+    ) -> Union[np.ndarray, scipy.sparse.spmatrix, List[scipy.sparse.spmatrix]]:
         """Make a prediction.
 
         Parameters
         ----------
         data : str, pathlib.Path, numpy array, pandas DataFrame, H2O DataTable's Frame or scipy.sparse
             Data source for prediction.
             If str or pathlib.Path, it represents the path to a text file (CSV, TSV, or LibSVM).
@@ -3514,91 +4090,191 @@
                 you can install the shap package (https://github.com/slundberg/shap).
                 Note that unlike the shap package, with ``pred_contrib`` we return a matrix with an extra
                 column, where the last column is the expected value.
 
         data_has_header : bool, optional (default=False)
             Whether the data has header.
             Used only if data is str.
-        is_reshape : bool, optional (default=True)
-            If True, result is reshaped to [nrow, ncol].
+        validate_features : bool, optional (default=False)
+            If True, ensure that the features used to predict match the ones used to train.
+            Used only if data is pandas DataFrame.
         **kwargs
             Other parameters for the prediction.
 
         Returns
         -------
         result : numpy array, scipy.sparse or list of scipy.sparse
             Prediction result.
             Can be sparse or a list of sparse objects (each element represents predictions for one class) for feature contributions (when ``pred_contrib=True``).
         """
-        predictor = self._to_predictor(deepcopy(kwargs))
+        predictor = self._to_predictor(pred_parameter=deepcopy(kwargs))
         if num_iteration is None:
             if start_iteration <= 0:
                 num_iteration = self.best_iteration
             else:
                 num_iteration = -1
-        return predictor.predict(data, start_iteration, num_iteration,
-                                 raw_score, pred_leaf, pred_contrib,
-                                 data_has_header, is_reshape)
+        return predictor.predict(
+            data=data,
+            start_iteration=start_iteration,
+            num_iteration=num_iteration,
+            raw_score=raw_score,
+            pred_leaf=pred_leaf,
+            pred_contrib=pred_contrib,
+            data_has_header=data_has_header,
+            validate_features=validate_features
+        )
 
-    def refit(self, data, label, decay_rate=0.9, **kwargs):
+    def refit(
+        self,
+        data: _LGBM_TrainDataType,
+        label: _LGBM_LabelType,
+        decay_rate: float = 0.9,
+        reference: Optional[Dataset] = None,
+        weight: Optional[_LGBM_WeightType] = None,
+        group: Optional[_LGBM_GroupType] = None,
+        init_score: Optional[_LGBM_InitScoreType] = None,
+        feature_name: _LGBM_FeatureNameConfiguration = 'auto',
+        categorical_feature: _LGBM_CategoricalFeatureConfiguration = 'auto',
+        dataset_params: Optional[Dict[str, Any]] = None,
+        free_raw_data: bool = True,
+        validate_features: bool = False,
+        **kwargs
+    ) -> "Booster":
         """Refit the existing Booster by new data.
 
         Parameters
         ----------
-        data : str, pathlib.Path, numpy array, pandas DataFrame, H2O DataTable's Frame or scipy.sparse
+        data : str, pathlib.Path, numpy array, pandas DataFrame, H2O DataTable's Frame, scipy.sparse, Sequence, list of Sequence or list of numpy array
             Data source for refit.
             If str or pathlib.Path, it represents the path to a text file (CSV, TSV, or LibSVM).
         label : list, numpy 1-D array or pandas Series / one-column DataFrame
             Label for refit.
         decay_rate : float, optional (default=0.9)
             Decay rate of refit,
             will use ``leaf_output = decay_rate * old_leaf_output + (1.0 - decay_rate) * new_leaf_output`` to refit trees.
+        reference : Dataset or None, optional (default=None)
+            Reference for ``data``.
+
+            .. versionadded:: 4.0.0
+
+        weight : list, numpy 1-D array, pandas Series or None, optional (default=None)
+            Weight for each ``data`` instance. Weights should be non-negative.
+
+            .. versionadded:: 4.0.0
+
+        group : list, numpy 1-D array, pandas Series or None, optional (default=None)
+            Group/query size for ``data``.
+            Only used in the learning-to-rank task.
+            sum(group) = n_samples.
+            For example, if you have a 100-document dataset with ``group = [10, 20, 40, 10, 10, 10]``, that means that you have 6 groups,
+            where the first 10 records are in the first group, records 11-30 are in the second group, records 31-70 are in the third group, etc.
+
+            .. versionadded:: 4.0.0
+
+        init_score : list, list of lists (for multi-class task), numpy array, pandas Series, pandas DataFrame (for multi-class task), or None, optional (default=None)
+            Init score for ``data``.
+
+            .. versionadded:: 4.0.0
+
+        feature_name : list of str, or 'auto', optional (default="auto")
+            Feature names for ``data``.
+            If 'auto' and data is pandas DataFrame, data columns names are used.
+
+            .. versionadded:: 4.0.0
+
+        categorical_feature : list of str or int, or 'auto', optional (default="auto")
+            Categorical features for ``data``.
+            If list of int, interpreted as indices.
+            If list of str, interpreted as feature names (need to specify ``feature_name`` as well).
+            If 'auto' and data is pandas DataFrame, pandas unordered categorical columns are used.
+            All values in categorical features will be cast to int32 and thus should be less than int32 max value (2147483647).
+            Large values could be memory consuming. Consider using consecutive integers starting from zero.
+            All negative values in categorical features will be treated as missing values.
+            The output cannot be monotonically constrained with respect to a categorical feature.
+            Floating point numbers in categorical features will be rounded towards 0.
+
+            .. versionadded:: 4.0.0
+
+        dataset_params : dict or None, optional (default=None)
+            Other parameters for Dataset ``data``.
+
+            .. versionadded:: 4.0.0
+
+        free_raw_data : bool, optional (default=True)
+            If True, raw data is freed after constructing inner Dataset for ``data``.
+
+            .. versionadded:: 4.0.0
+
+        validate_features : bool, optional (default=False)
+            If True, ensure that the features used to refit the model match the original ones.
+            Used only if data is pandas DataFrame.
+
+            .. versionadded:: 4.0.0
+
         **kwargs
             Other parameters for refit.
             These parameters will be passed to ``predict`` method.
 
         Returns
         -------
         result : Booster
             Refitted Booster.
         """
         if self.__set_objective_to_none:
             raise LightGBMError('Cannot refit due to null objective function.')
-        predictor = self._to_predictor(deepcopy(kwargs))
-        leaf_preds = predictor.predict(data, -1, pred_leaf=True)
+        if dataset_params is None:
+            dataset_params = {}
+        predictor = self._to_predictor(pred_parameter=deepcopy(kwargs))
+        leaf_preds: np.ndarray = predictor.predict(  # type: ignore[assignment]
+            data=data,
+            start_iteration=-1,
+            pred_leaf=True,
+            validate_features=validate_features
+        )
         nrow, ncol = leaf_preds.shape
-        out_is_linear = ctypes.c_bool(False)
+        out_is_linear = ctypes.c_int(0)
         _safe_call(_LIB.LGBM_BoosterGetLinear(
-            self.handle,
+            self._handle,
             ctypes.byref(out_is_linear)))
         new_params = _choose_param_value(
             main_param_name="linear_tree",
             params=self.params,
             default_value=None
         )
-        new_params["linear_tree"] = out_is_linear.value
-        train_set = Dataset(data, label, silent=True, params=new_params)
+        new_params["linear_tree"] = bool(out_is_linear.value)
+        new_params.update(dataset_params)
+        train_set = Dataset(
+            data=data,
+            label=label,
+            reference=reference,
+            weight=weight,
+            group=group,
+            init_score=init_score,
+            feature_name=feature_name,
+            categorical_feature=categorical_feature,
+            params=new_params,
+            free_raw_data=free_raw_data,
+        )
         new_params['refit_decay_rate'] = decay_rate
         new_booster = Booster(new_params, train_set)
         # Copy models
         _safe_call(_LIB.LGBM_BoosterMerge(
-            new_booster.handle,
-            predictor.handle))
+            new_booster._handle,
+            predictor._handle))
         leaf_preds = leaf_preds.reshape(-1)
-        ptr_data, _, _ = c_int_array(leaf_preds)
+        ptr_data, _, _ = _c_int_array(leaf_preds)
         _safe_call(_LIB.LGBM_BoosterRefit(
-            new_booster.handle,
+            new_booster._handle,
             ptr_data,
             ctypes.c_int32(nrow),
             ctypes.c_int32(ncol)))
-        new_booster.network = self.network
-        new_booster.__attr = self.__attr.copy()
+        new_booster._network = self._network
         return new_booster
 
-    def get_leaf_output(self, tree_id, leaf_id):
+    def get_leaf_output(self, tree_id: int, leaf_id: int) -> float:
         """Get the output of a leaf.
 
         Parameters
         ----------
         tree_id : int
             The index of the tree.
         leaf_id : int
@@ -3607,79 +4283,120 @@
         Returns
         -------
         result : float
             The output of the leaf.
         """
         ret = ctypes.c_double(0)
         _safe_call(_LIB.LGBM_BoosterGetLeafValue(
-            self.handle,
+            self._handle,
             ctypes.c_int(tree_id),
             ctypes.c_int(leaf_id),
             ctypes.byref(ret)))
         return ret.value
 
-    def _to_predictor(self, pred_parameter=None):
+    def set_leaf_output(
+        self,
+        tree_id: int,
+        leaf_id: int,
+        value: float,
+    ) -> 'Booster':
+        """Set the output of a leaf.
+
+        .. versionadded:: 4.0.0
+
+        Parameters
+        ----------
+        tree_id : int
+            The index of the tree.
+        leaf_id : int
+            The index of the leaf in the tree.
+        value : float
+            Value to set as the output of the leaf.
+
+        Returns
+        -------
+        self : Booster
+            Booster with the leaf output set.
+        """
+        _safe_call(
+            _LIB.LGBM_BoosterSetLeafValue(
+                self._handle,
+                ctypes.c_int(tree_id),
+                ctypes.c_int(leaf_id),
+                ctypes.c_double(value)
+            )
+        )
+        return self
+
+    def _to_predictor(
+        self,
+        pred_parameter: Dict[str, Any]
+    ) -> _InnerPredictor:
         """Convert to predictor."""
-        predictor = _InnerPredictor(booster_handle=self.handle, pred_parameter=pred_parameter)
+        predictor = _InnerPredictor(booster_handle=self._handle, pred_parameter=pred_parameter)
         predictor.pandas_categorical = self.pandas_categorical
         return predictor
 
-    def num_feature(self):
+    def num_feature(self) -> int:
         """Get number of features.
 
         Returns
         -------
         num_feature : int
             The number of features.
         """
         out_num_feature = ctypes.c_int(0)
         _safe_call(_LIB.LGBM_BoosterGetNumFeature(
-            self.handle,
+            self._handle,
             ctypes.byref(out_num_feature)))
         return out_num_feature.value
 
-    def feature_name(self):
+    def feature_name(self) -> List[str]:
         """Get names of features.
 
         Returns
         -------
-        result : list
+        result : list of str
             List with names of features.
         """
         num_feature = self.num_feature()
         # Get name of features
         tmp_out_len = ctypes.c_int(0)
         reserved_string_buffer_size = 255
         required_string_buffer_size = ctypes.c_size_t(0)
         string_buffers = [ctypes.create_string_buffer(reserved_string_buffer_size) for _ in range(num_feature)]
         ptr_string_buffers = (ctypes.c_char_p * num_feature)(*map(ctypes.addressof, string_buffers))
         _safe_call(_LIB.LGBM_BoosterGetFeatureNames(
-            self.handle,
+            self._handle,
             ctypes.c_int(num_feature),
             ctypes.byref(tmp_out_len),
             ctypes.c_size_t(reserved_string_buffer_size),
             ctypes.byref(required_string_buffer_size),
             ptr_string_buffers))
         if num_feature != tmp_out_len.value:
             raise ValueError("Length of feature names doesn't equal with num_feature")
         actual_string_buffer_size = required_string_buffer_size.value
         # if buffer length is not long enough, reallocate buffers
         if reserved_string_buffer_size < actual_string_buffer_size:
             string_buffers = [ctypes.create_string_buffer(actual_string_buffer_size) for _ in range(num_feature)]
             ptr_string_buffers = (ctypes.c_char_p * num_feature)(*map(ctypes.addressof, string_buffers))
             _safe_call(_LIB.LGBM_BoosterGetFeatureNames(
-                self.handle,
+                self._handle,
                 ctypes.c_int(num_feature),
                 ctypes.byref(tmp_out_len),
                 ctypes.c_size_t(actual_string_buffer_size),
                 ctypes.byref(required_string_buffer_size),
                 ptr_string_buffers))
         return [string_buffers[i].value.decode('utf-8') for i in range(num_feature)]
 
-    def feature_importance(self, importance_type='split', iteration=None):
+    def feature_importance(
+        self,
+        importance_type: str = 'split',
+        iteration: Optional[int] = None
+    ) -> np.ndarray:
         """Get feature importances.
 
         Parameters
         ----------
         importance_type : str, optional (default="split")
             How the importance is calculated.
             If "split", result contains numbers of times the feature is used in a model.
@@ -3692,27 +4409,32 @@
         Returns
         -------
         result : numpy array
             Array with feature importances.
         """
         if iteration is None:
             iteration = self.best_iteration
-        importance_type_int = FEATURE_IMPORTANCE_TYPE_MAPPER[importance_type]
+        importance_type_int = _FEATURE_IMPORTANCE_TYPE_MAPPER[importance_type]
         result = np.empty(self.num_feature(), dtype=np.float64)
         _safe_call(_LIB.LGBM_BoosterFeatureImportance(
-            self.handle,
+            self._handle,
             ctypes.c_int(iteration),
             ctypes.c_int(importance_type_int),
             result.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))
-        if importance_type_int == 0:
+        if importance_type_int == _C_API_FEATURE_IMPORTANCE_SPLIT:
             return result.astype(np.int32)
         else:
             return result
 
-    def get_split_value_histogram(self, feature, bins=None, xgboost_style=False):
+    def get_split_value_histogram(
+        self,
+        feature: Union[int, str],
+        bins: Optional[Union[int, str]] = None,
+        xgboost_style: bool = False
+    ) -> Union[Tuple[np.ndarray, np.ndarray], np.ndarray, pd_DataFrame]:
         """Get split value histogram for the specified feature.
 
         Parameters
         ----------
         feature : int or str
             The feature name or index the histogram is calculated for.
             If int, interpreted as index.
@@ -3737,15 +4459,15 @@
         -------
         result_tuple : tuple of 2 numpy arrays
             If ``xgboost_style=False``, the values of the histogram of used splitting values for the specified feature
             and the bin edges.
         result_array_like : numpy array or pandas DataFrame (if pandas is installed)
             If ``xgboost_style=True``, the histogram of used splitting values for the specified feature.
         """
-        def add(root):
+        def add(root: Dict[str, Any]) -> None:
             """Recursively add thresholds."""
             if 'split_index' in root:  # non-leaf
                 if feature_names is not None and isinstance(feature, str):
                     split_feature = feature_names[root['split_feature']]
                 else:
                     split_feature = root['split_feature']
                 if split_feature == feature:
@@ -3755,15 +4477,15 @@
                         values.append(root['threshold'])
                 add(root['left_child'])
                 add(root['right_child'])
 
         model = self.dump_model()
         feature_names = model.get('feature_names')
         tree_infos = model['tree_info']
-        values = []
+        values: List[float] = []
         for tree_info in tree_infos:
             add(tree_info['tree_structure'])
 
         if bins is None or isinstance(bins, int) and xgboost_style:
             n_unique = len(np.unique(values))
             bins = max(min(n_unique, bins) if bins is not None else n_unique, 1)
         hist, bin_edges = np.histogram(values, bins=bins)
@@ -3773,25 +4495,30 @@
             if PANDAS_INSTALLED:
                 return pd_DataFrame(ret, columns=['SplitValue', 'Count'])
             else:
                 return ret
         else:
             return hist, bin_edges
 
-    def __inner_eval(self, data_name, data_idx, feval=None):
+    def __inner_eval(
+        self,
+        data_name: str,
+        data_idx: int,
+        feval: Optional[Union[_LGBM_CustomEvalFunction, List[_LGBM_CustomEvalFunction]]]
+    ) -> List[_LGBM_BoosterEvalMethodResultType]:
         """Evaluate training or validation data."""
         if data_idx >= self.__num_dataset:
             raise ValueError("Data_idx should be smaller than number of dataset")
         self.__get_eval_info()
         ret = []
         if self.__num_inner_eval > 0:
             result = np.empty(self.__num_inner_eval, dtype=np.float64)
             tmp_out_len = ctypes.c_int(0)
             _safe_call(_LIB.LGBM_BoosterGetEval(
-                self.handle,
+                self._handle,
                 ctypes.c_int(data_idx),
                 ctypes.byref(tmp_out_len),
                 result.ctypes.data_as(ctypes.POINTER(ctypes.c_double))))
             if tmp_out_len.value != self.__num_inner_eval:
                 raise ValueError("Wrong length of eval results")
             for i in range(self.__num_inner_eval):
                 ret.append((data_name, self.__name_inner_eval[i],
@@ -3811,59 +4538,63 @@
                     for eval_name, val, is_higher_better in feval_ret:
                         ret.append((data_name, eval_name, val, is_higher_better))
                 else:
                     eval_name, val, is_higher_better = feval_ret
                     ret.append((data_name, eval_name, val, is_higher_better))
         return ret
 
-    def __inner_predict(self, data_idx):
+    def __inner_predict(self, data_idx: int) -> np.ndarray:
         """Predict for training and validation dataset."""
         if data_idx >= self.__num_dataset:
             raise ValueError("Data_idx should be smaller than number of dataset")
         if self.__inner_predict_buffer[data_idx] is None:
             if data_idx == 0:
                 n_preds = self.train_set.num_data() * self.__num_class
             else:
                 n_preds = self.valid_sets[data_idx - 1].num_data() * self.__num_class
             self.__inner_predict_buffer[data_idx] = np.empty(n_preds, dtype=np.float64)
         # avoid to predict many time in one iteration
         if not self.__is_predicted_cur_iter[data_idx]:
             tmp_out_len = ctypes.c_int64(0)
-            data_ptr = self.__inner_predict_buffer[data_idx].ctypes.data_as(ctypes.POINTER(ctypes.c_double))
+            data_ptr = self.__inner_predict_buffer[data_idx].ctypes.data_as(ctypes.POINTER(ctypes.c_double))  # type: ignore[union-attr]
             _safe_call(_LIB.LGBM_BoosterGetPredict(
-                self.handle,
+                self._handle,
                 ctypes.c_int(data_idx),
                 ctypes.byref(tmp_out_len),
                 data_ptr))
-            if tmp_out_len.value != len(self.__inner_predict_buffer[data_idx]):
+            if tmp_out_len.value != len(self.__inner_predict_buffer[data_idx]):  # type: ignore[arg-type]
                 raise ValueError(f"Wrong length of predict results for data {data_idx}")
             self.__is_predicted_cur_iter[data_idx] = True
-        return self.__inner_predict_buffer[data_idx]
+        result: np.ndarray = self.__inner_predict_buffer[data_idx]  # type: ignore[assignment]
+        if self.__num_class > 1:
+            num_data = result.size // self.__num_class
+            result = result.reshape(num_data, self.__num_class, order='F')
+        return result
 
-    def __get_eval_info(self):
+    def __get_eval_info(self) -> None:
         """Get inner evaluation count and names."""
         if self.__need_reload_eval_info:
             self.__need_reload_eval_info = False
             out_num_eval = ctypes.c_int(0)
             # Get num of inner evals
             _safe_call(_LIB.LGBM_BoosterGetEvalCounts(
-                self.handle,
+                self._handle,
                 ctypes.byref(out_num_eval)))
             self.__num_inner_eval = out_num_eval.value
             if self.__num_inner_eval > 0:
                 # Get name of eval metrics
                 tmp_out_len = ctypes.c_int(0)
                 reserved_string_buffer_size = 255
                 required_string_buffer_size = ctypes.c_size_t(0)
                 string_buffers = [
                     ctypes.create_string_buffer(reserved_string_buffer_size) for _ in range(self.__num_inner_eval)
                 ]
                 ptr_string_buffers = (ctypes.c_char_p * self.__num_inner_eval)(*map(ctypes.addressof, string_buffers))
                 _safe_call(_LIB.LGBM_BoosterGetEvalNames(
-                    self.handle,
+                    self._handle,
                     ctypes.c_int(self.__num_inner_eval),
                     ctypes.byref(tmp_out_len),
                     ctypes.c_size_t(reserved_string_buffer_size),
                     ctypes.byref(required_string_buffer_size),
                     ptr_string_buffers))
                 if self.__num_inner_eval != tmp_out_len.value:
                     raise ValueError("Length of eval names doesn't equal with num_evals")
@@ -3871,58 +4602,19 @@
                 # if buffer length is not long enough, reallocate buffers
                 if reserved_string_buffer_size < actual_string_buffer_size:
                     string_buffers = [
                         ctypes.create_string_buffer(actual_string_buffer_size) for _ in range(self.__num_inner_eval)
                     ]
                     ptr_string_buffers = (ctypes.c_char_p * self.__num_inner_eval)(*map(ctypes.addressof, string_buffers))
                     _safe_call(_LIB.LGBM_BoosterGetEvalNames(
-                        self.handle,
+                        self._handle,
                         ctypes.c_int(self.__num_inner_eval),
                         ctypes.byref(tmp_out_len),
                         ctypes.c_size_t(actual_string_buffer_size),
                         ctypes.byref(required_string_buffer_size),
                         ptr_string_buffers))
                 self.__name_inner_eval = [
                     string_buffers[i].value.decode('utf-8') for i in range(self.__num_inner_eval)
                 ]
                 self.__higher_better_inner_eval = [
                     name.startswith(('auc', 'ndcg@', 'map@', 'average_precision')) for name in self.__name_inner_eval
                 ]
-
-    def attr(self, key):
-        """Get attribute string from the Booster.
-
-        Parameters
-        ----------
-        key : str
-            The name of the attribute.
-
-        Returns
-        -------
-        value : str or None
-            The attribute value.
-            Returns None if attribute does not exist.
-        """
-        return self.__attr.get(key, None)
-
-    def set_attr(self, **kwargs):
-        """Set attributes to the Booster.
-
-        Parameters
-        ----------
-        **kwargs
-            The attributes to set.
-            Setting a value to None deletes an attribute.
-
-        Returns
-        -------
-        self : Booster
-            Booster with set attributes.
-        """
-        for key, value in kwargs.items():
-            if value is not None:
-                if not isinstance(value, str):
-                    raise ValueError("Only string values are accepted")
-                self.__attr[key] = value
-            else:
-                self.__attr.pop(key, None)
-        return self
```

### Comparing `lightgbm-3.3.5/lightgbm/callback.py` & `lightgbm-4.0.0/lightgbm/callback.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,28 +1,45 @@
 # coding: utf-8
 """Callbacks library."""
 import collections
-from operator import gt, lt
-from typing import Any, Callable, Dict, List, Union
+from functools import partial
+from typing import Any, Callable, Dict, List, Tuple, Union
 
-from .basic import _ConfigAliases, _log_info, _log_warning
+from .basic import _ConfigAliases, _LGBM_BoosterEvalMethodResultType, _log_info, _log_warning
+
+__all__ = [
+    'early_stopping',
+    'log_evaluation',
+    'record_evaluation',
+    'reset_parameter',
+]
+
+_EvalResultDict = Dict[str, Dict[str, List[Any]]]
+_EvalResultTuple = Union[
+    _LGBM_BoosterEvalMethodResultType,
+    Tuple[str, str, float, bool, float]
+]
+_ListOfEvalResultTuples = Union[
+    List[_LGBM_BoosterEvalMethodResultType],
+    List[Tuple[str, str, float, bool, float]]
+]
 
 
 class EarlyStopException(Exception):
     """Exception of early stopping."""
 
-    def __init__(self, best_iteration: int, best_score: float) -> None:
+    def __init__(self, best_iteration: int, best_score: _ListOfEvalResultTuples) -> None:
         """Create early stopping exception.
 
         Parameters
         ----------
         best_iteration : int
             The best iteration stopped.
-        best_score : float
-            The score of the best iteration.
+        best_score : list of (eval_name, metric_name, eval_result, is_higher_better) tuple or (eval_name, metric_name, eval_result, is_higher_better, stdv) tuple
+            Scores for each metric, on each validation set, as of the best iteration.
         """
         super().__init__()
         self.best_iteration = best_iteration
         self.best_score = best_score
 
 
 # Callback environment used by callbacks
@@ -32,38 +49,44 @@
      "params",
      "iteration",
      "begin_iteration",
      "end_iteration",
      "evaluation_result_list"])
 
 
-def _format_eval_result(value: list, show_stdv: bool = True) -> str:
+def _format_eval_result(value: _EvalResultTuple, show_stdv: bool) -> str:
     """Format metric string."""
     if len(value) == 4:
         return f"{value[0]}'s {value[1]}: {value[2]:g}"
     elif len(value) == 5:
         if show_stdv:
-            return f"{value[0]}'s {value[1]}: {value[2]:g} + {value[4]:g}"
+            return f"{value[0]}'s {value[1]}: {value[2]:g} + {value[4]:g}"  # type: ignore[misc]
         else:
             return f"{value[0]}'s {value[1]}: {value[2]:g}"
     else:
         raise ValueError("Wrong metric value")
 
 
-def print_evaluation(period: int = 1, show_stdv: bool = True) -> Callable:
-    """Create a callback that logs the evaluation results.
+class _LogEvaluationCallback:
+    """Internal log evaluation callable class."""
 
-    Deprecated, use ``log_evaluation()`` instead.
-    """
-    _log_warning("'print_evaluation()' callback is deprecated and will be removed in a future release of LightGBM. "
-                 "Use 'log_evaluation()' callback instead.")
-    return log_evaluation(period=period, show_stdv=show_stdv)
+    def __init__(self, period: int = 1, show_stdv: bool = True) -> None:
+        self.order = 10
+        self.before_iteration = False
+
+        self.period = period
+        self.show_stdv = show_stdv
+
+    def __call__(self, env: CallbackEnv) -> None:
+        if self.period > 0 and env.evaluation_result_list and (env.iteration + 1) % self.period == 0:
+            result = '\t'.join([_format_eval_result(x, self.show_stdv) for x in env.evaluation_result_list])
+            _log_info(f'[{env.iteration + 1}]\t{result}')
 
 
-def log_evaluation(period: int = 1, show_stdv: bool = True) -> Callable:
+def log_evaluation(period: int = 1, show_stdv: bool = True) -> _LogEvaluationCallback:
     """Create a callback that logs the evaluation results.
 
     By default, standard output resource is used.
     Use ``register_logger()`` function to register a custom logger.
 
     Note
     ----
@@ -75,23 +98,58 @@
         The period to log the evaluation results.
         The last boosting stage or the boosting stage found by using ``early_stopping`` callback is also logged.
     show_stdv : bool, optional (default=True)
         Whether to log stdv (if provided).
 
     Returns
     -------
-    callback : callable
+    callback : _LogEvaluationCallback
         The callback that logs the evaluation results every ``period`` boosting iteration(s).
     """
-    def _callback(env: CallbackEnv) -> None:
-        if period > 0 and env.evaluation_result_list and (env.iteration + 1) % period == 0:
-            result = '\t'.join([_format_eval_result(x, show_stdv) for x in env.evaluation_result_list])
-            _log_info(f'[{env.iteration + 1}]\t{result}')
-    _callback.order = 10  # type: ignore
-    return _callback
+    return _LogEvaluationCallback(period=period, show_stdv=show_stdv)
+
+
+class _RecordEvaluationCallback:
+    """Internal record evaluation callable class."""
+
+    def __init__(self, eval_result: _EvalResultDict) -> None:
+        self.order = 20
+        self.before_iteration = False
+
+        if not isinstance(eval_result, dict):
+            raise TypeError('eval_result should be a dictionary')
+        self.eval_result = eval_result
+
+    def _init(self, env: CallbackEnv) -> None:
+        self.eval_result.clear()
+        for item in env.evaluation_result_list:
+            if len(item) == 4:  # regular train
+                data_name, eval_name = item[:2]
+            else:  # cv
+                data_name, eval_name = item[1].split()
+            self.eval_result.setdefault(data_name, collections.OrderedDict())
+            if len(item) == 4:
+                self.eval_result[data_name].setdefault(eval_name, [])
+            else:
+                self.eval_result[data_name].setdefault(f'{eval_name}-mean', [])
+                self.eval_result[data_name].setdefault(f'{eval_name}-stdv', [])
+
+    def __call__(self, env: CallbackEnv) -> None:
+        if env.iteration == env.begin_iteration:
+            self._init(env)
+        for item in env.evaluation_result_list:
+            if len(item) == 4:
+                data_name, eval_name, result = item[:3]
+                self.eval_result[data_name][eval_name].append(result)
+            else:
+                data_name, eval_name = item[1].split()
+                res_mean = item[2]
+                res_stdv = item[4]
+                self.eval_result[data_name][f'{eval_name}-mean'].append(res_mean)
+                self.eval_result[data_name][f'{eval_name}-stdv'].append(res_stdv)
 
 
 def record_evaluation(eval_result: Dict[str, Dict[str, List[Any]]]) -> Callable:
     """Create a callback that records the evaluation history into ``eval_result``.
 
     Parameters
     ----------
@@ -116,33 +174,46 @@
                  {
                   'logloss': [0.480385, 0.357756, ...]
                  }
             }
 
     Returns
     -------
-    callback : callable
+    callback : _RecordEvaluationCallback
         The callback that records the evaluation history into the passed dictionary.
     """
-    if not isinstance(eval_result, dict):
-        raise TypeError('eval_result should be a dictionary')
-    eval_result.clear()
-
-    def _init(env: CallbackEnv) -> None:
-        for data_name, eval_name, _, _ in env.evaluation_result_list:
-            eval_result.setdefault(data_name, collections.OrderedDict())
-            eval_result[data_name].setdefault(eval_name, [])
-
-    def _callback(env: CallbackEnv) -> None:
-        if not eval_result:
-            _init(env)
-        for data_name, eval_name, result, _ in env.evaluation_result_list:
-            eval_result[data_name][eval_name].append(result)
-    _callback.order = 20  # type: ignore
-    return _callback
+    return _RecordEvaluationCallback(eval_result=eval_result)
+
+
+class _ResetParameterCallback:
+    """Internal reset parameter callable class."""
+
+    def __init__(self, **kwargs: Union[list, Callable]) -> None:
+        self.order = 10
+        self.before_iteration = True
+
+        self.kwargs = kwargs
+
+    def __call__(self, env: CallbackEnv) -> None:
+        new_parameters = {}
+        for key, value in self.kwargs.items():
+            if isinstance(value, list):
+                if len(value) != env.end_iteration - env.begin_iteration:
+                    raise ValueError(f"Length of list {key!r} has to be equal to 'num_boost_round'.")
+                new_param = value[env.iteration - env.begin_iteration]
+            elif callable(value):
+                new_param = value(env.iteration - env.begin_iteration)
+            else:
+                raise ValueError("Only list and callable values are supported "
+                                 "as a mapping from boosting round index to new parameter value.")
+            if new_param != env.params.get(key, None):
+                new_parameters[key] = new_param
+        if new_parameters:
+            env.model.reset_parameter(new_parameters)
+            env.params.update(new_parameters)
 
 
 def reset_parameter(**kwargs: Union[list, Callable]) -> Callable:
     """Create a callback that resets the parameter after the first iteration.
 
     .. note::
 
@@ -155,41 +226,169 @@
         or a callable that calculates the parameter in terms of
         current number of round (e.g. yields learning rate decay).
         If list lst, parameter = lst[current_round].
         If callable func, parameter = func(current_round).
 
     Returns
     -------
-    callback : callable
+    callback : _ResetParameterCallback
         The callback that resets the parameter after the first iteration.
     """
-    def _callback(env: CallbackEnv) -> None:
-        new_parameters = {}
-        for key, value in kwargs.items():
-            if isinstance(value, list):
-                if len(value) != env.end_iteration - env.begin_iteration:
-                    raise ValueError(f"Length of list {key!r} has to equal to 'num_boost_round'.")
-                new_param = value[env.iteration - env.begin_iteration]
+    return _ResetParameterCallback(**kwargs)
+
+
+class _EarlyStoppingCallback:
+    """Internal early stopping callable class."""
+
+    def __init__(
+        self,
+        stopping_rounds: int,
+        first_metric_only: bool = False,
+        verbose: bool = True,
+        min_delta: Union[float, List[float]] = 0.0
+    ) -> None:
+        self.order = 30
+        self.before_iteration = False
+
+        self.stopping_rounds = stopping_rounds
+        self.first_metric_only = first_metric_only
+        self.verbose = verbose
+        self.min_delta = min_delta
+
+        self.enabled = True
+        self._reset_storages()
+
+    def _reset_storages(self) -> None:
+        self.best_score: List[float] = []
+        self.best_iter: List[int] = []
+        self.best_score_list: List[_ListOfEvalResultTuples] = []
+        self.cmp_op: List[Callable[[float, float], bool]] = []
+        self.first_metric = ''
+
+    def _gt_delta(self, curr_score: float, best_score: float, delta: float) -> bool:
+        return curr_score > best_score + delta
+
+    def _lt_delta(self, curr_score: float, best_score: float, delta: float) -> bool:
+        return curr_score < best_score - delta
+
+    def _is_train_set(self, ds_name: str, eval_name: str, train_name: str) -> bool:
+        return (ds_name == "cv_agg" and eval_name == "train") or ds_name == train_name
+
+    def _init(self, env: CallbackEnv) -> None:
+        is_dart = any(env.params.get(alias, "") == 'dart' for alias in _ConfigAliases.get("boosting"))
+        only_train_set = (
+            len(env.evaluation_result_list) == 1
+            and self._is_train_set(
+                ds_name=env.evaluation_result_list[0][0],
+                eval_name=env.evaluation_result_list[0][1].split(" ")[0],
+                train_name=env.model._train_data_name)
+        )
+        self.enabled = not is_dart and not only_train_set
+        if not self.enabled:
+            if is_dart:
+                _log_warning('Early stopping is not available in dart mode')
+            elif only_train_set:
+                _log_warning('Only training set found, disabling early stopping.')
+            return
+        if not env.evaluation_result_list:
+            raise ValueError('For early stopping, '
+                             'at least one dataset and eval metric is required for evaluation')
+
+        if self.stopping_rounds <= 0:
+            raise ValueError("stopping_rounds should be greater than zero.")
+
+        if self.verbose:
+            _log_info(f"Training until validation scores don't improve for {self.stopping_rounds} rounds")
+
+        self._reset_storages()
+
+        n_metrics = len({m[1] for m in env.evaluation_result_list})
+        n_datasets = len(env.evaluation_result_list) // n_metrics
+        if isinstance(self.min_delta, list):
+            if not all(t >= 0 for t in self.min_delta):
+                raise ValueError('Values for early stopping min_delta must be non-negative.')
+            if len(self.min_delta) == 0:
+                if self.verbose:
+                    _log_info('Disabling min_delta for early stopping.')
+                deltas = [0.0] * n_datasets * n_metrics
+            elif len(self.min_delta) == 1:
+                if self.verbose:
+                    _log_info(f'Using {self.min_delta[0]} as min_delta for all metrics.')
+                deltas = self.min_delta * n_datasets * n_metrics
             else:
-                new_param = value(env.iteration - env.begin_iteration)
-            if new_param != env.params.get(key, None):
-                new_parameters[key] = new_param
-        if new_parameters:
-            env.model.reset_parameter(new_parameters)
-            env.params.update(new_parameters)
-    _callback.before_iteration = True  # type: ignore
-    _callback.order = 10  # type: ignore
-    return _callback
+                if len(self.min_delta) != n_metrics:
+                    raise ValueError('Must provide a single value for min_delta or as many as metrics.')
+                if self.first_metric_only and self.verbose:
+                    _log_info(f'Using only {self.min_delta[0]} as early stopping min_delta.')
+                deltas = self.min_delta * n_datasets
+        else:
+            if self.min_delta < 0:
+                raise ValueError('Early stopping min_delta must be non-negative.')
+            if self.min_delta > 0 and n_metrics > 1 and not self.first_metric_only and self.verbose:
+                _log_info(f'Using {self.min_delta} as min_delta for all metrics.')
+            deltas = [self.min_delta] * n_datasets * n_metrics
+
+        # split is needed for "<dataset type> <metric>" case (e.g. "train l1")
+        self.first_metric = env.evaluation_result_list[0][1].split(" ")[-1]
+        for eval_ret, delta in zip(env.evaluation_result_list, deltas):
+            self.best_iter.append(0)
+            if eval_ret[3]:  # greater is better
+                self.best_score.append(float('-inf'))
+                self.cmp_op.append(partial(self._gt_delta, delta=delta))
+            else:
+                self.best_score.append(float('inf'))
+                self.cmp_op.append(partial(self._lt_delta, delta=delta))
+
+    def _final_iteration_check(self, env: CallbackEnv, eval_name_splitted: List[str], i: int) -> None:
+        if env.iteration == env.end_iteration - 1:
+            if self.verbose:
+                best_score_str = '\t'.join([_format_eval_result(x, show_stdv=True) for x in self.best_score_list[i]])
+                _log_info('Did not meet early stopping. '
+                          f'Best iteration is:\n[{self.best_iter[i] + 1}]\t{best_score_str}')
+                if self.first_metric_only:
+                    _log_info(f"Evaluated only: {eval_name_splitted[-1]}")
+            raise EarlyStopException(self.best_iter[i], self.best_score_list[i])
 
+    def __call__(self, env: CallbackEnv) -> None:
+        if env.iteration == env.begin_iteration:
+            self._init(env)
+        if not self.enabled:
+            return
+        # self.best_score_list is initialized to an empty list
+        first_time_updating_best_score_list = (self.best_score_list == [])
+        for i in range(len(env.evaluation_result_list)):
+            score = env.evaluation_result_list[i][2]
+            if first_time_updating_best_score_list or self.cmp_op[i](score, self.best_score[i]):
+                self.best_score[i] = score
+                self.best_iter[i] = env.iteration
+                if first_time_updating_best_score_list:
+                    self.best_score_list.append(env.evaluation_result_list)
+                else:
+                    self.best_score_list[i] = env.evaluation_result_list
+            # split is needed for "<dataset type> <metric>" case (e.g. "train l1")
+            eval_name_splitted = env.evaluation_result_list[i][1].split(" ")
+            if self.first_metric_only and self.first_metric != eval_name_splitted[-1]:
+                continue  # use only the first metric for early stopping
+            if self._is_train_set(env.evaluation_result_list[i][0], eval_name_splitted[0], env.model._train_data_name):
+                continue  # train data for lgb.cv or sklearn wrapper (underlying lgb.train)
+            elif env.iteration - self.best_iter[i] >= self.stopping_rounds:
+                if self.verbose:
+                    eval_result_str = '\t'.join([_format_eval_result(x, show_stdv=True) for x in self.best_score_list[i]])
+                    _log_info(f"Early stopping, best iteration is:\n[{self.best_iter[i] + 1}]\t{eval_result_str}")
+                    if self.first_metric_only:
+                        _log_info(f"Evaluated only: {eval_name_splitted[-1]}")
+                raise EarlyStopException(self.best_iter[i], self.best_score_list[i])
+            self._final_iteration_check(env, eval_name_splitted, i)
 
-def early_stopping(stopping_rounds: int, first_metric_only: bool = False, verbose: bool = True) -> Callable:
+
+def early_stopping(stopping_rounds: int, first_metric_only: bool = False, verbose: bool = True, min_delta: Union[float, List[float]] = 0.0) -> _EarlyStoppingCallback:
     """Create a callback that activates early stopping.
 
     Activates early stopping.
-    The model will train until the validation score stops improving.
+    The model will train until the validation score doesn't improve by at least ``min_delta``.
     Validation score needs to improve at least every ``stopping_rounds`` round(s)
     to continue training.
     Requires at least one validation data and one metric.
     If there's more than one, will check all of them. But the training data is ignored anyway.
     To check only the first metric set ``first_metric_only`` to True.
     The index of iteration that has the best performance will be saved in the ``best_iteration`` attribute of a model.
 
@@ -199,84 +398,20 @@
         The possible number of rounds without the trend occurrence.
     first_metric_only : bool, optional (default=False)
         Whether to use only the first metric for early stopping.
     verbose : bool, optional (default=True)
         Whether to log message with early stopping information.
         By default, standard output resource is used.
         Use ``register_logger()`` function to register a custom logger.
+    min_delta : float or list of float, optional (default=0.0)
+        Minimum improvement in score to keep training.
+        If float, this single value is used for all metrics.
+        If list, its length should match the total number of metrics.
+
+        .. versionadded:: 4.0.0
 
     Returns
     -------
-    callback : callable
+    callback : _EarlyStoppingCallback
         The callback that activates early stopping.
     """
-    best_score = []
-    best_iter = []
-    best_score_list: list = []
-    cmp_op = []
-    enabled = [True]
-    first_metric = ['']
-
-    def _init(env: CallbackEnv) -> None:
-        enabled[0] = not any(env.params.get(boost_alias, "") == 'dart' for boost_alias
-                             in _ConfigAliases.get("boosting"))
-        if not enabled[0]:
-            _log_warning('Early stopping is not available in dart mode')
-            return
-        if not env.evaluation_result_list:
-            raise ValueError('For early stopping, '
-                             'at least one dataset and eval metric is required for evaluation')
-
-        if verbose:
-            _log_info(f"Training until validation scores don't improve for {stopping_rounds} rounds")
-
-        # split is needed for "<dataset type> <metric>" case (e.g. "train l1")
-        first_metric[0] = env.evaluation_result_list[0][1].split(" ")[-1]
-        for eval_ret in env.evaluation_result_list:
-            best_iter.append(0)
-            best_score_list.append(None)
-            if eval_ret[3]:
-                best_score.append(float('-inf'))
-                cmp_op.append(gt)
-            else:
-                best_score.append(float('inf'))
-                cmp_op.append(lt)
-
-    def _final_iteration_check(env: CallbackEnv, eval_name_splitted: List[str], i: int) -> None:
-        if env.iteration == env.end_iteration - 1:
-            if verbose:
-                best_score_str = '\t'.join([_format_eval_result(x) for x in best_score_list[i]])
-                _log_info('Did not meet early stopping. '
-                          f'Best iteration is:\n[{best_iter[i] + 1}]\t{best_score_str}')
-                if first_metric_only:
-                    _log_info(f"Evaluated only: {eval_name_splitted[-1]}")
-            raise EarlyStopException(best_iter[i], best_score_list[i])
-
-    def _callback(env: CallbackEnv) -> None:
-        if not cmp_op:
-            _init(env)
-        if not enabled[0]:
-            return
-        for i in range(len(env.evaluation_result_list)):
-            score = env.evaluation_result_list[i][2]
-            if best_score_list[i] is None or cmp_op[i](score, best_score[i]):
-                best_score[i] = score
-                best_iter[i] = env.iteration
-                best_score_list[i] = env.evaluation_result_list
-            # split is needed for "<dataset type> <metric>" case (e.g. "train l1")
-            eval_name_splitted = env.evaluation_result_list[i][1].split(" ")
-            if first_metric_only and first_metric[0] != eval_name_splitted[-1]:
-                continue  # use only the first metric for early stopping
-            if ((env.evaluation_result_list[i][0] == "cv_agg" and eval_name_splitted[0] == "train"
-                 or env.evaluation_result_list[i][0] == env.model._train_data_name)):
-                _final_iteration_check(env, eval_name_splitted, i)
-                continue  # train data for lgb.cv or sklearn wrapper (underlying lgb.train)
-            elif env.iteration - best_iter[i] >= stopping_rounds:
-                if verbose:
-                    eval_result_str = '\t'.join([_format_eval_result(x) for x in best_score_list[i]])
-                    _log_info(f"Early stopping, best iteration is:\n[{best_iter[i] + 1}]\t{eval_result_str}")
-                    if first_metric_only:
-                        _log_info(f"Evaluated only: {eval_name_splitted[-1]}")
-                raise EarlyStopException(best_iter[i], best_score_list[i])
-            _final_iteration_check(env, eval_name_splitted, i)
-    _callback.order = 30  # type: ignore
-    return _callback
+    return _EarlyStoppingCallback(stopping_rounds=stopping_rounds, first_metric_only=first_metric_only, verbose=verbose, min_delta=min_delta)
```

### Comparing `lightgbm-3.3.5/lightgbm/dask.py` & `lightgbm-4.0.0/lightgbm/dask.py`

 * *Files 4% similar despite different names*

```diff
@@ -2,39 +2,62 @@
 """Distributed training with LightGBM and dask.distributed.
 
 This module enables you to perform distributed training with LightGBM on
 dask.Array and dask.DataFrame collections.
 
 It is based on dask-lightgbm, which was based on dask-xgboost.
 """
+import operator
 import socket
-from collections import defaultdict, namedtuple
+from collections import defaultdict
 from copy import deepcopy
 from enum import Enum, auto
 from functools import partial
-from typing import Any, Callable, Dict, Iterable, List, Optional, Tuple, Type, Union
+from typing import Any, Dict, Iterable, List, Optional, Tuple, Type, Union
 from urllib.parse import urlparse
 
 import numpy as np
 import scipy.sparse as ss
 
-from .basic import LightGBMError, _choose_param_value, _ConfigAliases, _log_info, _log_warning, _safe_call
-from .compat import (DASK_INSTALLED, PANDAS_INSTALLED, SKLEARN_INSTALLED, Client, LGBMNotFittedError, concat,
+from .basic import LightGBMError, _choose_param_value, _ConfigAliases, _log_info, _log_warning
+from .compat import (DASK_INSTALLED, PANDAS_INSTALLED, SKLEARN_INSTALLED, Client, Future, LGBMNotFittedError, concat,
                      dask_Array, dask_array_from_delayed, dask_bag_from_delayed, dask_DataFrame, dask_Series,
                      default_client, delayed, pd_DataFrame, pd_Series, wait)
-from .sklearn import (LGBMClassifier, LGBMModel, LGBMRanker, LGBMRegressor, _lgbmmodel_doc_custom_eval_note,
-                      _lgbmmodel_doc_fit, _lgbmmodel_doc_predict)
+from .sklearn import (LGBMClassifier, LGBMModel, LGBMRanker, LGBMRegressor, _LGBM_ScikitCustomObjectiveFunction,
+                      _LGBM_ScikitEvalMetricType, _lgbmmodel_doc_custom_eval_note, _lgbmmodel_doc_fit,
+                      _lgbmmodel_doc_predict)
+
+__all__ = [
+    'DaskLGBMClassifier',
+    'DaskLGBMRanker',
+    'DaskLGBMRegressor',
+]
 
 _DaskCollection = Union[dask_Array, dask_DataFrame, dask_Series]
 _DaskMatrixLike = Union[dask_Array, dask_DataFrame]
 _DaskVectorLike = Union[dask_Array, dask_Series]
 _DaskPart = Union[np.ndarray, pd_DataFrame, pd_Series, ss.spmatrix]
 _PredictionDtype = Union[Type[np.float32], Type[np.float64], Type[np.int32], Type[np.int64]]
 
-_HostWorkers = namedtuple('_HostWorkers', ['default', 'all'])
+
+class _RemoteSocket:
+    def acquire(self) -> int:
+        self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
+        self.socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
+        self.socket.bind(('', 0))
+        return self.socket.getsockname()[1]
+
+    def release(self) -> None:
+        self.socket.close()
+
+
+def _acquire_port() -> Tuple[_RemoteSocket, int]:
+    s = _RemoteSocket()
+    port = s.acquire()
+    return s, port
 
 
 class _DatasetNames(Enum):
     """Placeholder names used by lightgbm.dask internals to say 'also evaluate the training data'.
 
     Avoid duplicating the training data when the validation set refers to elements of training data.
     """
@@ -60,79 +83,48 @@
     """
     if client is None:
         return default_client()
     else:
         return client
 
 
-def _find_n_open_ports(n: int) -> List[int]:
-    """Find n random open ports on localhost.
-
-    Returns
-    -------
-    ports : list of int
-        n random open ports on localhost.
-    """
-    sockets = []
-    for _ in range(n):
-        s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
-        s.bind(('', 0))
-        sockets.append(s)
-    ports = []
-    for s in sockets:
-        ports.append(s.getsockname()[1])
-        s.close()
-    return ports
-
-
-def _group_workers_by_host(worker_addresses: Iterable[str]) -> Dict[str, _HostWorkers]:
-    """Group all worker addresses by hostname.
-
-    Returns
-    -------
-    host_to_workers : dict
-        mapping from hostname to all its workers.
-    """
-    host_to_workers: Dict[str, _HostWorkers] = {}
-    for address in worker_addresses:
-        hostname = urlparse(address).hostname
-        if hostname not in host_to_workers:
-            host_to_workers[hostname] = _HostWorkers(default=address, all=[address])
-        else:
-            host_to_workers[hostname].all.append(address)
-    return host_to_workers
-
-
 def _assign_open_ports_to_workers(
     client: Client,
-    host_to_workers: Dict[str, _HostWorkers]
-) -> Dict[str, int]:
+    workers: List[str],
+) -> Tuple[Dict[str, Future], Dict[str, int]]:
     """Assign an open port to each worker.
 
     Returns
     -------
+    worker_to_socket_future: dict
+        mapping from worker address to a future pointing to the remote socket.
     worker_to_port: dict
-        mapping from worker address to an open port.
+        mapping from worker address to an open port in the worker's host.
     """
-    host_ports_futures = {}
-    for hostname, workers in host_to_workers.items():
-        n_workers_in_host = len(workers.all)
-        host_ports_futures[hostname] = client.submit(
-            _find_n_open_ports,
-            n=n_workers_in_host,
-            workers=[workers.default],
-            pure=False,
+    # Acquire port in worker
+    worker_to_future = {}
+    for worker in workers:
+        worker_to_future[worker] = client.submit(
+            _acquire_port,
+            workers=[worker],
             allow_other_workers=False,
+            pure=False,
         )
-    found_ports = client.gather(host_ports_futures)
-    worker_to_port = {}
-    for hostname, workers in host_to_workers.items():
-        for worker, port in zip(workers.all, found_ports[hostname]):
-            worker_to_port[worker] = port
-    return worker_to_port
+
+    # schedule futures to retrieve each element of the tuple
+    worker_to_socket_future = {}
+    worker_to_port_future = {}
+    for worker, socket_future in worker_to_future.items():
+        worker_to_socket_future[worker] = client.submit(operator.itemgetter(0), socket_future)
+        worker_to_port_future[worker] = client.submit(operator.itemgetter(1), socket_future)
+
+    # retrieve ports
+    worker_to_port = client.gather(worker_to_port_future)
+
+    return worker_to_socket_future, worker_to_port
 
 
 def _concat(seq: List[_DaskPart]) -> _DaskPart:
     if isinstance(seq[0], np.ndarray):
         return np.concatenate(seq, axis=0)
     elif isinstance(seq[0], (pd_DataFrame, pd_Series)):
         return concat(seq, axis=0)
@@ -147,33 +139,33 @@
 
 
 def _pad_eval_names(lgbm_model: LGBMModel, required_names: List[str]) -> LGBMModel:
     """Append missing (key, value) pairs to a LightGBM model's evals_result_ and best_score_ OrderedDict attrs based on a set of required eval_set names.
 
     Allows users to rely on expected eval_set names being present when fitting DaskLGBM estimators with ``eval_set``.
     """
-    not_evaluated = 'not evaluated'
     for eval_name in required_names:
         if eval_name not in lgbm_model.evals_result_:
-            lgbm_model.evals_result_[eval_name] = not_evaluated
+            lgbm_model.evals_result_[eval_name] = {}
         if eval_name not in lgbm_model.best_score_:
-            lgbm_model.best_score_[eval_name] = not_evaluated
+            lgbm_model.best_score_[eval_name] = {}
 
     return lgbm_model
 
 
 def _train_part(
     params: Dict[str, Any],
     model_factory: Type[LGBMModel],
     list_of_parts: List[Dict[str, _DaskPart]],
     machines: str,
     local_listen_port: int,
     num_machines: int,
     return_model: bool,
-    time_out: int = 120,
+    time_out: int,
+    remote_socket: _RemoteSocket,
     **kwargs: Any
 ) -> Optional[LGBMModel]:
     network_params = {
         'machines': machines,
         'local_listen_port': local_listen_port,
         'time_out': time_out,
         'num_machines': num_machines
@@ -296,14 +288,16 @@
         eval_component_idx = [i for i in range(n_evals) if i not in missing_eval_component_idx]
         if eval_names:
             local_eval_names = [eval_names[i] for i in eval_component_idx]
         if eval_class_weight:
             kwargs['eval_class_weight'] = [eval_class_weight[i] for i in eval_component_idx]
 
     model = model_factory(**params)
+    if remote_socket is not None:
+        remote_socket.release()
     try:
         if is_ranker:
             model.fit(
                 data,
                 label,
                 sample_weight=weight,
                 init_score=init_score,
@@ -346,26 +340,26 @@
             assert parts.shape[1] == 1
         else:
             assert parts.ndim == 1 or parts.shape[1] == 1
         parts = parts.flatten().tolist()
     return parts
 
 
-def _machines_to_worker_map(machines: str, worker_addresses: List[str]) -> Dict[str, int]:
+def _machines_to_worker_map(machines: str, worker_addresses: Iterable[str]) -> Dict[str, int]:
     """Create a worker_map from machines list.
 
     Given ``machines`` and a list of Dask worker addresses, return a mapping where the keys are
     ``worker_addresses`` and the values are ports from ``machines``.
 
     Parameters
     ----------
     machines : str
         A comma-delimited list of workers, of the form ``ip1:port,ip2:port``.
     worker_addresses : list of str
-        A list of Dask worker addresses, of the form ``{protocol}{hostname}:{port}``, where ``port`` is the port Dask's scheduler uses to talk to that worker.
+        An iterable of Dask worker addresses, of the form ``{protocol}{hostname}:{port}``, where ``port`` is the port Dask's scheduler uses to talk to that worker.
 
     Returns
     -------
     result : Dict[str, int]
         Dictionary where keys are work addresses in the form expected by Dask and values are a port for LightGBM to use.
     """
     machine_addresses = machines.split(",")
@@ -377,14 +371,16 @@
     for address in machine_addresses:
         host, port = address.split(":")
         machine_to_port[host].add(int(port))
 
     out = {}
     for address in worker_addresses:
         worker_host = urlparse(address).hostname
+        if not worker_host:
+            raise ValueError(f"Could not parse host name from worker address '{address}'")
         out[address] = machine_to_port[worker_host].pop()
 
     return out
 
 
 def _train(
     client: Client,
@@ -397,16 +393,16 @@
     group: Optional[_DaskVectorLike] = None,
     eval_set: Optional[List[Tuple[_DaskMatrixLike, _DaskCollection]]] = None,
     eval_names: Optional[List[str]] = None,
     eval_sample_weight: Optional[List[_DaskVectorLike]] = None,
     eval_class_weight: Optional[List[Union[dict, str]]] = None,
     eval_init_score: Optional[List[_DaskCollection]] = None,
     eval_group: Optional[List[_DaskVectorLike]] = None,
-    eval_metric: Optional[Union[Callable, str, List[Union[Callable, str]]]] = None,
-    eval_at: Optional[Iterable[int]] = None,
+    eval_metric: Optional[_LGBM_ScikitEvalMetricType] = None,
+    eval_at: Optional[Union[List[int], Tuple[int, ...]]] = None,
     **kwargs: Any
 ) -> LGBMModel:
     """Inner train routine.
 
     Parameters
     ----------
     client : dask.distributed.Client
@@ -416,45 +412,45 @@
     label : Dask Array, Dask DataFrame or Dask Series of shape = [n_samples]
         The target values (class labels in classification, real numbers in regression).
     params : dict
         Parameters passed to constructor of the local underlying model.
     model_factory : lightgbm.LGBMClassifier, lightgbm.LGBMRegressor, or lightgbm.LGBMRanker class
         Class of the local underlying model.
     sample_weight : Dask Array or Dask Series of shape = [n_samples] or None, optional (default=None)
-        Weights of training data.
+        Weights of training data. Weights should be non-negative.
     init_score : Dask Array or Dask Series of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task), or Dask Array or Dask DataFrame of shape = [n_samples, n_classes] (for multi-class task), or None, optional (default=None)
         Init score of training data.
     group : Dask Array or Dask Series or None, optional (default=None)
         Group/query data.
         Only used in the learning-to-rank task.
         sum(group) = n_samples.
         For example, if you have a 100-document dataset with ``group = [10, 20, 40, 10, 10, 10]``, that means that you have 6 groups,
         where the first 10 records are in the first group, records 11-30 are in the second group, records 31-70 are in the third group, etc.
     eval_set : list of (X, y) tuples of Dask data collections, or None, optional (default=None)
         List of (X, y) tuple pairs to use as validation sets.
         Note, that not all workers may receive chunks of every eval set within ``eval_set``. When the returned
         lightgbm estimator is not trained using any chunks of a particular eval set, its corresponding component
-        of evals_result_ and best_score_ will be 'not_evaluated'.
+        of ``evals_result_`` and ``best_score_`` will be empty dictionaries.
     eval_names : list of str, or None, optional (default=None)
         Names of eval_set.
     eval_sample_weight : list of Dask Array or Dask Series, or None, optional (default=None)
-        Weights for each validation set in eval_set.
+        Weights for each validation set in eval_set. Weights should be non-negative.
     eval_class_weight : list of dict or str, or None, optional (default=None)
         Class weights, one dict or str for each validation set in eval_set.
     eval_init_score : list of Dask Array, Dask Series or Dask DataFrame (for multi-class task), or None, optional (default=None)
         Initial model score for each validation set in eval_set.
     eval_group : list of Dask Array or Dask Series, or None, optional (default=None)
         Group/query for each validation set in eval_set.
     eval_metric : str, callable, list or None, optional (default=None)
         If str, it should be a built-in evaluation metric to use.
         If callable, it should be a custom evaluation metric, see note below for more details.
         If list, it can be a list of built-in metrics, a list of custom evaluation metrics, or a mix of both.
         In either case, the ``metric`` from the Dask model parameters (or inferred from the objective) will be evaluated and used as well.
         Default: 'l2' for DaskLGBMRegressor, 'binary(multi)_logloss' for DaskLGBMClassifier, 'ndcg' for DaskLGBMRanker.
-    eval_at : iterable of int, optional (default=None)
+    eval_at : list or tuple of int, optional (default=None)
         The evaluation positions of the specified ranking metric.
     **kwargs
         Other parameters passed to ``fit`` method of the local underlying model.
 
     Returns
     -------
     model : lightgbm.LGBMClassifier, lightgbm.LGBMRegressor, or lightgbm.LGBMRanker class
@@ -550,21 +546,56 @@
     # evals_set will to be re-constructed into smaller lists of (X, y) tuples, where
     # X and y are each delayed sub-lists of original eval dask Collections.
     if eval_set:
         # find maximum number of parts in an individual eval set so that we can
         # pad eval sets when they come in different sizes.
         n_largest_eval_parts = max(x[0].npartitions for x in eval_set)
 
-        eval_sets = defaultdict(list)
+        eval_sets: Dict[
+            int,
+            List[
+                Union[
+                    _DatasetNames,
+                    Tuple[
+                        List[Optional[_DaskMatrixLike]],
+                        List[Optional[_DaskVectorLike]]
+                    ]
+                ]
+            ]
+        ] = defaultdict(list)
         if eval_sample_weight:
-            eval_sample_weights = defaultdict(list)
+            eval_sample_weights: Dict[
+                int,
+                List[
+                    Union[
+                        _DatasetNames,
+                        List[Optional[_DaskVectorLike]]
+                    ]
+                ]
+            ] = defaultdict(list)
         if eval_group:
-            eval_groups = defaultdict(list)
+            eval_groups: Dict[
+                int,
+                List[
+                    Union[
+                        _DatasetNames,
+                        List[Optional[_DaskVectorLike]]
+                    ]
+                ]
+            ] = defaultdict(list)
         if eval_init_score:
-            eval_init_scores = defaultdict(list)
+            eval_init_scores: Dict[
+                int,
+                List[
+                    Union[
+                        _DatasetNames,
+                        List[Optional[_DaskMatrixLike]]
+                    ]
+                ]
+            ] = defaultdict(list)
 
         for i, (X_eval, y_eval) in enumerate(eval_set):
             n_this_eval_parts = X_eval.npartitions
 
             # when individual eval set is equivalent to training data, skip recomputing parts.
             if X_eval is data and y_eval is label:
                 for parts_idx in range(n_parts):
@@ -584,16 +615,16 @@
                         y_e = None
 
                     if j < n_parts:
                         # first time a chunk of this eval set is added to this part.
                         eval_sets[parts_idx].append(([x_e], [y_e]))
                     else:
                         # append additional chunks of this eval set to this part.
-                        eval_sets[parts_idx][-1][0].append(x_e)
-                        eval_sets[parts_idx][-1][1].append(y_e)
+                        eval_sets[parts_idx][-1][0].append(x_e)  # type: ignore[index, union-attr]
+                        eval_sets[parts_idx][-1][1].append(y_e)  # type: ignore[index, union-attr]
 
             if eval_sample_weight:
                 if eval_sample_weight[i] is sample_weight:
                     for parts_idx in range(n_parts):
                         eval_sample_weights[parts_idx].append(_DatasetNames.SAMPLE_WEIGHT)
                 else:
                     eval_w_parts = _split_to_parts(data=eval_sample_weight[i], is_matrix=False)
@@ -605,15 +636,15 @@
                         else:
                             w_e = None
 
                         parts_idx = j % n_parts
                         if j < n_parts:
                             eval_sample_weights[parts_idx].append([w_e])
                         else:
-                            eval_sample_weights[parts_idx][-1].append(w_e)
+                            eval_sample_weights[parts_idx][-1].append(w_e)  # type: ignore[union-attr]
 
             if eval_init_score:
                 if eval_init_score[i] is init_score:
                     for parts_idx in range(n_parts):
                         eval_init_scores[parts_idx].append(_DatasetNames.INIT_SCORE)
                 else:
                     eval_init_score_parts = _split_to_parts(data=eval_init_score[i], is_matrix=False)
@@ -623,15 +654,15 @@
                         else:
                             init_score_e = None
 
                         parts_idx = j % n_parts
                         if j < n_parts:
                             eval_init_scores[parts_idx].append([init_score_e])
                         else:
-                            eval_init_scores[parts_idx][-1].append(init_score_e)
+                            eval_init_scores[parts_idx][-1].append(init_score_e)  # type: ignore[union-attr]
 
             if eval_group:
                 if eval_group[i] is group:
                     for parts_idx in range(n_parts):
                         eval_groups[parts_idx].append(_DatasetNames.GROUP)
                 else:
                     eval_g_parts = _split_to_parts(data=eval_group[i], is_matrix=False)
@@ -641,15 +672,15 @@
                         else:
                             g_e = None
 
                         parts_idx = j % n_parts
                         if j < n_parts:
                             eval_groups[parts_idx].append([g_e])
                         else:
-                            eval_groups[parts_idx][-1].append(g_e)
+                            eval_groups[parts_idx][-1].append(g_e)  # type: ignore[union-attr]
 
         # assign sub-eval_set components to worker parts.
         for parts_idx, e_set in eval_sets.items():
             parts[parts_idx]['eval_set'] = e_set
             if eval_sample_weight:
                 parts[parts_idx]['eval_sample_weight'] = eval_sample_weights[parts_idx]
             if eval_init_score:
@@ -660,30 +691,31 @@
     # Start computation in the background
     parts = list(map(delayed, parts))
     parts = client.compute(parts)
     wait(parts)
 
     for part in parts:
         if part.status == 'error':  # type: ignore
-            return part  # trigger error locally
+            # trigger error locally
+            return part  # type: ignore[return-value]
 
     # Find locations of all parts and map them to particular Dask workers
     key_to_part_dict = {part.key: part for part in parts}  # type: ignore
     who_has = client.who_has(parts)
     worker_map = defaultdict(list)
     for key, workers in who_has.items():
         worker_map[next(iter(workers))].append(key_to_part_dict[key])
 
     # Check that all workers were provided some of eval_set. Otherwise warn user that validation
     # data artifacts may not be populated depending on worker returning final estimator.
     if eval_set:
         for worker in worker_map:
             has_eval_set = False
             for part in worker_map[worker]:
-                if 'eval_set' in part.result():
+                if 'eval_set' in part.result():  # type: ignore[attr-defined]
                     has_eval_set = True
                     break
 
             if not has_eval_set:
                 _log_warning(
                     f"Worker {worker} was not allocated eval_set data. Therefore evals_result_ and best_score_ data may be unreliable. "
                     "Try rebalancing data across workers."
@@ -715,41 +747,41 @@
         main_param_name="machines",
         params=params,
         default_value=None
     )
     machines = params.pop("machines")
 
     # figure out network params
+    worker_to_socket_future: Dict[str, Future] = {}
     worker_addresses = worker_map.keys()
     if machines is not None:
         _log_info("Using passed-in 'machines' parameter")
         worker_address_to_port = _machines_to_worker_map(
             machines=machines,
             worker_addresses=worker_addresses
         )
     else:
         if listen_port_in_params:
             _log_info("Using passed-in 'local_listen_port' for all workers")
-            unique_hosts = set(urlparse(a).hostname for a in worker_addresses)
+            unique_hosts = {urlparse(a).hostname for a in worker_addresses}
             if len(unique_hosts) < len(worker_addresses):
                 msg = (
                     "'local_listen_port' was provided in Dask training parameters, but at least one "
                     "machine in the cluster has multiple Dask worker processes running on it. Please omit "
                     "'local_listen_port' or pass 'machines'."
                 )
                 raise LightGBMError(msg)
 
             worker_address_to_port = {
                 address: local_listen_port
                 for address in worker_addresses
             }
         else:
             _log_info("Finding random open ports for workers")
-            host_to_workers = _group_workers_by_host(worker_map.keys())
-            worker_address_to_port = _assign_open_ports_to_workers(client, host_to_workers)
+            worker_to_socket_future, worker_address_to_port = _assign_open_ports_to_workers(client, list(worker_map.keys()))
 
         machines = ','.join([
             f'{urlparse(worker_address).hostname}:{port}'
             for worker_address, port
             in worker_address_to_port.items()
         ])
 
@@ -769,14 +801,15 @@
             model_factory=model_factory,
             params={**params, 'num_threads': worker_ncores[worker]},
             list_of_parts=list_of_parts,
             machines=machines,
             local_listen_port=worker_address_to_port[worker],
             num_machines=num_machines,
             time_out=params.get('time_out', 120),
+            remote_socket=worker_to_socket_future.get(worker, None),
             return_model=(worker == master_worker),
             workers=[worker],
             allow_other_workers=False,
             pure=False,
             **kwargs
         )
         for worker, list_of_parts in worker_map.items()
@@ -810,14 +843,15 @@
     raw_score: bool,
     pred_proba: bool,
     pred_leaf: bool,
     pred_contrib: bool,
     **kwargs: Any
 ) -> _DaskPart:
 
+    result: _DaskPart
     if part.shape[0] == 0:
         result = np.array([])
     elif pred_proba:
         result = model.predict_proba(
             part,
             raw_score=raw_score,
             pred_leaf=pred_leaf,
@@ -895,15 +929,15 @@
             pred_leaf=pred_leaf,
             pred_contrib=pred_contrib,
             **kwargs
         ).values
     elif isinstance(data, dask_Array):
         # for multi-class classification with sparse matrices, pred_contrib predictions
         # are returned as a list of sparse matrices (one per class)
-        num_classes = model._n_classes or -1
+        num_classes = model._n_classes
 
         if (
             num_classes > 2
             and pred_contrib
             and isinstance(data._meta, ss.spmatrix)
         ):
 
@@ -927,15 +961,15 @@
             preds = bag.map_partitions(predict_function)
 
             # pred_contrib output will have one column per feature,
             # plus one more for the base value
             num_cols = model.n_features_ + 1
 
             nrows_per_chunk = data.chunks[0]
-            out = [[] for _ in range(num_classes)]
+            out: List[List[dask_Array]] = [[] for _ in range(num_classes)]
 
             # need to tell Dask the expected type and shape of individual preds
             pred_meta = data._meta
 
             for j, partition in enumerate(preds.to_delayed()):
                 for i in range(num_classes):
                     part = dask_array_from_delayed(
@@ -952,35 +986,38 @@
             elif isinstance(pred_meta, ss.csc_matrix):
                 concat_fn = partial(ss.vstack, format='csc')
             else:
                 concat_fn = ss.vstack
 
             # At this point, `out` is a list of lists of delayeds (each of which points to a matrix).
             # Concatenate them to return a list of Dask Arrays.
+            out_arrays: List[dask_Array] = []
             for i in range(num_classes):
-                out[i] = dask_array_from_delayed(
-                    value=delayed(concat_fn)(out[i]),
-                    shape=(data.shape[0], num_cols),
-                    meta=pred_meta
+                out_arrays.append(
+                    dask_array_from_delayed(
+                        value=delayed(concat_fn)(out[i]),
+                        shape=(data.shape[0], num_cols),
+                        meta=pred_meta
+                    )
                 )
 
-            return out
+            return out_arrays
 
         data_row = client.compute(data[[0]]).result()
         predict_fn = partial(
             _predict_part,
             model=model,
             raw_score=raw_score,
             pred_proba=pred_proba,
             pred_leaf=pred_leaf,
             pred_contrib=pred_contrib,
             **kwargs,
         )
         pred_row = predict_fn(data_row)
-        chunks = (data.chunks[0],)
+        chunks: Tuple[int, ...] = (data.chunks[0],)
         map_blocks_kwargs = {}
         if len(pred_row.shape) > 1:
             chunks += (pred_row.shape[1],)
         else:
             map_blocks_kwargs['drop_axis'] = 1
         return data.map_blocks(
             predict_fn,
@@ -1006,15 +1043,15 @@
             raise LGBMNotFittedError('Cannot access property client_ before calling fit().')
 
         return _get_dask_client(client=self.client)
 
     def _lgb_dask_getstate(self) -> Dict[Any, Any]:
         """Remove un-picklable attributes before serialization."""
         client = self.__dict__.pop("client", None)
-        self._other_params.pop("client", None)
+        self._other_params.pop("client", None)  # type: ignore[attr-defined]
         out = deepcopy(self.__dict__)
         out.update({"client": None})
         self.client = client
         return out
 
     def _lgb_dask_fit(
         self,
@@ -1026,26 +1063,24 @@
         group: Optional[_DaskVectorLike] = None,
         eval_set: Optional[List[Tuple[_DaskMatrixLike, _DaskCollection]]] = None,
         eval_names: Optional[List[str]] = None,
         eval_sample_weight: Optional[List[_DaskVectorLike]] = None,
         eval_class_weight: Optional[List[Union[dict, str]]] = None,
         eval_init_score: Optional[List[_DaskCollection]] = None,
         eval_group: Optional[List[_DaskVectorLike]] = None,
-        eval_metric: Optional[Union[Callable, str, List[Union[Callable, str]]]] = None,
-        eval_at: Optional[Iterable[int]] = None,
-        early_stopping_rounds: Optional[int] = None,
+        eval_metric: Optional[_LGBM_ScikitEvalMetricType] = None,
+        eval_at: Optional[Union[List[int], Tuple[int, ...]]] = None,
         **kwargs: Any
     ) -> "_DaskLGBMModel":
+        if not DASK_INSTALLED:
+            raise LightGBMError('dask is required for lightgbm.dask')
         if not all((DASK_INSTALLED, PANDAS_INSTALLED, SKLEARN_INSTALLED)):
             raise LightGBMError('dask, pandas and scikit-learn are required for lightgbm.dask')
 
-        if early_stopping_rounds is not None:
-            raise RuntimeError('early_stopping_rounds is not currently supported in lightgbm.dask')
-
-        params = self.get_params(True)
+        params = self.get_params(True)  # type: ignore[attr-defined]
         params.pop("client", None)
 
         model = _train(
             client=_get_dask_client(self.client),
             data=X,
             label=y,
             params=params,
@@ -1060,30 +1095,30 @@
             eval_init_score=eval_init_score,
             eval_group=eval_group,
             eval_metric=eval_metric,
             eval_at=eval_at,
             **kwargs
         )
 
-        self.set_params(**model.get_params())
-        self._lgb_dask_copy_extra_params(model, self)
+        self.set_params(**model.get_params())  # type: ignore[attr-defined]
+        self._lgb_dask_copy_extra_params(model, self)  # type: ignore[attr-defined]
 
         return self
 
     def _lgb_dask_to_local(self, model_factory: Type[LGBMModel]) -> LGBMModel:
-        params = self.get_params()
+        params = self.get_params()  # type: ignore[attr-defined]
         params.pop("client", None)
         model = model_factory(**params)
         self._lgb_dask_copy_extra_params(self, model)
         model._other_params.pop("client", None)
         return model
 
     @staticmethod
     def _lgb_dask_copy_extra_params(source: Union["_DaskLGBMModel", LGBMModel], dest: Union["_DaskLGBMModel", LGBMModel]) -> None:
-        params = source.get_params()
+        params = source.get_params()  # type: ignore[union-attr]
         attributes = source.__dict__
         extra_param_names = set(attributes.keys()).difference(params.keys())
         for name in extra_param_names:
             setattr(dest, name, attributes[name])
 
 
 class DaskLGBMClassifier(LGBMClassifier, _DaskLGBMModel):
@@ -1093,27 +1128,26 @@
         self,
         boosting_type: str = 'gbdt',
         num_leaves: int = 31,
         max_depth: int = -1,
         learning_rate: float = 0.1,
         n_estimators: int = 100,
         subsample_for_bin: int = 200000,
-        objective: Optional[Union[Callable, str]] = None,
+        objective: Optional[Union[str, _LGBM_ScikitCustomObjectiveFunction]] = None,
         class_weight: Optional[Union[dict, str]] = None,
         min_split_gain: float = 0.,
         min_child_weight: float = 1e-3,
         min_child_samples: int = 20,
         subsample: float = 1.,
         subsample_freq: int = 0,
         colsample_bytree: float = 1.,
         reg_alpha: float = 0.,
         reg_lambda: float = 0.,
         random_state: Optional[Union[int, np.random.RandomState]] = None,
-        n_jobs: int = -1,
-        silent: bool = "warn",
+        n_jobs: Optional[int] = None,
         importance_type: str = 'split',
         client: Optional[Client] = None,
         **kwargs: Any
     ):
         """Docstring is inherited from the lightgbm.LGBMClassifier.__init__."""
         self.client = client
         super().__init__(
@@ -1131,122 +1165,148 @@
             subsample=subsample,
             subsample_freq=subsample_freq,
             colsample_bytree=colsample_bytree,
             reg_alpha=reg_alpha,
             reg_lambda=reg_lambda,
             random_state=random_state,
             n_jobs=n_jobs,
-            silent=silent,
             importance_type=importance_type,
             **kwargs
         )
 
     _base_doc = LGBMClassifier.__init__.__doc__
-    _before_kwargs, _kwargs, _after_kwargs = _base_doc.partition('**kwargs')
-    _base_doc = f"""
+    _before_kwargs, _kwargs, _after_kwargs = _base_doc.partition('**kwargs')  # type: ignore
+    __init__.__doc__ = f"""
         {_before_kwargs}client : dask.distributed.Client or None, optional (default=None)
         {' ':4}Dask client. If ``None``, ``distributed.default_client()`` will be used at runtime. The Dask client used by this class will not be saved if the model object is pickled.
         {_kwargs}{_after_kwargs}
         """
 
-    # the note on custom objective functions in LGBMModel.__init__ is not
-    # currently relevant for the Dask estimators
-    __init__.__doc__ = _base_doc[:_base_doc.find('Note\n')]
-
     def __getstate__(self) -> Dict[Any, Any]:
         return self._lgb_dask_getstate()
 
-    def fit(
+    def fit(  # type: ignore[override]
         self,
         X: _DaskMatrixLike,
         y: _DaskCollection,
         sample_weight: Optional[_DaskVectorLike] = None,
         init_score: Optional[_DaskCollection] = None,
         eval_set: Optional[List[Tuple[_DaskMatrixLike, _DaskCollection]]] = None,
         eval_names: Optional[List[str]] = None,
         eval_sample_weight: Optional[List[_DaskVectorLike]] = None,
         eval_class_weight: Optional[List[Union[dict, str]]] = None,
         eval_init_score: Optional[List[_DaskCollection]] = None,
-        eval_metric: Optional[Union[Callable, str, List[Union[Callable, str]]]] = None,
-        early_stopping_rounds: Optional[int] = None,
+        eval_metric: Optional[_LGBM_ScikitEvalMetricType] = None,
         **kwargs: Any
     ) -> "DaskLGBMClassifier":
         """Docstring is inherited from the lightgbm.LGBMClassifier.fit."""
-        if early_stopping_rounds is not None:
-            raise RuntimeError('early_stopping_rounds is not currently supported in lightgbm.dask')
-
-        return self._lgb_dask_fit(
+        self._lgb_dask_fit(
             model_factory=LGBMClassifier,
             X=X,
             y=y,
             sample_weight=sample_weight,
             init_score=init_score,
             eval_set=eval_set,
             eval_names=eval_names,
             eval_sample_weight=eval_sample_weight,
             eval_class_weight=eval_class_weight,
             eval_init_score=eval_init_score,
             eval_metric=eval_metric,
             **kwargs
         )
+        return self
 
     _base_doc = _lgbmmodel_doc_fit.format(
         X_shape="Dask Array or Dask DataFrame of shape = [n_samples, n_features]",
         y_shape="Dask Array, Dask DataFrame or Dask Series of shape = [n_samples]",
         sample_weight_shape="Dask Array or Dask Series of shape = [n_samples] or None, optional (default=None)",
         init_score_shape="Dask Array or Dask Series of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task), or Dask Array or Dask DataFrame of shape = [n_samples, n_classes] (for multi-class task), or None, optional (default=None)",
         group_shape="Dask Array or Dask Series or None, optional (default=None)",
         eval_sample_weight_shape="list of Dask Array or Dask Series, or None, optional (default=None)",
         eval_init_score_shape="list of Dask Array, Dask Series or Dask DataFrame (for multi-class task), or None, optional (default=None)",
         eval_group_shape="list of Dask Array or Dask Series, or None, optional (default=None)"
     )
 
-    # DaskLGBMClassifier does not support group, eval_group, early_stopping_rounds.
+    # DaskLGBMClassifier does not support group, eval_group.
     _base_doc = (_base_doc[:_base_doc.find('group :')]
                  + _base_doc[_base_doc.find('eval_set :'):])
 
     _base_doc = (_base_doc[:_base_doc.find('eval_group :')]
                  + _base_doc[_base_doc.find('eval_metric :'):])
 
-    _base_doc = (_base_doc[:_base_doc.find('early_stopping_rounds :')]
-                 + _base_doc[_base_doc.find('verbose :'):])
-
     # DaskLGBMClassifier support for callbacks and init_model is not tested
     fit.__doc__ = f"""{_base_doc[:_base_doc.find('callbacks :')]}**kwargs
         Other parameters passed through to ``LGBMClassifier.fit()``.
 
+    Returns
+    -------
+    self : lightgbm.DaskLGBMClassifier
+        Returns self.
+
     {_lgbmmodel_doc_custom_eval_note}
         """
 
-    def predict(self, X: _DaskMatrixLike, **kwargs: Any) -> dask_Array:
+    def predict(
+        self,
+        X: _DaskMatrixLike,  # type: ignore[override]
+        raw_score: bool = False,
+        start_iteration: int = 0,
+        num_iteration: Optional[int] = None,
+        pred_leaf: bool = False,
+        pred_contrib: bool = False,
+        validate_features: bool = False,
+        **kwargs: Any
+    ) -> dask_Array:
         """Docstring is inherited from the lightgbm.LGBMClassifier.predict."""
         return _predict(
             model=self.to_local(),
             data=X,
             dtype=self.classes_.dtype,
             client=_get_dask_client(self.client),
+            raw_score=raw_score,
+            start_iteration=start_iteration,
+            num_iteration=num_iteration,
+            pred_leaf=pred_leaf,
+            pred_contrib=pred_contrib,
+            validate_features=validate_features,
             **kwargs
         )
 
     predict.__doc__ = _lgbmmodel_doc_predict.format(
         description="Return the predicted value for each sample.",
         X_shape="Dask Array or Dask DataFrame of shape = [n_samples, n_features]",
         output_name="predicted_result",
         predicted_result_shape="Dask Array of shape = [n_samples] or shape = [n_samples, n_classes]",
         X_leaves_shape="Dask Array of shape = [n_samples, n_trees] or shape = [n_samples, n_trees * n_classes]",
         X_SHAP_values_shape="Dask Array of shape = [n_samples, n_features + 1] or shape = [n_samples, (n_features + 1) * n_classes] or (if multi-class and using sparse inputs) a list of ``n_classes`` Dask Arrays of shape = [n_samples, n_features + 1]"
     )
 
-    def predict_proba(self, X: _DaskMatrixLike, **kwargs: Any) -> dask_Array:
+    def predict_proba(
+        self,
+        X: _DaskMatrixLike,  # type: ignore[override]
+        raw_score: bool = False,
+        start_iteration: int = 0,
+        num_iteration: Optional[int] = None,
+        pred_leaf: bool = False,
+        pred_contrib: bool = False,
+        validate_features: bool = False,
+        **kwargs: Any
+    ) -> dask_Array:
         """Docstring is inherited from the lightgbm.LGBMClassifier.predict_proba."""
         return _predict(
             model=self.to_local(),
             data=X,
             pred_proba=True,
             client=_get_dask_client(self.client),
+            raw_score=raw_score,
+            start_iteration=start_iteration,
+            num_iteration=num_iteration,
+            pred_leaf=pred_leaf,
+            pred_contrib=pred_contrib,
+            validate_features=validate_features,
             **kwargs
         )
 
     predict_proba.__doc__ = _lgbmmodel_doc_predict.format(
         description="Return the predicted probability for each class for each sample.",
         X_shape="Dask Array or Dask DataFrame of shape = [n_samples, n_features]",
         output_name="predicted_probability",
@@ -1273,27 +1333,26 @@
         self,
         boosting_type: str = 'gbdt',
         num_leaves: int = 31,
         max_depth: int = -1,
         learning_rate: float = 0.1,
         n_estimators: int = 100,
         subsample_for_bin: int = 200000,
-        objective: Optional[Union[Callable, str]] = None,
+        objective: Optional[Union[str, _LGBM_ScikitCustomObjectiveFunction]] = None,
         class_weight: Optional[Union[dict, str]] = None,
         min_split_gain: float = 0.,
         min_child_weight: float = 1e-3,
         min_child_samples: int = 20,
         subsample: float = 1.,
         subsample_freq: int = 0,
         colsample_bytree: float = 1.,
         reg_alpha: float = 0.,
         reg_lambda: float = 0.,
         random_state: Optional[Union[int, np.random.RandomState]] = None,
-        n_jobs: int = -1,
-        silent: bool = "warn",
+        n_jobs: Optional[int] = None,
         importance_type: str = 'split',
         client: Optional[Client] = None,
         **kwargs: Any
     ):
         """Docstring is inherited from the lightgbm.LGBMRegressor.__init__."""
         self.client = client
         super().__init__(
@@ -1311,102 +1370,113 @@
             subsample=subsample,
             subsample_freq=subsample_freq,
             colsample_bytree=colsample_bytree,
             reg_alpha=reg_alpha,
             reg_lambda=reg_lambda,
             random_state=random_state,
             n_jobs=n_jobs,
-            silent=silent,
             importance_type=importance_type,
             **kwargs
         )
 
     _base_doc = LGBMRegressor.__init__.__doc__
-    _before_kwargs, _kwargs, _after_kwargs = _base_doc.partition('**kwargs')
-    _base_doc = f"""
+    _before_kwargs, _kwargs, _after_kwargs = _base_doc.partition('**kwargs')  # type: ignore
+    __init__.__doc__ = f"""
         {_before_kwargs}client : dask.distributed.Client or None, optional (default=None)
         {' ':4}Dask client. If ``None``, ``distributed.default_client()`` will be used at runtime. The Dask client used by this class will not be saved if the model object is pickled.
         {_kwargs}{_after_kwargs}
         """
-    # the note on custom objective functions in LGBMModel.__init__ is not
-    # currently relevant for the Dask estimators
-    __init__.__doc__ = _base_doc[:_base_doc.find('Note\n')]
 
     def __getstate__(self) -> Dict[Any, Any]:
         return self._lgb_dask_getstate()
 
-    def fit(
+    def fit(  # type: ignore[override]
         self,
         X: _DaskMatrixLike,
         y: _DaskCollection,
         sample_weight: Optional[_DaskVectorLike] = None,
         init_score: Optional[_DaskVectorLike] = None,
         eval_set: Optional[List[Tuple[_DaskMatrixLike, _DaskCollection]]] = None,
         eval_names: Optional[List[str]] = None,
         eval_sample_weight: Optional[List[_DaskVectorLike]] = None,
         eval_init_score: Optional[List[_DaskVectorLike]] = None,
-        eval_metric: Optional[Union[Callable, str, List[Union[Callable, str]]]] = None,
-        early_stopping_rounds: Optional[int] = None,
+        eval_metric: Optional[_LGBM_ScikitEvalMetricType] = None,
         **kwargs: Any
     ) -> "DaskLGBMRegressor":
         """Docstring is inherited from the lightgbm.LGBMRegressor.fit."""
-        if early_stopping_rounds is not None:
-            raise RuntimeError('early_stopping_rounds is not currently supported in lightgbm.dask')
-
-        return self._lgb_dask_fit(
+        self._lgb_dask_fit(
             model_factory=LGBMRegressor,
             X=X,
             y=y,
             sample_weight=sample_weight,
             init_score=init_score,
             eval_set=eval_set,
             eval_names=eval_names,
             eval_sample_weight=eval_sample_weight,
             eval_init_score=eval_init_score,
             eval_metric=eval_metric,
             **kwargs
         )
+        return self
 
     _base_doc = _lgbmmodel_doc_fit.format(
         X_shape="Dask Array or Dask DataFrame of shape = [n_samples, n_features]",
         y_shape="Dask Array, Dask DataFrame or Dask Series of shape = [n_samples]",
         sample_weight_shape="Dask Array or Dask Series of shape = [n_samples] or None, optional (default=None)",
         init_score_shape="Dask Array or Dask Series of shape = [n_samples] or None, optional (default=None)",
         group_shape="Dask Array or Dask Series or None, optional (default=None)",
         eval_sample_weight_shape="list of Dask Array or Dask Series, or None, optional (default=None)",
         eval_init_score_shape="list of Dask Array or Dask Series, or None, optional (default=None)",
         eval_group_shape="list of Dask Array or Dask Series, or None, optional (default=None)"
     )
 
-    # DaskLGBMRegressor does not support group, eval_class_weight, eval_group, early_stopping_rounds.
+    # DaskLGBMRegressor does not support group, eval_class_weight, eval_group.
     _base_doc = (_base_doc[:_base_doc.find('group :')]
                  + _base_doc[_base_doc.find('eval_set :'):])
 
     _base_doc = (_base_doc[:_base_doc.find('eval_class_weight :')]
                  + _base_doc[_base_doc.find('eval_init_score :'):])
 
     _base_doc = (_base_doc[:_base_doc.find('eval_group :')]
                  + _base_doc[_base_doc.find('eval_metric :'):])
 
-    _base_doc = (_base_doc[:_base_doc.find('early_stopping_rounds :')]
-                 + _base_doc[_base_doc.find('verbose :'):])
-
     # DaskLGBMRegressor support for callbacks and init_model is not tested
     fit.__doc__ = f"""{_base_doc[:_base_doc.find('callbacks :')]}**kwargs
         Other parameters passed through to ``LGBMRegressor.fit()``.
 
+    Returns
+    -------
+    self : lightgbm.DaskLGBMRegressor
+        Returns self.
+
     {_lgbmmodel_doc_custom_eval_note}
         """
 
-    def predict(self, X: _DaskMatrixLike, **kwargs) -> dask_Array:
+    def predict(
+        self,
+        X: _DaskMatrixLike,  # type: ignore[override]
+        raw_score: bool = False,
+        start_iteration: int = 0,
+        num_iteration: Optional[int] = None,
+        pred_leaf: bool = False,
+        pred_contrib: bool = False,
+        validate_features: bool = False,
+        **kwargs: Any
+    ) -> dask_Array:
         """Docstring is inherited from the lightgbm.LGBMRegressor.predict."""
         return _predict(
             model=self.to_local(),
             data=X,
             client=_get_dask_client(self.client),
+            raw_score=raw_score,
+            start_iteration=start_iteration,
+            num_iteration=num_iteration,
+            pred_leaf=pred_leaf,
+            pred_contrib=pred_contrib,
+            validate_features=validate_features,
             **kwargs
         )
 
     predict.__doc__ = _lgbmmodel_doc_predict.format(
         description="Return the predicted value for each sample.",
         X_shape="Dask Array or Dask DataFrame of shape = [n_samples, n_features]",
         output_name="predicted_result",
@@ -1433,27 +1503,26 @@
         self,
         boosting_type: str = 'gbdt',
         num_leaves: int = 31,
         max_depth: int = -1,
         learning_rate: float = 0.1,
         n_estimators: int = 100,
         subsample_for_bin: int = 200000,
-        objective: Optional[Union[Callable, str]] = None,
+        objective: Optional[Union[str, _LGBM_ScikitCustomObjectiveFunction]] = None,
         class_weight: Optional[Union[dict, str]] = None,
         min_split_gain: float = 0.,
         min_child_weight: float = 1e-3,
         min_child_samples: int = 20,
         subsample: float = 1.,
         subsample_freq: int = 0,
         colsample_bytree: float = 1.,
         reg_alpha: float = 0.,
         reg_lambda: float = 0.,
         random_state: Optional[Union[int, np.random.RandomState]] = None,
-        n_jobs: int = -1,
-        silent: bool = "warn",
+        n_jobs: Optional[int] = None,
         importance_type: str = 'split',
         client: Optional[Client] = None,
         **kwargs: Any
     ):
         """Docstring is inherited from the lightgbm.LGBMRanker.__init__."""
         self.client = client
         super().__init__(
@@ -1471,56 +1540,47 @@
             subsample=subsample,
             subsample_freq=subsample_freq,
             colsample_bytree=colsample_bytree,
             reg_alpha=reg_alpha,
             reg_lambda=reg_lambda,
             random_state=random_state,
             n_jobs=n_jobs,
-            silent=silent,
             importance_type=importance_type,
             **kwargs
         )
 
     _base_doc = LGBMRanker.__init__.__doc__
-    _before_kwargs, _kwargs, _after_kwargs = _base_doc.partition('**kwargs')
-    _base_doc = f"""
+    _before_kwargs, _kwargs, _after_kwargs = _base_doc.partition('**kwargs')  # type: ignore
+    __init__.__doc__ = f"""
         {_before_kwargs}client : dask.distributed.Client or None, optional (default=None)
         {' ':4}Dask client. If ``None``, ``distributed.default_client()`` will be used at runtime. The Dask client used by this class will not be saved if the model object is pickled.
         {_kwargs}{_after_kwargs}
         """
 
-    # the note on custom objective functions in LGBMModel.__init__ is not
-    # currently relevant for the Dask estimators
-    __init__.__doc__ = _base_doc[:_base_doc.find('Note\n')]
-
     def __getstate__(self) -> Dict[Any, Any]:
         return self._lgb_dask_getstate()
 
-    def fit(
+    def fit(  # type: ignore[override]
         self,
         X: _DaskMatrixLike,
         y: _DaskCollection,
         sample_weight: Optional[_DaskVectorLike] = None,
         init_score: Optional[_DaskVectorLike] = None,
         group: Optional[_DaskVectorLike] = None,
         eval_set: Optional[List[Tuple[_DaskMatrixLike, _DaskCollection]]] = None,
         eval_names: Optional[List[str]] = None,
         eval_sample_weight: Optional[List[_DaskVectorLike]] = None,
         eval_init_score: Optional[List[_DaskVectorLike]] = None,
         eval_group: Optional[List[_DaskVectorLike]] = None,
-        eval_metric: Optional[Union[Callable, str, List[Union[Callable, str]]]] = None,
-        eval_at: Iterable[int] = (1, 2, 3, 4, 5),
-        early_stopping_rounds: Optional[int] = None,
+        eval_metric: Optional[_LGBM_ScikitEvalMetricType] = None,
+        eval_at: Union[List[int], Tuple[int, ...]] = (1, 2, 3, 4, 5),
         **kwargs: Any
     ) -> "DaskLGBMRanker":
         """Docstring is inherited from the lightgbm.LGBMRanker.fit."""
-        if early_stopping_rounds is not None:
-            raise RuntimeError('early_stopping_rounds is not currently supported in lightgbm.dask')
-
-        return self._lgb_dask_fit(
+        self._lgb_dask_fit(
             model_factory=LGBMRanker,
             X=X,
             y=y,
             sample_weight=sample_weight,
             init_score=init_score,
             group=group,
             eval_set=eval_set,
@@ -1528,14 +1588,15 @@
             eval_sample_weight=eval_sample_weight,
             eval_init_score=eval_init_score,
             eval_group=eval_group,
             eval_metric=eval_metric,
             eval_at=eval_at,
             **kwargs
         )
+        return self
 
     _base_doc = _lgbmmodel_doc_fit.format(
         X_shape="Dask Array or Dask DataFrame of shape = [n_samples, n_features]",
         y_shape="Dask Array, Dask DataFrame or Dask Series of shape = [n_samples]",
         sample_weight_shape="Dask Array or Dask Series of shape = [n_samples] or None, optional (default=None)",
         init_score_shape="Dask Array or Dask Series of shape = [n_samples] or None, optional (default=None)",
         group_shape="Dask Array or Dask Series or None, optional (default=None)",
@@ -1544,32 +1605,53 @@
         eval_group_shape="list of Dask Array or Dask Series, or None, optional (default=None)"
     )
 
     # DaskLGBMRanker does not support eval_class_weight or early stopping
     _base_doc = (_base_doc[:_base_doc.find('eval_class_weight :')]
                  + _base_doc[_base_doc.find('eval_init_score :'):])
 
-    _base_doc = (_base_doc[:_base_doc.find('early_stopping_rounds :')]
-                 + "eval_at : iterable of int, optional (default=(1, 2, 3, 4, 5))\n"
+    _base_doc = (_base_doc[:_base_doc.find('feature_name :')]
+                 + "eval_at : list or tuple of int, optional (default=(1, 2, 3, 4, 5))\n"
                  + f"{' ':8}The evaluation positions of the specified metric.\n"
-                 + f"{' ':4}{_base_doc[_base_doc.find('verbose :'):]}")
+                 + f"{' ':4}{_base_doc[_base_doc.find('feature_name :'):]}")
 
     # DaskLGBMRanker support for callbacks and init_model is not tested
     fit.__doc__ = f"""{_base_doc[:_base_doc.find('callbacks :')]}**kwargs
         Other parameters passed through to ``LGBMRanker.fit()``.
 
+    Returns
+    -------
+    self : lightgbm.DaskLGBMRanker
+        Returns self.
+
     {_lgbmmodel_doc_custom_eval_note}
         """
 
-    def predict(self, X: _DaskMatrixLike, **kwargs: Any) -> dask_Array:
+    def predict(
+        self,
+        X: _DaskMatrixLike,  # type: ignore[override]
+        raw_score: bool = False,
+        start_iteration: int = 0,
+        num_iteration: Optional[int] = None,
+        pred_leaf: bool = False,
+        pred_contrib: bool = False,
+        validate_features: bool = False,
+        **kwargs: Any
+    ) -> dask_Array:
         """Docstring is inherited from the lightgbm.LGBMRanker.predict."""
         return _predict(
             model=self.to_local(),
             data=X,
             client=_get_dask_client(self.client),
+            raw_score=raw_score,
+            start_iteration=start_iteration,
+            num_iteration=num_iteration,
+            pred_leaf=pred_leaf,
+            pred_contrib=pred_contrib,
+            validate_features=validate_features,
             **kwargs
         )
 
     predict.__doc__ = _lgbmmodel_doc_predict.format(
         description="Return the predicted value for each sample.",
         X_shape="Dask Array or Dask DataFrame of shape = [n_samples, n_features]",
         output_name="predicted_result",
```

### Comparing `lightgbm-3.3.5/lightgbm/engine.py` & `lightgbm-4.0.0/lightgbm/engine.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,206 +1,196 @@
 # coding: utf-8
 """Library with training routines of LightGBM."""
 import collections
 import copy
+import json
 from operator import attrgetter
 from pathlib import Path
-from typing import Any, Callable, Dict, List, Optional, Tuple, Union
+from typing import Any, Callable, Dict, Iterable, List, Optional, Tuple, Union
 
 import numpy as np
 
 from . import callback
-from .basic import Booster, Dataset, LightGBMError, _ConfigAliases, _InnerPredictor, _log_warning
-from .compat import SKLEARN_INSTALLED, _LGBMGroupKFold, _LGBMStratifiedKFold
+from .basic import (Booster, Dataset, LightGBMError, _choose_param_value, _ConfigAliases, _InnerPredictor,
+                    _LGBM_BoosterEvalMethodResultType, _LGBM_CategoricalFeatureConfiguration,
+                    _LGBM_CustomObjectiveFunction, _LGBM_EvalFunctionResultType, _LGBM_FeatureNameConfiguration,
+                    _log_warning)
+from .compat import SKLEARN_INSTALLED, _LGBMBaseCrossValidator, _LGBMGroupKFold, _LGBMStratifiedKFold
+
+__all__ = [
+    'cv',
+    'CVBooster',
+    'train',
+]
+
 
-_LGBM_CustomObjectiveFunction = Callable[
-    [Union[List, np.ndarray], Dataset],
-    Tuple[Union[List, np.ndarray], Union[List, np.ndarray]]
+_LGBM_CustomMetricFunction = Union[
+    Callable[
+        [np.ndarray, Dataset],
+        _LGBM_EvalFunctionResultType,
+    ],
+    Callable[
+        [np.ndarray, Dataset],
+        List[_LGBM_EvalFunctionResultType]
+    ],
 ]
-_LGBM_CustomMetricFunction = Callable[
-    [Union[List, np.ndarray], Dataset],
-    Tuple[str, float, bool]
+
+_LGBM_PreprocFunction = Callable[
+    [Dataset, Dataset, Dict[str, Any]],
+    Tuple[Dataset, Dataset, Dict[str, Any]]
 ]
 
 
 def train(
     params: Dict[str, Any],
     train_set: Dataset,
     num_boost_round: int = 100,
     valid_sets: Optional[List[Dataset]] = None,
     valid_names: Optional[List[str]] = None,
-    fobj: Optional[_LGBM_CustomObjectiveFunction] = None,
     feval: Optional[Union[_LGBM_CustomMetricFunction, List[_LGBM_CustomMetricFunction]]] = None,
     init_model: Optional[Union[str, Path, Booster]] = None,
-    feature_name: Union[List[str], str] = 'auto',
-    categorical_feature: Union[List[str], List[int], str] = 'auto',
-    early_stopping_rounds: Optional[int] = None,
-    evals_result: Optional[Dict[str, Any]] = None,
-    verbose_eval: Union[bool, int, str] = 'warn',
-    learning_rates: Optional[Union[List[float], Callable[[int], float]]] = None,
+    feature_name: _LGBM_FeatureNameConfiguration = 'auto',
+    categorical_feature: _LGBM_CategoricalFeatureConfiguration = 'auto',
     keep_training_booster: bool = False,
     callbacks: Optional[List[Callable]] = None
 ) -> Booster:
     """Perform the training with given parameters.
 
     Parameters
     ----------
     params : dict
-        Parameters for training.
+        Parameters for training. Values passed through ``params`` take precedence over those
+        supplied via arguments.
     train_set : Dataset
         Data to be trained on.
     num_boost_round : int, optional (default=100)
         Number of boosting iterations.
     valid_sets : list of Dataset, or None, optional (default=None)
         List of data to be evaluated on during training.
     valid_names : list of str, or None, optional (default=None)
         Names of ``valid_sets``.
-    fobj : callable or None, optional (default=None)
-        Customized objective function.
-        Should accept two parameters: preds, train_data,
-        and return (grad, hess).
-
-            preds : list or numpy 1-D array
-                The predicted values.
-                Predicted values are returned before any transformation,
-                e.g. they are raw margin instead of probability of positive class for binary task.
-            train_data : Dataset
-                The training dataset.
-            grad : list or numpy 1-D array
-                The value of the first order derivative (gradient) of the loss
-                with respect to the elements of preds for each sample point.
-            hess : list or numpy 1-D array
-                The value of the second order derivative (Hessian) of the loss
-                with respect to the elements of preds for each sample point.
-
-        For multi-class task, the preds is group by class_id first, then group by row_id.
-        If you want to get i-th row preds in j-th class, the access way is score[j * num_data + i]
-        and you should group grad and hess in this way as well.
-
     feval : callable, list of callable, or None, optional (default=None)
         Customized evaluation function.
-        Each evaluation function should accept two parameters: preds, train_data,
+        Each evaluation function should accept two parameters: preds, eval_data,
         and return (eval_name, eval_result, is_higher_better) or list of such tuples.
 
-            preds : list or numpy 1-D array
+            preds : numpy 1-D array or numpy 2-D array (for multi-class task)
                 The predicted values.
-                If ``fobj`` is specified, predicted values are returned before any transformation,
+                For multi-class task, preds are numpy 2-D array of shape = [n_samples, n_classes].
+                If custom objective function is used, predicted values are returned before any transformation,
                 e.g. they are raw margin instead of probability of positive class for binary task in this case.
-            train_data : Dataset
-                The training dataset.
+            eval_data : Dataset
+                A ``Dataset`` to evaluate.
             eval_name : str
                 The name of evaluation function (without whitespaces).
             eval_result : float
                 The eval result.
             is_higher_better : bool
                 Is eval result higher better, e.g. AUC is ``is_higher_better``.
 
-        For multi-class task, the preds is group by class_id first, then group by row_id.
-        If you want to get i-th row preds in j-th class, the access way is preds[j * num_data + i].
         To ignore the default metric corresponding to the used objective,
         set the ``metric`` parameter to the string ``"None"`` in ``params``.
     init_model : str, pathlib.Path, Booster or None, optional (default=None)
         Filename of LightGBM model or Booster instance used for continue training.
     feature_name : list of str, or 'auto', optional (default="auto")
         Feature names.
         If 'auto' and data is pandas DataFrame, data columns names are used.
     categorical_feature : list of str or int, or 'auto', optional (default="auto")
         Categorical features.
         If list of int, interpreted as indices.
         If list of str, interpreted as feature names (need to specify ``feature_name`` as well).
         If 'auto' and data is pandas DataFrame, pandas unordered categorical columns are used.
-        All values in categorical features should be less than int32 max value (2147483647).
+        All values in categorical features will be cast to int32 and thus should be less than int32 max value (2147483647).
         Large values could be memory consuming. Consider using consecutive integers starting from zero.
         All negative values in categorical features will be treated as missing values.
         The output cannot be monotonically constrained with respect to a categorical feature.
-    early_stopping_rounds : int or None, optional (default=None)
-        Activates early stopping. The model will train until the validation score stops improving.
-        Validation score needs to improve at least every ``early_stopping_rounds`` round(s)
-        to continue training.
-        Requires at least one validation data and one metric.
-        If there's more than one, will check all of them. But the training data is ignored anyway.
-        To check only the first metric, set the ``first_metric_only`` parameter to ``True`` in ``params``.
-        The index of iteration that has the best performance will be saved in the ``best_iteration`` field
-        if early stopping logic is enabled by setting ``early_stopping_rounds``.
-    evals_result : dict or None, optional (default=None)
-        Dictionary used to store all evaluation results of all the items in ``valid_sets``.
-        This should be initialized outside of your call to ``train()`` and should be empty.
-        Any initial contents of the dictionary will be deleted.
-
-        .. rubric:: Example
-
-        With a ``valid_sets`` = [valid_set, train_set],
-        ``valid_names`` = ['eval', 'train']
-        and a ``params`` = {'metric': 'logloss'}
-        returns {'train': {'logloss': ['0.48253', '0.35953', ...]},
-        'eval': {'logloss': ['0.480385', '0.357756', ...]}}.
-
-    verbose_eval : bool or int, optional (default=True)
-        Requires at least one validation data.
-        If True, the eval metric on the valid set is printed at each boosting stage.
-        If int, the eval metric on the valid set is printed at every ``verbose_eval`` boosting stage.
-        The last boosting stage or the boosting stage found by using ``early_stopping_rounds`` is also printed.
-
-        .. rubric:: Example
-
-        With ``verbose_eval`` = 4 and at least one item in ``valid_sets``,
-        an evaluation metric is printed every 4 (instead of 1) boosting stages.
-
-    learning_rates : list, callable or None, optional (default=None)
-        List of learning rates for each boosting round
-        or a callable that calculates ``learning_rate``
-        in terms of current number of round (e.g. yields learning rate decay).
+        Floating point numbers in categorical features will be rounded towards 0.
     keep_training_booster : bool, optional (default=False)
         Whether the returned Booster will be used to keep training.
         If False, the returned value will be converted into _InnerPredictor before returning.
         This means you won't be able to use ``eval``, ``eval_train`` or ``eval_valid`` methods of the returned Booster.
         When your model is very large and cause the memory error,
         you can try to set this param to ``True`` to avoid the model conversion performed during the internal call of ``model_to_string``.
         You can still use _InnerPredictor as ``init_model`` for future continue training.
     callbacks : list of callable, or None, optional (default=None)
         List of callback functions that are applied at each iteration.
         See Callbacks in Python API for more information.
 
+    Note
+    ----
+    A custom objective function can be provided for the ``objective`` parameter.
+    It should accept two parameters: preds, train_data and return (grad, hess).
+
+        preds : numpy 1-D array or numpy 2-D array (for multi-class task)
+            The predicted values.
+            Predicted values are returned before any transformation,
+            e.g. they are raw margin instead of probability of positive class for binary task.
+        train_data : Dataset
+            The training dataset.
+        grad : numpy 1-D array or numpy 2-D array (for multi-class task)
+            The value of the first order derivative (gradient) of the loss
+            with respect to the elements of preds for each sample point.
+        hess : numpy 1-D array or numpy 2-D array (for multi-class task)
+            The value of the second order derivative (Hessian) of the loss
+            with respect to the elements of preds for each sample point.
+
+    For multi-class task, preds are numpy 2-D array of shape = [n_samples, n_classes],
+    and grad and hess should be returned in the same format.
+
     Returns
     -------
     booster : Booster
         The trained Booster model.
     """
+    if not isinstance(train_set, Dataset):
+        raise TypeError(f"train() only accepts Dataset object, train_set has type '{type(train_set).__name__}'.")
+
+    if num_boost_round <= 0:
+        raise ValueError(f"num_boost_round must be greater than 0. Got {num_boost_round}.")
+
+    if isinstance(valid_sets, list):
+        for i, valid_item in enumerate(valid_sets):
+            if not isinstance(valid_item, Dataset):
+                raise TypeError(
+                    "Every item in valid_sets must be a Dataset object. "
+                    f"Item {i} has type '{type(valid_item).__name__}'."
+                )
+
     # create predictor first
     params = copy.deepcopy(params)
-    if fobj is not None:
-        for obj_alias in _ConfigAliases.get("objective"):
-            params.pop(obj_alias, None)
-        params['objective'] = 'none'
+    params = _choose_param_value(
+        main_param_name='objective',
+        params=params,
+        default_value=None
+    )
+    fobj: Optional[_LGBM_CustomObjectiveFunction] = None
+    if callable(params["objective"]):
+        fobj = params["objective"]
+        params["objective"] = 'none'
     for alias in _ConfigAliases.get("num_iterations"):
         if alias in params:
             num_boost_round = params.pop(alias)
             _log_warning(f"Found `{alias}` in params. Will use it instead of argument")
     params["num_iterations"] = num_boost_round
-    # show deprecation warning only for early stop argument, setting early stop via global params should still be possible
-    if early_stopping_rounds is not None and early_stopping_rounds > 0:
-        _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
-                     "Pass 'early_stopping()' callback via 'callbacks' argument instead.")
-    for alias in _ConfigAliases.get("early_stopping_round"):
-        if alias in params:
-            early_stopping_rounds = params.pop(alias)
-    params["early_stopping_round"] = early_stopping_rounds
+    # setting early stopping via global params should be possible
+    params = _choose_param_value(
+        main_param_name="early_stopping_round",
+        params=params,
+        default_value=None
+    )
+    if params["early_stopping_round"] is None:
+        params.pop("early_stopping_round")
     first_metric_only = params.get('first_metric_only', False)
 
-    if num_boost_round <= 0:
-        raise ValueError("num_boost_round should be greater than zero.")
     predictor: Optional[_InnerPredictor] = None
     if isinstance(init_model, (str, Path)):
         predictor = _InnerPredictor(model_file=init_model, pred_parameter=params)
     elif isinstance(init_model, Booster):
-        predictor = init_model._to_predictor(dict(init_model.params, **params))
+        predictor = init_model._to_predictor(pred_parameter=dict(init_model.params, **params))
     init_iteration = predictor.num_total_iteration if predictor is not None else 0
-    # check dataset
-    if not isinstance(train_set, Dataset):
-        raise TypeError("Training only accepts Dataset object")
 
     train_set._update_params(params) \
              ._set_predictor(predictor) \
              .set_feature_name(feature_name) \
              .set_categorical_feature(categorical_feature)
 
     is_valid_contain_train = False
@@ -215,60 +205,44 @@
         for i, valid_data in enumerate(valid_sets):
             # reduce cost for prediction training data
             if valid_data is train_set:
                 is_valid_contain_train = True
                 if valid_names is not None:
                     train_data_name = valid_names[i]
                 continue
-            if not isinstance(valid_data, Dataset):
-                raise TypeError("Training only accepts Dataset object")
             reduced_valid_sets.append(valid_data._update_params(params).set_reference(train_set))
             if valid_names is not None and len(valid_names) > i:
                 name_valid_sets.append(valid_names[i])
             else:
                 name_valid_sets.append(f'valid_{i}')
     # process callbacks
     if callbacks is None:
-        callbacks = set()
+        callbacks_set = set()
     else:
         for i, cb in enumerate(callbacks):
             cb.__dict__.setdefault('order', i - len(callbacks))
-        callbacks = set(callbacks)
+        callbacks_set = set(callbacks)
 
-    # Most of legacy advanced options becomes callbacks
-    if verbose_eval != "warn":
-        _log_warning("'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. "
-                     "Pass 'log_evaluation()' callback via 'callbacks' argument instead.")
-    else:
-        if callbacks:  # assume user has already specified log_evaluation callback
-            verbose_eval = False
-        else:
-            verbose_eval = True
-    if verbose_eval is True:
-        callbacks.add(callback.log_evaluation())
-    elif isinstance(verbose_eval, int):
-        callbacks.add(callback.log_evaluation(verbose_eval))
-
-    if early_stopping_rounds is not None and early_stopping_rounds > 0:
-        callbacks.add(callback.early_stopping(early_stopping_rounds, first_metric_only, verbose=bool(verbose_eval)))
-
-    if learning_rates is not None:
-        _log_warning("'learning_rates' argument is deprecated and will be removed in a future release of LightGBM. "
-                     "Pass 'reset_parameter()' callback via 'callbacks' argument instead.")
-        callbacks.add(callback.reset_parameter(learning_rate=learning_rates))
-
-    if evals_result is not None:
-        _log_warning("'evals_result' argument is deprecated and will be removed in a future release of LightGBM. "
-                     "Pass 'record_evaluation()' callback via 'callbacks' argument instead.")
-        callbacks.add(callback.record_evaluation(evals_result))
-
-    callbacks_before_iter = {cb for cb in callbacks if getattr(cb, 'before_iteration', False)}
-    callbacks_after_iter = callbacks - callbacks_before_iter
-    callbacks_before_iter = sorted(callbacks_before_iter, key=attrgetter('order'))
-    callbacks_after_iter = sorted(callbacks_after_iter, key=attrgetter('order'))
+    if "early_stopping_round" in params:
+        callbacks_set.add(
+            callback.early_stopping(
+                stopping_rounds=params["early_stopping_round"],  # type: ignore[arg-type]
+                first_metric_only=first_metric_only,
+                verbose=_choose_param_value(
+                    main_param_name="verbosity",
+                    params=params,
+                    default_value=1
+                ).pop("verbosity") > 0
+            )
+        )
+
+    callbacks_before_iter_set = {cb for cb in callbacks_set if getattr(cb, 'before_iteration', False)}
+    callbacks_after_iter_set = callbacks_set - callbacks_before_iter_set
+    callbacks_before_iter = sorted(callbacks_before_iter_set, key=attrgetter('order'))
+    callbacks_after_iter = sorted(callbacks_after_iter_set, key=attrgetter('order'))
 
     # construct booster
     try:
         booster = Booster(params=params, train_set=train_set)
         if is_valid_contain_train:
             booster.set_train_data_name(train_data_name)
         for valid_set, name_valid_set in zip(reduced_valid_sets, name_valid_sets):
@@ -287,15 +261,15 @@
                                     iteration=i,
                                     begin_iteration=init_iteration,
                                     end_iteration=init_iteration + num_boost_round,
                                     evaluation_result_list=None))
 
         booster.update(fobj=fobj)
 
-        evaluation_result_list = []
+        evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] = []
         # check evaluation result.
         if valid_sets is not None:
             if is_valid_contain_train:
                 evaluation_result_list.extend(booster.eval_train(feval))
             evaluation_result_list.extend(booster.eval_valid(feval))
         try:
             for cb in callbacks_after_iter:
@@ -309,58 +283,181 @@
             booster.best_iteration = earlyStopException.best_iteration + 1
             evaluation_result_list = earlyStopException.best_score
             break
     booster.best_score = collections.defaultdict(collections.OrderedDict)
     for dataset_name, eval_name, score, _ in evaluation_result_list:
         booster.best_score[dataset_name][eval_name] = score
     if not keep_training_booster:
-        booster.model_from_string(booster.model_to_string(), verbose='_silent_false').free_dataset()
+        booster.model_from_string(booster.model_to_string()).free_dataset()
     return booster
 
 
 class CVBooster:
     """CVBooster in LightGBM.
 
-    Auxiliary data structure to hold and redirect all boosters of ``cv`` function.
+    Auxiliary data structure to hold and redirect all boosters of ``cv()`` function.
     This class has the same methods as Booster class.
-    All method calls are actually performed for underlying Boosters and then all returned results are returned in a list.
+    All method calls, except for the following methods, are actually performed for underlying Boosters and
+    then all returned results are returned in a list.
+
+    - ``model_from_string()``
+    - ``model_to_string()``
+    - ``save_model()``
 
     Attributes
     ----------
     boosters : list of Booster
         The list of underlying fitted models.
     best_iteration : int
         The best iteration of fitted model.
     """
 
-    def __init__(self):
+    def __init__(
+        self,
+        model_file: Optional[Union[str, Path]] = None
+    ):
         """Initialize the CVBooster.
 
-        Generally, no need to instantiate manually.
+        Parameters
+        ----------
+        model_file : str, pathlib.Path or None, optional (default=None)
+            Path to the CVBooster model file.
         """
-        self.boosters = []
+        self.boosters: List[Booster] = []
         self.best_iteration = -1
 
-    def _append(self, booster):
+        if model_file is not None:
+            with open(model_file, "r") as file:
+                self._from_dict(json.load(file))
+
+    def _append(self, booster: Booster) -> None:
         """Add a booster to CVBooster."""
         self.boosters.append(booster)
 
-    def __getattr__(self, name):
+    def _from_dict(self, models: Dict[str, Any]) -> None:
+        """Load CVBooster from dict."""
+        self.best_iteration = models["best_iteration"]
+        self.boosters = []
+        for model_str in models["boosters"]:
+            self._append(Booster(model_str=model_str))
+
+    def _to_dict(self, num_iteration: Optional[int], start_iteration: int, importance_type: str) -> Dict[str, Any]:
+        """Serialize CVBooster to dict."""
+        models_str = []
+        for booster in self.boosters:
+            models_str.append(booster.model_to_string(num_iteration=num_iteration, start_iteration=start_iteration,
+                                                      importance_type=importance_type))
+        return {"boosters": models_str, "best_iteration": self.best_iteration}
+
+    def __getattr__(self, name: str) -> Callable[[Any, Any], List[Any]]:
         """Redirect methods call of CVBooster."""
-        def handler_function(*args, **kwargs):
+        def handler_function(*args: Any, **kwargs: Any) -> List[Any]:
             """Call methods with each booster, and concatenate their results."""
             ret = []
             for booster in self.boosters:
                 ret.append(getattr(booster, name)(*args, **kwargs))
             return ret
         return handler_function
 
+    def __getstate__(self) -> Dict[str, Any]:
+        return vars(self)
+
+    def __setstate__(self, state: Dict[str, Any]) -> None:
+        vars(self).update(state)
+
+    def model_from_string(self, model_str: str) -> "CVBooster":
+        """Load CVBooster from a string.
 
-def _make_n_folds(full_data, folds, nfold, params, seed, fpreproc=None, stratified=True,
-                  shuffle=True, eval_train_metric=False):
+        Parameters
+        ----------
+        model_str : str
+            Model will be loaded from this string.
+
+        Returns
+        -------
+        self : CVBooster
+            Loaded CVBooster object.
+        """
+        self._from_dict(json.loads(model_str))
+        return self
+
+    def model_to_string(
+        self,
+        num_iteration: Optional[int] = None,
+        start_iteration: int = 0,
+        importance_type: str = 'split'
+    ) -> str:
+        """Save CVBooster to JSON string.
+
+        Parameters
+        ----------
+        num_iteration : int or None, optional (default=None)
+            Index of the iteration that should be saved.
+            If None, if the best iteration exists, it is saved; otherwise, all iterations are saved.
+            If <= 0, all iterations are saved.
+        start_iteration : int, optional (default=0)
+            Start index of the iteration that should be saved.
+        importance_type : str, optional (default="split")
+            What type of feature importance should be saved.
+            If "split", result contains numbers of times the feature is used in a model.
+            If "gain", result contains total gains of splits which use the feature.
+
+        Returns
+        -------
+        str_repr : str
+            JSON string representation of CVBooster.
+        """
+        return json.dumps(self._to_dict(num_iteration, start_iteration, importance_type))
+
+    def save_model(
+        self,
+        filename: Union[str, Path],
+        num_iteration: Optional[int] = None,
+        start_iteration: int = 0,
+        importance_type: str = 'split'
+    ) -> "CVBooster":
+        """Save CVBooster to a file as JSON text.
+
+        Parameters
+        ----------
+        filename : str or pathlib.Path
+            Filename to save CVBooster.
+        num_iteration : int or None, optional (default=None)
+            Index of the iteration that should be saved.
+            If None, if the best iteration exists, it is saved; otherwise, all iterations are saved.
+            If <= 0, all iterations are saved.
+        start_iteration : int, optional (default=0)
+            Start index of the iteration that should be saved.
+        importance_type : str, optional (default="split")
+            What type of feature importance should be saved.
+            If "split", result contains numbers of times the feature is used in a model.
+            If "gain", result contains total gains of splits which use the feature.
+
+        Returns
+        -------
+        self : CVBooster
+            Returns self.
+        """
+        with open(filename, "w") as file:
+            json.dump(self._to_dict(num_iteration, start_iteration, importance_type), file)
+
+        return self
+
+
+def _make_n_folds(
+    full_data: Dataset,
+    folds: Optional[Union[Iterable[Tuple[np.ndarray, np.ndarray]], _LGBMBaseCrossValidator]],
+    nfold: int,
+    params: Dict[str, Any],
+    seed: int,
+    fpreproc: Optional[_LGBM_PreprocFunction],
+    stratified: bool,
+    shuffle: bool,
+    eval_train_metric: bool
+) -> CVBooster:
     """Make a n-fold list of Booster from random indices."""
     full_data = full_data.construct()
     num_data = full_data.num_data()
     if folds is not None:
         if not hasattr(folds, '__iter__') and not hasattr(folds, 'split'):
             raise AttributeError("folds should be a generator or iterator of (train_idx, test_idx) tuples "
                                  "or scikit-learn splitter object with split method")
@@ -411,44 +508,55 @@
         if eval_train_metric:
             cvbooster.add_valid(train_set, 'train')
         cvbooster.add_valid(valid_set, 'valid')
         ret._append(cvbooster)
     return ret
 
 
-def _agg_cv_result(raw_results, eval_train_metric=False):
+def _agg_cv_result(
+    raw_results: List[List[Tuple[str, str, float, bool]]]
+) -> List[Tuple[str, str, float, bool, float]]:
     """Aggregate cross-validation results."""
-    cvmap = collections.OrderedDict()
-    metric_type = {}
+    cvmap: Dict[str, List[float]] = collections.OrderedDict()
+    metric_type: Dict[str, bool] = {}
     for one_result in raw_results:
         for one_line in one_result:
-            if eval_train_metric:
-                key = f"{one_line[0]} {one_line[1]}"
-            else:
-                key = one_line[1]
+            key = f"{one_line[0]} {one_line[1]}"
             metric_type[key] = one_line[3]
             cvmap.setdefault(key, [])
             cvmap[key].append(one_line[2])
     return [('cv_agg', k, np.mean(v), metric_type[k], np.std(v)) for k, v in cvmap.items()]
 
 
-def cv(params, train_set, num_boost_round=100,
-       folds=None, nfold=5, stratified=True, shuffle=True,
-       metrics=None, fobj=None, feval=None, init_model=None,
-       feature_name='auto', categorical_feature='auto',
-       early_stopping_rounds=None, fpreproc=None,
-       verbose_eval=None, show_stdv=True, seed=0,
-       callbacks=None, eval_train_metric=False,
-       return_cvbooster=False):
+def cv(
+    params: Dict[str, Any],
+    train_set: Dataset,
+    num_boost_round: int = 100,
+    folds: Optional[Union[Iterable[Tuple[np.ndarray, np.ndarray]], _LGBMBaseCrossValidator]] = None,
+    nfold: int = 5,
+    stratified: bool = True,
+    shuffle: bool = True,
+    metrics: Optional[Union[str, List[str]]] = None,
+    feval: Optional[Union[_LGBM_CustomMetricFunction, List[_LGBM_CustomMetricFunction]]] = None,
+    init_model: Optional[Union[str, Path, Booster]] = None,
+    feature_name: _LGBM_FeatureNameConfiguration = 'auto',
+    categorical_feature: _LGBM_CategoricalFeatureConfiguration = 'auto',
+    fpreproc: Optional[_LGBM_PreprocFunction] = None,
+    seed: int = 0,
+    callbacks: Optional[List[Callable]] = None,
+    eval_train_metric: bool = False,
+    return_cvbooster: bool = False
+) -> Dict[str, Union[List[float], CVBooster]]:
     """Perform the cross-validation with given parameters.
 
     Parameters
     ----------
     params : dict
-        Parameters for Booster.
+        Parameters for training. Values passed through ``params`` take precedence over those
+        supplied via arguments.
     train_set : Dataset
         Data to be trained on.
     num_boost_round : int, optional (default=100)
         Number of boosting iterations.
     folds : generator or iterator of (train_idx, test_idx) tuples, scikit-learn splitter object or None, optional (default=None)
         If generator or iterator, it should yield the train and test indices for each fold.
         If object, it should be one of the scikit-learn splitter classes
@@ -460,203 +568,201 @@
     stratified : bool, optional (default=True)
         Whether to perform stratified sampling.
     shuffle : bool, optional (default=True)
         Whether to shuffle before splitting data.
     metrics : str, list of str, or None, optional (default=None)
         Evaluation metrics to be monitored while CV.
         If not None, the metric in ``params`` will be overridden.
-    fobj : callable or None, optional (default=None)
-        Customized objective function.
-        Should accept two parameters: preds, train_data,
-        and return (grad, hess).
-
-            preds : list or numpy 1-D array
-                The predicted values.
-                Predicted values are returned before any transformation,
-                e.g. they are raw margin instead of probability of positive class for binary task.
-            train_data : Dataset
-                The training dataset.
-            grad : list or numpy 1-D array
-                The value of the first order derivative (gradient) of the loss
-                with respect to the elements of preds for each sample point.
-            hess : list or numpy 1-D array
-                The value of the second order derivative (Hessian) of the loss
-                with respect to the elements of preds for each sample point.
-
-        For multi-class task, the preds is group by class_id first, then group by row_id.
-        If you want to get i-th row preds in j-th class, the access way is score[j * num_data + i]
-        and you should group grad and hess in this way as well.
-
     feval : callable, list of callable, or None, optional (default=None)
         Customized evaluation function.
-        Each evaluation function should accept two parameters: preds, train_data,
+        Each evaluation function should accept two parameters: preds, eval_data,
         and return (eval_name, eval_result, is_higher_better) or list of such tuples.
 
-            preds : list or numpy 1-D array
+            preds : numpy 1-D array or numpy 2-D array (for multi-class task)
                 The predicted values.
-                If ``fobj`` is specified, predicted values are returned before any transformation,
+                For multi-class task, preds are numpy 2-D array of shape = [n_samples, n_classes].
+                If custom objective function is used, predicted values are returned before any transformation,
                 e.g. they are raw margin instead of probability of positive class for binary task in this case.
-            train_data : Dataset
-                The training dataset.
+            eval_data : Dataset
+                A ``Dataset`` to evaluate.
             eval_name : str
                 The name of evaluation function (without whitespace).
             eval_result : float
                 The eval result.
             is_higher_better : bool
                 Is eval result higher better, e.g. AUC is ``is_higher_better``.
 
-        For multi-class task, the preds is group by class_id first, then group by row_id.
-        If you want to get i-th row preds in j-th class, the access way is preds[j * num_data + i].
         To ignore the default metric corresponding to the used objective,
         set ``metrics`` to the string ``"None"``.
     init_model : str, pathlib.Path, Booster or None, optional (default=None)
         Filename of LightGBM model or Booster instance used for continue training.
     feature_name : list of str, or 'auto', optional (default="auto")
         Feature names.
         If 'auto' and data is pandas DataFrame, data columns names are used.
     categorical_feature : list of str or int, or 'auto', optional (default="auto")
         Categorical features.
         If list of int, interpreted as indices.
         If list of str, interpreted as feature names (need to specify ``feature_name`` as well).
         If 'auto' and data is pandas DataFrame, pandas unordered categorical columns are used.
-        All values in categorical features should be less than int32 max value (2147483647).
+        All values in categorical features will be cast to int32 and thus should be less than int32 max value (2147483647).
         Large values could be memory consuming. Consider using consecutive integers starting from zero.
         All negative values in categorical features will be treated as missing values.
         The output cannot be monotonically constrained with respect to a categorical feature.
-    early_stopping_rounds : int or None, optional (default=None)
-        Activates early stopping.
-        CV score needs to improve at least every ``early_stopping_rounds`` round(s)
-        to continue.
-        Requires at least one metric. If there's more than one, will check all of them.
-        To check only the first metric, set the ``first_metric_only`` parameter to ``True`` in ``params``.
-        Last entry in evaluation history is the one from the best iteration.
+        Floating point numbers in categorical features will be rounded towards 0.
     fpreproc : callable or None, optional (default=None)
         Preprocessing function that takes (dtrain, dtest, params)
         and returns transformed versions of those.
-    verbose_eval : bool, int, or None, optional (default=None)
-        Whether to display the progress.
-        If True, progress will be displayed at every boosting stage.
-        If int, progress will be displayed at every given ``verbose_eval`` boosting stage.
-    show_stdv : bool, optional (default=True)
-        Whether to display the standard deviation in progress.
-        Results are not affected by this parameter, and always contain std.
     seed : int, optional (default=0)
         Seed used to generate the folds (passed to numpy.random.seed).
     callbacks : list of callable, or None, optional (default=None)
         List of callback functions that are applied at each iteration.
         See Callbacks in Python API for more information.
     eval_train_metric : bool, optional (default=False)
         Whether to display the train metric in progress.
         The score of the metric is calculated again after each training step, so there is some impact on performance.
     return_cvbooster : bool, optional (default=False)
         Whether to return Booster models trained on each fold through ``CVBooster``.
 
+    Note
+    ----
+    A custom objective function can be provided for the ``objective`` parameter.
+    It should accept two parameters: preds, train_data and return (grad, hess).
+
+        preds : numpy 1-D array or numpy 2-D array (for multi-class task)
+            The predicted values.
+            Predicted values are returned before any transformation,
+            e.g. they are raw margin instead of probability of positive class for binary task.
+        train_data : Dataset
+            The training dataset.
+        grad : numpy 1-D array or numpy 2-D array (for multi-class task)
+            The value of the first order derivative (gradient) of the loss
+            with respect to the elements of preds for each sample point.
+        hess : numpy 1-D array or numpy 2-D array (for multi-class task)
+            The value of the second order derivative (Hessian) of the loss
+            with respect to the elements of preds for each sample point.
+
+    For multi-class task, preds are numpy 2-D array of shape = [n_samples, n_classes],
+    and grad and hess should be returned in the same format.
+
     Returns
     -------
     eval_hist : dict
         Evaluation history.
         The dictionary has the following format:
         {'metric1-mean': [values], 'metric1-stdv': [values],
         'metric2-mean': [values], 'metric2-stdv': [values],
         ...}.
-        If ``return_cvbooster=True``, also returns trained boosters via ``cvbooster`` key.
+        If ``return_cvbooster=True``, also returns trained boosters wrapped in a ``CVBooster`` object via ``cvbooster`` key.
     """
     if not isinstance(train_set, Dataset):
-        raise TypeError("Training only accepts Dataset object")
+        raise TypeError(f"cv() only accepts Dataset object, train_set has type '{type(train_set).__name__}'.")
+
+    if num_boost_round <= 0:
+        raise ValueError(f"num_boost_round must be greater than 0. Got {num_boost_round}.")
 
     params = copy.deepcopy(params)
-    if fobj is not None:
-        for obj_alias in _ConfigAliases.get("objective"):
-            params.pop(obj_alias, None)
-        params['objective'] = 'none'
+    params = _choose_param_value(
+        main_param_name='objective',
+        params=params,
+        default_value=None
+    )
+    fobj: Optional[_LGBM_CustomObjectiveFunction] = None
+    if callable(params["objective"]):
+        fobj = params["objective"]
+        params["objective"] = 'none'
     for alias in _ConfigAliases.get("num_iterations"):
         if alias in params:
-            _log_warning(f"Found `{alias}` in params. Will use it instead of argument")
+            _log_warning(f"Found '{alias}' in params. Will use it instead of 'num_boost_round' argument")
             num_boost_round = params.pop(alias)
     params["num_iterations"] = num_boost_round
-    if early_stopping_rounds is not None and early_stopping_rounds > 0:
-        _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
-                     "Pass 'early_stopping()' callback via 'callbacks' argument instead.")
-    for alias in _ConfigAliases.get("early_stopping_round"):
-        if alias in params:
-            early_stopping_rounds = params.pop(alias)
-    params["early_stopping_round"] = early_stopping_rounds
+    # setting early stopping via global params should be possible
+    params = _choose_param_value(
+        main_param_name="early_stopping_round",
+        params=params,
+        default_value=None
+    )
+    if params["early_stopping_round"] is None:
+        params.pop("early_stopping_round")
     first_metric_only = params.get('first_metric_only', False)
 
-    if num_boost_round <= 0:
-        raise ValueError("num_boost_round should be greater than zero.")
     if isinstance(init_model, (str, Path)):
         predictor = _InnerPredictor(model_file=init_model, pred_parameter=params)
     elif isinstance(init_model, Booster):
-        predictor = init_model._to_predictor(dict(init_model.params, **params))
+        predictor = init_model._to_predictor(pred_parameter=dict(init_model.params, **params))
     else:
         predictor = None
 
     if metrics is not None:
         for metric_alias in _ConfigAliases.get("metric"):
             params.pop(metric_alias, None)
         params['metric'] = metrics
 
     train_set._update_params(params) \
              ._set_predictor(predictor) \
              .set_feature_name(feature_name) \
              .set_categorical_feature(categorical_feature)
 
     results = collections.defaultdict(list)
-    cvfolds = _make_n_folds(train_set, folds=folds, nfold=nfold,
+    cvfolds = _make_n_folds(full_data=train_set, folds=folds, nfold=nfold,
                             params=params, seed=seed, fpreproc=fpreproc,
                             stratified=stratified, shuffle=shuffle,
                             eval_train_metric=eval_train_metric)
 
     # setup callbacks
     if callbacks is None:
-        callbacks = set()
+        callbacks_set = set()
     else:
         for i, cb in enumerate(callbacks):
             cb.__dict__.setdefault('order', i - len(callbacks))
-        callbacks = set(callbacks)
-    if early_stopping_rounds is not None and early_stopping_rounds > 0:
-        callbacks.add(callback.early_stopping(early_stopping_rounds, first_metric_only, verbose=False))
-    if verbose_eval is not None:
-        _log_warning("'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. "
-                     "Pass 'log_evaluation()' callback via 'callbacks' argument instead.")
-    if verbose_eval is True:
-        callbacks.add(callback.log_evaluation(show_stdv=show_stdv))
-    elif isinstance(verbose_eval, int):
-        callbacks.add(callback.log_evaluation(verbose_eval, show_stdv=show_stdv))
-
-    callbacks_before_iter = {cb for cb in callbacks if getattr(cb, 'before_iteration', False)}
-    callbacks_after_iter = callbacks - callbacks_before_iter
-    callbacks_before_iter = sorted(callbacks_before_iter, key=attrgetter('order'))
-    callbacks_after_iter = sorted(callbacks_after_iter, key=attrgetter('order'))
+        callbacks_set = set(callbacks)
+
+    if "early_stopping_round" in params:
+        callbacks_set.add(
+            callback.early_stopping(
+                stopping_rounds=params["early_stopping_round"],  # type: ignore[arg-type]
+                first_metric_only=first_metric_only,
+                verbose=_choose_param_value(
+                    main_param_name="verbosity",
+                    params=params,
+                    default_value=1
+                ).pop("verbosity") > 0
+            )
+        )
+
+    callbacks_before_iter_set = {cb for cb in callbacks_set if getattr(cb, 'before_iteration', False)}
+    callbacks_after_iter_set = callbacks_set - callbacks_before_iter_set
+    callbacks_before_iter = sorted(callbacks_before_iter_set, key=attrgetter('order'))
+    callbacks_after_iter = sorted(callbacks_after_iter_set, key=attrgetter('order'))
 
     for i in range(num_boost_round):
         for cb in callbacks_before_iter:
             cb(callback.CallbackEnv(model=cvfolds,
                                     params=params,
                                     iteration=i,
                                     begin_iteration=0,
                                     end_iteration=num_boost_round,
                                     evaluation_result_list=None))
-        cvfolds.update(fobj=fobj)
-        res = _agg_cv_result(cvfolds.eval_valid(feval), eval_train_metric)
+        cvfolds.update(fobj=fobj)  # type: ignore[call-arg]
+        res = _agg_cv_result(cvfolds.eval_valid(feval))  # type: ignore[call-arg]
         for _, key, mean, _, std in res:
             results[f'{key}-mean'].append(mean)
             results[f'{key}-stdv'].append(std)
         try:
             for cb in callbacks_after_iter:
                 cb(callback.CallbackEnv(model=cvfolds,
                                         params=params,
                                         iteration=i,
                                         begin_iteration=0,
                                         end_iteration=num_boost_round,
                                         evaluation_result_list=res))
         except callback.EarlyStopException as earlyStopException:
             cvfolds.best_iteration = earlyStopException.best_iteration + 1
+            for bst in cvfolds.boosters:
+                bst.best_iteration = cvfolds.best_iteration
             for k in results:
                 results[k] = results[k][:cvfolds.best_iteration]
             break
 
     if return_cvbooster:
-        results['cvbooster'] = cvfolds
+        results['cvbooster'] = cvfolds  # type: ignore[assignment]
 
     return dict(results)
```

### Comparing `lightgbm-3.3.5/lightgbm/libpath.py` & `lightgbm-4.0.0/lightgbm/libpath.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,36 +1,30 @@
 # coding: utf-8
 """Find the path to LightGBM dynamic library files."""
-from os import environ
 from pathlib import Path
 from platform import system
 from typing import List
 
+__all__: List[str] = []
+
 
 def find_lib_path() -> List[str]:
     """Find the path to LightGBM library files.
 
     Returns
     -------
     lib_path: list of str
        List of all found library paths to LightGBM.
     """
-    if environ.get('LIGHTGBM_BUILD_DOC', False):
-        # we don't need lib_lightgbm while building docs
-        return []
-
-    curr_path = Path(__file__).absolute().parent
+    curr_path = Path(__file__).absolute()
     dll_path = [curr_path,
                 curr_path.parents[1],
-                curr_path / 'compile',
-                curr_path.parent / 'compile',
-                curr_path.parents[1] / 'lib']
+                curr_path.parents[0] / 'bin',
+                curr_path.parents[0] / 'lib']
     if system() in ('Windows', 'Microsoft'):
-        dll_path.append(curr_path.parent / 'compile' / 'Release')
-        dll_path.append(curr_path.parent / 'compile' / 'windows' / 'x64' / 'DLL')
         dll_path.append(curr_path.parents[1] / 'Release')
         dll_path.append(curr_path.parents[1] / 'windows' / 'x64' / 'DLL')
         dll_path = [p / 'lib_lightgbm.dll' for p in dll_path]
     else:
         dll_path = [p / 'lib_lightgbm.so' for p in dll_path]
     lib_path = [str(p) for p in dll_path if p.is_file()]
     if not lib_path:
```

### Comparing `lightgbm-3.3.5/lightgbm/plotting.py` & `lightgbm-4.0.0/lightgbm/plotting.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,27 +1,36 @@
 # coding: utf-8
 """Plotting library."""
+import math
 from copy import deepcopy
 from io import BytesIO
 from typing import Any, Dict, List, Optional, Tuple, Union
 
 import numpy as np
 
-from .basic import Booster, _log_warning
-from .compat import GRAPHVIZ_INSTALLED, MATPLOTLIB_INSTALLED
+from .basic import Booster, _data_from_pandas, _is_zero, _log_warning, _MissingType
+from .compat import GRAPHVIZ_INSTALLED, MATPLOTLIB_INSTALLED, pd_DataFrame
 from .sklearn import LGBMModel
 
+__all__ = [
+    'create_tree_digraph',
+    'plot_importance',
+    'plot_metric',
+    'plot_split_value_histogram',
+    'plot_tree',
+]
 
-def _check_not_tuple_of_2_elements(obj: Any, obj_name: str = 'obj') -> None:
+
+def _check_not_tuple_of_2_elements(obj: Any, obj_name: str) -> None:
     """Check object is not tuple or does not have 2 elements."""
     if not isinstance(obj, tuple) or len(obj) != 2:
         raise TypeError(f"{obj_name} must be a tuple of 2 elements.")
 
 
-def _float2str(value: float, precision: Optional[int] = None) -> str:
+def _float2str(value: float, precision: Optional[int]) -> str:
     return (f"{value:.{precision}f}"
             if precision is not None and not isinstance(value, str)
             else str(value))
 
 
 def plot_importance(
     booster: Union[Booster, LGBMModel],
@@ -232,33 +241,33 @@
         raise ImportError('You must install matplotlib and restart your session to plot split value histogram.')
 
     if isinstance(booster, LGBMModel):
         booster = booster.booster_
     elif not isinstance(booster, Booster):
         raise TypeError('booster must be Booster or LGBMModel.')
 
-    hist, bins = booster.get_split_value_histogram(feature=feature, bins=bins, xgboost_style=False)
+    hist, split_bins = booster.get_split_value_histogram(feature=feature, bins=bins, xgboost_style=False)
     if np.count_nonzero(hist) == 0:
         raise ValueError('Cannot plot split value histogram, '
                          f'because feature {feature} was not used in splitting')
-    width = width_coef * (bins[1] - bins[0])
-    centred = (bins[:-1] + bins[1:]) / 2
+    width = width_coef * (split_bins[1] - split_bins[0])
+    centred = (split_bins[:-1] + split_bins[1:]) / 2
 
     if ax is None:
         if figsize is not None:
             _check_not_tuple_of_2_elements(figsize, 'figsize')
         _, ax = plt.subplots(1, 1, figsize=figsize, dpi=dpi)
 
     ax.bar(centred, hist, align='center', width=width, **kwargs)
 
     if xlim is not None:
         _check_not_tuple_of_2_elements(xlim, 'xlim')
     else:
-        range_result = bins[-1] - bins[0]
-        xlim = (bins[0] - range_result * 0.2, bins[-1] + range_result * 0.2)
+        range_result = split_bins[-1] - split_bins[0]
+        xlim = (split_bins[0] - range_result * 0.2, split_bins[-1] + range_result * 0.2)
     ax.set_xlim(xlim)
 
     ax.yaxis.set_major_locator(MaxNLocator(integer=True))
     if ylim is not None:
         _check_not_tuple_of_2_elements(ylim, 'ylim')
     else:
         ylim = (0, max(hist) * 1.1)
@@ -354,21 +363,21 @@
 
     if ax is None:
         if figsize is not None:
             _check_not_tuple_of_2_elements(figsize, 'figsize')
         _, ax = plt.subplots(1, 1, figsize=figsize, dpi=dpi)
 
     if dataset_names is None:
-        dataset_names = iter(eval_results.keys())
+        dataset_names_iter = iter(eval_results.keys())
     elif not isinstance(dataset_names, (list, tuple, set)) or not dataset_names:
         raise ValueError('dataset_names should be iterable and cannot be empty')
     else:
-        dataset_names = iter(dataset_names)
+        dataset_names_iter = iter(dataset_names)
 
-    name = next(dataset_names)  # take one as sample
+    name = next(dataset_names_iter)  # take one as sample
     metrics_for_one = eval_results[name]
     num_metric = len(metrics_for_one)
     if metric is None:
         if num_metric > 1:
             _log_warning("More than one metric available, picking one to plot.")
         metric, results = metrics_for_one.popitem()
     else:
@@ -377,15 +386,15 @@
         results = metrics_for_one[metric]
     num_iteration = len(results)
     max_result = max(results)
     min_result = min(results)
     x_ = range(num_iteration)
     ax.plot(x_, results, label=name)
 
-    for name in dataset_names:
+    for name in dataset_names_iter:
         metrics_for_one = eval_results[name]
         results = metrics_for_one[metric]
         max_result = max(max(results), max_result)
         min_result = min(min(results), min_result)
         ax.plot(x_, results, label=name)
 
     ax.legend(loc='best')
@@ -399,109 +408,183 @@
     if ylim is not None:
         _check_not_tuple_of_2_elements(ylim, 'ylim')
     else:
         range_result = max_result - min_result
         ylim = (min_result - range_result * 0.2, max_result + range_result * 0.2)
     ax.set_ylim(ylim)
 
-    if ylabel == 'auto':
-        _log_warning("'auto' value of 'ylabel' argument is deprecated and will be removed in a future release of LightGBM. "
-                     "Use '@metric@' placeholder instead.")
-        ylabel = '@metric@'
-
     if title is not None:
         ax.set_title(title)
     if xlabel is not None:
         ax.set_xlabel(xlabel)
     if ylabel is not None:
         ylabel = ylabel.replace('@metric@', metric)
         ax.set_ylabel(ylabel)
     ax.grid(grid)
     return ax
 
 
+def _determine_direction_for_numeric_split(
+    fval: float,
+    threshold: float,
+    missing_type_str: str,
+    default_left: bool,
+) -> str:
+    missing_type = _MissingType(missing_type_str)
+    if math.isnan(fval) and missing_type != _MissingType.NAN:
+        fval = 0.0
+    if ((missing_type == _MissingType.ZERO and _is_zero(fval))
+            or (missing_type == _MissingType.NAN and math.isnan(fval))):
+        direction = 'left' if default_left else 'right'
+    else:
+        direction = 'left' if fval <= threshold else 'right'
+    return direction
+
+
+def _determine_direction_for_categorical_split(fval: float, thresholds: str) -> str:
+    if math.isnan(fval) or int(fval) < 0:
+        return 'right'
+    int_thresholds = {int(t) for t in thresholds.split('||')}
+    return 'left' if int(fval) in int_thresholds else 'right'
+
+
 def _to_graphviz(
     tree_info: Dict[str, Any],
     show_info: List[str],
     feature_names: Union[List[str], None],
-    precision: Optional[int] = 3,
-    orientation: str = 'horizontal',
-    constraints: Optional[List[int]] = None,
+    precision: Optional[int],
+    orientation: str,
+    constraints: Optional[List[int]],
+    example_case: Optional[Union[np.ndarray, pd_DataFrame]],
+    max_category_values: int,
     **kwargs: Any
 ) -> Any:
     """Convert specified tree to graphviz instance.
 
     See:
       - https://graphviz.readthedocs.io/en/stable/api.html#digraph
     """
     if GRAPHVIZ_INSTALLED:
         from graphviz import Digraph
     else:
         raise ImportError('You must install graphviz and restart your session to plot tree.')
 
-    def add(root, total_count, parent=None, decision=None):
+    def add(
+        root: Dict[str, Any],
+        total_count: int,
+        parent: Optional[str],
+        decision: Optional[str],
+        highlight: bool
+    ) -> None:
         """Recursively add node or edge."""
+        fillcolor = 'white'
+        style = ''
+        tooltip = None
+        if highlight:
+            color = 'blue'
+            penwidth = '3'
+        else:
+            color = 'black'
+            penwidth = '1'
         if 'split_index' in root:  # non-leaf
+            shape = "rectangle"
             l_dec = 'yes'
             r_dec = 'no'
+            threshold = root['threshold']
             if root['decision_type'] == '<=':
-                lte_symbol = "&#8804;"
-                operator = lte_symbol
+                operator = "&#8804;"
             elif root['decision_type'] == '==':
                 operator = "="
             else:
                 raise ValueError('Invalid decision type in tree model.')
             name = f"split{root['split_index']}"
+            split_feature = root['split_feature']
             if feature_names is not None:
-                label = f"<B>{feature_names[root['split_feature']]}</B> {operator}"
+                label = f"<B>{feature_names[split_feature]}</B> {operator}"
             else:
-                label = f"feature <B>{root['split_feature']}</B> {operator} "
-            label += f"<B>{_float2str(root['threshold'], precision)}</B>"
+                label = f"feature <B>{split_feature}</B> {operator} "
+            direction = None
+            if example_case is not None:
+                if root['decision_type'] == '==':
+                    direction = _determine_direction_for_categorical_split(
+                        fval=example_case[split_feature],
+                        thresholds=root['threshold']
+                    )
+                else:
+                    direction = _determine_direction_for_numeric_split(
+                        fval=example_case[split_feature],
+                        threshold=root['threshold'],
+                        missing_type_str=root['missing_type'],
+                        default_left=root['default_left']
+                    )
+            if root['decision_type'] == '==':
+                category_values = root['threshold'].split('||')
+                if len(category_values) > max_category_values:
+                    tooltip = root['threshold']
+                    threshold = '||'.join(category_values[:2]) + '||...||' + category_values[-1]
+
+            label += f"<B>{_float2str(threshold, precision)}</B>"
             for info in ['split_gain', 'internal_value', 'internal_weight', "internal_count", "data_percentage"]:
                 if info in show_info:
                     output = info.split('_')[-1]
                     if info in {'split_gain', 'internal_value', 'internal_weight'}:
                         label += f"<br/>{_float2str(root[info], precision)} {output}"
                     elif info == 'internal_count':
                         label += f"<br/>{output}: {root[info]}"
                     elif info == "data_percentage":
                         label += f"<br/>{_float2str(root['internal_count'] / total_count * 100, 2)}% of data"
 
-            fillcolor = "white"
-            style = ""
             if constraints:
                 if constraints[root['split_feature']] == 1:
                     fillcolor = "#ddffdd"  # light green
                 if constraints[root['split_feature']] == -1:
                     fillcolor = "#ffdddd"  # light red
                 style = "filled"
             label = f"<{label}>"
-            graph.node(name, label=label, shape="rectangle", style=style, fillcolor=fillcolor)
-            add(root['left_child'], total_count, name, l_dec)
-            add(root['right_child'], total_count, name, r_dec)
+            add(
+                root=root['left_child'],
+                total_count=total_count,
+                parent=name,
+                decision=l_dec,
+                highlight=highlight and direction == "left"
+            )
+            add(
+                root=root['right_child'],
+                total_count=total_count,
+                parent=name,
+                decision=r_dec,
+                highlight=highlight and direction == "right"
+            )
         else:  # leaf
+            shape = "ellipse"
             name = f"leaf{root['leaf_index']}"
             label = f"leaf {root['leaf_index']}: "
             label += f"<B>{_float2str(root['leaf_value'], precision)}</B>"
             if 'leaf_weight' in show_info:
                 label += f"<br/>{_float2str(root['leaf_weight'], precision)} weight"
             if 'leaf_count' in show_info:
                 label += f"<br/>count: {root['leaf_count']}"
             if "data_percentage" in show_info:
                 label += f"<br/>{_float2str(root['leaf_count'] / total_count * 100, 2)}% of data"
             label = f"<{label}>"
-            graph.node(name, label=label)
+        graph.node(name, label=label, shape=shape, style=style, fillcolor=fillcolor, color=color, penwidth=penwidth, tooltip=tooltip)
         if parent is not None:
-            graph.edge(parent, name, decision)
+            graph.edge(parent, name, decision, color=color, penwidth=penwidth)
 
     graph = Digraph(**kwargs)
     rankdir = "LR" if orientation == "horizontal" else "TB"
     graph.attr("graph", nodesep="0.05", ranksep="0.3", rankdir=rankdir)
     if "internal_count" in tree_info['tree_structure']:
-        add(tree_info['tree_structure'], tree_info['tree_structure']["internal_count"])
+        add(
+            root=tree_info['tree_structure'],
+            total_count=tree_info['tree_structure']["internal_count"],
+            parent=None,
+            decision=None,
+            highlight=example_case is not None
+        )
     else:
         raise Exception("Cannot plot trees with no split")
 
     if constraints:
         # "#ddffdd" is light green, "#ffdddd" is light red
         legend = """<
             <TABLE BORDER="0" CELLBORDER="1" CELLSPACING="0" CELLPADDING="4">
@@ -524,14 +607,16 @@
 
 def create_tree_digraph(
     booster: Union[Booster, LGBMModel],
     tree_index: int = 0,
     show_info: Optional[List[str]] = None,
     precision: Optional[int] = 3,
     orientation: str = 'horizontal',
+    example_case: Optional[Union[np.ndarray, pd_DataFrame]] = None,
+    max_category_values: int = 10,
     **kwargs: Any
 ) -> Any:
     """Create a digraph representation of specified tree.
 
     Each node in the graph represents a node in the tree.
 
     Non-leaf nodes have labels like ``Column_10 <= 875.9``, which means
@@ -557,21 +642,45 @@
         What information should be shown in nodes.
 
             - ``'split_gain'`` : gain from adding this split to the model
             - ``'internal_value'`` : raw predicted value that would be produced by this node if it was a leaf node
             - ``'internal_count'`` : number of records from the training data that fall into this non-leaf node
             - ``'internal_weight'`` : total weight of all nodes that fall into this non-leaf node
             - ``'leaf_count'`` : number of records from the training data that fall into this leaf node
-            - ``'leaf_weight'`` : total weight (sum of hessian) of all observations that fall into this leaf node
+            - ``'leaf_weight'`` : total weight (sum of Hessian) of all observations that fall into this leaf node
             - ``'data_percentage'`` : percentage of training data that fall into this node
     precision : int or None, optional (default=3)
         Used to restrict the display of floating point values to a certain precision.
     orientation : str, optional (default='horizontal')
         Orientation of the tree.
         Can be 'horizontal' or 'vertical'.
+    example_case : numpy 2-D array, pandas DataFrame or None, optional (default=None)
+        Single row with the same structure as the training data.
+        If not None, the plot will highlight the path that sample takes through the tree.
+
+        .. versionadded:: 4.0.0
+
+    max_category_values : int, optional (default=10)
+        The maximum number of category values to display in tree nodes, if the number of thresholds is greater than this value, thresholds will be collapsed and displayed on the label tooltip instead.
+
+        .. warning::
+
+            Consider wrapping the SVG string of the tree graph with ``IPython.display.HTML`` when running on JupyterLab to get the `tooltip <https://graphviz.org/docs/attrs/tooltip>`_ working right.
+
+            Example:
+
+            .. code-block:: python
+
+                from IPython.display import HTML
+
+                graph = lgb.create_tree_digraph(clf, max_category_values=5)
+                HTML(graph._repr_image_svg_xml())
+
+        .. versionadded:: 4.0.0
+
     **kwargs
         Other parameters passed to ``Digraph`` constructor.
         Check https://graphviz.readthedocs.io/en/stable/api.html#digraph for the full list of supported parameters.
 
     Returns
     -------
     graph : graphviz.Digraph
@@ -595,29 +704,53 @@
         tree_info = tree_infos[tree_index]
     else:
         raise IndexError('tree_index is out of range.')
 
     if show_info is None:
         show_info = []
 
-    graph = _to_graphviz(tree_info, show_info, feature_names, precision,
-                         orientation, monotone_constraints, **kwargs)
+    if example_case is not None:
+        if not isinstance(example_case, (np.ndarray, pd_DataFrame)) or example_case.ndim != 2:
+            raise ValueError('example_case must be a numpy 2-D array or a pandas DataFrame')
+        if example_case.shape[0] != 1:
+            raise ValueError('example_case must have a single row.')
+        if isinstance(example_case, pd_DataFrame):
+            example_case = _data_from_pandas(
+                data=example_case,
+                feature_name=None,
+                categorical_feature=None,
+                pandas_categorical=booster.pandas_categorical
+            )[0]
+        example_case = example_case[0]
+
+    graph = _to_graphviz(
+        tree_info=tree_info,
+        show_info=show_info,
+        feature_names=feature_names,
+        precision=precision,
+        orientation=orientation,
+        constraints=monotone_constraints,
+        example_case=example_case,
+        max_category_values=max_category_values,
+        **kwargs
+    )
 
     return graph
 
 
 def plot_tree(
     booster: Union[Booster, LGBMModel],
     ax=None,
     tree_index: int = 0,
     figsize: Optional[Tuple[float, float]] = None,
     dpi: Optional[int] = None,
     show_info: Optional[List[str]] = None,
     precision: Optional[int] = 3,
     orientation: str = 'horizontal',
+    example_case: Optional[Union[np.ndarray, pd_DataFrame]] = None,
     **kwargs: Any
 ) -> Any:
     """Plot specified tree.
 
     Each node in the graph represents a node in the tree.
 
     Non-leaf nodes have labels like ``Column_10 <= 875.9``, which means
@@ -650,21 +783,27 @@
         What information should be shown in nodes.
 
             - ``'split_gain'`` : gain from adding this split to the model
             - ``'internal_value'`` : raw predicted value that would be produced by this node if it was a leaf node
             - ``'internal_count'`` : number of records from the training data that fall into this non-leaf node
             - ``'internal_weight'`` : total weight of all nodes that fall into this non-leaf node
             - ``'leaf_count'`` : number of records from the training data that fall into this leaf node
-            - ``'leaf_weight'`` : total weight (sum of hessian) of all observations that fall into this leaf node
+            - ``'leaf_weight'`` : total weight (sum of Hessian) of all observations that fall into this leaf node
             - ``'data_percentage'`` : percentage of training data that fall into this node
     precision : int or None, optional (default=3)
         Used to restrict the display of floating point values to a certain precision.
     orientation : str, optional (default='horizontal')
         Orientation of the tree.
         Can be 'horizontal' or 'vertical'.
+    example_case : numpy 2-D array, pandas DataFrame or None, optional (default=None)
+        Single row with the same structure as the training data.
+        If not None, the plot will highlight the path that sample takes through the tree.
+
+        .. versionadded:: 4.0.0
+
     **kwargs
         Other parameters passed to ``Digraph`` constructor.
         Check https://graphviz.readthedocs.io/en/stable/api.html#digraph for the full list of supported parameters.
 
     Returns
     -------
     ax : matplotlib.axes.Axes
@@ -679,15 +818,15 @@
     if ax is None:
         if figsize is not None:
             _check_not_tuple_of_2_elements(figsize, 'figsize')
         _, ax = plt.subplots(1, 1, figsize=figsize, dpi=dpi)
 
     graph = create_tree_digraph(booster=booster, tree_index=tree_index,
                                 show_info=show_info, precision=precision,
-                                orientation=orientation, **kwargs)
+                                orientation=orientation, example_case=example_case, **kwargs)
 
     s = BytesIO()
     s.write(graph.pipe(format='png'))
     s.seek(0)
     img = image.imread(s)
 
     ax.imshow(img)
```

### Comparing `lightgbm-3.3.5/lightgbm/sklearn.py` & `lightgbm-4.0.0/lightgbm/sklearn.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,117 +1,177 @@
 # coding: utf-8
 """Scikit-learn wrapper interface for LightGBM."""
 import copy
 from inspect import signature
-from typing import Callable, Dict, Optional, Union
+from pathlib import Path
+from typing import Any, Callable, Dict, List, Optional, Tuple, Union
 
 import numpy as np
+import scipy.sparse
 
-from .basic import Dataset, LightGBMError, _choose_param_value, _ConfigAliases, _log_warning
-from .callback import log_evaluation, record_evaluation
+from .basic import (Booster, Dataset, LightGBMError, _choose_param_value, _ConfigAliases, _LGBM_BoosterBestScoreType,
+                    _LGBM_CategoricalFeatureConfiguration, _LGBM_EvalFunctionResultType, _LGBM_FeatureNameConfiguration,
+                    _LGBM_GroupType, _LGBM_InitScoreType, _LGBM_LabelType, _LGBM_WeightType, _log_warning)
+from .callback import _EvalResultDict, record_evaluation
 from .compat import (SKLEARN_INSTALLED, LGBMNotFittedError, _LGBMAssertAllFinite, _LGBMCheckArray,
                      _LGBMCheckClassificationTargets, _LGBMCheckSampleWeight, _LGBMCheckXY, _LGBMClassifierBase,
-                     _LGBMComputeSampleWeight, _LGBMLabelEncoder, _LGBMModelBase, _LGBMRegressorBase, dt_DataTable,
-                     pd_DataFrame)
+                     _LGBMComputeSampleWeight, _LGBMCpuCount, _LGBMLabelEncoder, _LGBMModelBase, _LGBMRegressorBase,
+                     dt_DataTable, pd_DataFrame)
 from .engine import train
 
+__all__ = [
+    'LGBMClassifier',
+    'LGBMModel',
+    'LGBMRanker',
+    'LGBMRegressor',
+]
+
+_LGBM_ScikitMatrixLike = Union[
+    dt_DataTable,
+    List[Union[List[float], List[int]]],
+    np.ndarray,
+    pd_DataFrame,
+    scipy.sparse.spmatrix
+]
+_LGBM_ScikitCustomObjectiveFunction = Union[
+    # f(labels, preds)
+    Callable[
+        [Optional[np.ndarray], np.ndarray],
+        Tuple[np.ndarray, np.ndarray]
+    ],
+    # f(labels, preds, weights)
+    Callable[
+        [Optional[np.ndarray], np.ndarray, Optional[np.ndarray]],
+        Tuple[np.ndarray, np.ndarray]
+    ],
+    # f(labels, preds, weights, group)
+    Callable[
+        [Optional[np.ndarray], np.ndarray, Optional[np.ndarray], Optional[np.ndarray]],
+        Tuple[np.ndarray, np.ndarray]
+    ],
+]
+_LGBM_ScikitCustomEvalFunction = Union[
+    # f(labels, preds)
+    Callable[
+        [Optional[np.ndarray], np.ndarray],
+        _LGBM_EvalFunctionResultType
+    ],
+    Callable[
+        [Optional[np.ndarray], np.ndarray],
+        List[_LGBM_EvalFunctionResultType]
+    ],
+    # f(labels, preds, weights)
+    Callable[
+        [Optional[np.ndarray], np.ndarray, Optional[np.ndarray]],
+        _LGBM_EvalFunctionResultType
+    ],
+    Callable[
+        [Optional[np.ndarray], np.ndarray, Optional[np.ndarray]],
+        List[_LGBM_EvalFunctionResultType]
+    ],
+    # f(labels, preds, weights, group)
+    Callable[
+        [Optional[np.ndarray], np.ndarray, Optional[np.ndarray], Optional[np.ndarray]],
+        _LGBM_EvalFunctionResultType
+    ],
+    Callable[
+        [Optional[np.ndarray], np.ndarray, Optional[np.ndarray], Optional[np.ndarray]],
+        List[_LGBM_EvalFunctionResultType]
+    ]
+]
+_LGBM_ScikitEvalMetricType = Union[
+    str,
+    _LGBM_ScikitCustomEvalFunction,
+    List[Union[str, _LGBM_ScikitCustomEvalFunction]]
+]
+_LGBM_ScikitValidSet = Tuple[_LGBM_ScikitMatrixLike, _LGBM_LabelType]
+
 
 class _ObjectiveFunctionWrapper:
     """Proxy class for objective function."""
 
-    def __init__(self, func):
+    def __init__(self, func: _LGBM_ScikitCustomObjectiveFunction):
         """Construct a proxy class.
 
         This class transforms objective function to match objective function with signature ``new_func(preds, dataset)``
         as expected by ``lightgbm.engine.train``.
 
         Parameters
         ----------
         func : callable
-            Expects a callable with signature ``func(y_true, y_pred)`` or ``func(y_true, y_pred, group)``
+            Expects a callable with following signatures:
+            ``func(y_true, y_pred)``,
+            ``func(y_true, y_pred, weight)``
+            or ``func(y_true, y_pred, weight, group)``
             and returns (grad, hess):
 
-                y_true : array-like of shape = [n_samples]
+                y_true : numpy 1-D array of shape = [n_samples]
                     The target values.
-                y_pred : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)
+                y_pred : numpy 1-D array of shape = [n_samples] or numpy 2-D array of shape = [n_samples, n_classes] (for multi-class task)
                     The predicted values.
                     Predicted values are returned before any transformation,
                     e.g. they are raw margin instead of probability of positive class for binary task.
-                group : array-like
+                weight : numpy 1-D array of shape = [n_samples]
+                    The weight of samples. Weights should be non-negative.
+                group : numpy 1-D array
                     Group/query data.
                     Only used in the learning-to-rank task.
                     sum(group) = n_samples.
                     For example, if you have a 100-document dataset with ``group = [10, 20, 40, 10, 10, 10]``, that means that you have 6 groups,
                     where the first 10 records are in the first group, records 11-30 are in the second group, records 31-70 are in the third group, etc.
-                grad : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)
+                grad : numpy 1-D array of shape = [n_samples] or numpy 2-D array of shape [n_samples, n_classes] (for multi-class task)
                     The value of the first order derivative (gradient) of the loss
                     with respect to the elements of y_pred for each sample point.
-                hess : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)
+                hess : numpy 1-D array of shape = [n_samples] or numpy 2-D array of shape = [n_samples, n_classes] (for multi-class task)
                     The value of the second order derivative (Hessian) of the loss
                     with respect to the elements of y_pred for each sample point.
 
         .. note::
 
-            For multi-class task, the y_pred is group by class_id first, then group by row_id.
-            If you want to get i-th row y_pred in j-th class, the access way is y_pred[j * num_data + i]
-            and you should group grad and hess in this way as well.
+            For multi-class task, y_pred is a numpy 2-D array of shape = [n_samples, n_classes],
+            and grad and hess should be returned in the same format.
         """
         self.func = func
 
-    def __call__(self, preds, dataset):
+    def __call__(self, preds: np.ndarray, dataset: Dataset) -> Tuple[np.ndarray, np.ndarray]:
         """Call passed function with appropriate arguments.
 
         Parameters
         ----------
-        preds : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)
+        preds : numpy 1-D array of shape = [n_samples] or numpy 2-D array of shape = [n_samples, n_classes] (for multi-class task)
             The predicted values.
         dataset : Dataset
             The training dataset.
 
         Returns
         -------
-        grad : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)
+        grad : numpy 1-D array of shape = [n_samples] or numpy 2-D array of shape = [n_samples, n_classes] (for multi-class task)
             The value of the first order derivative (gradient) of the loss
             with respect to the elements of preds for each sample point.
-        hess : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)
+        hess : numpy 1-D array of shape = [n_samples] or numpy 2-D array of shape = [n_samples, n_classes] (for multi-class task)
             The value of the second order derivative (Hessian) of the loss
             with respect to the elements of preds for each sample point.
         """
         labels = dataset.get_label()
         argc = len(signature(self.func).parameters)
         if argc == 2:
-            grad, hess = self.func(labels, preds)
+            grad, hess = self.func(labels, preds)  # type: ignore[call-arg]
         elif argc == 3:
-            grad, hess = self.func(labels, preds, dataset.get_group())
+            grad, hess = self.func(labels, preds, dataset.get_weight())  # type: ignore[call-arg]
+        elif argc == 4:
+            grad, hess = self.func(labels, preds, dataset.get_weight(), dataset.get_group())  # type: ignore [call-arg]
         else:
-            raise TypeError(f"Self-defined objective function should have 2 or 3 arguments, got {argc}")
-        """weighted for objective"""
-        weight = dataset.get_weight()
-        if weight is not None:
-            """only one class"""
-            if len(weight) == len(grad):
-                grad = np.multiply(grad, weight)
-                hess = np.multiply(hess, weight)
-            else:
-                num_data = len(weight)
-                num_class = len(grad) // num_data
-                if num_class * num_data != len(grad):
-                    raise ValueError("Length of grad and hess should equal to num_class * num_data")
-                for k in range(num_class):
-                    for i in range(num_data):
-                        idx = k * num_data + i
-                        grad[idx] *= weight[i]
-                        hess[idx] *= weight[i]
+            raise TypeError(f"Self-defined objective function should have 2, 3 or 4 arguments, got {argc}")
         return grad, hess
 
 
 class _EvalFunctionWrapper:
     """Proxy class for evaluation function."""
 
-    def __init__(self, func):
+    def __init__(self, func: _LGBM_ScikitCustomEvalFunction):
         """Construct a proxy class.
 
         This class transforms evaluation function to match evaluation function with signature ``new_func(preds, dataset)``
         as expected by ``lightgbm.engine.train``.
 
         Parameters
         ----------
@@ -119,48 +179,47 @@
             Expects a callable with following signatures:
             ``func(y_true, y_pred)``,
             ``func(y_true, y_pred, weight)``
             or ``func(y_true, y_pred, weight, group)``
             and returns (eval_name, eval_result, is_higher_better) or
             list of (eval_name, eval_result, is_higher_better):
 
-                y_true : array-like of shape = [n_samples]
+                y_true : numpy 1-D array of shape = [n_samples]
                     The target values.
-                y_pred : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)
+                y_pred : numpy 1-D array of shape = [n_samples] or numpy 2-D array shape = [n_samples, n_classes] (for multi-class task)
                     The predicted values.
                     In case of custom ``objective``, predicted values are returned before any transformation,
                     e.g. they are raw margin instead of probability of positive class for binary task in this case.
-                weight : array-like of shape = [n_samples]
-                    The weight of samples.
-                group : array-like
+                weight : numpy 1-D array of shape = [n_samples]
+                    The weight of samples. Weights should be non-negative.
+                group : numpy 1-D array
                     Group/query data.
                     Only used in the learning-to-rank task.
                     sum(group) = n_samples.
                     For example, if you have a 100-document dataset with ``group = [10, 20, 40, 10, 10, 10]``, that means that you have 6 groups,
                     where the first 10 records are in the first group, records 11-30 are in the second group, records 31-70 are in the third group, etc.
                 eval_name : str
                     The name of evaluation function (without whitespace).
                 eval_result : float
                     The eval result.
                 is_higher_better : bool
                     Is eval result higher better, e.g. AUC is ``is_higher_better``.
-
-        .. note::
-
-            For multi-class task, the y_pred is group by class_id first, then group by row_id.
-            If you want to get i-th row y_pred in j-th class, the access way is y_pred[j * num_data + i].
         """
         self.func = func
 
-    def __call__(self, preds, dataset):
+    def __call__(
+        self,
+        preds: np.ndarray,
+        dataset: Dataset
+    ) -> Union[_LGBM_EvalFunctionResultType, List[_LGBM_EvalFunctionResultType]]:
         """Call passed function with appropriate arguments.
 
         Parameters
         ----------
-        preds : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)
+        preds : numpy 1-D array of shape = [n_samples] or numpy 2-D array of shape = [n_samples, n_classes] (for multi-class task)
             The predicted values.
         dataset : Dataset
             The training dataset.
 
         Returns
         -------
         eval_name : str
@@ -169,19 +228,19 @@
             The eval result.
         is_higher_better : bool
             Is eval result higher better, e.g. AUC is ``is_higher_better``.
         """
         labels = dataset.get_label()
         argc = len(signature(self.func).parameters)
         if argc == 2:
-            return self.func(labels, preds)
+            return self.func(labels, preds)  # type: ignore[call-arg]
         elif argc == 3:
-            return self.func(labels, preds, dataset.get_weight())
+            return self.func(labels, preds, dataset.get_weight())  # type: ignore[call-arg]
         elif argc == 4:
-            return self.func(labels, preds, dataset.get_weight(), dataset.get_group())
+            return self.func(labels, preds, dataset.get_weight(), dataset.get_group())  # type: ignore[call-arg]
         else:
             raise TypeError(f"Self-defined eval function should have 2, 3 or 4 arguments, got {argc}")
 
 
 # documentation templates for LGBMModel methods are shared between the classes in
 # this module and those in the ``dask`` module
 
@@ -192,117 +251,96 @@
     Parameters
     ----------
     X : {X_shape}
         Input feature matrix.
     y : {y_shape}
         The target values (class labels in classification, real numbers in regression).
     sample_weight : {sample_weight_shape}
-        Weights of training data.
+        Weights of training data. Weights should be non-negative.
     init_score : {init_score_shape}
         Init score of training data.
     group : {group_shape}
         Group/query data.
         Only used in the learning-to-rank task.
         sum(group) = n_samples.
         For example, if you have a 100-document dataset with ``group = [10, 20, 40, 10, 10, 10]``, that means that you have 6 groups,
         where the first 10 records are in the first group, records 11-30 are in the second group, records 31-70 are in the third group, etc.
     eval_set : list or None, optional (default=None)
         A list of (X, y) tuple pairs to use as validation sets.
     eval_names : list of str, or None, optional (default=None)
         Names of eval_set.
     eval_sample_weight : {eval_sample_weight_shape}
-        Weights of eval data.
+        Weights of eval data. Weights should be non-negative.
     eval_class_weight : list or None, optional (default=None)
         Class weights of eval data.
     eval_init_score : {eval_init_score_shape}
         Init score of eval data.
     eval_group : {eval_group_shape}
         Group data of eval data.
     eval_metric : str, callable, list or None, optional (default=None)
         If str, it should be a built-in evaluation metric to use.
         If callable, it should be a custom evaluation metric, see note below for more details.
         If list, it can be a list of built-in metrics, a list of custom evaluation metrics, or a mix of both.
         In either case, the ``metric`` from the model parameters will be evaluated and used as well.
         Default: 'l2' for LGBMRegressor, 'logloss' for LGBMClassifier, 'ndcg' for LGBMRanker.
-    early_stopping_rounds : int or None, optional (default=None)
-        Activates early stopping. The model will train until the validation score stops improving.
-        Validation score needs to improve at least every ``early_stopping_rounds`` round(s)
-        to continue training.
-        Requires at least one validation data and one metric.
-        If there's more than one, will check all of them. But the training data is ignored anyway.
-        To check only the first metric, set the ``first_metric_only`` parameter to ``True``
-        in additional parameters ``**kwargs`` of the model constructor.
-    verbose : bool or int, optional (default=True)
-        Requires at least one evaluation data.
-        If True, the eval metric on the eval set is printed at each boosting stage.
-        If int, the eval metric on the eval set is printed at every ``verbose`` boosting stage.
-        The last boosting stage or the boosting stage found by using ``early_stopping_rounds`` is also printed.
-
-        .. rubric:: Example
-
-        With ``verbose`` = 4 and at least one item in ``eval_set``,
-        an evaluation metric is printed every 4 (instead of 1) boosting stages.
-
     feature_name : list of str, or 'auto', optional (default='auto')
         Feature names.
         If 'auto' and data is pandas DataFrame, data columns names are used.
     categorical_feature : list of str or int, or 'auto', optional (default='auto')
         Categorical features.
         If list of int, interpreted as indices.
         If list of str, interpreted as feature names (need to specify ``feature_name`` as well).
         If 'auto' and data is pandas DataFrame, pandas unordered categorical columns are used.
-        All values in categorical features should be less than int32 max value (2147483647).
+        All values in categorical features will be cast to int32 and thus should be less than int32 max value (2147483647).
         Large values could be memory consuming. Consider using consecutive integers starting from zero.
         All negative values in categorical features will be treated as missing values.
         The output cannot be monotonically constrained with respect to a categorical feature.
+        Floating point numbers in categorical features will be rounded towards 0.
     callbacks : list of callable, or None, optional (default=None)
         List of callback functions that are applied at each iteration.
         See Callbacks in Python API for more information.
     init_model : str, pathlib.Path, Booster, LGBMModel or None, optional (default=None)
         Filename of LightGBM model, Booster instance or LGBMModel instance used for continue training.
 
     Returns
     -------
-    self : object
+    self : LGBMModel
         Returns self.
     """
 )
 
 _lgbmmodel_doc_custom_eval_note = """
     Note
     ----
     Custom eval function expects a callable with following signatures:
     ``func(y_true, y_pred)``, ``func(y_true, y_pred, weight)`` or
     ``func(y_true, y_pred, weight, group)``
     and returns (eval_name, eval_result, is_higher_better) or
     list of (eval_name, eval_result, is_higher_better):
 
-        y_true : array-like of shape = [n_samples]
+        y_true : numpy 1-D array of shape = [n_samples]
             The target values.
-        y_pred : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)
+        y_pred : numpy 1-D array of shape = [n_samples] or numpy 2-D array of shape = [n_samples, n_classes] (for multi-class task)
             The predicted values.
             In case of custom ``objective``, predicted values are returned before any transformation,
             e.g. they are raw margin instead of probability of positive class for binary task in this case.
-        weight : array-like of shape = [n_samples]
-            The weight of samples.
-        group : array-like
+        weight : numpy 1-D array of shape = [n_samples]
+            The weight of samples. Weights should be non-negative.
+        group : numpy 1-D array
             Group/query data.
             Only used in the learning-to-rank task.
             sum(group) = n_samples.
             For example, if you have a 100-document dataset with ``group = [10, 20, 40, 10, 10, 10]``, that means that you have 6 groups,
             where the first 10 records are in the first group, records 11-30 are in the second group, records 31-70 are in the third group, etc.
         eval_name : str
             The name of evaluation function (without whitespace).
         eval_result : float
             The eval result.
         is_higher_better : bool
             Is eval result higher better, e.g. AUC is ``is_higher_better``.
-
-    For multi-class task, the y_pred is group by class_id first, then group by row_id.
-    If you want to get i-th row y_pred in j-th class, the access way is y_pred[j * num_data + i].
 """
 
 _lgbmmodel_doc_predict = (
     """
     {description}
 
     Parameters
@@ -328,14 +366,17 @@
 
             If you want to get more explanations for your model's predictions using SHAP values,
             like SHAP interaction values,
             you can install the shap package (https://github.com/slundberg/shap).
             Note that unlike the shap package, with ``pred_contrib`` we return a matrix with an extra
             column, where the last column is the expected value.
 
+    validate_features : bool, optional (default=False)
+        If True, ensure that the features used to predict match the ones used to train.
+        Used only if data is pandas DataFrame.
     **kwargs
         Other parameters for the prediction.
 
     Returns
     -------
     {output_name} : {predicted_result_shape}
         The predicted values.
@@ -354,38 +395,36 @@
         self,
         boosting_type: str = 'gbdt',
         num_leaves: int = 31,
         max_depth: int = -1,
         learning_rate: float = 0.1,
         n_estimators: int = 100,
         subsample_for_bin: int = 200000,
-        objective: Optional[Union[str, Callable]] = None,
+        objective: Optional[Union[str, _LGBM_ScikitCustomObjectiveFunction]] = None,
         class_weight: Optional[Union[Dict, str]] = None,
         min_split_gain: float = 0.,
         min_child_weight: float = 1e-3,
         min_child_samples: int = 20,
         subsample: float = 1.,
         subsample_freq: int = 0,
         colsample_bytree: float = 1.,
         reg_alpha: float = 0.,
         reg_lambda: float = 0.,
         random_state: Optional[Union[int, np.random.RandomState]] = None,
-        n_jobs: int = -1,
-        silent: Union[bool, str] = 'warn',
+        n_jobs: Optional[int] = None,
         importance_type: str = 'split',
         **kwargs
     ):
         r"""Construct a gradient boosting model.
 
         Parameters
         ----------
         boosting_type : str, optional (default='gbdt')
             'gbdt', traditional Gradient Boosting Decision Tree.
             'dart', Dropouts meet Multiple Additive Regression Trees.
-            'goss', Gradient-based One-Side Sampling.
             'rf', Random Forest.
         num_leaves : int, optional (default=31)
             Maximum tree leaves for base learners.
         max_depth : int, optional (default=-1)
             Maximum tree depth for base learners, <=0 means no limit.
         learning_rate : float, optional (default=0.1)
             Boosting learning rate.
@@ -411,15 +450,15 @@
             inversely proportional to class frequencies in the input data as ``n_samples / (n_classes * np.bincount(y))``.
             If None, all classes are supposed to have weight one.
             Note, that these weights will be multiplied with ``sample_weight`` (passed through the ``fit`` method)
             if ``sample_weight`` is specified.
         min_split_gain : float, optional (default=0.)
             Minimum loss reduction required to make a further partition on a leaf node of the tree.
         min_child_weight : float, optional (default=1e-3)
-            Minimum sum of instance weight (hessian) needed in a child (leaf).
+            Minimum sum of instance weight (Hessian) needed in a child (leaf).
         min_child_samples : int, optional (default=20)
             Minimum number of data needed in a child (leaf).
         subsample : float, optional (default=1.)
             Subsample ratio of the training instance.
         subsample_freq : int, optional (default=0)
             Frequency of subsample, <=0 means no enable.
         colsample_bytree : float, optional (default=1.)
@@ -429,18 +468,29 @@
         reg_lambda : float, optional (default=0.)
             L2 regularization term on weights.
         random_state : int, RandomState object or None, optional (default=None)
             Random number seed.
             If int, this number is used to seed the C++ code.
             If RandomState object (numpy), a random integer is picked based on its state to seed the C++ code.
             If None, default seeds in C++ code are used.
-        n_jobs : int, optional (default=-1)
-            Number of parallel threads.
-        silent : bool, optional (default=True)
-            Whether to print messages while running boosting.
+        n_jobs : int or None, optional (default=None)
+            Number of parallel threads to use for training (can be changed at prediction time by
+            passing it as an extra keyword argument).
+
+            For better performance, it is recommended to set this to the number of physical cores
+            in the CPU.
+
+            Negative integers are interpreted as following joblib's formula (n_cpus + 1 + n_jobs), just like
+            scikit-learn (so e.g. -1 means using all threads). A value of zero corresponds the default number of
+            threads configured for OpenMP in the system. A value of ``None`` (the default) corresponds
+            to using the number of physical cores in the system (its correct detection requires
+            either the ``joblib`` or the ``psutil`` util libraries to be installed).
+
+            .. versionchanged:: 4.0.0
+
         importance_type : str, optional (default='split')
             The type of feature importance to be filled into ``feature_importances_``.
             If 'split', result contains numbers of times the feature is used in a model.
             If 'gain', result contains total gains of splits which use the feature.
         **kwargs
             Other parameters for the model.
             Check http://lightgbm.readthedocs.io/en/latest/Parameters.html for more parameters.
@@ -449,39 +499,41 @@
 
                 \*\*kwargs is not supported in sklearn, it may cause unexpected issues.
 
         Note
         ----
         A custom objective function can be provided for the ``objective`` parameter.
         In this case, it should have the signature
-        ``objective(y_true, y_pred) -> grad, hess`` or
-        ``objective(y_true, y_pred, group) -> grad, hess``:
+        ``objective(y_true, y_pred) -> grad, hess``,
+        ``objective(y_true, y_pred, weight) -> grad, hess``
+        or ``objective(y_true, y_pred, weight, group) -> grad, hess``:
 
-            y_true : array-like of shape = [n_samples]
+            y_true : numpy 1-D array of shape = [n_samples]
                 The target values.
-            y_pred : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)
+            y_pred : numpy 1-D array of shape = [n_samples] or numpy 2-D array of shape = [n_samples, n_classes] (for multi-class task)
                 The predicted values.
                 Predicted values are returned before any transformation,
                 e.g. they are raw margin instead of probability of positive class for binary task.
-            group : array-like
+            weight : numpy 1-D array of shape = [n_samples]
+                The weight of samples. Weights should be non-negative.
+            group : numpy 1-D array
                 Group/query data.
                 Only used in the learning-to-rank task.
                 sum(group) = n_samples.
                 For example, if you have a 100-document dataset with ``group = [10, 20, 40, 10, 10, 10]``, that means that you have 6 groups,
                 where the first 10 records are in the first group, records 11-30 are in the second group, records 31-70 are in the third group, etc.
-            grad : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)
+            grad : numpy 1-D array of shape = [n_samples] or numpy 2-D array of shape = [n_samples, n_classes] (for multi-class task)
                 The value of the first order derivative (gradient) of the loss
                 with respect to the elements of y_pred for each sample point.
-            hess : array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task)
+            hess : numpy 1-D array of shape = [n_samples] or numpy 2-D array of shape = [n_samples, n_classes] (for multi-class task)
                 The value of the second order derivative (Hessian) of the loss
                 with respect to the elements of y_pred for each sample point.
 
-        For multi-class task, the y_pred is group by class_id first, then group by row_id.
-        If you want to get i-th row y_pred in j-th class, the access way is y_pred[j * num_data + i]
-        and you should group grad and hess in this way as well.
+        For multi-class task, y_pred is a numpy 2-D array of shape = [n_samples, n_classes],
+        and grad and hess should be returned in the same format.
         """
         if not SKLEARN_INSTALLED:
             raise LightGBMError('scikit-learn is required for lightgbm.sklearn. '
                                 'You must install scikit-learn and restart your session to use this module.')
 
         self.boosting_type = boosting_type
         self.objective = objective
@@ -496,47 +548,46 @@
         self.subsample = subsample
         self.subsample_freq = subsample_freq
         self.colsample_bytree = colsample_bytree
         self.reg_alpha = reg_alpha
         self.reg_lambda = reg_lambda
         self.random_state = random_state
         self.n_jobs = n_jobs
-        self.silent = silent
         self.importance_type = importance_type
-        self._Booster = None
-        self._evals_result = None
-        self._best_score = None
-        self._best_iteration = None
-        self._other_params = {}
+        self._Booster: Optional[Booster] = None
+        self._evals_result: _EvalResultDict = {}
+        self._best_score: _LGBM_BoosterBestScoreType = {}
+        self._best_iteration: int = -1
+        self._other_params: Dict[str, Any] = {}
         self._objective = objective
         self.class_weight = class_weight
-        self._class_weight = None
-        self._class_map = None
-        self._n_features = None
-        self._n_features_in = None
-        self._classes = None
-        self._n_classes = None
+        self._class_weight: Optional[Union[Dict, str]] = None
+        self._class_map: Optional[Dict[int, int]] = None
+        self._n_features: int = -1
+        self._n_features_in: int = -1
+        self._classes: Optional[np.ndarray] = None
+        self._n_classes: int = -1
         self.set_params(**kwargs)
 
-    def _more_tags(self):
+    def _more_tags(self) -> Dict[str, Any]:
         return {
             'allow_nan': True,
             'X_types': ['2darray', 'sparse', '1dlabels'],
             '_xfail_checks': {
                 'check_no_attributes_set_in_init':
                 'scikit-learn incorrectly asserts that private attributes '
                 'cannot be set in __init__: '
                 '(see https://github.com/microsoft/LightGBM/issues/2628)'
             }
         }
 
     def __sklearn_is_fitted__(self) -> bool:
         return getattr(self, "fitted_", False)
 
-    def get_params(self, deep=True):
+    def get_params(self, deep: bool = True) -> Dict[str, Any]:
         """Get parameters for this estimator.
 
         Parameters
         ----------
         deep : bool, optional (default=True)
             If True, will return the parameters for this estimator and
             contained subobjects that are estimators.
@@ -546,15 +597,15 @@
         params : dict
             Parameter names mapped to their values.
         """
         params = super().get_params(deep=deep)
         params.update(self._other_params)
         return params
 
-    def set_params(self, **params):
+    def set_params(self, **params: Any) -> "LGBMModel":
         """Set the parameters of this estimator.
 
         Parameters
         ----------
         **params
             Parameter names with their new values.
 
@@ -566,78 +617,75 @@
         for key, value in params.items():
             setattr(self, key, value)
             if hasattr(self, f"_{key}"):
                 setattr(self, f"_{key}", value)
             self._other_params[key] = value
         return self
 
-    def fit(self, X, y,
-            sample_weight=None, init_score=None, group=None,
-            eval_set=None, eval_names=None, eval_sample_weight=None,
-            eval_class_weight=None, eval_init_score=None, eval_group=None,
-            eval_metric=None, early_stopping_rounds=None, verbose='warn',
-            feature_name='auto', categorical_feature='auto',
-            callbacks=None, init_model=None):
-        """Docstring is set after definition, using a template."""
-        if self._objective is None:
-            if isinstance(self, LGBMRegressor):
-                self._objective = "regression"
-            elif isinstance(self, LGBMClassifier):
-                self._objective = "binary"
-            elif isinstance(self, LGBMRanker):
-                self._objective = "lambdarank"
-            else:
-                raise ValueError("Unknown LGBMModel type.")
-        if callable(self._objective):
-            self._fobj = _ObjectiveFunctionWrapper(self._objective)
-        else:
-            self._fobj = None
+    def _process_params(self, stage: str) -> Dict[str, Any]:
+        """Process the parameters of this estimator based on its type, parameter aliases, etc.
+
+        Parameters
+        ----------
+        stage : str
+            Name of the stage (can be ``fit`` or ``predict``) this method is called from.
 
+        Returns
+        -------
+        processed_params : dict
+            Processed parameter names mapped to their values.
+        """
+        assert stage in {"fit", "predict"}
         params = self.get_params()
-        # user can set verbose with kwargs, it has higher priority
-        if self.silent != "warn":
-            _log_warning("'silent' argument is deprecated and will be removed in a future release of LightGBM. "
-                         "Pass 'verbose' parameter via keyword arguments instead.")
-            silent = self.silent
+
+        params.pop('objective', None)
+        for alias in _ConfigAliases.get('objective'):
+            if alias in params:
+                obj = params.pop(alias)
+                _log_warning(f"Found '{alias}' in params. Will use it instead of 'objective' argument")
+                if stage == "fit":
+                    self._objective = obj
+        if stage == "fit":
+            if self._objective is None:
+                if isinstance(self, LGBMRegressor):
+                    self._objective = "regression"
+                elif isinstance(self, LGBMClassifier):
+                    if self._n_classes > 2:
+                        self._objective = "multiclass"
+                    else:
+                        self._objective = "binary"
+                elif isinstance(self, LGBMRanker):
+                    self._objective = "lambdarank"
+                else:
+                    raise ValueError("Unknown LGBMModel type.")
+        if callable(self._objective):
+            if stage == "fit":
+                params['objective'] = _ObjectiveFunctionWrapper(self._objective)
+            else:
+                params['objective'] = 'None'
         else:
-            silent = True
-        if not any(verbose_alias in params for verbose_alias in _ConfigAliases.get("verbosity")) and silent:
-            params['verbose'] = -1
-        params.pop('silent', None)
+            params['objective'] = self._objective
+
         params.pop('importance_type', None)
         params.pop('n_estimators', None)
         params.pop('class_weight', None)
+
         if isinstance(params['random_state'], np.random.RandomState):
             params['random_state'] = params['random_state'].randint(np.iinfo(np.int32).max)
-        for alias in _ConfigAliases.get('objective'):
-            params.pop(alias, None)
-        if self._n_classes is not None and self._n_classes > 2:
+        if self._n_classes > 2:
             for alias in _ConfigAliases.get('num_class'):
                 params.pop(alias, None)
             params['num_class'] = self._n_classes
         if hasattr(self, '_eval_at'):
             eval_at = self._eval_at
             for alias in _ConfigAliases.get('eval_at'):
                 if alias in params:
                     _log_warning(f"Found '{alias}' in params. Will use it instead of 'eval_at' argument")
                     eval_at = params.pop(alias)
             params['eval_at'] = eval_at
-        params['objective'] = self._objective
-        if self._fobj:
-            params['objective'] = 'None'  # objective = nullptr for unknown objective
-
-        # Do not modify original args in fit function
-        # Refer to https://github.com/microsoft/LightGBM/pull/2619
-        eval_metric_list = copy.deepcopy(eval_metric)
-        if not isinstance(eval_metric_list, list):
-            eval_metric_list = [eval_metric_list]
-
-        # Separate built-in from callable evaluation metrics
-        eval_metrics_callable = [_EvalFunctionWrapper(f) for f in eval_metric_list if callable(f)]
-        eval_metrics_builtin = [m for m in eval_metric_list if isinstance(m, str)]
 
         # register default metric for consistency with callable eval_metric case
         original_metric = self._objective if isinstance(self._objective, str) else None
         if original_metric is None:
             # try to deduce from class instance
             if isinstance(self, LGBMRegressor):
                 original_metric = "l2"
@@ -645,14 +693,78 @@
                 original_metric = "multi_logloss" if self._n_classes > 2 else "binary_logloss"
             elif isinstance(self, LGBMRanker):
                 original_metric = "ndcg"
 
         # overwrite default metric by explicitly set metric
         params = _choose_param_value("metric", params, original_metric)
 
+        # use joblib conventions for negative n_jobs, just like scikit-learn
+        # at predict time, this is handled later due to the order of parameter updates
+        if stage == "fit":
+            params = _choose_param_value("num_threads", params, self.n_jobs)
+            params["num_threads"] = self._process_n_jobs(params["num_threads"])
+
+        return params
+
+    def _process_n_jobs(self, n_jobs: Optional[int]) -> int:
+        """Convert special values of n_jobs to their actual values according to the formulas that apply.
+
+        Parameters
+        ----------
+        n_jobs : int or None
+            The original value of n_jobs, potentially having special values such as 'None' or
+            negative integers.
+
+        Returns
+        -------
+        n_jobs : int
+            The value of n_jobs with special values converted to actual number of threads.
+        """
+        if n_jobs is None:
+            n_jobs = _LGBMCpuCount(only_physical_cores=True)
+        elif n_jobs < 0:
+            n_jobs = max(_LGBMCpuCount(only_physical_cores=False) + 1 + n_jobs, 1)
+        return n_jobs
+
+    def fit(
+        self,
+        X: _LGBM_ScikitMatrixLike,
+        y: _LGBM_LabelType,
+        sample_weight: Optional[_LGBM_WeightType] = None,
+        init_score: Optional[_LGBM_InitScoreType] = None,
+        group: Optional[_LGBM_GroupType] = None,
+        eval_set: Optional[List[_LGBM_ScikitValidSet]] = None,
+        eval_names: Optional[List[str]] = None,
+        eval_sample_weight: Optional[List[_LGBM_WeightType]] = None,
+        eval_class_weight: Optional[List[float]] = None,
+        eval_init_score: Optional[List[_LGBM_InitScoreType]] = None,
+        eval_group: Optional[List[_LGBM_GroupType]] = None,
+        eval_metric: Optional[_LGBM_ScikitEvalMetricType] = None,
+        feature_name: _LGBM_FeatureNameConfiguration = 'auto',
+        categorical_feature: _LGBM_CategoricalFeatureConfiguration = 'auto',
+        callbacks: Optional[List[Callable]] = None,
+        init_model: Optional[Union[str, Path, Booster, "LGBMModel"]] = None
+    ) -> "LGBMModel":
+        """Docstring is set after definition, using a template."""
+        params = self._process_params(stage="fit")
+
+        # Do not modify original args in fit function
+        # Refer to https://github.com/microsoft/LightGBM/pull/2619
+        eval_metric_list: List[Union[str, _LGBM_ScikitCustomEvalFunction]]
+        if eval_metric is None:
+            eval_metric_list = []
+        elif isinstance(eval_metric, list):
+            eval_metric_list = copy.deepcopy(eval_metric)
+        else:
+            eval_metric_list = [copy.deepcopy(eval_metric)]
+
+        # Separate built-in from callable evaluation metrics
+        eval_metrics_callable = [_EvalFunctionWrapper(f) for f in eval_metric_list if callable(f)]
+        eval_metrics_builtin = [m for m in eval_metric_list if isinstance(m, str)]
+
         # concatenate metric from params (or default if not provided in params) and eval_metric
         params['metric'] = [params['metric']] if isinstance(params['metric'], (str, type(None))) else params['metric']
         params['metric'] = [e for e in eval_metrics_builtin if e not in params['metric']] + params['metric']
         params['metric'] = [metric for metric in params['metric'] if metric is not None]
 
         if not isinstance(X, (pd_DataFrame, dt_DataTable)):
             _X, _y = _LGBMCheckXY(X, y, accept_sparse=True, force_all_finite=False, ensure_min_samples=2)
@@ -670,24 +782,19 @@
             else:
                 sample_weight = np.multiply(sample_weight, class_sample_weight)
 
         self._n_features = _X.shape[1]
         # copy for consistency
         self._n_features_in = self._n_features
 
-        def _construct_dataset(X, y, sample_weight, init_score, group, params,
-                               categorical_feature='auto'):
-            return Dataset(X, label=y, weight=sample_weight, group=group,
-                           init_score=init_score, params=params,
-                           categorical_feature=categorical_feature)
-
-        train_set = _construct_dataset(_X, _y, sample_weight, init_score, group, params,
-                                       categorical_feature=categorical_feature)
+        train_set = Dataset(data=_X, label=_y, weight=sample_weight, group=group,
+                            init_score=init_score, categorical_feature=categorical_feature,
+                            params=params)
 
-        valid_sets = []
+        valid_sets: List[Dataset] = []
         if eval_set is not None:
 
             def _get_meta_data(collection, name, i):
                 if collection is None:
                     return None
                 elif isinstance(collection, list):
                     return collection[i] if len(collection) > i else None
@@ -711,322 +818,435 @@
                         valid_class_sample_weight = _LGBMComputeSampleWeight(valid_class_weight, valid_data[1])
                         if valid_weight is None or len(valid_weight) == 0:
                             valid_weight = valid_class_sample_weight
                         else:
                             valid_weight = np.multiply(valid_weight, valid_class_sample_weight)
                     valid_init_score = _get_meta_data(eval_init_score, 'eval_init_score', i)
                     valid_group = _get_meta_data(eval_group, 'eval_group', i)
-                    valid_set = _construct_dataset(valid_data[0], valid_data[1],
-                                                   valid_weight, valid_init_score, valid_group, params)
+                    valid_set = Dataset(data=valid_data[0], label=valid_data[1], weight=valid_weight,
+                                        group=valid_group, init_score=valid_init_score,
+                                        categorical_feature='auto', params=params)
+
                 valid_sets.append(valid_set)
 
         if isinstance(init_model, LGBMModel):
             init_model = init_model.booster_
 
-        if early_stopping_rounds is not None and early_stopping_rounds > 0:
-            _log_warning("'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. "
-                         "Pass 'early_stopping()' callback via 'callbacks' argument instead.")
-            params['early_stopping_rounds'] = early_stopping_rounds
-
         if callbacks is None:
             callbacks = []
         else:
             callbacks = copy.copy(callbacks)  # don't use deepcopy here to allow non-serializable objects
 
-        if verbose != 'warn':
-            _log_warning("'verbose' argument is deprecated and will be removed in a future release of LightGBM. "
-                         "Pass 'log_evaluation()' callback via 'callbacks' argument instead.")
-        else:
-            if callbacks:  # assume user has already specified log_evaluation callback
-                verbose = False
-            else:
-                verbose = True
-        callbacks.append(log_evaluation(int(verbose)))
-
-        evals_result = {}
+        evals_result: _EvalResultDict = {}
         callbacks.append(record_evaluation(evals_result))
 
         self._Booster = train(
             params=params,
             train_set=train_set,
             num_boost_round=self.n_estimators,
             valid_sets=valid_sets,
             valid_names=eval_names,
-            fobj=self._fobj,
-            feval=eval_metrics_callable,
+            feval=eval_metrics_callable,  # type: ignore[arg-type]
             init_model=init_model,
             feature_name=feature_name,
             callbacks=callbacks
         )
 
-        if evals_result:
-            self._evals_result = evals_result
-        else:  # reset after previous call to fit()
-            self._evals_result = None
-
-        if self._Booster.best_iteration != 0:
-            self._best_iteration = self._Booster.best_iteration
-        else:  # reset after previous call to fit()
-            self._best_iteration = None
-
+        self._evals_result = evals_result
+        self._best_iteration = self._Booster.best_iteration
         self._best_score = self._Booster.best_score
 
         self.fitted_ = True
 
         # free dataset
         self._Booster.free_dataset()
         del train_set, valid_sets
         return self
 
     fit.__doc__ = _lgbmmodel_doc_fit.format(
-        X_shape="array-like or sparse matrix of shape = [n_samples, n_features]",
-        y_shape="array-like of shape = [n_samples]",
-        sample_weight_shape="array-like of shape = [n_samples] or None, optional (default=None)",
-        init_score_shape="array-like of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task) or shape = [n_samples, n_classes] (for multi-class task) or None, optional (default=None)",
-        group_shape="array-like or None, optional (default=None)",
-        eval_sample_weight_shape="list of array, or None, optional (default=None)",
-        eval_init_score_shape="list of array, or None, optional (default=None)",
-        eval_group_shape="list of array, or None, optional (default=None)"
+        X_shape="numpy array, pandas DataFrame, H2O DataTable's Frame , scipy.sparse, list of lists of int or float of shape = [n_samples, n_features]",
+        y_shape="numpy array, pandas DataFrame, pandas Series, list of int or float of shape = [n_samples]",
+        sample_weight_shape="numpy array, pandas Series, list of int or float of shape = [n_samples] or None, optional (default=None)",
+        init_score_shape="numpy array, pandas DataFrame, pandas Series, list of int or float of shape = [n_samples] or shape = [n_samples * n_classes] (for multi-class task) or shape = [n_samples, n_classes] (for multi-class task) or None, optional (default=None)",
+        group_shape="numpy array, pandas Series, list of int or float, or None, optional (default=None)",
+        eval_sample_weight_shape="list of array (same types as ``sample_weight`` supports), or None, optional (default=None)",
+        eval_init_score_shape="list of array (same types as ``init_score`` supports), or None, optional (default=None)",
+        eval_group_shape="list of array (same types as ``group`` supports), or None, optional (default=None)"
     ) + "\n\n" + _lgbmmodel_doc_custom_eval_note
 
-    def predict(self, X, raw_score=False, start_iteration=0, num_iteration=None,
-                pred_leaf=False, pred_contrib=False, **kwargs):
+    def predict(
+        self,
+        X: _LGBM_ScikitMatrixLike,
+        raw_score: bool = False,
+        start_iteration: int = 0,
+        num_iteration: Optional[int] = None,
+        pred_leaf: bool = False,
+        pred_contrib: bool = False,
+        validate_features: bool = False,
+        **kwargs: Any
+    ):
         """Docstring is set after definition, using a template."""
         if not self.__sklearn_is_fitted__():
             raise LGBMNotFittedError("Estimator not fitted, call fit before exploiting the model.")
         if not isinstance(X, (pd_DataFrame, dt_DataTable)):
             X = _LGBMCheckArray(X, accept_sparse=True, force_all_finite=False)
         n_features = X.shape[1]
         if self._n_features != n_features:
             raise ValueError("Number of features of the model must "
                              f"match the input. Model n_features_ is {self._n_features} and "
                              f"input n_features is {n_features}")
-        return self._Booster.predict(X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,
-                                     pred_leaf=pred_leaf, pred_contrib=pred_contrib, **kwargs)
+        # retrive original params that possibly can be used in both training and prediction
+        # and then overwrite them (considering aliases) with params that were passed directly in prediction
+        predict_params = self._process_params(stage="predict")
+        for alias in _ConfigAliases.get_by_alias(
+            "data",
+            "X",
+            "raw_score",
+            "start_iteration",
+            "num_iteration",
+            "pred_leaf",
+            "pred_contrib",
+            *kwargs.keys()
+        ):
+            predict_params.pop(alias, None)
+        predict_params.update(kwargs)
+
+        # number of threads can have values with special meaning which is only applied
+        # in the scikit-learn interface, these should not reach the c++ side as-is
+        predict_params = _choose_param_value("num_threads", predict_params, self.n_jobs)
+        predict_params["num_threads"] = self._process_n_jobs(predict_params["num_threads"])
+
+        return self._Booster.predict(  # type: ignore[union-attr]
+            X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration,
+            pred_leaf=pred_leaf, pred_contrib=pred_contrib, validate_features=validate_features,
+            **predict_params
+        )
 
     predict.__doc__ = _lgbmmodel_doc_predict.format(
         description="Return the predicted value for each sample.",
-        X_shape="array-like or sparse matrix of shape = [n_samples, n_features]",
+        X_shape="numpy array, pandas DataFrame, H2O DataTable's Frame , scipy.sparse, list of lists of int or float of shape = [n_samples, n_features]",
         output_name="predicted_result",
         predicted_result_shape="array-like of shape = [n_samples] or shape = [n_samples, n_classes]",
         X_leaves_shape="array-like of shape = [n_samples, n_trees] or shape = [n_samples, n_trees * n_classes]",
         X_SHAP_values_shape="array-like of shape = [n_samples, n_features + 1] or shape = [n_samples, (n_features + 1) * n_classes] or list with n_classes length of such objects"
     )
 
     @property
-    def n_features_(self):
+    def n_features_(self) -> int:
         """:obj:`int`: The number of features of fitted model."""
         if not self.__sklearn_is_fitted__():
             raise LGBMNotFittedError('No n_features found. Need to call fit beforehand.')
         return self._n_features
 
     @property
-    def n_features_in_(self):
+    def n_features_in_(self) -> int:
         """:obj:`int`: The number of features of fitted model."""
         if not self.__sklearn_is_fitted__():
             raise LGBMNotFittedError('No n_features_in found. Need to call fit beforehand.')
         return self._n_features_in
 
     @property
-    def best_score_(self):
+    def best_score_(self) -> _LGBM_BoosterBestScoreType:
         """:obj:`dict`: The best score of fitted model."""
         if not self.__sklearn_is_fitted__():
             raise LGBMNotFittedError('No best_score found. Need to call fit beforehand.')
         return self._best_score
 
     @property
-    def best_iteration_(self):
-        """:obj:`int` or :obj:`None`: The best iteration of fitted model if ``early_stopping()`` callback has been specified."""
+    def best_iteration_(self) -> int:
+        """:obj:`int`: The best iteration of fitted model if ``early_stopping()`` callback has been specified."""
         if not self.__sklearn_is_fitted__():
             raise LGBMNotFittedError('No best_iteration found. Need to call fit with early_stopping callback beforehand.')
         return self._best_iteration
 
     @property
-    def objective_(self):
+    def objective_(self) -> Union[str, _LGBM_ScikitCustomObjectiveFunction]:
         """:obj:`str` or :obj:`callable`: The concrete objective used while fitting this model."""
         if not self.__sklearn_is_fitted__():
             raise LGBMNotFittedError('No objective found. Need to call fit beforehand.')
-        return self._objective
+        return self._objective  # type: ignore[return-value]
 
     @property
-    def booster_(self):
+    def n_estimators_(self) -> int:
+        """:obj:`int`: True number of boosting iterations performed.
+
+        This might be less than parameter ``n_estimators`` if early stopping was enabled or
+        if boosting stopped early due to limits on complexity like ``min_gain_to_split``.
+        
+        .. versionadded:: 4.0.0
+        """
+        if not self.__sklearn_is_fitted__():
+            raise LGBMNotFittedError('No n_estimators found. Need to call fit beforehand.')
+        return self._Booster.current_iteration()  # type: ignore
+
+    @property
+    def n_iter_(self) -> int:
+        """:obj:`int`: True number of boosting iterations performed.
+
+        This might be less than parameter ``n_estimators`` if early stopping was enabled or
+        if boosting stopped early due to limits on complexity like ``min_gain_to_split``.
+        
+        .. versionadded:: 4.0.0
+        """
+        if not self.__sklearn_is_fitted__():
+            raise LGBMNotFittedError('No n_iter found. Need to call fit beforehand.')
+        return self._Booster.current_iteration()  # type: ignore
+
+    @property
+    def booster_(self) -> Booster:
         """Booster: The underlying Booster of this model."""
         if not self.__sklearn_is_fitted__():
             raise LGBMNotFittedError('No booster found. Need to call fit beforehand.')
-        return self._Booster
+        return self._Booster  # type: ignore[return-value]
 
     @property
-    def evals_result_(self):
-        """:obj:`dict` or :obj:`None`: The evaluation results if validation sets have been specified."""
+    def evals_result_(self) -> _EvalResultDict:
+        """:obj:`dict`: The evaluation results if validation sets have been specified."""
         if not self.__sklearn_is_fitted__():
             raise LGBMNotFittedError('No results found. Need to call fit with eval_set beforehand.')
         return self._evals_result
 
     @property
-    def feature_importances_(self):
+    def feature_importances_(self) -> np.ndarray:
         """:obj:`array` of shape = [n_features]: The feature importances (the higher, the more important).
 
         .. note::
 
             ``importance_type`` attribute is passed to the function
             to configure the type of importance values to be extracted.
         """
         if not self.__sklearn_is_fitted__():
             raise LGBMNotFittedError('No feature_importances found. Need to call fit beforehand.')
-        return self._Booster.feature_importance(importance_type=self.importance_type)
+        return self._Booster.feature_importance(importance_type=self.importance_type)  # type: ignore[union-attr]
 
     @property
-    def feature_name_(self):
-        """:obj:`array` of shape = [n_features]: The names of features."""
+    def feature_name_(self) -> List[str]:
+        """:obj:`list` of shape = [n_features]: The names of features."""
         if not self.__sklearn_is_fitted__():
             raise LGBMNotFittedError('No feature_name found. Need to call fit beforehand.')
-        return self._Booster.feature_name()
+        return self._Booster.feature_name()  # type: ignore[union-attr]
 
 
 class LGBMRegressor(_LGBMRegressorBase, LGBMModel):
     """LightGBM regressor."""
 
-    def fit(self, X, y,
-            sample_weight=None, init_score=None,
-            eval_set=None, eval_names=None, eval_sample_weight=None,
-            eval_init_score=None, eval_metric=None, early_stopping_rounds=None,
-            verbose='warn', feature_name='auto', categorical_feature='auto',
-            callbacks=None, init_model=None):
+    def fit(  # type: ignore[override]
+        self,
+        X: _LGBM_ScikitMatrixLike,
+        y: _LGBM_LabelType,
+        sample_weight: Optional[_LGBM_WeightType] = None,
+        init_score: Optional[_LGBM_InitScoreType] = None,
+        eval_set: Optional[List[_LGBM_ScikitValidSet]] = None,
+        eval_names: Optional[List[str]] = None,
+        eval_sample_weight: Optional[List[_LGBM_WeightType]] = None,
+        eval_init_score: Optional[List[_LGBM_InitScoreType]] = None,
+        eval_metric: Optional[_LGBM_ScikitEvalMetricType] = None,
+        feature_name: _LGBM_FeatureNameConfiguration = 'auto',
+        categorical_feature: _LGBM_CategoricalFeatureConfiguration = 'auto',
+        callbacks: Optional[List[Callable]] = None,
+        init_model: Optional[Union[str, Path, Booster, LGBMModel]] = None
+    ) -> "LGBMRegressor":
         """Docstring is inherited from the LGBMModel."""
-        super().fit(X, y, sample_weight=sample_weight, init_score=init_score,
-                    eval_set=eval_set, eval_names=eval_names, eval_sample_weight=eval_sample_weight,
-                    eval_init_score=eval_init_score, eval_metric=eval_metric,
-                    early_stopping_rounds=early_stopping_rounds, verbose=verbose, feature_name=feature_name,
-                    categorical_feature=categorical_feature, callbacks=callbacks, init_model=init_model)
+        super().fit(
+            X,
+            y,
+            sample_weight=sample_weight,
+            init_score=init_score,
+            eval_set=eval_set,
+            eval_names=eval_names,
+            eval_sample_weight=eval_sample_weight,
+            eval_init_score=eval_init_score,
+            eval_metric=eval_metric,
+            feature_name=feature_name,
+            categorical_feature=categorical_feature,
+            callbacks=callbacks,
+            init_model=init_model
+        )
         return self
 
-    _base_doc = LGBMModel.fit.__doc__
+    _base_doc = LGBMModel.fit.__doc__.replace("self : LGBMModel", "self : LGBMRegressor")  # type: ignore
     _base_doc = (_base_doc[:_base_doc.find('group :')]  # type: ignore
                  + _base_doc[_base_doc.find('eval_set :'):])  # type: ignore
     _base_doc = (_base_doc[:_base_doc.find('eval_class_weight :')]
                  + _base_doc[_base_doc.find('eval_init_score :'):])
     fit.__doc__ = (_base_doc[:_base_doc.find('eval_group :')]
                    + _base_doc[_base_doc.find('eval_metric :'):])
 
 
 class LGBMClassifier(_LGBMClassifierBase, LGBMModel):
     """LightGBM classifier."""
 
-    def fit(self, X, y,
-            sample_weight=None, init_score=None,
-            eval_set=None, eval_names=None, eval_sample_weight=None,
-            eval_class_weight=None, eval_init_score=None, eval_metric=None,
-            early_stopping_rounds=None, verbose='warn',
-            feature_name='auto', categorical_feature='auto',
-            callbacks=None, init_model=None):
+    def fit(  # type: ignore[override]
+        self,
+        X: _LGBM_ScikitMatrixLike,
+        y: _LGBM_LabelType,
+        sample_weight: Optional[_LGBM_WeightType] = None,
+        init_score: Optional[_LGBM_InitScoreType] = None,
+        eval_set: Optional[List[_LGBM_ScikitValidSet]] = None,
+        eval_names: Optional[List[str]] = None,
+        eval_sample_weight: Optional[List[_LGBM_WeightType]] = None,
+        eval_class_weight: Optional[List[float]] = None,
+        eval_init_score: Optional[List[_LGBM_InitScoreType]] = None,
+        eval_metric: Optional[_LGBM_ScikitEvalMetricType] = None,
+        feature_name: _LGBM_FeatureNameConfiguration = 'auto',
+        categorical_feature: _LGBM_CategoricalFeatureConfiguration = 'auto',
+        callbacks: Optional[List[Callable]] = None,
+        init_model: Optional[Union[str, Path, Booster, LGBMModel]] = None
+    ) -> "LGBMClassifier":
         """Docstring is inherited from the LGBMModel."""
         _LGBMAssertAllFinite(y)
         _LGBMCheckClassificationTargets(y)
         self._le = _LGBMLabelEncoder().fit(y)
         _y = self._le.transform(y)
         self._class_map = dict(zip(self._le.classes_, self._le.transform(self._le.classes_)))
         if isinstance(self.class_weight, dict):
             self._class_weight = {self._class_map[k]: v for k, v in self.class_weight.items()}
 
         self._classes = self._le.classes_
-        self._n_classes = len(self._classes)
-
-        if self._n_classes > 2:
-            # Switch to using a multiclass objective in the underlying LGBM instance
-            ova_aliases = {"multiclassova", "multiclass_ova", "ova", "ovr"}
-            if self._objective not in ova_aliases and not callable(self._objective):
-                self._objective = "multiclass"
+        self._n_classes = len(self._classes)  # type: ignore[arg-type]
 
+        # adjust eval metrics to match whether binary or multiclass
+        # classification is being performed
         if not callable(eval_metric):
-            if isinstance(eval_metric, (str, type(None))):
-                eval_metric = [eval_metric]
+            if isinstance(eval_metric, list):
+                eval_metric_list = eval_metric
+            elif isinstance(eval_metric, str):
+                eval_metric_list = [eval_metric]
+            else:
+                eval_metric_list = []
             if self._n_classes > 2:
-                for index, metric in enumerate(eval_metric):
+                for index, metric in enumerate(eval_metric_list):
                     if metric in {'logloss', 'binary_logloss'}:
-                        eval_metric[index] = "multi_logloss"
+                        eval_metric_list[index] = "multi_logloss"
                     elif metric in {'error', 'binary_error'}:
-                        eval_metric[index] = "multi_error"
+                        eval_metric_list[index] = "multi_error"
             else:
-                for index, metric in enumerate(eval_metric):
+                for index, metric in enumerate(eval_metric_list):
                     if metric in {'logloss', 'multi_logloss'}:
-                        eval_metric[index] = 'binary_logloss'
+                        eval_metric_list[index] = 'binary_logloss'
                     elif metric in {'error', 'multi_error'}:
-                        eval_metric[index] = 'binary_error'
+                        eval_metric_list[index] = 'binary_error'
+            eval_metric = eval_metric_list
 
         # do not modify args, as it causes errors in model selection tools
-        valid_sets = None
+        valid_sets: Optional[List[_LGBM_ScikitValidSet]] = None
         if eval_set is not None:
             if isinstance(eval_set, tuple):
                 eval_set = [eval_set]
-            valid_sets = [None] * len(eval_set)
-            for i, (valid_x, valid_y) in enumerate(eval_set):
+            valid_sets = []
+            for valid_x, valid_y in eval_set:
                 if valid_x is X and valid_y is y:
-                    valid_sets[i] = (valid_x, _y)
+                    valid_sets.append((valid_x, _y))
                 else:
-                    valid_sets[i] = (valid_x, self._le.transform(valid_y))
+                    valid_sets.append((valid_x, self._le.transform(valid_y)))
 
-        super().fit(X, _y, sample_weight=sample_weight, init_score=init_score, eval_set=valid_sets,
-                    eval_names=eval_names, eval_sample_weight=eval_sample_weight,
-                    eval_class_weight=eval_class_weight, eval_init_score=eval_init_score,
-                    eval_metric=eval_metric, early_stopping_rounds=early_stopping_rounds,
-                    verbose=verbose, feature_name=feature_name, categorical_feature=categorical_feature,
-                    callbacks=callbacks, init_model=init_model)
+        super().fit(
+            X,
+            _y,
+            sample_weight=sample_weight,
+            init_score=init_score,
+            eval_set=valid_sets,
+            eval_names=eval_names,
+            eval_sample_weight=eval_sample_weight,
+            eval_class_weight=eval_class_weight,
+            eval_init_score=eval_init_score,
+            eval_metric=eval_metric,
+            feature_name=feature_name,
+            categorical_feature=categorical_feature,
+            callbacks=callbacks,
+            init_model=init_model
+        )
         return self
 
-    _base_doc = LGBMModel.fit.__doc__
+    _base_doc = LGBMModel.fit.__doc__.replace("self : LGBMModel", "self : LGBMClassifier")  # type: ignore
     _base_doc = (_base_doc[:_base_doc.find('group :')]  # type: ignore
                  + _base_doc[_base_doc.find('eval_set :'):])  # type: ignore
     fit.__doc__ = (_base_doc[:_base_doc.find('eval_group :')]
                    + _base_doc[_base_doc.find('eval_metric :'):])
 
-    def predict(self, X, raw_score=False, start_iteration=0, num_iteration=None,
-                pred_leaf=False, pred_contrib=False, **kwargs):
+    def predict(
+        self,
+        X: _LGBM_ScikitMatrixLike,
+        raw_score: bool = False,
+        start_iteration: int = 0,
+        num_iteration: Optional[int] = None,
+        pred_leaf: bool = False,
+        pred_contrib: bool = False,
+        validate_features: bool = False,
+        **kwargs: Any
+    ):
         """Docstring is inherited from the LGBMModel."""
-        result = self.predict_proba(X, raw_score, start_iteration, num_iteration,
-                                    pred_leaf, pred_contrib, **kwargs)
+        result = self.predict_proba(
+            X=X,
+            raw_score=raw_score,
+            start_iteration=start_iteration,
+            num_iteration=num_iteration,
+            pred_leaf=pred_leaf,
+            pred_contrib=pred_contrib,
+            validate_features=validate_features,
+            **kwargs
+        )
         if callable(self._objective) or raw_score or pred_leaf or pred_contrib:
             return result
         else:
             class_index = np.argmax(result, axis=1)
             return self._le.inverse_transform(class_index)
 
     predict.__doc__ = LGBMModel.predict.__doc__
 
-    def predict_proba(self, X, raw_score=False, start_iteration=0, num_iteration=None,
-                      pred_leaf=False, pred_contrib=False, **kwargs):
+    def predict_proba(
+        self,
+        X: _LGBM_ScikitMatrixLike,
+        raw_score: bool = False,
+        start_iteration: int = 0,
+        num_iteration: Optional[int] = None,
+        pred_leaf: bool = False,
+        pred_contrib: bool = False,
+        validate_features: bool = False,
+        **kwargs: Any
+    ):
         """Docstring is set after definition, using a template."""
-        result = super().predict(X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, **kwargs)
+        result = super().predict(
+            X=X,
+            raw_score=raw_score,
+            start_iteration=start_iteration,
+            num_iteration=num_iteration,
+            pred_leaf=pred_leaf,
+            pred_contrib=pred_contrib,
+            validate_features=validate_features,
+            **kwargs
+        )
         if callable(self._objective) and not (raw_score or pred_leaf or pred_contrib):
             _log_warning("Cannot compute class probabilities or labels "
                          "due to the usage of customized objective function.\n"
                          "Returning raw scores instead.")
             return result
-        elif self._n_classes > 2 or raw_score or pred_leaf or pred_contrib:
+        elif self._n_classes > 2 or raw_score or pred_leaf or pred_contrib:  # type: ignore [operator]
             return result
         else:
             return np.vstack((1. - result, result)).transpose()
 
     predict_proba.__doc__ = _lgbmmodel_doc_predict.format(
         description="Return the predicted probability for each class for each sample.",
-        X_shape="array-like or sparse matrix of shape = [n_samples, n_features]",
+        X_shape="numpy array, pandas DataFrame, H2O DataTable's Frame , scipy.sparse, list of lists of int or float of shape = [n_samples, n_features]",
         output_name="predicted_probability",
         predicted_result_shape="array-like of shape = [n_samples] or shape = [n_samples, n_classes]",
         X_leaves_shape="array-like of shape = [n_samples, n_trees] or shape = [n_samples, n_trees * n_classes]",
         X_SHAP_values_shape="array-like of shape = [n_samples, n_features + 1] or shape = [n_samples, (n_features + 1) * n_classes] or list with n_classes length of such objects"
     )
 
     @property
-    def classes_(self):
+    def classes_(self) -> np.ndarray:
         """:obj:`array` of shape = [n_classes]: The class label array."""
         if not self.__sklearn_is_fitted__():
             raise LGBMNotFittedError('No classes found. Need to call fit beforehand.')
-        return self._classes
+        return self._classes  # type: ignore[return-value]
 
     @property
-    def n_classes_(self):
+    def n_classes_(self) -> int:
         """:obj:`int`: The number of classes."""
         if not self.__sklearn_is_fitted__():
             raise LGBMNotFittedError('No classes found. Need to call fit beforehand.')
         return self._n_classes
 
 
 class LGBMRanker(LGBMModel):
@@ -1035,21 +1255,33 @@
     .. warning::
 
         scikit-learn doesn't support ranking applications yet,
         therefore this class is not really compatible with the sklearn ecosystem.
         Please use this class mainly for training and applying ranking models in common sklearnish way.
     """
 
-    def fit(self, X, y,
-            sample_weight=None, init_score=None, group=None,
-            eval_set=None, eval_names=None, eval_sample_weight=None,
-            eval_init_score=None, eval_group=None, eval_metric=None,
-            eval_at=(1, 2, 3, 4, 5), early_stopping_rounds=None, verbose='warn',
-            feature_name='auto', categorical_feature='auto',
-            callbacks=None, init_model=None):
+    def fit(  # type: ignore[override]
+        self,
+        X: _LGBM_ScikitMatrixLike,
+        y: _LGBM_LabelType,
+        sample_weight: Optional[_LGBM_WeightType] = None,
+        init_score: Optional[_LGBM_InitScoreType] = None,
+        group: Optional[_LGBM_GroupType] = None,
+        eval_set: Optional[List[_LGBM_ScikitValidSet]] = None,
+        eval_names: Optional[List[str]] = None,
+        eval_sample_weight: Optional[List[_LGBM_WeightType]] = None,
+        eval_init_score: Optional[List[_LGBM_InitScoreType]] = None,
+        eval_group: Optional[List[_LGBM_GroupType]] = None,
+        eval_metric: Optional[_LGBM_ScikitEvalMetricType] = None,
+        eval_at: Union[List[int], Tuple[int, ...]] = (1, 2, 3, 4, 5),
+        feature_name: _LGBM_FeatureNameConfiguration = 'auto',
+        categorical_feature: _LGBM_CategoricalFeatureConfiguration = 'auto',
+        callbacks: Optional[List[Callable]] = None,
+        init_model: Optional[Union[str, Path, Booster, LGBMModel]] = None
+    ) -> "LGBMRanker":
         """Docstring is inherited from the LGBMModel."""
         # check group data
         if group is None:
             raise ValueError("Should set group for ranking task")
 
         if eval_set is not None:
             if eval_group is None:
@@ -1060,22 +1292,34 @@
                   and any(i not in eval_group or eval_group[i] is None for i in range(len(eval_group)))
                   or isinstance(eval_group, list)
                   and any(group is None for group in eval_group)):
                 raise ValueError("Should set group for all eval datasets for ranking task; "
                                  "if you use dict, the index should start from 0")
 
         self._eval_at = eval_at
-        super().fit(X, y, sample_weight=sample_weight, init_score=init_score, group=group,
-                    eval_set=eval_set, eval_names=eval_names, eval_sample_weight=eval_sample_weight,
-                    eval_init_score=eval_init_score, eval_group=eval_group, eval_metric=eval_metric,
-                    early_stopping_rounds=early_stopping_rounds, verbose=verbose, feature_name=feature_name,
-                    categorical_feature=categorical_feature, callbacks=callbacks, init_model=init_model)
+        super().fit(
+            X,
+            y,
+            sample_weight=sample_weight,
+            init_score=init_score,
+            group=group,
+            eval_set=eval_set,
+            eval_names=eval_names,
+            eval_sample_weight=eval_sample_weight,
+            eval_init_score=eval_init_score,
+            eval_group=eval_group,
+            eval_metric=eval_metric,
+            feature_name=feature_name,
+            categorical_feature=categorical_feature,
+            callbacks=callbacks,
+            init_model=init_model
+        )
         return self
 
-    _base_doc = LGBMModel.fit.__doc__
+    _base_doc = LGBMModel.fit.__doc__.replace("self : LGBMModel", "self : LGBMRanker")  # type: ignore
     fit.__doc__ = (_base_doc[:_base_doc.find('eval_class_weight :')]  # type: ignore
                    + _base_doc[_base_doc.find('eval_init_score :'):])  # type: ignore
     _base_doc = fit.__doc__
-    _before_early_stop, _early_stop, _after_early_stop = _base_doc.partition('early_stopping_rounds :')
-    fit.__doc__ = f"""{_before_early_stop}eval_at : iterable of int, optional (default=(1, 2, 3, 4, 5))
+    _before_feature_name, _feature_name, _after_feature_name = _base_doc.partition('feature_name :')
+    fit.__doc__ = f"""{_before_feature_name}eval_at : list or tuple of int, optional (default=(1, 2, 3, 4, 5))
         The evaluation positions of the specified metric.
-    {_early_stop}{_after_early_stop}"""
+    {_feature_name}{_after_feature_name}"""
```

