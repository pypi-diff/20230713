# Comparing `tmp/stix_shifter_modules_datadog-5.3.0.dev827-py2.py3-none-any.whl.zip` & `tmp/stix_shifter_modules_datadog-5.3.1-py2.py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,25 +1,25 @@
-Zip file size: 29839 bytes, number of entries: 23
--rw-rw-r--  2.0 unx        0 b- defN 23-May-25 15:57 stix_shifter_modules/datadog/__init__.py
--rw-rw-r--  2.0 unx      431 b- defN 23-May-25 15:57 stix_shifter_modules/datadog/entry_point.py
--rw-rw-r--  2.0 unx    15968 b- defN 23-May-25 15:58 stix_shifter_modules/datadog/configuration/config.json
--rw-rw-r--  2.0 unx      155 b- defN 23-May-25 15:58 stix_shifter_modules/datadog/configuration/dialects.json
--rw-rw-r--  2.0 unx     2692 b- defN 23-May-25 15:58 stix_shifter_modules/datadog/configuration/lang_en.json
--rw-rw-r--  2.0 unx        0 b- defN 23-May-25 15:57 stix_shifter_modules/datadog/stix_translation/__init__.py
--rw-rw-r--  2.0 unx    22536 b- defN 23-May-25 15:58 stix_shifter_modules/datadog/stix_translation/json_to_stix_translator.py
--rw-rw-r--  2.0 unx    14016 b- defN 23-May-25 15:57 stix_shifter_modules/datadog/stix_translation/query_constructor.py
--rw-rw-r--  2.0 unx     1029 b- defN 23-May-25 15:57 stix_shifter_modules/datadog/stix_translation/query_translator.py
--rw-rw-r--  2.0 unx      780 b- defN 23-May-25 15:57 stix_shifter_modules/datadog/stix_translation/json/events_from_stix_map.json
--rw-rw-r--  2.0 unx      248 b- defN 23-May-25 15:57 stix_shifter_modules/datadog/stix_translation/json/operators.json
--rw-rw-r--  2.0 unx     1062 b- defN 23-May-25 15:57 stix_shifter_modules/datadog/stix_translation/json/processes_from_stix_map.json
--rw-rw-r--  2.0 unx     2523 b- defN 23-May-25 15:57 stix_shifter_modules/datadog/stix_translation/json/to_stix_map.json
--rw-rw-r--  2.0 unx        0 b- defN 23-May-25 15:57 stix_shifter_modules/datadog/stix_transmission/__init__.py
--rw-rw-r--  2.0 unx     3631 b- defN 23-May-25 15:57 stix_shifter_modules/datadog/stix_transmission/api_client.py
--rw-rw-r--  2.0 unx     6880 b- defN 23-May-25 15:57 stix_shifter_modules/datadog/stix_transmission/connector.py
--rw-rw-r--  2.0 unx     1032 b- defN 23-May-25 15:57 stix_shifter_modules/datadog/stix_transmission/error_mapper.py
--rw-rw-r--  2.0 unx    12786 b- defN 23-May-25 15:58 stix_shifter_modules_datadog-5.3.0.dev827.dist-info/LICENSE.md
--rw-rw-r--  2.0 unx     8123 b- defN 23-May-25 15:58 stix_shifter_modules_datadog-5.3.0.dev827.dist-info/METADATA
--rw-rw-r--  2.0 unx     1418 b- defN 23-May-25 15:58 stix_shifter_modules_datadog-5.3.0.dev827.dist-info/NOTICE
--rw-rw-r--  2.0 unx      110 b- defN 23-May-25 15:58 stix_shifter_modules_datadog-5.3.0.dev827.dist-info/WHEEL
--rw-rw-r--  2.0 unx       21 b- defN 23-May-25 15:58 stix_shifter_modules_datadog-5.3.0.dev827.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     2639 b- defN 23-May-25 15:58 stix_shifter_modules_datadog-5.3.0.dev827.dist-info/RECORD
-23 files, 98080 bytes uncompressed, 25281 bytes compressed:  74.2%
+Zip file size: 30059 bytes, number of entries: 23
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jun-15 14:04 stix_shifter_modules/datadog/__init__.py
+-rw-rw-r--  2.0 unx      431 b- defN 23-Jun-15 14:04 stix_shifter_modules/datadog/entry_point.py
+-rw-rw-r--  2.0 unx    15927 b- defN 23-Jun-15 14:07 stix_shifter_modules/datadog/configuration/config.json
+-rw-rw-r--  2.0 unx      155 b- defN 23-Jun-15 14:07 stix_shifter_modules/datadog/configuration/dialects.json
+-rw-rw-r--  2.0 unx     2692 b- defN 23-Jun-15 14:07 stix_shifter_modules/datadog/configuration/lang_en.json
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jun-15 14:04 stix_shifter_modules/datadog/stix_translation/__init__.py
+-rw-rw-r--  2.0 unx    22646 b- defN 23-Jun-15 14:07 stix_shifter_modules/datadog/stix_translation/json_to_stix_translator.py
+-rw-rw-r--  2.0 unx    14016 b- defN 23-Jun-15 14:04 stix_shifter_modules/datadog/stix_translation/query_constructor.py
+-rw-rw-r--  2.0 unx     1029 b- defN 23-Jun-15 14:04 stix_shifter_modules/datadog/stix_translation/query_translator.py
+-rw-rw-r--  2.0 unx      780 b- defN 23-Jun-15 14:04 stix_shifter_modules/datadog/stix_translation/json/events_from_stix_map.json
+-rw-rw-r--  2.0 unx      248 b- defN 23-Jun-15 14:04 stix_shifter_modules/datadog/stix_translation/json/operators.json
+-rw-rw-r--  2.0 unx     1062 b- defN 23-Jun-15 14:04 stix_shifter_modules/datadog/stix_translation/json/processes_from_stix_map.json
+-rw-rw-r--  2.0 unx     2510 b- defN 23-Jun-15 14:04 stix_shifter_modules/datadog/stix_translation/json/to_stix_map.json
+-rw-rw-r--  2.0 unx        0 b- defN 23-Jun-15 14:04 stix_shifter_modules/datadog/stix_transmission/__init__.py
+-rw-rw-r--  2.0 unx     5014 b- defN 23-Jun-15 14:04 stix_shifter_modules/datadog/stix_transmission/api_client.py
+-rw-rw-r--  2.0 unx     6473 b- defN 23-Jun-15 14:04 stix_shifter_modules/datadog/stix_transmission/connector.py
+-rw-rw-r--  2.0 unx     1170 b- defN 23-Jun-15 14:04 stix_shifter_modules/datadog/stix_transmission/error_mapper.py
+-rw-rw-r--  2.0 unx    12786 b- defN 23-Jun-15 14:07 stix_shifter_modules_datadog-5.3.1.dist-info/LICENSE.md
+-rw-rw-r--  2.0 unx     8124 b- defN 23-Jun-15 14:07 stix_shifter_modules_datadog-5.3.1.dist-info/METADATA
+-rw-rw-r--  2.0 unx     1418 b- defN 23-Jun-15 14:07 stix_shifter_modules_datadog-5.3.1.dist-info/NOTICE
+-rw-rw-r--  2.0 unx      110 b- defN 23-Jun-15 14:07 stix_shifter_modules_datadog-5.3.1.dist-info/WHEEL
+-rw-rw-r--  2.0 unx       21 b- defN 23-Jun-15 14:07 stix_shifter_modules_datadog-5.3.1.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     2597 b- defN 23-Jun-15 14:07 stix_shifter_modules_datadog-5.3.1.dist-info/RECORD
+23 files, 99209 bytes uncompressed, 25585 bytes compressed:  74.2%
```

## zipnote {}

```diff
@@ -45,26 +45,26 @@
 
 Filename: stix_shifter_modules/datadog/stix_transmission/connector.py
 Comment: 
 
 Filename: stix_shifter_modules/datadog/stix_transmission/error_mapper.py
 Comment: 
 
-Filename: stix_shifter_modules_datadog-5.3.0.dev827.dist-info/LICENSE.md
+Filename: stix_shifter_modules_datadog-5.3.1.dist-info/LICENSE.md
 Comment: 
 
-Filename: stix_shifter_modules_datadog-5.3.0.dev827.dist-info/METADATA
+Filename: stix_shifter_modules_datadog-5.3.1.dist-info/METADATA
 Comment: 
 
-Filename: stix_shifter_modules_datadog-5.3.0.dev827.dist-info/NOTICE
+Filename: stix_shifter_modules_datadog-5.3.1.dist-info/NOTICE
 Comment: 
 
-Filename: stix_shifter_modules_datadog-5.3.0.dev827.dist-info/WHEEL
+Filename: stix_shifter_modules_datadog-5.3.1.dist-info/WHEEL
 Comment: 
 
-Filename: stix_shifter_modules_datadog-5.3.0.dev827.dist-info/top_level.txt
+Filename: stix_shifter_modules_datadog-5.3.1.dist-info/top_level.txt
 Comment: 
 
-Filename: stix_shifter_modules_datadog-5.3.0.dev827.dist-info/RECORD
+Filename: stix_shifter_modules_datadog-5.3.1.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## stix_shifter_modules/datadog/configuration/config.json

### Pretty-printed

 * *Similarity: 0.999999785841557%*

 * *Differences: {"'connection'": "{'options': {'mapping': {'default': {'to_stix_map': {'id': {'transformer': "*

 * *                 "'ToString'}, 'date_happened': {2: {delete: ['cybox']}, 3: {delete: "*

 * *                 "['cybox']}}}}}}}"}*

```diff
@@ -234,20 +234,18 @@
                             },
                             {
                                 "key": "x-oca-event.created",
                                 "object": "x-oca-event",
                                 "transformer": "EpochToTimestamp"
                             },
                             {
-                                "cybox": false,
                                 "key": "first_observed",
                                 "transformer": "EpochToTimestamp"
                             },
                             {
-                                "cybox": false,
                                 "key": "last_observed",
                                 "transformer": "EpochToTimestamp"
                             }
                         ],
                         "device_name": {
                             "key": "x-oca-event.agent",
                             "object": "x-oca-event"
@@ -265,15 +263,16 @@
                                 "key": "x-oca-event.domain_ref",
                                 "object": "x-oca-event",
                                 "references": "domain-name"
                             }
                         ],
                         "id": {
                             "key": "x-oca-event.code",
-                            "object": "x-oca-event"
+                            "object": "x-oca-event",
+                            "transformer": "ToString"
                         },
                         "id_str": {
                             "key": "x-oca-event.code",
                             "object": "x-oca-event"
                         },
                         "is_aggregate": {
                             "key": "x-datadog-event.unaggregated",
```

## stix_shifter_modules/datadog/stix_translation/json_to_stix_translator.py

```diff
@@ -62,15 +62,14 @@
         self.identity_id = data_source["id"]
         self.ds_to_stix_map = ds_to_stix_map
         self.transformers = transformers
         self.options = options
         self.callback = callback
 
         # parse through options
-        self.cybox_default = options.get('cybox_default', True)
 
         self.properties = observable.properties
 
         self.data_source = data_source['name']
         self.ds_key_map = [val for val in self.gen_dict_extract('ds_key', ds_to_stix_map)]
 
         self.bundle = {
@@ -297,27 +296,33 @@
                 if key is None:
                     continue
 
                 transformer = self.transformers[prop['transformer']] if 'transformer' in prop else None
                 references = references = prop['references'] if 'references' in prop else None
                 # unwrap array of stix values to separate stix objects
                 unwrap = True if 'unwrap' in prop and isinstance(data, list) else False
-                cybox = prop.get('cybox', self.cybox_default)
+                if "." in key:
+                    cybox = True
+                else:
+                    cybox = False
+                
+                # cybox = prop.get('cybox', self.cybox_default)
 
                 if self.callback:
                     try:
                         generic_hash_key = self.callback(parent_data, ds_sub_key, key, self.options)
                         if generic_hash_key:
                             key = generic_hash_key
                     except Exception as e:
                         continue
 
                 config_keys = key.split('.')
                 if len(config_keys) < 2:
-                    if False is prop.get('cybox', self.cybox_default): 
+                    # if False is prop.get('cybox', self.cybox_default):
+                    if not cybox:
                         object_tag_ref_map['out_cybox'][key] = self._compose_value_object(data, [], observable_key=key, object_tag_ref_map=object_tag_ref_map, transformer=transformer, references=references, unwrap=unwrap)
                     pass
                 else:
                     type_name = config_keys[0]
                     property_key = config_keys[1]
                     # set the object to combine properties from same SCO
                     parent_key = prop['object'] if 'object' in prop else type_name
```

## stix_shifter_modules/datadog/stix_translation/json/to_stix_map.json

### Pretty-printed

 * *Similarity: 0.9868421052631579%*

 * *Differences: {"'date_happened'": "{2: {delete: ['cybox']}, 3: {delete: ['cybox']}}",*

 * * "'id'": "{'transformer': 'ToString'}"}*

```diff
@@ -15,20 +15,18 @@
         },
         {
             "key": "x-oca-event.created",
             "object": "x-oca-event",
             "transformer": "EpochToTimestamp"
         },
         {
-            "cybox": false,
             "key": "first_observed",
             "transformer": "EpochToTimestamp"
         },
         {
-            "cybox": false,
             "key": "last_observed",
             "transformer": "EpochToTimestamp"
         }
     ],
     "device_name": {
         "key": "x-oca-event.agent",
         "object": "x-oca-event"
@@ -46,15 +44,16 @@
             "key": "x-oca-event.domain_ref",
             "object": "x-oca-event",
             "references": "domain-name"
         }
     ],
     "id": {
         "key": "x-oca-event.code",
-        "object": "x-oca-event"
+        "object": "x-oca-event",
+        "transformer": "ToString"
     },
     "id_str": {
         "key": "x-oca-event.code",
         "object": "x-oca-event"
     },
     "is_aggregate": {
         "key": "x-datadog-event.unaggregated",
```

## stix_shifter_modules/datadog/stix_transmission/api_client.py

```diff
@@ -2,76 +2,100 @@
 import datadog_api_client.v1 
 import datadog_api_client.v1.api 
 from datadog_api_client.v1.api import events_api
 from datadog_api_client.v2.api import processes_api
 from urllib3.exceptions import MaxRetryError
 import urllib3
 
+from stix_shifter_utils.utils import logger
+from stix_shifter_utils.utils.error_response import ErrorResponder
+
+import asyncio
+
 class APIClient:
 
     def __init__(self, connection, configuration):
+        self.logger = logger.set_logger(__name__)
+        self.connector = __name__.split('.')[1]
+
         self.connection = connection
         self.auth = configuration.get('auth')
         self.configuration = datadog_api_client.v1.Configuration(host=connection["site_url"])
         self.configuration.api_key["apiKeyAuth"] = self.auth["api_key"]
         self.configuration.api_key["appKeyAuth"] = self.auth["application_key"]
         self.timeout = connection['options'].get('timeout')
         if "selfSignedCert" in connection:
             self.configuration.ssl_ca_cert = connection["selfSignedCert"]
         else:
             self.configuration.verify_ssl = False
         urllib3.disable_warnings()
 
-    def ping_data_source(self):
+    async def ping_data_source(self):
         """To Validate API key"""
         # Enter a context with an instance of the API client
-        return_obj = {"code": 200}
-        with datadog_api_client.v1.ApiClient(self.configuration) as api_client:
+        # return_obj = {"code": 200}
+        return_obj = {}
+        response_dict = {}
+        async with datadog_api_client.v1.AsyncApiClient(self.configuration) as api_client:
             # Create an instance of the API class
             api_instance = events_api.EventsApi(api_client)
             current_time = int(time.time())
             try:
                 # There is no any specific Datadog endpoint which validate application key
-                api_instance.list_events(start=current_time, end=current_time)
+                await api_instance.list_events(start=current_time, end=current_time)
+                return_obj['success'] = True
             except MaxRetryError as e:
                 e.status = 1004
-                return_obj.update({"code": e.status, "message": e.reason})
+                self.logger.error('error when pinging datasource {}:'.format(e.reason))
+                response_dict['type'] = 'MaxRetryError'
+                response_dict['message'] = 'Server error {}'.format(e.reason)
+                ErrorResponder.fill_error(return_obj, response_dict, ['message'], connector=self.connector)                
             except datadog_api_client.v1.ApiException as e:
-                return_obj.update({"code": e.status, "message": e.reason})
+                self.logger.error('error when pinging datasource: {}'.format(e.reason))
+                response_dict['code'] = e.status
+                response_dict['type'] = 'ServerError'
+                response_dict['message'] = 'Server error: {}'.format(e.reason)
+                ErrorResponder.fill_error(return_obj, response_dict, ['message'], connector=self.connector)
+            except Exception as ex:
+                self.logger.error('error when pinging datasource: {}'.format(ex))
+                response_dict['code'] = ex.errno
+                response_dict['type'] = 'ConnectionError'
+                response_dict['message'] = 'Server error: {}'.format(ex.strerror)
+                ErrorResponder.fill_error(return_obj, response_dict, ['message'], connector=self.connector)
         return return_obj
 
-    def get_search_results(self, search_id, page=None):
+    async def get_search_results(self, search_id, page=None):
         """get the response from Datadog endpoints
         :param search_id: dict, filter parameters
         :param page: int,length value
         :return: response, json object"""
         return_obj = {"code": 200}
         if page:
             search_id.update({"exclude_aggregate": True, "page": page})
         if "source" in search_id:
             search_id["sources"] = search_id.pop("source")
-        with datadog_api_client.v1.ApiClient(self.configuration) as api_client:
+        async with datadog_api_client.v1.AsyncApiClient(self.configuration) as api_client:
             api_instance = events_api.EventsApi(api_client)
             try:
-                api_response = api_instance.list_events(**search_id)
+                api_response = await api_instance.list_events(**search_id)
                 return_obj.update({"data": api_response})
             except datadog_api_client.v1.ApiException as e:
                 return_obj.update({"code": e.status, "message": e.reason})
         return return_obj
 
-    def get_processes_results(self):
+    async def get_processes_results(self):
         return_obj = {"code": 200}
         configuration = datadog_api_client.v2.Configuration(host=self.connection["site_url"])
         configuration.api_key["apiKeyAuth"] = self.auth["api_key"]
         configuration.api_key["appKeyAuth"] = self.auth["application_key"]
         if "selfSignedCert" in self.connection:
             configuration.ssl_ca_cert = self.connection["selfSignedCert"]
         else:
             configuration.verify_ssl = False
-        with datadog_api_client.v2.ApiClient(configuration) as api_client:
+        async with datadog_api_client.v2.AsyncApiClient(configuration) as api_client:
             api_instance = processes_api.ProcessesApi(api_client)
             try:
-                api_response = api_instance.list_processes()
+                api_response = await api_instance.list_processes()
                 return_obj.update({"data": api_response})
             except datadog_api_client.v2.ApiException as e:
                 return_obj.update({"code": e.status, "message": e.reason})
         return return_obj
```

## stix_shifter_modules/datadog/stix_transmission/connector.py

```diff
@@ -8,53 +8,42 @@
 class Connector(BaseJsonSyncConnector):
     def __init__(self, connection, configuration):
         self.api_client = APIClient(connection, configuration)
         self.logger = logger.set_logger(__name__)
         self.connector = __name__.split('.')[1]
 
     async def ping_connection(self):
-        try:
-            response = self.api_client.ping_data_source()
-            # Construct a response object
-            return_obj = dict()
-            if response["code"] == 200:
-                return_obj['success'] = True
-            else:
-                ErrorResponder.fill_error(return_obj, response, ['message'], connector=self.connector)
-            return return_obj
-        except Exception as err:
-            self.logger.error('error when pinging datasource {}:'.format(err))
-            raise
+        return await self.api_client.ping_data_source()
 
     async def create_results_connection(self, query_expr, offset, length):
         payload = json.loads(query_expr)
         if payload['source'] == 'events':
-            return self.get_events(payload, offset, length)
+            return await self.get_events(payload, offset, length)
         else:
-            return self.get_processes(payload, offset, length)
+            return await self.get_processes(payload, offset, length)
 
-    def get_events(self, query_expr, offset, length):
+    async def get_events(self, query_expr, offset, length):
         length = int(length)
         offset = int(offset)
 
         # total records is the sum of the offset and length(limit) value
         total_records = offset + length
         try:
             # Separate out api supported url params
             query_expr, filter_attr = Connector.modify_query_expr(query_expr['query'])
             # Grab the response, extract the response code, and convert it to readable json
-            response_dict = self.api_client.get_search_results(query_expr)
+            response_dict = await self.api_client.get_search_results(query_expr)
             event_list = []
             return_obj = dict()
             if response_dict["code"] == 200:
                 response = response_dict["data"]["events"]
                 response_list = response
                 page = 1
                 while len(response) == 1000 and total_records > len(response_list):
-                    response = self.api_client.get_search_results(query_expr, page=page)
+                    response = await self.api_client.get_search_results(query_expr, page=page)
                     response = response["data"]["events"]
                     response_list = response_list + response
                     page = page + 1
                 # Construct a response object
                 for event in response_list:
                     json_string = json.dumps(event.__dict__, default=str)
                     event_list.append(json.loads(json_string)["_data_store"])
@@ -69,33 +58,33 @@
             return return_obj
         except Exception as err:
             self.logger.error('error when getting search results: {}'.format(err))
             import traceback
             self.logger.error(traceback.print_stack())
             raise
 
-    def get_processes(self, query_expr, offset, length):
+    async def get_processes(self, query_expr, offset, length):
         length = int(length)
         offset = int(offset)
 
         # total records is the sum of the offset and length(limit) value
         total_records = offset + length
         try:
             # Separate out api supported url params
             query_expr, filter_attr = Connector.modify_query_expr(query_expr['query'])
             # Grab the response, extract the response code, and convert it to readable json
-            response_dict = self.api_client.get_processes_results()
+            response_dict = await self.api_client.get_processes_results()
             process_list = []
             return_obj = dict()
             if response_dict["code"] == 200:
                 response = response_dict["data"]["data"]
                 response_list = response
                 page = 1
                 while len(response) == 1000 and total_records > len(response_list):
-                    response = self.api_client.get_processes_results()
+                    response = await self.api_client.get_processes_results()
                     response = response["data"]["data"]
                     response_list = response_list + response
                     page = page + 1
                 # Construct a response object
                 for process in response_list:
                     json_string = json.dumps(process['attributes'].__dict__, default=str)
                     process_list.append(json.loads(json_string)["_data_store"])
```

## stix_shifter_modules/datadog/stix_transmission/error_mapper.py

```diff
@@ -3,32 +3,34 @@
 from stix_shifter_utils.utils import logger
 
 error_mapping = {
     # Authentication Failure
     403: ErrorCode.TRANSMISSION_FORBIDDEN,
     # A request parameter is not valid
     400: ErrorCode.TRANSMISSION_INVALID_PARAMETER,
-    1004: ErrorCode.TRANSMISSION_AUTH_SSL
+    1004: ErrorCode.TRANSMISSION_AUTH_SSL,
+    500: ErrorCode.TRANSMISSION_CONNECT,
+    8: ErrorCode.TRANSMISSION_REMOTE_SYSTEM_IS_UNAVAILABLE
 }
 
 
 class ErrorMapper():
     logger = logger.set_logger(__name__)
     DEFAULT_ERROR = ErrorCode.TRANSMISSION_MODULE_DEFAULT_ERROR
 
     @staticmethod
-    def set_error_code(json_data, return_obj):
+    def set_error_code(json_data, return_obj, connector=None):
         code = None
         try:
             code = int(json_data['code'])
         except Exception:
             pass
 
         error_code = ErrorMapper.DEFAULT_ERROR
 
         if code in error_mapping:
             error_code = error_mapping[code]
 
         if error_code == ErrorMapper.DEFAULT_ERROR:
             ErrorMapper.logger.error("failed to map: " + str(json_data))
 
-        ErrorMapperBase.set_error_code(return_obj, error_code)
+        ErrorMapperBase.set_error_code(return_obj, error_code, connector=connector)
```

## Comparing `stix_shifter_modules_datadog-5.3.0.dev827.dist-info/LICENSE.md` & `stix_shifter_modules_datadog-5.3.1.dist-info/LICENSE.md`

 * *Files identical despite different names*

## Comparing `stix_shifter_modules_datadog-5.3.0.dev827.dist-info/METADATA` & `stix_shifter_modules_datadog-5.3.1.dist-info/METADATA`

 * *Files 2% similar despite different names*

```diff
@@ -1,24 +1,24 @@
 Metadata-Version: 2.1
 Name: stix-shifter-modules-datadog
-Version: 5.3.0.dev827
+Version: 5.3.1
 Summary: Tools and interface to translate STIX formatted results and queries to different data source formats and to set up appropriate connection strings for invoking and triggering actions in openwhisk
 Home-page: https://github.com/opencybersecurityalliance/stix-shifter
 Author: ibm
 Author-email: 
 Project-URL: Source, https://github.com/opencybersecurityalliance/stix-shifter
 Keywords: datasource stix translate transform transmit
 Classifier: License :: OSI Approved :: Apache Software License
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Description-Content-Type: text/markdown
 License-File: LICENSE.md
 License-File: NOTICE
-Requires-Dist: datadog-api-client (==1.2.0)
 Requires-Dist: urllib3 (==1.26.15)
+Requires-Dist: datadog-api-client[async] (==2.12.0)
 
 [![example workflow](https://github.com/opencybersecurityalliance/stix-shifter/actions/workflows/main.yml/badge.svg)](https://github.com/opencybersecurityalliance/stix-shifter/actions)
 [![codecov](https://codecov.io/gh/opencybersecurityalliance/stix-shifter/branch/develop/graph/badge.svg?token=gQvl14peRj)](https://codecov.io/gh/opencybersecurityalliance/stix-shifter)
 
 # Introduction to STIX-Shifter
 
 STIX-shifter is an open source python library allowing software to connect to products that house data repositories by using STIX Patterning, and return results as STIX Observations.
```

## Comparing `stix_shifter_modules_datadog-5.3.0.dev827.dist-info/NOTICE` & `stix_shifter_modules_datadog-5.3.1.dist-info/NOTICE`

 * *Files identical despite different names*

## Comparing `stix_shifter_modules_datadog-5.3.0.dev827.dist-info/RECORD` & `stix_shifter_modules_datadog-5.3.1.dist-info/RECORD`

 * *Files 12% similar despite different names*

```diff
@@ -1,23 +1,23 @@
 stix_shifter_modules/datadog/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 stix_shifter_modules/datadog/entry_point.py,sha256=vrgElLonSDvog-CAlJWyyqb_sAiP27dvE36lFg1Sa7E,431
-stix_shifter_modules/datadog/configuration/config.json,sha256=OZV_8B38B3s2TrzbeDLQR5WO0Ao5lAMljfF2oim0Lbc,15968
+stix_shifter_modules/datadog/configuration/config.json,sha256=echaX6qL8yHQZ6GMbeQg3dF9cLZe4qo6jN3wyPmLNtI,15927
 stix_shifter_modules/datadog/configuration/dialects.json,sha256=VYnXWzomNO0jY52voWiUaiUI-LAeJhTjoOxQAwjideE,155
 stix_shifter_modules/datadog/configuration/lang_en.json,sha256=jIBMailrqrH9zMYyS8Gn6HRcdw-aTjCRIo_BX1SRhaI,2692
 stix_shifter_modules/datadog/stix_translation/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-stix_shifter_modules/datadog/stix_translation/json_to_stix_translator.py,sha256=8KbNAbPFHVIw6CN4tylW35GqJ1sxBZpaxpQaFAM6e0M,22536
+stix_shifter_modules/datadog/stix_translation/json_to_stix_translator.py,sha256=vffR1MRpwX6NMwXy0MldaTecIIzvVSZIlcqXOM8Nx7I,22646
 stix_shifter_modules/datadog/stix_translation/query_constructor.py,sha256=h6W6Cn-V451ikRe_b7See3k16DAh-ayBwdlSQTWI6iY,14016
 stix_shifter_modules/datadog/stix_translation/query_translator.py,sha256=1IsBlz_YYM9s0myfyed9Wy0fqkV82k77UXd_fTEE38w,1029
 stix_shifter_modules/datadog/stix_translation/json/events_from_stix_map.json,sha256=_cTuYjMoHE8RkAYRSkjBF0O7OxBucOuqnfIgtJLvvoU,780
 stix_shifter_modules/datadog/stix_translation/json/operators.json,sha256=q-CKxYlebmzi4MUtDZtnOHj5VJVXK2Dj043Kp2tCahM,248
 stix_shifter_modules/datadog/stix_translation/json/processes_from_stix_map.json,sha256=tz_r9Kdqll1Uo7I8_1DK6Wf04k5jK8u0FMZQlRQgNxs,1062
-stix_shifter_modules/datadog/stix_translation/json/to_stix_map.json,sha256=aC3WrilxQ1vhRMFGJTffhN7jnTsUtFcwU-bzKl0E86U,2523
+stix_shifter_modules/datadog/stix_translation/json/to_stix_map.json,sha256=4DDpvGnENTVco4LFAkLl66GkJqbSj67qZjpqGddOxbc,2510
 stix_shifter_modules/datadog/stix_transmission/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-stix_shifter_modules/datadog/stix_transmission/api_client.py,sha256=2UfI1fmHsuCU9EKn-8OI0oxWZKMnwXo8Y9z6nlTxgkI,3631
-stix_shifter_modules/datadog/stix_transmission/connector.py,sha256=50KSzwfyjAFpCOaBjv6OhWTi-31Iz7in7gBiYbI-kv4,6880
-stix_shifter_modules/datadog/stix_transmission/error_mapper.py,sha256=Cqtt8tnSuoWTP7MupVb0qUCWRW2DcukgTKZ5c0_78L8,1032
-stix_shifter_modules_datadog-5.3.0.dev827.dist-info/LICENSE.md,sha256=ssGEKMVW69oFTBblVhD1YPolqCOyOCJi4wRDRI7xCnU,12786
-stix_shifter_modules_datadog-5.3.0.dev827.dist-info/METADATA,sha256=NGVvkYai24J8oaR9wl2-8MzoROImh6XDN5dc8nQcZfM,8123
-stix_shifter_modules_datadog-5.3.0.dev827.dist-info/NOTICE,sha256=wx-gWE9vSnLJ7YQkrGlMp9VNXOXG57TTxDDRd9CEdYg,1418
-stix_shifter_modules_datadog-5.3.0.dev827.dist-info/WHEEL,sha256=bb2Ot9scclHKMOLDEHY6B2sicWOgugjFKaJsT7vwMQo,110
-stix_shifter_modules_datadog-5.3.0.dev827.dist-info/top_level.txt,sha256=NX-VgUOr8fI-lMXHt3gtjfsEn1UPaGAVszt6Z_CTp2s,21
-stix_shifter_modules_datadog-5.3.0.dev827.dist-info/RECORD,,
+stix_shifter_modules/datadog/stix_transmission/api_client.py,sha256=_04MYHCF6ha5KMxge8eXTEX58NXuxedVOP6AXzlB1ho,5014
+stix_shifter_modules/datadog/stix_transmission/connector.py,sha256=Sgjg2zmC_DczrvGNoXen1HK5moC8mSr67uG7DwTVkFo,6473
+stix_shifter_modules/datadog/stix_transmission/error_mapper.py,sha256=0EOe6nfQjZpoRJQuwlUVDjnuELcVznA-wITQt3tLg6g,1170
+stix_shifter_modules_datadog-5.3.1.dist-info/LICENSE.md,sha256=ssGEKMVW69oFTBblVhD1YPolqCOyOCJi4wRDRI7xCnU,12786
+stix_shifter_modules_datadog-5.3.1.dist-info/METADATA,sha256=xGYFAXmFWPyHijAxRcoVLCfce8mzhAQIcSiWeC_R3wM,8124
+stix_shifter_modules_datadog-5.3.1.dist-info/NOTICE,sha256=wx-gWE9vSnLJ7YQkrGlMp9VNXOXG57TTxDDRd9CEdYg,1418
+stix_shifter_modules_datadog-5.3.1.dist-info/WHEEL,sha256=bb2Ot9scclHKMOLDEHY6B2sicWOgugjFKaJsT7vwMQo,110
+stix_shifter_modules_datadog-5.3.1.dist-info/top_level.txt,sha256=NX-VgUOr8fI-lMXHt3gtjfsEn1UPaGAVszt6Z_CTp2s,21
+stix_shifter_modules_datadog-5.3.1.dist-info/RECORD,,
```

